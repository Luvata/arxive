<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-10-05T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03027" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03030" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03032" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03033" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03043" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03047" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03049" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03052" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03054" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03055" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03059" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03084" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03085" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03086" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03088" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03094" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03103" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03104" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03106" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03111" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03112" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03119" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03121" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03123" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03146" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03147" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03148" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03149" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03150" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03152" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03156" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03158" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03161" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03163" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03165" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03166" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03174" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03178" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03182" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03195" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03206" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03212" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03217" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03218" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03221" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03225" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03228" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03240" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03243" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03253" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03266" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03272" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03273" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03274" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03278" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03281" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03285" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03288" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03294" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03298" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03301" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03302" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03311" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03312" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03314" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03320" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03324" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03331" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03334" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03339" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03342" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03349" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03354" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03358" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03388" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03393" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03396" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03398" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03399" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03400" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03404" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03406" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03410" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03419" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03435" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03447" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03456" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03461" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03466" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03480" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03482" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03485" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03491" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03494" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03500" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03512" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03515" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03529" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03530" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03545" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03546" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03556" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03563" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03572" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03575" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03578" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03581" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03585" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03589" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03597" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03605" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03606" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03611" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03613" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03614" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03618" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03624" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03635" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03641" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03646" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03647" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03652" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03655" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03675" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03684" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03693" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03695" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03696" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03707" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03710" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03714" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03716" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03718" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03720" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03722" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03725" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03731" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1802.00810" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1912.05957" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.11559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2011.15122" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.00696" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2104.07454" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.06178" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.03890" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.03991" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.14883" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.15497" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.02062" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.05120" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.08417" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.02824" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2204.05923" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.03519" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.05250" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.05895" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.11447" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.12266" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.12148" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.01422" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.01944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.00635" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01856" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.02648" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.06074" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.06921" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.05603" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.09350" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.00942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.02787" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.02936" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.04054" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.01751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.09874" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.10650" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.14655" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.16887" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.00195" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.01150" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.06715" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.08979" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.11004" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.14420" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12081" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12766" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13673" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15086" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15357" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15871" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.16102" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.20057" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.03116" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.03364" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.07629" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.08586" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.08827" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.09376" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.13512" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.04333" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.05435" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06092" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06125" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.07726" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.11546" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.00143" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.00436" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.12439" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.16150" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.16738" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.00079" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.01807" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.05395" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.07056" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.07936" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.09472" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.09476" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11745" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12488" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12871" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.13777" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.14073" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.14331" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15294" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.17167" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.17260" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.17329" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.17348" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.17357" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00035" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00247" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00818" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01425" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01690" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02027" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02156" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02357" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02676" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02861" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02964" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02995" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01423" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02671" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2310.03027">
<title>Synergistic Fusion of Graph and Transformer Features for Enhanced Molecular Property Prediction. (arXiv:2310.03027v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2310.03027</link>
<description rdf:parseType="Literal">&lt;p&gt;Molecular property prediction is a critical task in computational drug
discovery. While recent advances in Graph Neural Networks (GNNs) and
Transformers have shown to be effective and promising, they face the following
limitations: Transformer self-attention does not explicitly consider the
underlying molecule structure while GNN feature representation alone is not
sufficient to capture granular and hidden interactions and characteristics that
distinguish similar molecules. To address these limitations, we propose SYN-
FUSION, a novel approach that synergistically combines pre-trained features
from GNNs and Transformers. This approach provides a comprehensive molecular
representation, capturing both the global molecule structure and the individual
atom characteristics. Experimental results on MoleculeNet benchmarks
demonstrate superior performance, surpassing previous models in 5 out of 7
classification datasets and 4 out of 6 regression datasets. The performance of
SYN-FUSION has been compared with other Graph-Transformer models that have been
jointly trained using a combination of transformer and graph features, and it
is found that our approach is on par with those models in terms of performance.
Extensive analysis of the learned fusion model across aspects such as loss,
latent space, and weight distribution further validates the effectiveness of
SYN-FUSION. Finally, an ablation study unequivocally demonstrates that the
synergy achieved by SYN-FUSION surpasses the performance of its individual
model components and their ensemble, offering a substantial improvement in
predicting molecular properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Prakash_M/0/1/0/all/0/1&quot;&gt;M V Sai Prakash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+N_S/0/1/0/all/0/1&quot;&gt;Siddartha Reddy N&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Parab_G/0/1/0/all/0/1&quot;&gt;Ganesh Parab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+V_V/0/1/0/all/0/1&quot;&gt;Varun V&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Vaddina_V/0/1/0/all/0/1&quot;&gt;Vishal Vaddina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gopalakrishnan_S/0/1/0/all/0/1&quot;&gt;Saisubramaniam Gopalakrishnan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03028">
<title>SAF: Smart Aggregation Framework for Revealing Atoms Importance Rank and Improving Prediction Rates in Drug Discovery. (arXiv:2310.03028v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2310.03028</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning, and representation learning in particular, has the
potential to facilitate drug discovery by screening a large chemical space in
silico. A successful approach for representing molecules is to treat them as a
graph and utilize graph neural networks. One of the key limitations of such
methods is the necessity to represent compounds with different numbers of
atoms, which requires aggregating the atom&apos;s information. Common aggregation
operators, such as averaging, result in loss of information at the atom level.
In this work, we propose a novel aggregating approach where each atom is
weighted non-linearly using the Boltzmann distribution with a hyperparameter
analogous to temperature. We show that using this weighted aggregation improves
the ability of the gold standard message-passing neural network to predict
antibiotic activity. Moreover, by changing the temperature hyperparameter, our
approach can reveal the atoms that are important for activity prediction in a
smooth and consistent way, thus providing a novel, regulated attention
mechanism for graph neural networks. We further validate our method by showing
that it recapitulates the functional group in beta-Lactam antibiotics. The
ability of our approach to rank the atoms&apos; importance for a desired function
can be used within any graph neural network to provide interpretability of the
results and predictions at the node level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Taub_R/0/1/0/all/0/1&quot;&gt;Ronen Taub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Savir_Y/0/1/0/all/0/1&quot;&gt;Yonatan Savir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03030">
<title>GPT-MolBERTa: GPT Molecular Features Language Model for molecular property prediction. (arXiv:2310.03030v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2310.03030</link>
<description rdf:parseType="Literal">&lt;p&gt;With the emergence of Transformer architectures and their powerful
understanding of textual data, a new horizon has opened up to predict the
molecular properties based on text description. While SMILES are the most
common form of representation, they are lacking robustness, rich information
and canonicity, which limit their effectiveness in becoming generalizable
representations. Here, we present GPT-MolBERTa, a self-supervised large
language model (LLM) which uses detailed textual descriptions of molecules to
predict their properties. A text based description of 326000 molecules were
collected using ChatGPT and used to train LLM to learn the representation of
molecules. To predict the properties for the downstream tasks, both BERT and
RoBERTa models were used in the finetuning stage. Experiments show that
GPT-MolBERTa performs well on various molecule property benchmarks, and
approaching state of the art performance in regression tasks. Additionally,
further analysis of the attention mechanisms show that GPT-MolBERTa is able to
pick up important information from the input textual data, displaying the
interpretability of the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Balaji_S/0/1/0/all/0/1&quot;&gt;Suryanarayanan Balaji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Magar_R/0/1/0/all/0/1&quot;&gt;Rishikesh Magar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Jadhav_Y/0/1/0/all/0/1&quot;&gt;Yayati Jadhav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+BaratiFarimani_a/0/1/0/all/0/1&quot;&gt;and Amir BaratiFarimani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03031">
<title>How Prevalent is Gender Bias in ChatGPT? -- Exploring German and English ChatGPT Responses. (arXiv:2310.03031v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03031</link>
<description rdf:parseType="Literal">&lt;p&gt;With the introduction of ChatGPT, OpenAI made large language models (LLM)
accessible to users with limited IT expertise. However, users with no
background in natural language processing (NLP) might lack a proper
understanding of LLMs. Thus the awareness of their inherent limitations, and
therefore will take the systems&apos; output at face value. In this paper, we
systematically analyse prompts and the generated responses to identify possible
problematic issues with a special focus on gender biases, which users need to
be aware of when processing the system&apos;s output. We explore how ChatGPT reacts
in English and German if prompted to answer from a female, male, or neutral
perspective. In an in-depth investigation, we examine selected prompts and
analyse to what extent responses differ if the system is prompted several times
in an identical way. On this basis, we show that ChatGPT is indeed useful for
helping non-IT users draft texts for their daily work. However, it is
absolutely crucial to thoroughly check the system&apos;s responses for biases as
well as for syntactic and grammatical mistakes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urchs_S/0/1/0/all/0/1&quot;&gt;Stefanie Urchs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thurner_V/0/1/0/all/0/1&quot;&gt;Veronika Thurner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assenmacher_M/0/1/0/all/0/1&quot;&gt;Matthias A&amp;#xdf;enmacher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heumann_C/0/1/0/all/0/1&quot;&gt;Christian Heumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiemichen_S/0/1/0/all/0/1&quot;&gt;Stephanie Thiemichen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03032">
<title>Graph-enhanced Optimizers for Structure-aware Recommendation Embedding Evolution. (arXiv:2310.03032v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2310.03032</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedding plays a critical role in modern recommender systems because they
are virtual representations of real-world entities and the foundation for
subsequent decision models. In this paper, we propose a novel embedding update
mechanism, Structure-aware Embedding Evolution (SEvo for short), to encourage
related nodes to evolve similarly at each step. Unlike GNN (Graph Neural
Network) that typically serves as an intermediate part, SEvo is able to
directly inject the graph structure information into embedding with negligible
computational overhead in training. The convergence properties of SEvo as well
as its possible variants are theoretically analyzed to justify the validity of
the designs. Moreover, SEvo can be seamlessly integrated into existing
optimizers for state-of-the-art performance. In particular, SEvo-enhanced AdamW
with moment estimate correction demonstrates consistent improvements across a
spectrum of models and datasets, suggesting a novel technical route to
effectively utilize graph structure information beyond explicit GNN modules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Cong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianyong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03033">
<title>Benchmarking Local Robustness of High-Accuracy Binary Neural Networks for Enhanced Traffic Sign Recognition. (arXiv:2310.03033v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03033</link>
<description rdf:parseType="Literal">&lt;p&gt;Traffic signs play a critical role in road safety and traffic management for
autonomous driving systems. Accurate traffic sign classification is essential
but challenging due to real-world complexities like adversarial examples and
occlusions. To address these issues, binary neural networks offer promise in
constructing classifiers suitable for resource-constrained devices.
&lt;/p&gt;
&lt;p&gt;In our previous work, we proposed high-accuracy BNN models for traffic sign
recognition, focusing on compact size for limited computation and energy
resources. To evaluate their local robustness, this paper introduces a set of
benchmark problems featuring layers that challenge state-of-the-art
verification tools. These layers include binarized convolutions, max pooling,
batch normalization, fully connected. The difficulty of the verification
problem is given by the high number of network parameters (905k - 1.7 M), of
the input dimension (2.7k-12k), and of the number of regions (43) as well by
the fact that the neural networks are not sparse.
&lt;/p&gt;
&lt;p&gt;The proposed BNN models and local robustness properties can be checked at
https://github.com/ChristopherBrix/vnncomp2023_benchmarks/tree/main/benchmarks/traffic_signs_recognition.
&lt;/p&gt;
&lt;p&gt;The results of the 4th International Verification of Neural Networks
Competition (VNN-COMP&apos;23) revealed the fact that 4, out of 7, solvers can
handle many of our benchmarks randomly selected (minimum is 6, maximum is 36,
out of 45). Surprisingly, tools output also wrong results or missing
counterexample (ranging from 1 to 4). Currently, our focus lies in exploring
the possibility of achieving a greater count of solved instances by extending
the allotted time (previously set at 8 minutes). Furthermore, we are intrigued
by the reasons behind the erroneous outcomes provided by the tools for certain
benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Postovan_A/0/1/0/all/0/1&quot;&gt;Andreea Postovan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erascu_M/0/1/0/all/0/1&quot;&gt;M&amp;#x103;d&amp;#x103;lina Era&amp;#x15f;cu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03043">
<title>A Deep Reinforcement Learning Approach for Interactive Search with Sentence-level Feedback. (arXiv:2310.03043v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03043</link>
<description rdf:parseType="Literal">&lt;p&gt;Interactive search can provide a better experience by incorporating
interaction feedback from the users. This can significantly improve search
accuracy as it helps avoid irrelevant information and captures the users&apos;
search intents. Existing state-of-the-art (SOTA) systems use reinforcement
learning (RL) models to incorporate the interactions but focus on item-level
feedback, ignoring the fine-grained information found in sentence-level
feedback. Yet such feedback requires extensive RL action space exploration and
large amounts of annotated data. This work addresses these challenges by
proposing a new deep Q-learning (DQ) approach, DQrank. DQrank adapts BERT-based
models, the SOTA in natural language processing, to select crucial sentences
based on users&apos; engagement and rank the items to obtain more satisfactory
responses. We also propose two mechanisms to better explore optimal actions.
DQrank further utilizes the experience replay mechanism in DQ to store the
feedback sentences to obtain a better initial ranking performance. We validate
the effectiveness of DQrank on three search datasets. The results show that
DQRank performs at least 12% better than the previous SOTA RL approaches. We
also conduct detailed ablation studies. The ablation results demonstrate that
each model component can efficiently extract and accumulate long-term
engagement effects from the users&apos; sentence-level feedback. This structure
offers new technologies with promised performance to construct a search system
with sentence-level interaction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jianghong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1&quot;&gt;Joyce C. Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1&quot;&gt;Chen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agichtein_E/0/1/0/all/0/1&quot;&gt;Eugene Agichtein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03047">
<title>Differentiable Chemical Physics by Geometric Deep Learning for Gradient-based Property Optimization of Mixtures. (arXiv:2310.03047v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2310.03047</link>
<description rdf:parseType="Literal">&lt;p&gt;Chemical mixtures, satisfying multi-objective performance metrics and
constraints, enable their use in chemical processes and electrochemical
devices. In this work, we develop a differentiable chemical-physics framework
for modeling chemical mixtures, DiffMix, where geometric deep learning (GDL) is
leveraged to map from molecular species, compositions and environment
conditions, to physical coefficients in the mixture physics laws. In
particular, we extend mixture thermodynamic and transport laws by creating
learnable physical coefficients, where we use graph neural networks as the
molecule encoder and enforce component-wise permutation-invariance. We start
our model evaluations with thermodynamics of binary mixtures, and further
benchmarked multicomponent electrolyte mixtures on their transport properties,
in order to test the model generalizability. We show improved prediction
accuracy and model robustness of DiffMix than its purely data-driven variants.
Furthermore, we demonstrate the efficient optimization of electrolyte transport
properties, built on the gradient obtained using DiffMix auto-differentiation.
Our simulation runs are then backed up by the data generated by a robotic
experimentation setup, Clio. By combining mixture physics and GDL, DiffMix
expands the predictive modeling methods for chemical mixtures and provides
low-cost optimization approaches in large chemical spaces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ramsundar_B/0/1/0/all/0/1&quot;&gt;Bharath Ramsundar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Annevelink_E/0/1/0/all/0/1&quot;&gt;Emil Annevelink&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hongyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Dave_A/0/1/0/all/0/1&quot;&gt;Adarsh Dave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Guan_P/0/1/0/all/0/1&quot;&gt;Pin-Wen Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gering_K/0/1/0/all/0/1&quot;&gt;Kevin Gering&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Viswanathan_V/0/1/0/all/0/1&quot;&gt;Venkatasubramanian Viswanathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03049">
<title>QuATON: Quantization Aware Training of Optical Neurons. (arXiv:2310.03049v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03049</link>
<description rdf:parseType="Literal">&lt;p&gt;Optical neural architectures (ONAs) use coding elements with optimized
physical parameters to perform intelligent measurements. However, fabricating
ONAs while maintaining design performances is challenging. Limitations in
fabrication techniques often limit the realizable precision of the trained
parameters. Physical constraints may also limit the range of values the
physical parameters can hold. Thus, ONAs should be trained within the
implementable constraints. However, such physics-based constraints reduce the
training objective to a constrained optimization problem, making it harder to
optimize with existing gradient-based methods. To alleviate these critical
issues that degrade performance from simulation to realization we propose a
physics-informed quantization-aware training framework. Our approach accounts
for the physical constraints during the training process, leading to robust
designs. We evaluate our approach on an ONA proposed in the literature, named a
diffractive deep neural network (D2NN), for all-optical phase imaging and for
classification of phase objects. With extensive experiments on different
quantization levels and datasets, we show that our approach leads to ONA
designs that are robust to quantization noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kariyawasam_H/0/1/0/all/0/1&quot;&gt;Hasindu Kariyawasam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hettiarachchi_R/0/1/0/all/0/1&quot;&gt;Ramith Hettiarachchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wadduwage_D/0/1/0/all/0/1&quot;&gt;Dushan Wadduwage&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03052">
<title>Memoria: Hebbian Memory Architecture for Human-Like Sequential Processing. (arXiv:2310.03052v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03052</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformers have demonstrated their success in various domains and tasks.
However, Transformers struggle with long input sequences due to their limited
capacity. While one solution is to increase input length, endlessly stretching
the length is unrealistic. Furthermore, humans selectively remember and use
only relevant information from inputs, unlike Transformers which process all
raw data from start to end. We introduce Memoria, a general memory network that
applies Hebbian theory which is a major theory explaining human memory
formulation to enhance long-term dependencies in neural networks. Memoria
stores and retrieves information called engram at multiple memory levels of
working memory, short-term memory, and long-term memory, using connection
weights that change according to Hebb&apos;s rule. Through experiments with popular
Transformer-based models like BERT and GPT, we present that Memoria
significantly improves the ability to consider long-term dependencies in
various tasks. Results show that Memoria outperformed existing methodologies in
sorting and language modeling, and long text classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sangjun Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bak_J/0/1/0/all/0/1&quot;&gt;JinYeong Bak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03054">
<title>Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03054</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose conditional flows of the maximum mean discrepancy (MMD) with the
negative distance kernel for posterior sampling and conditional generative
modeling. This MMD, which is also known as energy distance, has several
advantageous properties like efficient computation via slicing and sorting. We
approximate the joint distribution of the ground truth and the observations
using discrete Wasserstein gradient flows and establish an error bound for the
posterior distributions. Further, we prove that our particle flow is indeed a
Wasserstein gradient flow of an appropriate functional. The power of our method
is demonstrated by numerical examples including conditional image generation
and inverse problems like superresolution, inpainting and computed tomography
in low-dose and limited-angle settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hagemann_P/0/1/0/all/0/1&quot;&gt;Paul Hagemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hertrich_J/0/1/0/all/0/1&quot;&gt;Johannes Hertrich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Altekruger_F/0/1/0/all/0/1&quot;&gt;Fabian Altekr&amp;#xfc;ger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Beinert_R/0/1/0/all/0/1&quot;&gt;Robert Beinert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chemseddine_J/0/1/0/all/0/1&quot;&gt;Jannis Chemseddine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Steidl_G/0/1/0/all/0/1&quot;&gt;Gabriele Steidl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03055">
<title>Modified LAB Algorithm with Clustering-based Search Space Reduction Method for solving Engineering Design Problems. (arXiv:2310.03055v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03055</link>
<description rdf:parseType="Literal">&lt;p&gt;A modified LAB algorithm is introduced in this paper. It builds upon the
original LAB algorithm (Reddy et al. 2023), which is a socio-inspired algorithm
that models competitive and learning behaviours within a group, establishing
hierarchical roles. The proposed algorithm incorporates the roulette wheel
approach and a reduction factor introducing inter-group competition and
iteratively narrowing down the sample space. The algorithm is validated by
solving the benchmark test problems from CEC 2005 and CEC 2017. The solutions
are validated using standard statistical tests such as two-sided and pairwise
signed rank Wilcoxon test and Friedman rank test. The algorithm exhibited
improved and superior robustness as well as search space exploration
capabilities. Furthermore, a Clustering-Based Search Space Reduction (C-SSR)
method is proposed, making the algorithm capable to solve constrained problems.
The C-SSR method enables the algorithm to identify clusters of feasible
regions, satisfying the constraints and contributing to achieve the optimal
solution. This method demonstrates its effectiveness as a potential alternative
to traditional constraint handling techniques. The results obtained using the
Modified LAB algorithm are then compared with those achieved by other recent
metaheuristic algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_R/0/1/0/all/0/1&quot;&gt;Ruturaj Reddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1&quot;&gt;Utkarsh Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kale_I/0/1/0/all/0/1&quot;&gt;Ishaan Kale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shastri_A/0/1/0/all/0/1&quot;&gt;Apoorva Shastri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1&quot;&gt;Anand J Kulkarni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03059">
<title>Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models. (arXiv:2310.03059v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03059</link>
<description rdf:parseType="Literal">&lt;p&gt;The popularity of pre-trained large models has revolutionized downstream
tasks across diverse fields, such as language, vision, and multi-modality. To
minimize the adaption cost for downstream tasks, many Parameter-Efficient
Fine-Tuning (PEFT) techniques are proposed for language and 2D image
pre-trained models. However, the specialized PEFT method for 3D pre-trained
models is still under-explored. To this end, we introduce Point-PEFT, a novel
framework for adapting point cloud pre-trained models with minimal learnable
parameters. Specifically, for a pre-trained 3D model, we freeze most of its
parameters, and only tune the newly added PEFT modules on downstream tasks,
which consist of a Point-prior Prompt and a Geometry-aware Adapter. The
Point-prior Prompt adopts a set of learnable prompt tokens, for which we
propose to construct a memory bank with domain-specific knowledge, and utilize
a parameter-free attention to enhance the prompt tokens. The Geometry-aware
Adapter aims to aggregate point cloud features within spatial neighborhoods to
capture fine-grained geometric information through local interactions.
Extensive experiments indicate that our Point-PEFT can achieve better
performance than the full fine-tuning on various downstream tasks, while using
only 5% of the trainable parameters, demonstrating the efficiency and
effectiveness of our approach. Code will be released at
https://github.com/EvenJoker/Point-PEFT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_I/0/1/0/all/0/1&quot;&gt;Ivan Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_E/0/1/0/all/0/1&quot;&gt;Eric Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_R/0/1/0/all/0/1&quot;&gt;Ray Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03084">
<title>Discovering Knowledge-Critical Subnetworks in Pretrained Language Models. (arXiv:2310.03084v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03084</link>
<description rdf:parseType="Literal">&lt;p&gt;Pretrained language models (LMs) encode implicit representations of knowledge
in their parameters. However, localizing these representations and
disentangling them from each other remains an open problem. In this work, we
investigate whether pretrained language models contain various
knowledge-critical subnetworks: particular sparse computational subgraphs
responsible for encoding specific knowledge the model has memorized. We propose
a multi-objective differentiable weight masking scheme to discover these
subnetworks and show that we can use them to precisely remove specific
knowledge from models while minimizing adverse effects on the behavior of the
original language model. We demonstrate our method on multiple GPT2 variants,
uncovering highly sparse subnetworks (98%+) that are solely responsible for
specific collections of relational knowledge. When these subnetworks are
removed, the remaining network maintains most of its initial capacity (modeling
language and other memorized relational knowledge) but struggles to express the
removed knowledge, and suffers performance drops on examples needing this
removed knowledge on downstream tasks after finetuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bayazit_D/0/1/0/all/0/1&quot;&gt;Deniz Bayazit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foroutan_N/0/1/0/all/0/1&quot;&gt;Negar Foroutan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zeming Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1&quot;&gt;Gail Weiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1&quot;&gt;Antoine Bosselut&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03085">
<title>Batch-less stochastic gradient descent for compressive learning of deep regularization for image denoising. (arXiv:2310.03085v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03085</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of denoising with the help of prior information taken
from a database of clean signals or images. Denoising with variational methods
is very efficient if a regularizer well adapted to the nature of the data is
available. Thanks to the maximum a posteriori Bayesian framework, such
regularizer can be systematically linked with the distribution of the data.
With deep neural networks (DNN), complex distributions can be recovered from a
large training database.To reduce the computational burden of this task, we
adapt the compressive learning framework to the learning of regularizers
parametrized by DNN. We propose two variants of stochastic gradient descent
(SGD) for the recovery of deep regularization parameters from a heavily
compressed database. These algorithms outperform the initially proposed method
that was limited to low-dimensional signals, each iteration using information
from the whole database. They also benefit from classical SGD convergence
guarantees. Thanks to these improvements we show that this method can be
applied for patch based image denoising.}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1&quot;&gt;Hui Shi&lt;/a&gt; (IMB), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Traonmilin_Y/0/1/0/all/0/1&quot;&gt;Yann Traonmilin&lt;/a&gt; (IMB), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aujol_J/0/1/0/all/0/1&quot;&gt;J-F Aujol&lt;/a&gt; (IMB)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03086">
<title>Deep Learning in Computational Biology: Advancements, Challenges, and Future Outlook. (arXiv:2310.03086v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03086</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has become a powerful tool in computational biology,
revolutionising the analysis and interpretation of biological data over time.
In our article review, we delve into various aspects of deep learning in
computational biology. Specifically, we examine its history, advantages, and
challenges. Our focus is on two primary applications: DNA sequence
classification and prediction, as well as protein structure prediction from
sequence data. Additionally, we provide insights into the outlook for this
field. To fully harness the potential of deep learning in computational
biology, it is crucial to address the challenges that come with it. These
challenges include the requirement for large, labelled datasets and the
interpretability of deep learning models. The use of deep learning in the
analysis of DNA sequences has brought about a significant transformation in the
detection of genomic variants and the analysis of gene expression. This has
greatly contributed to the advancement of personalised medicine and drug
discovery. Convolutional neural networks (CNNs) have been shown to be highly
accurate in predicting genetic variations and gene expression levels. Deep
learning techniques are used for analysing epigenetic data, including DNA
methylation and histone modifications. This provides valuable insights into
metabolic conditions and gene regulation. The field of protein structure
prediction has been significantly impacted by deep learning, which has enabled
accurate determination of the three-dimensional shape of proteins and
prediction of their interactions. The future of deep learning in computational
biology looks promising. With the development of advanced deep learning models
and interpretation techniques, there is potential to overcome current
challenges and further our understanding of biological systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Suresh Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guruparan_D/0/1/0/all/0/1&quot;&gt;Dhanyashri Guruparan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aaron_P/0/1/0/all/0/1&quot;&gt;Pavithren Aaron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Telajan_P/0/1/0/all/0/1&quot;&gt;Philemon Telajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahadevan_K/0/1/0/all/0/1&quot;&gt;Kavinesh Mahadevan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davagandhi_D/0/1/0/all/0/1&quot;&gt;Dinesh Davagandhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_O/0/1/0/all/0/1&quot;&gt;Ong Xin Yue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03088">
<title>Physics-Informed Neural Networks for Accelerating Power System State Estimation. (arXiv:2310.03088v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03088</link>
<description rdf:parseType="Literal">&lt;p&gt;State estimation is the cornerstone of the power system control center since
it provides the operating condition of the system in consecutive time
intervals. This work investigates the application of physics-informed neural
networks (PINNs) for accelerating power systems state estimation in monitoring
the operation of power systems. Traditional state estimation techniques often
rely on iterative algorithms that can be computationally intensive,
particularly for large-scale power systems. In this paper, a novel approach
that leverages the inherent physical knowledge of power systems through the
integration of PINNs is proposed. By incorporating physical laws as prior
knowledge, the proposed method significantly reduces the computational
complexity associated with state estimation while maintaining high accuracy.
The proposed method achieves up to 11% increase in accuracy, 75% reduction in
standard deviation of results, and 30% faster convergence, as demonstrated by
comprehensive experiments on the IEEE 14-bus system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Falas_S/0/1/0/all/0/1&quot;&gt;Solon Falas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asprou_M/0/1/0/all/0/1&quot;&gt;Markos Asprou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konstantinou_C/0/1/0/all/0/1&quot;&gt;Charalambos Konstantinou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michael_M/0/1/0/all/0/1&quot;&gt;Maria K. Michael&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03094">
<title>Large Language Model Cascades with Mixture of Thoughts Representations for Cost-efficient Reasoning. (arXiv:2310.03094v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03094</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) such as GPT-4 have exhibited remarkable
performance in a variety of tasks, but this strong performance often comes with
the high expense of using paid API services. In this paper, we are motivated to
study building an LLM cascade to save the cost of using LLMs, particularly for
performing reasoning (e.g., mathematical, causal) tasks. Our cascade pipeline
follows the intuition that simpler questions can be addressed by a weaker but
more affordable LLM, whereas only the challenging questions necessitate the
stronger and more expensive LLM. To realize this decision-making, we consider
the &quot;answer consistency&quot; of the weaker LLM as a signal of the question
difficulty and propose several methods for the answer sampling and consistency
checking, including one leveraging a mixture of two thought representations
(i.e., Chain-of-Thought and Program-of-Thought). Through experiments on six
reasoning benchmark datasets, with GPT-3.5-turbo and GPT-4 being the weaker and
stronger LLMs, respectively, we demonstrate that our proposed LLM cascades can
achieve performance comparable to using solely the stronger LLM but require
only 40% of its cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_M/0/1/0/all/0/1&quot;&gt;Murong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jie Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Min Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1&quot;&gt;Liang Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1&quot;&gt;Ziyu Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03103">
<title>Dual Prompt Tuning for Domain-Aware Federated Learning. (arXiv:2310.03103v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03103</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning is a distributed machine learning paradigm that allows
multiple clients to collaboratively train a shared model with their local data.
Nonetheless, conventional federated learning algorithms often struggle to
generalize well due to the ubiquitous domain shift across clients. In this
work, we consider a challenging yet realistic federated learning scenario where
the training data of each client originates from different domains. We address
the challenges of domain shift by leveraging the technique of prompt learning,
and propose a novel method called Federated Dual Prompt Tuning (Fed-DPT).
Specifically, Fed-DPT employs a pre-trained vision-language model and then
applies both visual and textual prompt tuning to facilitate domain adaptation
over decentralized data. Extensive experiments of Fed-DPT demonstrate its
significant effectiveness in domain-aware federated learning. With a
pre-trained CLIP model (ViT-Base as image encoder), the proposed Fed-DPT
attains 68.4% average accuracy over six domains in the DomainNet dataset, which
improves the original CLIP by a large margin of 14.8%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1&quot;&gt;Guoyizhe Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Feng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1&quot;&gt;Anshul Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1&quot;&gt;Rama Chellappa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03104">
<title>DP-SGD for non-decomposable objective functions. (arXiv:2310.03104v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03104</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised pre-training is a common step in developing computer vision
models and large language models. In this setting, the absence of labels
requires the use of similarity-based loss functions, such as contrastive loss,
that favor minimizing the distance between similar inputs and maximizing the
distance between distinct inputs. As privacy concerns mount, training these
models using differential privacy has become more important. However, due to
how inputs are generated for these losses, one of their undesirable properties
is that their $L_2$ sensitivity can grow with increasing batch size. This
property is particularly disadvantageous for differentially private training
methods, such as DP-SGD. To overcome this issue, we develop a new DP-SGD
variant for similarity based loss functions -- in particular the commonly used
contrastive loss -- that manipulates gradients of the objective function in a
novel way to obtain a senstivity of the summed gradient that is $O(1)$ for
batch size $n$. We test our DP-SGD variant on some preliminary CIFAR-10
pre-training and CIFAR-100 finetuning tasks and show that, in both tasks, our
method&apos;s performance comes close to that of a non-private model and generally
outperforms DP-SGD applied directly to the contrastive loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_W/0/1/0/all/0/1&quot;&gt;William Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medina_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Mu&amp;#xf1;oz Medina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribero_M/0/1/0/all/0/1&quot;&gt;M&amp;#xf3;nica Ribero&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03106">
<title>Creating an Atlas of Normal Tissue for Pruning WSI Patching Through Anomaly Detection. (arXiv:2310.03106v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2310.03106</link>
<description rdf:parseType="Literal">&lt;p&gt;Patching gigapixel whole slide images (WSIs) is an important task in
computational pathology. Some methods have been proposed to select a subset of
patches as WSI representation for downstream tasks. While most of the
computational pathology tasks are designed to classify or detect the presence
of pathological lesions in each WSI, the confounding role and redundant nature
of normal histology in tissue samples are generally overlooked in WSI
representations. In this paper, we propose and validate the concept of an
&quot;atlas of normal tissue&quot; solely using samples of WSIs obtained from normal
tissue biopsies. Such atlases can be employed to eliminate normal fragments of
tissue samples and hence increase the representativeness collection of patches.
We tested our proposed method by establishing a normal atlas using 107 normal
skin WSIs and demonstrated how established indexes and search engines like
Yottixel can be improved. We used 553 WSIs of cutaneous squamous cell carcinoma
(cSCC) to show the advantage. We also validated our method applied to an
external dataset of 451 breast WSIs. The number of selected WSI patches was
reduced by 30% to 50% after utilizing the proposed normal atlas while
maintaining the same indexing and search performance in leave-one-patinet-out
validation for both datasets. We show that the proposed normal atlas shows
promise for unsupervised selection of the most representative patches of the
abnormal/malignant WSI lesions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nejat_P/0/1/0/all/0/1&quot;&gt;Peyman Nejat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Alsaafin_A/0/1/0/all/0/1&quot;&gt;Areej Alsaafin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Alabtah_G/0/1/0/all/0/1&quot;&gt;Ghazal Alabtah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Comfere_N/0/1/0/all/0/1&quot;&gt;Nneka Comfere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mangold_A/0/1/0/all/0/1&quot;&gt;Aaron Mangold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Murphree_D/0/1/0/all/0/1&quot;&gt;Dennis Murphree&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zot_P/0/1/0/all/0/1&quot;&gt;Patricija Zot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yasir_S/0/1/0/all/0/1&quot;&gt;Saba Yasir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Garcia_J/0/1/0/all/0/1&quot;&gt;Joaquin J. Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tizhoosh_H/0/1/0/all/0/1&quot;&gt;H.R. Tizhoosh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03111">
<title>Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data. (arXiv:2310.03111v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03111</link>
<description rdf:parseType="Literal">&lt;p&gt;Characterizing the relationship between neural population activity and
behavioral data is a central goal of neuroscience. While latent variable models
(LVMs) are successful in describing high-dimensional time-series data, they are
typically only designed for a single type of data, making it difficult to
identify structure shared across different experimental data modalities. Here,
we address this shortcoming by proposing an unsupervised LVM which extracts
temporally evolving shared and independent latents for distinct, simultaneously
recorded experimental modalities. We do this by combining Gaussian Process
Factor Analysis (GPFA), an interpretable LVM for neural spiking data with
temporally smooth latent space, with Gaussian Process Variational Autoencoders
(GP-VAEs), which similarly use a GP prior to characterize correlations in a
latent space, but admit rich expressivity due to a deep neural network mapping
to observations. We achieve interpretability in our model by partitioning
latent variability into components that are either shared between or
independent to each modality. We parameterize the latents of our model in the
Fourier domain, and show improved latent identification using this approach
over standard GP-VAE methods. We validate our model on simulated multi-modal
data consisting of Poisson spike counts and MNIST images that scale and rotate
smoothly over time. We show that the multi-modal GP-VAE (MM-GPVAE) is able to
not only identify the shared and independent latent structure across modalities
accurately, but provides good reconstructions of both images and neural rates
on held-out trials. Finally, we demonstrate our framework on two real world
multi-modal experimental settings: Drosophila whole-brain calcium imaging
alongside tracked limb positions, and Manduca sexta spike train measurements
from ten wing muscles as the animal tracks a visual stimulus.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gondur_R/0/1/0/all/0/1&quot;&gt;Rabia Gondur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sikandar_U/0/1/0/all/0/1&quot;&gt;Usama Bin Sikandar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaffer_E/0/1/0/all/0/1&quot;&gt;Evan Schaffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aoi_M/0/1/0/all/0/1&quot;&gt;Mikio Christian Aoi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keeley_S/0/1/0/all/0/1&quot;&gt;Stephen L Keeley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03112">
<title>Leveraging Model-based Trees as Interpretable Surrogate Models for Model Distillation. (arXiv:2310.03112v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03112</link>
<description rdf:parseType="Literal">&lt;p&gt;Surrogate models play a crucial role in retrospectively interpreting complex
and powerful black box machine learning models via model distillation. This
paper focuses on using model-based trees as surrogate models which partition
the feature space into interpretable regions via decision rules. Within each
region, interpretable models based on additive main effects are used to
approximate the behavior of the black box model, striking for an optimal
balance between interpretability and performance. Four model-based tree
algorithms, namely SLIM, GUIDE, MOB, and CTree, are compared regarding their
ability to generate such surrogate models. We investigate fidelity,
interpretability, stability, and the algorithms&apos; capability to capture
interaction effects through appropriate splits. Based on our comprehensive
analyses, we finally provide an overview of user-specific recommendations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herbinger_J/0/1/0/all/0/1&quot;&gt;Julia Herbinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dandl_S/0/1/0/all/0/1&quot;&gt;Susanne Dandl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ewald_F/0/1/0/all/0/1&quot;&gt;Fiona K. Ewald&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Loibl_S/0/1/0/all/0/1&quot;&gt;Sofia Loibl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Casalicchio_G/0/1/0/all/0/1&quot;&gt;Giuseppe Casalicchio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03119">
<title>Crossed-IoT device portability of Electromagnetic Side Channel Analysis: Challenges and Dataset. (arXiv:2310.03119v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03119</link>
<description rdf:parseType="Literal">&lt;p&gt;IoT (Internet of Things) refers to the network of interconnected physical
devices, vehicles, home appliances, and other items embedded with sensors,
software, and connectivity, enabling them to collect and exchange data. IoT
Forensics is collecting and analyzing digital evidence from IoT devices to
investigate cybercrimes, security breaches, and other malicious activities that
may have taken place on these connected devices. In particular, EM-SCA has
become an essential tool for IoT forensics due to its ability to reveal
confidential information about the internal workings of IoT devices without
interfering these devices or wiretapping their networks. However, the accuracy
and reliability of EM-SCA results can be limited by device variability,
environmental factors, and data collection and processing methods. Besides,
there is very few research on these limitations that affects significantly the
accuracy of EM-SCA approaches for the crossed-IoT device portability as well as
limited research on the possible solutions to address such challenge.
Therefore, this empirical study examines the impact of device variability on
the accuracy and reliability of EM-SCA approaches, in particular
machine-learning (ML) based approaches for EM-SCA. We firstly presents the
background, basic concepts and techniques used to evaluate the limitations of
current EM-SCA approaches and datasets. Our study then addresses one of the
most important limitation, which is caused by the multi-core architecture of
the processors (SoC). We present an approach to collect the EM-SCA datasets and
demonstrate the feasibility of using transfer learning to obtain more
meaningful and reliable results from EM-SCA in IoT forensics of crossed-IoT
devices. Our study moreover contributes a new dataset for using deep learning
models in analysing Electromagnetic Side-Channel data with regards to the
cross-device portability matter.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yasarathna_T/0/1/0/all/0/1&quot;&gt;Tharindu Lakshan Yasarathna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navanesan_L/0/1/0/all/0/1&quot;&gt;Lojenaa Navanesan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barque_S/0/1/0/all/0/1&quot;&gt;Simon Barque&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sayakkara_A/0/1/0/all/0/1&quot;&gt;Assanka Sayakkara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Khac_N/0/1/0/all/0/1&quot;&gt;Nhien-An Le-Khac&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03121">
<title>OpenMM 8: Molecular Dynamics Simulation with Machine Learning Potentials. (arXiv:2310.03121v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2310.03121</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning plays an important and growing role in molecular simulation.
The newest version of the OpenMM molecular dynamics toolkit introduces new
features to support the use of machine learning potentials. Arbitrary PyTorch
models can be added to a simulation and used to compute forces and energy. A
higher-level interface allows users to easily model their molecules of interest
with general purpose, pretrained potential functions. A collection of optimized
CUDA kernels and custom PyTorch operations greatly improves the speed of
simulations. We demonstrate these features on simulations of cyclin-dependent
kinase 8 (CDK8) and the green fluorescent protein (GFP) chromophore in water.
Taken together, these features make it practical to use machine learning to
improve the accuracy of simulations at only a modest increase in cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Eastman_P/0/1/0/all/0/1&quot;&gt;Peter Eastman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Galvelis_R/0/1/0/all/0/1&quot;&gt;Raimondas Galvelis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Pelaez_R/0/1/0/all/0/1&quot;&gt;Ra&amp;#xfa;l P. Pel&amp;#xe1;ez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Abreu_C/0/1/0/all/0/1&quot;&gt;Charlles R. A. Abreu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Farr_S/0/1/0/all/0/1&quot;&gt;Stephen E. Farr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gallicchio_E/0/1/0/all/0/1&quot;&gt;Emilio Gallicchio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gorenko_A/0/1/0/all/0/1&quot;&gt;Anton Gorenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Henry_M/0/1/0/all/0/1&quot;&gt;Michael M. Henry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hu_F/0/1/0/all/0/1&quot;&gt;Frank Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jing Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kramer_A/0/1/0/all/0/1&quot;&gt;Andreas Kr&amp;#xe4;mer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Michel_J/0/1/0/all/0/1&quot;&gt;Julien Michel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mitchell_J/0/1/0/all/0/1&quot;&gt;Joshua A. Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Pande_V/0/1/0/all/0/1&quot;&gt;Vijay S. Pande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rodrigues_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o PGLM Rodrigues&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rodriguez_Guerra_J/0/1/0/all/0/1&quot;&gt;Jaime Rodriguez-Guerra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Simmonett_A/0/1/0/all/0/1&quot;&gt;Andrew C. Simmonett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Swails_J/0/1/0/all/0/1&quot;&gt;Jason Swails&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhang_I/0/1/0/all/0/1&quot;&gt;Ivy Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chodera_J/0/1/0/all/0/1&quot;&gt;John D. Chodera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Fabritiis_G/0/1/0/all/0/1&quot;&gt;Gianni De Fabritiis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Markland_T/0/1/0/all/0/1&quot;&gt;Thomas E. Markland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03123">
<title>Efficient Federated Prompt Tuning for Black-box Large Pre-trained Models. (arXiv:2310.03123v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03123</link>
<description rdf:parseType="Literal">&lt;p&gt;With the blowout development of pre-trained models (PTMs), the efficient
tuning of these models for diverse downstream applications has emerged as a
pivotal research concern. Although recent investigations into prompt tuning
have provided promising avenues, three salient challenges persist: (1) memory
constraint: the continuous growth in the size of open-source PTMs renders
fine-tuning, even a fraction of their parameters, challenging for many
practitioners. (2) model privacy: existing PTMs often function as public API
services, with their parameters inaccessible for effective or tailored
fine-tuning. (3) data privacy: the fine-tuning of PTMs necessitates
high-quality datasets, which are typically localized and not shared to public.
To optimally harness each local dataset while navigating memory constraints and
preserving privacy, we propose Federated Black-Box Prompt Tuning (Fed-BBPT).
This innovative approach eschews reliance on parameter architectures and
private dataset access, instead capitalizing on a central server that aids
local users in collaboratively training a prompt generator through regular
aggregation. Local users leverage API-driven learning via a zero-order
optimizer, obviating the need for PTM deployment. Relative to extensive
fine-tuning, Fed-BBPT proficiently sidesteps memory challenges tied to PTM
storage and fine-tuning on local machines, tapping into comprehensive,
high-quality, yet private training datasets. A thorough evaluation across 40
datasets spanning CV and NLP tasks underscores the robustness of our proposed
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zihao Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yifan Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xueqian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lifu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1&quot;&gt;Li Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03146">
<title>Fairness-enhancing mixed effects deep learning improves fairness on in- and out-of-distribution clustered (non-iid) data. (arXiv:2310.03146v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03146</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional deep learning (DL) suffers from two core problems. Firstly, it
assumes training samples are independent and identically distributed. However,
numerous real-world datasets group samples by shared measurements (e.g., study
participants or cells), violating this assumption. In these scenarios, DL can
show compromised performance, limited generalization, and interpretability
issues, coupled with cluster confounding causing Type 1 and 2 errors. Secondly,
models are typically trained for overall accuracy, often neglecting
underrepresented groups and introducing biases in crucial areas like loan
approvals or determining health insurance rates, such biases can significantly
impact one&apos;s quality of life. To address both of these challenges
simultaneously, we present a mixed effects deep learning (MEDL) framework. MEDL
separately quantifies cluster-invariant fixed effects (FE) and cluster-specific
random effects (RE) through the introduction of: 1) a cluster adversary which
encourages the learning of cluster-invariant FE, 2) a Bayesian neural network
which quantifies the RE, and a mixing function combining the FE an RE into a
mixed-effect prediction. We marry this MEDL with adversarial debiasing, which
promotes equality-of-odds fairness across FE, RE, and ME predictions for
fairness-sensitive variables. We evaluated our approach using three datasets:
two from census/finance focusing on income classification and one from
healthcare predicting hospitalization duration, a regression task. Our
framework notably enhances fairness across all sensitive variables-increasing
fairness up to 82% for age, 43% for race, 86% for sex, and 27% for
marital-status. Besides promoting fairness, our method maintains the robust
performance and clarity of MEDL. It&apos;s versatile, suitable for various dataset
types and tasks, making it broadly applicable. Our GitHub repository houses the
implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1&quot;&gt;Adam Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1&quot;&gt;Son Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montillo_A/0/1/0/all/0/1&quot;&gt;Albert Montillo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03147">
<title>Context-Based Tweet Engagement Prediction. (arXiv:2310.03147v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2310.03147</link>
<description rdf:parseType="Literal">&lt;p&gt;Twitter is currently one of the biggest social media platforms. Its users may
share, read, and engage with short posts called tweets. For the ACM Recommender
Systems Conference 2020, Twitter published a dataset around 70 GB in size for
the annual RecSys Challenge. In 2020, the RecSys Challenge invited
participating teams to create models that would predict engagement likelihoods
for given user-tweet combinations. The submitted models predicting like, reply,
retweet, and quote engagements were evaluated based on two metrics: area under
the precision-recall curve (PRAUC) and relative cross-entropy (RCE).
&lt;/p&gt;
&lt;p&gt;In this diploma thesis, we used the RecSys 2020 Challenge dataset and
evaluation procedure to investigate how well context alone may be used to
predict tweet engagement likelihood. In doing so, we employed the Spark engine
on TU Wien&apos;s Little Big Data Cluster to create scalable data preprocessing,
feature engineering, feature selection, and machine learning pipelines. We
manually created just under 200 additional features to describe tweet context.
&lt;/p&gt;
&lt;p&gt;The results indicate that features describing users&apos; prior engagement history
and the popularity of hashtags and links in the tweet were the most
informative. We also found that factors such as the prediction algorithm,
training dataset size, training dataset sampling method, and feature selection
significantly affect the results. After comparing the best results of our
context-only prediction models with content-only models and with models
developed by the Challenge winners, we identified that the context-based models
underperformed in terms of the RCE score. This work thus concludes by situating
this discrepancy and proposing potential improvements to our implementation,
which is shared in a public git repository.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeromela_J/0/1/0/all/0/1&quot;&gt;Jovan Jeromela&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03148">
<title>Multi-Task Learning For Reduced Popularity Bias In Multi-Territory Video Recommendations. (arXiv:2310.03148v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2310.03148</link>
<description rdf:parseType="Literal">&lt;p&gt;Various data imbalances that naturally arise in a multi-territory
personalized recommender system can lead to a significant item bias for
globally prevalent items. A locally popular item can be overshadowed by a
globally prevalent item. Moreover, users&apos; viewership patterns/statistics can
drastically change from one geographic location to another which may suggest to
learn specific user embeddings. In this paper, we propose a multi-task learning
(MTL) technique, along with an adaptive upsampling method to reduce popularity
bias in multi-territory recommendations. Our proposed framework is designed to
enrich training examples with active users representation through upsampling,
and capable of learning geographic-based user embeddings by leveraging MTL.
Through experiments, we demonstrate the effectiveness of our framework in
multiple territories compared to a baseline not incorporating our proposed
techniques.~Noticeably, we show improved relative gain of up to $65.27\%$ in
PR-AUC metric. A case study is presented to demonstrate the advantages of our
methods in attenuating the popularity bias of global items.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gampa_P/0/1/0/all/0/1&quot;&gt;Phanideep Gampa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javadi_F/0/1/0/all/0/1&quot;&gt;Farnoosh Javadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bayar_B/0/1/0/all/0/1&quot;&gt;Belhassen Bayar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yessenalina_A/0/1/0/all/0/1&quot;&gt;Ainur Yessenalina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03149">
<title>Attributing Learned Concepts in Neural Networks to Training Data. (arXiv:2310.03149v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03149</link>
<description rdf:parseType="Literal">&lt;p&gt;By now there is substantial evidence that deep learning models learn certain
human-interpretable features as part of their internal representations of data.
As having the right (or wrong) concepts is critical to trustworthy machine
learning systems, it is natural to ask which inputs from the model&apos;s original
training set were most important for learning a concept at a given layer. To
answer this, we combine data attribution methods with methods for probing the
concepts learned by a model. Training network and probe ensembles for two
concept datasets on a range of network layers, we use the recently developed
TRAK method for large-scale data attribution. We find some evidence for
convergence, where removing the 10,000 top attributing images for a concept and
retraining the model does not change the location of the concept in the network
nor the probing sparsity of the concept. This suggests that rather than being
highly dependent on a few specific examples, the features that inform the
development of a concept are spread in a more diffuse manner across its
exemplars, implying robustness in concept formation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konz_N/0/1/0/all/0/1&quot;&gt;Nicholas Konz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godfrey_C/0/1/0/all/0/1&quot;&gt;Charles Godfrey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapiro_M/0/1/0/all/0/1&quot;&gt;Madelyn Shapiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1&quot;&gt;Jonathan Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1&quot;&gt;Henry Kvinge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Davis Brown&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03150">
<title>Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly. (arXiv:2310.03150v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03150</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLM) and foundation models are popular as they offer
new opportunities for individuals and businesses to improve natural language
processing, interact with data, and retrieve information faster. However,
training or fine-tuning LLMs requires a vast amount of data, which can be
challenging to access due to legal or technical restrictions and may require
private computing resources. Federated Learning (FL) is a solution designed to
overcome these challenges and expand data access for deep learning
applications.
&lt;/p&gt;
&lt;p&gt;This paper takes a hardware-centric approach to explore how LLMs can be
brought to modern edge computing systems. Our study fine-tunes the FLAN-T5
model family, ranging from 80M to 3B parameters, using FL for a text
summarization task. We provide a micro-level hardware benchmark, compare the
model FLOP utilization to a state-of-the-art data center GPU, and study the
network utilization in realistic conditions. Our contribution is twofold:
First, we evaluate the current capabilities of edge computing systems and their
potential for LLM FL workloads. Second, by comparing these systems with a
data-center GPU, we demonstrate the potential for improvement and the next
steps toward achieving greater computational efficiency at the edge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woisetschlager_H/0/1/0/all/0/1&quot;&gt;Herbert Woisetschl&amp;#xe4;ger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isenko_A/0/1/0/all/0/1&quot;&gt;Alexander Isenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shiqiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mayer_R/0/1/0/all/0/1&quot;&gt;Ruben Mayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobsen_H/0/1/0/all/0/1&quot;&gt;Hans-Arno Jacobsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03152">
<title>Towards out-of-distribution generalizable predictions of chemical kinetics properties. (arXiv:2310.03152v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03152</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning (ML) techniques have found applications in estimating
chemical kinetics properties. With the accumulated drug molecules identified
through &quot;AI4drug discovery&quot;, the next imperative lies in AI-driven design for
high-throughput chemical synthesis processes, with the estimation of properties
of unseen reactions with unexplored molecules. To this end, the existing ML
approaches for kinetics property prediction are required to be
Out-Of-Distribution (OOD) generalizable. In this paper, we categorize the OOD
kinetic property prediction into three levels (structure, condition, and
mechanism), revealing unique aspects of such problems. Under this framework, we
create comprehensive datasets to benchmark (1) the state-of-the-art ML
approaches for reaction prediction in the OOD setting and (2) the
state-of-the-art graph OOD methods in kinetics property prediction problems.
Our results demonstrated the challenges and opportunities in OOD kinetics
property prediction. Our datasets and benchmarks can further support research
in this direction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zihao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yongqiang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1&quot;&gt;Yang Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Weijiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bo Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;James Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1&quot;&gt;Hanghang Tong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03156">
<title>FedHyper: A Universal and Robust Learning Rate Scheduler for Federated Learning with Hypergradient Descent. (arXiv:2310.03156v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03156</link>
<description rdf:parseType="Literal">&lt;p&gt;The theoretical landscape of federated learning (FL) undergoes rapid
evolution, but its practical application encounters a series of intricate
challenges, and hyperparameter optimization is one of these critical
challenges. Amongst the diverse adjustments in hyperparameters, the adaptation
of the learning rate emerges as a crucial component, holding the promise of
significantly enhancing the efficacy of FL systems. In response to this
critical need, this paper presents FedHyper, a novel hypergradient-based
learning rate adaptation algorithm specifically designed for FL. FedHyper
serves as a universal learning rate scheduler that can adapt both global and
local rates as the training progresses. In addition, FedHyper not only
showcases unparalleled robustness to a spectrum of initial learning rate
configurations but also significantly alleviates the necessity for laborious
empirical learning rate adjustments. We provide a comprehensive theoretical
analysis of FedHyper&apos;s convergence rate and conduct extensive experiments on
vision and language benchmark datasets. The results demonstrate that FEDHYPER
consistently converges 1.1-3x faster than FedAvg and the competing baselines
while achieving superior final accuracy. Moreover, FedHyper catalyzes a
remarkable surge in accuracy, augmenting it by up to 15% compared to FedAvg
under suboptimal initial learning rate settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziyao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Ang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03158">
<title>Assessment of Prediction Intervals Using Uncertainty Characteristics Curves. (arXiv:2310.03158v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03158</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate quantification of model uncertainty has long been recognized as a
fundamental requirement for trusted AI. In regression tasks, uncertainty is
typically quantified using prediction intervals calibrated to an ad-hoc
operating point, making evaluation and comparison across different studies
relatively difficult. Our work leverages: (1) the concept of operating
characteristics curves and (2) the notion of a gain over a null reference, to
derive a novel operating point agnostic assessment methodology for prediction
intervals. The paper defines the Uncertainty Characteristics Curve and
demonstrates its utility in selected scenarios. We argue that the proposed
method addresses the current need for comprehensive assessment of prediction
intervals and thus represents a valuable addition to the uncertainty
quantification toolbox.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navratil_J/0/1/0/all/0/1&quot;&gt;Jiri Navratil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elder_B/0/1/0/all/0/1&quot;&gt;Benjamin Elder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arnold_M/0/1/0/all/0/1&quot;&gt;Matthew Arnold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Soumya Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1&quot;&gt;Prasanna Sattigeri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03161">
<title>Neural architecture impact on identifying temporally extended Reinforcement Learning tasks. (arXiv:2310.03161v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03161</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by recent developments in attention models for image classification
and natural language processing, we present various Attention based
architectures in reinforcement learning (RL) domain, capable of performing well
on OpenAI Gym Atari-2600 game suite. In spite of the recent success of Deep
Reinforcement learning techniques in various fields like robotics, gaming and
healthcare, they suffer from a major drawback that neural networks are
difficult to interpret. We try to get around this problem with the help of
Attention based models. In Attention based models, extracting and overlaying of
attention map onto images allows for direct observation of information used by
agent to select actions and easier interpretation of logic behind the chosen
actions. Our models in addition to playing well on gym-Atari environments, also
provide insights on how agent perceives its environment. In addition, motivated
by recent developments in attention based video-classification models using
Vision Transformer, we come up with an architecture based on Vision
Transformer, for image-based RL domain too. Compared to previous works in
Vision Transformer, our model is faster to train and requires fewer
computational resources. 3
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+George_V/0/1/0/all/0/1&quot;&gt;Victor Vadakechirayath George&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03163">
<title>FedNAR: Federated Optimization with Normalized Annealing Regularization. (arXiv:2310.03163v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03163</link>
<description rdf:parseType="Literal">&lt;p&gt;Weight decay is a standard technique to improve generalization performance in
modern deep neural network optimization, and is also widely adopted in
federated learning (FL) to prevent overfitting in local clients. In this paper,
we first explore the choices of weight decay and identify that weight decay
value appreciably influences the convergence of existing FL algorithms. While
preventing overfitting is crucial, weight decay can introduce a different
optimization goal towards the global objective, which is further amplified in
FL due to multiple local updates and heterogeneous data distribution. To
address this challenge, we develop {\it Federated optimization with Normalized
Annealing Regularization} (FedNAR), a simple yet effective and versatile
algorithmic plug-in that can be seamlessly integrated into any existing FL
algorithms. Essentially, we regulate the magnitude of each update by performing
co-clipping of the gradient and weight decay. We provide a comprehensive
theoretical analysis of FedNAR&apos;s convergence rate and conduct extensive
experiments on both vision and language datasets with different backbone
federated optimization algorithms. Our experimental results consistently
demonstrate that incorporating FedNAR into existing FL algorithms leads to
accelerated convergence and heightened model accuracy. Moreover, FedNAR
exhibits resilience in the face of various hyperparameter configurations.
Specifically, FedNAR has the ability to self-adjust the weight decay when the
initial specification is not optimal, while the accuracy of traditional FL
algorithms would markedly decline. Our codes are released at
\href{https://github.com/ljb121002/fednar}{https://github.com/ljb121002/fednar}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Junbo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Ang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1&quot;&gt;Chong Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_Q/0/1/0/all/0/1&quot;&gt;Qirong Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongyi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03165">
<title>Enhancing Accuracy in Deep Learning Using Random Matrix Theory. (arXiv:2310.03165v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03165</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we explore the applications of random matrix theory (RMT) in
the training of deep neural networks (DNNs), focusing on layer pruning to
simplify DNN architecture and loss landscape. RMT, recently used to address
overfitting in deep learning, enables the examination of DNN&apos;s weight layer
spectra. We use these techniques to optimally determine the number of singular
values to be removed from the weight layers of a DNN during training via
singular value decomposition (SVD). This process aids in DNN simplification and
accuracy enhancement, as evidenced by training simple DNN models on the MNIST
and Fashion MNIST datasets.
&lt;/p&gt;
&lt;p&gt;Our method can be applied to any fully connected or convolutional layer of a
pretrained DNN, decreasing the layer&apos;s parameters and simplifying the DNN
architecture while preserving or even enhancing the model&apos;s accuracy. By
discarding small singular values based on RMT criteria, the accuracy of the
test set remains consistent, facilitating more efficient DNN training without
compromising performance.
&lt;/p&gt;
&lt;p&gt;We provide both theoretical and empirical evidence supporting our claim that
the elimination of small singular values based on RMT does not negatively
impact the DNN&apos;s accuracy. Our results offer valuable insights into the
practical application of RMT for the creation of more efficient and accurate
deep-learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berlyand_L/0/1/0/all/0/1&quot;&gt;Leonid Berlyand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandier_E/0/1/0/all/0/1&quot;&gt;Etienne Sandier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shmalo_Y/0/1/0/all/0/1&quot;&gt;Yitzchak Shmalo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03166">
<title>Raze to the Ground: Query-Efficient Adversarial HTML Attacks on Machine-Learning Phishing Webpage Detectors. (arXiv:2310.03166v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2310.03166</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine-learning phishing webpage detectors (ML-PWD) have been shown to
suffer from adversarial manipulations of the HTML code of the input webpage.
Nevertheless, the attacks recently proposed have demonstrated limited
effectiveness due to their lack of optimizing the usage of the adopted
manipulations, and they focus solely on specific elements of the HTML code. In
this work, we overcome these limitations by first designing a novel set of
fine-grained manipulations which allow to modify the HTML code of the input
phishing webpage without compromising its maliciousness and visual appearance,
i.e., the manipulations are functionality- and rendering-preserving by design.
We then select which manipulations should be applied to bypass the target
detector by a query-efficient black-box optimization algorithm. Our experiments
show that our attacks are able to raze to the ground the performance of current
state-of-the-art ML-PWD using just 30 queries, thus overcoming the weaker
attacks developed in previous work, and enabling a much fairer robustness
evaluation of ML-PWD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montaruli_B/0/1/0/all/0/1&quot;&gt;Biagio Montaruli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demetrio_L/0/1/0/all/0/1&quot;&gt;Luca Demetrio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1&quot;&gt;Maura Pintor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Compagna_L/0/1/0/all/0/1&quot;&gt;Luca Compagna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balzarotti_D/0/1/0/all/0/1&quot;&gt;Davide Balzarotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1&quot;&gt;Battista Biggio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03174">
<title>Test Case Recommendations with Distributed Representation of Code Syntactic Features. (arXiv:2310.03174v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03174</link>
<description rdf:parseType="Literal">&lt;p&gt;Frequent modifications of unit test cases are inevitable due to software&apos;s
continuous underlying changes in source code, design, and requirements. Since
manually maintaining software test suites is tedious, timely, and costly,
automating the process of generation and maintenance of test units will
significantly impact the effectiveness and efficiency of software testing
processes.
&lt;/p&gt;
&lt;p&gt;To this end, we propose an automated approach which exploits both structural
and semantic properties of source code methods and test cases to recommend the
most relevant and useful unit tests to the developers. The proposed approach
initially trains a neural network to transform method-level source code, as
well as unit tests, into distributed representations (embedded vectors) while
preserving the importance of the structure in the code. Retrieving the semantic
and structural properties of a given method, the approach computes cosine
similarity between the method&apos;s embedding and the previously-embedded training
instances. Further, according to the similarity scores between the embedding
vectors, the model identifies the closest methods of embedding and the
associated unit tests as the most similar recommendations.
&lt;/p&gt;
&lt;p&gt;The results on the Methods2Test dataset showed that, while there is no
guarantee to have similar relevant test cases for the group of similar methods,
the proposed approach extracts the most similar existing test cases for a given
method in the dataset, and evaluations show that recommended test cases
decrease the developers&apos; effort to generating expected test cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezaei_M/0/1/0/all/0/1&quot;&gt;Mosab Rezaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alhoori_H/0/1/0/all/0/1&quot;&gt;Hamed Alhoori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahimi_M/0/1/0/all/0/1&quot;&gt;Mona Rahimi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03178">
<title>Digital Ethics in Federated Learning. (arXiv:2310.03178v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03178</link>
<description rdf:parseType="Literal">&lt;p&gt;The Internet of Things (IoT) consistently generates vast amounts of data,
sparking increasing concern over the protection of data privacy and the
limitation of data misuse. Federated learning (FL) facilitates collaborative
capabilities among multiple parties by sharing machine learning (ML) model
parameters instead of raw user data, and it has recently gained significant
attention for its potential in privacy preservation and learning efficiency
enhancement. In this paper, we highlight the digital ethics concerns that arise
when human-centric devices serve as clients in FL. More specifically,
challenges of game dynamics, fairness, incentive, and continuity arise in FL
due to differences in perspectives and objectives between clients and the
server. We analyze these challenges and their solutions from the perspectives
of both the client and the server, and through the viewpoints of centralized
and decentralized FL. Finally, we explore the opportunities in FL for
human-centric IoT as directions for future development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1&quot;&gt;Liangqi Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziran Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1&quot;&gt;Christopher G. Brinton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03182">
<title>Robust and Interpretable Medical Image Classifiers via Concept Bottleneck Models. (arXiv:2310.03182v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03182</link>
<description rdf:parseType="Literal">&lt;p&gt;Medical image classification is a critical problem for healthcare, with the
potential to alleviate the workload of doctors and facilitate diagnoses of
patients. However, two challenges arise when deploying deep learning models to
real-world healthcare applications. First, neural models tend to learn spurious
correlations instead of desired features, which could fall short when
generalizing to new domains (e.g., patients with different ages). Second, these
black-box models lack interpretability. When making diagnostic predictions, it
is important to understand why a model makes a decision for trustworthy and
safety considerations. In this paper, to address these two limitations, we
propose a new paradigm to build robust and interpretable medical image
classifiers with natural language concepts. Specifically, we first query
clinical concepts from GPT-4, then transform latent image features into
explicit concepts with a vision-language model. We systematically evaluate our
method on eight medical image classification datasets to verify its
effectiveness. On challenging datasets with strong confounding factors, our
method can mitigate spurious correlations thus substantially outperform
standard visual encoders and other baselines. Finally, we show how
classification with a small number of concepts brings a level of
interpretability for understanding model decisions through case studies in real
medical data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1&quot;&gt;An Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1&quot;&gt;Yiwu Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zexue He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karypis_P/0/1/0/all/0/1&quot;&gt;Petros Karypis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zihan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1&quot;&gt;Chengyu Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gentili_A/0/1/0/all/0/1&quot;&gt;Amilcare Gentili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1&quot;&gt;Chun-Nan Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1&quot;&gt;Jingbo Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1&quot;&gt;Julian McAuley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03195">
<title>Deep reinforcement learning for machine scheduling: Methodology, the state-of-the-art, and future directions. (arXiv:2310.03195v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03195</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine scheduling aims to optimize job assignments to machines while
adhering to manufacturing rules and job specifications. This optimization leads
to reduced operational costs, improved customer demand fulfillment, and
enhanced production efficiency. However, machine scheduling remains a
challenging combinatorial problem due to its NP-hard nature. Deep Reinforcement
Learning (DRL), a key component of artificial general intelligence, has shown
promise in various domains like gaming and robotics. Researchers have explored
applying DRL to machine scheduling problems since 1995. This paper offers a
comprehensive review and comparison of DRL-based approaches, highlighting their
methodology, applications, advantages, and limitations. It categorizes these
approaches based on computational components: conventional neural networks,
encoder-decoder architectures, graph neural networks, and metaheuristic
algorithms. Our review concludes that DRL-based methods outperform exact
solvers, heuristics, and tabular reinforcement learning algorithms in terms of
computation speed and generating near-global optimal solutions. These DRL-based
approaches have been successfully applied to static and dynamic scheduling
across diverse machine environments and job characteristics. However, DRL-based
schedulers face limitations in handling complex operational constraints,
configurable multi-objective optimization, generalization, scalability,
interpretability, and robustness. Addressing these challenges will be a crucial
focus for future research in this field. This paper serves as a valuable
resource for researchers to assess the current state of DRL-based machine
scheduling and identify research gaps. It also aids experts and practitioners
in selecting the appropriate DRL approach for production scheduling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khadivi_M/0/1/0/all/0/1&quot;&gt;Maziyar Khadivi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charter_T/0/1/0/all/0/1&quot;&gt;Todd Charter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yaghoubi_M/0/1/0/all/0/1&quot;&gt;Marjan Yaghoubi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jalayer_M/0/1/0/all/0/1&quot;&gt;Masoud Jalayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahang_M/0/1/0/all/0/1&quot;&gt;Maryam Ahang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shojaeinasab_A/0/1/0/all/0/1&quot;&gt;Ardeshir Shojaeinasab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Najjaran_H/0/1/0/all/0/1&quot;&gt;Homayoun Najjaran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03206">
<title>Regret Analysis of Distributed Online Control for LTI Systems with Adversarial Disturbances. (arXiv:2310.03206v1 [math.OC])</title>
<link>http://arxiv.org/abs/2310.03206</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the distributed online control problem over a network of
linear time-invariant (LTI) systems (with possibly unknown dynamics) in the
presence of adversarial perturbations. There exists a global network cost that
is characterized by a time-varying convex function, which evolves in an
adversarial manner and is sequentially and partially observed by local agents.
The goal of each agent is to generate a control sequence that can compete with
the best centralized control policy in hindsight, which has access to the
global cost. This problem is formulated as a regret minimization. For the case
of known dynamics, we propose a fully distributed disturbance feedback
controller that guarantees a regret bound of $O(\sqrt{T}\log T)$, where $T$ is
the time horizon. For the unknown dynamics case, we design a distributed
explore-then-commit approach, where in the exploration phase all agents jointly
learn the system dynamics, and in the learning phase our proposed control
algorithm is applied using each agent system estimate. We establish a regret
bound of $O(T^{2/3} \text{poly}(\log T))$ for this setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chang_T/0/1/0/all/0/1&quot;&gt;Ting-Jui Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shahrampour_S/0/1/0/all/0/1&quot;&gt;Shahin Shahrampour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03212">
<title>PDR-CapsNet: an Energy-Efficient Parallel Approach to Dynamic Routing in Capsule Networks. (arXiv:2310.03212v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03212</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional Neural Networks (CNNs) have produced state-of-the-art results
for image classification tasks. However, they are limited in their ability to
handle rotational and viewpoint variations due to information loss in
max-pooling layers. Capsule Networks (CapsNets) employ a
computationally-expensive iterative process referred to as dynamic routing to
address these issues. CapsNets, however, often fall short on complex datasets
and require more computational resources than CNNs. To overcome these
challenges, we introduce the Parallel Dynamic Routing CapsNet (PDR-CapsNet), a
deeper and more energy-efficient alternative to CapsNet that offers superior
performance, less energy consumption, and lower overfitting rates. By
leveraging a parallelization strategy, PDR-CapsNet mitigates the computational
complexity of CapsNet and increases throughput, efficiently using hardware
resources. As a result, we achieve 83.55\% accuracy while requiring 87.26\%
fewer parameters, 32.27\% and 47.40\% fewer MACs, and Flops, achieving 3x
faster inference and 7.29J less energy consumption on a 2080Ti GPU with 11GB
VRAM compared to CapsNet and for the CIFAR-10 dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javadinia_S/0/1/0/all/0/1&quot;&gt;Samaneh Javadinia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baniasadi_A/0/1/0/all/0/1&quot;&gt;Amirali Baniasadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03217">
<title>Formal and Practical Elements for the Certification of Machine Learning Systems. (arXiv:2310.03217v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03217</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past decade, machine learning has demonstrated impressive results,
often surpassing human capabilities in sensing tasks relevant to autonomous
flight. Unlike traditional aerospace software, the parameters of machine
learning models are not hand-coded nor derived from physics but learned from
data. They are automatically adjusted during a training phase, and their values
do not usually correspond to physical requirements. As a result, requirements
cannot be directly traced to lines of code, hindering the current bottom-up
aerospace certification paradigm. This paper attempts to address this gap by 1)
demystifying the inner workings and processes to build machine learning models,
2) formally establishing theoretical guarantees given by those processes, and
3) complementing these formal elements with practical considerations to develop
a complete certification argument for safety-critical machine learning systems.
Based on a scalable statistical verifier, our proposed framework is
model-agnostic and tool-independent, making it adaptable to many use cases in
the industry. We demonstrate results on a widespread application in autonomous
flight: vision-based landing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durand_J/0/1/0/all/0/1&quot;&gt;Jean-Guillaume Durand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubois_A/0/1/0/all/0/1&quot;&gt;Arthur Dubois&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moss_R/0/1/0/all/0/1&quot;&gt;Robert J. Moss&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03218">
<title>Learning Energy-Based Prior Model with Diffusion-Amortized MCMC. (arXiv:2310.03218v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03218</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent space Energy-Based Models (EBMs), also known as energy-based priors,
have drawn growing interests in the field of generative modeling due to its
flexibility in the formulation and strong modeling power of the latent space.
However, the common practice of learning latent space EBMs with non-convergent
short-run MCMC for prior and posterior sampling is hindering the model from
further progress; the degenerate MCMC sampling quality in practice often leads
to degraded generation quality and instability in training, especially with
highly multi-modal and/or high-dimensional target distributions. To remedy this
sampling issue, in this paper we introduce a simple but effective
diffusion-based amortization method for long-run MCMC sampling and develop a
novel learning algorithm for the latent space EBM based on it. We provide
theoretical evidence that the learned amortization of MCMC is a valid long-run
MCMC sampler. Experiments on several image modeling benchmark datasets
demonstrate the superior performance of our method compared with strong
counterparts
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Peiyu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yaxuan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1&quot;&gt;Sirui Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaojian Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1&quot;&gt;Ruiqi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Nian Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03221">
<title>Know2BIO: A Comprehensive Dual-View Benchmark for Evolving Biomedical Knowledge Graphs. (arXiv:2310.03221v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03221</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graphs (KGs) have emerged as a powerful framework for representing
and integrating complex biomedical information. However, assembling KGs from
diverse sources remains a significant challenge in several aspects, including
entity alignment, scalability, and the need for continuous updates to keep pace
with scientific advancements. Moreover, the representative power of KGs is
often limited by the scarcity of multi-modal data integration. To overcome
these challenges, we propose Know2BIO, a general-purpose heterogeneous KG
benchmark for the biomedical domain. Know2BIO integrates data from 30 diverse
sources, capturing intricate relationships across 11 biomedical categories. It
currently consists of ~219,000 nodes and ~6,200,000 edges. Know2BIO is capable
of user-directed automated updating to reflect the latest knowledge in
biomedical science. Furthermore, Know2BIO is accompanied by multi-modal data:
node features including text descriptions, protein and compound sequences and
structures, enabling the utilization of emerging natural language processing
methods and multi-modal data integration strategies. We evaluate KG
representation models on Know2BIO, demonstrating its effectiveness as a
benchmark for KG representation learning in the biomedical field. Data and
source code of Know2BIO are available at
https://github.com/Yijia-Xiao/Know2BIO/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1&quot;&gt;Yijia Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinecke_D/0/1/0/all/0/1&quot;&gt;Dylan Steinecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pelletier_A/0/1/0/all/0/1&quot;&gt;Alexander Russell Pelletier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yushi Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ping_P/0/1/0/all/0/1&quot;&gt;Peipei Ping&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03223">
<title>TacoGFN: Target Conditioned GFlowNet for Structure-Based Drug Design. (arXiv:2310.03223v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03223</link>
<description rdf:parseType="Literal">&lt;p&gt;We seek to automate the generation of drug-like compounds conditioned to
specific protein pocket targets. Most current methods approximate the
protein-molecule distribution of a finite dataset and, therefore struggle to
generate molecules with significant binding improvement over the training
dataset. We instead frame the pocket-conditioned molecular generation task as
an RL problem and develop TacoGFN, a target conditional Generative Flow Network
model. Our method is explicitly encouraged to generate molecules with desired
properties as opposed to fitting on a pre-existing data distribution. To this
end, we develop transformer-based docking score prediction to speed up docking
score computation and propose TacoGFN to explore molecule space efficiently.
Furthermore, we incorporate several rounds of active learning where generated
samples are queried using a docking oracle to improve the docking score
prediction. This approach allows us to accurately explore as much of the
molecule landscape as we can afford computationally. Empirically, molecules
generated using TacoGFN and its variants significantly outperform all baseline
methods across every property (Docking score, QED, SA, Lipinski), while being
orders of magnitude faster.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1&quot;&gt;Tony Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandey_M/0/1/0/all/0/1&quot;&gt;Mohit Pandey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ester_M/0/1/0/all/0/1&quot;&gt;Martin Ester&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03225">
<title>Safe Exploration in Reinforcement Learning: A Generalized Formulation and Algorithms. (arXiv:2310.03225v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03225</link>
<description rdf:parseType="Literal">&lt;p&gt;Safe exploration is essential for the practical use of reinforcement learning
(RL) in many real-world scenarios. In this paper, we present a generalized safe
exploration (GSE) problem as a unified formulation of common safe exploration
problems. We then propose a solution of the GSE problem in the form of a
meta-algorithm for safe exploration, MASE, which combines an unconstrained RL
algorithm with an uncertainty quantifier to guarantee safety in the current
episode while properly penalizing unsafe explorations before actual safety
violation to discourage them in future episodes. The advantage of MASE is that
we can optimize a policy while guaranteeing with a high probability that no
safety constraint will be violated under proper assumptions. Specifically, we
present two variants of MASE with different constructions of the uncertainty
quantifier: one based on generalized linear models with theoretical guarantees
of safety and near-optimality, and another that combines a Gaussian process to
ensure safety with a deep RL algorithm to maximize the reward. Finally, we
demonstrate that our proposed algorithm achieves better performance than
state-of-the-art algorithms on grid-world and Safety Gym benchmarks without
violating any safety constraints, even during training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wachi_A/0/1/0/all/0/1&quot;&gt;Akifumi Wachi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashimoto_W/0/1/0/all/0/1&quot;&gt;Wataru Hashimoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1&quot;&gt;Xun Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashimoto_K/0/1/0/all/0/1&quot;&gt;Kazumune Hashimoto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03228">
<title>History Matching for Geological Carbon Storage using Data-Space Inversion with Spatio-Temporal Data Parameterization. (arXiv:2310.03228v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03228</link>
<description rdf:parseType="Literal">&lt;p&gt;History matching based on monitoring data will enable uncertainty reduction,
and thus improved aquifer management, in industrial-scale carbon storage
operations. In traditional model-based data assimilation, geomodel parameters
are modified to force agreement between flow simulation results and
observations. In data-space inversion (DSI), history-matched quantities of
interest, e.g., posterior pressure and saturation fields conditioned to
observations, are inferred directly, without constructing posterior geomodels.
This is accomplished efficiently using a set of O(1000) prior simulation
results, data parameterization, and posterior sampling within a Bayesian
setting. In this study, we develop and implement (in DSI) a deep-learning-based
parameterization to represent spatio-temporal pressure and CO2 saturation
fields at a set of time steps. The new parameterization uses an adversarial
autoencoder (AAE) for dimension reduction and a convolutional long short-term
memory (convLSTM) network to represent the spatial distribution and temporal
evolution of the pressure and saturation fields. This parameterization is used
with an ensemble smoother with multiple data assimilation (ESMDA) in the DSI
framework to enable posterior predictions. A realistic 3D system characterized
by prior geological realizations drawn from a range of geological scenarios is
considered. A local grid refinement procedure is introduced to estimate the
error covariance term that appears in the history matching formulation.
Extensive history matching results are presented for various quantities, for
multiple synthetic true models. Substantial uncertainty reduction in posterior
pressure and saturation fields is achieved in all cases. The framework is
applied to efficiently provide posterior predictions for a range of error
covariance specifications. Such an assessment would be expensive using a
model-based approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Su Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durlofsky_L/0/1/0/all/0/1&quot;&gt;Louis J. Durlofsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03234">
<title>Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])</title>
<link>http://arxiv.org/abs/2310.03234</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates new families of compositional optimization problems,
called $\underline{\bf n}$on-$\underline{\bf s}$mooth $\underline{\bf
w}$eakly-$\underline{\bf c}$onvex $\underline{\bf f}$inite-sum $\underline{\bf
c}$oupled $\underline{\bf c}$ompositional $\underline{\bf o}$ptimization (NSWC
FCCO). There has been a growing interest in FCCO due to its wide-ranging
applications in machine learning and AI, as well as its ability to address the
shortcomings of stochastic algorithms based on empirical risk minimization.
However, current research on FCCO presumes that both the inner and outer
functions are smooth, limiting their potential to tackle a more diverse set of
problems. Our research expands on this area by examining non-smooth
weakly-convex FCCO, where the outer function is weakly convex and
non-decreasing, and the inner function is weakly-convex. We analyze a
single-loop algorithm and establish its complexity for finding an
$\epsilon$-stationary point of the Moreau envelop of the objective function.
Additionally, we also extend the algorithm to solving novel non-smooth
weakly-convex tri-level finite-sum coupled compositional optimization problems,
which feature a nested arrangement of three functions. Lastly, we explore the
applications of our algorithms in deep learning for two-way partial AUC
maximization and multi-instance two-way partial AUC maximization, using
empirical studies to showcase the effectiveness of the proposed algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hu_Q/0/1/0/all/0/1&quot;&gt;Quanqi Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhu_D/0/1/0/all/0/1&quot;&gt;Dixian Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1&quot;&gt;Tianbao Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03240">
<title>Relational Convolutional Networks: A framework for learning representations of hierarchical relations. (arXiv:2310.03240v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03240</link>
<description rdf:parseType="Literal">&lt;p&gt;A maturing area of research in deep learning is the development of
architectures that can learn explicit representations of relational features.
In this paper, we focus on the problem of learning representations of
hierarchical relations, proposing an architectural framework we call
&quot;relational convolutional networks&quot;. Given a sequence of objects, a
&quot;multi-dimensional inner product relation&quot; module produces a relation tensor
describing all pairwise relations. A &quot;relational convolution&quot; layer then
transforms the relation tensor into a sequence of new objects, each describing
the relations within some group of objects at the previous layer. Graphlet
filters, analogous to filters in convolutional neural networks, represent a
template of relations against which the relation tensor is compared at each
grouping. Repeating this yields representations of higher-order, hierarchical
relations. We present the motivation and details of the architecture, together
with a set of experiments to demonstrate how relational convolutional networks
can provide an effective framework for modeling relational tasks that have
hierarchical structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Altabaa_A/0/1/0/all/0/1&quot;&gt;Awni Altabaa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lafferty_J/0/1/0/all/0/1&quot;&gt;John Lafferty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03243">
<title>Sparse Deep Learning for Time Series Data: Theory and Applications. (arXiv:2310.03243v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03243</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse deep learning has become a popular technique for improving the
performance of deep neural networks in areas such as uncertainty
quantification, variable selection, and large-scale network compression.
However, most existing research has focused on problems where the observations
are independent and identically distributed (i.i.d.), and there has been little
work on the problems where the observations are dependent, such as time series
data and sequential data in natural language processing. This paper aims to
address this gap by studying the theory for sparse deep learning with dependent
data. We show that sparse recurrent neural networks (RNNs) can be consistently
estimated, and their predictions are asymptotically normally distributed under
appropriate assumptions, enabling the prediction uncertainty to be correctly
quantified. Our numerical results show that sparse deep learning outperforms
state-of-the-art methods, such as conformal predictions, in prediction
uncertainty quantification for time series data. Furthermore, our results
indicate that the proposed method can consistently identify the autoregressive
order for time series data and outperform existing methods in large-scale model
compression. Our proposed method has important practical implications in fields
such as finance, healthcare, and energy, where both accurate point estimates
and prediction uncertainty quantification are of concern.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mingxuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liang_F/0/1/0/all/0/1&quot;&gt;Faming Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03253">
<title>Molecule Design by Latent Prompt Transformer. (arXiv:2310.03253v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03253</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a latent prompt Transformer model for solving challenging
optimization problems such as molecule design, where the goal is to find
molecules with optimal values of a target chemical or biological property that
can be computed by an existing software. Our proposed model consists of three
components. (1) A latent vector whose prior distribution is modeled by a Unet
transformation of a Gaussian white noise vector. (2) A molecule generation
model that generates the string-based representation of molecule conditional on
the latent vector in (1). We adopt the causal Transformer model that takes the
latent vector in (1) as prompt. (3) A property prediction model that predicts
the value of the target property of a molecule based on a non-linear regression
on the latent vector in (1). We call the proposed model the latent prompt
Transformer model. After initial training of the model on existing molecules
and their property values, we then gradually shift the model distribution
towards the region that supports desired values of the target property for the
purpose of molecule design. Our experiments show that our proposed model
achieves state of the art performances on several benchmark molecule design
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1&quot;&gt;Deqian Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yuhao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1&quot;&gt;Jianwen Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Nian Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03258">
<title>Detecting Electricity Service Equity Issues with Transfer Counterfactual Learning on Large-Scale Outage Datasets. (arXiv:2310.03258v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03258</link>
<description rdf:parseType="Literal">&lt;p&gt;Energy justice is a growing area of interest in interdisciplinary energy
research. However, identifying systematic biases in the energy sector remains
challenging due to confounding variables, intricate heterogeneity in treatment
effects, and limited data availability. To address these challenges, we
introduce a novel approach for counterfactual causal analysis centered on
energy justice. We use subgroup analysis to manage diverse factors and leverage
the idea of transfer learning to mitigate data scarcity in each subgroup. In
our numerical analysis, we apply our method to a large-scale customer-level
power outage data set and investigate the counterfactual effect of demographic
factors, such as income and age of the population, on power outage durations.
Our results indicate that low-income and elderly-populated areas consistently
experience longer power outages, regardless of weather conditions. This points
to existing biases in the power system and highlights the need for focused
improvements in areas with economic challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1&quot;&gt;Song Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1&quot;&gt;Xiangrui Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huestis_Mitchell_S/0/1/0/all/0/1&quot;&gt;Sarah A Huestis-Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shixiang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yao Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xavier_A/0/1/0/all/0/1&quot;&gt;Alinson Santos Xavier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_F/0/1/0/all/0/1&quot;&gt;Feng Qiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03266">
<title>UniPredict: Large Language Models are Universal Tabular Predictors. (arXiv:2310.03266v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03266</link>
<description rdf:parseType="Literal">&lt;p&gt;Tabular data prediction is a fundamental machine learning task for many
applications. Existing methods predominantly employ discriminative modeling and
operate under the assumption of a fixed target column, necessitating
re-training for every new predictive task. Inspired by the generative power of
large language models (LLMs), this paper exploits the idea of building
universal tabular data predictors based on generative modeling, namely
UniPredict. Here, we show that scaling up an LLM to extensive tabular datasets
with the capability of comprehending diverse tabular inputs and predicting for
target variables following the input instructions. Specifically, we train a
single LLM on an aggregation of 169 tabular datasets with diverse targets and
compare its performance against baselines that are trained on each dataset
separately. We observe this versatile UniPredict model demonstrates an
advantage over other models, ranging from 5.4% to 13.4%, when compared with the
best tree-boosting baseline and the best neural network baseline, respectively.
We further test UniPredict in few-shot learning settings on another 62 tabular
datasets. Our method achieves strong performance in quickly adapting to new
tasks, where our method outperforms XGBoost over 100% on the low-resource setup
and shows a significant margin over all baselines. We envision that UniPredict
sheds light on developing a universal tabular data prediction system that
learns from data at scale and serves a wide range of prediction tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruiyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zifeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03272">
<title>Network Alignment with Transferable Graph Autoencoders. (arXiv:2310.03272v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03272</link>
<description rdf:parseType="Literal">&lt;p&gt;Network alignment is the task of establishing one-to-one correspondences
between the nodes of different graphs and finds a plethora of applications in
high-impact domains. However, this task is known to be NP-hard in its general
form, and existing algorithms do not scale up as the size of the graphs
increases. To tackle both challenges we propose a novel generalized graph
autoencoder architecture, designed to extract powerful and robust node
embeddings, that are tailored to the alignment task. We prove that the
generated embeddings are associated with the eigenvalues and eigenvectors of
the graphs and can achieve more accurate alignment compared to classical
spectral methods. Our proposed framework also leverages transfer learning and
data augmentation to achieve efficient network alignment at a very large scale
without retraining. Extensive experiments on both network and sub-network
alignment with real-world graphs provide corroborating evidence supporting the
effectiveness and scalability of the proposed approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Jiashu He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanatsoulis_C/0/1/0/all/0/1&quot;&gt;Charilaos I. Kanatsoulis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Alejandro Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03273">
<title>Ablation Study to Clarify the Mechanism of Object Segmentation in Multi-Object Representation Learning. (arXiv:2310.03273v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03273</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-object representation learning aims to represent complex real-world
visual input using the composition of multiple objects. Representation learning
methods have often used unsupervised learning to segment an input image into
individual objects and encode these objects into each latent vector. However,
it is not clear how previous methods have achieved the appropriate segmentation
of individual objects. Additionally, most of the previous methods regularize
the latent vectors using a Variational Autoencoder (VAE). Therefore, it is not
clear whether VAE regularization contributes to appropriate object
segmentation. To elucidate the mechanism of object segmentation in multi-object
representation learning, we conducted an ablation study on MONet, which is a
typical method. MONet represents multiple objects using pairs that consist of
an attention mask and the latent vector corresponding to the attention mask.
Each latent vector is encoded from the input image and attention mask. Then,
the component image and attention mask are decoded from each latent vector. The
loss function of MONet consists of 1) the sum of reconstruction losses between
the input image and decoded component image, 2) the VAE regularization loss of
the latent vector, and 3) the reconstruction loss of the attention mask to
explicitly encode shape information. We conducted an ablation study on these
three loss functions to investigate the effect on segmentation performance. Our
results showed that the VAE regularization loss did not affect segmentation
performance and the others losses did affect it. Based on this result, we
hypothesize that it is important to maximize the attention mask of the image
region best represented by a single latent vector corresponding to the
attention mask. We confirmed this hypothesis by evaluating a new loss function
with the same mechanism as the hypothesis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komatsu_T/0/1/0/all/0/1&quot;&gt;Takayuki Komatsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ohmura_Y/0/1/0/all/0/1&quot;&gt;Yoshiyuki Ohmura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1&quot;&gt;Yasuo Kuniyoshi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03274">
<title>Fragment-based Pretraining and Finetuning on Molecular Graphs. (arXiv:2310.03274v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03274</link>
<description rdf:parseType="Literal">&lt;p&gt;Property prediction on molecular graphs is an important application of Graph
Neural Networks (GNNs). Recently, unlabeled molecular data has become abundant,
which facilitates the rapid development of self-supervised learning for GNNs in
the chemical domain. In this work, we propose pretraining GNNs at the fragment
level, which serves as a promising middle ground to overcome the limitations of
node-level and graph-level pretraining. Borrowing techniques from recent work
on principle subgraph mining, we obtain a compact vocabulary of prevalent
fragments that span a large pretraining dataset. From the extracted vocabulary,
we introduce several fragment-based contrastive and predictive pretraining
tasks. The contrastive learning task jointly pretrains two different GNNs: one
based on molecular graphs and one based on fragment graphs, which represents
high-order connectivity within molecules. By enforcing the consistency between
the fragment embedding and the aggregated embedding of the corresponding atoms
from the molecular graphs, we ensure that both embeddings capture structural
information at multiple resolutions. The structural information of the fragment
graphs is further exploited to extract auxiliary labels for the graph-level
predictive pretraining. We employ both the pretrained molecular-based and
fragment-based GNNs for downstream prediction, thus utilizing the fragment
information during finetuning. Our models advance the performances on 5 out of
8 common molecular benchmarks and improve the performances on long-range
biological benchmarks by at least 11.5%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luong_K/0/1/0/all/0/1&quot;&gt;Kha-Dinh Luong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Ambuj Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03278">
<title>Mitigating Pilot Contamination and Enabling IoT Scalability in Massive MIMO Systems. (arXiv:2310.03278v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2310.03278</link>
<description rdf:parseType="Literal">&lt;p&gt;Massive MIMO is expected to play an important role in the development of 5G
networks. This paper addresses the issue of pilot contamination and scalability
in massive MIMO systems. The current practice of reusing orthogonal pilot
sequences in adjacent cells leads to difficulty in differentiating incoming
inter- and intra-cell pilot sequences. One possible solution is to increase the
number of orthogonal pilot sequences, which results in dedicating more space of
coherence block to pilot transmission than data transmission. This, in turn,
also hinders the scalability of massive MIMO systems, particularly in
accommodating a large number of IoT devices within a cell. To overcome these
challenges, this paper devises an innovative pilot allocation scheme based on
the data transfer patterns of IoT devices. The scheme assigns orthogonal pilot
sequences to clusters of devices instead of individual devices, allowing
multiple devices to utilize the same pilot for periodically transmitting data.
Moreover, we formulate the pilot assignment problem as a graph coloring problem
and use the max k-cut graph partitioning approach to overcome the pilot
contamination in a multicell massive MIMO system. The proposed scheme
significantly improves the spectral efficiency and enables the scalability of
massive MIMO systems; for instance, by using ten orthogonal pilot sequences, we
are able to accommodate 200 devices with only a 12.5% omission rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saeed_M/0/1/0/all/0/1&quot;&gt;Muhammad Kamran Saeed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamal_A/0/1/0/all/0/1&quot;&gt;Ahmed E. Kamal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khokhar_A/0/1/0/all/0/1&quot;&gt;Ashfaq Khokhar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03281">
<title>A 5&apos; UTR Language Model for Decoding Untranslated Regions of mRNA and Function Predictions. (arXiv:2310.03281v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03281</link>
<description rdf:parseType="Literal">&lt;p&gt;The 5&apos; UTR, a regulatory region at the beginning of an mRNA molecule, plays a
crucial role in regulating the translation process and impacts the protein
expression level. Language models have showcased their effectiveness in
decoding the functions of protein and genome sequences. Here, we introduced a
language model for 5&apos; UTR, which we refer to as the UTR-LM. The UTR-LM is
pre-trained on endogenous 5&apos; UTRs from multiple species and is further
augmented with supervised information including secondary structure and minimum
free energy. We fine-tuned the UTR-LM in a variety of downstream tasks. The
model outperformed the best-known benchmark by up to 42% for predicting the
Mean Ribosome Loading, and by up to 60% for predicting the Translation
Efficiency and the mRNA Expression Level. The model also applies to identifying
unannotated Internal Ribosome Entry Sites within the untranslated region and
improves the AUPR from 0.37 to 0.52 compared to the best baseline. Further, we
designed a library of 211 novel 5&apos; UTRs with high predicted values of
translation efficiency and evaluated them via a wet-lab assay. Experiment
results confirmed that our top designs achieved a 32.5% increase in protein
production level relative to well-established 5&apos; UTR optimized for
therapeutics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_Y/0/1/0/all/0/1&quot;&gt;Yanyi Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1&quot;&gt;Dan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yupeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kaixuan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yue Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cong_L/0/1/0/all/0/1&quot;&gt;Le Cong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jason Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mengdi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03285">
<title>Burning the Adversarial Bridges: Robust Windows Malware Detection Against Binary-level Mutations. (arXiv:2310.03285v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03285</link>
<description rdf:parseType="Literal">&lt;p&gt;Toward robust malware detection, we explore the attack surface of existing
malware detection systems. We conduct root-cause analyses of the practical
binary-level black-box adversarial malware examples. Additionally, we uncover
the sensitivity of volatile features within the detection engines and exhibit
their exploitability. Highlighting volatile information channels within the
software, we introduce three software pre-processing steps to eliminate the
attack surface, namely, padding removal, software stripping, and inter-section
information resetting. Further, to counter the emerging section injection
attacks, we propose a graph-based section-dependent information extraction
scheme for software representation. The proposed scheme leverages aggregated
information within various sections in the software to enable robust malware
detection and mitigate adversarial settings. Our experimental results show that
traditional malware detection models are ineffective against adversarial
threats. However, the attack surface can be largely reduced by eliminating the
volatile information. Therefore, we propose simple-yet-effective methods to
mitigate the impacts of binary manipulation attacks. Overall, our graph-based
malware detection scheme can accurately detect malware with an area under the
curve score of 88.32\% and a score of 88.19% under a combination of binary
manipulation attacks, exhibiting the efficiency of our proposed scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abusnaina_A/0/1/0/all/0/1&quot;&gt;Ahmed Abusnaina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yizhen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1&quot;&gt;Sunpreet Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Ke Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christodorescu_M/0/1/0/all/0/1&quot;&gt;Mihai Christodorescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohaisen_D/0/1/0/all/0/1&quot;&gt;David Mohaisen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03288">
<title>PoseAction: Action Recognition for Patients in the Ward using Deep Learning Approaches. (arXiv:2310.03288v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03288</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time intelligent detection and prediction of subjects&apos; behavior
particularly their movements or actions is critical in the ward. This approach
offers the advantage of reducing in-hospital care costs and improving the
efficiency of healthcare workers, which is especially true for scenarios at
night or during peak admission periods. Therefore, in this work, we propose
using computer vision (CV) and deep learning (DL) methods for detecting
subjects and recognizing their actions. We utilize OpenPose as an accurate
subject detector for recognizing the positions of human subjects in the video
stream. Additionally, we employ AlphAction&apos;s Asynchronous Interaction
Aggregation (AIA) network to predict the actions of detected subjects. This
integrated model, referred to as PoseAction, is proposed. At the same time, the
proposed model is further trained to predict 12 common actions in ward areas,
such as staggering, chest pain, and falling down, using medical-related video
clips from the NTU RGB+D and NTU RGB+D 120 datasets. The results demonstrate
that PoseAction achieves the highest classification mAP of 98.72% (IoU@0.5).
Additionally, this study develops an online real-time mode for action
recognition, which strongly supports the clinical translation of PoseAction.
Furthermore, using OpenPose&apos;s function for recognizing face key points, we also
implement face blurring, which is a practical solution to address the privacy
protection concerns of patients and healthcare workers. Nevertheless, the
training data for PoseAction is currently limited, particularly in terms of
label diversity. Consequently, the subsequent step involves utilizing a more
diverse dataset (including general actions) to train the model&apos;s parameters for
improved generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zherui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeow_R/0/1/0/all/0/1&quot;&gt;Raye Chen-Hua Yeow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03294">
<title>LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers. (arXiv:2310.03294v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03294</link>
<description rdf:parseType="Literal">&lt;p&gt;Increasing the context length of large language models (LLMs) unlocks
fundamentally new capabilities, but also significantly increases the memory
footprints of training. Previous model-parallel systems such as Megatron-LM
partition and compute different attention heads in parallel, resulting in large
communication volumes, so they cannot scale beyond the number of attention
heads, thereby hindering its adoption. In this paper, we introduce a new
approach, LightSeq, for long-context LLMs training. LightSeq has many notable
advantages. First, LightSeq partitions over the sequence dimension, hence is
agnostic to model architectures and readily applicable for models with varying
numbers of attention heads, such as Multi-Head, Multi-Query and Grouped-Query
attention. Second, LightSeq not only requires up to 4.7x less communication
than Megatron-LM on popular LLMs but also overlaps the communication with
computation. To further reduce the training time, LightSeq features a novel
gradient checkpointing scheme to bypass an forward computation for
memory-efficient attention. We evaluate LightSeq on Llama-7B and its variants
with sequence lengths from 32K to 512K. Through comprehensive experiments on
single and cross-node training, we show that LightSeq achieves up to 1.24-2.01x
end-to-end speedup, and a 2-8x longer sequence length on models with fewer
heads, compared to Megatron-LM. Codes will be available at
https://github.com/RulinShao/LightSeq.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Dacheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1&quot;&gt;Rulin Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_A/0/1/0/all/0/1&quot;&gt;Anze Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Joseph E. Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1&quot;&gt;Ion Stoica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xuezhe Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03298">
<title>A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling. (arXiv:2310.03298v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03298</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-fidelity (MF) methods are gaining popularity for enhancing surrogate
modeling and design optimization by incorporating data from various
low-fidelity (LF) models. While most existing MF methods assume a fixed
dataset, adaptive sampling methods that dynamically allocate resources among
fidelity models can achieve higher efficiency in the exploring and exploiting
the design space. However, most existing MF methods rely on the hierarchical
assumption of fidelity levels or fail to capture the intercorrelation between
multiple fidelity levels and utilize it to quantify the value of the future
samples and navigate the adaptive sampling. To address this hurdle, we propose
a framework hinged on a latent embedding for different fidelity models and the
associated pre-posterior analysis to explicitly utilize their correlation for
adaptive sampling. In this framework, each infill sampling iteration includes
two steps: We first identify the location of interest with the greatest
potential improvement using the high-fidelity (HF) model, then we search for
the next sample across all fidelity levels that maximize the improvement per
unit cost at the location identified in the first step. This is made possible
by a single Latent Variable Gaussian Process (LVGP) model that maps different
fidelity models into an interpretable latent space to capture their
correlations without assuming hierarchical fidelity levels. The LVGP enables us
to assess how LF sampling candidates will affect HF response with pre-posterior
analysis and determine the next sample with the best benefit-to-cost ratio.
Through test cases, we demonstrate that the proposed method outperforms the
benchmark methods in both MF global fitting (GF) and Bayesian Optimization (BO)
problems in convergence rate and robustness. Moreover, the method offers the
flexibility to switch between GF and BO by simply changing the acquisition
function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yi-Ping Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Comlek_Y/0/1/0/all/0/1&quot;&gt;Yigitcan Comlek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03301">
<title>Learning Energy Decompositions for Partial Inference of GFlowNets. (arXiv:2310.03301v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03301</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies generative flow networks (GFlowNets) to sample objects
from the Boltzmann energy distribution via a sequence of actions. In
particular, we focus on improving GFlowNet with partial inference: training
flow functions with the evaluation of the intermediate states or transitions.
To this end, the recently developed forward-looking GFlowNet reparameterizes
the flow functions based on evaluating the energy of intermediate states.
However, such an evaluation of intermediate energies may (i) be too expensive
or impossible to evaluate and (ii) even provide misleading training signals
under large energy fluctuations along the sequence of actions. To resolve this
issue, we propose learning energy decompositions for GFlowNets (LED-GFN). Our
main idea is to (i) decompose the energy of an object into learnable potential
functions defined on state transitions and (ii) reparameterize the flow
functions using the potential functions. In particular, to produce informative
local credits, we propose to regularize the potential to change smoothly over
the sequence of actions. It is also noteworthy that training GFlowNet with our
learned potential can preserve the optimal policy. We empirically verify the
superiority of LED-GFN in five problems including the generation of
unstructured and maximum independent sets, molecular graphs, and RNA sequences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1&quot;&gt;Hyosoon Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Minsu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1&quot;&gt;Sungsoo Ahn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03302">
<title>Benchmarking Large Language Models As AI Research Agents. (arXiv:2310.03302v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03302</link>
<description rdf:parseType="Literal">&lt;p&gt;Scientific experimentation involves an iterative process of creating
hypotheses, designing experiments, running experiments, and analyzing the
results. Can we build AI research agents to perform these long-horizon tasks?
To take a step towards building and evaluating research agents on such
open-ended decision-making tasks, we focus on the problem of machine learning
engineering: given a task description and a dataset, build a high-performing
model. In this paper, we propose MLAgentBench, a suite of ML tasks for
benchmarking AI research agents. Agents can perform actions like
reading/writing files, executing code, and inspecting outputs. With these
actions, agents could run experiments, analyze the results, and modify the code
of entire machine learning pipelines, such as data processing, architecture,
training processes, etc. The benchmark then automatically evaluates the agent&apos;s
performance objectively over various metrics related to performance and
efficiency. We also design an LLM-based research agent to automatically perform
experimentation loops in such an environment. Empirically, we find that a
GPT-4-based research agent can feasibly build compelling ML models over many
tasks in MLAgentBench, displaying highly interpretable plans and actions.
However, the success rates vary considerably; they span from almost 90\% on
well-established older datasets to as low as 10\% on recent Kaggle Challenges
-- unavailable during the LLM model&apos;s pretraining -- and even 0\% on newer
research challenges like BabyLM. Finally, we identify several key challenges
for LLM-based research agents such as long-term planning and hallucination. Our
code is released at https://github.com/snap-stanford/MLAgentBench.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qian Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vora_J/0/1/0/all/0/1&quot;&gt;Jian Vora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03311">
<title>Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses. (arXiv:2310.03311v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03311</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational dimensionality reduction methods are known for their high
accuracy, generative abilities, and robustness. These methods have many
theoretical justifications. Here we introduce a unifying principle rooted in
information theory to rederive and generalize existing variational methods and
design new ones. We base our framework on an interpretation of the multivariate
information bottleneck, in which two Bayesian networks are traded off against
one another. We interpret the first network as an encoder graph, which
specifies what information to keep when compressing the data. We interpret the
second network as a decoder graph, which specifies a generative model for the
data. Using this framework, we rederive existing dimensionality reduction
methods such as the deep variational information bottleneck (DVIB), beta
variational auto-encoders (beta-VAE), and deep variational canonical
correlation analysis (DVCCA). The framework naturally introduces a trade-off
parameter between compression and reconstruction in the DVCCA family of
algorithms, resulting in the new beta-DVCCA family. In addition, we derive a
new variational dimensionality reduction method, deep variational symmetric
informational bottleneck (DVSIB), which simultaneously compresses two variables
to preserve information between their compressed representations. We implement
all of these algorithms and evaluate their ability to produce shared low
dimensional latent spaces on a modified noisy MNIST dataset. We show that
algorithms that are better matched to the structure of the data (beta-DVCCA and
DVSIB) produce better latent spaces as measured by classification accuracy and
the dimensionality of the latent variables. We believe that this framework can
be used to unify other multi-view representation learning algorithms.
Additionally, it provides a straightforward framework for deriving
problem-specific loss functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdelaleem_E/0/1/0/all/0/1&quot;&gt;Eslam Abdelaleem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nemenman_I/0/1/0/all/0/1&quot;&gt;Ilya Nemenman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martini_K/0/1/0/all/0/1&quot;&gt;K. Michael Martini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03312">
<title>Certifiably Robust Graph Contrastive Learning. (arXiv:2310.03312v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2310.03312</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Contrastive Learning (GCL) has emerged as a popular unsupervised graph
representation learning method. However, it has been shown that GCL is
vulnerable to adversarial attacks on both the graph structure and node
attributes. Although empirical approaches have been proposed to enhance the
robustness of GCL, the certifiable robustness of GCL is still remain
unexplored. In this paper, we develop the first certifiably robust framework in
GCL. Specifically, we first propose a unified criteria to evaluate and certify
the robustness of GCL. We then introduce a novel technique, RES (Randomized
Edgedrop Smoothing), to ensure certifiable robustness for any GCL model, and
this certified robustness can be provably preserved in downstream tasks.
Furthermore, an effective training method is proposed for robust GCL. Extensive
experiments on real-world datasets demonstrate the effectiveness of our
proposed method in providing effective certifiable robustness and enhancing the
robustness of any GCL model. The source code of RES is available at
https://github.com/ventr1c/RES-GCL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1&quot;&gt;Minhua Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1&quot;&gt;Teng Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1&quot;&gt;Enyan Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Suhang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03314">
<title>Enhanced Human-Robot Collaboration using Constrained Probabilistic Human-Motion Prediction. (arXiv:2310.03314v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2310.03314</link>
<description rdf:parseType="Literal">&lt;p&gt;Human motion prediction is an essential step for efficient and safe
human-robot collaboration. Current methods either purely rely on representing
the human joints in some form of neural network-based architecture or use
regression models offline to fit hyper-parameters in the hope of capturing a
model encompassing human motion. While these methods provide good initial
results, they are missing out on leveraging well-studied human body kinematic
models as well as body and scene constraints which can help boost the efficacy
of these prediction frameworks while also explicitly avoiding implausible human
joint configurations. We propose a novel human motion prediction framework that
incorporates human joint constraints and scene constraints in a Gaussian
Process Regression (GPR) model to predict human motion over a set time horizon.
This formulation is combined with an online context-aware constraints model to
leverage task-dependent motions. It is tested on a human arm kinematic model
and implemented on a human-robot collaborative setup with a UR5 robot arm to
demonstrate the real-time capability of our approach. Simulations were also
performed on datasets like HA4M and ANDY. The simulation and experimental
results demonstrate considerable improvements in a Gaussian Process framework
when these constraints are explicitly considered.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothari_A/0/1/0/all/0/1&quot;&gt;Aadi Kothari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tohme_T/0/1/0/all/0/1&quot;&gt;Tony Tohme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaotong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Youcef_Toumi_K/0/1/0/all/0/1&quot;&gt;Kamal Youcef-Toumi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03320">
<title>BioBridge: Bridging Biomedical Foundation Models via Knowledge Graph. (arXiv:2310.03320v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03320</link>
<description rdf:parseType="Literal">&lt;p&gt;Foundation models (FMs) are able to leverage large volumes of unlabeled data
to demonstrate superior performance across a wide range of tasks. However, FMs
developed for biomedical domains have largely remained unimodal, i.e.,
independently trained and used for tasks on protein sequences alone, small
molecule structures alone, or clinical data alone. To overcome this limitation
of biomedical FMs, we present BioBridge, a novel parameter-efficient learning
framework, to bridge independently trained unimodal FMs to establish multimodal
behavior. BioBridge achieves it by utilizing Knowledge Graphs (KG) to learn
transformations between one unimodal FM and another without fine-tuning any
underlying unimodal FMs. Our empirical results demonstrate that BioBridge can
beat the best baseline KG embedding methods (on average by around 76.3%) in
cross-modal retrieval tasks. We also identify BioBridge demonstrates
out-of-domain generalization ability by extrapolating to unseen modalities or
relations. Additionally, we also show that BioBridge presents itself as a
general purpose retriever that can aid biomedical multimodal question answering
as well as enhance the guided generation of novel drugs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zifeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zichen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1&quot;&gt;Balasubramaniam Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ioannidis_V/0/1/0/all/0/1&quot;&gt;Vassilis N. Ioannidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rangwala_H/0/1/0/all/0/1&quot;&gt;Huzefa Rangwala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anubhai_R/0/1/0/all/0/1&quot;&gt;Rishita Anubhai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03324">
<title>Investigating the Limitation of CLIP Models: The Worst-Performing Categories. (arXiv:2310.03324v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03324</link>
<description rdf:parseType="Literal">&lt;p&gt;Contrastive Language-Image Pre-training (CLIP) provides a foundation model by
integrating natural language into visual concepts, enabling zero-shot
recognition on downstream tasks. It is usually expected that satisfactory
overall accuracy can be achieved across numerous domains through well-designed
textual prompts. However, we found that their performance in the worst
categories is significantly inferior to the overall performance. For example,
on ImageNet, there are a total of 10 categories with class-wise accuracy as low
as 0\%, even though the overall performance has achieved 64.1\%. This
phenomenon reveals the potential risks associated with using CLIP models,
particularly in risk-sensitive applications where specific categories hold
significant importance. To address this issue, we investigate the alignment
between the two modalities in the CLIP model and propose the Class-wise
Matching Margin (\cmm) to measure the inference confusion. \cmm\ can
effectively identify the worst-performing categories and estimate the potential
performance of the candidate prompts. We further query large language models to
enrich descriptions of worst-performing categories and build a weighted
ensemble to highlight the efficient prompts. Experimental results clearly
verify the effectiveness of our proposal, where the accuracy on the worst-10
categories on ImageNet is boosted to 5.2\%, without manual prompt engineering,
laborious optimization, or access to labeled validation data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1&quot;&gt;Jie-Jing Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jiang-Xin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xiao-Wen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1&quot;&gt;Lan-Zhe Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yu-Feng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03325">
<title>Learning Concept-Based Visual Causal Transition and Symbolic Reasoning for Visual Planning. (arXiv:2310.03325v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2310.03325</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual planning simulates how humans make decisions to achieve desired goals
in the form of searching for visual causal transitions between an initial
visual state and a final visual goal state. It has become increasingly
important in egocentric vision with its advantages in guiding agents to perform
daily tasks in complex environments. In this paper, we propose an interpretable
and generalizable visual planning framework consisting of i) a novel
Substitution-based Concept Learner (SCL) that abstracts visual inputs into
disentangled concept representations, ii) symbol abstraction and reasoning that
performs task planning via the self-learned symbols, and iii) a Visual Causal
Transition model (ViCT) that grounds visual causal transitions to semantically
similar real-world actions. Given an initial state, we perform goal-conditioned
visual planning with a symbolic reasoning method fueled by the learned
representations and causal transitions to reach the goal state. To verify the
effectiveness of the proposed model, we collect a large-scale visual planning
dataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this
challenging dataset demonstrate the superior performance of our method in
visual task planning. Empirically, we show that our framework can generalize to
unseen task trajectories and unseen object categories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1&quot;&gt;Yilue Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Peiyu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Nian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Lifeng Fan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03331">
<title>Fine-tune Language Models to Approximate Unbiased In-context Learning. (arXiv:2310.03331v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03331</link>
<description rdf:parseType="Literal">&lt;p&gt;In-context learning (ICL) is an astonishing emergent ability of large
language models (LLMs). By presenting a prompt that includes multiple
input-output pairs as examples and introducing a new query input, models can
generate the corresponding output. However, the performance of models heavily
relies on the quality of the input prompt when implementing in-context
learning. Biased or imbalanced input prompts can significantly degrade the
performance of language models. To address this issue, we introduce a
reweighted algorithm called RICL (Reweighted In-context Learning). This
algorithm fine-tunes language models using an unbiased validation set to
determine the optimal weight for each input-output example to approximate
unbiased in-context learning. Furthermore, we also introduce a low-cost
reweighted algorithm, a linear optimal weight approximation algorithm called
LARICL (Linear Approximation of Reweighted In-context Learning). This algorithm
requires minimal training cost while providing effective results. We prove the
convergence of our algorithm and validate its performance through experiments
conducted on a numerical dataset. The experimental findings reveal a
substantial improvement in comparison to benchmarks including the performance
of casual prompt-based in-context learning and the performance of a classic
fine-tuning method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1&quot;&gt;Timothy Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chiwun Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03334">
<title>Untargeted White-box Adversarial Attack with Heuristic Defence Methods in Real-time Deep Learning based Network Intrusion Detection System. (arXiv:2310.03334v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03334</link>
<description rdf:parseType="Literal">&lt;p&gt;Network Intrusion Detection System (NIDS) is a key component in securing the
computer network from various cyber security threats and network attacks.
However, consider an unfortunate situation where the NIDS is itself attacked
and vulnerable more specifically, we can say, How to defend the defender?. In
Adversarial Machine Learning (AML), the malicious actors aim to fool the
Machine Learning (ML) and Deep Learning (DL) models to produce incorrect
predictions with intentionally crafted adversarial examples. These adversarial
perturbed examples have become the biggest vulnerability of ML and DL based
systems and are major obstacles to their adoption in real-time and
mission-critical applications such as NIDS. AML is an emerging research domain,
and it has become a necessity for the in-depth study of adversarial attacks and
their defence strategies to safeguard the computer network from various cyber
security threads. In this research work, we aim to cover important aspects
related to NIDS, adversarial attacks and its defence mechanism to increase the
robustness of the ML and DL based NIDS. We implemented four powerful
adversarial attack techniques, namely, Fast Gradient Sign Method (FGSM),
Jacobian Saliency Map Attack (JSMA), Projected Gradient Descent (PGD) and
Carlini &amp;amp; Wagner (C&amp;amp;W) in NIDS. We analyzed its performance in terms of various
performance metrics in detail. Furthermore, the three heuristics defence
strategies, i.e., Adversarial Training (AT), Gaussian Data Augmentation (GDA)
and High Confidence (HC), are implemented to improve the NIDS robustness under
adversarial attack situations. The complete workflow is demonstrated in
real-time network with data packet flow. This research work provides the
overall background for the researchers interested in AML and its implementation
from a computer network security point of view.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roshan_K/0/1/0/all/0/1&quot;&gt;Khushnaseeb Roshan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zafar_A/0/1/0/all/0/1&quot;&gt;Aasim Zafar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haque_S/0/1/0/all/0/1&quot;&gt;Sheikh Burhan Ul Haque&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03339">
<title>Probabilistic Forecasting of Day-Ahead Electricity Prices and their Volatility with LSTMs. (arXiv:2310.03339v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03339</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate forecasts of electricity prices are crucial for the management of
electric power systems and the development of smart applications. European
electricity prices have risen substantially and became highly volatile after
the Russian invasion of Ukraine, challenging established forecasting methods.
Here, we present a Long Short-Term Memory (LSTM) model for the
German-Luxembourg day-ahead electricity prices addressing these challenges. The
recurrent structure of the LSTM allows the model to adapt to trends, while the
joint prediction of both mean and standard deviation enables a probabilistic
prediction. Using a physics-inspired approach - superstatistics - to derive an
explanation for the statistics of prices, we show that the LSTM model
faithfully reproduces both prices and their volatility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trebbien_J/0/1/0/all/0/1&quot;&gt;Julius Trebbien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Putz_S/0/1/0/all/0/1&quot;&gt;Sebastian P&amp;#xfc;tz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schafer_B/0/1/0/all/0/1&quot;&gt;Benjamin Sch&amp;#xe4;fer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nygaard_H/0/1/0/all/0/1&quot;&gt;Heidi S. Nyg&amp;#xe5;rd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorjao_L/0/1/0/all/0/1&quot;&gt;Leonardo Rydin Gorj&amp;#xe3;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witthaut_D/0/1/0/all/0/1&quot;&gt;Dirk Witthaut&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03342">
<title>LESSON: Learning to Integrate Exploration Strategies for Reinforcement Learning via an Option Framework. (arXiv:2310.03342v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03342</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, a unified framework for exploration in reinforcement learning
(RL) is proposed based on an option-critic model. The proposed framework learns
to integrate a set of diverse exploration strategies so that the agent can
adaptively select the most effective exploration strategy over time to realize
a relevant exploration-exploitation trade-off for each given task. The
effectiveness of the proposed exploration framework is demonstrated by various
experiments in the MiniGrid and Atari environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1&quot;&gt;Woojun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jeonghye Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1&quot;&gt;Youngchul Sung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03349">
<title>An Integrated Algorithm for Robust and Imperceptible Audio Adversarial Examples. (arXiv:2310.03349v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2310.03349</link>
<description rdf:parseType="Literal">&lt;p&gt;Audio adversarial examples are audio files that have been manipulated to fool
an automatic speech recognition (ASR) system, while still sounding benign to a
human listener. Most methods to generate such samples are based on a two-step
algorithm: first, a viable adversarial audio file is produced, then, this is
fine-tuned with respect to perceptibility and robustness. In this work, we
present an integrated algorithm that uses psychoacoustic models and room
impulse responses (RIR) in the generation step. The RIRs are dynamically
created by a neural network during the generation process to simulate a
physical environment to harden our examples against transformations experienced
in over-the-air attacks. We compare the different approaches in three
experiments: in a simulated environment and in a realistic over-the-air
scenario to evaluate the robustness, and in a human study to evaluate the
perceptibility. Our algorithms considering psychoacoustics only or in addition
to the robustness show an improvement in the signal-to-noise ratio (SNR) as
well as in the human perception study, at the cost of an increased word error
rate (WER).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ettenhofer_A/0/1/0/all/0/1&quot;&gt;Armin Ettenhofer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulze_J/0/1/0/all/0/1&quot;&gt;Jan-Philipp Schulze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pizzi_K/0/1/0/all/0/1&quot;&gt;Karla Pizzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03353">
<title>Deep Geometric Learning with Monotonicity Constraints for Alzheimer&apos;s Disease Progression. (arXiv:2310.03353v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2310.03353</link>
<description rdf:parseType="Literal">&lt;p&gt;Alzheimer&apos;s disease (AD) is a devastating neurodegenerative condition that
precedes progressive and irreversible dementia; thus, predicting its
progression over time is vital for clinical diagnosis and treatment. Numerous
studies have implemented structural magnetic resonance imaging (MRI) to model
AD progression, focusing on three integral aspects: (i) temporal variability,
(ii) incomplete observations, and (iii) temporal geometric characteristics.
However, deep learning-based approaches regarding data variability and sparsity
have yet to consider inherent geometrical properties sufficiently. The ordinary
differential equation-based geometric modeling method (ODE-RGRU) has recently
emerged as a promising strategy for modeling time-series data by intertwining a
recurrent neural network and an ODE in Riemannian space. Despite its
achievements, ODE-RGRU encounters limitations when extrapolating positive
definite symmetric metrics from incomplete samples, leading to feature reverse
occurrences that are particularly problematic, especially within the clinical
facet. Therefore, this study proposes a novel geometric learning approach that
models longitudinal MRI biomarkers and cognitive scores by combining three
modules: topological space shift, ODE-RGRU, and trajectory estimation. We have
also developed a training algorithm that integrates manifold mapping with
monotonicity constraints to reflect measurement transition irreversibility. We
verify our proposed method&apos;s efficacy by predicting clinical labels and
cognitive scores over time in regular and irregular settings. Furthermore, we
thoroughly analyze our proposed framework through an ablation study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1&quot;&gt;Seungwoo Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_W/0/1/0/all/0/1&quot;&gt;Wonsik Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohn_J/0/1/0/all/0/1&quot;&gt;Junghyo Sohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suk_H/0/1/0/all/0/1&quot;&gt;Heung-Il Suk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03354">
<title>Fictitious Cross-Play: Learning Global Nash Equilibrium in Mixed Cooperative-Competitive Games. (arXiv:2310.03354v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2310.03354</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-play (SP) is a popular multi-agent reinforcement learning (MARL)
framework for solving competitive games, where each agent optimizes policy by
treating others as part of the environment. Despite the empirical successes,
the theoretical properties of SP-based methods are limited to two-player
zero-sum games. However, for mixed cooperative-competitive games where agents
on the same team need to cooperate with each other, we can show a simple
counter-example where SP-based methods cannot converge to a global Nash
equilibrium (NE) with high probability. Alternatively, Policy-Space Response
Oracles (PSRO) is an iterative framework for learning NE, where the best
responses w.r.t. previous policies are learned in each iteration. PSRO can be
directly extended to mixed cooperative-competitive settings by jointly learning
team best responses with all convergence properties unchanged. However, PSRO
requires repeatedly training joint policies from scratch till convergence,
which makes it hard to scale to complex games. In this work, we develop a novel
algorithm, Fictitious Cross-Play (FXP), which inherits the benefits from both
frameworks. FXP simultaneously trains an SP-based main policy and a counter
population of best response policies. The main policy is trained by fictitious
self-play and cross-play against the counter population, while the counter
policies are trained as the best responses to the main policy&apos;s past versions.
We validate our method in matrix games and show that FXP converges to global
NEs while SP methods fail. We also conduct experiments in a gridworld domain,
where FXP achieves higher Elo ratings and lower exploitabilities than
baselines, and a more challenging football game, where FXP defeats SOTA models
with over 94% win rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zelai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yancheng Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03358">
<title>Robust Representation Learning via Asymmetric Negative Contrast and Reverse Attention. (arXiv:2310.03358v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03358</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are vulnerable to adversarial noise. Adversarial
training (AT) has been demonstrated to be the most effective defense strategy
to protect neural networks from being fooled. However, we find AT omits to
learning robust features, resulting in poor performance of adversarial
robustness. To address this issue, we highlight two characteristics of robust
representation: (1) $\bf{exclusion}$: the feature of natural examples keeps
away from that of other classes; (2) $\bf{alignment}$: the feature of natural
and corresponding adversarial examples is close to each other. These motivate
us to propose a generic framework of AT to gain robust representation, by the
asymmetric negative contrast and reverse attention. Specifically, we design an
asymmetric negative contrast based on predicted probabilities, to push away
examples of different classes in the feature space. Moreover, we propose to
weight feature by parameters of the linear classifier as the reverse attention,
to obtain class-aware feature and pull close the feature of the same class.
Empirical evaluations on three benchmark datasets show our methods greatly
advance the robustness of AT and achieve state-of-the-art performance. Code is
available at &amp;lt;https://github.com/changzhang777/ANCRA&amp;gt;.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_N/0/1/0/all/0/1&quot;&gt;Nuoyan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Decheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Dawei Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1&quot;&gt;Xinbo Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1&quot;&gt;Nannan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03365">
<title>Swin-Tempo: Temporal-Aware Lung Nodule Detection in CT Scans as Video Sequences Using Swin Transformer-Enhanced UNet. (arXiv:2310.03365v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2310.03365</link>
<description rdf:parseType="Literal">&lt;p&gt;Lung cancer is highly lethal, emphasizing the critical need for early
detection. However, identifying lung nodules poses significant challenges for
radiologists, who rely heavily on their expertise and experience for accurate
diagnosis. To address this issue, computer-aided diagnosis systems based on
machine learning techniques have emerged to assist doctors in identifying lung
nodules from computed tomography (CT) scans. Unfortunately, existing networks
in this domain often suffer from computational complexity, leading to high
rates of false negatives and false positives, limiting their effectiveness. To
address these challenges, we present an innovative model that harnesses the
strengths of both convolutional neural networks and vision transformers.
Inspired by object detection in videos, we treat each 3D CT image as a video,
individual slices as frames, and lung nodules as objects, enabling a
time-series application. The primary objective of our work is to overcome
hardware limitations during model training, allowing for efficient processing
of 2D data while utilizing inter-slice information for accurate identification
based on 3D image context. We validated the proposed network by applying a
10-fold cross-validation technique to the publicly available Lung Nodule
Analysis 2016 dataset. Our proposed architecture achieves an average
sensitivity criterion of 97.84% and a competition performance metrics (CPM) of
96.0% with few parameters. Comparative analysis with state-of-the-art
advancements in lung nodule identification demonstrates the significant
accuracy achieved by our proposed model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jafari_H/0/1/0/all/0/1&quot;&gt;Hossein Jafari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Faez_K/0/1/0/all/0/1&quot;&gt;Karim Faez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Amindavar_H/0/1/0/all/0/1&quot;&gt;Hamidreza Amindavar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03378">
<title>Machine learning the interaction network in coupled dynamical systems. (arXiv:2310.03378v1 [math.DS])</title>
<link>http://arxiv.org/abs/2310.03378</link>
<description rdf:parseType="Literal">&lt;p&gt;The study of interacting dynamical systems continues to attract research
interest in various fields of science and engineering. In a collection of
interacting particles, the interaction network contains information about how
various components interact with one another. Inferring the information about
the interaction network from the dynamics of agents is a problem of
long-standing interest. In this work, we employ a self-supervised neural
network model to achieve two outcomes: to recover the interaction network and
to predict the dynamics of individual agents. Both these information are
inferred solely from the observed trajectory data. This work presents an
application of the Neural Relational Inference model to two dynamical systems:
coupled particles mediated by Hooke&apos;s law interaction and coupled phase
(Kuramoto) oscillators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bhure_P/0/1/0/all/0/1&quot;&gt;Pawan R. Bhure&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Santhanam_M/0/1/0/all/0/1&quot;&gt;M. S. Santhanam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03388">
<title>OpenPatch: a 3D patchwork for Out-Of-Distribution detectionpdf icon. (arXiv:2310.03388v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03388</link>
<description rdf:parseType="Literal">&lt;p&gt;Moving deep learning models from the laboratory setting to the open world
entails preparing them to handle unforeseen conditions. In several applications
the occurrence of novel classes during deployment poses a significant threat,
thus it is crucial to effectively detect them. Ideally, this skill should be
used when needed without requiring any further computational training effort at
every new task. Out-of-distribution detection has attracted significant
attention in the last years, however the majority of the studies deal with 2D
images ignoring the inherent 3D nature of the real-world and often confusing
between domain and semantic novelty. In this work, we focus on the latter,
considering the objects geometric structure captured by 3D point clouds
regardless of the specific domain. We advance the field by introducing
OpenPatch that builds on a large pre-trained model and simply extracts from its
intermediate features a set of patch representations that describe each known
class. For any new sample, we obtain a novelty score by evaluating whether it
can be recomposed mainly by patches of a single known class or rather via the
contribution of multiple classes. We present an extensive experimental
evaluation of our approach for the task of semantic novelty detection on
real-world point cloud samples when the reference known data are synthetic. We
demonstrate that OpenPatch excels in both the full and few-shot known sample
scenarios, showcasing its robustness across varying pre-training objectives and
network backbones. The inherent training-free nature of our method allows for
its immediate application to a wide array of real-world tasks, offering a
compelling advantage over approaches that need expensive retraining efforts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabino_P/0/1/0/all/0/1&quot;&gt;Paolo Rabino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alliegro_A/0/1/0/all/0/1&quot;&gt;Antonio Alliegro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borlino_F/0/1/0/all/0/1&quot;&gt;Francesco Cappio Borlino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tommasi_T/0/1/0/all/0/1&quot;&gt;Tatiana Tommasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03393">
<title>Uncertainty quantification for deep learning-based schemes for solving high-dimensional backward stochastic differential equations. (arXiv:2310.03393v1 [math.NA])</title>
<link>http://arxiv.org/abs/2310.03393</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning-based numerical schemes for solving high-dimensional backward
stochastic differential equations (BSDEs) have recently raised plenty of
scientific interest. While they enable numerical methods to approximate very
high-dimensional BSDEs, their reliability has not been studied and is thus not
understood. In this work, we study uncertainty quantification (UQ) for a class
of deep learning-based BSDE schemes. More precisely, we review the sources of
uncertainty involved in the schemes and numerically study the impact of
different sources. Usually, the standard deviation (STD) of the approximate
solutions obtained from multiple runs of the algorithm with different datasets
is calculated to address the uncertainty. This approach is computationally
quite expensive, especially for high-dimensional problems. Hence, we develop a
UQ model that efficiently estimates the STD of the approximate solution using
only a single run of the algorithm. The model also estimates the mean of the
approximate solution, which can be leveraged to initialize the algorithm and
improve the optimization process. Our numerical experiments show that the UQ
model produces reliable estimates of the mean and STD of the approximate
solution for the considered class of deep learning-based BSDE schemes. The
estimated STD captures multiple sources of uncertainty, demonstrating its
effectiveness in quantifying the uncertainty. Additionally, the model
illustrates the improved performance when comparing different schemes based on
the estimated STD values. Furthermore, it can identify hyperparameter values
for which the scheme achieves good approximations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kapllani_L/0/1/0/all/0/1&quot;&gt;Lorenc Kapllani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Teng_L/0/1/0/all/0/1&quot;&gt;Long Teng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Rottmann_M/0/1/0/all/0/1&quot;&gt;Matthias Rottmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03396">
<title>Learning to Simplify Spatial-Temporal Graphs in Gait Analysis. (arXiv:2310.03396v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03396</link>
<description rdf:parseType="Literal">&lt;p&gt;Gait analysis leverages unique walking patterns for person identification and
assessment across multiple domains. Among the methods used for gait analysis,
skeleton-based approaches have shown promise due to their robust and
interpretable features. However, these methods often rely on hand-crafted
spatial-temporal graphs that are based on human anatomy disregarding the
particularities of the dataset and task. This paper proposes a novel method to
simplify the spatial-temporal graph representation for gait-based gender
estimation, improving interpretability without losing performance. Our approach
employs two models, an upstream and a downstream model, that can adjust the
adjacency matrix for each walking instance, thereby removing the fixed nature
of the graph. By employing the Straight-Through Gumbel-Softmax trick, our model
is trainable end-to-end. We demonstrate the effectiveness of our approach on
the CASIA-B dataset for gait-based gender estimation. The resulting graphs are
interpretable and differ qualitatively from fixed graphs used in existing
models. Our research contributes to enhancing the explainability and
task-specific adaptability of gait recognition, promoting more efficient and
reliable gait-based biometrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cosma_A/0/1/0/all/0/1&quot;&gt;Adrian Cosma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radoi_E/0/1/0/all/0/1&quot;&gt;Emilian Radoi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03398">
<title>Interpolating between Clustering and Dimensionality Reduction with Gromov-Wasserstein. (arXiv:2310.03398v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03398</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a versatile adaptation of existing dimensionality reduction (DR)
objectives, enabling the simultaneous reduction of both sample and feature
sizes. Correspondances between input and embedding samples are computed through
a semi-relaxed Gromov-Wasserstein optimal transport (OT) problem. When the
embedding sample size matches that of the input, our model recovers classical
popular DR models. When the embedding&apos;s dimensionality is unconstrained, we
show that the OT plan delivers a competitive hard clustering. We emphasize the
importance of intermediate stages that blend DR and clustering for summarizing
real data and apply our method to visualize datasets of images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assel_H/0/1/0/all/0/1&quot;&gt;Hugues Van Assel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_Cuaz_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric Vincent-Cuaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vayer_T/0/1/0/all/0/1&quot;&gt;Titouan Vayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flamary_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Flamary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1&quot;&gt;Nicolas Courty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03399">
<title>GRAPES: Learning to Sample Graphs for Scalable Graph Neural Networks. (arXiv:2310.03399v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03399</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks (GNNs) learn the representation of nodes in a graph by
aggregating the neighborhood information in various ways. As these networks
grow in depth, their receptive field grows exponentially due to the increase in
neighborhood sizes, resulting in high memory costs. Graph sampling solves
memory issues in GNNs by sampling a small ratio of the nodes in the graph. This
way, GNNs can scale to much larger graphs. Most sampling methods focus on fixed
sampling heuristics, which may not generalize to different structures or tasks.
We introduce GRAPES, an adaptive graph sampling method that learns to identify
sets of influential nodes for training a GNN classifier. GRAPES uses a GFlowNet
to learn node sampling probabilities given the classification objectives. We
evaluate GRAPES across several small- and large-scale graph benchmarks and
demonstrate its effectiveness in accuracy and scalability. In contrast to
existing sampling methods, GRAPES maintains high accuracy even with small
sample sizes and, therefore, can scale to very large graphs. Our code is
publicly available at https://github.com/dfdazac/grapes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Younesian_T/0/1/0/all/0/1&quot;&gt;Taraneh Younesian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thanapalasingam_T/0/1/0/all/0/1&quot;&gt;Thiviyan Thanapalasingam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krieken_E/0/1/0/all/0/1&quot;&gt;Emile van Krieken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daza_D/0/1/0/all/0/1&quot;&gt;Daniel Daza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bloem_P/0/1/0/all/0/1&quot;&gt;Peter Bloem&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03400">
<title>Adapting Large Language Models for Content Moderation: Pitfalls in Data Engineering and Supervised Fine-tuning. (arXiv:2310.03400v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03400</link>
<description rdf:parseType="Literal">&lt;p&gt;Nowadays, billions of people engage in communication and express their
opinions on the internet daily. Unfortunately, not all of these expressions are
friendly or compliant, making content moderation an indispensable task. With
the successful development of Large Language Models (LLMs) in recent years,
LLM-based methods have become a feasible solution for handling tasks in various
domains. However, in the field of content moderation, there is still a lack of
detailed work that systematically introduces implementation details. In this
paper, we introduce how to fine-tune an LLM model that can be privately
deployed for content moderation. Specifically, we discuss whether incorporating
reasons during the fine-tuning process would be better or if it should be
treated as a classification task directly. We also explore the benefits of
utilizing reasons generated by more powerful LLMs for fine-tuning privately
deployed models and the impact of different processing approaches when the
answers generated by the more powerful LLMs are incorrect. We report the entire
research process and the key findings in this paper, hoping to provide valuable
experience for researchers who are fine-tuning privately deployed models in
their domain-specific research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1&quot;&gt;Huan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Changqing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1&quot;&gt;Huazhu Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1&quot;&gt;Peilin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1&quot;&gt;Bingzhe Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03404">
<title>EAG-RS: A Novel Explainability-guided ROI-Selection Framework for ASD Diagnosis via Inter-regional Relation Learning. (arXiv:2310.03404v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03404</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models based on resting-state functional magnetic resonance
imaging (rs-fMRI) have been widely used to diagnose brain diseases,
particularly autism spectrum disorder (ASD). Existing studies have leveraged
the functional connectivity (FC) of rs-fMRI, achieving notable classification
performance. However, they have significant limitations, including the lack of
adequate information while using linear low-order FC as inputs to the model,
not considering individual characteristics (i.e., different symptoms or varying
stages of severity) among patients with ASD, and the non-explainability of the
decision process. To cover these limitations, we propose a novel
explainability-guided region of interest (ROI) selection (EAG-RS) framework
that identifies non-linear high-order functional associations among brain
regions by leveraging an explainable artificial intelligence technique and
selects class-discriminative regions for brain disease identification. The
proposed framework includes three steps: (i) inter-regional relation learning
to estimate non-linear relations through random seed-based network masking,
(ii) explainable connection-wise relevance score estimation to explore
high-order relations between functional connections, and (iii) non-linear
high-order FC-based diagnosis-informative ROI selection and classifier learning
to identify ASD. We validated the effectiveness of our proposed method by
conducting experiments using the Autism Brain Imaging Database Exchange (ABIDE)
dataset, demonstrating that the proposed method outperforms other comparative
methods in terms of various evaluation metrics. Furthermore, we qualitatively
analyzed the selected ROIs and identified ASD subtypes linked to previous
neuroscientific studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_W/0/1/0/all/0/1&quot;&gt;Wonsik Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeon_E/0/1/0/all/0/1&quot;&gt;Eunjin Jeon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_E/0/1/0/all/0/1&quot;&gt;Eunsong Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suk_H/0/1/0/all/0/1&quot;&gt;Heung-Il Suk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03406">
<title>RUSOpt: Robotic UltraSound Probe Normalization with Bayesian Optimization for In-plane and Out-plane Scanning. (arXiv:2310.03406v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2310.03406</link>
<description rdf:parseType="Literal">&lt;p&gt;The one of the significant challenges faced by autonomous robotic ultrasound
systems is acquiring high-quality images across different patients. The proper
orientation of the robotized probe plays a crucial role in governing the
quality of ultrasound images. To address this challenge, we propose a
sample-efficient method to automatically adjust the orientation of the
ultrasound probe normal to the point of contact on the scanning surface,
thereby improving the acoustic coupling of the probe and resulting image
quality. Our method utilizes Bayesian Optimization (BO) based search on the
scanning surface to efficiently search for the normalized probe orientation. We
formulate a novel objective function for BO that leverages the contact force
measurements and underlying mechanics to identify the normal. We further
incorporate a regularization scheme in BO to handle the noisy objective
function. The performance of the proposed strategy has been assessed through
experiments on urinary bladder phantoms. These phantoms included planar,
tilted, and rough surfaces, and were examined using both linear and convex
probes with varying search space limits. Further, simulation-based studies have
been carried out using 3D human mesh models. The results demonstrate that the
mean ($\pm$SD) absolute angular error averaged over all phantoms and 3D models
is $\boldsymbol{2.4\pm0.7^\circ}$ and $\boldsymbol{2.1\pm1.3^\circ}$,
respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raina_D/0/1/0/all/0/1&quot;&gt;Deepak Raina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathur_A/0/1/0/all/0/1&quot;&gt;Abhishek Mathur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Voyles_R/0/1/0/all/0/1&quot;&gt;Richard M. Voyles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wachs_J/0/1/0/all/0/1&quot;&gt;Juan Wachs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandrashekhara_S/0/1/0/all/0/1&quot;&gt;SH Chandrashekhara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1&quot;&gt;Subir Kumar Saha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03410">
<title>Over-the-Air Federated Learning with Compressed Sensing: Is Sparsification Necessary?. (arXiv:2310.03410v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2310.03410</link>
<description rdf:parseType="Literal">&lt;p&gt;Over-the-Air (OtA) Federated Learning (FL) refers to an FL system where
multiple agents apply OtA computation for transmitting model updates to a
common edge server. Two important features of OtA computation, namely linear
processing and signal-level superposition, motivate the use of linear
compression with compressed sensing (CS) methods to reduce the number of data
samples transmitted over the channel. The previous works on applying CS methods
in OtA FL have primarily assumed that the original model update vectors are
sparse, or they have been sparsified before compression. However, it is unclear
whether linear compression with CS-based reconstruction is more effective than
directly sending the non-zero elements in the sparsified update vectors, under
the same total power constraint. In this study, we examine and compare several
communication designs with or without sparsification. Our findings demonstrate
that sparsification before compression is not necessary. Alternatively,
sparsification without linear compression can also achieve better performance
than the commonly considered setup that combines both.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edin_A/0/1/0/all/0/1&quot;&gt;Adrian Edin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zheng Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03419">
<title>Pre-Training and Fine-Tuning Generative Flow Networks. (arXiv:2310.03419v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03419</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Flow Networks (GFlowNets) are amortized samplers that learn
stochastic policies to sequentially generate compositional objects from a given
unnormalized reward distribution. They can generate diverse sets of high-reward
objects, which is an important consideration in scientific discovery tasks.
However, as they are typically trained from a given extrinsic reward function,
it remains an important open challenge about how to leverage the power of
pre-training and train GFlowNets in an unsupervised fashion for efficient
adaptation to downstream tasks. Inspired by recent successes of unsupervised
pre-training in various domains, we introduce a novel approach for reward-free
pre-training of GFlowNets. By framing the training as a self-supervised
problem, we propose an outcome-conditioned GFlowNet (OC-GFN) that learns to
explore the candidate space. Specifically, OC-GFN learns to reach any targeted
outcomes, akin to goal-conditioned policies in reinforcement learning. We show
that the pre-trained OC-GFN model can allow for a direct extraction of a policy
capable of sampling from any new reward functions in downstream tasks.
Nonetheless, adapting OC-GFN on a downstream task-specific reward involves an
intractable marginalization over possible outcomes. We propose a novel way to
approximate this marginalization by learning an amortized predictor enabling
efficient fine-tuning. Extensive experimental results validate the efficacy of
our approach, demonstrating the effectiveness of pre-training the OC-GFN, and
its ability to swiftly adapt to downstream tasks and discover modes more
efficiently. This work may serve as a foundation for further exploration of
pre-training strategies in the context of GFlowNets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1&quot;&gt;Ling Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1&quot;&gt;Moksh Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madan_K/0/1/0/all/0/1&quot;&gt;Kanika Madan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03424">
<title>Neural Language Model Pruning for Automatic Speech Recognition. (arXiv:2310.03424v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03424</link>
<description rdf:parseType="Literal">&lt;p&gt;We study model pruning methods applied to Transformer-based neural network
language models for automatic speech recognition. We explore three aspects of
the pruning frame work, namely criterion, method and scheduler, analyzing their
contribution in terms of accuracy and inference speed. To the best of our
knowledge, such in-depth analyses on large-scale recognition systems has not
been reported in the literature. In addition, we propose a variant of low-rank
approximation suitable for incrementally compressing models, and delivering
multiple models with varied target sizes. Among other results, we show that a)
data-driven pruning outperforms magnitude-driven in several scenarios; b)
incremental pruning achieves higher accuracy compared to one-shot pruning,
especially when targeting smaller sizes; and c) low-rank approximation presents
the best trade-off between size reduction and inference speed-up for moderate
compression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emili_L/0/1/0/all/0/1&quot;&gt;Leonardo Emili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fraga_Silva_T/0/1/0/all/0/1&quot;&gt;Thiago Fraga-Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pusateri_E/0/1/0/all/0/1&quot;&gt;Ernest Pusateri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nussbaum_Thom_M/0/1/0/all/0/1&quot;&gt;Markus Nu&amp;#xdf;baum-Thom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oualil_Y/0/1/0/all/0/1&quot;&gt;Youssef Oualil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03435">
<title>Variational Inference for GARCH-family Models. (arXiv:2310.03435v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03435</link>
<description rdf:parseType="Literal">&lt;p&gt;The Bayesian estimation of GARCH-family models has been typically addressed
through Monte Carlo sampling. Variational Inference is gaining popularity and
attention as a robust approach for Bayesian inference in complex machine
learning models; however, its adoption in econometrics and finance is limited.
This paper discusses the extent to which Variational Inference constitutes a
reliable and feasible alternative to Monte Carlo sampling for Bayesian
inference in GARCH-like models. Through a large-scale experiment involving the
constituents of the S&amp;amp;P 500 index, several Variational Inference optimizers, a
variety of volatility models, and a case study, we show that Variational
Inference is an attractive, remarkably well-calibrated, and competitive method
for Bayesian learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Magris_M/0/1/0/all/0/1&quot;&gt;Martin Magris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Iosifidis_A/0/1/0/all/0/1&quot;&gt;Alexandros Iosifidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03447">
<title>FLAIM: AIM-based Synthetic Data Generation in the Federated Setting. (arXiv:2310.03447v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2310.03447</link>
<description rdf:parseType="Literal">&lt;p&gt;Preserving individual privacy while enabling collaborative data sharing is
crucial for organizations. Synthetic data generation is one solution, producing
artificial data that mirrors the statistical properties of private data. While
numerous techniques have been devised under differential privacy, they
predominantly assume data is centralized. However, data is often distributed
across multiple clients in a federated manner. In this work, we initiate the
study of federated synthetic tabular data generation. Building upon a SOTA
central method known as AIM, we present DistAIM and FLAIM. We show it is
straightforward to distribute AIM, extending a recent approach based on secure
multi-party computation which necessitates additional overhead, making it less
suited to federated scenarios. We then demonstrate that naively federating AIM
can lead to substantial degradation in utility under the presence of
heterogeneity. To mitigate both issues, we propose an augmented FLAIM approach
that maintains a private proxy of heterogeneity. We simulate our methods across
a range of benchmark datasets under different degrees of heterogeneity and show
this can improve utility while reducing overhead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maddock_S/0/1/0/all/0/1&quot;&gt;Samuel Maddock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1&quot;&gt;Graham Cormode&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maple_C/0/1/0/all/0/1&quot;&gt;Carsten Maple&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03456">
<title>Multi-Resolution Audio-Visual Feature Fusion for Temporal Action Localization. (arXiv:2310.03456v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03456</link>
<description rdf:parseType="Literal">&lt;p&gt;Temporal Action Localization (TAL) aims to identify actions&apos; start, end, and
class labels in untrimmed videos. While recent advancements using transformer
networks and Feature Pyramid Networks (FPN) have enhanced visual feature
recognition in TAL tasks, less progress has been made in the integration of
audio features into such frameworks. This paper introduces the Multi-Resolution
Audio-Visual Feature Fusion (MRAV-FF), an innovative method to merge
audio-visual data across different temporal resolutions. Central to our
approach is a hierarchical gated cross-attention mechanism, which discerningly
weighs the importance of audio information at diverse temporal scales. Such a
technique not only refines the precision of regression boundaries but also
bolsters classification confidence. Importantly, MRAV-FF is versatile, making
it compatible with existing FPN TAL architectures and offering a significant
enhancement in performance when audio data is available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fish_E/0/1/0/all/0/1&quot;&gt;Edward Fish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinbren_J/0/1/0/all/0/1&quot;&gt;Jon Weinbren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilbert_A/0/1/0/all/0/1&quot;&gt;Andrew Gilbert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03461">
<title>Which mode is better for federated learning? Centralized or Decentralized. (arXiv:2310.03461v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03461</link>
<description rdf:parseType="Literal">&lt;p&gt;Both centralized and decentralized approaches have shown excellent
performance and great application value in federated learning (FL). However,
current studies do not provide sufficient evidence to show which one performs
better. Although from the optimization perspective, decentralized methods can
approach the comparable convergence of centralized methods with less
communication, its test performance has always been inefficient in empirical
studies. To comprehensively explore their behaviors in FL, we study their
excess risks, including the joint analysis of both optimization and
generalization. We prove that on smooth non-convex objectives, 1) centralized
FL (CFL) always generalizes better than decentralized FL (DFL); 2) from
perspectives of the excess risk and test error in CFL, adopting partial
participation is superior to full participation; and, 3) there is a necessary
requirement for the topology in DFL to avoid performance collapse as the
training scale increases. Based on some simple hardware metrics, we could
evaluate which framework is better in practice. Extensive experiments are
conducted on common setups in FL to validate that our theoretical analysis is
contextually valid in practical scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1&quot;&gt;Li Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03466">
<title>The Blame Problem in Evaluating Local Explanations, and How to Tackle it. (arXiv:2310.03466v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03466</link>
<description rdf:parseType="Literal">&lt;p&gt;The number of local model-agnostic explanation techniques proposed has grown
rapidly recently. One main reason is that the bar for developing new
explainability techniques is low due to the lack of optimal evaluation
measures. Without rigorous measures, it is hard to have concrete evidence of
whether the new explanation techniques can significantly outperform their
predecessors. Our study proposes a new taxonomy for evaluating local
explanations: robustness, evaluation using ground truth from synthetic datasets
and interpretable models, model randomization, and human-grounded evaluation.
Using this proposed taxonomy, we highlight that all categories of evaluation
methods, except those based on the ground truth from interpretable models,
suffer from a problem we call the &quot;blame problem.&quot; In our study, we argue that
this category of evaluation measure is a more reasonable method for evaluating
local model-agnostic explanations. However, we show that even this category of
evaluation measures has further limitations. The evaluation of local
explanations remains an open research problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahnama_A/0/1/0/all/0/1&quot;&gt;Amir Hossein Akhavan Rahnama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03480">
<title>The Cadenza ICASSP 2024 Grand Challenge. (arXiv:2310.03480v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2310.03480</link>
<description rdf:parseType="Literal">&lt;p&gt;The Cadenza project aims to enhance the audio quality of music for
individuals with hearing loss. As part of this, the project is organizing the
ICASSP SP Cadenza Challenge: Music Demixing/Remixing for Hearing Aids. The
challenge can be tackled by decomposing the music at the hearing aid
microphones into vocals, bass, drums, and other components. These can then be
intelligently remixed in a personalized manner to improve audio quality.
Alternatively, an end-to-end approach could be used. Processes need to consider
the music itself, the gain applied to each component, and the listener&apos;s
hearing loss. The submitted entries will be evaluated using the intrusive
objective metric, the Hearing Aid Audio Quality Index (HAAQI). This paper
outlines the challenge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dabike_G/0/1/0/all/0/1&quot;&gt;Gerardo Roa Dabike&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Akeroyd_M/0/1/0/all/0/1&quot;&gt;Michael A. Akeroyd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bannister_S/0/1/0/all/0/1&quot;&gt;Scott Bannister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Barker_J/0/1/0/all/0/1&quot;&gt;Jon Barker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cox_T/0/1/0/all/0/1&quot;&gt;Trevor J. Cox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fazenda_B/0/1/0/all/0/1&quot;&gt;Bruno Fazenda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Firth_J/0/1/0/all/0/1&quot;&gt;Jennifer Firth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Graetzer_S/0/1/0/all/0/1&quot;&gt;Simone Graetzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Greasley_A/0/1/0/all/0/1&quot;&gt;Alinka Greasley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Vos_R/0/1/0/all/0/1&quot;&gt;Rebecca Vos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Whitmer_W/0/1/0/all/0/1&quot;&gt;William Whitmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03482">
<title>The Geometric Structure of Fully-Connected ReLU-Layers. (arXiv:2310.03482v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03482</link>
<description rdf:parseType="Literal">&lt;p&gt;We formalize and interpret the geometric structure of $d$-dimensional fully
connected ReLU-layers in neural networks. The parameters of a ReLU-layer induce
a natural partition of the input domain, such that in each sector of the
partition, the ReLU-layer can be greatly simplified. This leads to a geometric
interpretation of a ReLU-layer as a projection onto a polyhedral cone followed
by an affine transformation, in line with the description in
[doi:10.48550/arXiv.&lt;a href=&quot;/abs/1905.08922&quot;&gt;1905.08922&lt;/a&gt;] for convolutional networks with ReLU
activations. Further, this structure facilitates simplified expressions for
preimages of the intersection between partition sectors and hyperplanes, which
is useful when describing decision boundaries in a classification setting. We
investigate this in detail for a feed-forward network with one hidden
ReLU-layer, where we provide results on the geometric complexity of the
decision boundary generated by such networks, as well as proving that modulo an
affine transformation, such a network can only generate $d$ different decision
boundaries. Finally, the effect of adding more layers to the network is
discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vallin_J/0/1/0/all/0/1&quot;&gt;Jonatan Vallin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larsson_K/0/1/0/all/0/1&quot;&gt;Karl Larsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larson_M/0/1/0/all/0/1&quot;&gt;Mats G. Larson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03485">
<title>BTDNet: a Multi-Modal Approach for Brain Tumor Radiogenomic Classification. (arXiv:2310.03485v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2310.03485</link>
<description rdf:parseType="Literal">&lt;p&gt;Brain tumors pose significant health challenges worldwide, with glioblastoma
being one of the most aggressive forms. Accurate determination of the
O6-methylguanine-DNA methyltransferase (MGMT) promoter methylation status is
crucial for personalized treatment strategies. However, traditional methods are
labor-intensive and time-consuming. This paper proposes a novel multi-modal
approach, BTDNet, leveraging multi-parametric MRI scans, including FLAIR, T1w,
T1wCE, and T2 3D volumes, to predict MGMT promoter methylation status. BTDNet
addresses two main challenges: the variable volume lengths (i.e., each volume
consists of a different number of slices) and the volume-level annotations
(i.e., the whole 3D volume is annotated and not the independent slices that it
consists of). BTDNet consists of four components: i) the data augmentation one
(that performs geometric transformations, convex combinations of data pairs and
test-time data augmentation); ii) the 3D analysis one (that performs global
analysis through a CNN-RNN); iii) the routing one (that contains a mask layer
that handles variable input feature lengths), and iv) the modality fusion one
(that effectively enhances data representation, reduces ambiguities and
mitigates data scarcity). The proposed method outperforms by large margins the
state-of-the-art methods in the RSNA-ASNR-MICCAI BraTS 2021 Challenge, offering
a promising avenue for enhancing brain tumor diagnosis and treatment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kollias_D/0/1/0/all/0/1&quot;&gt;Dimitrios Kollias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Vendal_K/0/1/0/all/0/1&quot;&gt;Karanjot Vendal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gadhavi_P/0/1/0/all/0/1&quot;&gt;Priyanka Gadhavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Russom_S/0/1/0/all/0/1&quot;&gt;Solomon Russom&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03491">
<title>TPDR: A Novel Two-Step Transformer-based Product and Class Description Match and Retrieval Method. (arXiv:2310.03491v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2310.03491</link>
<description rdf:parseType="Literal">&lt;p&gt;There is a niche of companies responsible for intermediating the purchase of
large batches of varied products for other companies, for which the main
challenge is to perform product description standardization, i.e., matching an
item described by a client with a product described in a catalog. The problem
is complex since the client&apos;s product description may be: (1) potentially
noisy; (2) short and uninformative (e.g., missing information about model and
size); and (3) cross-language. In this paper, we formalize this problem as a
ranking task: given an initial client product specification (query), return the
most appropriate standardized descriptions (response). In this paper, we
propose TPDR, a two-step Transformer-based Product and Class Description
Retrieval method that is able to explore the semantic correspondence between IS
and SD, by exploiting attention mechanisms and contrastive learning. First,
TPDR employs the transformers as two encoders sharing the embedding vector
space: one for encoding the IS and another for the SD, in which corresponding
pairs (IS, SD) must be close in the vector space. Closeness is further enforced
by a contrastive learning mechanism leveraging a specialized loss function.
TPDR also exploits a (second) re-ranking step based on syntactic features that
are very important for the exact matching (model, dimension) of certain
products that may have been neglected by the transformers. To evaluate our
proposal, we consider 11 datasets from a real company, covering different
application contexts. Our solution was able to retrieve the correct
standardized product before the 5th ranking position in 71% of the cases and
its correct category in the first position in 80% of the situations. Moreover,
the effectiveness gains over purely syntactic or semantic baselines reach up to
3.7 times, solving cases that none of the approaches in isolation can do by
themselves.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cunha_W/0/1/0/all/0/1&quot;&gt;Washington Cunha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franca_C/0/1/0/all/0/1&quot;&gt;Celso Fran&amp;#xe7;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rocha_L/0/1/0/all/0/1&quot;&gt;Leonardo Rocha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goncalves_M/0/1/0/all/0/1&quot;&gt;Marcos Andr&amp;#xe9; Gon&amp;#xe7;alves&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03494">
<title>How the level sampling process impacts zero-shot generalisation in deep reinforcement learning. (arXiv:2310.03494v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03494</link>
<description rdf:parseType="Literal">&lt;p&gt;A key limitation preventing the wider adoption of autonomous agents trained
via deep reinforcement learning (RL) is their limited ability to generalise to
new environments, even when these share similar characteristics with
environments encountered during training. In this work, we investigate how a
non-uniform sampling strategy of individual environment instances, or levels,
affects the zero-shot generalisation (ZSG) ability of RL agents, considering
two failure modes: overfitting and over-generalisation. As a first step, we
measure the mutual information (MI) between the agent&apos;s internal representation
and the set of training levels, which we find to be well-correlated to instance
overfitting. In contrast to uniform sampling, adaptive sampling strategies
prioritising levels based on their value loss are more effective at maintaining
lower MI, which provides a novel theoretical justification for this class of
techniques. We then turn our attention to unsupervised environment design (UED)
methods, which adaptively generate new training levels and minimise MI more
effectively than methods sampling from a fixed set. However, we find UED
methods significantly shift the training distribution, resulting in
over-generalisation and worse ZSG performance over the distribution of
interest. To prevent both instance overfitting and over-generalisation, we
introduce self-supervised environment design (SSED). SSED generates levels
using a variational autoencoder, effectively reducing MI while minimising the
shift with the distribution of interest, and leads to statistically significant
improvements in ZSG over fixed-set level sampling strategies and UED methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcin_S/0/1/0/all/0/1&quot;&gt;Samuel Garcin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doran_J/0/1/0/all/0/1&quot;&gt;James Doran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1&quot;&gt;Shangmin Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucas_C/0/1/0/all/0/1&quot;&gt;Christopher G. Lucas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1&quot;&gt;Stefano V. Albrecht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03500">
<title>Deep Generative Models of Music Expectation. (arXiv:2310.03500v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2310.03500</link>
<description rdf:parseType="Literal">&lt;p&gt;A prominent theory of affective response to music revolves around the
concepts of surprisal and expectation. In prior work, this idea has been
operationalized in the form of probabilistic models of music which allow for
precise computation of song (or note-by-note) probabilities, conditioned on a
&apos;training set&apos; of prior musical or cultural experiences. To date, however,
these models have been limited to compute exact probabilities through
hand-crafted features or restricted to linear models which are likely not
sufficient to represent the complex conditional distributions present in music.
In this work, we propose to use modern deep probabilistic generative models in
the form of a Diffusion Model to compute an approximate likelihood of a musical
input sequence. Unlike prior work, such a generative model parameterized by
deep neural networks is able to learn complex non-linear features directly from
a training set itself. In doing so, we expect to find that such models are able
to more accurately represent the &apos;surprisal&apos; of music for human listeners. From
the literature, it is known that there is an inverted U-shaped relationship
between surprisal and the amount human subjects &apos;like&apos; a given song. In this
work we show that pre-trained diffusion models indeed yield musical surprisal
values which exhibit a negative quadratic relationship with measured subject
&apos;liking&apos; ratings, and that the quality of this relationship is competitive with
state of the art methods such as IDyOM. We therefore present this model a
preliminary step in developing modern deep generative models of music
expectation and subjective likability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masclef_N/0/1/0/all/0/1&quot;&gt;Ninon Liz&amp;#xe9; Masclef&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keller_T/0/1/0/all/0/1&quot;&gt;T. Anderson Keller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03512">
<title>Otago Exercises Monitoring for Older Adults by a Single IMU and Hierarchical Machine Learning Models. (arXiv:2310.03512v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03512</link>
<description rdf:parseType="Literal">&lt;p&gt;Otago Exercise Program (OEP) is a rehabilitation program for older adults to
improve frailty, sarcopenia, and balance. Accurate monitoring of patient
involvement in OEP is challenging, as self-reports (diaries) are often
unreliable. With the development of wearable sensors, Human Activity
Recognition (HAR) systems using wearable sensors have revolutionized
healthcare. However, their usage for OEP still shows limited performance. The
objective of this study is to build an unobtrusive and accurate system to
monitor OEP for older adults. Data was collected from older adults wearing a
single waist-mounted Inertial Measurement Unit (IMU). Two datasets were
collected, one in a laboratory setting, and one at the homes of the patients. A
hierarchical system is proposed with two stages: 1) using a deep learning model
to recognize whether the patients are performing OEP or activities of daily
life (ADLs) using a 10-minute sliding window; 2) based on stage 1, using a
6-second sliding window to recognize the OEP sub-classes performed. The results
showed that in stage 1, OEP could be recognized with window-wise f1-scores over
0.95 and Intersection-over-Union (IoU) f1-scores over 0.85 for both datasets.
In stage 2, for the home scenario, four activities could be recognized with
f1-scores over 0.8: ankle plantarflexors, abdominal muscles, knee bends, and
sit-to-stand. The results showed the potential of monitoring the compliance of
OEP using a single IMU in daily life. Also, some OEP sub-classes are possible
to be recognized for further analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_M/0/1/0/all/0/1&quot;&gt;Meng Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dedeyne_L/0/1/0/all/0/1&quot;&gt;Lenore Dedeyne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dupont_J/0/1/0/all/0/1&quot;&gt;Jolan Dupont&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vercauteren_L/0/1/0/all/0/1&quot;&gt;Laura Vercauteren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amini_N/0/1/0/all/0/1&quot;&gt;Nadjia Amini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lapauw_L/0/1/0/all/0/1&quot;&gt;Laurence Lapauw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gielen_E/0/1/0/all/0/1&quot;&gt;Evelien Gielen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verschueren_S/0/1/0/all/0/1&quot;&gt;Sabine Verschueren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varon_C/0/1/0/all/0/1&quot;&gt;Carolina Varon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raedt_W/0/1/0/all/0/1&quot;&gt;Walter De Raedt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanrumste_B/0/1/0/all/0/1&quot;&gt;Bart Vanrumste&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03515">
<title>High-dimensional Bayesian Optimization with Group Testing. (arXiv:2310.03515v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03515</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian optimization is an effective method for optimizing
expensive-to-evaluate black-box functions. High-dimensional problems are
particularly challenging as the surrogate model of the objective suffers from
the curse of dimensionality, which makes accurate modeling difficult. We
propose a group testing approach to identify active variables to facilitate
efficient optimization in these domains. The proposed algorithm, Group Testing
Bayesian Optimization (GTBO), first runs a testing phase where groups of
variables are systematically selected and tested on whether they influence the
objective. To that end, we extend the well-established theory of group testing
to functions of continuous ranges. In the second phase, GTBO guides
optimization by placing more importance on the active dimensions. By exploiting
the axis-aligned subspace assumption, GTBO is competitive against
state-of-the-art methods on several synthetic and real-world high-dimensional
optimization tasks. Furthermore, GTBO aids in the discovery of active
parameters in applications, thereby enhancing practitioners&apos; understanding of
the problem at hand.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hellsten_E/0/1/0/all/0/1&quot;&gt;Erik Orm Hellsten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hvarfner_C/0/1/0/all/0/1&quot;&gt;Carl Hvarfner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papenmeier_L/0/1/0/all/0/1&quot;&gt;Leonard Papenmeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nardi_L/0/1/0/all/0/1&quot;&gt;Luigi Nardi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03529">
<title>Deep Ridgelet Transform: Voice with Koopman Operator Proves Universality of Formal Deep Networks. (arXiv:2310.03529v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03529</link>
<description rdf:parseType="Literal">&lt;p&gt;We identify hidden layers inside a DNN with group actions on the data space,
and formulate the DNN as a dual voice transform with respect to Koopman
operator, a linear representation of the group action. Based on the group
theoretic arguments, particularly by using Schur&apos;s lemma, we show a simple
proof of the universality of those DNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1&quot;&gt;Sho Sonoda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashimoto_Y/0/1/0/all/0/1&quot;&gt;Yuka Hashimoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1&quot;&gt;Isao Ishikawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1&quot;&gt;Masahiro Ikeda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03530">
<title>Joint Group Invariant Functions on Data-Parameter Domain Induce Universal Neural Networks. (arXiv:2310.03530v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03530</link>
<description rdf:parseType="Literal">&lt;p&gt;The symmetry and geometry of input data are considered to be encoded in the
internal data representation inside the neural network, but the specific
encoding rule has been less investigated. By focusing on a joint group
invariant function on the data-parameter domain, we present a systematic rule
to find a dual group action on the parameter domain from a group action on the
data domain. Further, we introduce generalized neural networks induced from the
joint invariant functions, and present a new group theoretic proof of their
universality theorems by using Schur&apos;s lemma. Since traditional universality
theorems were demonstrated based on functional analytical methods, this study
sheds light on the group theoretic aspect of the approximation theory,
connecting geometric deep learning to abstract harmonic analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1&quot;&gt;Sho Sonoda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishi_H/0/1/0/all/0/1&quot;&gt;Hideyuki Ishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1&quot;&gt;Isao Ishikawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1&quot;&gt;Masahiro Ikeda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03545">
<title>Distribution-free risk assessment of regression-based machine learning algorithms. (arXiv:2310.03545v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03545</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning algorithms have grown in sophistication over the years and
are increasingly deployed for real-life applications. However, when using
machine learning techniques in practical settings, particularly in high-risk
applications such as medicine and engineering, obtaining the failure
probability of the predictive model is critical. We refer to this problem as
the risk-assessment task. We focus on regression algorithms and the
risk-assessment task of computing the probability of the true label lying
inside an interval defined around the model&apos;s prediction. We solve the
risk-assessment problem using the conformal prediction approach, which provides
prediction intervals that are guaranteed to contain the true label with a given
probability. Using this coverage property, we prove that our approximated
failure probability is conservative in the sense that it is not lower than the
true failure probability of the ML algorithm. We conduct extensive experiments
to empirically study the accuracy of the proposed method for problems with and
without covariate shift. Our analysis focuses on different modeling regimes,
dataset sizes, and conformal prediction methodologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sukrita Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarna_N/0/1/0/all/0/1&quot;&gt;Neeraj Sarna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orfanoudaki_A/0/1/0/all/0/1&quot;&gt;Agni Orfanoudaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1&quot;&gt;Michael Berger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03546">
<title>Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models. (arXiv:2310.03546v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03546</link>
<description rdf:parseType="Literal">&lt;p&gt;Posterior sampling has been shown to be a powerful Bayesian approach for
solving imaging inverse problems. The recent plug-and-play unadjusted Langevin
algorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling
and minimum mean squared error (MMSE) estimation by combining physical
measurement models with deep-learning priors specified using image denoisers.
However, the intricate relationship between the sampling distribution of
PnP-ULA and the mismatched data-fidelity and denoiser has not been
theoretically analyzed. We address this gap by proposing a posterior-L2
pseudometric and using it to quantify an explicit error bound for PnP-ULA under
mismatched posterior distribution. We numerically validate our theory on
several inverse problems such as sampling from Gaussian mixture models and
image deblurring. Our results suggest that the sensitivity of the sampling
distribution of PnP-ULA to a mismatch in the measurement model and the denoiser
can be precisely characterized.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Renaud_M/0/1/0/all/0/1&quot;&gt;Marien Renaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiaming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1&quot;&gt;Valentin de Bortoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Almansa_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Almansa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kamilov_U/0/1/0/all/0/1&quot;&gt;Ulugbek S. Kamilov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03556">
<title>Stable Training of Probabilistic Models Using the Leave-One-Out Maximum Log-Likelihood Objective. (arXiv:2310.03556v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03556</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic modelling of power systems operation and planning processes
depends on data-driven methods, which require sufficiently large datasets. When
historical data lacks this, it is desired to model the underlying data
generation mechanism as a probability distribution to assess the data quality
and generate more data, if needed. Kernel density estimation (KDE) based models
are popular choices for this task, but they fail to adapt to data regions with
varying densities. In this paper, an adaptive KDE model is employed to
circumvent this, where each kernel in the model has an individual bandwidth.
The leave-one-out maximum log-likelihood (LOO-MLL) criterion is proposed to
prevent the singular solutions that the regular MLL criterion gives rise to,
and it is proven that LOO-MLL prevents these. Relying on this guaranteed
robustness, the model is extended by assigning learnable weights to the
kernels. In addition, a modified expectation-maximization algorithm is employed
to accelerate the optimization speed reliably. The performance of the proposed
method and models are exhibited on two power systems datasets using different
statistical tests and by comparison with Gaussian mixture models. Results show
that the proposed models have promising performance, in addition to their
singularity prevention guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bolat_K/0/1/0/all/0/1&quot;&gt;Kutay B&amp;#xf6;lat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tindemans_S/0/1/0/all/0/1&quot;&gt;Simon H. Tindemans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Palensky_P/0/1/0/all/0/1&quot;&gt;Peter Palensky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03563">
<title>BID-NeRF: RGB-D image pose estimation with inverted Neural Radiance Fields. (arXiv:2310.03563v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03563</link>
<description rdf:parseType="Literal">&lt;p&gt;We aim to improve the Inverted Neural Radiance Fields (iNeRF) algorithm which
defines the image pose estimation problem as a NeRF based iterative linear
optimization. NeRFs are novel neural space representation models that can
synthesize photorealistic novel views of real-world scenes or objects. Our
contributions are as follows: we extend the localization optimization objective
with a depth-based loss function, we introduce a multi-image based loss
function where a sequence of images with known relative poses are used without
increasing the computational complexity, we omit hierarchical sampling during
volumetric rendering, meaning only the coarse model is used for pose
estimation, and we how that by extending the sampling interval convergence can
be achieved even or higher initial pose estimate errors. With the proposed
modifications the convergence speed is significantly improved, and the basin of
convergence is substantially extended.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Csehi_A/0/1/0/all/0/1&quot;&gt;&amp;#xc1;goston Istv&amp;#xe1;n Csehi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jozsa_C/0/1/0/all/0/1&quot;&gt;Csaba M&amp;#xe1;t&amp;#xe9; J&amp;#xf3;zsa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03572">
<title>Residual Multi-Fidelity Neural Network Computing. (arXiv:2310.03572v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03572</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we consider the general problem of constructing a neural
network surrogate model using multi-fidelity information. Given an inexpensive
low-fidelity and an expensive high-fidelity computational model, we present a
residual multi-fidelity computational framework that formulates the correlation
between models as a residual function, a possibly non-linear mapping between 1)
the shared input space of the models together with the low-fidelity model
output and 2) the discrepancy between the two model outputs. To accomplish
this, we train two neural networks to work in concert. The first network learns
the residual function on a small set of high-fidelity and low-fidelity data.
Once trained, this network is used to generate additional synthetic
high-fidelity data, which is used in the training of a second network. This
second network, once trained, acts as our surrogate for the high-fidelity
quantity of interest. We present three numerical examples to demonstrate the
power of the proposed framework. In particular, we show that dramatic savings
in computational cost may be achieved when the output predictions are desired
to be accurate within small tolerances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_O/0/1/0/all/0/1&quot;&gt;Owen Davis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Motamed_M/0/1/0/all/0/1&quot;&gt;Mohammad Motamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tempone_R/0/1/0/all/0/1&quot;&gt;Raul Tempone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03575">
<title>Analysis of learning a flow-based generative model from limited sample complexity. (arXiv:2310.03575v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03575</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of training a flow-based generative model, parametrized
by a two-layer autoencoder, to sample from a high-dimensional Gaussian mixture.
We provide a sharp end-to-end analysis of the problem. First, we provide a
tight closed-form characterization of the learnt velocity field, when
parametrized by a shallow denoising auto-encoder trained on a finite number $n$
of samples from the target distribution. Building on this analysis, we provide
a sharp description of the corresponding generative flow, which pushes the base
Gaussian density forward to an approximation of the target density. In
particular, we provide closed-form formulae for the distance between the mean
of the generated mixture and the mean of the target mixture, which we show
decays as $\Theta_n(\frac{1}{n})$. Finally, this rate is shown to be in fact
Bayes-optimal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cui_H/0/1/0/all/0/1&quot;&gt;Hugo Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krzakala_F/0/1/0/all/0/1&quot;&gt;Florent Krzakala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1&quot;&gt;Eric Vanden-Eijnden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zdeborova_L/0/1/0/all/0/1&quot;&gt;Lenka Zdeborov&amp;#xe1;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03578">
<title>Targeted Adversarial Attacks on Generalizable Neural Radiance Fields. (arXiv:2310.03578v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03578</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Radiance Fields (NeRFs) have recently emerged as a powerful tool for
3D scene representation and rendering. These data-driven models can learn to
synthesize high-quality images from sparse 2D observations, enabling realistic
and interactive scene reconstructions. However, the growing usage of NeRFs in
critical applications such as augmented reality, robotics, and virtual
environments could be threatened by adversarial attacks.
&lt;/p&gt;
&lt;p&gt;In this paper we present how generalizable NeRFs can be attacked by both
low-intensity adversarial attacks and adversarial patches, where the later
could be robust enough to be used in real world applications. We also
demonstrate targeted attacks, where a specific, predefined output scene is
generated by these attack with success.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horvath_A/0/1/0/all/0/1&quot;&gt;Andras Horvath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jozsa_C/0/1/0/all/0/1&quot;&gt;Csaba M. Jozsa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03581">
<title>Resilient Legged Local Navigation: Learning to Traverse with Compromised Perception End-to-End. (arXiv:2310.03581v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2310.03581</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous robots must navigate reliably in unknown environments even under
compromised exteroceptive perception, or perception failures. Such failures
often occur when harsh environments lead to degraded sensing, or when the
perception algorithm misinterprets the scene due to limited generalization. In
this paper, we model perception failures as invisible obstacles and pits, and
train a reinforcement learning (RL) based local navigation policy to guide our
legged robot. Unlike previous works relying on heuristics and anomaly detection
to update navigational information, we train our navigation policy to
reconstruct the environment information in the latent space from corrupted
perception and react to perception failures end-to-end. To this end, we
incorporate both proprioception and exteroception into our policy inputs,
thereby enabling the policy to sense collisions on different body parts and
pits, prompting corresponding reactions. We validate our approach in simulation
and on the real quadruped robot ANYmal running in real-time (&amp;lt;10 ms CPU
inference). In a quantitative comparison with existing heuristic-based locally
reactive planners, our policy increases the success rate over 30% when facing
perception failures. Project Page: https://bit.ly/45NBTuh.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1&quot;&gt;Jin Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frey_J/0/1/0/all/0/1&quot;&gt;Jonas Frey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudin_N/0/1/0/all/0/1&quot;&gt;Nikita Rudin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mattamala_M/0/1/0/all/0/1&quot;&gt;Matias Mattamala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cadena_C/0/1/0/all/0/1&quot;&gt;Cesar Cadena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1&quot;&gt;Marco Hutter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03585">
<title>Smoothing Methods for Automatic Differentiation Across Conditional Branches. (arXiv:2310.03585v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03585</link>
<description rdf:parseType="Literal">&lt;p&gt;Programs involving discontinuities introduced by control flow constructs such
as conditional branches pose challenges to mathematical optimization methods
that assume a degree of smoothness in the objective function&apos;s response
surface. Smooth interpretation (SI) is a form of abstract interpretation that
approximates the convolution of a program&apos;s output with a Gaussian kernel, thus
smoothing its output in a principled manner. Here, we combine SI with automatic
differentiation (AD) to efficiently compute gradients of smoothed programs. In
contrast to AD across a regular program execution, these gradients also capture
the effects of alternative control flow paths. The combination of SI with AD
enables the direct gradient-based parameter synthesis for branching programs,
allowing for instance the calibration of simulation models or their combination
with neural network models in machine learning pipelines. We detail the effects
of the approximations made for tractability in SI and propose a novel Monte
Carlo estimator that avoids the underlying assumptions by estimating the
smoothed programs&apos; gradients through a combination of AD and sampling. Using
DiscoGrad, our tool for automatically translating simple C++ programs to a
smooth differentiable form, we perform an extensive evaluation. We compare the
combination of SI with AD and our Monte Carlo estimator to existing
gradient-free and stochastic methods on four non-trivial and originally
discontinuous problems ranging from classical simulation-based optimization to
neural network-driven control. While the optimization progress with the
SI-based estimator depends on the complexity of the programs&apos; control flow, our
Monte Carlo estimator is competitive in all problems, exhibiting the fastest
convergence by a substantial margin in our highest-dimensional problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreikemeyer_J/0/1/0/all/0/1&quot;&gt;Justin N. Kreikemeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andelfinger_P/0/1/0/all/0/1&quot;&gt;Philipp Andelfinger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03589">
<title>TimeGPT-1. (arXiv:2310.03589v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03589</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce TimeGPT, the first foundation model for time
series, capable of generating accurate predictions for diverse datasets not
seen during training. We evaluate our pre-trained model against established
statistical, machine learning, and deep learning methods, demonstrating that
TimeGPT zero-shot inference excels in performance, efficiency, and simplicity.
Our study provides compelling evidence that insights from other domains of
artificial intelligence can be effectively applied to time series analysis. We
conclude that large-scale time series models offer an exciting opportunity to
democratize access to precise predictions and reduce uncertainty by leveraging
the capabilities of contemporary advancements in deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garza_A/0/1/0/all/0/1&quot;&gt;Azul Garza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mergenthaler_Canseco_M/0/1/0/all/0/1&quot;&gt;Max Mergenthaler-Canseco&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03597">
<title>Sampling via Gradient Flows in the Space of Probability Measures. (arXiv:2310.03597v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03597</link>
<description rdf:parseType="Literal">&lt;p&gt;Sampling a target probability distribution with an unknown normalization
constant is a fundamental challenge in computational science and engineering.
Recent work shows that algorithms derived by considering gradient flows in the
space of probability measures open up new avenues for algorithm development.
This paper makes three contributions to this sampling approach by scrutinizing
the design components of such gradient flows. Any instantiation of a gradient
flow for sampling needs an energy functional and a metric to determine the
flow, as well as numerical approximations of the flow to derive algorithms. Our
first contribution is to show that the Kullback-Leibler divergence, as an
energy functional, has the unique property (among all f-divergences) that
gradient flows resulting from it do not depend on the normalization constant of
the target distribution. Our second contribution is to study the choice of
metric from the perspective of invariance. The Fisher-Rao metric is known as
the unique choice (up to scaling) that is diffeomorphism invariant. As a
computationally tractable alternative, we introduce a relaxed, affine
invariance property for the metrics and gradient flows. In particular, we
construct various affine invariant Wasserstein and Stein gradient flows. Affine
invariant gradient flows are shown to behave more favorably than their
non-affine-invariant counterparts when sampling highly anisotropic
distributions, in theory and by using particle methods. Our third contribution
is to study, and develop efficient algorithms based on Gaussian approximations
of the gradient flows; this leads to an alternative to particle methods. We
establish connections between various Gaussian approximate gradient flows,
discuss their relation to gradient methods arising from parametric variational
inference, and study their convergence properties both theoretically and
numerically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yifan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;Daniel Zhengyu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jiaoyang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Reich_S/0/1/0/all/0/1&quot;&gt;Sebastian Reich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stuart_A/0/1/0/all/0/1&quot;&gt;Andrew M Stuart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03605">
<title>FASER: Binary Code Similarity Search through the use of Intermediate Representations. (arXiv:2310.03605v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2310.03605</link>
<description rdf:parseType="Literal">&lt;p&gt;Being able to identify functions of interest in cross-architecture software
is useful whether you are analysing for malware, securing the software supply
chain or conducting vulnerability research. Cross-Architecture Binary Code
Similarity Search has been explored in numerous studies and has used a wide
range of different data sources to achieve its goals. The data sources
typically used draw on common structures derived from binaries such as function
control flow graphs or binary level call graphs, the output of the disassembly
process or the outputs of a dynamic analysis approach. One data source which
has received less attention is binary intermediate representations. Binary
Intermediate representations possess two interesting properties: they are cross
architecture by their very nature and encode the semantics of a function
explicitly to support downstream usage. Within this paper we propose Function
as a String Encoded Representation (FASER) which combines long document
transformers with the use of intermediate representations to create a model
capable of cross architecture function search without the need for manual
feature engineering, pre-training or a dynamic analysis step. We compare our
approach against a series of baseline approaches for two tasks; A general
function search task and a targeted vulnerability search task. Our approach
demonstrates strong performance across both tasks, performing better than all
baseline approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collyer_J/0/1/0/all/0/1&quot;&gt;Josh Collyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watson_T/0/1/0/all/0/1&quot;&gt;Tim Watson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_I/0/1/0/all/0/1&quot;&gt;Iain Phillips&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03606">
<title>Comparing Time-Series Analysis Approaches Utilized in Research Papers to Forecast COVID-19 Cases in Africa: A Literature Review. (arXiv:2310.03606v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03606</link>
<description rdf:parseType="Literal">&lt;p&gt;This literature review aimed to compare various time-series analysis
approaches utilized in forecasting COVID-19 cases in Africa. The study involved
a methodical search for English-language research papers published between
January 2020 and July 2023, focusing specifically on papers that utilized
time-series analysis approaches on COVID-19 datasets in Africa. A variety of
databases including PubMed, Google Scholar, Scopus, and Web of Science were
utilized for this process. The research papers underwent an evaluation process
to extract relevant information regarding the implementation and performance of
the time-series analysis models. The study highlighted the different
methodologies employed, evaluating their effectiveness and limitations in
forecasting the spread of the virus. The result of this review could contribute
deeper insights into the field, and future research should consider these
insights to improve time series analysis models and explore the integration of
different approaches for enhanced public health decision-making.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebadi_A/0/1/0/all/0/1&quot;&gt;Ali Ebadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahafizadeh_E/0/1/0/all/0/1&quot;&gt;Ebrahim Sahafizadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03611">
<title>GENER: A Parallel Layer Deep Learning Network To Detect Gene-Gene Interactions From Gene Expression Data. (arXiv:2310.03611v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03611</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting and discovering new gene interactions based on known gene
expressions and gene interaction data presents a significant challenge. Various
statistical and deep learning methods have attempted to tackle this challenge
by leveraging the topological structure of gene interactions and gene
expression patterns to predict novel gene interactions. In contrast, some
approaches have focused exclusively on utilizing gene expression profiles. In
this context, we introduce GENER, a parallel-layer deep learning network
designed exclusively for the identification of gene-gene relationships using
gene expression data. We conducted two training experiments and compared the
performance of our network with that of existing statistical and deep learning
approaches. Notably, our model achieved an average AUROC score of 0.834 on the
combined BioGRID&amp;amp;DREAM5 dataset, outperforming competing methods in predicting
gene-gene interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elnaggar_A/0/1/0/all/0/1&quot;&gt;Ahmed Fakhry Elnaggar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khafagy_R/0/1/0/all/0/1&quot;&gt;Raneem Ali Khafagy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ludl_A/0/1/0/all/0/1&quot;&gt;Adriaan-Alexander Ludl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03613">
<title>Solving a Class of Non-Convex Minimax Optimization in Federated Learning. (arXiv:2310.03613v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03613</link>
<description rdf:parseType="Literal">&lt;p&gt;The minimax problems arise throughout machine learning applications, ranging
from adversarial training and policy evaluation in reinforcement learning to
AUROC maximization. To address the large-scale data challenges across multiple
clients with communication-efficient distributed training, federated learning
(FL) is gaining popularity. Many optimization algorithms for minimax problems
have been developed in the centralized setting (\emph{i.e.} single-machine).
Nonetheless, the algorithm for minimax problems under FL is still
underexplored. In this paper, we study a class of federated nonconvex minimax
optimization problems. We propose FL algorithms (FedSGDA+ and FedSGDA-M) and
reduce existing complexity results for the most common minimax problems. For
nonconvex-concave problems, we propose FedSGDA+ and reduce the communication
complexity to $O(\varepsilon^{-6})$. Under nonconvex-strongly-concave and
nonconvex-PL minimax settings, we prove that FedSGDA-M has the best-known
sample complexity of $O(\kappa^{3} N^{-1}\varepsilon^{-3})$ and the best-known
communication complexity of $O(\kappa^{2}\varepsilon^{-2})$. FedSGDA-M is the
first algorithm to match the best sample complexity $O(\varepsilon^{-3})$
achieved by the single-machine method under the nonconvex-strongly-concave
setting. Extensive experimental results on fair classification and AUROC
maximization show the efficiency of our algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xidong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jianhui Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zhengmian Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Aidong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Heng Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03614">
<title>Adversarial Machine Learning for Social Good: Reframing the Adversary as an Ally. (arXiv:2310.03614v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03614</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks (DNNs) have been the driving force behind many of the
recent advances in machine learning. However, research has shown that DNNs are
vulnerable to adversarial examples -- input samples that have been perturbed to
force DNN-based models to make errors. As a result, Adversarial Machine
Learning (AdvML) has gained a lot of attention, and researchers have
investigated these vulnerabilities in various settings and modalities. In
addition, DNNs have also been found to incorporate embedded bias and often
produce unexplainable predictions, which can result in anti-social AI
applications. The emergence of new AI technologies that leverage Large Language
Models (LLMs), such as ChatGPT and GPT-4, increases the risk of producing
anti-social applications at scale. AdvML for Social Good (AdvML4G) is an
emerging field that repurposes the AdvML bug to invent pro-social applications.
Regulators, practitioners, and researchers should collaborate to encourage the
development of pro-social applications and hinder the development of
anti-social ones. In this work, we provide the first comprehensive review of
the emerging field of AdvML4G. This paper encompasses a taxonomy that
highlights the emergence of AdvML4G, a discussion of the differences and
similarities between AdvML4G and AdvML, a taxonomy covering social good-related
concepts and aspects, an exploration of the motivations behind the emergence of
AdvML4G at the intersection of ML4G and AdvML, and an extensive summary of the
works that utilize AdvML4G as an auxiliary tool for innovating pro-social
applications. Finally, we elaborate upon various challenges and open research
issues that require significant attention from the research community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Maliki_S/0/1/0/all/0/1&quot;&gt;Shawqi Al-Maliki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qayyum_A/0/1/0/all/0/1&quot;&gt;Adnan Qayyum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ali_H/0/1/0/all/0/1&quot;&gt;Hassan Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdallah_M/0/1/0/all/0/1&quot;&gt;Mohamed Abdallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qadir_J/0/1/0/all/0/1&quot;&gt;Junaid Qadir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1&quot;&gt;Dinh Thai Hoang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1&quot;&gt;Dusit Niyato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Fuqaha_A/0/1/0/all/0/1&quot;&gt;Ala Al-Fuqaha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03618">
<title>CLASSify: A Web-Based Tool for Machine Learning. (arXiv:2310.03618v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03618</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning classification problems are widespread in bioinformatics,
but the technical knowledge required to perform model training, optimization,
and inference can prevent researchers from utilizing this technology. This
article presents an automated tool for machine learning classification problems
to simplify the process of training models and producing results while
providing informative visualizations and insights into the data. This tool
supports both binary and multiclass classification problems, and it provides
access to a variety of models and methods. Synthetic data can be generated
within the interface to fill missing values, balance class labels, or generate
entirely new datasets. It also provides support for feature evaluation and
generates explainability scores to indicate which features influence the output
the most. We present CLASSify, an open-source tool for simplifying the user
experience of solving classification problems without the need for knowledge of
machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mullen_A/0/1/0/all/0/1&quot;&gt;Aaron D. Mullen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Armstrong_S/0/1/0/all/0/1&quot;&gt;Samuel E. Armstrong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talbert_J/0/1/0/all/0/1&quot;&gt;Jeff Talbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bumgardner_V/0/1/0/all/0/1&quot;&gt;V.K. Cody Bumgardner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03624">
<title>High-Degrees-of-Freedom Dynamic Neural Fields for Robot Self-Modeling and Motion Planning. (arXiv:2310.03624v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03624</link>
<description rdf:parseType="Literal">&lt;p&gt;A robot self-model is a task-agnostic representation of the robot&apos;s physical
morphology that can be used for motion planning tasks in absence of classical
geometric kinematic models. In particular, when the latter are hard to engineer
or the robot&apos;s kinematics change unexpectedly, human-free self-modeling is a
necessary feature of truly autonomous agents. In this work, we leverage neural
fields to allow a robot to self-model its kinematics as a neural-implicit query
model learned only from 2D images annotated with camera poses and
configurations. This enables significantly greater applicability than existing
approaches which have been dependent on depth images or geometry knowledge. To
this end, alongside a curricular data sampling strategy, we propose a new
encoder-based neural density field architecture for dynamic object-centric
scenes conditioned on high numbers of degrees of freedom (DOFs). In a 7-DOF
robot test setup, the learned self-model achieves a Chamfer-L2 distance of 2%
of the robot&apos;s workspace dimension. We demonstrate the capabilities of this
model on a motion planning task as an exemplary downstream application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulze_L/0/1/0/all/0/1&quot;&gt;Lennart Schulze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipson_H/0/1/0/all/0/1&quot;&gt;Hod Lipson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03635">
<title>CLEVRER-Humans: Describing Physical and Causal Events the Human Way. (arXiv:2310.03635v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2310.03635</link>
<description rdf:parseType="Literal">&lt;p&gt;Building machines that can reason about physical events and their causal
relationships is crucial for flexible interaction with the physical world.
However, most existing physical and causal reasoning benchmarks are exclusively
based on synthetically generated events and synthetic natural language
descriptions of causal relationships. This design brings up two issues. First,
there is a lack of diversity in both event types and natural language
descriptions; second, causal relationships based on manually-defined heuristics
are different from human judgments. To address both shortcomings, we present
the CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of
physical events with human labels. We employ two techniques to improve data
collection efficiency: first, a novel iterative event cloze task to elicit a
new representation of events in videos, which we term Causal Event Graphs
(CEGs); second, a data augmentation technique based on neural language
generative models. We convert the collected CEGs into questions and answers to
be consistent with prior work. Finally, we study a collection of baseline
approaches for CLEVRER-Humans question-answering, highlighting the great
challenges set forth by our benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1&quot;&gt;Jiayuan Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xuelin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xikun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1&quot;&gt;Noah D. Goodman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03641">
<title>Distributional PAC-Learning from Nisan&apos;s Natural Proofs. (arXiv:2310.03641v1 [cs.CC])</title>
<link>http://arxiv.org/abs/2310.03641</link>
<description rdf:parseType="Literal">&lt;p&gt;(Abridged) Carmosino et al. (2016) demonstrated that natural proofs of
circuit lower bounds for \Lambda imply efficient algorithms for learning
\Lambda-circuits, but only over the uniform distribution, with membership
queries, and provided \AC^0[p] \subseteq \Lambda. We consider whether this
implication can be generalized to \Lambda \not\supseteq \AC^0[p], and to
learning algorithms in Valiant&apos;s PAC model, which use only random examples and
learn over arbitrary example distributions. We give results of both positive
and negative flavor.
&lt;/p&gt;
&lt;p&gt;On the negative side, we observe that if, for every circuit class \Lambda,
the implication from natural proofs for \Lambda to learning \Lambda-circuits in
Valiant&apos;s PAC model holds, then there is a polynomial time solution to
O(n^{1.5})-uSVP (unique Shortest Vector Problem), and polynomial time quantum
solutions to O(n^{1.5})-SVP (Shortest Vector Problem) and O(n^{1.5})-SIVP
(Shortest Independent Vector Problem). This indicates that whether natural
proofs for \Lambda imply efficient learning algorithms for \Lambda in Valiant&apos;s
PAC model may depend on \Lambda.
&lt;/p&gt;
&lt;p&gt;On the positive side, our main result is that specific natural proofs arising
from a type of communication complexity argument (e.g., Nisan (1993), for
depth-2 majority circuits) imply PAC-learning algorithms in a new
distributional variant of Valiant&apos;s model. Our distributional PAC model is
stronger than the average-case prediction model of Blum et al (1993) and the
heuristic PAC model of Nanashima (2021), and has several important properties
which make it of independent interest, such as being boosting-friendly. The
main applications of our result are new distributional PAC-learning algorithms
for depth-2 majority circuits, polytopes and DNFs over natural target
distributions, as well as the nonexistence of encoded-input weak PRFs that can
be evaluated by depth-2 majority circuits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karchmer_A/0/1/0/all/0/1&quot;&gt;Ari Karchmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03646">
<title>TRAM: Bridging Trust Regions and Sharpness Aware Minimization. (arXiv:2310.03646v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03646</link>
<description rdf:parseType="Literal">&lt;p&gt;By reducing the curvature of the loss surface in the parameter space,
Sharpness-aware minimization (SAM) yields widespread robustness improvement
under domain transfer. Instead of focusing on parameters, however, this work
considers the transferability of representations as the optimization target for
out-of-domain generalization in a fine-tuning setup. To encourage the retention
of transferable representations, we consider trust region-based fine-tuning
methods, which exploit task-specific skills without forgetting task-agnostic
representations from pre-training. We unify parameter- and representation-space
smoothing approaches by using trust region bounds to inform SAM-style
regularizers on both of these optimization surfaces. We propose Trust Region
Aware Minimization (TRAM), a fine-tuning algorithm that optimizes for flat
minima and smooth, informative representations without forgetting pre-trained
structure. We find that TRAM outperforms both sharpness-aware and trust
region-based optimization methods on cross-domain language modeling and
cross-lingual transfer, where robustness to domain transfer and representation
generality are critical for success. TRAM establishes a new standard in
training generalizable models with minimal additional computation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sherborne_T/0/1/0/all/0/1&quot;&gt;Tom Sherborne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1&quot;&gt;Naomi Saphra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasigi_P/0/1/0/all/0/1&quot;&gt;Pradeep Dasigi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1&quot;&gt;Hao Peng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03647">
<title>Rethinking Fairness for Human-AI Collaboration. (arXiv:2310.03647v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03647</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing approaches to algorithmic fairness aim to ensure equitable outcomes
if human decision-makers comply perfectly with algorithmic decisions. However,
perfect compliance with the algorithm is rarely a reality or even a desirable
outcome in human-AI collaboration. Yet, recent studies have shown that
selective compliance with fair algorithms can amplify discrimination relative
to the prior human policy. As a consequence, ensuring equitable outcomes
requires fundamentally different algorithmic design principles that ensure
robustness to the decision-maker&apos;s (a priori unknown) compliance pattern. We
define the notion of compliance-robustly fair algorithmic recommendations that
are guaranteed to (weakly) improve fairness in decisions, regardless of the
human&apos;s compliance pattern. We propose a simple optimization strategy to
identify the best performance-improving compliance-robustly fair policy.
However, we show that it may be infeasible to design algorithmic
recommendations that are simultaneously fair in isolation, compliance-robustly
fair, and more accurate than the human policy; thus, if our goal is to improve
the equity and accuracy of human-AI collaboration, it may not be desirable to
enforce traditional fairness constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1&quot;&gt;Haosen Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastani_H/0/1/0/all/0/1&quot;&gt;Hamsa Bastani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1&quot;&gt;Osbert Bastani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03652">
<title>Extreme sparsification of physics-augmented neural networks for interpretable model discovery in mechanics. (arXiv:2310.03652v1 [cs.CE])</title>
<link>http://arxiv.org/abs/2310.03652</link>
<description rdf:parseType="Literal">&lt;p&gt;Data-driven constitutive modeling with neural networks has received increased
interest in recent years due to its ability to easily incorporate physical and
mechanistic constraints and to overcome the challenging and time-consuming task
of formulating phenomenological constitutive laws that can accurately capture
the observed material response. However, even though neural network-based
constitutive laws have been shown to generalize proficiently, the generated
representations are not easily interpretable due to their high number of
trainable parameters. Sparse regression approaches exist that allow to
obtaining interpretable expressions, but the user is tasked with creating a
library of model forms which by construction limits their expressiveness to the
functional forms provided in the libraries. In this work, we propose to train
regularized physics-augmented neural network-based constitutive models
utilizing a smoothed version of $L^{0}$-regularization. This aims to maintain
the trustworthiness inherited by the physical constraints, but also enables
interpretability which has not been possible thus far on any type of machine
learning-based constitutive model where model forms were not assumed a-priory
but were actually discovered. During the training process, the network
simultaneously fits the training data and penalizes the number of active
parameters, while also ensuring constitutive constraints such as thermodynamic
consistency. We show that the method can reliably obtain interpretable and
trustworthy constitutive models for compressible and incompressible
hyperelasticity, yield functions, and hardening models for elastoplasticity,
for synthetic and experimental data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuhg_J/0/1/0/all/0/1&quot;&gt;Jan N. Fuhg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_R/0/1/0/all/0/1&quot;&gt;Reese E. Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouklas_N/0/1/0/all/0/1&quot;&gt;Nikolaos Bouklas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03655">
<title>Strategic Evaluation: Subjects, Evaluators, and Society. (arXiv:2310.03655v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2310.03655</link>
<description rdf:parseType="Literal">&lt;p&gt;A broad current application of algorithms is in formal and quantitative
measures of murky concepts -- like merit -- to make decisions. When people
strategically respond to these sorts of evaluations in order to gain favorable
decision outcomes, their behavior can be subjected to moral judgments. They may
be described as &apos;gaming the system&apos; or &apos;cheating,&apos; or (in other cases)
investing &apos;honest effort&apos; or &apos;improving.&apos; Machine learning literature on
strategic behavior has tried to describe these dynamics by emphasizing the
efforts expended by decision subjects hoping to obtain a more favorable
assessment -- some works offer ways to preempt or prevent such manipulations,
some differentiate &apos;gaming&apos; from &apos;improvement&apos; behavior, while others aim to
measure the effort burden or disparate effects of classification systems. We
begin from a different starting point: that the design of an evaluation itself
can be understood as furthering goals held by the evaluator which may be
misaligned with broader societal goals. To develop the idea that evaluation
represents a strategic interaction in which both the evaluator and the subject
of their evaluation are operating out of self-interest, we put forward a model
that represents the process of evaluation using three interacting agents: a
decision subject, an evaluator, and society, representing a bundle of values
and oversight mechanisms. We highlight our model&apos;s applicability to a number of
social systems where one or two players strategically undermine the others&apos;
interests to advance their own. Treating evaluators as themselves strategic
allows us to re-cast the scrutiny directed at decision subjects, towards the
incentives that underpin institutional designs of evaluations. The moral
standing of strategic behaviors often depend on the moral standing of the
evaluations and incentives that provoke such behaviors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laufer_B/0/1/0/all/0/1&quot;&gt;Benjamin Laufer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1&quot;&gt;Jon Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1&quot;&gt;Karen Levy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nissenbaum_H/0/1/0/all/0/1&quot;&gt;Helen Nissenbaum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03675">
<title>Hadamard Domain Training with Integers for Class Incremental Quantized Learning. (arXiv:2310.03675v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03675</link>
<description rdf:parseType="Literal">&lt;p&gt;Continual learning is a desirable feature in many modern machine learning
applications, which allows in-field adaptation and updating, ranging from
accommodating distribution shift, to fine-tuning, and to learning new tasks.
For applications with privacy and low latency requirements, the compute and
memory demands imposed by continual learning can be cost-prohibitive for
resource-constraint edge platforms. Reducing computational precision through
fully quantized training (FQT) simultaneously reduces memory footprint and
increases compute efficiency for both training and inference. However,
aggressive quantization especially integer FQT typically degrades model
accuracy to unacceptable levels. In this paper, we propose a technique that
leverages inexpensive Hadamard transforms to enable low-precision training with
only integer matrix multiplications. We further determine which tensors need
stochastic rounding and propose tiled matrix multiplication to enable low-bit
width accumulators. We demonstrate the effectiveness of our technique on
several human activity recognition datasets and CIFAR100 in a class incremental
learning setting. We achieve less than 0.5% and 3% accuracy degradation while
we quantize all matrix multiplications inputs down to 4-bits with 8-bit
accumulators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schiemer_M/0/1/0/all/0/1&quot;&gt;Martin Schiemer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaefer_C/0/1/0/all/0/1&quot;&gt;Clemens JS Schaefer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vap_J/0/1/0/all/0/1&quot;&gt;Jayden Parker Vap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horeni_M/0/1/0/all/0/1&quot;&gt;Mark James Horeni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Emma Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Juan Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1&quot;&gt;Siddharth Joshi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03684">
<title>SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03684</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite efforts to align large language models (LLMs) with human values,
widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to
jailbreaking attacks, wherein an adversary fools a targeted LLM into generating
objectionable content. To address this vulnerability, we propose SmoothLLM, the
first algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our
finding that adversarially-generated prompts are brittle to character-level
changes, our defense first randomly perturbs multiple copies of a given input
prompt, and then aggregates the corresponding predictions to detect adversarial
inputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to
below one percentage point, avoids unnecessary conservatism, and admits
provable guarantees on attack mitigation. Moreover, our defense uses
exponentially fewer queries than existing attacks and is compatible with any
LLM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robey_A/0/1/0/all/0/1&quot;&gt;Alexander Robey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1&quot;&gt;Eric Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1&quot;&gt;Hamed Hassani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1&quot;&gt;George J. Pappas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03693">
<title>Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!. (arXiv:2310.03693v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03693</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimizing large language models (LLMs) for downstream use cases often
involves the customization of pre-trained LLMs through further fine-tuning.
Meta&apos;s open release of Llama models and OpenAI&apos;s APIs for fine-tuning GPT-3.5
Turbo on custom datasets also encourage this practice. But, what are the safety
costs associated with such custom fine-tuning? We note that while existing
safety alignment infrastructures can restrict harmful behaviors of LLMs at
inference time, they do not cover safety risks when fine-tuning privileges are
extended to end-users. Our red teaming studies find that the safety alignment
of LLMs can be compromised by fine-tuning with only a few adversarially
designed training examples. For instance, we jailbreak GPT-3.5 Turbo&apos;s safety
guardrails by fine-tuning it on only 10 such examples at a cost of less than
$0.20 via OpenAI&apos;s APIs, making the model responsive to nearly any harmful
instructions. Disconcertingly, our research also reveals that, even without
malicious intent, simply fine-tuning with benign and commonly used datasets can
also inadvertently degrade the safety alignment of LLMs, though to a lesser
extent. These findings suggest that fine-tuning aligned LLMs introduces new
safety risks that current safety infrastructures fall short of addressing --
even if a model&apos;s initial safety alignment is impeccable, it is not necessarily
to be maintained after custom fine-tuning. We outline and critically analyze
potential mitigations and advocate for further research efforts toward
reinforcing safety protocols for the custom fine-tuning of aligned LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1&quot;&gt;Xiangyu Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1&quot;&gt;Yi Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1&quot;&gt;Tinghao Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pin-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1&quot;&gt;Ruoxi Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1&quot;&gt;Prateek Mittal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1&quot;&gt;Peter Henderson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03695">
<title>Multimarginal generative modeling with stochastic interpolants. (arXiv:2310.03695v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03695</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a set of $K$ probability densities, we consider the multimarginal
generative modeling problem of learning a joint distribution that recovers
these densities as marginals. The structure of this joint distribution should
identify multi-way correspondences among the prescribed marginals. We formalize
an approach to this task within a generalization of the stochastic interpolant
framework, leading to efficient learning algorithms built upon dynamical
transport of measure. Our generative models are defined by velocity and score
fields that can be characterized as the minimizers of simple quadratic
objectives, and they are defined on a simplex that generalizes the time
variable in the usual dynamical transport framework. The resulting transport on
the simplex is influenced by all marginals, and we show that multi-way
correspondences can be extracted. The identification of such correspondences
has applications to style transfer, algorithmic fairness, and data
decorruption. In addition, the multimarginal perspective enables an efficient
algorithm for reducing the dynamical transport cost in the ordinary
two-marginal setting. We demonstrate these capacities with several numerical
examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albergo_M/0/1/0/all/0/1&quot;&gt;Michael S. Albergo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boffi_N/0/1/0/all/0/1&quot;&gt;Nicholas M. Boffi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindsey_M/0/1/0/all/0/1&quot;&gt;Michael Lindsey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1&quot;&gt;Eric Vanden-Eijnden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03696">
<title>Banach Space Optimality of Neural Architectures With Multivariate Nonlinearities. (arXiv:2310.03696v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03696</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the variational optimality (specifically, the Banach space
optimality) of a large class of neural architectures with multivariate
nonlinearities/activation functions. To that end, we construct a new family of
Banach spaces defined via a regularization operator and the $k$-plane
transform. We prove a representer theorem that states that the solution sets to
learning problems posed over these Banach spaces are completely characterized
by neural architectures with multivariate nonlinearities. These optimal
architectures have skip connections and are tightly connected to orthogonal
weight normalization and multi-index models, both of which have received
considerable interest in the neural network community. Our framework is
compatible with a number of classical nonlinearities including the rectified
linear unit (ReLU) activation function, the norm activation function, and the
radial basis functions found in the theory of thin-plate/polyharmonic splines.
We also show that the underlying spaces are special instances of reproducing
kernel Banach spaces and variation spaces. Our results shed light on the
regularity of functions learned by neural networks trained on data,
particularly with multivariate nonlinearities, and provide new theoretical
motivation for several architectural choices found in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Parhi_R/0/1/0/all/0/1&quot;&gt;Rahul Parhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Unser_M/0/1/0/all/0/1&quot;&gt;Michael Unser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03707">
<title>OMG-ATTACK: Self-Supervised On-Manifold Generation of Transferable Evasion Attacks. (arXiv:2310.03707v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03707</link>
<description rdf:parseType="Literal">&lt;p&gt;Evasion Attacks (EA) are used to test the robustness of trained neural
networks by distorting input data to misguide the model into incorrect
classifications. Creating these attacks is a challenging task, especially with
the ever-increasing complexity of models and datasets. In this work, we
introduce a self-supervised, computationally economical method for generating
adversarial examples, designed for the unseen black-box setting. Adapting
techniques from representation learning, our method generates on-manifold EAs
that are encouraged to resemble the data distribution. These attacks are
comparable in effectiveness compared to the state-of-the-art when attacking the
model trained on, but are significantly more effective when attacking unseen
models, as the attacks are more related to the data rather than the model
itself. Our experiments consistently demonstrate the method is effective across
various models, unseen data categories, and even defended models, suggesting a
significant role for on-manifold EAs when targeting unseen models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tal_O/0/1/0/all/0/1&quot;&gt;Ofir Bar Tal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haviv_A/0/1/0/all/0/1&quot;&gt;Adi Haviv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1&quot;&gt;Amit H. Bermano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03708">
<title>Beyond One-Preference-for-All: Multi-Objective Direct Preference Optimization. (arXiv:2310.03708v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03708</link>
<description rdf:parseType="Literal">&lt;p&gt;Language models (LMs), despite aligning well with an average labeler through
reinforcement learning from human feedback (RLHF), may not universally suit
diverse human preferences. Recent approaches therefore opt for customization by
collecting multi-dimensional feedback and creating distinct rewards for each
dimension (e.g., helpfulness, harmlessness, honesty). LMs can then be tailored
to different preferences using multi-objective RL (MORL) with different reward
weightings. Yet, RL fine-tuning is unstable and resource-heavy, especially for
MORLHF with diverse and usually conflicting objectives. In this paper, we
present Multi-Objective Direct Preference Optimization (MODPO), an RL-free
algorithm that extends Direct Preference Optimization (DPO) for multiple
alignment objectives. Essentially, MODPO trains different LMs to represent
different collective reward models that combine all objectives with specific
weightings. With a simple cross-entropy loss, the LMs optimized against the
MODPO objective are analytically the exact solutions of the original MORLHF
objective. Empirical results in safety alignment and long-form question
answering confirm that MODPO matches or outperforms existing methods,
efficiently producing a Pareto-optimal set of LMs that cater to diverse
preferences with 3 times less computational resources compared with MORLHF.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhanhui Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1&quot;&gt;Jing Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1&quot;&gt;Xiangyu Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1&quot;&gt;Wanli Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1&quot;&gt;Yu Qiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03710">
<title>Agent Instructs Large Language Models to be General Zero-Shot Reasoners. (arXiv:2310.03710v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03710</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a method to improve the zero-shot reasoning abilities of large
language models on general language understanding tasks. Specifically, we build
an autonomous agent to instruct the reasoning process of large language models.
We show this approach further unleashes the zero-shot reasoning abilities of
large language models to more tasks. We study the performance of our method on
a wide set of datasets spanning generation, classification, and reasoning. We
show that our method generalizes to most tasks and obtains state-of-the-art
zero-shot performance on 20 of the 29 datasets that we evaluate. For instance,
our method boosts the performance of state-of-the-art large language models by
a large margin, including Vicuna-13b (13.3%), Llama-2-70b-chat (23.2%), and
GPT-3.5 Turbo (17.0%). Compared to zero-shot chain of thought, our improvement
in reasoning is striking, with an average increase of 10.5%. With our method,
Llama-2-70b-chat outperforms zero-shot GPT-3.5 Turbo by 10.2%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crispino_N/0/1/0/all/0/1&quot;&gt;Nicholas Crispino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montgomery_K/0/1/0/all/0/1&quot;&gt;Kyle Montgomery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1&quot;&gt;Fankun Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dawn Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chenguang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03714">
<title>DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines. (arXiv:2310.03714v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03714</link>
<description rdf:parseType="Literal">&lt;p&gt;The ML community is rapidly exploring techniques for prompting language
models (LMs) and for stacking them into pipelines that solve complex tasks.
Unfortunately, existing LM pipelines are typically implemented using hard-coded
&quot;prompt templates&quot;, i.e. lengthy strings discovered via trial and error. Toward
a more systematic approach for developing and optimizing LM pipelines, we
introduce DSPy, a programming model that abstracts LM pipelines as text
transformation graphs, i.e. imperative computational graphs where LMs are
invoked through declarative modules. DSPy modules are parameterized, meaning
they can learn (by creating and collecting demonstrations) how to apply
compositions of prompting, finetuning, augmentation, and reasoning techniques.
We design a compiler that will optimize any DSPy pipeline to maximize a given
metric. We conduct two case studies, showing that succinct DSPy programs can
express and optimize sophisticated LM pipelines that reason about math word
problems, tackle multi-hop retrieval, answer complex questions, and control
agent loops. Within minutes of compiling, a few lines of DSPy allow GPT-3.5 and
llama2-13b-chat to self-bootstrap pipelines that outperform standard few-shot
prompting (generally by over 25% and 65%, respectively) and pipelines with
expert-created demonstrations (by up to 5-46% and 16-40%, respectively). On top
of that, DSPy programs compiled to open and relatively small LMs like
770M-parameter T5 and llama2-13b-chat are competitive with approaches that rely
on expert-written prompt chains for proprietary GPT-3.5. DSPy is available at
https://github.com/stanfordnlp/dspy
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khattab_O/0/1/0/all/0/1&quot;&gt;Omar Khattab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhvi_A/0/1/0/all/0/1&quot;&gt;Arnav Singhvi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maheshwari_P/0/1/0/all/0/1&quot;&gt;Paridhi Maheshwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santhanam_K/0/1/0/all/0/1&quot;&gt;Keshav Santhanam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vardhamanan_S/0/1/0/all/0/1&quot;&gt;Sri Vardhamanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haq_S/0/1/0/all/0/1&quot;&gt;Saiful Haq&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Ashutosh Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_T/0/1/0/all/0/1&quot;&gt;Thomas T. Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moazam_H/0/1/0/all/0/1&quot;&gt;Hanna Moazam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_H/0/1/0/all/0/1&quot;&gt;Heather Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1&quot;&gt;Matei Zaharia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1&quot;&gt;Christopher Potts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03716">
<title>A Long Way to Go: Investigating Length Correlations in RLHF. (arXiv:2310.03716v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03716</link>
<description rdf:parseType="Literal">&lt;p&gt;Great successes have been reported using Reinforcement Learning from Human
Feedback (RLHF) to align large language models. Open-source preference datasets
and reward models have enabled wider experimentation beyond generic chat
settings, particularly to make systems more &quot;helpful&quot; for tasks like web
question answering, summarization, and multi-turn dialogue. When optimizing for
helpfulness, RLHF has been consistently observed to drive models to produce
longer outputs. This paper demonstrates that optimizing for response length is
a significant factor behind RLHF&apos;s reported improvements in these settings.
First, we study the relationship between reward and length for reward models
trained on three open-source preference datasets for helpfulness. Here, length
correlates strongly with reward, and improvements in reward score are driven in
large part by shifting the distribution over output lengths. We then explore
interventions during both RL and reward model learning to see if we can achieve
the same downstream improvements as RLHF without increasing length. While our
interventions mitigate length increases, they aren&apos;t uniformly effective across
settings. Furthermore, we find that even running RLHF with a reward based
solely on length can reproduce most of the downstream improvements over the
initial policy model, showing that reward models in these settings have a long
way to go.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhal_P/0/1/0/all/0/1&quot;&gt;Prasann Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_T/0/1/0/all/0/1&quot;&gt;Tanya Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiacheng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1&quot;&gt;Greg Durrett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03718">
<title>Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning. (arXiv:2310.03718v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03718</link>
<description rdf:parseType="Literal">&lt;p&gt;Safe reinforcement learning (RL) focuses on training reward-maximizing agents
subject to pre-defined safety constraints. Yet, learning versatile safe
policies that can adapt to varying safety constraint requirements during
deployment without retraining remains a largely unexplored and challenging
area. In this work, we formulate the versatile safe RL problem and consider two
primary requirements: training efficiency and zero-shot adaptation capability.
To address them, we introduce the Conditioned Constrained Policy Optimization
(CCPO) framework, consisting of two key modules: (1) Versatile Value Estimation
(VVE) for approximating value functions under unseen threshold conditions, and
(2) Conditioned Variational Inference (CVI) for encoding arbitrary constraint
thresholds during policy optimization. Our extensive experiments demonstrate
that CCPO outperforms the baselines in terms of safety and task performance
while preserving zero-shot adaptation capabilities to different constraint
thresholds data-efficiently. This makes our approach suitable for real-world
dynamic applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yihang Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zuxin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cen_Z/0/1/0/all/0/1&quot;&gt;Zhepeng Cen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jiacheng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wenhao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tingnan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1&quot;&gt;Ding Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03720">
<title>HeaP: Hierarchical Policies for Web Actions using LLMs. (arXiv:2310.03720v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03720</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have demonstrated remarkable capabilities in
performing a range of instruction following tasks in few and zero-shot
settings. However, teaching LLMs to perform tasks on the web presents
fundamental challenges -- combinatorially large open-world tasks and variations
across web interfaces. We tackle these challenges by leveraging LLMs to
decompose web tasks into a collection of sub-tasks, each of which can be solved
by a low-level, closed-loop policy. These policies constitute a shared grammar
across tasks, i.e., new web tasks can be expressed as a composition of these
policies. We propose a novel framework, Hierarchical Policies for Web Actions
using LLMs (HeaP), that learns a set of hierarchical LLM prompts from
demonstrations for planning high-level tasks and executing them via a sequence
of low-level policies. We evaluate HeaP against a range of baselines on a suite
of web tasks, including MiniWoB++, WebArena, a mock airline CRM, as well as
live website interactions, and show that it is able to outperform prior works
using orders of magnitude less data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sodhi_P/0/1/0/all/0/1&quot;&gt;Paloma Sodhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Branavan_S/0/1/0/all/0/1&quot;&gt;S.R.K. Branavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDonald_R/0/1/0/all/0/1&quot;&gt;Ryan McDonald&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03722">
<title>Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])</title>
<link>http://arxiv.org/abs/2310.03722</link>
<description rdf:parseType="Literal">&lt;p&gt;In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$
of a Gaussian distribution with unknown variance $\sigma$. Curiously, he
employed both an improper (right Haar) mixture over $\sigma$ and an improper
(flat) mixture over $\mu$. Here, we elaborate carefully on the details of his
construction, which use generalized nonintegrable martingales and an extended
Ville&apos;s inequality. While this does yield a sequential t-test, it does not
yield an ``e-process&apos;&apos; (due to the nonintegrability of his martingale). In this
paper, we develop two new e-processes and confidence sequences for the same
setting: one is a test martingale in a reduced filtration, while the other is
an e-process in the canonical data filtration. These are respectively obtained
by swapping Lai&apos;s flat mixture for a Gaussian mixture, and swapping the right
Haar mixture over $\sigma$ with the maximum likelihood estimate under the null,
as done in universal inference. We also analyze the width of resulting
confidence sequences, which have a curious dependence on the error probability
$\alpha$. Numerical experiments are provided along the way to compare and
contrast the various approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongjian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ramdas_A/0/1/0/all/0/1&quot;&gt;Aaditya Ramdas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03725">
<title>Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03725</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative models inspired by dynamical transport of measure -- such as flows
and diffusions -- construct a continuous-time map between two probability
densities. Conventionally, one of these is the target density, only accessible
through samples, while the other is taken as a simple base density that is
data-agnostic. In this work, using the framework of stochastic interpolants, we
formalize how to \textit{couple} the base and the target densities. This
enables us to incorporate information about class labels or continuous
embeddings to construct dynamical transport maps that serve as conditional
generative models. We show that these transport maps can be learned by solving
a simple square loss regression problem analogous to the standard independent
setting. We demonstrate the usefulness of constructing dependent couplings in
practice through experiments in super-resolution and in-painting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albergo_M/0/1/0/all/0/1&quot;&gt;Michael S. Albergo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_M/0/1/0/all/0/1&quot;&gt;Mark Goldstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boffi_N/0/1/0/all/0/1&quot;&gt;Nicholas M. Boffi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1&quot;&gt;Rajesh Ranganath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1&quot;&gt;Eric Vanden-Eijnden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03731">
<title>MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning. (arXiv:2310.03731v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03731</link>
<description rdf:parseType="Literal">&lt;p&gt;The recently released GPT-4 Code Interpreter has demonstrated remarkable
proficiency in solving challenging math problems, primarily attributed to its
ability to seamlessly reason with natural language, generate code, execute
code, and continue reasoning based on the execution output. In this paper, we
present a method to fine-tune open-source language models, enabling them to use
code for modeling and deriving math equations and, consequently, enhancing
their mathematical reasoning abilities. We propose a method of generating novel
and high-quality datasets with math problems and their code-based solutions,
referred to as MathCodeInstruct. Each solution interleaves natural language,
code, and execution results. We also introduce a customized supervised
fine-tuning and inference approach. This approach yields the MathCoder models,
a family of models capable of generating code-based solutions for solving
challenging math problems. Impressively, the MathCoder models achieve
state-of-the-art scores among open-source LLMs on the MATH (45.2%) and GSM8K
(83.9%) datasets, substantially outperforming other open-source alternatives.
Notably, the MathCoder model not only surpasses ChatGPT-3.5 and PaLM-2 on GSM8K
and MATH but also outperforms GPT-4 on the competition-level MATH dataset. The
dataset and models will be released at https://github.com/mathllm/MathCoder.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Ke Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1&quot;&gt;Houxing Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Aojun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zimu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1&quot;&gt;Sichun Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1&quot;&gt;Weikang Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Renrui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Linqi Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_M/0/1/0/all/0/1&quot;&gt;Mingjie Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongsheng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00810">
<title>Deep Learning for Genomics: A Concise Overview. (arXiv:1802.00810v4 [q-bio.GN] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00810</link>
<description rdf:parseType="Literal">&lt;p&gt;Advancements in genomic research such as high-throughput sequencing
techniques have driven modern genomic studies into &quot;big data&quot; disciplines. This
data explosion is constantly challenging conventional methods used in genomics.
In parallel with the urgent demand for robust algorithms, deep learning has
succeeded in a variety of fields such as vision, speech, and text processing.
Yet genomics entails unique challenges to deep learning since we are expecting
from deep learning a superhuman intelligence that explores beyond our knowledge
to interpret the genome. A powerful deep learning model should rely on
insightful utilization of task-specific knowledge. In this paper, we briefly
discuss the strengths of different deep learning models from a genomic
perspective so as to fit each particular task with a proper deep architecture,
and remark on practical considerations of developing modern deep learning
architectures for genomics. We also provide a concise review of deep learning
applications in various aspects of genomic research, as well as pointing out
potential opportunities and obstacles for future genomics applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yue_T/0/1/0/all/0/1&quot;&gt;Tianwei Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuanxin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Longxiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gu_C/0/1/0/all/0/1&quot;&gt;Chunming Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Xue_H/0/1/0/all/0/1&quot;&gt;Haoru Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenping Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lyu_Q/0/1/0/all/0/1&quot;&gt;Qi Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Dun_Y/0/1/0/all/0/1&quot;&gt;Yujie Dun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1912.05957">
<title>Text as Environment: A Deep Reinforcement Learning Text Readability Assessment Model. (arXiv:1912.05957v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1912.05957</link>
<description rdf:parseType="Literal">&lt;p&gt;Evaluating the readability of a text can significantly facilitate the precise
expression of information in written form. The formulation of text readability
assessment involves the identification of meaningful properties of the text
regardless of its length. Sophisticated features and models are used to
evaluate the comprehensibility of texts accurately. Despite this, the problem
of assessing texts&apos; readability efficiently remains relatively untouched. The
efficiency of state-of-the-art text readability assessment models can be
further improved using deep reinforcement learning models. Using a hard
attention-based active inference technique, the proposed approach makes
efficient use of input text and computational resources. Through the use of
semi-supervised signals, the reinforcement learning model uses the minimum
amount of text in order to determine text&apos;s readability. A comparison of the
model on Weebit and Cambridge Exams with state-of-the-art models, such as the
BERT text readability model, shows that it is capable of achieving
state-of-the-art accuracy with a significantly smaller amount of input text
than other models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammadi_H/0/1/0/all/0/1&quot;&gt;Hamid Mohammadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khasteh_S/0/1/0/all/0/1&quot;&gt;Seyed Hossein Khasteh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.11559">
<title>Learning Graph Laplacian with MCP. (arXiv:2010.11559v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2010.11559</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of learning a graph under the Laplacian constraint
with a non-convex penalty: minimax concave penalty (MCP). For solving the MCP
penalized graphical model, we design an inexact proximal difference-of-convex
algorithm (DCA) and prove its convergence to critical points. We note that each
subproblem of the proximal DCA enjoys the nice property that the objective
function in its dual problem is continuously differentiable with a semismooth
gradient. Therefore, we apply an efficient semismooth Newton method to
subproblems of the proximal DCA. Numerical experiments on various synthetic and
real data sets demonstrate the effectiveness of the non-convex penalty MCP in
promoting sparsity. Compared with the existing state-of-the-art method, our
method is demonstrated to be more efficient and reliable for learning graph
Laplacian with MCP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yangjing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toh_K/0/1/0/all/0/1&quot;&gt;Kim-Chuan Toh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1&quot;&gt;Defeng Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2011.15122">
<title>Deep Controlled Learning for Inventory Control. (arXiv:2011.15122v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2011.15122</link>
<description rdf:parseType="Literal">&lt;p&gt;Problem Definition: Are traditional deep reinforcement learning (DRL)
algorithms, developed for a broad range of purposes including game-play and
robotics, the most suitable machine learning algorithms for applications in
inventory control? To what extent would DRL algorithms tailored to the unique
characteristics of inventory control problems provide superior performance
compared to DRL and traditional benchmarks? Methodology/results: We propose and
study Deep Controlled Learning (DCL), a new DRL framework based on approximate
policy iteration specifically designed to tackle inventory problems.
Comparative evaluations reveal that DCL outperforms existing state-of-the-art
heuristics in lost sales inventory control, perishable inventory systems, and
inventory systems with random lead times, achieving lower average costs across
all test instances and maintaining an optimality gap of no more than 0.1\%.
Notably, the same hyperparameter set is utilized across all experiments,
underscoring the robustness and generalizability of the proposed method.
Managerial implications: These substantial performance and robustness
improvements pave the way for the effective application of tailored DRL
algorithms to inventory management problems, empowering decision-makers to
optimize stock levels, minimize costs, and enhance responsiveness across
various industries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Temizoz_T/0/1/0/all/0/1&quot;&gt;Tarkan Temiz&amp;#xf6;z&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Imdahl_C/0/1/0/all/0/1&quot;&gt;Christina Imdahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dijkman_R/0/1/0/all/0/1&quot;&gt;Remco Dijkman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamghari_Idrissi_D/0/1/0/all/0/1&quot;&gt;Douniel Lamghari-Idrissi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaarsveld_W/0/1/0/all/0/1&quot;&gt;Willem van Jaarsveld&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.00696">
<title>Numerical Weather Forecasting using Convolutional-LSTM with Attention and Context Matcher Mechanisms. (arXiv:2102.00696v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2102.00696</link>
<description rdf:parseType="Literal">&lt;p&gt;Numerical weather forecasting using high-resolution physical models often
requires extensive computational resources on supercomputers, which diminishes
their wide usage in most real-life applications. As a remedy, applying deep
learning methods has revealed innovative solutions within this field. To this
end, we introduce a novel deep learning architecture for forecasting
high-resolution spatio-temporal weather data. Our approach extends the
conventional encoder-decoder structure by integrating Convolutional Long-short
Term Memory and Convolutional Neural Networks. In addition, we incorporate
attention and context matcher mechanisms into the model architecture. Our
Weather Model achieves significant performance improvements compared to
baseline deep learning models, including ConvLSTM, TrajGRU, and U-Net. Our
experimental evaluation involves high-scale, real-world benchmark numerical
weather datasets, namely the ERA5 hourly dataset on pressure levels and
WeatherBench. Our results demonstrate substantial improvements in identifying
spatial and temporal correlations with attention matrices focusing on distinct
parts of the input series to model atmospheric circulations. We also compare
our model with high-resolution physical models using the benchmark metrics and
show that our Weather Model is accurate and easy to interpret.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tekin_S/0/1/0/all/0/1&quot;&gt;Selim Furkan Tekin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fazla_A/0/1/0/all/0/1&quot;&gt;Arda Fazla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozat_S/0/1/0/all/0/1&quot;&gt;Suleyman Serdar Kozat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2104.07454">
<title>Memory Capacity of Recurrent Neural Networks with Matrix Representation. (arXiv:2104.07454v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2104.07454</link>
<description rdf:parseType="Literal">&lt;p&gt;It is well known that canonical recurrent neural networks (RNNs) face
limitations in learning long-term dependencies which have been addressed by
memory structures in long short-term memory (LSTM) networks. Neural Turing
machines (NTMs) are novel RNNs that implement the notion of programmable
computers with neural network controllers that can learn simple algorithmic
tasks. Matrix neural networks feature matrix representation which inherently
preserves the spatial structure of data when compared to canonical neural
networks that use vector-based representation. One may then argue that neural
networks with matrix representations may have the potential to provide better
memory capacity. In this paper, we define and study a probabilistic notion of
memory capacity based on Fisher information for matrix-based RNNs. We find
bounds on memory capacity for such networks under various hypotheses and
compare them with their vector counterparts. In particular, we show that the
memory capacity of such networks is bounded by $N^2$ for $N\times N$ state
matrix which generalizes the one known for vector networks. We also show and
analyze the increase in memory capacity for such networks which is introduced
when one exhibits an external state memory, such as NTMs. Consequently, we
construct NTMs with RNN controllers with matrix-based representation of
external memory, leading us to introduce Matrix NTMs. We demonstrate the
performance of this class of memory networks under certain algorithmic learning
tasks such as copying and recall and compare it with Matrix RNNs. We find an
improvement in the performance of Matrix NTMs by the addition of external
memory, in comparison to Matrix RNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renanse_A/0/1/0/all/0/1&quot;&gt;Animesh Renanse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Alok Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1&quot;&gt;Rohitash Chandra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.06178">
<title>Paying Attention to Astronomical Transients: Introducing the Time-series Transformer for Photometric Classification. (arXiv:2105.06178v3 [astro-ph.IM] UPDATED)</title>
<link>http://arxiv.org/abs/2105.06178</link>
<description rdf:parseType="Literal">&lt;p&gt;Future surveys such as the Legacy Survey of Space and Time (LSST) of the Vera
C. Rubin Observatory will observe an order of magnitude more astrophysical
transient events than any previous survey before. With this deluge of
photometric data, it will be impossible for all such events to be classified by
humans alone. Recent efforts have sought to leverage machine learning methods
to tackle the challenge of astronomical transient classification, with ever
improving success. Transformers are a recently developed deep learning
architecture, first proposed for natural language processing, that have shown a
great deal of recent success. In this work we develop a new transformer
architecture, which uses multi-head self attention at its core, for general
multi-variate time-series data. Furthermore, the proposed time-series
transformer architecture supports the inclusion of an arbitrary number of
additional features, while also offering interpretability. We apply the
time-series transformer to the task of photometric classification, minimising
the reliance of expert domain knowledge for feature selection, while achieving
results comparable to state-of-the-art photometric classification methods. We
achieve a logarithmic-loss of 0.507 on imbalanced data in a representative
setting using data from the Photometric LSST Astronomical Time-Series
Classification Challenge (PLAsTiCC). Moreover, we achieve a micro-averaged
receiver operating characteristic area under curve of 0.98 and micro-averaged
precision-recall area under curve of 0.87.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Allam_T/0/1/0/all/0/1&quot;&gt;Tarek Allam Jr.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+McEwen_J/0/1/0/all/0/1&quot;&gt;Jason D. McEwen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.03890">
<title>Model Explanations via the Axiomatic Causal Lens. (arXiv:2109.03890v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2109.03890</link>
<description rdf:parseType="Literal">&lt;p&gt;Explaining the decisions of black-box models is a central theme in the study
of trustworthy ML. Numerous measures have been proposed in the literature;
however, none of them take an axiomatic approach to causal explainability. In
this work, we propose three explanation measures which aggregate the set of all
but-for causes -- a necessary and sufficient explanation -- into feature
importance weights. Our first measure is a natural adaptation of Chockler and
Halpern&apos;s notion of causal responsibility, whereas the other two correspond to
existing game-theoretic influence measures. We present an axiomatic treatment
for our proposed indices, showing that they can be uniquely characterized by a
set of desirable properties. We also extend our approach to derive a new method
to compute the Shapley-Shubik and Banzhaf indices for black-box model
explanations. Finally, we analyze and compare the necessity and sufficiency of
all our proposed explanation measures in practice using the Adult-Income
dataset. Thus, our work is the first to formally bridge the gap between model
explanations, game-theoretic influence, and causal analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biradar_G/0/1/0/all/0/1&quot;&gt;Gagan Biradar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1&quot;&gt;Vignesh Viswanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zick_Y/0/1/0/all/0/1&quot;&gt;Yair Zick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.03991">
<title>Combining Differential Privacy and Byzantine Resilience in Distributed SGD. (arXiv:2110.03991v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.03991</link>
<description rdf:parseType="Literal">&lt;p&gt;Privacy and Byzantine resilience (BR) are two crucial requirements of
modern-day distributed machine learning. The two concepts have been extensively
studied individually but the question of how to combine them effectively
remains unanswered. This paper contributes to addressing this question by
studying the extent to which the distributed SGD algorithm, in the standard
parameter-server architecture, can learn an accurate model despite (a) a
fraction of the workers being malicious (Byzantine), and (b) the other
fraction, whilst being honest, providing noisy information to the server to
ensure differential privacy (DP). We first observe that the integration of
standard practices in DP and BR is not straightforward. In fact, we show that
many existing results on the convergence of distributed SGD under Byzantine
faults, especially those relying on $(\alpha,f)$-Byzantine resilience, are
rendered invalid when honest workers enforce DP. To circumvent this
shortcoming, we revisit the theory of $(\alpha,f)$-BR to obtain an approximate
convergence guarantee. Our analysis provides key insights on how to improve
this guarantee through hyperparameter optimization. Essentially, our
theoretical and empirical results show that (1) an imprudent combination of
standard approaches to DP and BR might be fruitless, but (2) by carefully
re-tuning the learning algorithm, we can obtain reasonable learning accuracy
while simultaneously guaranteeing DP and BR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1&quot;&gt;Nirupam Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinot_R/0/1/0/all/0/1&quot;&gt;Rafael Pinot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rouault_S/0/1/0/all/0/1&quot;&gt;Sebastien Rouault&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stephan_J/0/1/0/all/0/1&quot;&gt;John Stephan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.14883">
<title>Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training. (arXiv:2110.14883v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.14883</link>
<description rdf:parseType="Literal">&lt;p&gt;The success of Transformer models has pushed the deep learning model scale to
billions of parameters. Due to the limited memory resource of a single GPU,
However, the best practice for choosing the optimal parallel strategy is still
lacking, since it requires domain expertise in both deep learning and parallel
computing.
&lt;/p&gt;
&lt;p&gt;The Colossal-AI system addressed the above challenge by introducing a unified
interface to scale your sequential code of model training to distributed
environments. It supports parallel training methods such as data, pipeline,
tensor, and sequence parallelism, as well as heterogeneous training methods
integrated with zero redundancy optimizer. Compared to the baseline system,
Colossal-AI can achieve up to 2.76 times training speedup on large-scale
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shenggui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hongxin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_Z/0/1/0/all/0/1&quot;&gt;Zhengda Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1&quot;&gt;Jiarui Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Haichen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yuliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Boxiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1&quot;&gt;Yang You&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.15497">
<title>Unsupervised Foreground Extraction via Deep Region Competition. (arXiv:2110.15497v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2110.15497</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Deep Region Competition (DRC), an algorithm designed to extract
foreground objects from images in a fully unsupervised manner. Foreground
extraction can be viewed as a special case of generic image segmentation that
focuses on identifying and disentangling objects from the background. In this
work, we rethink the foreground extraction by reconciling energy-based prior
with generative image modeling in the form of Mixture of Experts (MoE), where
we further introduce the learned pixel re-assignment as the essential inductive
bias to capture the regularities of background regions. With this modeling, the
foreground-background partition can be naturally found through
Expectation-Maximization (EM). We show that the proposed method effectively
exploits the interaction between the mixture components during the partitioning
process, which closely connects to region competition, a seminal approach for
generic image segmentation. Experiments demonstrate that DRC exhibits more
competitive performances on complex real-world data and challenging
multi-object scenes compared with prior methods. Moreover, we show empirically
that DRC can potentially generalize to novel foreground objects even from
categories unseen during training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Peiyu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1&quot;&gt;Sirui Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaojian Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yixin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Nian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.02062">
<title>Linking Across Data Granularity: Fitting Multivariate Hawkes Processes to Partially Interval-Censored Data. (arXiv:2111.02062v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.02062</link>
<description rdf:parseType="Literal">&lt;p&gt;The multivariate Hawkes process (MHP) is widely used for analyzing data
streams that interact with each other, where events generate new events within
their own dimension (via self-excitation) or across different dimensions (via
cross-excitation). However, in certain applications, the timestamps of
individual events in some dimensions are unobservable, and only event counts
within intervals are known, referred to as partially interval-censored data.
The MHP is unsuitable for handling such data since its estimation requires
event timestamps. In this study, we introduce the Partial Mean Behavior Poisson
(PMBP) process, a novel point process which shares parameter equivalence with
the MHP and can effectively model both timestamped and interval-censored data.
We demonstrate the capabilities of the PMBP process using synthetic and
real-world datasets. Firstly, we illustrate that the PMBP process can
approximate MHP parameters and recover the spectral radius using synthetic
event histories. Next, we assess the performance of the PMBP process in
predicting YouTube popularity and find that it surpasses state-of-the-art
methods. Lastly, we leverage the PMBP process to gain qualitative insights from
a dataset comprising daily COVID-19 case counts from multiple countries and
COVID-19-related news articles. By clustering the PMBP-modeled countries, we
unveil hidden interaction patterns between occurrences of COVID-19 cases and
news reporting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calderon_P/0/1/0/all/0/1&quot;&gt;Pio Calderon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soen_A/0/1/0/all/0/1&quot;&gt;Alexander Soen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1&quot;&gt;Marian-Andrei Rizoiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.05120">
<title>On Convergence of Federated Averaging Langevin Dynamics. (arXiv:2112.05120v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2112.05120</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty
quantification and mean predictions with distributed clients. In particular, we
generalize beyond normal posterior distributions and consider a general class
of models. We develop theoretical guarantees for FA-LD for strongly log-concave
distributions with non-i.i.d data and study how the injected noise and the
stochastic-gradient noise, the heterogeneity of data, and the varying learning
rates affect the convergence. Such an analysis sheds light on the optimal
choice of local updates to minimize communication costs. Important to our
approach is that the communication efficiency does not deteriorate with the
injected noise in the Langevin algorithms. In addition, we examine in our FA-LD
algorithm both independent and correlated noise used over different clients. We
observe there is a trade-off between the pairs among communication, accuracy,
and data privacy. As local devices may become inactive in federated networks,
we also show convergence results based on different averaging schemes where
only partial device updates are available. In such a case, we discover an
additional bias that does not decay to zero.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deng_W/0/1/0/all/0/1&quot;&gt;Wei Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yi-An Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1&quot;&gt;Guang Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.08417">
<title>Characterization of causal ancestral graphs for time series with latent confounders. (arXiv:2112.08417v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/2112.08417</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a novel class of graphical models for
representing time lag specific causal relationships and independencies of
multivariate time series with unobserved confounders. We completely
characterize these graphs and show that they constitute proper subsets of the
currently employed model classes. As we show, from the novel graphs one can
thus draw stronger causal inferences -- without additional assumptions. We
further introduce a graphical representation of Markov equivalence classes of
the novel graphs. This graphical representation contains more causal knowledge
than what current state-of-the-art causal discovery algorithms learn.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gerhardus_A/0/1/0/all/0/1&quot;&gt;Andreas Gerhardus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.02824">
<title>Optimal 1-Wasserstein Distance for WGANs. (arXiv:2201.02824v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2201.02824</link>
<description rdf:parseType="Literal">&lt;p&gt;The mathematical forces at work behind Generative Adversarial Networks raise
challenging theoretical issues. Motivated by the important question of
characterizing the geometrical properties of the generated distributions, we
provide a thorough analysis of Wasserstein GANs (WGANs) in both the finite
sample and asymptotic regimes. We study the specific case where the latent
space is univariate and derive results valid regardless of the dimension of the
output space. We show in particular that for a fixed sample size, the optimal
WGANs are closely linked with connected paths minimizing the sum of the squared
Euclidean distances between the sample points. We also highlight the fact that
WGANs are able to approach (for the 1-Wasserstein distance) the target
distribution as the sample size tends to infinity, at a given convergence rate
and provided the family of generative Lipschitz functions grows appropriately.
We derive in passing new results on optimal transport theory in the
semi-discrete setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stephanovitch_A/0/1/0/all/0/1&quot;&gt;Arthur St&amp;#xe9;phanovitch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tanielian_U/0/1/0/all/0/1&quot;&gt;Ugo Tanielian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cadre_B/0/1/0/all/0/1&quot;&gt;Beno&amp;#xee;t Cadre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Klutchnikoff_N/0/1/0/all/0/1&quot;&gt;Nicolas Klutchnikoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Biau_G/0/1/0/all/0/1&quot;&gt;G&amp;#xe9;rard Biau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2204.05923">
<title>An Algebraically Converging Stochastic Gradient Descent Algorithm for Global Optimization. (arXiv:2204.05923v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2204.05923</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new gradient descent algorithm with added stochastic terms for
finding the global optimizers of nonconvex optimization problems. A key
component in the algorithm is the adaptive tuning of the randomness based on
the value of the objective function. In the language of simulated annealing,
the temperature is state-dependent. With this, we prove the global convergence
of the algorithm with an algebraic rate both in probability and in the
parameter space. This is a significant improvement over the classical rate from
using a more straightforward control of the noise term. The convergence proof
is based on the actual discrete setup of the algorithm, not just its continuous
limit as often done in the literature. We also present several numerical
examples to demonstrate the efficiency and robustness of the algorithm for
reasonably complex objective functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Engquist_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn Engquist&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ren_K/0/1/0/all/0/1&quot;&gt;Kui Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yunan Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.03519">
<title>Self-supervised Deep Unrolled Reconstruction Using Regularization by Denoising. (arXiv:2205.03519v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2205.03519</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning methods have been successfully used in various computer vision
tasks. Inspired by that success, deep learning has been explored in magnetic
resonance imaging (MRI) reconstruction. In particular, integrating deep
learning and model-based optimization methods has shown considerable
advantages. However, a large amount of labeled training data is typically
needed for high reconstruction quality, which is challenging for some MRI
applications. In this paper, we propose a novel reconstruction method, named
DURED-Net, that enables interpretable self-supervised learning for MR image
reconstruction by combining a self-supervised denoising network and a
plug-and-play method. We aim to boost the reconstruction performance of
Noise2Noise in MR reconstruction by adding an explicit prior that utilizes
imaging physics. Specifically, the leverage of a denoising network for MRI
reconstruction is achieved using Regularization by Denoising (RED). Experiment
results demonstrate that the proposed method requires a reduced amount of
training data to achieve high reconstruction quality among the state-of-art of
MR reconstruction utilizing the Noise2Noise method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_P/0/1/0/all/0/1&quot;&gt;Peizhou Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chaoyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaoliang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaojuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dong_L/0/1/0/all/0/1&quot;&gt;Liang Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ying_L/0/1/0/all/0/1&quot;&gt;Leslie Ying&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.05250">
<title>Spatial-temporal associations representation and application for process monitoring using graph convolution neural network. (arXiv:2205.05250v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.05250</link>
<description rdf:parseType="Literal">&lt;p&gt;Thank you very much for the attention and concern of colleagues and scholars
in this work. With the comments and guidance of experts, editors, and
reviewers, this work has been accepted for publishing in the journal &quot;Process
Safety and Environmental Protection&quot;. The theme of this paper relies on the
Spatial-temporal associations of numerous variables in the same industrial
processes, which refers to numerous variables obtained in dynamic industrial
processes with Spatial-temporal correlation characteristics, i.e., these
variables are not only highly correlated in time but also interrelated in
space. To handle this problem, three key issues need to be well addressed:
variable characteristics modeling and representation, graph network
construction (temporal information), and graph characteristics perception. The
first issue is implemented by assuming the data follows one improved Gaussian
distribution, while the graph network can be defined by the monitoring
variables and their edges which are calculated by their characteristics in
time. Finally, these networks corresponding to process states at different
times are fed into a graph convolutional neural network to implement graph
classification to achieve process monitoring. A benchmark experiment (Tennessee
Eastman chemical process) and one application study (cobalt purification from
zinc solution) are employed to demonstrate the feasibility and applicability of
this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1&quot;&gt;Hao Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1&quot;&gt;Xiaojun Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chunhua Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhiwen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gui_W/0/1/0/all/0/1&quot;&gt;Weihua Gui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.05895">
<title>Latent Diffusion Energy-Based Model for Interpretable Text Modeling. (arXiv:2206.05895v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.05895</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent space Energy-Based Models (EBMs), also known as energy-based priors,
have drawn growing interests in generative modeling. Fueled by its flexibility
in the formulation and strong modeling power of the latent space, recent works
built upon it have made interesting attempts aiming at the interpretability of
text modeling. However, latent space EBMs also inherit some flaws from EBMs in
data space; the degenerate MCMC sampling quality in practice can lead to poor
generation quality and instability in training, especially on data with complex
latent structures. Inspired by the recent efforts that leverage diffusion
recovery likelihood learning as a cure for the sampling issue, we introduce a
novel symbiosis between the diffusion models and latent space EBMs in a
variational learning framework, coined as the latent diffusion energy-based
model. We develop a geometric clustering-based regularization jointly with the
information bottleneck to further improve the quality of the learned latent
space. Experiments on several challenging tasks demonstrate the superior
performance of our model on interpretable text modeling over strong
counterparts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Peiyu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1&quot;&gt;Sirui Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaojian Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_B/0/1/0/all/0/1&quot;&gt;Baoxiong Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1&quot;&gt;Bo Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1&quot;&gt;Ruiqi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yixin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Nian Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.11447">
<title>Handling Data Heterogeneity in Federated Learning via Knowledge Distillation and Fusion. (arXiv:2207.11447v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2207.11447</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) supports distributed training of a global machine
learning model across multiple devices with the help of a central server.
However, data heterogeneity across different devices leads to the client model
drift issue and results in model performance degradation and poor model
fairness. To address the issue, we design Federated learning with global-local
Knowledge Fusion (FedKF) scheme in this paper. The key idea in FedKF is to let
the server return the global knowledge to be fused with the local knowledge in
each training round so that the local model can be regularized towards the
global optima. Therefore, the client model drift issue can be mitigated. In
FedKF, we first propose the active-inactive model aggregation technique that
supports a precise global knowledge representation. Then, we propose a
data-free knowledge distillation (KD) approach to enable each client model to
learn the global knowledge (embedded in the global model) while each client
model can still learn the local knowledge (embedded in the local dataset)
simultaneously, thereby realizing the global-local knowledge fusion process.
The theoretical analysis and intensive experiments demonstrate the superiority
of FedKF over previous solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1&quot;&gt;Xu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1&quot;&gt;Xinyu Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Cong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yichun Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jingwen Shi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.12266">
<title>Decoding speech perception from non-invasive brain recordings. (arXiv:2208.12266v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2208.12266</link>
<description rdf:parseType="Literal">&lt;p&gt;Decoding speech from brain activity is a long-awaited goal in both healthcare
and neuroscience. Invasive devices have recently led to major milestones in
that regard: deep learning algorithms trained on intracranial recordings now
start to decode elementary linguistic features (e.g. letters, words,
spectrograms). However, extending this approach to natural speech and
non-invasive brain recordings remains a major challenge. Here, we introduce a
model trained with contrastive-learning to decode self-supervised
representations of perceived speech from the non-invasive recordings of a large
cohort of healthy individuals. To evaluate this approach, we curate and
integrate four public datasets, encompassing 175 volunteers recorded with
magneto- or electro-encephalography (M/EEG), while they listened to short
stories and isolated sentences. The results show that our model can identify,
from 3 seconds of MEG signals, the corresponding speech segment with up to 41%
accuracy out of more than 1,000 distinct possibilities on average across
participants, and more than 80% in the very best participants - a performance
that allows the decoding of words and phrases absent from the training set. The
comparison of our model to a variety of baselines highlights the importance of
(i) a contrastive objective, (ii) pretrained representations of speech and
(iii) a common convolutional architecture simultaneously trained across
multiple participants. Finally, the analysis of the decoder&apos;s predictions
suggests that they primarily depend on lexical and contextual semantic
representations. Overall, this effective decoding of perceived speech from
non-invasive recordings delineates a promising path to decode language from
brain activity, without putting patients at risk for brain surgery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Defossez_A/0/1/0/all/0/1&quot;&gt;Alexandre D&amp;#xe9;fossez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Caucheteux_C/0/1/0/all/0/1&quot;&gt;Charlotte Caucheteux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rapin_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe9;r&amp;#xe9;my Rapin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kabeli_O/0/1/0/all/0/1&quot;&gt;Ori Kabeli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+King_J/0/1/0/all/0/1&quot;&gt;Jean-R&amp;#xe9;mi King&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.12148">
<title>Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection. (arXiv:2209.12148v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2209.12148</link>
<description rdf:parseType="Literal">&lt;p&gt;Anomaly detection has recently gained increasing attention in the field of
computer vision, likely due to its broad set of applications ranging from
product fault detection on industrial production lines and impending event
detection in video surveillance to finding lesions in medical scans. Regardless
of the domain, anomaly detection is typically framed as a one-class
classification task, where the learning is conducted on normal examples only.
An entire family of successful anomaly detection methods is based on learning
to reconstruct masked normal inputs (e.g. patches, future frames, etc.) and
exerting the magnitude of the reconstruction error as an indicator for the
abnormality level. Unlike other reconstruction-based methods, we present a
novel self-supervised masked convolutional transformer block (SSMCTB) that
comprises the reconstruction-based functionality at a core architectural level.
The proposed self-supervised block is extremely flexible, enabling information
masking at any layer of a neural network and being compatible with a wide range
of neural architectures. In this work, we extend our previous self-supervised
predictive convolutional attentive block (SSPCAB) with a 3D masked
convolutional layer, a transformer for channel-wise attention, as well as a
novel self-supervised objective based on Huber loss. Furthermore, we show that
our block is applicable to a wider variety of tasks, adding anomaly detection
in medical images and thermal videos to the previously considered tasks based
on RGB images and surveillance videos. We exhibit the generality and
flexibility of SSMCTB by integrating it into multiple state-of-the-art neural
models for anomaly detection, bringing forth empirical results that confirm
considerable performance improvements on five benchmarks. We release our code
and data as open source at: https://github.com/ristea/ssmctb.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madan_N/0/1/0/all/0/1&quot;&gt;Neelu Madan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ristea_N/0/1/0/all/0/1&quot;&gt;Nicolae-Catalin Ristea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1&quot;&gt;Radu Tudor Ionescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nasrollahi_K/0/1/0/all/0/1&quot;&gt;Kamal Nasrollahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1&quot;&gt;Fahad Shahbaz Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moeslund_T/0/1/0/all/0/1&quot;&gt;Thomas B. Moeslund&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1&quot;&gt;Mubarak Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.01422">
<title>Time-Varying Propensity Score to Bridge the Gap between the Past and Present. (arXiv:2210.01422v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.01422</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-world deployment of machine learning models is challenging because data
evolves over time. While no model can work when data evolves in an arbitrary
fashion, if there is some pattern to these changes, we might be able to design
methods to address it. This paper addresses situations when data evolves
gradually. We introduce a time-varying propensity score that can detect gradual
shifts in the distribution of data which allows us to selectively sample past
data to update the model -- not just similar data from the past like that of a
standard propensity score but also data that evolved in a similar fashion in
the past. The time-varying propensity score is quite general: we demonstrate
different ways of implementing it and evaluate it on a variety of problems
ranging from supervised learning (e.g., image classification problems) where
data undergoes a sequence of gradual shifts, to reinforcement learning tasks
(e.g., robotic manipulation and continuous control) where data shifts as the
policy or the task changes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fakoor_R/0/1/0/all/0/1&quot;&gt;Rasool Fakoor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mueller_J/0/1/0/all/0/1&quot;&gt;Jonas Mueller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1&quot;&gt;Zachary C. Lipton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1&quot;&gt;Pratik Chaudhari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1&quot;&gt;Alexander J. Smola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.01944">
<title>A Framework for Large Scale Synthetic Graph Dataset Generation. (arXiv:2210.01944v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.01944</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently there has been increasing interest in developing and deploying deep
graph learning algorithms for many tasks, such as fraud detection and
recommender systems. Albeit, there is a limited number of publicly available
graph-structured datasets, most of which are tiny compared to production-sized
applications or are limited in their application domain. This work tackles this
shortcoming by proposing a scalable synthetic graph generation tool to scale
the datasets to production-size graphs with trillions of edges and billions of
nodes. The tool learns a series of parametric models from proprietary datasets
that can be released to researchers to study various graph methods on the
synthetic data increasing prototype development and novel applications. We
demonstrate the generalizability of the framework across a series of datasets,
mimicking structural and feature distributions as well as the ability to scale
them across varying sizes demonstrating their usefulness for benchmarking and
model development. Code can be found on
https://github.com/NVIDIA/DeepLearningExamples/tree/master/Tools/DGLPyTorch/SyntheticGraphGeneration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darabi_S/0/1/0/all/0/1&quot;&gt;Sajad Darabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bigaj_P/0/1/0/all/0/1&quot;&gt;Piotr Bigaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majchrowski_D/0/1/0/all/0/1&quot;&gt;Dawid Majchrowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasymov_A/0/1/0/all/0/1&quot;&gt;Artur Kasymov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morkisz_P/0/1/0/all/0/1&quot;&gt;Pawel Morkisz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fit_Florea_A/0/1/0/all/0/1&quot;&gt;Alex Fit-Florea&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.00635">
<title>Two-stage LLM Fine-tuning with Less Specialization and More Generalization. (arXiv:2211.00635v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2211.00635</link>
<description rdf:parseType="Literal">&lt;p&gt;Pretrained large language models (LLMs) are general purpose problem solvers
applicable to a diverse set of tasks with prompts. They can be further improved
towards a specific task by fine-tuning on a specialized dataset. However,
fine-tuning usually makes the model narrowly specialized on this dataset with
reduced general in-context learning performances, which is undesirable whenever
the fine-tuned model needs to handle additional tasks where no fine-tuning data
is available. In this work, we first demonstrate that fine-tuning on a single
task indeed decreases LLMs&apos; general in-context learning performance. We
discover one important cause of such forgetting, format specialization, where
the model overfits to the format of the fine-tuned task. We further show that
format specialization happens at the very beginning of fine-tuning. To solve
this problem, we propose Prompt Tuning with MOdel Tuning (ProMoT), a simple yet
effective two-stage fine-tuning framework that reduces format specialization
and improves generalization. ProMoT offloads task-specific format learning into
additional and removable parameters by first doing prompt tuning and then
fine-tuning the model itself with this soft prompt attached. With experiments
on several fine-tuning tasks and 8 in-context evaluation tasks, we show that
ProMoT achieves comparable performance on fine-tuned tasks to standard
fine-tuning, but with much less loss of in-context learning performances across
a board range of out-of-domain evaluation tasks. More importantly, ProMoT can
even enhance generalization on in-context learning tasks that are semantically
related to the fine-tuned task, e.g. ProMoT on En-Fr translation significantly
improves performance on other language pairs, and ProMoT on NLI improves
performance on summarization. Experiments also show that ProMoT can improve the
generalization performance of multi-task training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yihan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1&quot;&gt;Si Si&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Daliang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lukasik_M/0/1/0/all/0/1&quot;&gt;Michal Lukasik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Felix Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1&quot;&gt;Inderjit S Dhillon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Sanjiv Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01856">
<title>Conditional Generative Models for Simulation of EMG During Naturalistic Movements. (arXiv:2211.01856v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.01856</link>
<description rdf:parseType="Literal">&lt;p&gt;Numerical models of electromyographic (EMG) signals have provided a huge
contribution to our fundamental understanding of human neurophysiology and
remain a central pillar of motor neuroscience and the development of
human-machine interfaces. However, whilst modern biophysical simulations based
on finite element methods are highly accurate, they are extremely
computationally expensive and thus are generally limited to modelling static
systems such as isometrically contracting limbs. As a solution to this problem,
we propose a transfer learning approach, in which a conditional generative
model is trained to mimic the output of an advanced numerical model. To this
end, we present BioMime, a conditional generative neural network trained
adversarially to generate motor unit activation potential waveforms under a
wide variety of volume conductor parameters. We demonstrate the ability of such
a model to predictively interpolate between a much smaller number of numerical
model&apos;s outputs with a high accuracy. Consequently, the computational load is
dramatically reduced, which allows the rapid simulation of EMG signals during
truly dynamic and naturalistic movements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shihan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clarke_A/0/1/0/all/0/1&quot;&gt;Alexander Kenneth Clarke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maksymenko_K/0/1/0/all/0/1&quot;&gt;Kostiantyn Maksymenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deslauriers_Gauthier_S/0/1/0/all/0/1&quot;&gt;Samuel Deslauriers-Gauthier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1&quot;&gt;Xinjun Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiangyang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farina_D/0/1/0/all/0/1&quot;&gt;Dario Farina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.02648">
<title>Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases. (arXiv:2212.02648v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2212.02648</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a simple but effective method to measure and mitigate model biases
caused by reliance on spurious cues. Instead of requiring costly changes to
one&apos;s data or model training, our method better utilizes the data one already
has by sorting them. Specifically, we rank images within their classes based on
spuriosity (the degree to which common spurious cues are present), proxied via
deep neural features of an interpretable network. With spuriosity rankings, it
is easy to identify minority subpopulations (i.e. low spuriosity images) and
assess model bias as the gap in accuracy between high and low spuriosity
images. One can even efficiently remove a model&apos;s bias at little cost to
accuracy by finetuning its classification head on low spuriosity images,
resulting in fairer treatment of samples regardless of spuriosity. We
demonstrate our method on ImageNet, annotating $5000$ class-feature
dependencies ($630$ of which we find to be spurious) and generating a dataset
of $325k$ soft segmentations for these features along the way. Having computed
spuriosity rankings via the identified spurious neural features, we assess
biases for $89$ diverse models and find that class-wise biases are highly
correlated across models. Our results suggest that model bias due to spurious
feature reliance is influenced far more by what the model is trained on than
how it is trained.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moayeri_M/0/1/0/all/0/1&quot;&gt;Mazda Moayeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenxiao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1&quot;&gt;Sahil Singla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1&quot;&gt;Soheil Feizi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.06074">
<title>Regression with Label Differential Privacy. (arXiv:2212.06074v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.06074</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the task of training regression models with the guarantee of label
differential privacy (DP). Based on a global prior distribution on label
values, which could be obtained privately, we derive a label DP randomization
mechanism that is optimal under a given regression loss function. We prove that
the optimal mechanism takes the form of a &quot;randomized response on bins&quot;, and
propose an efficient algorithm for finding the optimal bin values. We carry out
a thorough experimental evaluation on several datasets demonstrating the
efficacy of our algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1&quot;&gt;Badih Ghazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1&quot;&gt;Pritish Kamath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Ravi Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leeman_E/0/1/0/all/0/1&quot;&gt;Ethan Leeman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1&quot;&gt;Pasin Manurangsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varadarajan_A/0/1/0/all/0/1&quot;&gt;Avinash V Varadarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chiyuan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.06921">
<title>Losses over Labels: Weakly Supervised Learning via Direct Loss Construction. (arXiv:2212.06921v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.06921</link>
<description rdf:parseType="Literal">&lt;p&gt;Owing to the prohibitive costs of generating large amounts of labeled data,
programmatic weak supervision is a growing paradigm within machine learning. In
this setting, users design heuristics that provide noisy labels for subsets of
the data. These weak labels are combined (typically via a graphical model) to
form pseudolabels, which are then used to train a downstream model. In this
work, we question a foundational premise of the typical weakly supervised
learning pipeline: given that the heuristic provides all ``label&quot; information,
why do we need to generate pseudolabels at all? Instead, we propose to directly
transform the heuristics themselves into corresponding loss functions that
penalize differences between our model and the heuristic. By constructing
losses directly from the heuristics, we can incorporate more information than
is used in the standard weakly supervised pipeline, such as how the heuristics
make their decisions, which explicitly informs feature selection during
training. We call our method Losses over Labels (LoL) as it creates losses
directly from heuristics without going through the intermediate step of a
label. We show that LoL improves upon existing weak supervision methods on
several benchmark text and image classification tasks and further demonstrate
that incorporating gradient information leads to better performance on almost
every task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sam_D/0/1/0/all/0/1&quot;&gt;Dylan Sam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J. Zico Kolter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.05603">
<title>A Comprehensive Survey of Dataset Distillation. (arXiv:2301.05603v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.05603</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning technology has developed unprecedentedly in the last decade and
has become the primary choice in many application domains. This progress is
mainly attributed to a systematic collaboration in which rapidly growing
computing resources encourage advanced algorithms to deal with massive data.
However, it has gradually become challenging to handle the unlimited growth of
data with limited computing power. To this end, diverse approaches are proposed
to improve data processing efficiency. Dataset distillation, a dataset
reduction method, addresses this problem by synthesizing a small typical
dataset from substantial data and has attracted much attention from the deep
learning community. Existing dataset distillation methods can be taxonomized
into meta-learning and data matching frameworks according to whether they
explicitly mimic the performance of target data. Although dataset distillation
has shown surprising performance in compressing datasets, there are still
several limitations such as distilling high-resolution data or data with
complex label spaces. This paper provides a holistic understanding of dataset
distillation from multiple aspects, including distillation frameworks and
algorithms, factorized dataset distillation, performance comparison, and
applications. Finally, we discuss challenges and promising directions to
further promote future studies on dataset distillation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1&quot;&gt;Shiye Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.09350">
<title>Large-scale investigation of weakly-supervised deep learning for the fine-grained semantic indexing of biomedical literature. (arXiv:2301.09350v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2301.09350</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: Semantic indexing of biomedical literature is usually done at the
level of MeSH descriptors with several related but distinct biomedical concepts
often grouped together and treated as a single topic. This study proposes a new
method for the automated refinement of subject annotations at the level of MeSH
concepts. Methods: Lacking labelled data, we rely on weak supervision based on
concept occurrence in the abstract of an article, which is also enhanced by
dictionary-based heuristics. In addition, we investigate deep learning
approaches, making design choices to tackle the particular challenges of this
task. The new method is evaluated on a large-scale retrospective scenario,
based on concepts that have been promoted to descriptors. Results: In our
experiments concept occurrence was the strongest heuristic achieving a macro-F1
score of about 0.63 across several labels. The proposed method improved it
further by more than 4pp. Conclusion: The results suggest that concept
occurrence is a strong heuristic for refining the coarse-grained labels at the
level of MeSH concepts and the proposed method improves it further.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nentidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Nentidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzopoulos_T/0/1/0/all/0/1&quot;&gt;Thomas Chatzopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krithara_A/0/1/0/all/0/1&quot;&gt;Anastasia Krithara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1&quot;&gt;Grigorios Tsoumakas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paliouras_G/0/1/0/all/0/1&quot;&gt;Georgios Paliouras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.00942">
<title>Efficient Graph Field Integrators Meet Point Clouds. (arXiv:2302.00942v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.00942</link>
<description rdf:parseType="Literal">&lt;p&gt;We present two new classes of algorithms for efficient field integration on
graphs encoding point clouds. The first class, SeparatorFactorization(SF),
leverages the bounded genus of point cloud mesh graphs, while the second class,
RFDiffusion(RFD), uses popular epsilon-nearest-neighbor graph representations
for point clouds. Both can be viewed as providing the functionality of Fast
Multipole Methods (FMMs), which have had a tremendous impact on efficient
integration, but for non-Euclidean spaces. We focus on geometries induced by
distributions of walk lengths between points (e.g., shortest-path distance). We
provide an extensive theoretical analysis of our algorithms, obtaining new
results in structural graph theory as a byproduct. We also perform exhaustive
empirical evaluation, including on-surface interpolation for rigid and
deformable objects (particularly for mesh-dynamics modeling), Wasserstein
distance computations for point clouds, and the Gromov-Wasserstein variant.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1&quot;&gt;Krzysztof Choromanski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sehanobish_A/0/1/0/all/0/1&quot;&gt;Arijit Sehanobish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Han Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yunfan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berger_E/0/1/0/all/0/1&quot;&gt;Eli Berger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parshakova_T/0/1/0/all/0/1&quot;&gt;Tetiana Parshakova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_A/0/1/0/all/0/1&quot;&gt;Alvin Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watkins_D/0/1/0/all/0/1&quot;&gt;David Watkins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1&quot;&gt;Valerii Likhosherstov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1&quot;&gt;Somnath Basu Roy Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1&quot;&gt;Avinava Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1&quot;&gt;Deepali Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1&quot;&gt;Tamas Sarlos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaturvedi_S/0/1/0/all/0/1&quot;&gt;Snigdha Chaturvedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1&quot;&gt;Adrian Weller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.02787">
<title>Generative models for two-ground-truth partitions in networks. (arXiv:2302.02787v3 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2302.02787</link>
<description rdf:parseType="Literal">&lt;p&gt;A myriad of approaches have been proposed to characterise the mesoscale
structure of networks - most often as a partition based on patterns variously
called communities, blocks, or clusters. Clearly, distinct methods designed to
detect different types of patterns may provide a variety of answers to the
network&apos;s mesoscale structure. Yet, even multiple runs of a given method can
sometimes yield diverse and conflicting results, producing entire landscapes of
partitions which potentially include multiple (locally optimal) mesoscale
explanations of the network. Such ambiguity motivates a closer look at the
ability of these methods to find multiple qualitatively different &apos;ground
truth&apos; partitions in a network. Here, we propose the stochastic cross-block
model (SCBM), a generative model which allows for two distinct partitions to be
built into the mesoscale structure of a single benchmark network. We
demonstrate a use case of the benchmark model by appraising the power of
stochastic block models (SBMs) to detect implicitly planted coexisting
bi-community and core-periphery structures of different strengths. Given our
model design and experimental set-up, we find that the ability to detect the
two partitions individually varies by SBM variant and that coexistence of both
partitions is recovered only in a very limited number of cases. Our findings
suggest that in most instances only one - in some way dominating - structure
can be detected, even in the presence of other partitions. They underline the
need for considering entire landscapes of partitions when different competing
explanations exist and motivate future research to advance partition
coexistence detection methods. Our model also contributes to the field of
benchmark networks more generally by enabling further exploration of the
ability of new and existing methods to detect ambiguity in the mesoscale
structure of networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mangold_L/0/1/0/all/0/1&quot;&gt;Lena Mangold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_C/0/1/0/all/0/1&quot;&gt;Camille Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.02936">
<title>Private GANs, Revisited. (arXiv:2302.02936v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.02936</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that the canonical approach for training differentially private GANs
-- updating the discriminator with differentially private stochastic gradient
descent (DPSGD) -- can yield significantly improved results after modifications
to training. Specifically, we propose that existing instantiations of this
approach neglect to consider how adding noise only to discriminator updates
inhibits discriminator training, disrupting the balance between the generator
and discriminator necessary for successful GAN training. We show that a simple
fix -- taking more discriminator steps between generator steps -- restores
parity between the generator and discriminator and improves results.
&lt;/p&gt;
&lt;p&gt;Additionally, with the goal of restoring parity, we experiment with other
modifications -- namely, large batch sizes and adaptive discriminator update
frequency -- to improve discriminator training and see further improvements in
generation quality. Our results demonstrate that on standard image synthesis
benchmarks, DPSGD outperforms all alternative GAN privatization schemes. Code:
https://github.com/alexbie98/dpgan-revisit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bie_A/0/1/0/all/0/1&quot;&gt;Alex Bie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1&quot;&gt;Gautam Kamath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Guojun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.04054">
<title>Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.04054</link>
<description rdf:parseType="Literal">&lt;p&gt;Reliability of machine learning evaluation -- the consistency of observed
evaluation scores across replicated model training runs -- is affected by
several sources of nondeterminism which can be regarded as measurement noise.
Current tendencies to remove noise in order to enforce reproducibility of
research results neglect inherent nondeterminism at the implementation level
and disregard crucial interaction effects between algorithmic noise factors and
data properties. This limits the scope of conclusions that can be drawn from
such experiments. Instead of removing noise, we propose to incorporate several
sources of variance, including their interaction with data properties, into an
analysis of significance and reliability of machine learning evaluation, with
the aim to draw inferences beyond particular instances of trained models. We
show how to use linear mixed effects models (LMEMs) to analyze performance
evaluation scores, and to conduct statistical inference with a generalized
likelihood ratio test (GLRT). This allows us to incorporate arbitrary sources
of noise like meta-parameter variations into statistical significance testing,
and to assess performance differences conditional on data properties.
Furthermore, a variance component analysis (VCA) enables the analysis of the
contribution of noise sources to overall variance and the computation of a
reliability coefficient by the ratio of substantial to total variance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hagmann_M/0/1/0/all/0/1&quot;&gt;Michael Hagmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meier_P/0/1/0/all/0/1&quot;&gt;Philipp Meier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1&quot;&gt;Stefan Riezler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.01751">
<title>Deep Momentum Multi-Marginal Schr\&quot;odinger Bridge. (arXiv:2303.01751v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2303.01751</link>
<description rdf:parseType="Literal">&lt;p&gt;It is a crucial challenge to reconstruct population dynamics using unlabeled
samples from distributions at coarse time intervals. Recent approaches such as
flow-based models or Schr\&quot;odinger Bridge (SB) models have demonstrated
appealing performance, yet the inferred sample trajectories either fail to
account for the underlying stochasticity or are $\underline{D}$eep
$\underline{M}$omentum Multi-Marginal $\underline{S}$chr\&quot;odinger
$\underline{B}$ridge(DMSB), a novel computational framework that learns the
smooth measure-valued spline for stochastic systems that satisfy position
marginal constraints across time. By tailoring the celebrated Bregman Iteration
and extending the Iteration Proportional Fitting to phase space, we manage to
handle high-dimensional multi-marginal trajectory inference tasks efficiently.
Our algorithm outperforms baselines significantly, as evidenced by experiments
for synthetic datasets and a real-world single-cell RNA sequence dataset.
Additionally, the proposed approach can reasonably reconstruct the evolution of
velocity distribution, from position snapshots only, when there is a ground
truth velocity that is nevertheless inaccessible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianrong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guan-Horng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tao_M/0/1/0/all/0/1&quot;&gt;Molei Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Theodorou_E/0/1/0/all/0/1&quot;&gt;Evangelos A. Theodorou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.09874">
<title>Disentangling the Link Between Image Statistics and Human Perception. (arXiv:2303.09874v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.09874</link>
<description rdf:parseType="Literal">&lt;p&gt;In the 1950s, Barlow and Attneave hypothesised a link between biological
vision and information maximisation. Following Shannon, information was defined
using the probability of natural images. A number of physiological and
psychophysical phenomena have been derived ever since from principles like
info-max, efficient coding, or optimal denoising. However, it remains unclear
how this link is expressed in mathematical terms from image probability. First,
classical derivations were subjected to strong assumptions on the probability
models and on the behaviour of the sensors. Moreover, the direct evaluation of
the hypothesis was limited by the inability of the classical image models to
deliver accurate estimates of the probability. In this work we directly
evaluate image probabilities using an advanced generative model for natural
images, and we analyse how probability-related factors can be combined to
predict human perception via sensitivity of state-of-the-art subjective image
quality metrics. We use information theory and regression analysis to find a
combination of just two probability-related factors that achieves 0.8
correlation with subjective metrics. This probability-based sensitivity is
psychophysically validated by reproducing the basic trends of the Contrast
Sensitivity Function, its suprathreshold variation, and trends of the Weber-law
and masking.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hepburn_A/0/1/0/all/0/1&quot;&gt;Alexander Hepburn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laparra_V/0/1/0/all/0/1&quot;&gt;Valero Laparra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1&quot;&gt;Ra&amp;#xfa;l Santos-Rodriguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malo_J/0/1/0/all/0/1&quot;&gt;Jes&amp;#xfa;s Malo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.10650">
<title>Logic of Differentiable Logics: Towards a Uniform Semantics of DL. (arXiv:2303.10650v4 [cs.LO] UPDATED)</title>
<link>http://arxiv.org/abs/2303.10650</link>
<description rdf:parseType="Literal">&lt;p&gt;Differentiable logics (DL) have recently been proposed as a method of
training neural networks to satisfy logical specifications. A DL consists of a
syntax in which specifications are stated and an interpretation function that
translates expressions in the syntax into loss functions. These loss functions
can then be used during training with standard gradient descent algorithms. The
variety of existing DLs and the differing levels of formality with which they
are treated makes a systematic comparative study of their properties and
implementations difficult. This paper remedies this problem by suggesting a
meta-language for defining DLs that we call the Logic of Differentiable Logics,
or LDL. Syntactically, it generalises the syntax of existing DLs to FOL, and
for the first time introduces the formalism for reasoning about vectors and
learners. Semantically, it introduces a general interpretation function that
can be instantiated to define loss functions arising from different existing
DLs. We use LDL to establish several theoretical properties of existing DLs,
and to conduct their empirical study in neural network verification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slusarz_N/0/1/0/all/0/1&quot;&gt;Natalia &amp;#x15a;lusarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komendantskaya_E/0/1/0/all/0/1&quot;&gt;Ekaterina Komendantskaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daggitt_M/0/1/0/all/0/1&quot;&gt;Matthew L. Daggitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stewart_R/0/1/0/all/0/1&quot;&gt;Robert Stewart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stark_K/0/1/0/all/0/1&quot;&gt;Kathrin Stark&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.14655">
<title>GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for Real-time Soccer Commentary Generation. (arXiv:2303.14655v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.14655</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the recent emergence of video captioning models, how to generate
vivid, fine-grained video descriptions based on the background knowledge (i.e.,
long and informative commentary about the domain-specific scenes with
appropriate reasoning) is still far from being solved, which however has great
applications such as automatic sports narrative. In this paper, we present
GOAL, a benchmark of over 8.9k soccer video clips, 22k sentences, and 42k
knowledge triples for proposing a challenging new task setting as
Knowledge-grounded Video Captioning (KGVC). Moreover, we conduct experimental
adaption of existing methods to show the difficulty and potential directions
for solving this valuable and applicable task. Our data and code are available
at https://github.com/THU-KEG/goal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1&quot;&gt;Ji Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jifan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_T/0/1/0/all/0/1&quot;&gt;Teng Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1&quot;&gt;Kunyu Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yifan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1&quot;&gt;Xinyu Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaozhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yuxiao Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1&quot;&gt;Bin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1&quot;&gt;Lei Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Juanzi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1&quot;&gt;Weidong Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yu Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.16887">
<title>Towards Understanding the Effect of Pretraining Label Granularity. (arXiv:2303.16887v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.16887</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study how the granularity of pretraining labels affects the
generalization of deep neural networks in image classification tasks. We focus
on the &quot;fine-to-coarse&quot; transfer learning setting, where the pretraining label
space is more fine-grained than that of the target problem. Empirically, we
show that pretraining on the leaf labels of ImageNet21k produces better
transfer results on ImageNet1k than pretraining on other coarser granularity
levels, which supports the common practice used in the community.
Theoretically, we explain the benefit of fine-grained pretraining by proving
that, for a data distribution satisfying certain hierarchy conditions, 1)
coarse-grained pretraining only allows a neural network to learn the &quot;common&quot;
or &quot;easy-to-learn&quot; features well, while 2) fine-grained pretraining helps the
network learn the &quot;rarer&quot; or &quot;fine-grained&quot; features in addition to the common
ones, thus improving its accuracy on hard downstream test samples in which
common features are missing or weak in strength. Furthermore, we perform
comprehensive experiments using the label hierarchies of iNaturalist 2021 and
observe that the following conditions, in addition to proper choice of label
granularity, enable the transfer to work well in practice: 1) the pretraining
dataset needs to have a meaningful label hierarchy, and 2) the pretraining and
target label functions need to align well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_G/0/1/0/all/0/1&quot;&gt;Guan Zhe Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1&quot;&gt;Yin Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuxman_A/0/1/0/all/0/1&quot;&gt;Ariel Fuxman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_S/0/1/0/all/0/1&quot;&gt;Stanley H. Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_E/0/1/0/all/0/1&quot;&gt;Enming Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.00195">
<title>Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers. (arXiv:2304.00195v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2304.00195</link>
<description rdf:parseType="Literal">&lt;p&gt;An extension of Transformers is proposed that enables explicit relational
reasoning through a novel module called the Abstractor. At the core of the
Abstractor is a variant of attention called relational cross-attention. The
approach is motivated by an architectural inductive bias for relational
learning that disentangles relational information from extraneous features
about individual objects. This enables explicit relational reasoning,
supporting abstraction and generalization from limited data. The Abstractor is
first evaluated on simple discriminative relational tasks and compared to
existing relational architectures. Next, the Abstractor is evaluated on purely
relational sequence-to-sequence tasks, where dramatic improvements are seen in
sample efficiency compared to standard Transformers. Finally, Abstractors are
evaluated on a collection of tasks based on mathematical problem solving, where
modest but consistent improvements in performance and sample efficiency are
observed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Altabaa_A/0/1/0/all/0/1&quot;&gt;Awni Altabaa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Webb_T/0/1/0/all/0/1&quot;&gt;Taylor Webb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cohen_J/0/1/0/all/0/1&quot;&gt;Jonathan Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lafferty_J/0/1/0/all/0/1&quot;&gt;John Lafferty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.01150">
<title>Algebraic and Geometric Models for Space Networking. (arXiv:2304.01150v2 [math.AT] UPDATED)</title>
<link>http://arxiv.org/abs/2304.01150</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we introduce some new algebraic and geometric perspectives on
networked space communications. Our main contribution is a novel definition of
a time-varying graph (TVG), defined in terms of a matrix with values in subsets
of the real line P(R). We leverage semi-ring properties of P(R) to model
multi-hop communication in a TVG using matrix multiplication and a truncated
Kleene star. This leads to novel statistics on the communication capacity of
TVGs called lifetime curves, which we generate for large samples of randomly
chosen STARLINK satellites, whose connectivity is modeled over day-long
simulations. Determining when a large subsample of STARLINK is temporally
strongly connected is further analyzed using novel metrics introduced here that
are inspired by topological data analysis (TDA). To better model networking
scenarios between the Earth and Mars, we introduce various semi-rings capable
of modeling propagation delay as well as protocols common to Delay Tolerant
Networking (DTN), such as store-and-forward. Finally, we illustrate the
applicability of zigzag persistence for featurizing different space networks
and demonstrate the efficacy of K-Nearest Neighbors (KNN) classification for
distinguishing Earth-Mars and Earth-Moon satellite systems using time-varying
topology alone.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bernardoni_W/0/1/0/all/0/1&quot;&gt;William Bernardoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cardona_R/0/1/0/all/0/1&quot;&gt;Robert Cardona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cleveland_J/0/1/0/all/0/1&quot;&gt;Jacob Cleveland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Curry_J/0/1/0/all/0/1&quot;&gt;Justin Curry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Green_R/0/1/0/all/0/1&quot;&gt;Robert Green&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Heller_B/0/1/0/all/0/1&quot;&gt;Brian Heller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hylton_A/0/1/0/all/0/1&quot;&gt;Alan Hylton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lam_T/0/1/0/all/0/1&quot;&gt;Tung Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kassouf_Short_R/0/1/0/all/0/1&quot;&gt;Robert Kassouf-Short&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.06715">
<title>Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance. (arXiv:2304.06715v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.06715</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretability methods are valuable only if their explanations faithfully
describe the explained model. In this work, we consider neural networks whose
predictions are invariant under a specific symmetry group. This includes
popular architectures, ranging from convolutional to graph neural networks. Any
explanation that faithfully explains this type of model needs to be in
agreement with this invariance property. We formalize this intuition through
the notion of explanation invariance and equivariance by leveraging the
formalism from geometric deep learning. Through this rigorous formalism, we
derive (1) two metrics to measure the robustness of any interpretability method
with respect to the model symmetry group; (2) theoretical robustness guarantees
for some popular interpretability methods and (3) a systematic approach to
increase the invariance of any interpretability method with respect to a
symmetry group. By empirically measuring our metrics for explanations of models
associated with various modalities and symmetry groups, we derive a set of 5
guidelines to allow users and developers of interpretability methods to produce
robust explanations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crabbe_J/0/1/0/all/0/1&quot;&gt;Jonathan Crabb&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela van der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.08979">
<title>In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT. (arXiv:2304.08979v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2304.08979</link>
<description rdf:parseType="Literal">&lt;p&gt;The way users acquire information is undergoing a paradigm shift with the
advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves
knowledge from the model itself and generates answers for users. ChatGPT&apos;s
impressive question-answering (QA) capability has attracted more than 100
million users within a short period of time but has also raised concerns
regarding its reliability. In this paper, we perform the first large-scale
measurement of ChatGPT&apos;s reliability in the generic QA scenario with a
carefully curated set of 5,695 questions across ten datasets and eight domains.
We find that ChatGPT&apos;s reliability varies across different domains, especially
underperforming in law and science questions. We also demonstrate that system
roles, originally designed by OpenAI to allow users to steer ChatGPT&apos;s
behavior, can impact ChatGPT&apos;s reliability in an imperceptible way. We further
show that ChatGPT is vulnerable to adversarial examples, and even a single
character change can negatively affect its reliability in certain cases. We
believe that our study provides valuable insights into ChatGPT&apos;s reliability
and underscores the need for strengthening the reliability and security of
large language models (LLMs).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1&quot;&gt;Xinyue Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1&quot;&gt;Michael Backes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.11004">
<title>Knowledge Distillation Under Ideal Joint Classifier Assumption. (arXiv:2304.11004v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.11004</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge distillation constitutes a potent methodology for condensing
substantial neural networks into more compact and efficient counterparts.
Within this context, softmax regression representation learning serves as a
widely embraced approach, leveraging a pre-established teacher network to guide
the learning process of a diminutive student network. Notably, despite the
extensive inquiry into the efficacy of softmax regression representation
learning, the intricate underpinnings governing the knowledge transfer
mechanism remain inadequately elucidated. This study introduces the &apos;Ideal
Joint Classifier Knowledge Distillation&apos; (IJCKD) framework, an overarching
paradigm that not only furnishes a lucid and exhaustive comprehension of
prevailing knowledge distillation techniques but also establishes a theoretical
underpinning for prospective investigations. Employing mathematical
methodologies derived from domain adaptation theory, this investigation
conducts a comprehensive examination of the error boundary of the student
network contingent upon the teacher network. Consequently, our framework
facilitates efficient knowledge transference between teacher and student
networks, thereby accommodating a diverse spectrum of applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Huayu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiwen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ditzler_G/0/1/0/all/0/1&quot;&gt;Gregory Ditzler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roveda_J/0/1/0/all/0/1&quot;&gt;Janet Roveda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Ao Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.14420">
<title>Network Cascade Vulnerability using Constrained Bayesian Optimization. (arXiv:2304.14420v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2304.14420</link>
<description rdf:parseType="Literal">&lt;p&gt;Measures of power grid vulnerability are often assessed by the amount of
damage an adversary can exact on the network. However, the cascading impact of
such attacks is often overlooked, even though cascades are one of the primary
causes of large-scale blackouts. This paper explores modifications of
transmission line protection settings as candidates for adversarial attacks,
which can remain undetectable as long as the network equilibrium state remains
unaltered. This forms the basis of a black-box function in a Bayesian
optimization procedure, where the objective is to find protection settings that
maximize network degradation due to cascading. Notably, our proposed method is
agnostic to the choice of the cascade simulator and its underlying assumptions.
Numerical experiments reveal that, against conventional wisdom, maximally
misconfiguring the protection settings of all network lines does not cause the
most cascading. More surprisingly, even when the degree of misconfiguration is
limited due to resource constraints, it is still possible to find settings that
produce cascades comparable in severity to instances where there are no
resource constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1&quot;&gt;Albert Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anitescu_M/0/1/0/all/0/1&quot;&gt;Mihai Anitescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramanyam_A/0/1/0/all/0/1&quot;&gt;Anirudh Subramanyam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12081">
<title>MediTab: Scaling Medical Tabular Data Predictors via Data Consolidation, Enrichment, and Refinement. (arXiv:2305.12081v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12081</link>
<description rdf:parseType="Literal">&lt;p&gt;Tabular data prediction has been employed in medical applications such as
patient health risk prediction. However, existing methods usually revolve
around the algorithm design while overlooking the significance of data
engineering. Medical tabular datasets frequently exhibit significant
heterogeneity across different sources, with limited sample sizes per source.
As such, previous predictors are often trained on manually curated small
datasets that struggle to generalize across different tabular datasets during
inference. This paper proposes to scale medical tabular data predictors
(MediTab) to various tabular inputs with varying features. The method uses a
data engine that leverages large language models (LLMs) to consolidate tabular
samples to overcome the barrier across tables with distinct schema. It also
aligns out-domain data with the target task using a &quot;learn, annotate, and
refinement&quot; pipeline. The expanded training data then enables the pre-trained
MediTab to infer for arbitrary tabular input in the domain without fine-tuning,
resulting in significant improvements over supervised baselines: it reaches an
average ranking of 1.57 and 1.00 on 7 patient outcome prediction datasets and 3
trial outcome prediction datasets, respectively. In addition, MediTab exhibits
impressive zero-shot performances: it outperforms supervised XGBoost models by
8.9% and 17.2% on average in two prediction tasks, respectively. The code is
available at https://github.com/RyanWangZf/MediTab.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zifeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1&quot;&gt;Chufan Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1&quot;&gt;Cao Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12766">
<title>Explaining Emergent In-Context Learning as Kernel Regression. (arXiv:2305.12766v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12766</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have initiated a paradigm shift in transfer
learning. In contrast to the classic pretraining-then-finetuning procedure, in
order to use LLMs for downstream prediction tasks, one only needs to provide a
few demonstrations, known as in-context examples, without adding more or
updating existing model parameters. This in-context learning (ICL) capability
of LLMs is intriguing, and it is not yet fully understood how pretrained LLMs
acquire such capabilities. In this paper, we investigate the reason why a
transformer-based language model can accomplish in-context learning after
pre-training on a general language corpus by proposing one hypothesis that LLMs
can simulate kernel regression with internal representations when faced with
in-context examples. More concretely, we first prove that Bayesian inference on
in-context prompts can be asymptotically understood as kernel regression $\hat
y = \sum_i y_i K(x, x_i)/\sum_i K(x, x_i)$ as the number of in-context
demonstrations grows. Then, we empirically investigate the in-context behaviors
of language models. We find that during ICL, the attention and hidden features
in LLMs match the behaviors of a kernel regression. Finally, our theory
provides insights into multiple phenomena observed in the ICL field: why
retrieving demonstrative samples similar to test samples can help, why ICL
performance is sensitive to the output formats, and why ICL accuracy benefits
from selecting in-distribution and representative samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1&quot;&gt;Chi Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Han Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1&quot;&gt;Heng Ji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13673">
<title>Physics of Language Models: Part 1, Context-Free Grammar. (arXiv:2305.13673v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13673</link>
<description rdf:parseType="Literal">&lt;p&gt;We design controlled experiments to study HOW generative language models,
like GPT, learn context-free grammars (CFGs) -- diverse language systems with a
tree-like structure capturing many aspects of natural languages, programs, and
logics. CFGs are as hard as pushdown automata, and can be ambiguous so that
verifying if a string satisfies the rules requires dynamic programming. We
construct synthetic data and demonstrate that even for difficult (long and
ambiguous) CFGs, pre-trained transformers can learn to generate sentences with
near-perfect accuracy and impressive diversity.
&lt;/p&gt;
&lt;p&gt;More importantly, we delve into the physical principles behind how
transformers learns CFGs. We discover that the hidden states within the
transformer implicitly and precisely encode the CFG structure (such as putting
tree node information exactly on the subtree boundary), and learn to form
&quot;boundary to boundary&quot; attentions resembling dynamic programming. We also cover
some extension of CFGs as well as the robustness aspect of transformers against
grammar mistakes. Overall, our research provides a comprehensive and empirical
understanding of how transformers learn CFGs, and reveals the physical
mechanisms utilized by transformers to capture the structure and rules of
languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Allen-Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanzhi Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15086">
<title>Unpaired Image-to-Image Translation via Neural Schr\&quot;odinger Bridge. (arXiv:2305.15086v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15086</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models are a powerful class of generative models which simulate
stochastic differential equations (SDEs) to generate data from noise. Although
diffusion models have achieved remarkable progress in recent years, they have
limitations in the unpaired image-to-image translation tasks due to the
Gaussian prior assumption. Schr\&quot;odinger Bridge (SB), which learns an SDE to
translate between two arbitrary distributions, have risen as an attractive
solution to this problem. However, none of SB models so far have been
successful at unpaired translation between high-resolution images. In this
work, we propose the Unpaired Neural Schr\&quot;odinger Bridge (UNSB), which
expresses SB problem as a sequence of adversarial learning problems. This
allows us to incorporate advanced discriminators and regularization to learn a
SB between unpaired data. We demonstrate that UNSB is scalable and successfully
solves various unpaired image-to-image translation tasks. Code:
\url{https://github.com/cyclomon/UNSB}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Beomsu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwon_G/0/1/0/all/0/1&quot;&gt;Gihyun Kwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kwanyoung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15357">
<title>Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution. (arXiv:2305.15357v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15357</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models, as a kind of powerful generative model, have given
impressive results on image super-resolution (SR) tasks. However, due to the
randomness introduced in the reverse process of diffusion models, the
performances of diffusion-based SR models are fluctuating at every time of
sampling, especially for samplers with few resampled steps. This inherent
randomness of diffusion models results in ineffectiveness and instability,
making it challenging for users to guarantee the quality of SR results.
However, our work takes this randomness as an opportunity: fully analyzing and
leveraging it leads to the construction of an effective plug-and-play sampling
method that owns the potential to benefit a series of diffusion-based SR
methods. More in detail, we propose to steadily sample high-quality SR images
from pre-trained diffusion-based SR models by solving diffusion ordinary
differential equations (diffusion ODEs) with optimal boundary conditions (BCs)
and analyze the characteristics between the choices of BCs and their
corresponding SR results. Our analysis shows the route to obtain an
approximately optimal BC via an efficient exploration in the whole space. The
quality of SR results sampled by the proposed method with fewer steps
outperforms the quality of results sampled by current methods with randomness
from the same pre-trained diffusion-based SR model, which means that our
sampling method &quot;boosts&quot; current diffusion-based SR models without any
additional training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yiyang Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Huan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_W/0/1/0/all/0/1&quot;&gt;Wenhan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jianlong Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiaying Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15871">
<title>Learning Robust Statistics for Simulation-based Inference under Model Misspecification. (arXiv:2305.15871v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15871</link>
<description rdf:parseType="Literal">&lt;p&gt;Simulation-based inference (SBI) methods such as approximate Bayesian
computation (ABC), synthetic likelihood, and neural posterior estimation (NPE)
rely on simulating statistics to infer parameters of intractable likelihood
models. However, such methods are known to yield untrustworthy and misleading
inference outcomes under model misspecification, thus hindering their
widespread applicability. In this work, we propose the first general approach
to handle model misspecification that works across different classes of SBI
methods. Leveraging the fact that the choice of statistics determines the
degree of misspecification in SBI, we introduce a regularized loss function
that penalises those statistics that increase the mismatch between the data and
the model. Taking NPE and ABC as use cases, we demonstrate the superior
performance of our method on high-dimensional time-series models that are
artificially misspecified. We also apply our method to real data from the field
of radio propagation where the model is known to be misspecified. We show
empirically that the method yields robust inference in misspecified scenarios,
whilst still being accurate when the model is well-specified.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;Daolang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bharti_A/0/1/0/all/0/1&quot;&gt;Ayush Bharti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Souza_A/0/1/0/all/0/1&quot;&gt;Amauri Souza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Acerbi_L/0/1/0/all/0/1&quot;&gt;Luigi Acerbi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1&quot;&gt;Samuel Kaski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.16102">
<title>Demystifying Oversmoothing in Attention-Based Graph Neural Networks. (arXiv:2305.16102v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.16102</link>
<description rdf:parseType="Literal">&lt;p&gt;Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where
increasing network depth leads to homogeneous node representations. While
previous work has established that Graph Convolutional Networks (GCNs)
exponentially lose expressive power, it remains controversial whether the graph
attention mechanism can mitigate oversmoothing. In this work, we provide a
definitive answer to this question through a rigorous mathematical analysis, by
viewing attention-based GNNs as nonlinear time-varying dynamical systems and
incorporating tools and techniques from the theory of products of inhomogeneous
matrices and the joint spectral radius. We establish that, contrary to popular
belief, the graph attention mechanism cannot prevent oversmoothing and loses
expressive power exponentially. The proposed framework extends the existing
results on oversmoothing for symmetric GCNs to a significantly broader class of
GNN models, including random walk GCNs, Graph Attention Networks (GATs) and
(graph) transformers. In particular, our analysis accounts for asymmetric,
state-dependent and time-varying aggregation operators and a wide range of
common nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xinyi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ajorlou_A/0/1/0/all/0/1&quot;&gt;Amir Ajorlou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zihui Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jadbabaie_A/0/1/0/all/0/1&quot;&gt;Ali Jadbabaie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.20057">
<title>Three-Way Trade-Off in Multi-Objective Learning: Optimization, Generalization and Conflict-Avoidance. (arXiv:2305.20057v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.20057</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-objective learning (MOL) problems often arise in emerging machine
learning problems when there are multiple learning criteria, data modalities,
or learning tasks. Different from single-objective learning, one of the
critical challenges in MOL is the potential conflict among different objectives
during the iterative optimization process. Recent works have developed various
dynamic weighting algorithms for MOL such as MGDA and its variants, where the
central idea is to find an update direction that avoids conflicts among
objectives. Albeit its appealing intuition, empirical studies show that dynamic
weighting methods may not always outperform static ones. To understand this
theory-practical gap, we focus on a new stochastic variant of MGDA - the
Multi-objective gradient with Double sampling (MoDo) algorithm, and study the
generalization performance of the dynamic weighting-based MoDo and its
interplay with optimization through the lens of algorithm stability. Perhaps
surprisingly, we find that the key rationale behind MGDA -- updating along
conflict-avoidant direction - may hinder dynamic weighting algorithms from
achieving the optimal ${\cal O}(1/\sqrt{n})$ population risk, where $n$ is the
number of training samples. We further demonstrate the impact of the
variability of dynamic weights on the three-way trade-off among optimization,
generalization, and conflict avoidance that is unique in MOL. We showcase the
generality of our theoretical framework by analyzing other existing stochastic
MOL algorithms under the framework. Experiments on various multi-task learning
benchmarks are performed to demonstrate the practical applicability. Code is
available at https://github.com/heshandevaka/Trade-Off-MOL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lisha Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernando_H/0/1/0/all/0/1&quot;&gt;Heshan Fernando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1&quot;&gt;Yiming Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianyi Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.03116">
<title>Transferring Annotator- and Instance-dependent Transition Matrix for Learning from Crowds. (arXiv:2306.03116v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/2306.03116</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning from crowds describes that the annotations of training data are
obtained with crowd-sourcing services. Multiple annotators each complete their
own small part of the annotations, where labeling mistakes that depend on
annotators occur frequently. Modeling the label-noise generation process by the
noise transition matrix is a power tool to tackle the label noise. In
real-world crowd-sourcing scenarios, noise transition matrices are both
annotator- and instance-dependent. However, due to the high complexity of
annotator- and instance-dependent transition matrices (AIDTM), annotation
sparsity, which means each annotator only labels a little part of instances,
makes modeling AIDTM very challenging. Prior works simplify the problem by
assuming the transition matrix is instance-independent or using simple
parametric ways, which lose modeling generality. Motivated by this, we target a
more realistic problem, estimating general AIDTM in practice. Without losing
modeling generality, we parameterize AIDTM with deep neural networks. To
alleviate the modeling challenge, we suppose every annotator shares its noise
pattern with similar annotators, and estimate AIDTM via knowledge transfer. We
hence first model the mixture of noise patterns by all annotators, and then
transfer this modeling to individual annotators. Furthermore, considering that
the transfer from the mixture of noise patterns to individuals may cause two
annotators with highly different noise generations to perturb each other, we
employ the knowledge transfer between identified neighboring annotators to
calibrate the modeling. Theoretical analyses are derived to demonstrate that
both the knowledge transfer from global to individuals and the knowledge
transfer between neighboring individuals can help model general AIDTM.
Experiments confirm the superiority of the proposed approach on synthetic and
real-world crowd-sourcing data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shikun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1&quot;&gt;Xiaobo Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1&quot;&gt;Jiankang Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1&quot;&gt;Shiming Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tongliang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.03364">
<title>Learning Representations on the Unit Sphere: Investigating Angular Gaussian and von Mises-Fisher Distributions for Online Continual Learning. (arXiv:2306.03364v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.03364</link>
<description rdf:parseType="Literal">&lt;p&gt;We use the maximum a posteriori estimation principle for learning
representations distributed on the unit sphere. We propose to use the angular
Gaussian distribution, which corresponds to a Gaussian projected on the
unit-sphere and derive the associated loss function. We also consider the von
Mises-Fisher distribution, which is the conditional of a Gaussian in the
unit-sphere. The learned representations are pushed toward fixed directions,
which are the prior means of the Gaussians; allowing for a learning strategy
that is resilient to data drift. This makes it suitable for online continual
learning, which is the problem of training neural networks on a continuous data
stream, where multiple classification tasks are presented sequentially so that
data from past tasks are no longer accessible, and data from the current task
can be seen only once. To address this challenging scenario, we propose a
memory-based representation learning technique equipped with our new loss
functions. Our approach does not require negative data or knowledge of task
boundaries and performs well with smaller batch sizes while being
computationally efficient. We demonstrate with extensive experiments that the
proposed method outperforms the current state-of-the-art methods on both
standard evaluation scenarios and realistic scenarios with blurry task
boundaries. For reproducibility, we use the same training pipeline for every
compared method and share the code at https://t.ly/SQTj.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michel_N/0/1/0/all/0/1&quot;&gt;Nicolas Michel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chierchia_G/0/1/0/all/0/1&quot;&gt;Giovanni Chierchia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Negrel_R/0/1/0/all/0/1&quot;&gt;Romain Negrel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bercher_J/0/1/0/all/0/1&quot;&gt;Jean-Fran&amp;#xe7;ois Bercher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.07629">
<title>SqueezeLLM: Dense-and-Sparse Quantization. (arXiv:2306.07629v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.07629</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Large Language Models (LLMs) have demonstrated remarkable results
for a wide range of tasks. However, deploying these models for inference has
been a significant challenge due to their unprecedented resource requirements.
This has forced existing deployment frameworks to use multi-GPU inference
pipelines, which are often complex and costly, or to use smaller and less
performant models. In this work, we demonstrate that the main bottleneck for
generative inference with LLMs is memory bandwidth, rather than compute,
specifically for single batch inference. While quantization has emerged as a
promising solution by representing model weights with reduced precision,
previous efforts have often resulted in notable performance degradation. To
address this, we introduce SqueezeLLM, a post-training quantization framework
that not only enables lossless compression to ultra-low precisions of up to
3-bit, but also achieves higher quantization performance under the same memory
constraint. Our framework incorporates two novel ideas: (i) sensitivity-based
non-uniform quantization, which searches for the optimal bit precision
assignment based on second-order information; and (ii) the Dense-and-Sparse
decomposition that stores outliers and sensitive weight values in an efficient
sparse format. When applied to the LLaMA models, our 3-bit quantization
significantly reduces the perplexity gap from the FP16 baseline by up to 2.1x
as compared to the state-of-the-art methods with the same memory requirement.
Furthermore, when deployed on an A6000 GPU, our quantized models achieve up to
2.3x speedup compared to the baseline. Our code is open-sourced and available
online.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sehoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hooper_C/0/1/0/all/0/1&quot;&gt;Coleman Hooper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1&quot;&gt;Amir Gholami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1&quot;&gt;Zhen Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiuyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1&quot;&gt;Sheng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1&quot;&gt;Michael W. Mahoney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1&quot;&gt;Kurt Keutzer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.08586">
<title>FedJETs: Efficient Just-In-Time Personalization with Federated Mixture of Experts. (arXiv:2306.08586v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.08586</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the goals in Federated Learning (FL) is to create personalized models
that can adapt to the context of each participating client, while utilizing
knowledge from a shared global model. Yet, often, personalization requires a
fine-tuning step using clients&apos; labeled data in order to achieve good
performance. This may not be feasible in scenarios where incoming clients are
fresh and/or have privacy concerns. It, then, remains open how one can achieve
just-in-time personalization in these scenarios. We propose FedJETs, a novel
solution by using a Mixture-of-Experts (MoE) framework within a FL setup. Our
method leverages the diversity of the clients to train specialized experts on
different subsets of classes, and a gating function to route the input to the
most relevant expert(s). Our gating function harnesses the knowledge of a
pretrained model common expert to enhance its routing decisions on-the-fly. As
a highlight, our approach can improve accuracy up to 18\% in state of the art
FL settings, while maintaining competitive zero-shot performance. In practice,
our method can handle non-homogeneous data distributions, scale more
efficiently, and improve the state-of-the-art performance on common FL
benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1&quot;&gt;Chen Dun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_M/0/1/0/all/0/1&quot;&gt;Mirian Hipolito Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1&quot;&gt;Guoqing Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1&quot;&gt;Ahmed Hassan Awadallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1&quot;&gt;Robert Sim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dimitriadis_D/0/1/0/all/0/1&quot;&gt;Dimitrios Dimitriadis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.08827">
<title>PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs. (arXiv:2306.08827v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.08827</link>
<description rdf:parseType="Literal">&lt;p&gt;While significant progress has been made on Physics-Informed Neural Networks
(PINNs), a comprehensive comparison of these methods across a wide range of
Partial Differential Equations (PDEs) is still lacking. This study introduces
PINNacle, a benchmarking tool designed to fill this gap. PINNacle provides a
diverse dataset, comprising over 20 distinct PDEs from various domains,
including heat conduction, fluid dynamics, biology, and electromagnetics. These
PDEs encapsulate key challenges inherent to real-world problems, such as
complex geometry, multi-scale phenomena, nonlinearity, and high dimensionality.
PINNacle also offers a user-friendly toolbox, incorporating about 10
state-of-the-art PINN methods for systematic evaluation and comparison. We have
conducted extensive experiments with these methods, offering insights into
their strengths and weaknesses. In addition to providing a standardized means
of assessing performance, PINNacle also offers an in-depth analysis to guide
future research, particularly in areas such as domain decomposition methods and
loss reweighting for handling multi-scale problems and complex geometry. To the
best of our knowledge, it is the largest benchmark with a diverse and
comprehensive evaluation that will undoubtedly foster further research in
PINNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1&quot;&gt;Zhongkai Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jiachen Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1&quot;&gt;Chang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_F/0/1/0/all/0/1&quot;&gt;Fanzhi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Z/0/1/0/all/0/1&quot;&gt;Zeyu Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yichi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Songming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1&quot;&gt;Lu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.09376">
<title>Modularizing while Training: A New Paradigm for Modularizing DNN Models. (arXiv:2306.09376v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.09376</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural network (DNN) models have become increasingly crucial components
in intelligent software systems. However, training a DNN model is typically
expensive in terms of both time and money. To address this issue, researchers
have recently focused on reusing existing DNN models - borrowing the idea of
code reuse in software engineering. However, reusing an entire model could
cause extra overhead or inherits the weakness from the undesired
functionalities. Hence, existing work proposes to decompose an already trained
model into modules, i.e., modularizing-after-training, and enable module reuse.
Since trained models are not built for modularization,
modularizing-after-training incurs huge overhead and model accuracy loss. In
this paper, we propose a novel approach that incorporates modularization into
the model training process, i.e., modularizing-while-training (MwT). We train a
model to be structurally modular through two loss functions that optimize
intra-module cohesion and inter-module coupling. We have implemented the
proposed approach for modularizing Convolutional Neural Network (CNN) models in
this work. The evaluation results on representative models demonstrate that MwT
outperforms the state-of-the-art approach. Specifically, the accuracy loss
caused by MwT is only 1.13 percentage points, which is 1.76 percentage points
less than that of the baseline. The kernel retention rate of the modules
generated by MwT is only 14.58%, with a reduction of 74.31% over the
state-of-the-art approach. Furthermore, the total time cost required for
training and modularizing is only 108 minutes, half of the baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_B/0/1/0/all/0/1&quot;&gt;Binhang Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Hailong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1&quot;&gt;Ruobing Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1&quot;&gt;Xiang Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.13512">
<title>DISCO-10M: A Large-Scale Music Dataset. (arXiv:2306.13512v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2306.13512</link>
<description rdf:parseType="Literal">&lt;p&gt;Music datasets play a crucial role in advancing research in machine learning
for music. However, existing music datasets suffer from limited size,
accessibility, and lack of audio resources. To address these shortcomings, we
present DISCO-10M, a novel and extensive music dataset that surpasses the
largest previously available music dataset by an order of magnitude. To ensure
high-quality data, we implement a multi-stage filtering process. This process
incorporates similarities based on textual descriptions and audio embeddings.
Moreover, we provide precomputed CLAP embeddings alongside DISCO-10M,
facilitating direct application on various downstream tasks. These embeddings
enable efficient exploration of machine learning applications on the provided
data. With DISCO-10M, we aim to democratize and facilitate new research to help
advance the development of novel machine learning models for music.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lanzendorfer_L/0/1/0/all/0/1&quot;&gt;Luca A. Lanzend&amp;#xf6;rfer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grotschla_F/0/1/0/all/0/1&quot;&gt;Florian Gr&amp;#xf6;tschla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Funke_E/0/1/0/all/0/1&quot;&gt;Emil Funke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1&quot;&gt;Roger Wattenhofer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.04333">
<title>Enhancing Adversarial Robustness via Score-Based Optimization. (arXiv:2307.04333v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.04333</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial attacks have the potential to mislead deep neural network
classifiers by introducing slight perturbations. Developing algorithms that can
mitigate the effects of these attacks is crucial for ensuring the safe use of
artificial intelligence. Recent studies have suggested that score-based
diffusion models are effective in adversarial defenses. However, existing
diffusion-based defenses rely on the sequential simulation of the reversed
stochastic differential equations of diffusion models, which are
computationally inefficient and yield suboptimal results. In this paper, we
introduce a novel adversarial defense scheme named ScoreOpt, which optimizes
adversarial samples at test-time, towards original clean data in the direction
guided by score-based priors. We conduct comprehensive experiments on multiple
datasets, including CIFAR10, CIFAR100 and ImageNet. Our experimental results
demonstrate that our approach outperforms existing adversarial defenses in
terms of both robustness performance and inference speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Boya Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1&quot;&gt;Weijian Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhihua Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.05435">
<title>One-Versus-Others Attention: Scalable Multimodal Integration. (arXiv:2307.05435v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.05435</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal learning models have become increasingly important as they surpass
single-modality approaches on diverse tasks ranging from question-answering to
autonomous driving. Despite the importance of multimodal learning, existing
efforts focus on NLP applications, where the number of modalities is typically
less than four (audio, video, text, images). However, data inputs in other
domains, such as the medical field, may include X-rays, PET scans, MRIs,
genetic screening, clinical notes, and more, creating a need for both efficient
and accurate information fusion. Many state-of-the-art models rely on pairwise
cross-modal attention, which does not scale well for applications with more
than three modalities. For $n$ modalities, computing attention will result in
$n \choose 2$ operations, potentially requiring considerable amounts of
computational resources. To address this, we propose a new domain-neutral
attention mechanism, One-Versus-Others (OvO) attention, that scales linearly
with the number of modalities and requires only $n$ attention operations, thus
offering a significant reduction in computational complexity compared to
existing cross-modal attention algorithms. Using three diverse real-world
datasets as well as an additional simulation experiment, we show that our
method improves performance compared to popular fusion techniques while
decreasing computation costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golovanevsky_M/0/1/0/all/0/1&quot;&gt;Michal Golovanevsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schiller_E/0/1/0/all/0/1&quot;&gt;Eva Schiller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1&quot;&gt;Akira Nair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Ritambhara Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1&quot;&gt;Carsten Eickhoff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06092">
<title>Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06092</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the distribution of a fully connected neural network with random
Gaussian weights and biases in which the hidden layer widths are proportional
to a large constant $n$. Under mild assumptions on the non-linearity, we obtain
quantitative bounds on normal approximations valid at large but finite $n$ and
any fixed network depth. Our theorems show both for the finite-dimensional
distributions and the entire process, that the distance between a random fully
connected network (and its derivatives) to the corresponding infinite width
Gaussian process scales like $n^{-\gamma}$ for $\gamma&amp;gt;0$, with the exponent
depending on the metric used to measure discrepancy. Our bounds are strictly
stronger in terms of their dependence on network width than any previously
available in the literature; in the one-dimensional case, we also prove that
they are optimal, i.e., we establish matching lower bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Favaro_S/0/1/0/all/0/1&quot;&gt;Stefano Favaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1&quot;&gt;Boris Hanin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marinucci_D/0/1/0/all/0/1&quot;&gt;Domenico Marinucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nourdin_I/0/1/0/all/0/1&quot;&gt;Ivan Nourdin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peccati_G/0/1/0/all/0/1&quot;&gt;Giovanni Peccati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06125">
<title>Learning Hierarchical Interactive Multi-Object Search for Mobile Manipulation. (arXiv:2307.06125v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06125</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing object-search approaches enable robots to search through free
pathways, however, robots operating in unstructured human-centered environments
frequently also have to manipulate the environment to their needs. In this
work, we introduce a novel interactive multi-object search task in which a
robot has to open doors to navigate rooms and search inside cabinets and
drawers to find target objects. These new challenges require combining
manipulation and navigation skills in unexplored environments. We present
HIMOS, a hierarchical reinforcement learning approach that learns to compose
exploration, navigation, and manipulation skills. To achieve this, we design an
abstract high-level action space around a semantic map memory and leverage the
explored environment as instance navigation points. We perform extensive
experiments in simulation and the real world that demonstrate that, with
accurate perception, the decision making of HIMOS effectively transfers to new
environments in a zero-shot manner. It shows robustness to unseen subpolicies,
failures in their execution, and different robot kinematics. These capabilities
open the door to a wide range of downstream tasks across embodied AI and
real-world use cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmalstieg_F/0/1/0/all/0/1&quot;&gt;Fabian Schmalstieg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honerkamp_D/0/1/0/all/0/1&quot;&gt;Daniel Honerkamp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welschehold_T/0/1/0/all/0/1&quot;&gt;Tim Welschehold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1&quot;&gt;Abhinav Valada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.07726">
<title>Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection. (arXiv:2307.07726v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2307.07726</link>
<description rdf:parseType="Literal">&lt;p&gt;When artificial neural networks have demonstrated exceptional practical
success in a variety of domains, investigations into their theoretical
characteristics, such as their approximation power, statistical properties, and
generalization performance, have concurrently made significant strides. In this
paper, we construct a novel theory for understanding the effectiveness of
neural networks, which offers a perspective distinct from prior research.
Specifically, we explore the rationale underlying a common practice during the
construction of neural network models: sample splitting. Our findings indicate
that the optimal hyperparameters derived from sample splitting can enable a
neural network model that asymptotically minimizes the prediction risk. We
conduct extensive experiments across different application scenarios and
network architectures, and the results manifest our theory&apos;s effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gong_S/0/1/0/all/0/1&quot;&gt;Shijin Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinyu Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.11546">
<title>Towards practical reinforcement learning for tokamak magnetic control. (arXiv:2307.11546v2 [physics.plasm-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2307.11546</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) has shown promising results for real-time control
systems, including the domain of plasma magnetic control. However, there are
still significant drawbacks compared to traditional feedback control approaches
for magnetic confinement. In this work, we address key drawbacks of the RL
method; achieving higher control accuracy for desired plasma properties,
reducing the steady-state error, and decreasing the required time to learn new
tasks. We build on top of \cite{degrave2022magnetic}, and present algorithmic
improvements to the agent architecture and training procedure. We present
simulation results that show up to 65\% improvement in shape accuracy, achieve
substantial reduction in the long-term bias of the plasma current, and
additionally reduce the training time required to learn new tasks by a factor
of 3 or more. We present new experiments using the upgraded RL-based
controllers on the TCV tokamak, which validate the simulation results achieved,
and point the way towards routinely achieving accurate discharges using the RL
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Tracey_B/0/1/0/all/0/1&quot;&gt;Brendan D. Tracey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Michi_A/0/1/0/all/0/1&quot;&gt;Andrea Michi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chervonyi_Y/0/1/0/all/0/1&quot;&gt;Yuri Chervonyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Davies_I/0/1/0/all/0/1&quot;&gt;Ian Davies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Paduraru_C/0/1/0/all/0/1&quot;&gt;Cosmin Paduraru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lazic_N/0/1/0/all/0/1&quot;&gt;Nevena Lazic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Felici_F/0/1/0/all/0/1&quot;&gt;Federico Felici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ewalds_T/0/1/0/all/0/1&quot;&gt;Timo Ewalds&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Donner_C/0/1/0/all/0/1&quot;&gt;Craig Donner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Galperti_C/0/1/0/all/0/1&quot;&gt;Cristian Galperti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Buchli_J/0/1/0/all/0/1&quot;&gt;Jonas Buchli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Neunert_M/0/1/0/all/0/1&quot;&gt;Michael Neunert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Huber_A/0/1/0/all/0/1&quot;&gt;Andrea Huber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Evens_J/0/1/0/all/0/1&quot;&gt;Jonathan Evens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kurylowicz_P/0/1/0/all/0/1&quot;&gt;Paula Kurylowicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mankowitz_D/0/1/0/all/0/1&quot;&gt;Daniel J. Mankowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Riedmiller_M/0/1/0/all/0/1&quot;&gt;Martin Riedmiller&lt;/a&gt;, The &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Team_TCV/0/1/0/all/0/1&quot;&gt;TCV Team&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.00143">
<title>Formally Explaining Neural Networks within Reactive Systems. (arXiv:2308.00143v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2308.00143</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) are increasingly being used as controllers in
reactive systems. However, DNNs are highly opaque, which renders it difficult
to explain and justify their actions. To mitigate this issue, there has been a
surge of interest in explainable AI (XAI) techniques, capable of pinpointing
the input features that caused the DNN to act as it did. Existing XAI
techniques typically face two limitations: (i) they are heuristic, and do not
provide formal guarantees that the explanations are correct; and (ii) they
often apply to ``one-shot&apos;&apos; systems, where the DNN is invoked independently of
past invocations, as opposed to reactive systems. Here, we begin bridging this
gap, and propose a formal DNN-verification-based XAI technique for reasoning
about multi-step, reactive systems. We suggest methods for efficiently
calculating succinct explanations, by exploiting the system&apos;s transition
constraints in order to curtail the search space explored by the underlying
verifier. We evaluate our approach on two popular benchmarks from the domain of
automated navigation; and observe that our methods allow the efficient
computation of minimal and minimum explanations, significantly outperforming
the state of the art. We also demonstrate that our methods produce formal
explanations that are more reliable than competing, non-verification-based XAI
techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bassan_S/0/1/0/all/0/1&quot;&gt;Shahaf Bassan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amir_G/0/1/0/all/0/1&quot;&gt;Guy Amir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corsi_D/0/1/0/all/0/1&quot;&gt;Davide Corsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Refaeli_I/0/1/0/all/0/1&quot;&gt;Idan Refaeli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1&quot;&gt;Guy Katz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.00436">
<title>SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning. (arXiv:2308.00436v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2308.00436</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent progress in large language models (LLMs), especially the invention
of chain-of-thought prompting, has made it possible to automatically answer
questions by stepwise reasoning. However, when faced with more complicated
problems that require non-linear thinking, even the strongest LLMs make
mistakes. To address this, we explore whether LLMs are able to recognize errors
in their own step-by-step reasoning, without resorting to external resources.
To this end, we propose SelfCheck, a general-purpose zero-shot verification
schema for recognizing such errors. We then use the results of these checks to
improve question-answering performance by conducting weighted voting on
multiple solutions to the question. We test SelfCheck on three datasets (GSM8K,
MathQA, and MATH) and find that it successfully recognizes errors and, in turn,
increases final answer accuracies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miao_N/0/1/0/all/0/1&quot;&gt;Ning Miao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1&quot;&gt;Yee Whye Teh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1&quot;&gt;Tom Rainforth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.12439">
<title>BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection. (arXiv:2308.12439v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2308.12439</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel defense, against backdoor attacks on Deep Neural Networks
(DNNs), wherein adversaries covertly implant malicious behaviors (backdoors)
into DNNs. Our defense falls within the category of post-development defenses
that operate independently of how the model was generated. The proposed defense
is built upon a novel reverse engineering approach that can directly extract
backdoor functionality of a given backdoored model to a backdoor expert model.
The approach is straightforward -- finetuning the backdoored model over a small
set of intentionally mislabeled clean samples, such that it unlearns the normal
functionality while still preserving the backdoor functionality, and thus
resulting in a model (dubbed a backdoor expert model) that can only recognize
backdoor inputs. Based on the extracted backdoor expert model, we show the
feasibility of devising highly accurate backdoor input detectors that filter
out the backdoor inputs during model inference. Further augmented by an
ensemble strategy with a finetuned auxiliary model, our defense, BaDExpert
(Backdoor Input Detection with Backdoor Expert), effectively mitigates 17 SOTA
backdoor attacks while minimally impacting clean utility. The effectiveness of
BaDExpert has been verified on multiple datasets (CIFAR10, GTSRB and ImageNet)
across various model architectures (ResNet, VGG, MobileNetV2 and Vision
Transformer).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1&quot;&gt;Tinghao Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1&quot;&gt;Xiangyu Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1&quot;&gt;Ping He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yiming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiachen T. Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1&quot;&gt;Prateek Mittal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.16150">
<title>Modality Cycles with Masked Conditional Diffusion for Unsupervised Anomaly Segmentation in MRI. (arXiv:2308.16150v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.16150</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised anomaly segmentation aims to detect patterns that are distinct
from any patterns processed during training, commonly called abnormal or
out-of-distribution patterns, without providing any associated manual
segmentations. Since anomalies during deployment can lead to model failure,
detecting the anomaly can enhance the reliability of models, which is valuable
in high-risk domains like medical imaging. This paper introduces Masked
Modality Cycles with Conditional Diffusion (MMCCD), a method that enables
segmentation of anomalies across diverse patterns in multimodal MRI. The method
is based on two fundamental ideas. First, we propose the use of cyclic modality
translation as a mechanism for enabling abnormality detection.
Image-translation models learn tissue-specific modality mappings, which are
characteristic of tissue physiology. Thus, these learned mappings fail to
translate tissues or image patterns that have never been encountered during
training, and the error enables their segmentation. Furthermore, we combine
image translation with a masked conditional diffusion model, which attempts to
`imagine&apos; what tissue exists under a masked area, further exposing unknown
patterns as the generative model fails to recreate them. We evaluate our method
on a proxy task by training on healthy-looking slices of BraTS2021
multi-modality MRIs and testing on slices with tumors. We show that our method
compares favorably to previous unsupervised approaches based on image
reconstruction and denoising with autoencoders and diffusion models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liang_Z/0/1/0/all/0/1&quot;&gt;Ziyun Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Anthony_H/0/1/0/all/0/1&quot;&gt;Harry Anthony&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wagner_F/0/1/0/all/0/1&quot;&gt;Felix Wagner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kamnitsas_K/0/1/0/all/0/1&quot;&gt;Konstantinos Kamnitsas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.16738">
<title>SFUSNet: A Spatial-Frequency domain-based Multi-branch Network for diagnosis of Cervical Lymph Node Lesions in Ultrasound Images. (arXiv:2308.16738v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.16738</link>
<description rdf:parseType="Literal">&lt;p&gt;Booming deep learning has substantially improved the diagnosis for diverse
lesions in ultrasound images, but a conspicuous research gap concerning
cervical lymph node lesions still remains. The objective of this work is to
diagnose cervical lymph node lesions in ultrasound images by leveraging a deep
learning model. To this end, we first collected 3392 cervical ultrasound images
containing normal lymph nodes, benign lymph node lesions, malignant primary
lymph node lesions, and malignant metastatic lymph node lesions. Given that
ultrasound images are generated by the reflection and scattering of sound waves
across varied bodily tissues, we proposed the Conv-FFT Block. It integrates
convolutional operations with the fast Fourier transform to more astutely model
the images. Building upon this foundation, we designed a novel architecture,
named SFUSNet. SFUSNet not only discerns variances in ultrasound images from
the spatial domain but also adeptly captures micro-structural alterations
across various lesions in the frequency domain. To ascertain the potential of
SFUSNet, we benchmarked it against 12 popular architectures through five-fold
cross-validation. The results show that SFUSNet is the state-of-the-art model
and can achieve 92.89% accuracy. Moreover, its average precision, average
sensitivity and average specificity for four types of lesions achieve 90.46%,
89.95% and 97.49%, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yubiao Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xue_J/0/1/0/all/0/1&quot;&gt;Jun Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1&quot;&gt;Haihua Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Luo_B/0/1/0/all/0/1&quot;&gt;Bingchun Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenzhang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.00079">
<title>On the Implicit Bias of Adam. (arXiv:2309.00079v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.00079</link>
<description rdf:parseType="Literal">&lt;p&gt;In previous literature, backward error analysis was used to find ordinary
differential equations (ODEs) approximating the gradient descent trajectory. It
was found that finite step sizes implicitly regularize solutions because terms
appearing in the ODEs penalize the two-norm of the loss gradients. We prove
that the existence of similar implicit regularization in RMSProp and Adam
depends on their hyperparameters and the training stage, but with a different
&quot;norm&quot; involved: the corresponding ODE terms either penalize the (perturbed)
one-norm of the loss gradients or, on the contrary, hinder its decrease (the
latter case being typical). We also conduct numerical experiments and discuss
how the proven facts can influence generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cattaneo_M/0/1/0/all/0/1&quot;&gt;Matias D. Cattaneo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klusowski_J/0/1/0/all/0/1&quot;&gt;Jason M. Klusowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shigida_B/0/1/0/all/0/1&quot;&gt;Boris Shigida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.01807">
<title>Marginalized Importance Sampling for Off-Environment Policy Evaluation. (arXiv:2309.01807v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.01807</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement Learning (RL) methods are typically sample-inefficient, making
it challenging to train and deploy RL-policies in real world robots. Even a
robust policy trained in simulation requires a real-world deployment to assess
their performance. This paper proposes a new approach to evaluate the
real-world performance of agent policies prior to deploying them in the real
world. Our approach incorporates a simulator along with real-world offline data
to evaluate the performance of any policy using the framework of Marginalized
Importance Sampling (MIS). Existing MIS methods face two challenges: (1) large
density ratios that deviate from a reasonable range and (2) indirect
supervision, where the ratio needs to be inferred indirectly, thus exacerbating
estimation error. Our approach addresses these challenges by introducing the
target policy&apos;s occupancy in the simulator as an intermediate variable and
learning the density ratio as the product of two terms that can be learned
separately. The first term is learned with direct supervision and the second
term has a small magnitude, thus making it computationally efficient. We
analyze the sample complexity as well as error propagation of our two
step-procedure. Furthermore, we empirically evaluate our approach on Sim2Sim
environments such as Cartpole, Reacher, and Half-Cheetah. Our results show that
our method generalizes well across a variety of Sim2Sim gap, target policies
and offline data collection policies. We also demonstrate the performance of
our algorithm on a Sim2Real task of validating the performance of a 7 DoF
robotic arm using offline data along with the Gazebo simulator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katdare_P/0/1/0/all/0/1&quot;&gt;Pulkit Katdare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1&quot;&gt;Nan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1&quot;&gt;Katherine Driggs-Campbell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.05395">
<title>Practical Homomorphic Aggregation for Byzantine ML. (arXiv:2309.05395v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.05395</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the large-scale availability of data, machine learning (ML) algorithms
are being deployed in distributed topologies, where different nodes collaborate
to train ML models over their individual data by exchanging model-related
information (e.g., gradients) with a central server. However, distributed
learning schemes are notably vulnerable to two threats. First, Byzantine nodes
can single-handedly corrupt the learning by sending incorrect information to
the server, e.g., erroneous gradients. The standard approach to mitigate such
behavior is to use a non-linear robust aggregation method at the server.
Second, the server can violate the privacy of the nodes. Recent attacks have
shown that exchanging (unencrypted) gradients enables a curious server to
recover the totality of the nodes&apos; data. The use of homomorphic encryption
(HE), a gold standard security primitive, has extensively been studied as a
privacy-preserving solution to distributed learning in non-Byzantine scenarios.
However, due to HE&apos;s large computational demand especially for high-dimensional
ML models, there has not yet been any attempt to design purely homomorphic
operators for non-linear robust aggregators. In this work, we present SABLE,
the first completely homomorphic and Byzantine robust distributed learning
algorithm. SABLE essentially relies on a novel plaintext encoding method that
enables us to implement the robust aggregator over batching-friendly BGV.
Moreover, this encoding scheme also accelerates state-of-the-art homomorphic
sorting with larger security margins and smaller ciphertext size. We perform
extensive experiments on image classification tasks and show that our algorithm
achieves practical execution times while matching the ML performance of its
non-private counterpart.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choffrut_A/0/1/0/all/0/1&quot;&gt;Antoine Choffrut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinot_R/0/1/0/all/0/1&quot;&gt;Rafael Pinot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sirdey_R/0/1/0/all/0/1&quot;&gt;Renaud Sirdey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stephan_J/0/1/0/all/0/1&quot;&gt;John Stephan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuber_M/0/1/0/all/0/1&quot;&gt;Martin Zuber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.07056">
<title>Deep Quantum Graph Dreaming: Deciphering Neural Network Insights into Quantum Experiments. (arXiv:2309.07056v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2309.07056</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their promise to facilitate new scientific discoveries, the
opaqueness of neural networks presents a challenge in interpreting the logic
behind their findings. Here, we use a eXplainable-AI (XAI) technique called
$inception$ or $deep$ $dreaming$, which has been invented in machine learning
for computer vision. We use this technique to explore what neural networks
learn about quantum optics experiments. Our story begins by training deep
neural networks on the properties of quantum systems. Once trained, we &quot;invert&quot;
the neural network -- effectively asking how it imagines a quantum system with
a specific property, and how it would continuously modify the quantum system to
change a property. We find that the network can shift the initial distribution
of properties of the quantum system, and we can conceptualize the learned
strategies of the neural network. Interestingly, we find that, in the first
layers, the neural network identifies simple properties, while in the deeper
ones, it can identify complex quantum structures and even quantum entanglement.
This is in reminiscence of long-understood properties known in computer vision,
which we now identify in a complex natural science task. Our approach could be
useful in a more interpretable way to develop new advanced AI-based scientific
discovery techniques in quantum physics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jaouni_T/0/1/0/all/0/1&quot;&gt;Tareq Jaouni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Arlt_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf6;ren Arlt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ruiz_Gonzalez_C/0/1/0/all/0/1&quot;&gt;Carlos Ruiz-Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Karimi_E/0/1/0/all/0/1&quot;&gt;Ebrahim Karimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gu_X/0/1/0/all/0/1&quot;&gt;Xuemei Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Krenn_M/0/1/0/all/0/1&quot;&gt;Mario Krenn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.07936">
<title>Landscape-Sketch-Step: An AI/ML-Based Metaheuristic for Surrogate Optimization Problems. (arXiv:2309.07936v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.07936</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a new heuristics for global optimization in
scenarios where extensive evaluations of the cost function are expensive,
inaccessible, or even prohibitive. The method, which we call
Landscape-Sketch-and-Step (LSS), combines Machine Learning, Stochastic
Optimization, and Reinforcement Learning techniques, relying on historical
information from previously sampled points to make judicious choices of
parameter values where the cost function should be evaluated at. Unlike
optimization by Replica Exchange Monte Carlo methods, the number of evaluations
of the cost function required in this approach is comparable to that used by
Simulated Annealing, quality that is especially important in contexts like
high-throughput computing or high-performance computing tasks, where
evaluations are either computationally expensive or take a long time to be
performed. The method also differs from standard Surrogate Optimization
techniques, for it does not construct a surrogate model that aims at
approximating or reconstructing the objective function. We illustrate our
method by applying it to low dimensional optimization problems (dimensions 1,
2, 4, and 8) that mimick known difficulties of minimization on rugged energy
landscapes often seen in Condensed Matter Physics, where cost functions are
rugged and plagued with local minima. When compared to classical Simulated
Annealing, the LSS shows an effective acceleration of the optimization process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monteiro_R/0/1/0/all/0/1&quot;&gt;Rafael Monteiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sau_K/0/1/0/all/0/1&quot;&gt;Kartik Sau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.09472">
<title>Reconstructing Existing Levels through Level Inpainting. (arXiv:2309.09472v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.09472</link>
<description rdf:parseType="Literal">&lt;p&gt;Procedural Content Generation (PCG) and Procedural Content Generation via
Machine Learning (PCGML) have been used in prior work for generating levels in
various games. This paper introduces Content Augmentation and focuses on the
subproblem of level inpainting, which involves reconstructing and extending
video game levels. Drawing inspiration from image inpainting, we adapt two
techniques from this domain to address our specific use case. We present two
approaches for level inpainting: an Autoencoder and a U-net. Through a
comprehensive case study, we demonstrate their superior performance compared to
a baseline method and discuss their relative merits. Furthermore, we provide a
practical demonstration of both approaches for the level inpainting task and
offer insights into potential directions for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Johor Jara Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1&quot;&gt;Matthew Guzdial&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.09476">
<title>Mechanic Maker 2.0: Reinforcement Learning for Evaluating Generated Rules. (arXiv:2309.09476v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2309.09476</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated game design (AGD), the study of automatically generating game
rules, has a long history in technical games research. AGD approaches generally
rely on approximations of human play, either objective functions or AI agents.
Despite this, the majority of these approximators are static, meaning they do
not reflect human player&apos;s ability to learn and improve in a game. In this
paper, we investigate the application of Reinforcement Learning (RL) as an
approximator for human play for rule generation. We recreate the classic AGD
environment Mechanic Maker in Unity as a new, open-source rule generation
framework. Our results demonstrate that RL produces distinct sets of rules from
an A* agent baseline, which may be more usable by humans.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Johor Jara Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cooper_S/0/1/0/all/0/1&quot;&gt;Seth Cooper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1&quot;&gt;Matthew Guzdial&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11745">
<title>PIE: Simulating Disease Progression via Progressive Image Editing. (arXiv:2309.11745v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.11745</link>
<description rdf:parseType="Literal">&lt;p&gt;Disease progression simulation is a crucial area of research that has
significant implications for clinical diagnosis, prognosis, and treatment. One
major challenge in this field is the lack of continuous medical imaging
monitoring of individual patients over time. To address this issue, we develop
a novel framework termed Progressive Image Editing (PIE) that enables
controlled manipulation of disease-related image features, facilitating precise
and realistic disease progression simulation. Specifically, we leverage recent
advancements in text-to-image generative models to simulate disease progression
accurately and personalize it for each patient. We theoretically analyze the
iterative refining process in our framework as a gradient descent with an
exponentially decayed learning rate. To validate our framework, we conduct
experiments in three medical imaging domains. Our results demonstrate the
superiority of PIE over existing methods such as Stable Diffusion Walk and
Style-Based Manifold Extrapolation based on CLIP score (Realism) and Disease
Classification Confidence (Alignment). Our user study collected feedback from
35 veteran physicians to assess the generated progressions. Remarkably, 76.2%
of the feedback agrees with the fidelity of the generated progressions. To our
best knowledge, PIE is the first of its kind to generate disease progression
images meeting real-world standards. It is a promising tool for medical
research and clinical practice, potentially allowing healthcare providers to
model disease trajectories over time, predict future treatment responses, and
improve patient outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liang_K/0/1/0/all/0/1&quot;&gt;Kaizhao Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cao_X/0/1/0/all/0/1&quot;&gt;Xu Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liao_K/0/1/0/all/0/1&quot;&gt;Kuei-Da Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Tianren Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ye_W/0/1/0/all/0/1&quot;&gt;Wenqian Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhengyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cao_J/0/1/0/all/0/1&quot;&gt;Jianguo Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nama_T/0/1/0/all/0/1&quot;&gt;Tejas Nama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12488">
<title>Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.12488</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent experiments have shown that, often, when training a neural network
with gradient descent (GD) with a step size $\eta$, the operator norm of the
Hessian of the loss grows until it approximately reaches $2/\eta$, after which
it fluctuates around this value. The quantity $2/\eta$ has been called the
&quot;edge of stability&quot; based on consideration of a local quadratic approximation
of the loss. We perform a similar calculation to arrive at an &quot;edge of
stability&quot; for Sharpness-Aware Minimization (SAM), a variant of GD which has
been shown to improve its generalization. Unlike the case for GD, the resulting
SAM-edge depends on the norm of the gradient. Using three deep learning
training tasks, we see empirically that SAM operates on the edge of stability
identified by this analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1&quot;&gt;Philip M. Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter L. Bartlett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12871">
<title>AnglE-optimized Text Embeddings. (arXiv:2309.12871v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.12871</link>
<description rdf:parseType="Literal">&lt;p&gt;High-quality text embedding is pivotal in improving semantic textual
similarity (STS) tasks, which are crucial components in Large Language Model
(LLM) applications. However, a common challenge existing text embedding models
face is the problem of vanishing gradients, primarily due to their reliance on
the cosine function in the optimization objective, which has saturation zones.
To address this issue, this paper proposes a novel angle-optimized text
embedding model called AnglE. The core idea of AnglE is to introduce angle
optimization in a complex space. This novel approach effectively mitigates the
adverse effects of the saturation zone in the cosine function, which can impede
gradient and hinder optimization processes. To set up a comprehensive STS
evaluation, we experimented on existing short-text STS datasets and a newly
collected long-text STS dataset from GitHub Issues. Furthermore, we examine
domain-specific STS scenarios with limited labeled data and explore how AnglE
works with LLM-annotated data. Extensive experiments were conducted on various
tasks including short-text STS, long-text STS, and domain-specific STS tasks.
The results show that AnglE outperforms the state-of-the-art (SOTA) STS models
that ignore the cosine saturation zone. These findings demonstrate the ability
of AnglE to generate high-quality text embeddings and the usefulness of angle
optimization in STS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xianming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jing Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.13777">
<title>Diffeomorphic Multi-Resolution Deep Learning Registration for Applications in Breast MRI. (arXiv:2309.13777v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.13777</link>
<description rdf:parseType="Literal">&lt;p&gt;In breast surgical planning, accurate registration of MR images across
patient positions has the potential to improve the localisation of tumours
during breast cancer treatment. While learning-based registration methods have
recently become the state-of-the-art approach for most medical image
registration tasks, these methods have yet to make inroads into breast image
registration due to certain difficulties-the lack of rich texture information
in breast MR images and the need for the deformations to be diffeomophic. In
this work, we propose learning strategies for breast MR image registration that
are amenable to diffeomorphic constraints, together with early experimental
results from in-silico and in-vivo experiments. One key contribution of this
work is a registration network which produces superior registration outcomes
for breast images in addition to providing diffeomorphic guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+French_M/0/1/0/all/0/1&quot;&gt;Matthew G. French&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Talou_G/0/1/0/all/0/1&quot;&gt;Gonzalo D. Maso Talou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gamage_T/0/1/0/all/0/1&quot;&gt;Thiranja P. Babarenda Gamage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nash_M/0/1/0/all/0/1&quot;&gt;Martyn P. Nash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nielsen_P/0/1/0/all/0/1&quot;&gt;Poul M. Nielsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Doyle_A/0/1/0/all/0/1&quot;&gt;Anthony J. Doyle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Iglesias_J/0/1/0/all/0/1&quot;&gt;Juan Eugenio Iglesias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Balbastre_Y/0/1/0/all/0/1&quot;&gt;Ya&amp;#xeb;l Balbastre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Young_S/0/1/0/all/0/1&quot;&gt;Sean I. Young&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.14073">
<title>Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2309.14073</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a graphical structure for structural equation models that is
stable under marginalization under linearity and Gaussianity assumptions. We
show that computing the maximum likelihood estimation of this model is
equivalent to training a neural network. We implement a GPU-based algorithm
that computes the maximum likelihood estimation of these models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saremi_M/0/1/0/all/0/1&quot;&gt;Mehrzad Saremi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.14331">
<title>LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference. (arXiv:2309.14331v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.14331</link>
<description rdf:parseType="Literal">&lt;p&gt;The growth of Graph Convolution Network (GCN) model sizes has revolutionized
numerous applications, surpassing human performance in areas such as personal
healthcare and financial systems. The deployment of GCNs in the cloud raises
privacy concerns due to potential adversarial attacks on client data. To
address security concerns, Privacy-Preserving Machine Learning (PPML) using
Homomorphic Encryption (HE) secures sensitive client data. However, it
introduces substantial computational overhead in practical applications. To
tackle those challenges, we present LinGCN, a framework designed to reduce
multiplication depth and optimize the performance of HE based GCN inference.
LinGCN is structured around three key elements: (1) A differentiable structural
linearization algorithm, complemented by a parameterized discrete indicator
function, co-trained with model weights to meet the optimization goal. This
strategy promotes fine-grained node-level non-linear location selection,
resulting in a model with minimized multiplication depth. (2) A compact
node-wise polynomial replacement policy with a second-order trainable
activation function, steered towards superior convergence by a two-level
distillation approach from an all-ReLU based teacher model. (3) an enhanced HE
solution that enables finer-grained operator fusion for node-wise activation
functions, further reducing multiplication level consumption in HE-based
inference. Our experiments on the NTU-XVIEW skeleton joint dataset reveal that
LinGCN excels in latency, accuracy, and scalability for homomorphically
encrypted inference, outperforming solutions such as CryptoGCN. Remarkably,
LinGCN achieves a 14.2x latency speedup relative to CryptoGCN, while preserving
an inference accuracy of 75% and notably reducing multiplication depth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1&quot;&gt;Hongwu Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ran_R/0/1/0/all/0/1&quot;&gt;Ran Ran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yukui Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jiahui Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shaoyi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thorat_K/0/1/0/all/0/1&quot;&gt;Kiran Thorat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_T/0/1/0/all/0/1&quot;&gt;Tong Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chenghong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Xiaolin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Wujie Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1&quot;&gt;Caiwen Ding&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15294">
<title>Multiple Case Physics-Informed Neural Network for Biomedical Tube Flows. (arXiv:2309.15294v2 [physics.flu-dyn] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15294</link>
<description rdf:parseType="Literal">&lt;p&gt;Fluid dynamics computations for tube-like geometries are important for
biomedical evaluation of vascular and airway fluid dynamics. Physics-Informed
Neural Networks (PINNs) have recently emerged as a good alternative to
traditional computational fluid dynamics (CFD) methods. The vanilla PINN,
however, requires much longer training time than the traditional CFD methods
for each specific flow scenario and thus does not justify its mainstream use.
Here, we explore the use of the multi-case PINN approach for calculating
biomedical tube flows, where varied geometry cases are parameterized and
pre-trained on the PINN, such that results for unseen geometries can be
obtained in real time. Our objective is to identify network architecture,
tube-specific, and regularization strategies that can optimize this, via
experiments on a series of idealized 2D stenotic tube flows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wong_H/0/1/0/all/0/1&quot;&gt;Hong Shen Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chan_W/0/1/0/all/0/1&quot;&gt;Wei Xuan Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bing Huan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yap_C/0/1/0/all/0/1&quot;&gt;Choon Hwai Yap&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15325">
<title>Neural Operators for Accelerating Scientific Simulations and Design. (arXiv:2309.15325v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15325</link>
<description rdf:parseType="Literal">&lt;p&gt;Scientific discovery and engineering design are currently limited by the time
and cost of physical experiments, selected mostly through trial-and-error and
intuition that require deep domain expertise. Numerical simulations present an
alternative to physical experiments but are usually infeasible for complex
real-world domains due to the computational requirements of existing numerical
methods. Artificial intelligence (AI) presents a potential paradigm shift by
developing fast data-driven surrogate models. In particular, an AI framework,
known as neural operators, presents a principled framework for learning
mappings between functions defined on continuous domains, e.g., spatiotemporal
processes and partial differential equations (PDE). They can extrapolate and
predict solutions at new locations unseen during training, i.e., perform
zero-shot super-resolution. Neural operators can augment or even replace
existing simulators in many applications, such as computational fluid dynamics,
weather forecasting, and material modeling, while being 4-5 orders of magnitude
faster. Further, neural operators can be integrated with physics and other
domain constraints enforced at finer resolutions to obtain high-fidelity
solutions and good generalization. Since neural operators are differentiable,
they can directly optimize parameters for inverse design and other inverse
problems. We believe that neural operators present a transformative approach to
simulation and design, enabling rapid research and development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azzizadenesheli_K/0/1/0/all/0/1&quot;&gt;Kamyar Azzizadenesheli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kovachki_N/0/1/0/all/0/1&quot;&gt;Nikola Kovachki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zongyi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Schiaffini_M/0/1/0/all/0/1&quot;&gt;Miguel Liu-Schiaffini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1&quot;&gt;Jean Kossaifi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.17167">
<title>DyVal: Graph-informed Dynamic Evaluation of Large Language Models. (arXiv:2309.17167v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2309.17167</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have achieved remarkable performance in various
evaluation benchmarks. However, concerns about their performance are raised on
potential data contamination in their considerable volume of training corpus.
Moreover, the static nature and fixed complexity of current benchmarks may
inadequately gauge the advancing capabilities of LLMs. In this paper, we
introduce DyVal, a novel, general, and flexible evaluation protocol for dynamic
evaluation of LLMs. Based on our proposed dynamic evaluation framework, we
build graph-informed DyVal by leveraging the structural advantage of directed
acyclic graphs to dynamically generate evaluation samples with controllable
complexities. DyVal generates challenging evaluation sets on reasoning tasks
including mathematics, logical reasoning, and algorithm problems. We evaluate
various LLMs ranging from Flan-T5-large to ChatGPT and GPT4. Experiments
demonstrate that LLMs perform worse in DyVal-generated evaluation samples with
different complexities, emphasizing the significance of dynamic evaluation. We
also analyze the failure cases and results of different prompting methods.
Moreover, DyVal-generated samples are not only evaluation sets, but also
helpful data for fine-tuning to improve the performance of LLMs on existing
benchmarks. We hope that DyVal can shed light on the future evaluation research
of LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1&quot;&gt;Kaijie Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiaao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1&quot;&gt;Neil Zhenqiang Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1&quot;&gt;Diyi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.17260">
<title>PlaceNav: Topological Navigation through Place Recognition. (arXiv:2309.17260v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2309.17260</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent results suggest that splitting topological navigation into
robot-independent and robot-specific components improves navigation performance
by enabling the robot-independent part to be trained with data collected by
different robot types. However, the navigation methods are still limited by the
scarcity of suitable training data and suffer from poor computational scaling.
In this work, we present PlaceNav, subdividing the robot-independent part into
navigation-specific and generic computer vision components. We utilize visual
place recognition for the subgoal selection of the topological navigation
pipeline. This makes subgoal selection more efficient and enables leveraging
large-scale datasets from non-robotics sources, increasing training data
availability. Bayesian filtering, enabled by place recognition, further
improves navigation performance by increasing the temporal consistency of
subgoals. Our experimental results verify the design and the new model obtains
a 76% higher success rate in indoor and 23% higher in outdoor navigation tasks
with higher computational efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suomela_L/0/1/0/all/0/1&quot;&gt;Lauri Suomela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalliola_J/0/1/0/all/0/1&quot;&gt;Jussi Kalliola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edelman_H/0/1/0/all/0/1&quot;&gt;Harry Edelman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamarainen_J/0/1/0/all/0/1&quot;&gt;Joni-Kristian K&amp;#xe4;m&amp;#xe4;r&amp;#xe4;inen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.17329">
<title>Efficient Anatomical Labeling of Pulmonary Tree Structures via Implicit Point-Graph Networks. (arXiv:2309.17329v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.17329</link>
<description rdf:parseType="Literal">&lt;p&gt;Pulmonary diseases rank prominently among the principal causes of death
worldwide. Curing them will require, among other things, a better understanding
of the many complex 3D tree-shaped structures within the pulmonary system, such
as airways, arteries, and veins. In theory, they can be modeled using
high-resolution image stacks. Unfortunately, standard CNN approaches operating
on dense voxel grids are prohibitively expensive. To remedy this, we introduce
a point-based approach that preserves graph connectivity of tree skeleton and
incorporates an implicit surface representation. It delivers SOTA accuracy at a
low computational cost and the resulting models have usable surfaces. Due to
the scarcity of publicly accessible data, we have also curated an extensive
dataset to evaluate our approach and will make it public.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1&quot;&gt;Kangxian Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jiancheng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1&quot;&gt;Donglai Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1&quot;&gt;Ziqiao Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1&quot;&gt;Pascal Fua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.17348">
<title>Efficient Biologically Plausible Adversarial Training. (arXiv:2309.17348v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.17348</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial Neural Networks (ANNs) trained with Backpropagation (BP) show
astounding performance and are increasingly often used in performing our daily
life tasks. However, ANNs are highly vulnerable to adversarial attacks, which
alter inputs with small targeted perturbations that drastically disrupt the
models&apos; performance. The most effective method to make ANNs robust against
these attacks is adversarial training, in which the training dataset is
augmented with exemplary adversarial samples. Unfortunately, this approach has
the drawback of increased training complexity since generating adversarial
samples is very computationally demanding. In contrast to ANNs, humans are not
susceptible to adversarial attacks. Therefore, in this work, we investigate
whether biologically-plausible learning algorithms are more robust against
adversarial attacks than BP. In particular, we present an extensive comparative
analysis of the adversarial robustness of BP and Present the Error to Perturb
the Input To modulate Activity (PEPITA), a recently proposed
biologically-plausible learning algorithm, on various computer vision tasks. We
observe that PEPITA has higher intrinsic adversarial robustness and, with
adversarial training, has a more favourable natural-vs-adversarial performance
trade-off as, for the same natural accuracies, PEPITA&apos;s adversarial accuracies
decrease in average by 0.26% and BP&apos;s by 8.05%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farinha_M/0/1/0/all/0/1&quot;&gt;Matilde Tristany Farinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortner_T/0/1/0/all/0/1&quot;&gt;Thomas Ortner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dellaferrera_G/0/1/0/all/0/1&quot;&gt;Giorgia Dellaferrera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grewe_B/0/1/0/all/0/1&quot;&gt;Benjamin Grewe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pantazi_A/0/1/0/all/0/1&quot;&gt;Angeliki Pantazi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.17357">
<title>Module-wise Training of Neural Networks via the Minimizing Movement Scheme. (arXiv:2309.17357v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.17357</link>
<description rdf:parseType="Literal">&lt;p&gt;Greedy layer-wise or module-wise training of neural networks is compelling in
constrained and on-device settings where memory is limited, as it circumvents a
number of problems of end-to-end back-propagation. However, it suffers from a
stagnation problem, whereby early layers overfit and deeper layers stop
increasing the test accuracy after a certain depth. We propose to solve this
issue by introducing a module-wise regularization inspired by the minimizing
movement scheme for gradient flows in distribution space. We call the method
TRGL for Transport Regularized Greedy Learning and study it theoretically,
proving that it leads to greedy modules that are regular and that progressively
solve the task. Experimentally, we show improved accuracy of module-wise
training of various architectures such as ResNets, Transformers and VGG, when
our regularization is added, superior to that of other module-wise training
methods and often to end-to-end training, with as much as 60% less memory
usage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karkar_S/0/1/0/all/0/1&quot;&gt;Skander Karkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1&quot;&gt;Ibrahim Ayed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1&quot;&gt;Emmanuel de B&amp;#xe9;zenac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1&quot;&gt;Patrick Gallinari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00035">
<title>LoRA ensembles for large language model fine-tuning. (arXiv:2310.00035v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00035</link>
<description rdf:parseType="Literal">&lt;p&gt;Finetuned LLMs often exhibit poor uncertainty quantification, manifesting as
overconfidence, poor calibration, and unreliable prediction results on test
data or out-of-distribution samples. One approach commonly used in vision for
alleviating this issue is a deep ensemble, which constructs an ensemble by
training the same model multiple times using different random initializations.
However, there is a huge challenge to ensembling LLMs: the most effective LLMs
are very, very large. Keeping a single LLM in memory is already challenging
enough: keeping an ensemble of e.g. 5 LLMs in memory is impossible in many
settings. To address these issues, we propose an ensemble approach using
Low-Rank Adapters (LoRA), a parameter-efficient fine-tuning technique.
Critically, these low-rank adapters represent a very small number of
parameters, orders of magnitude less than the underlying pre-trained model.
Thus, it is possible to construct large ensembles of LoRA adapters with almost
the same computational overhead as using the original model. We find that LoRA
ensembles, applied on its own or on top of pre-existing regularization
techniques, gives consistent improvements in predictive accuracy and
uncertainty quantification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aitchison_L/0/1/0/all/0/1&quot;&gt;Laurence Aitchison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1&quot;&gt;Maja Rudolph&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00247">
<title>Bridging the Gap Between Foundation Models and Heterogeneous Federated Learning. (arXiv:2310.00247v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00247</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) offers privacy-preserving decentralized machine
learning, optimizing models at edge clients without sharing private data.
Simultaneously, foundation models (FMs) have gained traction in the artificial
intelligence (AI) community due to their exceptional performance across various
tasks. However, integrating FMs into FL presents challenges, primarily due to
their substantial size and intensive resource requirements. This is especially
true when considering the resource heterogeneity in edge FL systems. We present
an adaptive framework for Resource-aware Federated Foundation Models (RaFFM) to
address these challenges. RaFFM introduces specialized model compression
algorithms tailored for FL scenarios, such as salient parameter prioritization
and high-performance subnetwork extraction. These algorithms enable dynamic
scaling of given transformer-based FMs to fit heterogeneous resource
constraints at the network edge during both FL&apos;s optimization and deployment
stages. Experimental results demonstrate that RaFFM shows significant
superiority in resource utilization efficiency and uses fewer resources to
deploy FMs to FL. Despite the lower resource consumption, target models
optimized by RaFFM achieve performance on par with traditional FL methods
applied to full-sized FMs. This is evident across tasks in both natural
language processing and computer vision domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Sixing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munoz_J/0/1/0/all/0/1&quot;&gt;J. Pablo Mu&amp;#xf1;oz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1&quot;&gt;Ali Jannesari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00818">
<title>ECG-SL: Electrocardiogram(ECG) Segment Learning, a deep learning method for ECG signal. (arXiv:2310.00818v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00818</link>
<description rdf:parseType="Literal">&lt;p&gt;Electrocardiogram (ECG) is an essential signal in monitoring human heart
activities. Researchers have achieved promising results in leveraging ECGs in
clinical applications with deep learning models. However, the mainstream deep
learning approaches usually neglect the periodic and formative attribute of the
ECG heartbeat waveform. In this work, we propose a novel ECG-Segment based
Learning (ECG-SL) framework to explicitly model the periodic nature of ECG
signals. More specifically, ECG signals are first split into heartbeat
segments, and then structural features are extracted from each of the segments.
Based on the structural features, a temporal model is designed to learn the
temporal information for various clinical tasks. Further, due to the fact that
massive ECG signals are available but the labeled data are very limited, we
also explore self-supervised learning strategy to pre-train the models,
resulting significant improvement for downstream tasks. The proposed method
outperforms the baseline model and shows competitive performances compared with
task-specific methods in three clinical applications: cardiac condition
diagnosis, sleep apnea detection, and arrhythmia classification. Further, we
find that the ECG-SL tends to focus more on each heartbeat&apos;s peak and ST range
than ResNet by visualizing the saliency maps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Han Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Huiyuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sano_A/0/1/0/all/0/1&quot;&gt;Akane Sano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00944">
<title>Towards Robust 3D Object Detection In Rainy Conditions. (arXiv:2310.00944v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00944</link>
<description rdf:parseType="Literal">&lt;p&gt;LiDAR sensors are used in autonomous driving applications to accurately
perceive the environment. However, they are affected by adverse weather
conditions such as snow, fog, and rain. These everyday phenomena introduce
unwanted noise into the measurements, severely degrading the performance of
LiDAR-based perception systems. In this work, we propose a framework for
improving the robustness of LiDAR-based 3D object detectors against road spray.
Our approach uses a state-of-the-art adverse weather detection network to
filter out spray from the LiDAR point cloud, which is then used as input for
the object detector. In this way, the detected objects are less affected by the
adverse weather in the scene, resulting in a more accurate perception of the
environment. In addition to adverse weather filtering, we explore the use of
radar targets to further filter false positive detections. Tests on real-world
data show that our approach improves the robustness to road spray of several
popular 3D object detectors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piroli_A/0/1/0/all/0/1&quot;&gt;Aldi Piroli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dallabetta_V/0/1/0/all/0/1&quot;&gt;Vinzenz Dallabetta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kopp_J/0/1/0/all/0/1&quot;&gt;Johannes Kopp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walessa_M/0/1/0/all/0/1&quot;&gt;Marc Walessa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meissner_D/0/1/0/all/0/1&quot;&gt;Daniel Meissner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dietmayer_K/0/1/0/all/0/1&quot;&gt;Klaus Dietmayer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01425">
<title>Borges and AI. (arXiv:2310.01425v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.01425</link>
<description rdf:parseType="Literal">&lt;p&gt;Many believe that Large Language Models (LLMs) open the era of Artificial
Intelligence (AI). Some see opportunities while others see dangers. Yet both
proponents and opponents grasp AI through the imagery popularised by science
fiction. Will the machine become sentient and rebel against its creators? Will
we experience a paperclip apocalypse? Before answering such questions, we
should first ask whether this mental imagery provides a good description of the
phenomenon at hand. Understanding weather patterns through the moods of the
gods only goes so far. The present paper instead advocates understanding LLMs
and their connection to AI through the imagery of Jorge Luis Borges, a master
of 20th century literature, forerunner of magical realism, and precursor to
postmodern literature. This exercise leads to a new perspective that
illuminates the relation between language modelling and artificial
intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe9;on Bottou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01690">
<title>Forecasting Tropical Cyclones with Cascaded Diffusion Models. (arXiv:2310.01690v2 [physics.ao-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2310.01690</link>
<description rdf:parseType="Literal">&lt;p&gt;As cyclones become more intense due to climate change, the rise of AI-based
modelling provides a more affordable and accessible approach compared to
traditional methods based on mathematical models. This work leverages diffusion
models to forecast cyclone trajectories and precipitation patterns by
integrating satellite imaging, remote sensing, and atmospheric data, employing
a cascaded approach that incorporates forecasting, super-resolution, and
precipitation modelling, with training on a dataset of 51 cyclones from six
major basins. Experiments demonstrate that the final forecasts from the
cascaded models show accurate predictions up to a 36-hour rollout, with SSIM
and PSNR values exceeding 0.5 and 20 dB, respectively, for all three tasks.
This work also highlights the promising efficiency of AI methods such as
diffusion models for high-performance needs, such as cyclone forecasting, while
remaining computationally affordable, making them ideal for highly vulnerable
regions with critical forecasting needs and financial limitations. Code
accessible at \url{https://github.com/nathzi1505/forecast-diffmodels}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Nath_P/0/1/0/all/0/1&quot;&gt;Pritthijit Nath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Shukla_P/0/1/0/all/0/1&quot;&gt;Pancham Shukla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Quilodran_Casas_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;sar Quilodr&amp;#xe1;n-Casas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02027">
<title>DeepHGCN: Toward Deeper Hyperbolic Graph Convolutional Networks. (arXiv:2310.02027v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02027</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperbolic graph convolutional networks (HGCN) have demonstrated significant
potential in extracting information from hierarchical graphs. However, existing
HGCNs are limited to shallow architectures, due to the expensive hyperbolic
operations and the over-smoothing issue as depth increases. Although in GCNs,
treatments have been applied to alleviate over-smoothing, developing a
hyperbolic therapy presents distinct challenges since operations should be
carefully designed to fit the hyperbolic nature. Addressing the above
challenges, in this work, we propose DeepHGCN, the first deep multi-layer HGCN
architecture with dramatically improved computational efficiency and
substantially alleviated over-smoothing effect. DeepHGCN presents two key
enablers of deep HGCNs: (1) a novel hyperbolic feature transformation layer
that enables fast and accurate linear maps; and (2) Techniques such as
hyperbolic residual connections and regularization for both weights and
features facilitated by an efficient hyperbolic midpoint method. Extensive
experiments demonstrate that DeepHGCN obtains significant improvements in link
prediction and node classification tasks compared to both Euclidean and shallow
hyperbolic GCN variants.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiaxu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1&quot;&gt;Xinping Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xiaowei Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02156">
<title>Probabilistically Rewired Message-Passing Neural Networks. (arXiv:2310.02156v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02156</link>
<description rdf:parseType="Literal">&lt;p&gt;Message-passing graph neural networks (MPNNs) emerged as powerful tools for
processing graph-structured input. However, they operate on a fixed input graph
structure, ignoring potential noise and missing information. Furthermore, their
local aggregation mechanism can lead to problems such as over-squashing and
limited expressive power in capturing relevant graph structures. Existing
solutions to these challenges have primarily relied on heuristic methods, often
disregarding the underlying data distribution. Hence, devising principled
approaches for learning to infer graph structures relevant to the given
prediction task remains an open challenge. In this work, leveraging recent
progress in exact and differentiable $k$-subset sampling, we devise
probabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges
while omitting less beneficial ones. For the first time, our theoretical
analysis explores how PR-MPNNs enhance expressive power, and we identify
precise conditions under which they outperform purely randomized approaches.
Empirically, we demonstrate that our approach effectively mitigates issues like
over-squashing and under-reaching. In addition, on established real-world
datasets, our method exhibits competitive or superior predictive performance
compared to traditional MPNN models and recent graph transformer architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1&quot;&gt;Chendi Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manolache_A/0/1/0/all/0/1&quot;&gt;Andrei Manolache&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_K/0/1/0/all/0/1&quot;&gt;Kareem Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1&quot;&gt;Zhe Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1&quot;&gt;Guy Van den Broeck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1&quot;&gt;Mathias Niepert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morris_C/0/1/0/all/0/1&quot;&gt;Christopher Morris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02357">
<title>On the definition of toxicity in NLP. (arXiv:2310.02357v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02357</link>
<description rdf:parseType="Literal">&lt;p&gt;The fundamental problem in toxicity detection task lies in the fact that the
toxicity is ill-defined. This causes us to rely on subjective and vague data in
models&apos; training, which results in non-robust and non-accurate results: garbage
in - garbage out.
&lt;/p&gt;
&lt;p&gt;This work suggests a new, stress-level-based definition of toxicity designed
to be objective and context-aware. On par with it, we also describe possible
ways of applying this new definition to dataset creation and model training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berezin_S/0/1/0/all/0/1&quot;&gt;Sergey Berezin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farahbakhsh_R/0/1/0/all/0/1&quot;&gt;Reza Farahbakhsh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crespi_N/0/1/0/all/0/1&quot;&gt;Noel Crespi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02676">
<title>PostRainBench: A comprehensive benchmark and a new model for precipitation forecasting. (arXiv:2310.02676v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02676</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate precipitation forecasting is a vital challenge of both scientific
and societal importance. Data-driven approaches have emerged as a widely used
solution for addressing this challenge. However, solely relying on data-driven
approaches has limitations in modeling the underlying physics, making accurate
predictions difficult. Coupling AI-based post-processing techniques with
traditional Numerical Weather Prediction (NWP) methods offers a more effective
solution for improving forecasting accuracy. Despite previous post-processing
efforts, accurately predicting heavy rainfall remains challenging due to the
imbalanced precipitation data across locations and complex relationships
between multiple meteorological variables. To address these limitations, we
introduce the PostRainBench, a comprehensive multi-variable NWP post-processing
benchmark consisting of three datasets for NWP post-processing-based
precipitation forecasting. We propose CAMT, a simple yet effective Channel
Attention Enhanced Multi-task Learning framework with a specially designed
weighted loss function. Its flexible design allows for easy plug-and-play
integration with various backbones. Extensive experimental results on the
proposed benchmark show that our method outperforms state-of-the-art methods by
6.3%, 4.7%, and 26.8% in rain CSI on the three datasets respectively. Most
notably, our model is the first deep learning-based method to outperform
traditional Numerical Weather Prediction (NWP) approaches in extreme
precipitation conditions. It shows improvements of 15.6%, 17.4%, and 31.8% over
NWP predictions in heavy rain CSI on respective datasets. These results
highlight the potential impact of our model in reducing the severe consequences
of extreme weather events.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yujin Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiaming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1&quot;&gt;Xiang Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1&quot;&gt;Zeying Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Junwei Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02861">
<title>Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection. (arXiv:2310.02861v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02861</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph-level anomaly detection has gained significant attention as it finds
many applications in various domains, such as cancer diagnosis and enzyme
prediction. However, existing methods fail to capture the underlying properties
of graph anomalies, resulting in unexplainable framework design and
unsatisfying performance. In this paper, we take a step back and re-investigate
the spectral differences between anomalous and normal graphs. Our main
observation shows a significant disparity in the accumulated spectral energy
between these two classes. Moreover, we prove that the accumulated spectral
energy of the graph signal can be represented by its Rayleigh Quotient,
indicating that the Rayleigh Quotient is a driving factor behind the anomalous
properties of graphs. Motivated by this, we propose Rayleigh Quotient Graph
Neural Network (RQGNN), the first spectral GNN for graph-level anomaly
detection, providing a new perspective on exploring the inherent spectral
features of anomalous graphs. Specifically, we introduce a novel framework that
consists of two components: the Rayleigh Quotient learning component (RQL) and
Chebyshev Wavelet GNN with RQ-pooling (CWGNN-RQ). RQL explicitly captures the
Rayleigh Quotient of graphs and CWGNN-RQ implicitly explores the spectral space
of graphs. Extensive experiments on 10 real-world datasets show that RQGNN
outperforms the best rival by 6.74% in Macro-F1 score and 1.44% in AUC,
demonstrating the effectiveness of our framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1&quot;&gt;Xiangyu Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xingyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sibo Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02964">
<title>Co-modeling the Sequential and Graphical Routes for Peptide Representation Learning. (arXiv:2310.02964v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02964</link>
<description rdf:parseType="Literal">&lt;p&gt;Peptides are formed by the dehydration condensation of multiple amino acids.
The primary structure of a peptide can be represented either as an amino acid
sequence or as a molecular graph consisting of atoms and chemical bonds.
Previous studies have indicated that deep learning routes specific to
sequential and graphical peptide forms exhibit comparable performance on
downstream tasks. Despite the fact that these models learn representations of
the same modality of peptides, we find that they explain their predictions
differently. Considering sequential and graphical models as two experts making
inferences from different perspectives, we work on fusing expert knowledge to
enrich the learned representations for improving the discriminative
performance. To achieve this, we propose a peptide co-modeling method, RepCon,
which employs a contrastive learning-based framework to enhance the mutual
information of representations from decoupled sequential and graphical
end-to-end models. It considers representations from the sequential encoder and
the graphical encoder for the same peptide sample as a positive pair and learns
to enhance the consistency of representations between positive sample pairs and
to repel representations between negative pairs. Empirical studies of RepCon
and other co-modeling methods are conducted on open-source discriminative
datasets, including aggregation propensity, retention time, antimicrobial
peptide prediction, and family classification from Peptide Database. Our
results demonstrate the superiority of the co-modeling approach over
independent modeling, as well as the superiority of RepCon over other methods
under the co-modeling framework. In addition, the attribution on RepCon further
corroborates the validity of the approach at the level of model explanation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zihan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Ge Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiaqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jiangbin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Stan Z. Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02995">
<title>IBCL: Zero-shot Model Generation for Task Trade-offs in Continual Learning. (arXiv:2310.02995v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02995</link>
<description rdf:parseType="Literal">&lt;p&gt;Like generic multi-task learning, continual learning has the nature of
multi-objective optimization, and therefore faces a trade-off between the
performance of different tasks. That is, to optimize for the current task
distribution, it may need to compromise performance on some previous tasks.
This means that there exist multiple models that are Pareto-optimal at
different times, each addressing a distinct task performance trade-off.
Researchers have discussed how to train particular models to address specific
trade-off preferences. However, existing algorithms require training overheads
proportional to the number of preferences -- a large burden when there are
multiple, possibly infinitely many, preferences. As a response, we propose
Imprecise Bayesian Continual Learning (IBCL). Upon a new task, IBCL (1) updates
a knowledge base in the form of a convex hull of model parameter distributions
and (2) obtains particular models to address task trade-off preferences with
zero-shot. That is, IBCL does not require any additional training overhead to
generate preference-addressing models from its knowledge base. We show that
models obtained by IBCL have guarantees in identifying the Pareto optimal
parameters. Moreover, experiments on standard image classification and NLP
tasks support this guarantee. Statistically, IBCL improves average per-task
accuracy by at most 23\% and peak per-task accuracy by at most 15\% with
respect to the baseline methods, with steadily near-zero or positive backward
transfer. Most importantly, IBCL significantly reduces the training overhead
from training 1 model per preference to at most 3 models for all preferences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1&quot;&gt;Pengyuan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caprio_M/0/1/0/all/0/1&quot;&gt;Michele Caprio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1&quot;&gt;Eric Eaton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1&quot;&gt;Insup Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01423">
<title>An Empirical Study of AI Generated Text Detection Tools. (arXiv:2310.01423v1 [cs.CL] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2310.01423</link>
<description rdf:parseType="Literal">&lt;p&gt;Since ChatGPT has emerged as a major AIGC model, providing high-quality
responses across a wide range of applications (including software development
and maintenance), it has attracted much interest from many individuals. ChatGPT
has great promise, but there are serious problems that might arise from its
misuse, especially in the realms of education and public safety. Several AIGC
detectors are available, and they have all been tested on genuine text.
However, more study is needed to see how effective they are for multi-domain
ChatGPT material. This study aims to fill this need by creating a multi-domain
dataset for testing the state-of-the-art APIs and tools for detecting
artificially generated information used by universities and other research
institutions. A large dataset consisting of articles, abstracts, stories, news,
and product reviews was created for this study. The second step is to use the
newly created dataset to put six tools through their paces. Six different
artificial intelligence (AI) text identification systems, including &quot;GPTkit,&quot;
&quot;GPTZero,&quot; &quot;Originality,&quot; &quot;Sapling,&quot; &quot;Writer,&quot; and &quot;Zylalab,&quot; have accuracy
rates between 55.29 and 97.0%. Although all the tools fared well in the
evaluations, originality was particularly effective across the board.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akram_A/0/1/0/all/0/1&quot;&gt;Arslan Akram&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02671">
<title>Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods. (arXiv:2310.02671v1 [math.OC] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2310.02671</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov Decision Processes (MDPs) are a formal framework for modeling and
solving sequential decision-making problems. In finite-time horizons such
problems are relevant for instance for optimal stopping or specific supply
chain problems, but also in the training of large language models. In contrast
to infinite horizon MDPs optimal policies are not stationary, policies must be
learned for every single epoch. In practice all parameters are often trained
simultaneously, ignoring the inherent structure suggested by dynamic
programming. This paper introduces a combination of dynamic programming and
policy gradient called dynamic policy gradient, where the parameters are
trained backwards in time. For the tabular softmax parametrisation we carry out
the convergence analysis for simultaneous and dynamic policy gradient towards
global optima, both in the exact and sampled gradient settings without
regularisation. It turns out that the use of dynamic policy gradient training
much better exploits the structure of finite-time problems which is reflected
in improved convergence bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Klein_S/0/1/0/all/0/1&quot;&gt;Sara Klein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Weissmann_S/0/1/0/all/0/1&quot;&gt;Simon Weissmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Doring_L/0/1/0/all/0/1&quot;&gt;Leif D&amp;#xf6;ring&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>