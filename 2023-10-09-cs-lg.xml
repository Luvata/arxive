<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-10-08T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03745" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03747" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03748" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03749" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03750" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03752" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03753" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03754" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03755" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03756" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03757" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03758" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03759" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03760" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03767" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03770" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03772" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03773" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03778" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03779" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03789" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03812" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03817" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03823" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03833" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03838" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03840" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03843" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03845" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03848" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03861" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03865" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03879" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03882" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03884" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03890" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03898" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03899" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03902" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03906" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03912" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03915" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03919" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03925" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03927" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03941" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03946" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03957" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03964" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03968" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03977" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03981" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03984" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03985" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03986" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03999" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04003" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04006" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04015" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04017" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04038" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04041" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04047" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04059" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04064" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04074" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04078" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04128" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04140" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04145" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04159" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04171" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04178" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04179" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04190" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04216" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04218" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04238" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04241" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04264" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04283" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04285" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04292" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04295" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04299" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04311" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04314" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04323" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04327" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04328" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04334" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04336" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04343" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04345" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04349" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04352" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04354" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04361" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04363" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04367" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04369" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04373" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04395" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04400" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04406" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04407" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04411" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04413" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04415" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04417" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04418" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04420" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1806.06298" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2002.08410" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2012.03454" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.03645" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.02272" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.08190" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.10933" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.12143" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.03379" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2203.06865" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.15376" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.05794" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.08401" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.09631" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.12046" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.09475" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.11096" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.14358" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.06096" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.09851" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.14357" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.00012" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.00570" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.01814" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15612" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.17154" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.17558" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18030" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19523" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19663" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.02422" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04072" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11363" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11695" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.14435" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.15350" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.03887" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06362" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06966" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.10274" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.16708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.16888" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.00206" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05014" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.08896" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.09375" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.11053" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.11804" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.11838" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.07182" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.09464" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.10831" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12245" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.14293" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.14674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16108" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00177" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00763" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00771" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00785" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01320" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02373" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02520" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03022" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03030" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03149" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03156" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03281" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03605" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03611" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.05608" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2310.03745">
<title>Generative Hyperelasticity with Physics-Informed Probabilistic Diffusion Fields. (arXiv:2310.03745v1 [cs.CE])</title>
<link>http://arxiv.org/abs/2310.03745</link>
<description rdf:parseType="Literal">&lt;p&gt;Many natural materials exhibit highly complex, nonlinear, anisotropic, and
heterogeneous mechanical properties. Recently, it has been demonstrated that
data-driven strain energy functions possess the flexibility to capture the
behavior of these complex materials with high accuracy while satisfying
physics-based constraints. However, most of these approaches disregard the
uncertainty in the estimates and the spatial heterogeneity of these materials.
In this work, we leverage recent advances in generative models to address these
issues. We use as building block neural ordinary equations (NODE) that -- by
construction -- create polyconvex strain energy functions, a key property of
realistic hyperelastic material models. We combine this approach with
probabilistic diffusion models to generate new samples of strain energy
functions. This technique allows us to sample a vector of Gaussian white noise
and translate it to NODE parameters thereby representing plausible strain
energy functions. We extend our approach to spatially correlated diffusion
resulting in heterogeneous material properties for arbitrary geometries. We
extensively test our method with synthetic and experimental data on biological
tissues and run finite element simulations with various degrees of spatial
heterogeneity. We believe this approach is a major step forward including
uncertainty in predictive, data-driven models of hyperelasticity
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tac_V/0/1/0/all/0/1&quot;&gt;Vahidullah Tac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rausch_M/0/1/0/all/0/1&quot;&gt;Manuel K Rausch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilionis_I/0/1/0/all/0/1&quot;&gt;Ilias Bilionis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costabal_F/0/1/0/all/0/1&quot;&gt;Francisco Sahli Costabal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tepole_A/0/1/0/all/0/1&quot;&gt;Adrian Buganza Tepole&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03747">
<title>A Knowledge-Driven Cross-view Contrastive Learning for EEG Representation. (arXiv:2310.03747v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03747</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the abundant neurophysiological information in the
electroencephalogram (EEG) signal, EEG signals integrated with deep learning
methods have gained substantial traction across numerous real-world tasks.
However, the development of supervised learning methods based on EEG signals
has been hindered by the high cost and significant label discrepancies to
manually label large-scale EEG datasets. Self-supervised frameworks are adopted
in vision and language fields to solve this issue, but the lack of EEG-specific
theoretical foundations hampers their applicability across various tasks. To
solve these challenges, this paper proposes a knowledge-driven cross-view
contrastive learning framework (KDC2), which integrates neurological theory to
extract effective representations from EEG with limited labels. The KDC2 method
creates scalp and neural views of EEG signals, simulating the internal and
external representation of brain activity. Sequentially, inter-view and
cross-view contrastive learning pipelines in combination with various
augmentation methods are applied to capture neural features from different
views. By modeling prior neural knowledge based on homologous neural
information consistency theory, the proposed method extracts invariant and
complementary neural knowledge to generate combined representations.
Experimental results on different downstream tasks demonstrate that our method
outperforms state-of-the-art methods, highlighting the superior generalization
of neural knowledge-supported EEG representations across various brain tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Weng_W/0/1/0/all/0/1&quot;&gt;Weining Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gu_Y/0/1/0/all/0/1&quot;&gt;Yang Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qihui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yingying Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Miao_C/0/1/0/all/0/1&quot;&gt;Chunyan Miao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiqiang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03748">
<title>Phase Synchrony Component Self-Organization in Brain Computer Interface. (arXiv:2310.03748v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03748</link>
<description rdf:parseType="Literal">&lt;p&gt;Phase synchrony information plays a crucial role in analyzing functional
brain connectivity and identifying brain activities. A widely adopted feature
extraction pipeline, composed of preprocessing, selection of EEG acquisition
channels, and phase locking value (PLV) calculation, has achieved success in
motor imagery classification (MI). However, this pipeline is manual and reliant
on expert knowledge, limiting its convenience and adaptability to different
application scenarios. Moreover, most studies have employed mediocre
data-independent spatial filters to suppress noise, impeding the exploration of
more significant phase synchronization phenomena. To address the issues, we
propose the concept of phase synchrony component self-organization, which
enables the adaptive learning of data-dependent spatial filters for automating
both the preprocessing and channel selection procedures. Based on this concept,
the first deep learning end-to-end network is developed, which directly
extracts phase synchrony-based features from raw EEG signals and perform
classification. The network learns optimal filters during training, which are
obtained when the network achieves peak classification results. Extensive
experiments have demonstrated that our network outperforms state-of-the-art
methods. Remarkably, through the learned optimal filters, significant phase
synchronization phenomena can be observed. Specifically, by calculating the PLV
between a pair of signals extracted from each sample using two of the learned
spatial filters, we have obtained an average PLV exceeding 0.87 across all
tongue MI samples. This high PLV indicates a groundbreaking discovery in the
synchrony pattern of tongue MI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Niu_X/0/1/0/all/0/1&quot;&gt;Xu Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lu_N/0/1/0/all/0/1&quot;&gt;Na Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Huan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yan_R/0/1/0/all/0/1&quot;&gt;Ruofan Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03749">
<title>SCVCNet: Sliding cross-vector convolution network for cross-task and inter-individual-set EEG-based cognitive workload recognition. (arXiv:2310.03749v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03749</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a generic approach for applying the cognitive workload
recognizer by exploiting common electroencephalogram (EEG) patterns across
different human-machine tasks and individual sets. We propose a neural network
called SCVCNet, which eliminates task- and individual-set-related interferences
in EEGs by analyzing finer-grained frequency structures in the power spectral
densities. The SCVCNet utilizes a sliding cross-vector convolution (SCVC)
operation, where paired input layers representing the theta and alpha power are
employed. By extracting the weights from a kernel matrix&apos;s central row and
column, we compute the weighted sum of the two vectors around a specified scalp
location. Next, we introduce an inter-frequency-point feature integration
module to fuse the SCVC feature maps. Finally, we combined the two modules with
the output-channel pooling and classification layers to construct the model. To
train the SCVCNet, we employ the regularized least-square method with ridge
regression and the extreme learning machine theory. We validate its performance
using three databases, each consisting of distinct tasks performed by
independent participant groups. The average accuracy (0.6813 and 0.6229) and F1
score (0.6743 and 0.6076) achieved in two different validation paradigms show
partially higher performance than the previous works. All features and
algorithms are available on website:https://github.com/7ohnKeats/SCVCNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Li Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhan_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianhua Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zhong Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03750">
<title>Health diagnosis and recuperation of aged Li-ion batteries with data analytics and equivalent circuit modeling. (arXiv:2310.03750v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03750</link>
<description rdf:parseType="Literal">&lt;p&gt;Battery health assessment and recuperation play a crucial role in the
utilization of second-life Li-ion batteries. However, due to ambiguous aging
mechanisms and lack of correlations between the recovery effects and
operational states, it is challenging to accurately estimate battery health and
devise a clear strategy for cell rejuvenation. This paper presents aging and
reconditioning experiments of 62 commercial high-energy type lithium iron
phosphate (LFP) cells, which supplement existing datasets of high-power LFP
cells. The relatively large-scale data allow us to use machine learning models
to predict cycle life and identify important indicators of recoverable
capacity. Considering cell-to-cell inconsistencies, an average test error of
$16.84\% \pm 1.87\%$ (mean absolute percentage error) for cycle life prediction
is achieved by gradient boosting regressor given information from the first 80
cycles. In addition, it is found that some of the recoverable lost capacity is
attributed to the lateral lithium non-uniformity within the electrodes. An
equivalent circuit model is built and experimentally validated to demonstrate
how such non-uniformity can be accumulated, and how it can give rise to
recoverable capacity loss. SHapley Additive exPlanations (SHAP) analysis also
reveals that battery operation history significantly affects the capacity
recovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Made_R/0/1/0/all/0/1&quot;&gt;Riko I Made&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jing Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jintao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Moh_L/0/1/0/all/0/1&quot;&gt;Lionel C. H. Moh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhaolin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ding_N/0/1/0/all/0/1&quot;&gt;Ning Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chiam_S/0/1/0/all/0/1&quot;&gt;Sing Yang Chiam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Khoo_E/0/1/0/all/0/1&quot;&gt;Edwin Khoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yin_X/0/1/0/all/0/1&quot;&gt;Xuesong Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zheng_G/0/1/0/all/0/1&quot;&gt;Guangyuan Wesley Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03751">
<title>A Simple Illustration of Interleaved Learning using Kalman Filter for Linear Least Squares. (arXiv:2310.03751v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03751</link>
<description rdf:parseType="Literal">&lt;p&gt;Interleaved learning in machine learning algorithms is a biologically
inspired training method with promising results. In this short note, we
illustrate the interleaving mechanism via a simple statistical and optimization
framework based on Kalman Filter for Linear Least Squares.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+John_M/0/1/0/all/0/1&quot;&gt;Majnu John&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yihren Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03752">
<title>A Deep Learning Sequential Decoder for Transient High-Density Electromyography in Hand Gesture Recognition Using Subject-Embedded Transfer Learning. (arXiv:2310.03752v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03752</link>
<description rdf:parseType="Literal">&lt;p&gt;Hand gesture recognition (HGR) has gained significant attention due to the
increasing use of AI-powered human-computer interfaces that can interpret the
deep spatiotemporal dynamics of biosignals from the peripheral nervous system,
such as surface electromyography (sEMG). These interfaces have a range of
applications, including the control of extended reality, agile prosthetics, and
exoskeletons. However, the natural variability of sEMG among individuals has
led researchers to focus on subject-specific solutions. Deep learning methods,
which often have complex structures, are particularly data-hungry and can be
time-consuming to train, making them less practical for subject-specific
applications. In this paper, we propose and develop a generalizable, sequential
decoder of transient high-density sEMG (HD-sEMG) that achieves 73% average
accuracy on 65 gestures for partially-observed subjects through
subject-embedded transfer learning, leveraging pre-knowledge of HGR acquired
during pre-training. The use of transient HD-sEMG before gesture stabilization
allows us to predict gestures with the ultimate goal of counterbalancing system
control delays. The results show that the proposed generalized models
significantly outperform subject-specific approaches, especially when the
training data is limited, and there is a significant number of gesture classes.
By building on pre-knowledge and incorporating a multiplicative
subject-embedded structure, our method comparatively achieves more than 13%
average accuracy across partially observed subjects with minimal data
availability. This work highlights the potential of HD-sEMG and demonstrates
the benefits of modeling common patterns across users to reduce the need for
large amounts of data for new users, enhancing practicality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Azar_G/0/1/0/all/0/1&quot;&gt;Golara Ahmadi Azar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hu_Q/0/1/0/all/0/1&quot;&gt;Qin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Emami_M/0/1/0/all/0/1&quot;&gt;Melika Emami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fletcher_A/0/1/0/all/0/1&quot;&gt;Alyson Fletcher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rangan_S/0/1/0/all/0/1&quot;&gt;Sundeep Rangan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Atashzar_S/0/1/0/all/0/1&quot;&gt;S. Farokh Atashzar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03753">
<title>ECGNet: A generative adversarial network (GAN) approach to the synthesis of 12-lead ECG signals from single lead inputs. (arXiv:2310.03753v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03753</link>
<description rdf:parseType="Literal">&lt;p&gt;Electrocardiography (ECG) signal generation has been heavily explored using
generative adversarial networks (GAN) because the implementation of 12-lead
ECGs is not always feasible. The GAN models have achieved remarkable results in
reproducing ECG signals but are only designed for multiple lead inputs and the
features the GAN model preserves have not been identified-limiting the
generated signals use in cardiovascular disease (CVD)-predictive models. This
paper presents ECGNet which is a procedure that generates a complete set of
12-lead ECG signals from any single lead input using a GAN framework with a
bidirectional long short-term memory (LSTM) generator and a convolutional
neural network (CNN) discriminator. Cross and auto-correlation analysis
performed on the generated signals identifies features conserved during the
signal generation-i.e., features that can characterize the unique-nature of
each signal and thus likely indicators of CVD. Finally, by using ECG signals
annotated with the CVD-indicative features detailed by the correlation analysis
as inputs for a CVD-onset-predictive CNN model, we overcome challenges
preventing the prediction of multiple-CVD targets. Our models are experimented
on 15s 12-lead ECG dataset recorded using MyoVista&apos;s wavECG. Functional outcome
data for each patient is recorded and used in the CVD-predictive model. Our
best GAN model achieves state-of-the-art accuracy with Frechet Distance (FD)
scores of 4.73, 4.89, 5.18, 4.77, 4.71, and 5.55 on the V1-V6 pre-cordial leads
respectively and shows strength in preserving the P-Q segments and R-peaks in
the generated signals. To the best of our knowledge, ECGNet is the first to
predict all of the remaining eleven leads from the input of any single lead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bagga_M/0/1/0/all/0/1&quot;&gt;Max Bagga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jeon_H/0/1/0/all/0/1&quot;&gt;Hyunbae Jeon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Issokson_A/0/1/0/all/0/1&quot;&gt;Alex Issokson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03754">
<title>EMGTFNet: Fuzzy Vision Transformer to decode Upperlimb sEMG signals for Hand Gestures Recognition. (arXiv:2310.03754v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03754</link>
<description rdf:parseType="Literal">&lt;p&gt;Myoelectric control is an area of electromyography of increasing interest
nowadays, particularly in applications such as Hand Gesture Recognition (HGR)
for bionic prostheses. Today&apos;s focus is on pattern recognition using Machine
Learning and, more recently, Deep Learning methods. Despite achieving good
results on sparse sEMG signals, the latter models typically require large
datasets and training times. Furthermore, due to the nature of stochastic sEMG
signals, traditional models fail to generalize samples for atypical or noisy
values. In this paper, we propose the design of a Vision Transformer (ViT)
based architecture with a Fuzzy Neural Block (FNB) called EMGTFNet to perform
Hand Gesture Recognition from surface electromyography (sEMG) signals. The
proposed EMGTFNet architecture can accurately classify a variety of hand
gestures without any need for data augmentation techniques, transfer learning
or a significant increase in the number of parameters in the network. The
accuracy of the proposed model is tested using the publicly available NinaPro
database consisting of 49 different hand gestures. Experiments yield an average
test accuracy of 83.57\% \&amp;amp; 3.5\% using a 200 ms window size and only 56,793
trainable parameters. Our results outperform the ViT without FNB, thus
demonstrating that including FNB improves its performance. Our proposal
framework EMGTFNet reported the significant potential for its practical
application for prosthetic control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cordova_J/0/1/0/all/0/1&quot;&gt;Joseph Cherre C&amp;#xf3;rdova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Flores_C/0/1/0/all/0/1&quot;&gt;Christian Flores&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Andreu_Perez_J/0/1/0/all/0/1&quot;&gt;Javier Andreu-Perez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03755">
<title>Physics Informed Neural Network Code for 2D Transient Problems (PINN-2DT) Compatible with Google Colab. (arXiv:2310.03755v1 [cs.CE])</title>
<link>http://arxiv.org/abs/2310.03755</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an open-source Physics Informed Neural Network environment for
simulations of transient phenomena on two-dimensional rectangular domains, with
the following features: (1) it is compatible with Google Colab which allows
automatic execution on cloud environment; (2) it supports two dimensional
time-dependent PDEs; (3) it provides simple interface for definition of the
residual loss, boundary condition and initial loss, together with their
weights; (4) it support Neumann and Dirichlet boundary conditions; (5) it
allows for customizing the number of layers and neurons per layer, as well as
for arbitrary activation function; (6) the learning rate and number of epochs
are available as parameters; (7) it automatically differentiates PINN with
respect to spatial and temporal variables; (8) it provides routines for
plotting the convergence (with running average), initial conditions learnt, 2D
and 3D snapshots from the simulation and movies (9) it includes a library of
problems: (a) non-stationary heat transfer; (b) wave equation modeling a
tsunami; (c) atmospheric simulations including thermal inversion; (d) tumor
growth simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maczuga_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; Maczuga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skoczen_M/0/1/0/all/0/1&quot;&gt;Maciej Skocze&amp;#x144;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roznawski_P/0/1/0/all/0/1&quot;&gt;Przemys&amp;#x142;aw Ro&amp;#x17c;nawski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tluszcz_F/0/1/0/all/0/1&quot;&gt;Filip T&amp;#x142;uszcz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szubert_M/0/1/0/all/0/1&quot;&gt;Marcin Szubert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Los_M/0/1/0/all/0/1&quot;&gt;Marcin &amp;#x141;o&amp;#x15b;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dzwinel_W/0/1/0/all/0/1&quot;&gt;Witold Dzwinel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pingali_K/0/1/0/all/0/1&quot;&gt;Keshav Pingali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paszynski_M/0/1/0/all/0/1&quot;&gt;Maciej Paszy&amp;#x144;ski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03756">
<title>A Multi-channel EEG Data Analysis for Poor Neuro-prognostication in Comatose Patients with Self and Cross-channel Attention Mechanism. (arXiv:2310.03756v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03756</link>
<description rdf:parseType="Literal">&lt;p&gt;This work investigates the predictive potential of bipolar
electroencephalogram (EEG) recordings towards efficient prediction of poor
neurological outcomes. A retrospective design using a hybrid deep learning
approach is utilized to optimize an objective function aiming for high
specificity, i.e., true positive rate (TPR) with reduced false positives (&amp;lt;
0.05). A multi-channel EEG array of 18 bipolar channel pairs from a randomly
selected 5-minute segment in an hour is kept. In order to determine the outcome
prediction, a combination of a feature encoder with 1-D convolutional layers,
learnable position encoding, a context network with attention mechanisms, and
finally, a regressor and classifier blocks are used. The feature encoder
extricates local temporal and spatial features, while the following position
encoding and attention mechanisms attempt to capture global temporal
dependencies. Results: The proposed framework by our team, OUS IVS, when
validated on the challenge hidden validation data, exhibited a score of 0.57.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Qadir_H/0/1/0/all/0/1&quot;&gt;Hemin Ali Qadir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nesaragi_N/0/1/0/all/0/1&quot;&gt;Naimahmed Nesaragi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1&quot;&gt;Per Steiner Halvorsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Balasingham_I/0/1/0/all/0/1&quot;&gt;Ilangko Balasingham&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03757">
<title>Enhancing Healthcare with EOG: A Novel Approach to Sleep Stage Classification. (arXiv:2310.03757v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03757</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce an innovative approach to automated sleep stage classification
using EOG signals, addressing the discomfort and impracticality associated with
EEG data acquisition. In addition, it is important to note that this approach
is untapped in the field, highlighting its potential for novel insights and
contributions. Our proposed SE-Resnet-Transformer model provides an accurate
classification of five distinct sleep stages from raw EOG signal. Extensive
validation on publically available databases (SleepEDF-20, SleepEDF-78, and
SHHS) reveals noteworthy performance, with macro-F1 scores of 74.72, 70.63, and
69.26, respectively. Our model excels in identifying REM sleep, a crucial
aspect of sleep disorder investigations. We also provide insight into the
internal mechanisms of our model using techniques such as 1D-GradCAM and t-SNE
plots. Our method improves the accessibility of sleep stage classification
while decreasing the need for EEG modalities. This development will have
promising implications for healthcare and the incorporation of wearable
technology into sleep studies, thereby advancing the field&apos;s potential for
enhanced diagnostics and patient comfort.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Maiti_S/0/1/0/all/0/1&quot;&gt;Suvadeep Maiti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sharma_S/0/1/0/all/0/1&quot;&gt;Shivam Kumar Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bapi_R/0/1/0/all/0/1&quot;&gt;Raju S. Bapi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03758">
<title>A Unified Framework for Uniform Signal Recovery in Nonlinear Generative Compressed Sensing. (arXiv:2310.03758v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03758</link>
<description rdf:parseType="Literal">&lt;p&gt;In generative compressed sensing (GCS), we want to recover a signal
$\mathbf{x}^* \in \mathbb{R}^n$ from $m$ measurements ($m\ll n$) using a
generative prior $\mathbf{x}^*\in G(\mathbb{B}_2^k(r))$, where $G$ is typically
an $L$-Lipschitz continuous generative model and $\mathbb{B}_2^k(r)$ represents
the radius-$r$ $\ell_2$-ball in $\mathbb{R}^k$. Under nonlinear measurements,
most prior results are non-uniform, i.e., they hold with high probability for a
fixed $\mathbf{x}^*$ rather than for all $\mathbf{x}^*$ simultaneously. In this
paper, we build a unified framework to derive uniform recovery guarantees for
nonlinear GCS where the observation model is nonlinear and possibly
discontinuous or unknown. Our framework accommodates GCS with 1-bit/uniformly
quantized observations and single index models as canonical examples.
Specifically, using a single realization of the sensing ensemble and
generalized Lasso, {\em all} $\mathbf{x}^*\in G(\mathbb{B}_2^k(r))$ can be
recovered up to an $\ell_2$-error at most $\epsilon$ using roughly
$\tilde{O}({k}/{\epsilon^2})$ samples, with omitted logarithmic factors
typically being dominated by $\log L$. Notably, this almost coincides with
existing non-uniform guarantees up to logarithmic factors, hence the uniformity
costs very little. As part of our technical contributions, we introduce the
Lipschitz approximation to handle discontinuous observation models. We also
develop a concentration inequality that produces tighter bounds for product
processes whose index sets have low metric entropy. Experimental results are
presented to corroborate our theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Junren Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Scarlett_J/0/1/0/all/0/1&quot;&gt;Jonathan Scarlett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ng_M/0/1/0/all/0/1&quot;&gt;Michael K. Ng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhaoqiang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03759">
<title>A Novel Deep Learning Technique for Morphology Preserved Fetal ECG Extraction from Mother ECG using 1D-CycleGAN. (arXiv:2310.03759v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03759</link>
<description rdf:parseType="Literal">&lt;p&gt;Monitoring the electrical pulse of fetal heart through a non-invasive fetal
electrocardiogram (fECG) can easily detect abnormalities in the developing
heart to significantly reduce the infant mortality rate and post-natal
complications. Due to the overlapping of maternal and fetal R-peaks, the low
amplitude of the fECG, systematic and ambient noises, typical signal extraction
methods, such as adaptive filters, independent component analysis, empirical
mode decomposition, etc., are unable to produce satisfactory fECG. While some
techniques can produce accurate QRS waves, they often ignore other important
aspects of the ECG. Our approach, which is based on 1D CycleGAN, can
reconstruct the fECG signal from the mECG signal while maintaining the
morphology due to extensive preprocessing and appropriate framework. The
performance of our solution was evaluated by combining two available datasets
from Physionet, &quot;Abdominal and Direct Fetal ECG Database&quot; and &quot;Fetal
electrocardiograms, direct and abdominal with reference heartbeat annotations&quot;,
where it achieved an average PCC and Spectral-Correlation score of 88.4% and
89.4%, respectively. It detects the fQRS of the signal with accuracy,
precision, recall and F1 score of 92.6%, 97.6%, 94.8% and 96.4%, respectively.
It can also accurately produce the estimation of fetal heart rate and R-R
interval with an error of 0.25% and 0.27%, respectively. The main contribution
of our work is that, unlike similar studies, it can retain the morphology of
the ECG signal with high fidelity. The accuracy of our solution for fetal heart
rate and R-R interval length is comparable to existing state-of-the-art
techniques. This makes it a highly effective tool for early diagnosis of fetal
heart diseases and regular health checkups of the fetus.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Basak_P/0/1/0/all/0/1&quot;&gt;Promit Basak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sakib_A/0/1/0/all/0/1&quot;&gt;A.H.M Nazmus Sakib&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chowdhury_M/0/1/0/all/0/1&quot;&gt;Muhammad E. H. Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Al_Emadi_N/0/1/0/all/0/1&quot;&gt;Nasser Al-Emadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yalcin_H/0/1/0/all/0/1&quot;&gt;Huseyin Cagatay Yalcin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pedersen_S/0/1/0/all/0/1&quot;&gt;Shona Pedersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mahmud_S/0/1/0/all/0/1&quot;&gt;Sakib Mahmud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kiranyaz_S/0/1/0/all/0/1&quot;&gt;Serkan Kiranyaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Al_Maadeed_S/0/1/0/all/0/1&quot;&gt;Somaya Al-Maadeed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03760">
<title>Investigating Deep Neural Network Architecture and Feature Extraction Designs for Sensor-based Human Activity Recognition. (arXiv:2310.03760v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2310.03760</link>
<description rdf:parseType="Literal">&lt;p&gt;The extensive ubiquitous availability of sensors in smart devices and the
Internet of Things (IoT) has opened up the possibilities for implementing
sensor-based activity recognition. As opposed to traditional sensor time-series
processing and hand-engineered feature extraction, in light of deep learning&apos;s
proven effectiveness across various domains, numerous deep methods have been
explored to tackle the challenges in activity recognition, outperforming the
traditional signal processing and traditional machine learning approaches. In
this work, by performing extensive experimental studies on two human activity
recognition datasets, we investigate the performance of common deep learning
and machine learning approaches as well as different training mechanisms (such
as contrastive learning), and various feature representations extracted from
the sensor time-series data and measure their effectiveness for the human
activity recognition task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ahangarani_D/0/1/0/all/0/1&quot;&gt;Danial Ahangarani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shirazi_M/0/1/0/all/0/1&quot;&gt;Mohammad Shirazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ashraf_N/0/1/0/all/0/1&quot;&gt;Navid Ashraf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03767">
<title>Deep Reinforcement Learning Algorithms for Hybrid V2X Communication: A Benchmarking Study. (arXiv:2310.03767v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03767</link>
<description rdf:parseType="Literal">&lt;p&gt;In today&apos;s era, autonomous vehicles demand a safety level on par with
aircraft. Taking a cue from the aerospace industry, which relies on redundancy
to achieve high reliability, the automotive sector can also leverage this
concept by building redundancy in V2X (Vehicle-to-Everything) technologies.
Given the current lack of reliable V2X technologies, this idea is particularly
promising. By deploying multiple RATs (Radio Access Technologies) in parallel,
the ongoing debate over the standard technology for future vehicles can be put
to rest. However, coordinating multiple communication technologies is a complex
task due to dynamic, time-varying channels and varying traffic conditions. This
paper addresses the vertical handover problem in V2X using Deep Reinforcement
Learning (DRL) algorithms. The goal is to assist vehicles in selecting the most
appropriate V2X technology (DSRC/V-VLC) in a serpentine environment. The
results show that the benchmarked algorithms outperform the current
state-of-the-art approaches in terms of redundancy and usage rate of V-VLC
headlights. This result is a significant reduction in communication costs while
maintaining a high level of reliability. These results provide strong evidence
for integrating advanced DRL decision mechanisms into the architecture as a
promising approach to solving the vertical handover problem in V2X.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boukhalfa_F/0/1/0/all/0/1&quot;&gt;Fouzi Boukhalfa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alami_R/0/1/0/all/0/1&quot;&gt;Reda Alami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achab_M/0/1/0/all/0/1&quot;&gt;Mastane Achab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moulines_E/0/1/0/all/0/1&quot;&gt;Eric Moulines&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1&quot;&gt;Mehdi Bennis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03770">
<title>Progressive reduced order modeling: empowering data-driven modeling with selective knowledge transfer. (arXiv:2310.03770v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03770</link>
<description rdf:parseType="Literal">&lt;p&gt;Data-driven modeling can suffer from a constant demand for data, leading to
reduced accuracy and impractical for engineering applications due to the high
cost and scarcity of information. To address this challenge, we propose a
progressive reduced order modeling framework that minimizes data cravings and
enhances data-driven modeling&apos;s practicality. Our approach selectively
transfers knowledge from previously trained models through gates, similar to
how humans selectively use valuable knowledge while ignoring unuseful
information. By filtering relevant information from previous models, we can
create a surrogate model with minimal turnaround time and a smaller training
set that can still achieve high accuracy. We have tested our framework in
several cases, including transport in porous media, gravity-driven flow, and
finite deformation in hyperelastic materials. Our results illustrate that
retaining information from previous models and utilizing a valuable portion of
that knowledge can significantly improve the accuracy of the current model. We
have demonstrated the importance of progressive knowledge transfer and its
impact on model accuracy with reduced training samples. For instance, our
framework with four parent models outperforms the no-parent counterpart trained
on data nine times larger. Our research unlocks data-driven modeling&apos;s
potential for practical engineering applications by mitigating the data
scarcity issue. Our proposed framework is a significant step toward more
efficient and cost-effective data-driven modeling, fostering advancements
across various fields.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadeethum_T/0/1/0/all/0/1&quot;&gt;Teeratorn Kadeethum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OMalley_D/0/1/0/all/0/1&quot;&gt;Daniel O&amp;#x27;Malley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1&quot;&gt;Youngsoo Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viswanathan_H/0/1/0/all/0/1&quot;&gt;Hari S. Viswanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_H/0/1/0/all/0/1&quot;&gt;Hongkyu Yoon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03772">
<title>Investigating Alternative Feature Extraction Pipelines For Clinical Note Phenotyping. (arXiv:2310.03772v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03772</link>
<description rdf:parseType="Literal">&lt;p&gt;A common practice in the medical industry is the use of clinical notes, which
consist of detailed patient observations. However, electronic health record
systems frequently do not contain these observations in a structured format,
rendering patient information challenging to assess and evaluate automatically.
Using computational systems for the extraction of medical attributes offers
many applications, including longitudinal analysis of patients, risk
assessment, and hospital evaluation. Recent work has constructed successful
methods for phenotyping: extracting medical attributes from clinical notes.
BERT-based models can be used to transform clinical notes into a series of
representations, which are then condensed into a single document representation
based on their CLS embeddings and passed into an LSTM (Mulyar et al., 2020).
Though this pipeline yields a considerable performance improvement over
previous results, it requires extensive convergence time. This method also does
not allow for predicting attributes not yet identified in clinical notes.
&lt;/p&gt;
&lt;p&gt;Considering the wide variety of medical attributes that may be present in a
clinical note, we propose an alternative pipeline utilizing ScispaCy (Neumann
et al., 2019) for the extraction of common diseases. We then train various
supervised learning models to associate the presence of these conditions with
patient attributes. Finally, we replicate a ClinicalBERT (Alsentzer et al.,
2019) and LSTM-based approach for purposes of comparison. We find that
alternative methods moderately underperform the replicated LSTM approach. Yet,
considering a complex tradeoff between accuracy and runtime, in addition to the
fact that the alternative approach also allows for the detection of medical
conditions that are not already present in a clinical note, its usage may be
considered as a supplement to established methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniel_N/0/1/0/all/0/1&quot;&gt;Neil Daniel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03773">
<title>Functional data learning using convolutional neural networks. (arXiv:2310.03773v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03773</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we show how convolutional neural networks (CNN) can be used in
regression and classification learning problems of noisy and non-noisy
functional data. The main idea is to transform the functional data into a 28 by
28 image. We use a specific but typical architecture of a convolutional neural
network to perform all the regression exercises of parameter estimation and
functional form classification. First, we use some functional case studies of
functional data with and without random noise to showcase the strength of the
new method. In particular, we use it to estimate exponential growth and decay
rates, the bandwidths of sine and cosine functions, and the magnitudes and
widths of curve peaks. We also use it to classify the monotonicity and
curvatures of functional data, algebraic versus exponential growth, and the
number of peaks of functional data. Second, we apply the same convolutional
neural networks to Lyapunov exponent estimation in noisy and non-noisy chaotic
data, in estimating rates of disease transmission from epidemic curves, and in
detecting the similarity of drug dissolution profiles. Finally, we apply the
method to real-life data to detect Parkinson&apos;s disease patients in a
classification problem. The method, although simple, shows high accuracy and is
promising for future use in engineering and medical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galarza_J/0/1/0/all/0/1&quot;&gt;Jose Galarza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oraby_T/0/1/0/all/0/1&quot;&gt;Tamer Oraby&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03778">
<title>Lightweight Boosting Models for User Response Prediction Using Adversarial Validation. (arXiv:2310.03778v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03778</link>
<description rdf:parseType="Literal">&lt;p&gt;The ACM RecSys Challenge 2023, organized by ShareChat, aims to predict the
probability of the app being installed. This paper describes the lightweight
solution to this challenge. We formulate the task as a user response prediction
task. For rapid prototyping for the task, we propose a lightweight solution
including the following steps: 1) using adversarial validation, we effectively
eliminate uninformative features from a dataset; 2) to address noisy continuous
features and categorical features with a large number of unique values, we
employ feature engineering techniques.; 3) we leverage Gradient Boosted
Decision Trees (GBDT) for their exceptional performance and scalability. The
experiments show that a single LightGBM model, without additional ensembling,
performs quite well. Our team achieved ninth place in the challenge with the
final leaderboard score of 6.059065. Code for our approach can be found here:
https://github.com/choco9966/recsys-challenge-2023.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyeonwoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1&quot;&gt;Wonsung Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03779">
<title>HandMeThat: Human-Robot Communication in Physical and Social Environments. (arXiv:2310.03779v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2310.03779</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce HandMeThat, a benchmark for a holistic evaluation of instruction
understanding and following in physical and social environments. While previous
datasets primarily focused on language grounding and planning, HandMeThat
considers the resolution of human instructions with ambiguities based on the
physical (object states and relations) and social (human actions and goals)
information. HandMeThat contains 10,000 episodes of human-robot interactions.
In each episode, the robot first observes a trajectory of human actions towards
her internal goal. Next, the robot receives a human instruction and should take
actions to accomplish the subgoal set through the instruction. In this paper,
we present a textual interface for our benchmark, where the robot interacts
with a virtual environment through textual commands. We evaluate several
baseline models on HandMeThat, and show that both offline and online
reinforcement learning algorithms perform poorly on HandMeThat, suggesting
significant room for future work on physical and social human-robot
communications and interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1&quot;&gt;Yanming Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1&quot;&gt;Jiayuan Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Joshua B. Tenenbaum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03789">
<title>Droplets of Good Representations: Grokking as a First Order Phase Transition in Two Layer Networks. (arXiv:2310.03789v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03789</link>
<description rdf:parseType="Literal">&lt;p&gt;A key property of deep neural networks (DNNs) is their ability to learn new
features during training. This intriguing aspect of deep learning stands out
most clearly in recently reported Grokking phenomena. While mainly reflected as
a sudden increase in test accuracy, Grokking is also believed to be a beyond
lazy-learning/Gaussian Process (GP) phenomenon involving feature learning. Here
we apply a recent development in the theory of feature learning, the adaptive
kernel approach, to two teacher-student models with cubic-polynomial and
modular addition teachers. We provide analytical predictions on feature
learning and Grokking properties of these models and demonstrate a mapping
between Grokking and the theory of phase transitions. We show that after
Grokking, the state of the DNN is analogous to the mixed phase following a
first-order phase transition. In this mixed phase, the DNN generates useful
internal representations of the teacher that are sharply distinct from those
before the transition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rubin_N/0/1/0/all/0/1&quot;&gt;Noa Rubin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1&quot;&gt;Inbar Seroussi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1&quot;&gt;Zohar Ringel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03812">
<title>Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs. (arXiv:2310.03812v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03812</link>
<description rdf:parseType="Literal">&lt;p&gt;Set-based learning is an essential component of modern deep learning and
network science. Graph Neural Networks (GNNs) and their edge-free counterparts
Deepsets have proven remarkably useful on ragged and topologically challenging
datasets. The key to learning informative embeddings for set members is a
specified aggregation function, usually a sum, max, or mean. We propose
Fishnets, an aggregation strategy for learning information-optimal embeddings
for sets of data for both Bayesian inference and graph aggregation. We
demonstrate that i) Fishnets neural summaries can be scaled optimally to an
arbitrary number of data objects, ii) Fishnets aggregations are robust to
changes in data distribution, unlike standard deepsets, iii) Fishnets saturate
Bayesian information content and extend to regimes where MCMC techniques fail
and iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. We
show that by adopting a Fishnets aggregation scheme for message passing, GNNs
can achieve state-of-the-art performance versus architecture size on
ogbn-protein data over existing benchmarks with a fraction of learnable
parameters and faster training time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makinen_T/0/1/0/all/0/1&quot;&gt;T. Lucas Makinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alsing_J/0/1/0/all/0/1&quot;&gt;Justin Alsing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wandelt_B/0/1/0/all/0/1&quot;&gt;Benjamin D. Wandelt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03817">
<title>Logical Languages Accepted by Transformer Encoders with Hard Attention. (arXiv:2310.03817v1 [cs.FL])</title>
<link>http://arxiv.org/abs/2310.03817</link>
<description rdf:parseType="Literal">&lt;p&gt;We contribute to the study of formal languages that can be recognized by
transformer encoders. We focus on two self-attention mechanisms: (1) UHAT
(Unique Hard Attention Transformers) and (2) AHAT (Average Hard Attention
Transformers). UHAT encoders are known to recognize only languages inside the
circuit complexity class ${\sf AC}^0$, i.e., accepted by a family of poly-sized
and depth-bounded boolean circuits with unbounded fan-ins. On the other hand,
AHAT encoders can recognize languages outside ${\sf AC}^0$), but their
expressive power still lies within the bigger circuit complexity class ${\sf
TC}^0$, i.e., ${\sf AC}^0$-circuits extended by majority gates. We first show a
negative result that there is an ${\sf AC}^0$-language that cannot be
recognized by an UHAT encoder. On the positive side, we show that UHAT encoders
can recognize a rich fragment of ${\sf AC}^0$-languages, namely, all languages
definable in first-order logic with arbitrary unary numerical predicates. This
logic, includes, for example, all regular languages from ${\sf AC}^0$. We then
show that AHAT encoders can recognize all languages of our logic even when we
enrich it with counting terms. We apply these results to derive new results on
the expressive power of UHAT and AHAT up to permutation of letters (a.k.a.
Parikh images).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barcelo_P/0/1/0/all/0/1&quot;&gt;Pablo Barcelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozachinskiy_A/0/1/0/all/0/1&quot;&gt;Alexander Kozachinskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_A/0/1/0/all/0/1&quot;&gt;Anthony Widjaja Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Podolskii_V/0/1/0/all/0/1&quot;&gt;Vladimir Podolskii&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03823">
<title>ECAvg: An Edge-Cloud Collaborative Learning Approach using Averaged Weights. (arXiv:2310.03823v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03823</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of edge devices together with cloud provides a collaborative
relationship between both classes of devices where one complements the
shortcomings of the other. Resource-constraint edge devices can benefit from
the abundant computing power provided by servers by offloading computationally
intensive tasks to the server. Meanwhile, edge devices can leverage their close
proximity to the data source to perform less computationally intensive tasks on
the data. In this paper, we propose a collaborative edge-cloud paradigm called
ECAvg in which edge devices pre-train local models on their respective datasets
and transfer the models to the server for fine-tuning. The server averages the
pre-trained weights into a global model, which is fine-tuned on the combined
data from the various edge devices. The local (edge) models are then updated
with the weights of the global (server) model. We implement a CIFAR-10
classification task using MobileNetV2, a CIFAR-100 classification task using
ResNet50, and an MNIST classification using a neural network with a single
hidden layer. We observed performance improvement in the CIFAR-10 and CIFAR-100
classification tasks using our approach, where performance improved on the
server model with averaged weights and the edge models had a better performance
after model update. On the MNIST classification, averaging weights resulted in
a drop in performance on both the server and edge models due to negative
transfer learning. From the experiment results, we conclude that our approach
is successful when implemented on deep neural networks such as MobileNetV2 and
ResNet50 instead of simple neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mih_A/0/1/0/all/0/1&quot;&gt;Atah Nuh Mih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1&quot;&gt;Hung Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawnine_A/0/1/0/all/0/1&quot;&gt;Asfia Kawnine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wachowicz_M/0/1/0/all/0/1&quot;&gt;Monica Wachowicz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03833">
<title>Learning A Disentangling Representation For PU Learning. (arXiv:2310.03833v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03833</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we address the problem of learning a binary (positive vs.
negative) classifier given Positive and Unlabeled data commonly referred to as
PU learning. Although rudimentary techniques like clustering,
out-of-distribution detection, or positive density estimation can be used to
solve the problem in low-dimensional settings, their efficacy progressively
deteriorates with higher dimensions due to the increasing complexities in the
data distribution. In this paper we propose to learn a neural network-based
data representation using a loss function that can be used to project the
unlabeled data into two (positive and negative) clusters that can be easily
identified using simple clustering techniques, effectively emulating the
phenomenon observed in low-dimensional settings. We adopt a vector quantization
technique for the learned representations to amplify the separation between the
learned unlabeled data clusters. We conduct experiments on simulated PU data
that demonstrate the improved performance of our proposed method compared to
the current state-of-the-art approaches. We also provide some theoretical
justification for our two cluster-based approach and our algorithmic choices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamzam_O/0/1/0/all/0/1&quot;&gt;Omar Zamzam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akrami_H/0/1/0/all/0/1&quot;&gt;Haleh Akrami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1&quot;&gt;Mahdi Soltanolkotabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leahy_R/0/1/0/all/0/1&quot;&gt;Richard Leahy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03838">
<title>Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning. (arXiv:2310.03838v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03838</link>
<description rdf:parseType="Literal">&lt;p&gt;The integration of machine learning (ML) in numerous critical applications
introduces a range of privacy concerns for individuals who provide their
datasets for model training. One such privacy risk is Membership Inference
(MI), in which an attacker seeks to determine whether a particular data sample
was included in the training dataset of a model. Current state-of-the-art MI
attacks capitalize on access to the model&apos;s predicted confidence scores to
successfully perform membership inference, and employ data poisoning to further
enhance their effectiveness. In this work, we focus on the less explored and
more realistic label-only setting, where the model provides only the predicted
label on a queried sample. We show that existing label-only MI attacks are
ineffective at inferring membership in the low False Positive Rate (FPR)
regime. To address this challenge, we propose a new attack Chameleon that
leverages a novel adaptive data poisoning strategy and an efficient query
selection method to achieve significantly more accurate membership inference
than existing label-only attacks, especially at low FPRs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhari_H/0/1/0/all/0/1&quot;&gt;Harsh Chaudhari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Severi_G/0/1/0/all/0/1&quot;&gt;Giorgio Severi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oprea_A/0/1/0/all/0/1&quot;&gt;Alina Oprea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ullman_J/0/1/0/all/0/1&quot;&gt;Jonathan Ullman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03840">
<title>Contextualized Structural Self-supervised Learning for Ontology Matching. (arXiv:2310.03840v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03840</link>
<description rdf:parseType="Literal">&lt;p&gt;Ontology matching (OM) entails the identification of semantic relationships
between concepts within two or more knowledge graphs (KGs) and serves as a
critical step in integrating KGs from various sources. Recent advancements in
deep OM models have harnessed the power of transformer-based language models
and the advantages of knowledge graph embedding. Nevertheless, these OM models
still face persistent challenges, such as a lack of reference alignments,
runtime latency, and unexplored different graph structures within an end-to-end
framework. In this study, we introduce a novel self-supervised learning OM
framework with input ontologies, called LaKERMap. This framework capitalizes on
the contextual and structural information of concepts by integrating implicit
knowledge into transformers. Specifically, we aim to capture multiple
structural contexts, encompassing both local and global interactions, by
employing distinct training objectives. To assess our methods, we utilize the
Bio-ML datasets and tasks. The findings from our innovative approach reveal
that LaKERMap surpasses state-of-the-art systems in terms of alignment quality
and inference time. Our models and codes are available here:
https://github.com/ellenzhuwang/lakermap.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03843">
<title>Less is More: On the Feature Redundancy of Pretrained Models When Transferring to Few-shot Tasks. (arXiv:2310.03843v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03843</link>
<description rdf:parseType="Literal">&lt;p&gt;Transferring a pretrained model to a downstream task can be as easy as
conducting linear probing with target data, that is, training a linear
classifier upon frozen features extracted from the pretrained model. As there
may exist significant gaps between pretraining and downstream datasets, one may
ask whether all dimensions of the pretrained features are useful for a given
downstream task. We show that, for linear probing, the pretrained features can
be extremely redundant when the downstream data is scarce, or few-shot. For
some cases such as 5-way 1-shot tasks, using only 1\% of the most important
feature dimensions is able to recover the performance achieved by using the
full representation. Interestingly, most dimensions are redundant only under
few-shot settings and gradually become useful when the number of shots
increases, suggesting that feature redundancy may be the key to characterizing
the &quot;few-shot&quot; nature of few-shot transfer problems. We give a theoretical
understanding of this phenomenon and show how dimensions with high variance and
small distance between class centroids can serve as confounding factors that
severely disturb classification results under few-shot settings. As an attempt
at solving this problem, we find that the redundant features are difficult to
identify accurately with a small number of training samples, but we can instead
adjust feature magnitude with a soft mask based on estimated feature
importance. We show that this method can generally improve few-shot transfer
performance across various pretrained models and downstream datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xu Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1&quot;&gt;Difan Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1&quot;&gt;Lianli Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zenglin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jingkuan Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03845">
<title>Euclid: Identification of asteroid streaks in simulated images using deep learning. (arXiv:2310.03845v1 [astro-ph.EP])</title>
<link>http://arxiv.org/abs/2310.03845</link>
<description rdf:parseType="Literal">&lt;p&gt;Up to 150000 asteroids will be visible in the images of the ESA Euclid space
telescope, and the instruments of Euclid offer multiband visual to
near-infrared photometry and slitless spectra of these objects. Most asteroids
will appear as streaks in the images. Due to the large number of images and
asteroids, automated detection methods are needed. A non-machine-learning
approach based on the StreakDet software was previously tested, but the results
were not optimal for short and/or faint streaks. We set out to improve the
capability to detect asteroid streaks in Euclid images by using deep learning.
&lt;/p&gt;
&lt;p&gt;We built, trained, and tested a three-step machine-learning pipeline with
simulated Euclid images. First, a convolutional neural network (CNN) detected
streaks and their coordinates in full images, aiming to maximize the
completeness (recall) of detections. Then, a recurrent neural network (RNN)
merged snippets of long streaks detected in several parts by the CNN. Lastly,
gradient-boosted trees (XGBoost) linked detected streaks between different
Euclid exposures to reduce the number of false positives and improve the purity
(precision) of the sample.
&lt;/p&gt;
&lt;p&gt;The deep-learning pipeline surpasses the completeness and reaches a similar
level of purity of a non-machine-learning pipeline based on the StreakDet
software. Additionally, the deep-learning pipeline can detect asteroids
0.25-0.5 magnitudes fainter than StreakDet. The deep-learning pipeline could
result in a 50% increase in the number of detected asteroids compared to the
StreakDet software. There is still scope for further refinement, particularly
in improving the accuracy of streak coordinates and enhancing the completeness
of the final stage of the pipeline, which involves linking detections across
multiple exposures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Pontinen_M/0/1/0/all/0/1&quot;&gt;M. P&amp;#xf6;ntinen&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Granvik_M/0/1/0/all/0/1&quot;&gt;M. Granvik&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Nucita_A/0/1/0/all/0/1&quot;&gt;A. A. Nucita&lt;/a&gt; (3 and 4 and 5), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Conversi_L/0/1/0/all/0/1&quot;&gt;L. Conversi&lt;/a&gt; (6 and 7), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Altieri_B/0/1/0/all/0/1&quot;&gt;B. Altieri&lt;/a&gt; (7), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Carry_B/0/1/0/all/0/1&quot;&gt;B. Carry&lt;/a&gt; (8), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+ORiordan_C/0/1/0/all/0/1&quot;&gt;C. M. O&amp;#x27;Riordan&lt;/a&gt; (9), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Scott_D/0/1/0/all/0/1&quot;&gt;D. Scott&lt;/a&gt; (10), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Aghanim_N/0/1/0/all/0/1&quot;&gt;N. Aghanim&lt;/a&gt; (11), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Amara_A/0/1/0/all/0/1&quot;&gt;A. Amara&lt;/a&gt; (12), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Amendola_L/0/1/0/all/0/1&quot;&gt;L. Amendola&lt;/a&gt; (13), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Auricchio_N/0/1/0/all/0/1&quot;&gt;N. Auricchio&lt;/a&gt; (14), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Baldi_M/0/1/0/all/0/1&quot;&gt;M. Baldi&lt;/a&gt; (15 and 14 and 16), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Bonino_D/0/1/0/all/0/1&quot;&gt;D. Bonino&lt;/a&gt; (17), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Branchini_E/0/1/0/all/0/1&quot;&gt;E. Branchini&lt;/a&gt; (18 and 19), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Brescia_M/0/1/0/all/0/1&quot;&gt;M. Brescia&lt;/a&gt; (20 and 21), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Camera_S/0/1/0/all/0/1&quot;&gt;S. Camera&lt;/a&gt; (22 and 23 and 17), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Capobianco_V/0/1/0/all/0/1&quot;&gt;V. Capobianco&lt;/a&gt; (17), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Carbone_C/0/1/0/all/0/1&quot;&gt;C. Carbone&lt;/a&gt; (24), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Carretero_J/0/1/0/all/0/1&quot;&gt;J. Carretero&lt;/a&gt; (25 and 26), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Castellano_M/0/1/0/all/0/1&quot;&gt;M. Castellano&lt;/a&gt; (27), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Cavuoti_S/0/1/0/all/0/1&quot;&gt;S. Cavuoti&lt;/a&gt; (21 and 28), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Cimatti_A/0/1/0/all/0/1&quot;&gt;A. Cimatti&lt;/a&gt; (29), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Cledassou_R/0/1/0/all/0/1&quot;&gt;R. Cledassou&lt;/a&gt; (30 and 31), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Congedo_G/0/1/0/all/0/1&quot;&gt;G. Congedo&lt;/a&gt; (32), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Copin_Y/0/1/0/all/0/1&quot;&gt;Y. Copin&lt;/a&gt; (33), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Corcione_L/0/1/0/all/0/1&quot;&gt;L. Corcione&lt;/a&gt; (17), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Courbin_F/0/1/0/all/0/1&quot;&gt;F. Courbin&lt;/a&gt; (34), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Cropper_M/0/1/0/all/0/1&quot;&gt;M. Cropper&lt;/a&gt; (35), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Silva_A/0/1/0/all/0/1&quot;&gt;A. Da Silva&lt;/a&gt; (36 and 37), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Degaudenzi_H/0/1/0/all/0/1&quot;&gt;H. Degaudenzi&lt;/a&gt; (38), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Dinis_J/0/1/0/all/0/1&quot;&gt;J. Dinis&lt;/a&gt; (37 and 36), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Dubath_F/0/1/0/all/0/1&quot;&gt;F. Dubath&lt;/a&gt; (38), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Dupac_X/0/1/0/all/0/1&quot;&gt;X. Dupac&lt;/a&gt; (7), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Dusini_S/0/1/0/all/0/1&quot;&gt;S. Dusini&lt;/a&gt; (39), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Farrens_S/0/1/0/all/0/1&quot;&gt;S. Farrens&lt;/a&gt; (40), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Ferriol_S/0/1/0/all/0/1&quot;&gt;S. Ferriol&lt;/a&gt; (33), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Frailis_M/0/1/0/all/0/1&quot;&gt;M. Frailis&lt;/a&gt; (41), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Franceschi_E/0/1/0/all/0/1&quot;&gt;E. Franceschi&lt;/a&gt; (14), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Fumana_M/0/1/0/all/0/1&quot;&gt;M. Fumana&lt;/a&gt; (24), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Galeotta_S/0/1/0/all/0/1&quot;&gt;S. Galeotta&lt;/a&gt; (41), et al. (76 additional authors not shown)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03848">
<title>OpenIncrement: A Unified Framework for Open Set Recognition and Deep Class-Incremental Learning. (arXiv:2310.03848v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03848</link>
<description rdf:parseType="Literal">&lt;p&gt;In most works on deep incremental learning research, it is assumed that novel
samples are pre-identified for neural network retraining. However, practical
deep classifiers often misidentify these samples, leading to erroneous
predictions. Such misclassifications can degrade model performance. Techniques
like open set recognition offer a means to detect these novel samples,
representing a significant area in the machine learning domain.
&lt;/p&gt;
&lt;p&gt;In this paper, we introduce a deep class-incremental learning framework
integrated with open set recognition. Our approach refines class-incrementally
learned features to adapt them for distance-based open set recognition.
Experimental results validate that our method outperforms state-of-the-art
incremental learning techniques and exhibits superior performance in open set
recognition compared to baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiawen Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grohnfeldt_C/0/1/0/all/0/1&quot;&gt;Claas Grohnfeldt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kao_O/0/1/0/all/0/1&quot;&gt;Odej Kao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03861">
<title>Variational Barycentric Coordinates. (arXiv:2310.03861v1 [cs.GR])</title>
<link>http://arxiv.org/abs/2310.03861</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a variational technique to optimize for generalized barycentric
coordinates that offers additional control compared to existing models. Prior
work represents barycentric coordinates using meshes or closed-form formulae,
in practice limiting the choice of objective function. In contrast, we directly
parameterize the continuous function that maps any coordinate in a polytope&apos;s
interior to its barycentric coordinates using a neural field. This formulation
is enabled by our theoretical characterization of barycentric coordinates,
which allows us to construct neural fields that parameterize the entire
function class of valid coordinates. We demonstrate the flexibility of our
model using a variety of objective functions, including multiple smoothness and
deformation-aware energies; as a side contribution, we also present
mathematically-justified means of measuring and minimizing objectives like
total variation on discontinuous neural fields. We offer a practical
acceleration strategy, present a thorough validation of our algorithm, and
demonstrate several applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dodik_A/0/1/0/all/0/1&quot;&gt;Ana Dodik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stein_O/0/1/0/all/0/1&quot;&gt;Oded Stein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1&quot;&gt;Vincent Sitzmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1&quot;&gt;Justin Solomon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03865">
<title>Model Complexity of Program Phases. (arXiv:2310.03865v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03865</link>
<description rdf:parseType="Literal">&lt;p&gt;In resource limited computing systems, sequence prediction models must
operate under tight constraints. Various models are available that cater to
prediction under these conditions that in some way focus on reducing the cost
of implementation. These resource constrained sequence prediction models, in
practice, exhibit a fundamental tradeoff between the cost of implementation and
the quality of its predictions. This fundamental tradeoff seems to be largely
unexplored for models for different tasks. Here we formulate the necessary
theory and an associated empirical procedure to explore this tradeoff space for
a particular family of machine learning models such as deep neural networks. We
anticipate that the knowledge of the behavior of this tradeoff may be
beneficial in understanding the theoretical and practical limits of creation
and deployment of models for resource constrained tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karuvally_A/0/1/0/all/0/1&quot;&gt;Arjun Karuvally&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moss_J/0/1/0/all/0/1&quot;&gt;J. Eliot B. Moss&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03879">
<title>Non Commutative Convolutional Signal Models in Neural Networks: Stability to Small Deformations. (arXiv:2310.03879v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03879</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we discuss the results recently published in~[1] about
algebraic signal models (ASMs) based on non commutative algebras and their use
in convolutional neural networks. Relying on the general tools from algebraic
signal processing (ASP), we study the filtering and stability properties of non
commutative convolutional filters. We show how non commutative filters can be
stable to small perturbations on the space of operators. We also show that
although the spectral components of the Fourier representation in a non
commutative signal model are associated to spaces of dimension larger than one,
there is a trade-off between stability and selectivity similar to that observed
for commutative models. Our results have direct implications for group neural
networks, multigraph neural networks and quaternion neural networks, among
other non commutative architectures. We conclude by corroborating these results
through numerical experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parada_Mayorga_A/0/1/0/all/0/1&quot;&gt;Alejandro Parada-Mayorga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Butler_L/0/1/0/all/0/1&quot;&gt;Landon Butler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Alejandro Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03882">
<title>Small batch deep reinforcement learning. (arXiv:2310.03882v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03882</link>
<description rdf:parseType="Literal">&lt;p&gt;In value-based deep reinforcement learning with replay memories, the batch
size parameter specifies how many transitions to sample for each gradient
update. Although critical to the learning process, this value is typically not
adjusted when proposing new algorithms. In this work we present a broad
empirical study that suggests {\em reducing} the batch size can result in a
number of significant performance gains; this is surprising, as the general
tendency when training neural networks is towards larger batch sizes for
improved performance. We complement our experimental findings with a set of
empirical analyses towards better understanding this phenomenon.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obando_Ceron_J/0/1/0/all/0/1&quot;&gt;Johan Obando-Ceron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellemare_M/0/1/0/all/0/1&quot;&gt;Marc G. Bellemare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castro_P/0/1/0/all/0/1&quot;&gt;Pablo Samuel Castro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03884">
<title>Information Geometry for the Working Information Theorist. (arXiv:2310.03884v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2310.03884</link>
<description rdf:parseType="Literal">&lt;p&gt;Information geometry is a study of statistical manifolds, that is, spaces of
probability distributions from a geometric perspective. Its classical
information-theoretic applications relate to statistical concepts such as
Fisher information, sufficient statistics, and efficient estimators. Today,
information geometry has emerged as an interdisciplinary field that finds
applications in diverse areas such as radar sensing, array signal processing,
quantum physics, deep learning, and optimal transport. This article presents an
overview of essential information geometry to initiate an information theorist,
who may be unfamiliar with this exciting area of research. We explain the
concepts of divergences on statistical manifolds, generalized notions of
distances, orthogonality, and geodesics, thereby paving the way for concrete
applications and novel theoretical investigations. We also highlight some
recent information-geometric developments, which are of interest to the broader
information theory community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_K/0/1/0/all/0/1&quot;&gt;Kumar Vijay Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1&quot;&gt;M. Ashok Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1&quot;&gt;Ting-Kam Leonard Wong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03890">
<title>Accelerated Neural Network Training with Rooted Logistic Objectives. (arXiv:2310.03890v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03890</link>
<description rdf:parseType="Literal">&lt;p&gt;Many neural networks deployed in the real world scenarios are trained using
cross entropy based loss functions. From the optimization perspective, it is
known that the behavior of first order methods such as gradient descent
crucially depend on the separability of datasets. In fact, even in the most
simplest case of binary classification, the rate of convergence depends on two
factors: (1) condition number of data matrix, and (2) separability of the
dataset. With no further pre-processing techniques such as
over-parametrization, data augmentation etc., separability is an intrinsic
quantity of the data distribution under consideration. We focus on the
landscape design of the logistic function and derive a novel sequence of {\em
strictly} convex functions that are at least as strict as logistic loss. The
minimizers of these functions coincide with those of the minimum norm solution
wherever possible. The strict convexity of the derived function can be extended
to finetune state-of-the-art models and applications. In empirical experimental
analysis, we apply our proposed rooted logistic objective to multiple deep
models, e.g., fully-connected neural networks and transformers, on various of
classification benchmarks. Our results illustrate that training with rooted
loss function is converged faster and gains performance improvements.
Furthermore, we illustrate applications of our novel rooted loss function in
generative modeling based downstream applications, such as finetuning StyleGAN
model with the rooted loss. The code implementing our losses and models can be
found here for open source software development purposes:
https://anonymous.4open.science/r/rooted_loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veluswami_P/0/1/0/all/0/1&quot;&gt;Praveen Raj Veluswami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_H/0/1/0/all/0/1&quot;&gt;Harsh Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravi_S/0/1/0/all/0/1&quot;&gt;Sathya N. Ravi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03898">
<title>Class-Incremental Learning Using Generative Experience Replay Based on Time-aware Regularization. (arXiv:2310.03898v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03898</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning new tasks accumulatively without forgetting remains a critical
challenge in continual learning. Generative experience replay addresses this
challenge by synthesizing pseudo-data points for past learned tasks and later
replaying them for concurrent training along with the new tasks&apos; data.
Generative replay is the best strategy for continual learning under a strict
class-incremental setting when certain constraints need to be met: (i) constant
model size, (ii) no pre-training dataset, and (iii) no memory buffer for
storing past tasks&apos; data. Inspired by the biological nervous system mechanisms,
we introduce a time-aware regularization method to dynamically fine-tune the
three training objective terms used for generative replay: supervised learning,
latent regularization, and data reconstruction. Experimental results on major
benchmarks indicate that our method pushes the limit of brain-inspired
continual learners under such strict settings, improves memory retention, and
increases the average performance over continually arriving tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zizhao Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rostami_M/0/1/0/all/0/1&quot;&gt;Mohammad Rostami&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03899">
<title>CrysFormer: Protein Structure Prediction via 3d Patterson Maps and Partial Structure Attention. (arXiv:2310.03899v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03899</link>
<description rdf:parseType="Literal">&lt;p&gt;Determining the structure of a protein has been a decades-long open question.
A protein&apos;s three-dimensional structure often poses nontrivial computation
costs, when classical simulation algorithms are utilized. Advances in the
transformer neural network architecture -- such as AlphaFold2 -- achieve
significant improvements for this problem, by learning from a large dataset of
sequence information and corresponding protein structures. Yet, such methods
only focus on sequence information; other available prior knowledge, such as
protein crystallography and partial structure of amino acids, could be
potentially utilized. To the best of our knowledge, we propose the first
transformer-based model that directly utilizes protein crystallography and
partial structure information to predict the electron density maps of proteins.
Via two new datasets of peptide fragments (2-residue and 15-residue) , we
demonstrate our method, dubbed \texttt{CrysFormer}, can achieve accurate
predictions, based on a much smaller dataset size and with reduced computation
costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1&quot;&gt;Chen Dun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1&quot;&gt;Qiutai Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1&quot;&gt;Shikai Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stevens_R/0/1/0/all/0/1&quot;&gt;Ria Stevens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_M/0/1/0/all/0/1&quot;&gt;Mitchell D. Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_G/0/1/0/all/0/1&quot;&gt;George N. Phillips, Jr.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03902">
<title>Provable benefits of annealing for estimating normalizing constants: Importance Sampling, Noise-Contrastive Estimation, and beyond. (arXiv:2310.03902v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03902</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent research has developed several Monte Carlo methods for estimating the
normalization constant (partition function) based on the idea of annealing.
This means sampling successively from a path of distributions that interpolate
between a tractable &quot;proposal&quot; distribution and the unnormalized &quot;target&quot;
distribution. Prominent estimators in this family include annealed importance
sampling and annealed noise-contrastive estimation (NCE). Such methods hinge on
a number of design choices: which estimator to use, which path of distributions
to use and whether to use a path at all; so far, there is no definitive theory
on which choices are efficient. Here, we evaluate each design choice by the
asymptotic estimation error it produces. First, we show that using NCE is more
efficient than the importance sampling estimator, but in the limit of
infinitesimal path steps, the difference vanishes. Second, we find that using
the geometric path brings down the estimation error from an exponential to a
polynomial function of the parameter distance between the target and proposal
distributions. Third, we find that the arithmetic path, while rarely used, can
offer optimality properties over the universally-used geometric path. In fact,
in a particular limit, the optimal path is arithmetic. Based on this theory, we
finally propose a two-step estimator to approximate the optimal path in an
efficient way.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chehab_O/0/1/0/all/0/1&quot;&gt;Omar Chehab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hyvarinen_A/0/1/0/all/0/1&quot;&gt;Aapo Hyvarinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Risteski_A/0/1/0/all/0/1&quot;&gt;Andrej Risteski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03906">
<title>PyDCM: Custom Data Center Models with Reinforcement Learning for Sustainability. (arXiv:2310.03906v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03906</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing global emphasis on sustainability and reducing carbon
emissions is pushing governments and corporations to rethink their approach to
data center design and operation. Given their high energy consumption and
exponentially large computational workloads, data centers are prime candidates
for optimizing power consumption, especially in areas such as cooling and IT
energy usage. A significant challenge in this pursuit is the lack of a
configurable and scalable thermal data center model that offers an end-to-end
pipeline. Data centers consist of multiple IT components whose geometric
configuration and heat dissipation make thermal modeling difficult. This paper
presents PyDCM, a customizable Data Center Model implemented in Python, that
allows users to create unique configurations of IT equipment with custom server
specifications and geometric arrangements of IT cabinets. The use of vectorized
thermal calculations makes PyDCM orders of magnitude faster (30 times) than
current Energy Plus modeling implementations and scales sublinearly with the
number of CPUs. Also, PyDCM enables the use of Deep Reinforcement Learning via
the Gymnasium wrapper to optimize data center cooling and offers a
user-friendly platform for testing various data center design prototypes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naug_A/0/1/0/all/0/1&quot;&gt;Avisek Naug&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guillen_A/0/1/0/all/0/1&quot;&gt;Antonio Guillen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1&quot;&gt;Ricardo Luna Guti&amp;#xe9;rrez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gundecha_V/0/1/0/all/0/1&quot;&gt;Vineet Gundecha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markovikj_D/0/1/0/all/0/1&quot;&gt;Dejan Markovikj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kashyap_L/0/1/0/all/0/1&quot;&gt;Lekhapriya Dheeraj Kashyap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_L/0/1/0/all/0/1&quot;&gt;Lorenz Krause&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghorbanpour_S/0/1/0/all/0/1&quot;&gt;Sahand Ghorbanpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mousavi_S/0/1/0/all/0/1&quot;&gt;Sajad Mousavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babu_A/0/1/0/all/0/1&quot;&gt;Ashwin Ramesh Babu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1&quot;&gt;Soumyendu Sarkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03912">
<title>RTDK-BO: High Dimensional Bayesian Optimization with Reinforced Transformer Deep kernels. (arXiv:2310.03912v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03912</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian Optimization (BO), guided by Gaussian process (GP) surrogates, has
proven to be an invaluable technique for efficient, high-dimensional, black-box
optimization, a critical problem inherent to many applications such as
industrial design and scientific computing. Recent contributions have
introduced reinforcement learning (RL) to improve the optimization performance
on both single function optimization and \textit{few-shot} multi-objective
optimization. However, even few-shot techniques fail to exploit similarities
shared between closely related objectives. In this paper, we combine recent
developments in Deep Kernel Learning (DKL) and attention-based Transformer
models to improve the modeling powers of GP surrogates with meta-learning. We
propose a novel method for improving meta-learning BO surrogates by
incorporating attention mechanisms into DKL, empowering the surrogates to adapt
to contextual information gathered during the BO process. We combine this
Transformer Deep Kernel with a learned acquisition function trained with
continuous Soft Actor-Critic Reinforcement Learning to aid in exploration. This
Reinforced Transformer Deep Kernel (RTDK-BO) approach yields state-of-the-art
results in continuous high-dimensional optimization problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shmakov_A/0/1/0/all/0/1&quot;&gt;Alexander Shmakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naug_A/0/1/0/all/0/1&quot;&gt;Avisek Naug&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gundecha_V/0/1/0/all/0/1&quot;&gt;Vineet Gundecha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghorbanpour_S/0/1/0/all/0/1&quot;&gt;Sahand Ghorbanpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1&quot;&gt;Ricardo Luna Gutierrez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babu_A/0/1/0/all/0/1&quot;&gt;Ashwin Ramesh Babu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guillen_A/0/1/0/all/0/1&quot;&gt;Antonio Guillen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1&quot;&gt;Soumyendu Sarkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03915">
<title>Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control. (arXiv:2310.03915v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03915</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing autonomous agents that can interact with changing environments is
an open challenge in machine learning. Robustness is particularly important in
these settings as agents are often fit offline on expert demonstrations but
deployed online where they must generalize to the closed feedback loop within
the environment. In this work, we explore the application of recurrent neural
networks to tasks of this nature and understand how a parameterization of their
recurrent connectivity influences robustness in closed-loop settings.
Specifically, we represent the recurrent connectivity as a function of rank and
sparsity and show both theoretically and empirically that modulating these two
variables has desirable effects on network dynamics. The proposed low-rank,
sparse connectivity induces an interpretable prior on the network that proves
to be most amenable for a class of models known as closed-form continuous-time
neural networks (CfCs). We find that CfCs with fewer parameters can outperform
their full-rank, fully-connected counterparts in the online setting under
distribution shift. This yields memory-efficient and robust agents while
opening a new perspective on how we can modulate network dynamics through
connectivity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tumma_N/0/1/0/all/0/1&quot;&gt;Neehal Tumma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lechner_M/0/1/0/all/0/1&quot;&gt;Mathias Lechner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loo_N/0/1/0/all/0/1&quot;&gt;Noel Loo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasani_R/0/1/0/all/0/1&quot;&gt;Ramin Hasani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1&quot;&gt;Daniela Rus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03916">
<title>Toward a Foundation Model for Time Series Data. (arXiv:2310.03916v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03916</link>
<description rdf:parseType="Literal">&lt;p&gt;A foundation model is a machine learning model trained on a large and diverse
set of data, typically using self-supervised learning-based pre-training
techniques, that can be adapted to various downstream tasks. However, current
research on time series pre-training has mostly focused on models pre-trained
solely on data from a single domain, resulting in a lack of knowledge about
other types of time series. However, current research on time series
pre-training has predominantly focused on models trained exclusively on data
from a single domain. As a result, these models possess domain-specific
knowledge that may not be easily transferable to time series from other
domains. In this paper, we aim to develop an effective time series foundation
model by leveraging unlabeled samples from multiple domains. To achieve this,
we repurposed the publicly available UCR Archive and evaluated four existing
self-supervised learning-based pre-training methods, along with a novel method,
on the datasets. We tested these methods using four popular neural network
architectures for time series to understand how the pre-training methods
interact with different network designs. Our experimental results show that
pre-training improves downstream classification tasks by enhancing the
convergence of the fine-tuning process. Furthermore, we found that the proposed
pre-training method, when combined with the Transformer model, outperforms the
alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1&quot;&gt;Chin-Chia Michael Yeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1&quot;&gt;Xin Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huiyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Yujie Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Der_A/0/1/0/all/0/1&quot;&gt;Audrey Der&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_V/0/1/0/all/0/1&quot;&gt;Vivian Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1&quot;&gt;Zhongfang Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junpeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03919">
<title>An Efficient Content-based Time Series Retrieval System. (arXiv:2310.03919v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2310.03919</link>
<description rdf:parseType="Literal">&lt;p&gt;A Content-based Time Series Retrieval (CTSR) system is an information
retrieval system for users to interact with time series emerged from multiple
domains, such as finance, healthcare, and manufacturing. For example, users
seeking to learn more about the source of a time series can submit the time
series as a query to the CTSR system and retrieve a list of relevant time
series with associated metadata. By analyzing the retrieved metadata, users can
gather more information about the source of the time series. Because the CTSR
system is required to work with time series data from diverse domains, it needs
a high-capacity model to effectively measure the similarity between different
time series. On top of that, the model within the CTSR system has to compute
the similarity scores in an efficient manner as the users interact with the
system in real-time. In this paper, we propose an effective and efficient CTSR
model that outperforms alternative models, while still providing reasonable
inference runtimes. To demonstrate the capability of the proposed method in
solving business problems, we compare it against alternative models using our
in-house transaction data. Our findings reveal that the proposed model is the
most suitable solution compared to others for our transaction data problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1&quot;&gt;Chin-Chia Michael Yeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huiyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1&quot;&gt;Xin Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junpeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_V/0/1/0/all/0/1&quot;&gt;Vivian Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Yujie Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Der_A/0/1/0/all/0/1&quot;&gt;Audrey Der&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1&quot;&gt;Zhongfang Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_J/0/1/0/all/0/1&quot;&gt;Jeff M. Phillips&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03925">
<title>Multitask Learning for Time Series Data\\with 2D Convolution. (arXiv:2310.03925v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03925</link>
<description rdf:parseType="Literal">&lt;p&gt;Multitask learning (MTL) aims to develop a unified model that can handle a
set of closely related tasks simultaneously. By optimizing the model across
multiple tasks, MTL generally surpasses its non-MTL counterparts in terms of
generalizability. Although MTL has been extensively researched in various
domains such as computer vision, natural language processing, and
recommendation systems, its application to time series data has received
limited attention. In this paper, we investigate the application of MTL to the
time series classification (TSC) problem. However, when we integrate the
state-of-the-art 1D convolution-based TSC model with MTL, the performance of
the TSC model actually deteriorates. By comparing the 1D convolution-based
models with the Dynamic Time Warping (DTW) distance function, it appears that
the underwhelming results stem from the limited expressive power of the 1D
convolutional layers. To overcome this challenge, we propose a novel design for
a 2D convolution-based model that enhances the model&apos;s expressiveness.
Leveraging this advantage, our proposed method outperforms competing approaches
on both the UCR Archive and an industrial transaction TSC dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1&quot;&gt;Chin-Chia Michael Yeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1&quot;&gt;Xin Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junpeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huiyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Yujie Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Der_A/0/1/0/all/0/1&quot;&gt;Audrey Der&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1&quot;&gt;Zhongfang Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03927">
<title>Improving classifier decision boundaries using nearest neighbors. (arXiv:2310.03927v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03927</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are not learning optimal decision boundaries. We show that
decision boundaries are situated in areas of low training data density. They
are impacted by few training samples which can easily lead to overfitting. We
provide a simple algorithm performing a weighted average of the prediction of a
sample and its nearest neighbors&apos; (computed in latent space) leading to a minor
favorable outcomes for a variety of important measures for neural networks. In
our evaluation, we employ various self-trained and pre-trained convolutional
neural networks to show that our approach improves (i) resistance to label
noise, (ii) robustness against adversarial attacks, (iii) classification
accuracy, and to some degree even (iv) interpretability. While improvements are
not necessarily large in all four areas, our approach is conceptually simple,
i.e., improvements come without any modification to network architecture,
training procedure or dataset. Furthermore, they are in stark contrast to prior
works that often require trade-offs among the four objectives or provide
valuable, but non-actionable insights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1&quot;&gt;Johannes Schneider&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03941">
<title>LaTeX: Language Pattern-aware Triggering Event Detection for Adverse Experience during Pandemics. (arXiv:2310.03941v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03941</link>
<description rdf:parseType="Literal">&lt;p&gt;The COVID-19 pandemic has accentuated socioeconomic disparities across
various racial and ethnic groups in the United States. While previous studies
have utilized traditional survey methods like the Household Pulse Survey (HPS)
to elucidate these disparities, this paper explores the role of social media
platforms in both highlighting and addressing these challenges. Drawing from
real-time data sourced from Twitter, we analyzed language patterns related to
four major types of adverse experiences: loss of employment income (LI), food
scarcity (FS), housing insecurity (HI), and unmet needs for mental health
services (UM). We first formulate a sparsity optimization problem that extracts
low-level language features from social media data sources. Second, we propose
novel constraints on feature similarity exploiting prior knowledge about the
similarity of the language patterns among the adverse experiences. The proposed
problem is challenging to solve due to the non-convexity objective and
non-smoothness penalties. We develop an algorithm based on the alternating
direction method of multipliers (ADMM) framework to solve the proposed
formulation. Extensive experiments and comparisons to other models on
real-world social media and the detection of adverse experiences justify the
efficacy of our model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1&quot;&gt;Kaiqun Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yangxiao Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weiwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolady_D/0/1/0/all/0/1&quot;&gt;Deepthi Kolady&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03945">
<title>On Wasserstein distances for affine transformations of random vectors. (arXiv:2310.03945v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.03945</link>
<description rdf:parseType="Literal">&lt;p&gt;We expound on some known lower bounds of the quadratic Wasserstein distance
between random vectors in $\mathbb{R}^n$ with an emphasis on affine
transformations that have been used in manifold learning of data in Wasserstein
space. In particular, we give concrete lower bounds for rotated copies of
random vectors in $\mathbb{R}^2$ with uncorrelated components by computing the
Bures metric between the covariance matrices. We also derive upper bounds for
compositions of affine maps which yield a fruitful variety of diffeomorphisms
applied to an initial data measure. We apply these bounds to various
distributions including those lying on a 1-dimensional manifold in
$\mathbb{R}^2$ and illustrate the quality of the bounds. Finally, we give a
framework for mimicking handwritten digit or alphabet datasets that can be
applied in a manifold learning framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hamm_K/0/1/0/all/0/1&quot;&gt;Keaton Hamm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Korzeniowski_A/0/1/0/all/0/1&quot;&gt;Andrzej Korzeniowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03946">
<title>Improved prediction of ligand-protein binding affinities by meta-modeling. (arXiv:2310.03946v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03946</link>
<description rdf:parseType="Literal">&lt;p&gt;The accurate screening of candidate drug ligands against target proteins
through computational approaches is of prime interest to drug development
efforts, as filtering potential candidates would save time and expenses for
finding drugs. Such virtual screening depends in part on methods to predict the
binding affinity between ligands and proteins. Given many computational models
for binding affinity prediction with varying results across targets, we herein
develop a meta-modeling framework by integrating published empirical
structure-based docking and sequence-based deep learning models. In building
this framework, we evaluate many combinations of individual models, training
databases, and linear and nonlinear meta-modeling approaches. We show that many
of our meta-models significantly improve affinity predictions over individual
base models. Our best meta-models achieve comparable performance to
state-of-the-art exclusively structure-based deep learning tools. Overall, we
demonstrate that diverse modeling approaches can be ensembled together to gain
substantial improvement in binding affinity prediction while allowing control
over input features such as physicochemical properties or molecular
descriptors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Ho-Joon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emani_P/0/1/0/all/0/1&quot;&gt;Prashant S. Emani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerstein_M/0/1/0/all/0/1&quot;&gt;Mark B. Gerstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03957">
<title>Understanding prompt engineering may not require rethinking generalization. (arXiv:2310.03957v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03957</link>
<description rdf:parseType="Literal">&lt;p&gt;Zero-shot learning in prompted vision-language models, the practice of
crafting prompts to build classifiers without an explicit training process, has
achieved impressive performance in many settings. This success presents a
seemingly surprising observation: these methods suffer relatively little from
overfitting, i.e., when a prompt is manually engineered to achieve low error on
a given training set (thus rendering the method no longer actually zero-shot),
the approach still performs well on held-out test data. In this paper, we show
that we can explain such performance well via recourse to classical PAC-Bayes
bounds. Specifically, we show that the discrete nature of prompts, combined
with a PAC-Bayes prior given by a language model, results in generalization
bounds that are remarkably tight by the standards of the literature: for
instance, the generalization bound of an ImageNet classifier is often within a
few percentage points of the true test error. We demonstrate empirically that
this holds for existing handcrafted prompts and prompts generated through
simple greedy search. Furthermore, the resulting bound is well-suited for model
selection: the models with the best bound typically also have the best test
performance. This work thus provides a possible justification for the
widespread practice of prompt engineering, even if it seems that such methods
could potentially overfit the training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akinwande_V/0/1/0/all/0/1&quot;&gt;Victor Akinwande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yiding Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sam_D/0/1/0/all/0/1&quot;&gt;Dylan Sam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J. Zico Kolter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03964">
<title>A Learnable Counter-condition Analysis Framework for Functional Connectivity-based Neurological Disorder Diagnosis. (arXiv:2310.03964v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03964</link>
<description rdf:parseType="Literal">&lt;p&gt;To understand the biological characteristics of neurological disorders with
functional connectivity (FC), recent studies have widely utilized deep
learning-based models to identify the disease and conducted post-hoc analyses
via explainable models to discover disease-related biomarkers. Most existing
frameworks consist of three stages, namely, feature selection, feature
extraction for classification, and analysis, where each stage is implemented
separately. However, if the results at each stage lack reliability, it can
cause misdiagnosis and incorrect analysis in afterward stages. In this study,
we propose a novel unified framework that systemically integrates diagnoses
(i.e., feature selection and feature extraction) and explanations. Notably, we
devised an adaptive attention network as a feature selection approach to
identify individual-specific disease-related connections. We also propose a
functional network relational encoder that summarizes the global topological
properties of FC by learning the inter-network relations without pre-defined
edges between functional networks. Last but not least, our framework provides a
novel explanatory power for neuroscientific interpretation, also termed
counter-condition analysis. We simulated the FC that reverses the diagnostic
information (i.e., counter-condition FC): converting a normal brain to be
abnormal and vice versa. We validated the effectiveness of our framework by
using two large resting-state functional magnetic resonance imaging (fMRI)
datasets, Autism Brain Imaging Data Exchange (ABIDE) and REST-meta-MDD, and
demonstrated that our framework outperforms other competing methods for disease
identification. Furthermore, we analyzed the disease-related neurological
patterns based on counter-condition analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_E/0/1/0/all/0/1&quot;&gt;Eunsong Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heo_D/0/1/0/all/0/1&quot;&gt;Da-woon Heo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jiwon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suk_H/0/1/0/all/0/1&quot;&gt;Heung-Il Suk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03968">
<title>Ultimate limit on learning non-Markovian behavior: Fisher information rate and excess information. (arXiv:2310.03968v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03968</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the fundamental limits of learning unknown parameters of any
stochastic process from time-series data, and discover exact closed-form
expressions for how optimal inference scales with observation length. Given a
parametrized class of candidate models, the Fisher information of observed
sequence probabilities lower-bounds the variance in model estimation from
finite data. As sequence-length increases, the minimal variance scales as the
square inverse of the length -- with constant coefficient given by the
information rate. We discover a simple closed-form expression for this
information rate, even in the case of infinite Markov order. We furthermore
obtain the exact analytic lower bound on model variance from the
observation-induced metadynamic among belief states. We discover ephemeral,
exponential, and more general modes of convergence to the asymptotic
information rate. Surprisingly, this myopic information rate converges to the
asymptotic Fisher information rate with exactly the same relaxation timescales
that appear in the myopic entropy rate as it converges to the Shannon entropy
rate for the process. We illustrate these results with a sequence of examples
that highlight qualitatively distinct features of stochastic processes that
shape optimal learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riechers_P/0/1/0/all/0/1&quot;&gt;Paul M. Riechers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03977">
<title>Perfect Alignment May be Poisonous to Graph Contrastive Learning. (arXiv:2310.03977v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03977</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Contrastive Learning (GCL) aims to learn node representations by
aligning positive pairs and separating negative ones. However, limited research
has been conducted on the inner law behind specific augmentations used in
graph-based learning. What kind of augmentation will help downstream
performance, how does contrastive learning actually influence downstream tasks,
and why the magnitude of augmentation matters? This paper seeks to address
these questions by establishing a connection between augmentation and
downstream performance, as well as by investigating the generalization of
contrastive learning. Our findings reveal that GCL contributes to downstream
tasks mainly by separating different classes rather than gathering nodes of the
same class. So perfect alignment and augmentation overlap which draw all
intra-class samples the same can not explain the success of contrastive
learning. Then in order to comprehend how augmentation aids the contrastive
learning process, we conduct further investigations into its generalization,
finding that perfect alignment that draw positive pair the same could help
contrastive loss but is poisonous to generalization, on the contrary, imperfect
alignment enhances the model&apos;s generalization ability. We analyse the result by
information theory and graph spectrum theory respectively, and propose two
simple but effective methods to verify the theories. The two methods could be
easily applied to various GCL algorithms and extensive experiments are
conducted to prove its effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Huayi Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yong Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03981">
<title>CUPre: Cross-domain Unsupervised Pre-training for Few-Shot Cell Segmentation. (arXiv:2310.03981v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03981</link>
<description rdf:parseType="Literal">&lt;p&gt;While pre-training on object detection tasks, such as Common Objects in
Contexts (COCO) [1], could significantly boost the performance of cell
segmentation, it still consumes on massive fine-annotated cell images [2] with
bounding boxes, masks, and cell types for every cell in every image, to
fine-tune the pre-trained model. To lower the cost of annotation, this work
considers the problem of pre-training DNN models for few-shot cell
segmentation, where massive unlabeled cell images are available but only a
small proportion is annotated. Hereby, we propose Cross-domain Unsupervised
Pre-training, namely CUPre, transferring the capability of object detection and
instance segmentation for common visual objects (learned from COCO) to the
visual domain of cells using unlabeled images. Given a standard COCO
pre-trained network with backbone, neck, and head modules, CUPre adopts an
alternate multi-task pre-training (AMT2) procedure with two sub-tasks -- in
every iteration of pre-training, AMT2 first trains the backbone with cell
images from multiple cell datasets via unsupervised momentum contrastive
learning (MoCo) [3], and then trains the whole model with vanilla COCO datasets
via instance segmentation. After pre-training, CUPre fine-tunes the whole model
on the cell segmentation task using a few annotated images. We carry out
extensive experiments to evaluate CUPre using LIVECell [2] and BBBC038 [4]
datasets in few-shot instance segmentation settings. The experiment shows that
CUPre can outperform existing pre-training methods, achieving the highest
average precision (AP) for few-shot cell segmentation and detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1&quot;&gt;Weibin Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xuhong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qingzhong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yanwu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zhaozheng Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Haoyi Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03984">
<title>AdaRec: Adaptive Sequential Recommendation for Reinforcing Long-term User Engagement. (arXiv:2310.03984v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2310.03984</link>
<description rdf:parseType="Literal">&lt;p&gt;Growing attention has been paid to Reinforcement Learning (RL) algorithms
when optimizing long-term user engagement in sequential recommendation tasks.
One challenge in large-scale online recommendation systems is the constant and
complicated changes in users&apos; behavior patterns, such as interaction rates and
retention tendencies. When formulated as a Markov Decision Process (MDP), the
dynamics and reward functions of the recommendation system are continuously
affected by these changes. Existing RL algorithms for recommendation systems
will suffer from distribution shift and struggle to adapt in such an MDP. In
this paper, we introduce a novel paradigm called Adaptive Sequential
Recommendation (AdaRec) to address this issue. AdaRec proposes a new
distance-based representation loss to extract latent information from users&apos;
interaction trajectories. Such information reflects how RL policy fits to
current user behavior patterns, and helps the policy to identify subtle changes
in the recommendation system. To make rapid adaptation to these changes, AdaRec
encourages exploration with the idea of optimism under uncertainty. The
exploration is further guarded by zero-order action optimization to ensure
stable recommendation quality in complicated environments. We conduct extensive
empirical analyses in both simulator-based and live sequential recommendation
tasks, where AdaRec exhibits superior long-term performance compared to all
baseline algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1&quot;&gt;Zhenghai Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1&quot;&gt;Qingpeng Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_T/0/1/0/all/0/1&quot;&gt;Tianyou Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1&quot;&gt;Lantao Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1&quot;&gt;Peng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1&quot;&gt;Kun Gai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1&quot;&gt;Bo An&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03985">
<title>Dementia Assessment Using Mandarin Speech with an Attention-based Speech Recognition Encoder. (arXiv:2310.03985v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.03985</link>
<description rdf:parseType="Literal">&lt;p&gt;Dementia diagnosis requires a series of different testing methods, which is
complex and time-consuming. Early detection of dementia is crucial as it can
prevent further deterioration of the condition. This paper utilizes a speech
recognition model to construct a dementia assessment system tailored for
Mandarin speakers during the picture description task. By training an
attention-based speech recognition model on voice data closely resembling
real-world scenarios, we have significantly enhanced the model&apos;s recognition
capabilities. Subsequently, we extracted the encoder from the speech
recognition model and added a linear layer for dementia assessment. We
collected Mandarin speech data from 99 subjects and acquired their clinical
assessments from a local hospital. We achieved an accuracy of 92.04% in
Alzheimer&apos;s disease detection and a mean absolute error of 9% in clinical
dementia rating score prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zih-Jyun Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yi-Ju Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuo_P/0/1/0/all/0/1&quot;&gt;Po-Chih Kuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Likai Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1&quot;&gt;Chaur-Jong Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Cheng-Yu Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03986">
<title>Robust Multimodal Learning with Missing Modalities via Parameter-Efficient Adaptation. (arXiv:2310.03986v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.03986</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal learning seeks to utilize data from multiple sources to improve
the overall performance of downstream tasks. It is desirable for redundancies
in the data to make multimodal systems robust to missing or corrupted
observations in some correlated modalities. However, we observe that the
performance of several existing multimodal networks significantly deteriorates
if one or multiple modalities are absent at test time. To enable robustness to
missing modalities, we propose simple and parameter-efficient adaptation
procedures for pretrained multimodal networks. In particular, we exploit
low-rank adaptation and modulation of intermediate features to compensate for
the missing modalities. We demonstrate that such adaptation can partially
bridge performance drop due to missing modalities and outperform independent,
dedicated networks trained for the available modality combinations in some
cases. The proposed adaptation requires extremely small number of parameters
(e.g., fewer than 0.7% of the total parameters in most experiments). We conduct
a series of experiments to highlight the robustness of our proposed method
using diverse datasets for RGB-thermal and RGB-Depth semantic segmentation,
multimodal material segmentation, and multimodal sentiment analysis tasks. Our
proposed method demonstrates versatility across various tasks and datasets, and
outperforms existing methods for robust multimodal learning with missing
modalities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reza_M/0/1/0/all/0/1&quot;&gt;Md Kaykobad Reza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prater_Bennette_A/0/1/0/all/0/1&quot;&gt;Ashley Prater-Bennette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asif_M/0/1/0/all/0/1&quot;&gt;M. Salman Asif&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03999">
<title>Runtime Monitoring DNN-Based Perception. (arXiv:2310.03999v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.03999</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) are instrumental in realizing complex perception
systems. As many of these applications are safety-critical by design,
engineering rigor is required to ensure that the functional insufficiency of
the DNN-based perception is not the source of harm. In addition to conventional
static verification and testing techniques employed during the design phase,
there is a need for runtime verification techniques that can detect critical
events, diagnose issues, and even enforce requirements. This tutorial aims to
provide readers with a glimpse of techniques proposed in the literature. We
start with classical methods proposed in the machine learning community, then
highlight a few techniques proposed by the formal methods community. While we
surely can observe similarities in the design of monitors, how the decision
boundaries are created vary between the two communities. We conclude by
highlighting the need to rigorously design monitors, where data availability
outside the operational domain plays an important role.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Chih-Hong Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luttenberger_M/0/1/0/all/0/1&quot;&gt;Michael Luttenberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1&quot;&gt;Rongjie Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04003">
<title>The Role of Federated Learning in a Wireless World with Foundation Models. (arXiv:2310.04003v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2310.04003</link>
<description rdf:parseType="Literal">&lt;p&gt;Foundation models (FMs) are general-purpose artificial intelligence (AI)
models that have recently enabled multiple brand-new generative AI
applications. The rapid advances in FMs serve as an important contextual
backdrop for the vision of next-generation wireless networks, where federated
learning (FL) is a key enabler of distributed network intelligence. Currently,
the exploration of the interplay between FMs and FL is still in its nascent
stage. Naturally, FMs are capable of boosting the performance of FL, and FL
could also leverage decentralized data and computing resources to assist in the
training of FMs. However, the exceptionally high requirements that FMs have for
computing resources, storage, and communication overhead would pose critical
challenges to FL-enabled wireless networks. In this article, we explore the
extent to which FMs are suitable for FL over wireless networks, including a
broad overview of research challenges and opportunities. In particular, we
discuss multiple new paradigms for realizing future intelligent networks that
integrate FMs and FL. We also consolidate several broad research directions
associated with these paradigms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zihan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Howard H. Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1&quot;&gt;Y. C. Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chong_K/0/1/0/all/0/1&quot;&gt;Kai Fong Ernest Chong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1&quot;&gt;Tony Q. S. Quek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04006">
<title>Accelerating optimization over the space of probability measures. (arXiv:2310.04006v1 [math.OC])</title>
<link>http://arxiv.org/abs/2310.04006</link>
<description rdf:parseType="Literal">&lt;p&gt;Acceleration of gradient-based optimization methods is an issue of
significant practical and theoretical interest, particularly in machine
learning applications. Most research has focused on optimization over Euclidean
spaces, but given the need to optimize over spaces of probability measures in
many machine learning problems, it is of interest to investigate accelerated
gradient methods in this context too. To this end, we introduce a
Hamiltonian-flow approach that is analogous to moment-based approaches in
Euclidean space. We demonstrate that algorithms based on this approach can
achieve convergence rates of arbitrarily high order. Numerical examples
illustrate our claim.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tse_O/0/1/0/all/0/1&quot;&gt;Oliver Tse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wright_S/0/1/0/all/0/1&quot;&gt;Stephen J. Wright&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04015">
<title>Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization. (arXiv:2310.04015v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04015</link>
<description rdf:parseType="Literal">&lt;p&gt;While personalized recommendations systems have become increasingly popular,
ensuring user data protection remains a paramount concern in the development of
these learning systems. A common approach to enhancing privacy involves
training models using anonymous data rather than individual data. In this
paper, we explore a natural technique called \emph{look-alike clustering},
which involves replacing sensitive features of individuals with the cluster&apos;s
average values. We provide a precise analysis of how training models using
anonymous cluster centers affects their generalization capabilities. We focus
on an asymptotic regime where the size of the training set grows in proportion
to the features dimension. Our analysis is based on the Convex Gaussian Minimax
Theorem (CGMT) and allows us to theoretically understand the role of different
model components on the generalization error. In addition, we demonstrate that
in certain high-dimensional regimes, training over anonymous cluster centers
acts as a regularization and improves generalization error of the trained
models. Finally, we corroborate our asymptotic theory with finite-sample
numerical experiments where we observe a perfect match when the sample size is
only of order of a few hundreds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javanmard_A/0/1/0/all/0/1&quot;&gt;Adel Javanmard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1&quot;&gt;Vahab Mirrokni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04017">
<title>PGraphDTA: Improving Drug Target Interaction Prediction using Protein Language Models and Contact Maps. (arXiv:2310.04017v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04017</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing and discovering new drugs is a complex and resource-intensive
endeavor that often involves substantial costs, time investment, and safety
concerns. A key aspect of drug discovery involves identifying novel drug-target
(DT) interactions. Existing computational methods for predicting DT
interactions have primarily focused on binary classification tasks, aiming to
determine whether a DT pair interacts or not. However, protein-ligand
interactions exhibit a continuum of binding strengths, known as binding
affinity, presenting a persistent challenge for accurate prediction. In this
study, we investigate various techniques employed in Drug Target Interaction
(DTI) prediction and propose novel enhancements to enhance their performance.
Our approaches include the integration of Protein Language Models (PLMs) and
the incorporation of Contact Map information as an inductive bias within
current models. Through extensive experimentation, we demonstrate that our
proposed approaches outperform the baseline models considered in this study,
presenting a compelling case for further development in this direction. We
anticipate that the insights gained from this work will significantly narrow
the search space for potential drugs targeting specific proteins, thereby
accelerating drug discovery. Code and data for PGraphDTA are available at
https://anonymous.4open.science/r/PGraphDTA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bal_R/0/1/0/all/0/1&quot;&gt;Rakesh Bal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1&quot;&gt;Yijia Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04028">
<title>Genetic prediction of quantitative traits: a machine learner&apos;s guide focused on height. (arXiv:2310.04028v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04028</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning and deep learning have been celebrating many successes in
the application to biological problems, especially in the domain of protein
folding. Another equally complex and important question has received relatively
little attention by the machine learning community, namely the one of
prediction of complex traits from genetics. Tackling this problem requires
in-depth knowledge of the related genetics literature and awareness of various
subtleties associated with genetic data. In this guide, we provide an overview
for the machine learning community on current state of the art models and
associated subtleties which need to be taken into consideration when developing
new models for phenotype prediction. We use height as an example of a
continuous-valued phenotype and provide an introduction to benchmark datasets,
confounders, feature selection, and common metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bourguignon_L/0/1/0/all/0/1&quot;&gt;Lucie Bourguignon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weis_C/0/1/0/all/0/1&quot;&gt;Caroline Weis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jutzeler_C/0/1/0/all/0/1&quot;&gt;Catherine R. Jutzeler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adamer_M/0/1/0/all/0/1&quot;&gt;Michael Adamer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04038">
<title>Joint Projection Learning and Tensor Decomposition Based Incomplete Multi-view Clustering. (arXiv:2310.04038v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04038</link>
<description rdf:parseType="Literal">&lt;p&gt;Incomplete multi-view clustering (IMVC) has received increasing attention
since it is often that some views of samples are incomplete in reality. Most
existing methods learn similarity subgraphs from original incomplete multi-view
data and seek complete graphs by exploring the incomplete subgraphs of each
view for spectral clustering. However, the graphs constructed on the original
high-dimensional data may be suboptimal due to feature redundancy and noise.
Besides, previous methods generally ignored the graph noise caused by the
inter-class and intra-class structure variation during the transformation of
incomplete graphs and complete graphs. To address these problems, we propose a
novel Joint Projection Learning and Tensor Decomposition Based method (JPLTD)
for IMVC. Specifically, to alleviate the influence of redundant features and
noise in high-dimensional data, JPLTD introduces an orthogonal projection
matrix to project the high-dimensional features into a lower-dimensional space
for compact feature learning.Meanwhile, based on the lower-dimensional space,
the similarity graphs corresponding to instances of different views are
learned, and JPLTD stacks these graphs into a third-order low-rank tensor to
explore the high-order correlations across different views. We further consider
the graph noise of projected data caused by missing samples and use a
tensor-decomposition based graph filter for robust clustering.JPLTD decomposes
the original tensor into an intrinsic tensor and a sparse tensor. The intrinsic
tensor models the true data similarities. An effective optimization algorithm
is adopted to solve the JPLTD model. Comprehensive experiments on several
benchmark datasets demonstrate that JPLTD outperforms the state-of-the-art
methods. The code of JPLTD is available at https://github.com/weilvNJU/JPLTD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_W/0/1/0/all/0/1&quot;&gt;Wei Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Huaxiong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1&quot;&gt;Xiuyi Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chunlin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04041">
<title>Observation-Guided Diffusion Probabilistic Models. (arXiv:2310.04041v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04041</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel diffusion model called observation-guided diffusion
probabilistic model (OGDM), which effectively addresses the trade-off between
quality control and fast sampling. Our approach reestablishes the training
objective by integrating the guidance of the observation process with the
Markov chain in a principled way. This is achieved by introducing an additional
loss term derived from the observation based on the conditional discriminator
on noise level, which employs Bernoulli distribution indicating whether its
input lies on the (noisy) real manifold or not. This strategy allows us to
optimize the more accurate negative log-likelihood induced in the inference
stage especially when the number of function evaluations is limited. The
proposed training method is also advantageous even when incorporated only into
the fine-tuning process, and it is compatible with various fast inference
strategies since our method yields better denoising networks using the exactly
same inference procedure without incurring extra computational cost. We
demonstrate the effectiveness of the proposed training algorithm using diverse
inference methods on strong diffusion model baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1&quot;&gt;Junoh Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jinyoung Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sungik Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bohyung Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04047">
<title>AUTOPARLLM: GNN-Guided Automatic Code Parallelization using Large Language Models. (arXiv:2310.04047v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04047</link>
<description rdf:parseType="Literal">&lt;p&gt;Parallelizing sequentially written programs is a challenging task. Even
experienced developers need to spend considerable time finding parallelism
opportunities and then actually writing parallel versions of sequentially
written programs. To address this issue, we present AUTOPARLLM, a framework for
automatically discovering parallelism and generating the parallel version of
the sequentially written program. Our framework consists of two major
components: i) a heterogeneous Graph Neural Network (GNN) based parallelism
discovery and parallel pattern detection module, and ii) an LLM-based code
generator to generate the parallel counterpart of the sequential programs. We
use the GNN to learn the flow-aware characteristics of the programs to identify
parallel regions in sequential programs and then construct an enhanced prompt
using the GNN&apos;s results for the LLM-based generator to finally produce the
parallel counterparts of the sequential programs. We evaluate AUTOPARLLM on 11
applications of 2 well-known benchmark suites: NAS Parallel Benchmark and
Rodinia Benchmark. Our results show that AUTOPARLLM is indeed effective in
improving the state-of-the-art LLM-based models for the task of parallel code
generation in terms of multiple code generation metrics. AUTOPARLLM also
improves the average runtime of the parallel code generated by the
state-of-the-art LLMs by as high as 3.4% and 2.9% for the NAS Parallel
Benchmark and Rodinia Benchmark respectively. Additionally, to overcome the
issue that well-known metrics for translation evaluation have not been
optimized to evaluate the quality of the generated parallel code, we propose
OMPScore for evaluating the quality of the generated code. We show that
OMPScore exhibits a better correlation with human judgment than existing
metrics, measured by up to 75% improvement of Spearman correlation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmud_Q/0/1/0/all/0/1&quot;&gt;Quazi Ishtiaque Mahmud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+TehraniJamsaz_A/0/1/0/all/0/1&quot;&gt;Ali TehraniJamsaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_H/0/1/0/all/0/1&quot;&gt;Hung D Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1&quot;&gt;Nesreen K. Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1&quot;&gt;Ali Jannesari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04059">
<title>DEFT: A new distance-based feature set for keystroke dynamics. (arXiv:2310.04059v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04059</link>
<description rdf:parseType="Literal">&lt;p&gt;Keystroke dynamics is a behavioural biometric utilised for user
identification and authentication. We propose a new set of features based on
the distance between keys on the keyboard, a concept that has not been
considered before in keystroke dynamics. We combine flight times, a popular
metric, with the distance between keys on the keyboard and call them as
Distance Enhanced Flight Time features (DEFT). This novel approach provides
comprehensive insights into a person&apos;s typing behaviour, surpassing typing
velocity alone. We build a DEFT model by combining DEFT features with other
previously used keystroke dynamic features. The DEFT model is designed to be
device-agnostic, allowing us to evaluate its effectiveness across three
commonly used devices: desktop, mobile, and tablet. The DEFT model outperforms
the existing state-of-the-art methods when we evaluate its effectiveness across
two datasets. We obtain accuracy rates exceeding 99% and equal error rates
below 10% on all three devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaluarachchi_N/0/1/0/all/0/1&quot;&gt;Nuwan Kaluarachchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kandanaarachchi_S/0/1/0/all/0/1&quot;&gt;Sevvandi Kandanaarachchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_K/0/1/0/all/0/1&quot;&gt;Kristen Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arakala_A/0/1/0/all/0/1&quot;&gt;Arathi Arakala&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04064">
<title>How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation. (arXiv:2310.04064v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2310.04064</link>
<description rdf:parseType="Literal">&lt;p&gt;In the classical transformer attention scheme, we are given three $n \times
d$ size matrices $Q, K, V$ (the query, key, and value tokens), and the goal is
to compute a new $n \times d$ size matrix $D^{-1} \exp(QK^\top) V$ where $D =
\mathrm{diag}( \exp(QK^\top) {\bf 1}_n )$. In this work, we study a
generalization of attention which captures triple-wise correlations. This
generalization is able to solve problems about detecting triple-wise
connections that were shown to be impossible for transformers. The potential
downside of this generalization is that it appears as though computations are
even more difficult, since the straightforward algorithm requires cubic time in
$n$. However, we show that in the bounded-entry setting (which arises in
practice, and which is well-studied in both theory and practice), there is
actually a near-linear time algorithm. More precisely, we show that bounded
entries are both necessary and sufficient for quickly performing generalized
computations:
&lt;/p&gt;
&lt;p&gt;$\bullet$ On the positive side, if all entries of the input matrices are
bounded above by $o(\sqrt[3]{\log n})$ then we show how to approximate the
``tensor-type&apos;&apos; attention matrix in $n^{1+o(1)}$ time.
&lt;/p&gt;
&lt;p&gt;$\bullet$ On the negative side, we show that if the entries of the input
matrices may be as large as $\Omega(\sqrt[3]{\log n})$, then there is no
algorithm that runs faster than $n^{3-o(1)}$ (assuming the Strong Exponential
Time Hypothesis from fine-grained complexity theory).
&lt;/p&gt;
&lt;p&gt;We also show that our construction, algorithms, and lower bounds naturally
generalize to higher-order tensors and correlations. Interestingly, the higher
the order of the tensors, the lower the bound on the entries needs to be for an
efficient algorithm. Our results thus yield a natural tradeoff between the
boundedness of the entries, and order of the tensor one may use for more
expressive, efficient attention computation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alman_J/0/1/0/all/0/1&quot;&gt;Josh Alman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04074">
<title>Automatic Aspect Extraction from Scientific Texts. (arXiv:2310.04074v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.04074</link>
<description rdf:parseType="Literal">&lt;p&gt;Being able to extract from scientific papers their main points, key insights,
and other important information, referred to here as aspects, might facilitate
the process of conducting a scientific literature review. Therefore, the aim of
our research is to create a tool for automatic aspect extraction from
Russian-language scientific texts of any domain. In this paper, we present a
cross-domain dataset of scientific texts in Russian, annotated with such
aspects as Task, Contribution, Method, and Conclusion, as well as a baseline
algorithm for aspect extraction, based on the multilingual BERT model
fine-tuned on our data. We show that there are some differences in aspect
representation in different domains, but even though our model was trained on a
limited number of scientific domains, it is still able to generalize to new
domains, as was proved by cross-domain experiments. The code and the dataset
are available at
\url{https://github.com/anna-marshalova/automatic-aspect-extraction-from-scientific-texts}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marshalova_A/0/1/0/all/0/1&quot;&gt;Anna Marshalova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruches_E/0/1/0/all/0/1&quot;&gt;Elena Bruches&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batura_T/0/1/0/all/0/1&quot;&gt;Tatiana Batura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04078">
<title>Beyond Myopia: Learning from Positive and Unlabeled Data through Holistic Predictive Trends. (arXiv:2310.04078v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04078</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning binary classifiers from positive and unlabeled data (PUL) is vital
in many real-world applications, especially when verifying negative examples is
difficult. Despite the impressive empirical performance of recent PUL methods,
challenges like accumulated errors and increased estimation bias persist due to
the absence of negative labels. In this paper, we unveil an intriguing yet
long-overlooked observation in PUL: \textit{resampling the positive data in
each training iteration to ensure a balanced distribution between positive and
unlabeled examples results in strong early-stage performance. Furthermore,
predictive trends for positive and negative classes display distinctly
different patterns.} Specifically, the scores (output probability) of unlabeled
negative examples consistently decrease, while those of unlabeled positive
examples show largely chaotic trends. Instead of focusing on classification
within individual time frames, we innovatively adopt a holistic approach,
interpreting the scores of each example as a temporal point process (TPP). This
reformulates the core problem of PUL as recognizing trends in these scores. We
then propose a novel TPP-inspired measure for trend detection and prove its
asymptotic unbiasedness in predicting changes. Notably, our method accomplishes
PUL without requiring additional parameter tuning or prior assumptions,
offering an alternative perspective for tackling this problem. Extensive
experiments verify the superiority of our method, particularly in a highly
imbalanced real-world setting, where it achieves improvements of up to $11.3\%$
in key metrics. The code is available at
\href{https://github.com/wxr99/HolisticPU}{https://github.com/wxr99/HolisticPU}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinrui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1&quot;&gt;Wenhai Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_C/0/1/0/all/0/1&quot;&gt;Chuanxin Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LI_S/0/1/0/all/0/1&quot;&gt;Shaoyuan LI&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Songcan Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04128">
<title>Reinforcement Learning with Fast and Forgetful Memory. (arXiv:2310.04128v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04128</link>
<description rdf:parseType="Literal">&lt;p&gt;Nearly all real world tasks are inherently partially observable,
necessitating the use of memory in Reinforcement Learning (RL). Most model-free
approaches summarize the trajectory into a latent Markov state using memory
models borrowed from Supervised Learning (SL), even though RL tends to exhibit
different training and efficiency characteristics. Addressing this discrepancy,
we introduce Fast and Forgetful Memory, an algorithm-agnostic memory model
designed specifically for RL. Our approach constrains the model search space
via strong structural priors inspired by computational psychology. It is a
drop-in replacement for recurrent neural networks (RNNs) in recurrent RL
algorithms, achieving greater reward than RNNs across various recurrent
benchmarks and algorithms without changing any hyperparameters. Moreover, Fast
and Forgetful Memory exhibits training speeds two orders of magnitude faster
than RNNs, attributed to its logarithmic time and linear space complexity. Our
implementation is available at https://github.com/proroklab/ffm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morad_S/0/1/0/all/0/1&quot;&gt;Steven Morad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kortvelesy_R/0/1/0/all/0/1&quot;&gt;Ryan Kortvelesy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liwicki_S/0/1/0/all/0/1&quot;&gt;Stephan Liwicki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prorok_A/0/1/0/all/0/1&quot;&gt;Amanda Prorok&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04140">
<title>Routing Arena: A Benchmark Suite for Neural Routing Solvers. (arXiv:2310.04140v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04140</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Combinatorial Optimization has been researched actively in the last
eight years. Even though many of the proposed Machine Learning based approaches
are compared on the same datasets, the evaluation protocol exhibits essential
flaws and the selection of baselines often neglects State-of-the-Art Operations
Research approaches. To improve on both of these shortcomings, we propose the
Routing Arena, a benchmark suite for Routing Problems that provides a seamless
integration of consistent evaluation and the provision of baselines and
benchmarks prevalent in the Machine Learning- and Operations Research field.
The proposed evaluation protocol considers the two most important evaluation
cases for different applications: First, the solution quality for an a priori
fixed time budget and secondly the anytime performance of the respective
methods. By setting the solution trajectory in perspective to a Best Known
Solution and a Base Solver&apos;s solutions trajectory, we furthermore propose the
Weighted Relative Average Performance (WRAP), a novel evaluation metric that
quantifies the often claimed runtime efficiency of Neural Routing Solvers. A
comprehensive first experimental evaluation demonstrates that the most recent
Operations Research solvers generate state-of-the-art results in terms of
solution quality and runtime efficiency when it comes to the vehicle routing
problem. Nevertheless, some findings highlight the advantages of neural
approaches and motivate a shift in how neural solvers should be conceptualized.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thyssens_D/0/1/0/all/0/1&quot;&gt;Daniela Thyssens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dernedde_T/0/1/0/all/0/1&quot;&gt;Tim Dernedde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Falkner_J/0/1/0/all/0/1&quot;&gt;Jonas K. Falkner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1&quot;&gt;Lars Schmidt-Thieme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04145">
<title>From Zero to Hero: Detecting Leaked Data through Synthetic Data Injection and Model Querying. (arXiv:2310.04145v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04145</link>
<description rdf:parseType="Literal">&lt;p&gt;Safeguarding the Intellectual Property (IP) of data has become critically
important as machine learning applications continue to proliferate, and their
success heavily relies on the quality of training data. While various
mechanisms exist to secure data during storage, transmission, and consumption,
fewer studies have been developed to detect whether they are already leaked for
model training without authorization. This issue is particularly challenging
due to the absence of information and control over the training process
conducted by potential attackers.
&lt;/p&gt;
&lt;p&gt;In this paper, we concentrate on the domain of tabular data and introduce a
novel methodology, Local Distribution Shifting Synthesis (\textsc{LDSS}), to
detect leaked data that are used to train classification models. The core
concept behind \textsc{LDSS} involves injecting a small volume of synthetic
data--characterized by local shifts in class distribution--into the owner&apos;s
dataset. This enables the effective identification of models trained on leaked
data through model querying alone, as the synthetic data injection results in a
pronounced disparity in the predictions of models trained on leaked and
modified datasets. \textsc{LDSS} is \emph{model-oblivious} and hence compatible
with a diverse range of classification models, such as Naive Bayes, Decision
Tree, and Random Forest. We have conducted extensive experiments on seven types
of classification models across five real-world datasets. The comprehensive
results affirm the reliability, robustness, fidelity, security, and efficiency
of \textsc{LDSS}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1&quot;&gt;Biao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tung_A/0/1/0/all/0/1&quot;&gt;Anthony K. H. Tung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04159">
<title>Amortized Network Intervention to Steer the Excitatory Point Processes. (arXiv:2310.04159v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04159</link>
<description rdf:parseType="Literal">&lt;p&gt;We tackle the challenge of large-scale network intervention for guiding
excitatory point processes, such as infectious disease spread or traffic
congestion control. Our model-based reinforcement learning utilizes neural ODEs
to capture how the networked excitatory point processes will evolve subject to
the time-varying changes in network topology. Our approach incorporates
Gradient-Descent based Model Predictive Control (GD-MPC), offering policy
flexibility to accommodate prior knowledge and constraints. To address the
intricacies of planning and overcome the high dimensionality inherent to such
decision-making problems, we design an Amortize Network Interventions (ANI)
framework, allowing for the pooling of optimal policies from history and other
contexts, while ensuring a permutation equivalent property. This property
enables efficient knowledge transfer and sharing across diverse contexts. Our
approach has broad applications, from curbing infectious disease spread to
reducing carbon emissions through traffic light optimization, and thus has the
potential to address critical societal and environmental challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zitao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1&quot;&gt;Wendi Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04171">
<title>Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection. (arXiv:2310.04171v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04171</link>
<description rdf:parseType="Literal">&lt;p&gt;Fraud detection aims to discover fraudsters deceiving other users by, for
example, leaving fake reviews or making abnormal transactions. Graph-based
fraud detection methods consider this task as a classification problem with two
classes: frauds or normal. We address this problem using Graph Neural Networks
(GNNs) by proposing a dynamic relation-attentive aggregation mechanism. Based
on the observation that many real-world graphs include different types of
relations, we propose to learn a node representation per relation and aggregate
the node representations using a learnable attention function that assigns a
different attention coefficient to each relation. Furthermore, we combine the
node representations from different layers to consider both the local and
global structures of a target node, which is beneficial to improving the
performance of fraud detection on graphs with heterophily. By employing dynamic
graph attention in all the aggregation processes, our method adaptively
computes the attention coefficients for each node. Experimental results show
that our method, DRAG, outperforms state-of-the-art fraud detection methods on
real-world benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Heehyeon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jinhyeok Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whang_J/0/1/0/all/0/1&quot;&gt;Joyce Jiyoung Whang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04178">
<title>Introducing the Attribution Stability Indicator: a Measure for Time Series XAI Attributions. (arXiv:2310.04178v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04178</link>
<description rdf:parseType="Literal">&lt;p&gt;Given the increasing amount and general complexity of time series data in
domains such as finance, weather forecasting, and healthcare, there is a
growing need for state-of-the-art performance models that can provide
interpretable insights into underlying patterns and relationships. Attribution
techniques enable the extraction of explanations from time series models to
gain insights but are hard to evaluate for their robustness and
trustworthiness. We propose the Attribution Stability Indicator (ASI), a
measure to incorporate robustness and trustworthiness as properties of
attribution techniques for time series into account. We extend a perturbation
analysis with correlations of the original time series to the perturbed
instance and the attributions to include wanted properties in the measure. We
demonstrate the wanted properties based on an analysis of the attributions in a
dimension-reduced space and the ASI scores distribution over three whole time
series classification datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlegel_U/0/1/0/all/0/1&quot;&gt;Udo Schlegel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keim_D/0/1/0/all/0/1&quot;&gt;Daniel A. Keim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04179">
<title>Entropic Score metric: Decoupling Topology and Size in Training-free NAS. (arXiv:2310.04179v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.04179</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Networks design is a complex and often daunting task, particularly for
resource-constrained scenarios typical of mobile-sized models. Neural
Architecture Search is a promising approach to automate this process, but
existing competitive methods require large training time and computational
resources to generate accurate models. To overcome these limits, this paper
contributes with: i) a novel training-free metric, named Entropic Score, to
estimate model expressivity through the aggregated element-wise entropy of its
activations; ii) a cyclic search algorithm to separately yet synergistically
search model size and topology. Entropic Score shows remarkable ability in
searching for the topology of the network, and a proper combination with
LogSynflow, to search for model size, yields superior capability to completely
design high-performance Hybrid Transformers for edge applications in less than
1 GPU hour, resulting in the fastest and most accurate NAS method for ImageNet
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cavagnero_N/0/1/0/all/0/1&quot;&gt;Niccol&amp;#xf2; Cavagnero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robbiano_L/0/1/0/all/0/1&quot;&gt;Luca Robbiano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pistilli_F/0/1/0/all/0/1&quot;&gt;Francesca Pistilli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caputo_B/0/1/0/all/0/1&quot;&gt;Barbara Caputo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Averta_G/0/1/0/all/0/1&quot;&gt;Giuseppe Averta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04190">
<title>Non-Redundant Graph Neural Networks with Improved Expressiveness. (arXiv:2310.04190v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04190</link>
<description rdf:parseType="Literal">&lt;p&gt;Message passing graph neural networks iteratively compute node embeddings by
aggregating messages from all neighbors. This procedure can be viewed as a
neural variant of the Weisfeiler-Leman method, which limits their expressive
power. Moreover, oversmoothing and oversquashing restrict the number of layers
these networks can effectively utilize. The repeated exchange and encoding of
identical information in message passing amplifies oversquashing. We propose a
novel aggregation scheme based on neighborhood trees, which allows for
controlling the redundancy by pruning branches of the unfolding trees
underlying standard message passing. We prove that reducing redundancy improves
expressivity and experimentally show that it alleviates oversquashing. We
investigate the interaction between redundancy in message passing and
redundancy in computation and propose a compact representation of neighborhood
trees, from which we compute node and graph embeddings via a neural tree
canonization technique. Our method is provably more expressive than the
Weisfeiler-Leman method, less susceptible to oversquashing than message passing
neural networks, and provides high classification accuracy on widely-used
benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bause_F/0/1/0/all/0/1&quot;&gt;Franka Bause&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moustafa_S/0/1/0/all/0/1&quot;&gt;Samir Moustafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Langguth_J/0/1/0/all/0/1&quot;&gt;Johannes Langguth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gansterer_W/0/1/0/all/0/1&quot;&gt;Wilfried N. Gansterer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kriege_N/0/1/0/all/0/1&quot;&gt;Nils M. Kriege&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04216">
<title>Cost-Effective Retraining of Machine Learning Models. (arXiv:2310.04216v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04216</link>
<description rdf:parseType="Literal">&lt;p&gt;It is important to retrain a machine learning (ML) model in order to maintain
its performance as the data changes over time. However, this can be costly as
it usually requires processing the entire dataset again. This creates a
trade-off between retraining too frequently, which leads to unnecessary
computing costs, and not retraining often enough, which results in stale and
inaccurate ML models. To address this challenge, we propose ML systems that
make automated and cost-effective decisions about when to retrain an ML model.
We aim to optimize the trade-off by considering the costs associated with each
decision. Our research focuses on determining whether to retrain or keep an
existing ML model based on various factors, including the data, the model, and
the predictive queries answered by the model. Our main contribution is a
Cost-Aware Retraining Algorithm called Cara, which optimizes the trade-off over
streams of data and queries. To evaluate the performance of Cara, we analyzed
synthetic datasets and demonstrated that Cara can adapt to different data
drifts and retraining costs while performing similarly to an optimal
retrospective algorithm. We also conducted experiments with real-world datasets
and showed that Cara achieves better accuracy than drift detection baselines
while making fewer retraining decisions, ultimately resulting in lower total
costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahadevan_A/0/1/0/all/0/1&quot;&gt;Ananth Mahadevan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathioudakis_M/0/1/0/all/0/1&quot;&gt;Michael Mathioudakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04218">
<title>A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence Classes with the same Skeleton. (arXiv:2310.04218v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2310.04218</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal DAGs (also known as Bayesian networks) are a popular tool for encoding
conditional dependencies between random variables. In a causal DAG, the random
variables are modeled as vertices in the DAG, and it is stipulated that every
random variable is independent of its ancestors conditioned on its parents. It
is possible, however, for two different causal DAGs on the same set of random
variables to encode exactly the same set of conditional dependencies. Such
causal DAGs are said to be Markov equivalent, and equivalence classes of Markov
equivalent DAGs are known as Markov Equivalent Classes (MECs). Beautiful
combinatorial characterizations of MECs have been developed in the past few
decades, and it is known, in particular that all DAGs in the same MEC must have
the same &apos;&apos;skeleton&apos;&apos; (underlying undirected graph) and v-structures (induced
subgraph of the form $a\rightarrow b \leftarrow c$).
&lt;/p&gt;
&lt;p&gt;These combinatorial characterizations also suggest several natural
algorithmic questions. One of these is: given an undirected graph $G$ as input,
how many distinct Markov equivalence classes have the skeleton $G$? Much work
has been devoted in the last few years to this and other closely related
problems. However, to the best of our knowledge, a polynomial time algorithm
for the problem remains unknown.
&lt;/p&gt;
&lt;p&gt;In this paper, we make progress towards this goal by giving a fixed parameter
tractable algorithm for the above problem, with the parameters being the
treewidth and the maximum degree of the input graph $G$. The main technical
ingredient in our work is a construction we refer to as shadow, which lets us
create a &quot;local description&apos;&apos; of long-range constraints imposed by the
combinatorial characterizations of MECs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1&quot;&gt;Vidya Sagar Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04238">
<title>Bringing Quantum Algorithms to Automated Machine Learning: A Systematic Review of AutoML Frameworks Regarding Extensibility for QML Algorithms. (arXiv:2310.04238v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04238</link>
<description rdf:parseType="Literal">&lt;p&gt;This work describes the selection approach and analysis of existing AutoML
frameworks regarding their capability of a) incorporating Quantum Machine
Learning (QML) algorithms into this automated solving approach of the AutoML
framing and b) solving a set of industrial use-cases with different ML problem
types by benchmarking their most important characteristics. For that, available
open-source tools are condensed into a market overview and suitable frameworks
are systematically selected on a multi-phase, multi-criteria approach. This is
done by considering software selection approaches, as well as in terms of the
technical perspective of AutoML. The requirements for the framework selection
are divided into hard and soft criteria regarding their software and ML
attributes. Additionally, a classification of AutoML frameworks is made into
high- and low-level types, inspired by the findings of. Finally, we select Ray
and AutoGluon as the suitable low- and high-level frameworks respectively, as
they fulfil all requirements sufficiently and received the best evaluation
feedback during the use-case study. Based on those findings, we build an
extended Automated Quantum Machine Learning (AutoQML) framework with
QC-specific pipeline steps and decision characteristics for hardware and
software constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klau_D/0/1/0/all/0/1&quot;&gt;Dennis Klau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoller_M/0/1/0/all/0/1&quot;&gt;Marc Z&amp;#xf6;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tutschku_C/0/1/0/all/0/1&quot;&gt;Christian Tutschku&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04241">
<title>Comparing Auxiliary Tasks for Learning Representations for Reinforcement Learning. (arXiv:2310.04241v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04241</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning state representations has gained steady popularity in reinforcement
learning (RL) due to its potential to improve both sample efficiency and
returns on many environments. A straightforward and efficient method is to
generate representations with a distinct neural network trained on an auxiliary
task, i.e. a task that differs from the actual RL task. While a whole range of
such auxiliary tasks has been proposed in the literature, a comparison on
typical continuous control benchmark environments is computationally expensive
and has, to the best of our knowledge, not been performed before. This paper
presents such a comparison of common auxiliary tasks, based on hundreds of
agents trained with state-of-the-art off-policy RL algorithms. We compare
possible improvements in both sample efficiency and returns for environments
ranging from simple pendulum to a complex simulated robotics task. Our findings
show that representation learning with auxiliary tasks is beneficial for
environments of higher dimension and complexity, and that learning environment
dynamics is preferable to predicting rewards. We believe these insights will
enable other researchers to make more informed decisions on how to utilize
representation learning for their specific problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lange_M/0/1/0/all/0/1&quot;&gt;Moritz Lange&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krystiniak_N/0/1/0/all/0/1&quot;&gt;Noah Krystiniak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engelhardt_R/0/1/0/all/0/1&quot;&gt;Raphael C. Engelhardt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konen_W/0/1/0/all/0/1&quot;&gt;Wolfgang Konen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiskott_L/0/1/0/all/0/1&quot;&gt;Laurenz Wiskott&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04264">
<title>C(NN)FD -- deep learning predictions of tip clearance variations on multi-stage axial compressors aerodynamic performance. (arXiv:2310.04264v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04264</link>
<description rdf:parseType="Literal">&lt;p&gt;Application of deep learning methods to physical simulations such as CFD
(Computational Fluid Dynamics), have been so far of limited industrial
relevance. This paper demonstrates the development and application of a deep
learning framework for real-time predictions of the impact of tip clearance
variations on the aerodynamic performance of multi-stage axial compressors in
gas turbines. The proposed C(NN)FD architecture is proven to be scalable to
industrial applications, and achieves in real-time accuracy comparable to the
CFD benchmark. The deployed model, is readily integrated within the
manufacturing and build process of gas turbines, thus providing the opportunity
to analytically assess the impact on performance and potentially reduce
requirements for expensive physical tests.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruni_G/0/1/0/all/0/1&quot;&gt;Giuseppe Bruni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maleki_S/0/1/0/all/0/1&quot;&gt;Sepehr Maleki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnababu_S/0/1/0/all/0/1&quot;&gt;Senthil K. Krishnababu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04283">
<title>On the Error-Propagation of Inexact Deflation for Principal Component Analysis. (arXiv:2310.04283v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04283</link>
<description rdf:parseType="Literal">&lt;p&gt;Principal Component Analysis (PCA) is a popular tool in data analysis,
especially when the data is high-dimensional. PCA aims to find subspaces,
spanned by the so-called \textit{principal components}, that best explain the
variance in the dataset. The deflation method is a popular meta-algorithm --
used to discover such subspaces -- that sequentially finds individual principal
components, starting from the most important one and working its way towards
the less important ones. However, due to its sequential nature, the numerical
error introduced by not estimating principal components exactly -- e.g., due to
numerical approximations through this process -- propagates, as deflation
proceeds. To the best of our knowledge, this is the first work that
mathematically characterizes the error propagation of the inexact deflation
method, and this is the key contribution of this paper. We provide two main
results: $i)$ when the sub-routine for finding the leading eigenvector is
generic, and $ii)$ when power iteration is used as the sub-routine. In the
latter case, the additional directional information from power iteration allows
us to obtain a tighter error bound than the analysis of the sub-routine
agnostic case. As an outcome, we provide explicit characterization on how the
error progresses and affects subsequent principal component estimations for
this fundamental problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_F/0/1/0/all/0/1&quot;&gt;Fangshuo Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junhyung Lyle Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barnum_C/0/1/0/all/0/1&quot;&gt;Cruz Barnum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04285">
<title>Assessing Robustness via Score-Based Adversarial Image Generation. (arXiv:2310.04285v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.04285</link>
<description rdf:parseType="Literal">&lt;p&gt;Most adversarial attacks and defenses focus on perturbations within small
$\ell_p$-norm constraints. However, $\ell_p$ threat models cannot capture all
relevant semantic-preserving perturbations, and hence, the scope of robustness
evaluations is limited. In this work, we introduce Score-Based Adversarial
Generation (ScoreAG), a novel framework that leverages the advancements in
score-based generative models to generate adversarial examples beyond
$\ell_p$-norm constraints, so-called unrestricted adversarial examples,
overcoming their limitations. Unlike traditional methods, ScoreAG maintains the
core semantics of images while generating realistic adversarial examples,
either by transforming existing images or synthesizing new ones entirely from
scratch. We further exploit the generative capability of ScoreAG to purify
images, empirically enhancing the robustness of classifiers. Our extensive
empirical evaluation demonstrates that ScoreAG matches the performance of
state-of-the-art attacks and defenses across multiple benchmarks. This work
highlights the importance of investigating adversarial examples bounded by
semantics rather than $\ell_p$-norm constraints. ScoreAG represents an
important step towards more encompassing robustness assessments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kollovieh_M/0/1/0/all/0/1&quot;&gt;Marcel Kollovieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gosch_L/0/1/0/all/0/1&quot;&gt;Lukas Gosch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholten_Y/0/1/0/all/0/1&quot;&gt;Yan Scholten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lienen_M/0/1/0/all/0/1&quot;&gt;Marten Lienen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04292">
<title>Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets. (arXiv:2310.04292v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04292</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, pre-trained foundation models have enabled significant advancements
in multiple fields. In molecular machine learning, however, where datasets are
often hand-curated, and hence typically small, the lack of datasets with
labeled features, and codebases to manage those datasets, has hindered the
development of foundation models. In this work, we present seven novel datasets
categorized by size into three distinct categories: ToyMix, LargeMix and
UltraLarge. These datasets push the boundaries in both the scale and the
diversity of supervised labels for molecular learning. They cover nearly 100
million molecules and over 3000 sparsely defined tasks, totaling more than 13
billion individual labels of both quantum and biological nature. In comparison,
our datasets contain 300 times more data points than the widely used OGB-LSC
PCQM4Mv2 dataset, and 13 times more than the quantum-only QM1B dataset. In
addition, to support the development of foundational models based on our
proposed datasets, we present the Graphium graph machine learning library which
simplifies the process of building and training molecular machine learning
models for multi-task and multi-level molecular datasets. Finally, we present a
range of baseline results as a starting point of multi-task and multi-level
training on these datasets. Empirically, we observe that performance on
low-resource biological datasets show improvement by also training on large
amounts of quantum data. This indicates that there may be potential in
multi-task and multi-level training of a foundation model and fine-tuning it to
resource-constrained downstream tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beaini_D/0/1/0/all/0/1&quot;&gt;Dominique Beaini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shenyang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cunha_J/0/1/0/all/0/1&quot;&gt;Joao Alex Cunha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moisescu_Pareja_G/0/1/0/all/0/1&quot;&gt;Gabriela Moisescu-Pareja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dymov_O/0/1/0/all/0/1&quot;&gt;Oleksandr Dymov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maddrell_Mander_S/0/1/0/all/0/1&quot;&gt;Samuel Maddrell-Mander&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McLean_C/0/1/0/all/0/1&quot;&gt;Callum McLean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wenkel_F/0/1/0/all/0/1&quot;&gt;Frederik Wenkel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_L/0/1/0/all/0/1&quot;&gt;Luis M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohamud_J/0/1/0/all/0/1&quot;&gt;Jama Hussein Mohamud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parviz_A/0/1/0/all/0/1&quot;&gt;Ali Parviz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Craig_M/0/1/0/all/0/1&quot;&gt;Michael Craig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koziarski_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Koziarski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiarui Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhaocheng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabellini_C/0/1/0/all/0/1&quot;&gt;Cristian Gabellini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klaser_K/0/1/0/all/0/1&quot;&gt;Kerstin Klaser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dean_J/0/1/0/all/0/1&quot;&gt;Josef Dean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wognum_C/0/1/0/all/0/1&quot;&gt;Cas Wognum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sypetkowski_M/0/1/0/all/0/1&quot;&gt;Maciej Sypetkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1&quot;&gt;Guillaume Rabusseau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabbany_R/0/1/0/all/0/1&quot;&gt;Reihaneh Rabbany&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jian Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morris_C/0/1/0/all/0/1&quot;&gt;Christopher Morris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravanelli_M/0/1/0/all/0/1&quot;&gt;Mirco Ravanelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1&quot;&gt;Guy Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tossou_P/0/1/0/all/0/1&quot;&gt;Prudencio Tossou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mary_H/0/1/0/all/0/1&quot;&gt;Hadrien Mary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bois_T/0/1/0/all/0/1&quot;&gt;Therence Bois&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fitzgibbon_A/0/1/0/all/0/1&quot;&gt;Andrew Fitzgibbon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banaszewski_B/0/1/0/all/0/1&quot;&gt;B&amp;#x142;a&amp;#x17c;ej Banaszewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_C/0/1/0/all/0/1&quot;&gt;Chad Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1&quot;&gt;Dominic Masters&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04295">
<title>Identifying Representations for Intervention Extrapolation. (arXiv:2310.04295v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04295</link>
<description rdf:parseType="Literal">&lt;p&gt;The premise of identifiable and causal representation learning is to improve
the current representation learning paradigm in terms of generalizability or
robustness. Despite recent progress in questions of identifiability, more
theoretical results demonstrating concrete advantages of these methods for
downstream tasks are needed. In this paper, we consider the task of
intervention extrapolation: predicting how interventions affect an outcome,
even when those interventions are not observed at training time, and show that
identifiable representations can provide an effective solution to this task
even if the interventions affect the outcome non-linearly. Our setup includes
an outcome Y, observed features X, which are generated as a non-linear
transformation of latent features Z, and exogenous action variables A, which
influence Z. The objective of intervention extrapolation is to predict how
interventions on A that lie outside the training support of A affect Y. Here,
extrapolation becomes possible if the effect of A on Z is linear and the
residual when regressing Z on A has full support. As Z is latent, we combine
the task of intervention extrapolation with identifiable representation
learning, which we call Rep4Ex: we aim to map the observed features X into a
subspace that allows for non-linear extrapolation in A. We show using Wiener&apos;s
Tauberian theorem that the hidden representation is identifiable up to an
affine transformation in Z-space, which is sufficient for intervention
extrapolation. The identifiability is characterized by a novel constraint
describing the linearity assumption of A on Z. Based on this insight, we
propose a method that enforces the linear invariance constraint and can be
combined with any type of autoencoder. We validate our theoretical findings
through synthetic experiments and show that our approach succeeds in predicting
the effects of unseen interventions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saengkyongam_S/0/1/0/all/0/1&quot;&gt;Sorawit Saengkyongam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenfeld_E/0/1/0/all/0/1&quot;&gt;Elan Rosenfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfister_N/0/1/0/all/0/1&quot;&gt;Niklas Pfister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1&quot;&gt;Jonas Peters&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04299">
<title>Convergent ADMM Plug and Play PET Image Reconstruction. (arXiv:2310.04299v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2310.04299</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we investigate hybrid PET reconstruction algorithms based on
coupling a model-based variational reconstruction and the application of a
separately learnt Deep Neural Network operator (DNN) in an ADMM Plug and Play
framework. Following recent results in optimization, fixed point convergence of
the scheme can be achieved by enforcing an additional constraint on network
parameters during learning. We propose such an ADMM algorithm and show in a
realistic [18F]-FDG synthetic brain exam that the proposed scheme indeed lead
experimentally to convergence to a meaningful fixed point. When the proposed
constraint is not enforced during learning of the DNN, the proposed ADMM
algorithm was observed experimentally not to converge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sureau_F/0/1/0/all/0/1&quot;&gt;Florent Sureau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Latreche_M/0/1/0/all/0/1&quot;&gt;Mahdi Latreche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Savanier_M/0/1/0/all/0/1&quot;&gt;Marion Savanier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Comtat_C/0/1/0/all/0/1&quot;&gt;Claude Comtat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04311">
<title>Distributed Deep Joint Source-Channel Coding with Decoder-Only Side Information. (arXiv:2310.04311v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.04311</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider low-latency image transmission over a noisy wireless channel when
correlated side information is present only at the receiver side (the Wyner-Ziv
scenario). In particular, we are interested in developing practical schemes
using a data-driven joint source-channel coding (JSCC) approach, which has been
previously shown to outperform conventional separation-based approaches in the
practical finite blocklength regimes, and to provide graceful degradation with
channel quality. We propose a novel neural network architecture that
incorporates the decoder-only side information at multiple stages at the
receiver side. Our results demonstrate that the proposed method succeeds in
integrating the side information, yielding improved performance at all channel
noise levels in terms of the various distortion criteria considered here,
especially at low channel signal-to-noise ratios (SNRs) and small bandwidth
ratios (BRs). We also provide the source code of the proposed method to enable
further research and reproducibility of the results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yilmaz_S/0/1/0/all/0/1&quot;&gt;Selim F. Yilmaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozyilkan_E/0/1/0/all/0/1&quot;&gt;Ezgi Ozyilkan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1&quot;&gt;Deniz Gunduz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erkip_E/0/1/0/all/0/1&quot;&gt;Elza Erkip&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04314">
<title>Latent Graph Inference with Limited Supervision. (arXiv:2310.04314v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04314</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent graph inference (LGI) aims to jointly learn the underlying graph
structure and node representations from data features. However, existing LGI
methods commonly suffer from the issue of supervision starvation, where massive
edge weights are learned without semantic supervision and do not contribute to
the training loss. Consequently, these supervision-starved weights, which may
determine the predictions of testing samples, cannot be semantically optimal,
resulting in poor generalization. In this paper, we observe that this issue is
actually caused by the graph sparsification operation, which severely destroys
the important connections established between pivotal nodes and labeled ones.
To address this, we propose to restore the corrupted affinities and replenish
the missed supervision for better LGI. The key challenge then lies in
identifying the critical nodes and recovering the corrupted affinities. We
begin by defining the pivotal nodes as $k$-hop starved nodes, which can be
identified based on a given adjacency matrix. Considering the high
computational burden, we further present a more efficient alternative inspired
by CUR matrix decomposition. Subsequently, we eliminate the starved nodes by
reconstructing the destroyed connections. Extensive experiments on
representative benchmarks demonstrate that reducing the starved nodes
consistently improves the performance of state-of-the-art LGI methods,
especially under extremely limited supervision (6.12% improvement on Pubmed
with a labeling rate of only 0.3%).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jianglin Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yue Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yun Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04323">
<title>Adjustable Robust Reinforcement Learning for Online 3D Bin Packing. (arXiv:2310.04323v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04323</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing effective policies for the online 3D bin packing problem (3D-BPP)
has been a long-standing challenge, primarily due to the unpredictable nature
of incoming box sequences and stringent physical constraints. While current
deep reinforcement learning (DRL) methods for online 3D-BPP have shown
promising results in optimizing average performance over an underlying box
sequence distribution, they often fail in real-world settings where some
worst-case scenarios can materialize. Standard robust DRL algorithms tend to
overly prioritize optimizing the worst-case performance at the expense of
performance under normal problem instance distribution. To address these
issues, we first introduce a permutation-based attacker to investigate the
practical robustness of both DRL-based and heuristic methods proposed for
solving online 3D-BPP. Then, we propose an adjustable robust reinforcement
learning (AR2L) framework that allows efficient adjustment of robustness
weights to achieve the desired balance of the policy&apos;s performance in average
and worst-case environments. Specifically, we formulate the objective function
as a weighted sum of expected and worst-case returns, and derive the lower
performance bound by relating to the return under a mixture dynamics. To
realize this lower bound, we adopt an iterative procedure that searches for the
associated mixture dynamics and improves the corresponding policy. We integrate
this procedure into two popular robust adversarial algorithms to develop the
exact and approximate AR2L algorithms. Experiments demonstrate that AR2L is
versatile in the sense that it improves policy robustness while maintaining an
acceptable level of performance for the nominal case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yuxin Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yize Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1&quot;&gt;Fangzhen Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04327">
<title>Program Synthesis with Best-First Bottom-Up Search. (arXiv:2310.04327v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04327</link>
<description rdf:parseType="Literal">&lt;p&gt;Cost-guided bottom-up search (BUS) algorithms use a cost function to guide
the search to solve program synthesis tasks. In this paper, we show that
current state-of-the-art cost-guided BUS algorithms suffer from a common
problem: they can lose useful information given by the model and fail to
perform the search in a best-first order according to a cost function. We
introduce a novel best-first bottom-up search algorithm, which we call Bee
Search, that does not suffer information loss and is able to perform
cost-guided bottom-up synthesis in a best-first manner. Importantly, Bee Search
performs best-first search with respect to the generation of programs, i.e., it
does not even create in memory programs that are more expensive than the
solution program. It attains best-first ordering with respect to generation by
performing a search in an abstract space of program costs. We also introduce a
new cost function that better uses the information provided by an existing cost
model. Empirical results on string manipulation and bit-vector tasks show that
Bee Search can outperform existing cost-guided BUS approaches when employing
more complex domain-specific languages (DSLs); Bee Search and previous
approaches perform equally well with simpler DSLs. Furthermore, our new cost
function with Bee Search outperforms previous cost functions on string
manipulation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ameen_S/0/1/0/all/0/1&quot;&gt;Saqib Ameen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lelis_L/0/1/0/all/0/1&quot;&gt;Levi H. S. Lelis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04328">
<title>Robust Losses for Decision-Focused Learning. (arXiv:2310.04328v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04328</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimization models used to make discrete decisions often contain uncertain
parameters that are context-dependent and are estimated through prediction. To
account for the quality of the decision made based on the prediction,
decision-focused learning (end-to-end predict-then-optimize) aims at training
the predictive model to minimize regret, i.e., the loss incurred by making a
suboptimal decision. Despite the challenge of this loss function being possibly
non-convex and in general non-differentiable, effective gradient-based learning
approaches have been proposed to minimize the expected loss, using the
empirical loss as a surrogate. However, empirical regret can be an ineffective
surrogate because the uncertainty in the optimization model makes the empirical
regret unequal to the expected regret in expectation. To illustrate the impact
of this inequality, we evaluate the effect of aleatoric and epistemic
uncertainty on the accuracy of empirical regret as a surrogate. Next, we
propose three robust loss functions that more closely approximate expected
regret. Experimental results show that training two state-of-the-art
decision-focused learning approaches using robust regret losses improves
test-sample empirical regret in general while keeping computational time
equivalent relative to the number of training epochs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schutte_N/0/1/0/all/0/1&quot;&gt;Noah Schutte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Postek_K/0/1/0/all/0/1&quot;&gt;Krzysztof Postek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yorke_Smith_N/0/1/0/all/0/1&quot;&gt;Neil Yorke-Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04334">
<title>Saliency-Guided Hidden Associative Replay for Continual Learning. (arXiv:2310.04334v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04334</link>
<description rdf:parseType="Literal">&lt;p&gt;Continual Learning is a burgeoning domain in next-generation AI, focusing on
training neural networks over a sequence of tasks akin to human learning. While
CL provides an edge over traditional supervised learning, its central challenge
remains to counteract catastrophic forgetting and ensure the retention of prior
tasks during subsequent learning. Amongst various strategies to tackle this,
replay based methods have emerged as preeminent, echoing biological memory
mechanisms. However, these methods are memory intensive, often preserving
entire data samples, an approach inconsistent with humans selective memory
retention of salient experiences. While some recent works have explored the
storage of only significant portions of data in episodic memory, the inherent
nature of partial data necessitates innovative retrieval mechanisms. Current
solutions, like inpainting, approximate full data reconstruction from partial
cues, a method that diverges from genuine human memory processes. Addressing
these nuances, this paper presents the Saliency Guided Hidden Associative
Replay for Continual Learning. This novel framework synergizes associative
memory with replay-based strategies. SHARC primarily archives salient data
segments via sparse memory encoding. Importantly, by harnessing associative
memory paradigms, it introduces a content focused memory retrieval mechanism,
promising swift and near-perfect recall, bringing CL a step closer to authentic
human memory processes. Extensive experimental results demonstrate the
effectiveness of our proposed method for various continual learning tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_G/0/1/0/all/0/1&quot;&gt;Guangji Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qilong Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1&quot;&gt;Xiaoyang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yifei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Liang Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04336">
<title>Applying Reinforcement Learning to Option Pricing and Hedging. (arXiv:2310.04336v1 [q-fin.CP])</title>
<link>http://arxiv.org/abs/2310.04336</link>
<description rdf:parseType="Literal">&lt;p&gt;This thesis provides an overview of the recent advances in reinforcement
learning in pricing and hedging financial instruments, with a primary focus on
a detailed explanation of the Q-Learning Black Scholes approach, introduced by
Halperin (2017). This reinforcement learning approach bridges the traditional
Black and Scholes (1973) model with novel artificial intelligence algorithms,
enabling option pricing and hedging in a completely model-free and data-driven
way. This paper also explores the algorithm&apos;s performance under different state
variables and scenarios for a European put option. The results reveal that the
model is an accurate estimator under different levels of volatility and hedging
frequency. Moreover, this method exhibits robust performance across various
levels of option&apos;s moneyness. Lastly, the algorithm incorporates proportional
transaction costs, indicating diverse impacts on profit and loss, affected by
different statistical properties of the state variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Stoiljkovic_Z/0/1/0/all/0/1&quot;&gt;Zoran Stoiljkovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04343">
<title>Functional Geometry Guided Protein Sequence and Backbone Structure Co-Design. (arXiv:2310.04343v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04343</link>
<description rdf:parseType="Literal">&lt;p&gt;Proteins are macromolecules responsible for essential functions in almost all
living organisms. Designing reasonable proteins with desired functions is
crucial. A protein&apos;s sequence and structure are strongly correlated and they
together determine its function. In this paper, we propose NAEPro, a model to
jointly design Protein sequence and structure based on automatically detected
functional sites. NAEPro is powered by an interleaving network of attention and
equivariant layers, which can capture global correlation in a whole sequence
and local influence from nearest amino acids in three dimensional (3D) space.
Such an architecture facilitates effective yet economic message passing at two
levels. We evaluate our model and several strong baselines on two protein
datasets, $\beta$-lactamase and myoglobin. Experimental results show that our
model consistently achieves the highest amino acid recovery rate, TM-score, and
the lowest RMSD among all competitors. These findings prove the capability of
our model to design protein sequences and structures that closely resemble
their natural counterparts. Furthermore, in-depth analysis further confirms our
model&apos;s ability to generate highly effective proteins capable of binding to
their target metallocofactors. We provide code, data and models in Github.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhenqiao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yunlong Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1&quot;&gt;Wenxian Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lei Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04345">
<title>Neur2RO: Neural Two-Stage Robust Optimization. (arXiv:2310.04345v1 [math.OC])</title>
<link>http://arxiv.org/abs/2310.04345</link>
<description rdf:parseType="Literal">&lt;p&gt;Robust optimization provides a mathematical framework for modeling and
solving decision-making problems under worst-case uncertainty. This work
addresses two-stage robust optimization (2RO) problems (also called adjustable
robust optimization), wherein first-stage and second-stage decisions are made
before and after uncertainty is realized, respectively. This results in a
nested min-max-min optimization problem which is extremely challenging
computationally, especially when the decisions are discrete. We propose
Neur2RO, an efficient machine learning-driven instantiation of
column-and-constraint generation (CCG), a classical iterative algorithm for
2RO. Specifically, we learn to estimate the value function of the second-stage
problem via a novel neural network architecture that is easy to optimize over
by design. Embedding our neural network into CCG yields high-quality solutions
quickly as evidenced by experiments on two 2RO benchmarks, knapsack and capital
budgeting. For knapsack, Neur2RO finds solutions that are within roughly $2\%$
of the best-known values in a few seconds compared to the three hours of the
state-of-the-art exact branch-and-price algorithm; for larger and more complex
instances, Neur2RO finds even better solutions. For capital budgeting, Neur2RO
outperforms three variants of the $k$-adaptability algorithm, particularly on
the largest instances, with a 5 to 10-fold reduction in solution time. Our code
and data are available at https://github.com/khalil-research/Neur2RO.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dumouchelle_J/0/1/0/all/0/1&quot;&gt;Justin Dumouchelle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Julien_E/0/1/0/all/0/1&quot;&gt;Esther Julien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kurtz_J/0/1/0/all/0/1&quot;&gt;Jannis Kurtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Khalil_E/0/1/0/all/0/1&quot;&gt;Elias B. Khalil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04349">
<title>Learning to Grasp: from Somewhere to Anywhere. (arXiv:2310.04349v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2310.04349</link>
<description rdf:parseType="Literal">&lt;p&gt;Robotic grasping is still a partially solved, multidisciplinary problem where
data-driven techniques play an increasing role. The sparse nature of rewards
make the automatic generation of grasping datasets challenging, especially for
unconventional morphologies or highly actuated end-effectors. Most approaches
for obtaining large-scale datasets rely on numerous human-provided
demonstrations or heavily engineered solutions that do not scale well. Recent
advances in Quality-Diversity (QD) methods have investigated how to learn
object grasping at a specific pose with different robot morphologies. The
present work introduces a pipeline for adapting QD-generated trajectories to
new object poses. Using an RGB-D data stream, the vision pipeline first detects
the targeted object, predicts its 6-DOF pose, and finally tracks it. An
automatically generated reach-and-grasp trajectory can then be adapted by
projecting it relatively to the object frame. Hundreds of trajectories have
been deployed into the real world on several objects and with different robotic
setups: a Franka Research 3 with a parallel gripper and a UR5 with a dexterous
SIH Schunk hand. The transfer ratio obtained when applying transformation to
the object pose matches the one obtained when the object pose matches the
simulation, demonstrating the efficiency of the proposed approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helenon_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois H&amp;#xe9;l&amp;#xe9;non&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huber_J/0/1/0/all/0/1&quot;&gt;Johann Huber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amar_F/0/1/0/all/0/1&quot;&gt;Fa&amp;#xef;z Ben Amar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doncieux_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Doncieux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04352">
<title>Fair Feature Importance Scores for Interpreting Tree-Based Methods and Surrogates. (arXiv:2310.04352v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.04352</link>
<description rdf:parseType="Literal">&lt;p&gt;Across various sectors such as healthcare, criminal justice, national
security, finance, and technology, large-scale machine learning (ML) and
artificial intelligence (AI) systems are being deployed to make critical
data-driven decisions. Many have asked if we can and should trust these ML
systems to be making these decisions. Two critical components are prerequisites
for trust in ML systems: interpretability, or the ability to understand why the
ML system makes the decisions it does, and fairness, which ensures that ML
systems do not exhibit bias against certain individuals or groups. Both
interpretability and fairness are important and have separately received
abundant attention in the ML literature, but so far, there have been very few
methods developed to directly interpret models with regard to their fairness.
In this paper, we focus on arguably the most popular type of ML interpretation:
feature importance scores. Inspired by the use of decision trees in knowledge
distillation, we propose to leverage trees as interpretable surrogates for
complex black-box ML models. Specifically, we develop a novel fair feature
importance score for trees that can be used to interpret how each feature
contributes to fairness or bias in trees, tree-based ensembles, or tree-based
surrogates of any complex ML system. Like the popular mean decrease in impurity
for trees, our Fair Feature Importance Score is defined based on the mean
decrease (or increase) in group bias. Through simulations as well as real
examples on benchmark fairness datasets, we demonstrate that our Fair Feature
Importance Score offers valid interpretations for both tree-based ensembles and
tree-based surrogates of other ML systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Little_C/0/1/0/all/0/1&quot;&gt;Camille Olivia Little&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lina_D/0/1/0/all/0/1&quot;&gt;Debolina Halder Lina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Allen_G/0/1/0/all/0/1&quot;&gt;Genevera I. Allen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04353">
<title>A Language-Agent Approach to Formal Theorem-Proving. (arXiv:2310.04353v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04353</link>
<description rdf:parseType="Literal">&lt;p&gt;Language agents, which use a large language model (LLM) capable of in-context
learning to interact with an external environment, have recently emerged as a
promising approach to control tasks. We present the first language-agent
approach to formal theorem-proving. Our method, COPRA, uses a high-capacity,
black-box LLM (GPT-4) as part of a policy for a stateful backtracking search.
During the search, the policy can select proof tactics and retrieve lemmas and
definitions from an external database. Each selected tactic is executed in the
underlying proof framework, and the execution feedback is used to build the
prompt for the next policy invocation. The search also tracks selected
information from its history and uses it to reduce hallucinations and
unnecessary LLM queries.
&lt;/p&gt;
&lt;p&gt;We evaluate COPRA on the miniF2F benchmark for Lean and a set of Coq tasks
from the Compcert project. On these benchmarks, COPRA is significantly better
than one-shot invocations of GPT-4, as well as state-of-the-art models
fine-tuned on proof data, at finding correct proofs quickly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakur_A/0/1/0/all/0/1&quot;&gt;Amitayush Thakur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yeming Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1&quot;&gt;Swarat Chaudhuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04354">
<title>Integrating Transformations in Probabilistic Circuits. (arXiv:2310.04354v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.04354</link>
<description rdf:parseType="Literal">&lt;p&gt;This study addresses the predictive limitation of probabilistic circuits and
introduces transformations as a remedy to overcome it. We demonstrate this
limitation in robotic scenarios. We motivate that independent component
analysis is a sound tool to preserve the independence properties of
probabilistic circuits. Our approach is an extension of joint probability
trees, which are model-free deterministic circuits. By doing so, it is
demonstrated that the proposed approach is able to achieve higher likelihoods
while using fewer parameters compared to the joint probability trees on seven
benchmark data sets as well as on real robot data. Furthermore, we discuss how
to integrate transformations into tree-based learning routines. Finally, we
argue that exact inference with transformed quantile parameterized
distributions is not tractable. However, our approach allows for efficient
sampling and approximate inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schierenbeck_T/0/1/0/all/0/1&quot;&gt;Tom Schierenbeck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vutov_V/0/1/0/all/0/1&quot;&gt;Vladimir Vutov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dickhaus_T/0/1/0/all/0/1&quot;&gt;Thorsten Dickhaus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Beetz_M/0/1/0/all/0/1&quot;&gt;Michael Beetz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04361">
<title>Exploiting Transformer Activation Sparsity with Dynamic Inference. (arXiv:2310.04361v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04361</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer models, despite their impressive performance, often face
practical limitations due to their high computational requirements. At the same
time, previous studies have revealed significant activation sparsity in these
models, indicating the presence of redundant computations. In this paper, we
propose Dynamic Sparsified Transformer Inference (DSTI), a method that
radically reduces the inference cost of Transformer models by enforcing
activation sparsity and subsequently transforming a dense model into its sparse
Mixture of Experts (MoE) version. We demonstrate that it is possible to train
small gating networks that successfully predict the relative contribution of
each expert during inference. Furthermore, we introduce a mechanism that
dynamically determines the number of executed experts individually for each
token. DSTI can be applied to any Transformer-based architecture and has
negligible impact on the accuracy. For the BERT-base classification model, we
reduce inference cost by almost 60%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piorczynski_M/0/1/0/all/0/1&quot;&gt;Miko&amp;#x142;aj Pi&amp;#xf3;rczy&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szatkowski_F/0/1/0/all/0/1&quot;&gt;Filip Szatkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balazy_K/0/1/0/all/0/1&quot;&gt;Klaudia Ba&amp;#x142;azy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wojcik_B/0/1/0/all/0/1&quot;&gt;Bartosz W&amp;#xf3;jcik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04363">
<title>Amortizing intractable inference in large language models. (arXiv:2310.04363v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04363</link>
<description rdf:parseType="Literal">&lt;p&gt;Autoregressive large language models (LLMs) compress knowledge from their
training data through next-token conditional distributions. This limits
tractable querying of this knowledge to start-to-end autoregressive sampling.
However, many tasks of interest -- including sequence continuation, infilling,
and other forms of constrained generation -- involve sampling from intractable
posterior distributions. We address this limitation by using amortized Bayesian
inference to sample from these intractable posteriors. Such amortization is
algorithmically achieved by fine-tuning LLMs via diversity-seeking
reinforcement learning algorithms: generative flow networks (GFlowNets). We
empirically demonstrate that this distribution-matching paradigm of LLM
fine-tuning can serve as an effective alternative to maximum-likelihood
training and reward-maximizing policy optimization. As an important
application, we interpret chain-of-thought reasoning as a latent variable
modeling problem and demonstrate that our approach enables data-efficient
adaptation of LLMs to tasks that require multi-step rationalization and tool
use.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1&quot;&gt;Edward J. Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1&quot;&gt;Moksh Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elmoznino_E/0/1/0/all/0/1&quot;&gt;Eric Elmoznino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaddar_Y/0/1/0/all/0/1&quot;&gt;Younesse Kaddar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lajoie_G/0/1/0/all/0/1&quot;&gt;Guillaume Lajoie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malkin_N/0/1/0/all/0/1&quot;&gt;Nikolay Malkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04367">
<title>A Marketplace Price Anomaly Detection System at Scale. (arXiv:2310.04367v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.04367</link>
<description rdf:parseType="Literal">&lt;p&gt;Online marketplaces execute large volume of price updates that are initiated
by individual marketplace sellers each day on the platform. This price
democratization comes with increasing challenges with data quality. Lack of
centralized guardrails that are available for a traditional online retailer
causes a higher likelihood for inaccurate prices to get published on the
website, leading to poor customer experience and potential for revenue loss. We
present MoatPlus (Masked Optimal Anchors using Trees, Proximity-based Labeling
and Unsupervised Statistical-features), a scalable price anomaly detection
framework for a growing marketplace platform. The goal is to leverage proximity
and historical price trends from unsupervised statistical features to generate
an upper price bound. We build an ensemble of models to detect irregularities
in price-based features, exclude irregular features and use optimized weighting
scheme to build a reliable price bound in real-time pricing pipeline. We
observed that our approach improves precise anchor coverage by up to 46.6% in
high-vulnerability item subsets
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sarpal_A/0/1/0/all/0/1&quot;&gt;Akshit Sarpal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kang_Q/0/1/0/all/0/1&quot;&gt;Qiwen Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Fangping Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yang Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wan_L/0/1/0/all/0/1&quot;&gt;Lijie Wan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04369">
<title>MBTFNet: Multi-Band Temporal-Frequency Neural Network For Singing Voice Enhancement. (arXiv:2310.04369v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2310.04369</link>
<description rdf:parseType="Literal">&lt;p&gt;A typical neural speech enhancement (SE) approach mainly handles speech and
noise mixtures, which is not optimal for singing voice enhancement scenarios.
Music source separation (MSS) models treat vocals and various accompaniment
components equally, which may reduce performance compared to the model that
only considers vocal enhancement. In this paper, we propose a novel multi-band
temporal-frequency neural network (MBTFNet) for singing voice enhancement,
which particularly removes background music, noise and even backing vocals from
singing recordings. MBTFNet combines inter and intra-band modeling for better
processing of full-band signals. Dual-path modeling are introduced to expand
the receptive field of the model. We propose an implicit personalized
enhancement (IPE) stage based on signal-to-noise ratio (SNR) estimation, which
further improves the performance of MBTFNet. Experiments show that our proposed
model significantly outperforms several state-of-the-art SE and MSS models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Weiming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhouxuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1&quot;&gt;Zhili Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_S/0/1/0/all/0/1&quot;&gt;Shubo Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_R/0/1/0/all/0/1&quot;&gt;Runduo Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wenjiang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Weifeng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1&quot;&gt;Lei Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04373">
<title>Confronting Reward Model Overoptimization with Constrained RLHF. (arXiv:2310.04373v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04373</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models are typically aligned with human preferences by
optimizing $\textit{reward models}$ (RMs) fitted to human feedback. However,
human preferences are multi-faceted, and it is increasingly common to derive
reward from a composition of simpler reward models which each capture a
different aspect of language quality. This itself presents a challenge, as it
is difficult to appropriately weight these component RMs when combining them.
Compounding this difficulty, because any RM is only a proxy for human
evaluation, this process is vulnerable to $\textit{overoptimization}$, wherein
past a certain point, accumulating higher reward is associated with worse human
ratings. In this paper, we perform, to our knowledge, the first study on
overoptimization in composite RMs, showing that correlation between component
RMs has a significant effect on the locations of these points. We then
introduce an approach to solve this issue using constrained reinforcement
learning as a means of preventing the agent from exceeding each RM&apos;s threshold
of usefulness. Our method addresses the problem of weighting component RMs by
learning dynamic weights, naturally given by the Lagrange multipliers. As a
result, each RM stays within the range at which it is an effective proxy,
improving evaluation performance. Finally, we introduce an adaptive method
using gradient-free optimization to identify and optimize towards these points
during a single run.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moskovitz_T/0/1/0/all/0/1&quot;&gt;Ted Moskovitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Aaditya K. Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strouse_D/0/1/0/all/0/1&quot;&gt;DJ Strouse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandholm_T/0/1/0/all/0/1&quot;&gt;Tuomas Sandholm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca D. Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McAleer_S/0/1/0/all/0/1&quot;&gt;Stephen McAleer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04378">
<title>Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference. (arXiv:2310.04378v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2310.04378</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent Diffusion models (LDMs) have achieved remarkable results in
synthesizing high-resolution images. However, the iterative sampling process is
computationally intensive and leads to slow generation. Inspired by Consistency
Models (song et al.), we propose Latent Consistency Models (LCMs), enabling
swift inference with minimal steps on any pre-trained LDMs, including Stable
Diffusion (rombach et al). Viewing the guided reverse diffusion process as
solving an augmented probability flow ODE (PF-ODE), LCMs are designed to
directly predict the solution of such ODE in latent space, mitigating the need
for numerous iterations and allowing rapid, high-fidelity sampling. Efficiently
distilled from pre-trained classifier-free guided diffusion models, a
high-quality 768 x 768 2~4-step LCM takes only 32 A100 GPU hours for training.
Furthermore, we introduce Latent Consistency Fine-tuning (LCF), a novel method
that is tailored for fine-tuning LCMs on customized image datasets. Evaluation
on the LAION-5B-Aesthetics dataset demonstrates that LCMs achieve
state-of-the-art text-to-image generation performance with few-step inference.
Project Page: https://latent-consistency-models.github.io/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1&quot;&gt;Simian Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1&quot;&gt;Yiqin Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Longbo Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Hang Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04395">
<title>Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference. (arXiv:2310.04395v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04395</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a method to improve the efficiency and accuracy of amortized
Bayesian inference (ABI) by leveraging universal symmetries in the
probabilistic joint model $p(\theta, y)$ of parameters $\theta$ and data $y$.
In a nutshell, we invert Bayes&apos; theorem and estimate the marginal likelihood
based on approximate representations of the joint model. Upon perfect
approximation, the marginal likelihood is constant across all parameter values
by definition. However, approximation error leads to undesirable variance in
the marginal likelihood estimates across different parameter values. We
formulate violations of this symmetry as a loss function to accelerate the
learning dynamics of conditional neural density estimators. We apply our method
to a bimodal toy problem with an explicit likelihood (likelihood-based) and a
realistic model with an implicit likelihood (simulation-based).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmitt_M/0/1/0/all/0/1&quot;&gt;Marvin Schmitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habermann_D/0/1/0/all/0/1&quot;&gt;Daniel Habermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burkner_P/0/1/0/all/0/1&quot;&gt;Paul-Christian B&amp;#xfc;rkner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothe_U/0/1/0/all/0/1&quot;&gt;Ullrich K&amp;#xf6;the&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radev_S/0/1/0/all/0/1&quot;&gt;Stefan T. Radev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04400">
<title>On the Embedding Collapse when Scaling up Recommendation Models. (arXiv:2310.04400v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04400</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in deep foundation models have led to a promising trend of
developing large recommendation models to leverage vast amounts of available
data. However, we experiment to scale up existing recommendation models and
observe that the enlarged models do not improve satisfactorily. In this
context, we investigate the embedding layers of enlarged models and identify a
phenomenon of embedding collapse, which ultimately hinders scalability, wherein
the embedding matrix tends to reside in a low-dimensional subspace. Through
empirical and theoretical analysis, we demonstrate that the feature interaction
module specific to recommendation models has a two-sided effect. On the one
hand, the interaction restricts embedding learning when interacting with
collapsed embeddings, exacerbating the collapse issue. On the other hand,
feature interaction is crucial in mitigating the fitting of spurious features,
thereby improving scalability. Based on this analysis, we propose a simple yet
effective multi-embedding design incorporating embedding-set-specific
interaction modules to capture diverse patterns and reduce collapse. Extensive
experiments demonstrate that this proposed design provides consistent
scalability for various recommendation models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xingzhuo Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1&quot;&gt;Junwei Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Ximei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Baixu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jie Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1&quot;&gt;Mingsheng Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04406">
<title>Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models. (arXiv:2310.04406v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2310.04406</link>
<description rdf:parseType="Literal">&lt;p&gt;While large language models (LLMs) have demonstrated impressive performance
on a range of decision-making tasks, they rely on simple acting processes and
fall short of broad deployment as autonomous agents. We introduce LATS
(Language Agent Tree Search), a general framework that synergizes the
capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration
from Monte Carlo tree search in model-based reinforcement learning, LATS
employs LLMs as agents, value functions, and optimizers, repurposing their
latent strengths for enhanced decision-making. What is crucial in this method
is the use of an environment for external feedback, which offers a more
deliberate and adaptive problem-solving mechanism that moves beyond the
limitations of existing techniques. Our experimental evaluation across diverse
domains, such as programming, HotPotQA, and WebShop, illustrates the
applicability of LATS for both reasoning and acting. In particular, LATS
achieves 94.4\% for programming on HumanEval with GPT-4 and an average score of
75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness
and generality of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Andy Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1&quot;&gt;Kai Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlapentokh_Rothman_M/0/1/0/all/0/1&quot;&gt;Michal Shlapentokh-Rothman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haohan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04407">
<title>Policy-Gradient Training of Language Models for Ranking. (arXiv:2310.04407v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2310.04407</link>
<description rdf:parseType="Literal">&lt;p&gt;Text retrieval plays a crucial role in incorporating factual knowledge for
decision making into language processing pipelines, ranging from chat-based web
search to question answering systems. Current state-of-the-art text retrieval
models leverage pre-trained large language models (LLMs) to achieve competitive
performance, but training LLM-based retrievers via typical contrastive losses
requires intricate heuristics, including selecting hard negatives and using
additional supervision as learning signals. This reliance on heuristics stems
from the fact that the contrastive loss itself is heuristic and does not
directly optimize the downstream metrics of decision quality at the end of the
processing pipeline. To address this issue, we introduce Neural PG-RANK, a
novel training algorithm that learns to rank by instantiating a LLM as a
Plackett-Luce ranking policy. Neural PG-RANK provides a principled method for
end-to-end training of retrieval models as part of larger decision systems via
policy gradient, with little reliance on complex heuristics, and it effectively
unifies the training objective with downstream decision-making quality. We
conduct extensive experiments on various text retrieval benchmarks. The results
demonstrate that when the training objective aligns with the evaluation setup,
Neural PG-RANK yields remarkable in-domain performance improvement, with
substantial out-of-domain generalization to some critical datasets employed in
downstream question answering tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1&quot;&gt;Ge Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1&quot;&gt;Jonathan D. Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardie_C/0/1/0/all/0/1&quot;&gt;Claire Cardie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brantley_K/0/1/0/all/0/1&quot;&gt;Kiant&amp;#xe9; Brantley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joachim_T/0/1/0/all/0/1&quot;&gt;Thorsten Joachim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04411">
<title>Understanding, Predicting and Better Resolving Q-Value Divergence in Offline-RL. (arXiv:2310.04411v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04411</link>
<description rdf:parseType="Literal">&lt;p&gt;The divergence of the Q-value estimation has been a prominent issue in
offline RL, where the agent has no access to real dynamics. Traditional beliefs
attribute this instability to querying out-of-distribution actions when
bootstrapping value targets. Though this issue can be alleviated with policy
constraints or conservative Q estimation, a theoretical understanding of the
underlying mechanism causing the divergence has been absent. In this work, we
aim to thoroughly comprehend this mechanism and attain an improved solution. We
first identify a fundamental pattern, self-excitation, as the primary cause of
Q-value estimation divergence in offline RL. Then, we propose a novel
Self-Excite Eigenvalue Measure (SEEM) metric based on Neural Tangent Kernel
(NTK) to measure the evolving property of Q-network at training, which provides
an intriguing explanation of the emergence of divergence. For the first time,
our theory can reliably decide whether the training will diverge at an early
stage, and even predict the order of the growth for the estimated Q-value, the
model&apos;s norm, and the crashing step when an SGD optimizer is used. The
experiments demonstrate perfect alignment with this theoretic analysis.
Building on our insights, we propose to resolve divergence from a novel
perspective, namely improving the model&apos;s architecture for better extrapolating
behavior. Through extensive empirical studies, we identify LayerNorm as a good
solution to effectively avoid divergence without introducing detrimental bias,
leading to superior performance. Experimental results prove that it can still
work in some most challenging settings, i.e. using only 1 transitions of the
dataset, where all previous methods fail. Moreover, it can be easily plugged
into modern offline RL methods and achieve SOTA results on many challenging
tasks. We also give unique insights into its effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yang Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1&quot;&gt;Rui Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_B/0/1/0/all/0/1&quot;&gt;Bingyi Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Shiji Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1&quot;&gt;Gao Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04413">
<title>Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets. (arXiv:2310.04413v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04413</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline policy learning is aimed at learning decision-making policies using
existing datasets of trajectories without collecting additional data. The
primary motivation for using reinforcement learning (RL) instead of supervised
learning techniques such as behavior cloning is to find a policy that achieves
a higher average return than the trajectories constituting the dataset.
However, we empirically find that when a dataset is dominated by suboptimal
trajectories, state-of-the-art offline RL algorithms do not substantially
improve over the average return of trajectories in the dataset. We argue this
is due to an assumption made by current offline RL algorithms of staying close
to the trajectories in the dataset. If the dataset primarily consists of
sub-optimal trajectories, this assumption forces the policy to mimic the
suboptimal actions. We overcome this issue by proposing a sampling strategy
that enables the policy to only be constrained to ``good data&quot; rather than all
actions in the dataset (i.e., uniform sampling). We present a realization of
the sampling strategy and an algorithm that can be used as a plug-and-play
module in standard offline RL algorithms. Our evaluation demonstrates
significant performance gains in 72 imbalanced datasets, D4RL dataset, and
across three different offline RL algorithms. Code is available at
https://github.com/Improbable-AI/dw-offline-rl.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1&quot;&gt;Zhang-Wei Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Aviral Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karnik_S/0/1/0/all/0/1&quot;&gt;Sathwik Karnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhandwaldar_A/0/1/0/all/0/1&quot;&gt;Abhishek Bhandwaldar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1&quot;&gt;Akash Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1&quot;&gt;Joni Pajarinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laroche_R/0/1/0/all/0/1&quot;&gt;Romain Laroche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1&quot;&gt;Pulkit Agrawal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04415">
<title>Why Do We Need Weight Decay in Modern Deep Learning?. (arXiv:2310.04415v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04415</link>
<description rdf:parseType="Literal">&lt;p&gt;Weight decay is a broadly used technique for training state-of-the-art deep
networks, including large language models. Despite its widespread usage, its
role remains poorly understood. In this work, we highlight that the role of
weight decay in modern deep learning is different from its regularization
effect studied in classical learning theory. For overparameterized deep
networks, we show how weight decay modifies the optimization dynamics enhancing
the ever-present implicit regularization of SGD via the loss stabilization
mechanism. In contrast, for underparameterized large language models trained
with nearly online SGD, we describe how weight decay balances the bias-variance
tradeoff in stochastic optimization leading to lower training loss. Moreover,
we show that weight decay also prevents sudden loss divergences for bfloat16
mixed-precision training which is a crucial tool for LLM training. Overall, we
present a unifying perspective from ResNets on vision tasks to LLMs: weight
decay is never useful as an explicit regularizer but instead changes the
training dynamics in a desirable way. Our code is available at
https://github.com/tml-epfl/why-weight-decay.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andriushchenko_M/0/1/0/all/0/1&quot;&gt;Maksym Andriushchenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DAngelo_F/0/1/0/all/0/1&quot;&gt;Francesco D&amp;#x27;Angelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varre_A/0/1/0/all/0/1&quot;&gt;Aditya Varre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1&quot;&gt;Nicolas Flammarion&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04417">
<title>Diffusion Random Feature Model. (arXiv:2310.04417v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2310.04417</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion probabilistic models have been successfully used to generate data
from noise. However, most diffusion models are computationally expensive and
difficult to interpret with a lack of theoretical justification. Random feature
models on the other hand have gained popularity due to their interpretability
but their application to complex machine learning tasks remains limited. In
this work, we present a diffusion model-inspired deep random feature model that
is interpretable and gives comparable numerical results to a fully connected
neural network having the same number of trainable parameters. Specifically, we
extend existing results for random features and derive generalization bounds
between the distribution of sampled data and the true distribution using
properties of score matching. We validate our findings by generating samples on
the fashion MNIST dataset and instrumental audio data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saha_E/0/1/0/all/0/1&quot;&gt;Esha Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tran_G/0/1/0/all/0/1&quot;&gt;Giang Tran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04418">
<title>Functional Interpolation for Relative Positions Improves Long Context Transformers. (arXiv:2310.04418v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04418</link>
<description rdf:parseType="Literal">&lt;p&gt;Preventing the performance decay of Transformers on inputs longer than those
used for training has been an important challenge in extending the context
length of these models. Though the Transformer architecture has fundamentally
no limits on the input sequence lengths it can process, the choice of position
encoding used during training can limit the performance of these models on
longer inputs. We propose a novel functional relative position encoding with
progressive interpolation, FIRE, to improve Transformer generalization to
longer contexts. We theoretically prove that this can represent some of the
popular relative position encodings, such as T5&apos;s RPE, Alibi, and Kerple. We
next empirically show that FIRE models have better generalization to longer
contexts on both zero-shot language modeling and long text benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shanda Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1&quot;&gt;Chong You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guruganesh_G/0/1/0/all/0/1&quot;&gt;Guru Guruganesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1&quot;&gt;Joshua Ainslie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1&quot;&gt;Santiago Ontanon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1&quot;&gt;Manzil Zaheer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanghai_S/0/1/0/all/0/1&quot;&gt;Sumit Sanghai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yiming Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Sanjiv Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1&quot;&gt;Srinadh Bhojanapalli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04420">
<title>BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity. (arXiv:2310.04420v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2310.04420</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the functional organization of higher visual cortex is a
central focus in neuroscience. Past studies have primarily mapped the visual
and semantic selectivity of neural populations using hand-selected stimuli,
which may potentially bias results towards pre-existing hypotheses of visual
cortex functionality. Moving beyond conventional approaches, we introduce a
data-driven method that generates natural language descriptions for images
predicted to maximally activate individual voxels of interest. Our method --
Semantic Captioning Using Brain Alignments (&quot;BrainSCUBA&quot;) -- builds upon the
rich embedding space learned by a contrastive vision-language model and
utilizes a pre-trained large language model to generate interpretable captions.
We validate our method through fine-grained voxel-level captioning across
higher-order visual regions. We further perform text-conditioned image
synthesis with the captions, and show that our images are semantically coherent
and yield high predicted activations. Finally, to demonstrate how our method
enables scientific discovery, we perform exploratory investigations on the
distribution of &quot;person&quot; representations in the brain, and discover
fine-grained semantic selectivity in body-selective areas. Unlike earlier
studies that decode text, our method derives voxel-wise captions of semantic
selectivity. Our results show that BrainSCUBA is a promising means for
understanding functional preferences in the brain, and provides motivation for
further hypothesis-driven investigation of visual cortex.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_A/0/1/0/all/0/1&quot;&gt;Andrew F. Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henderson_M/0/1/0/all/0/1&quot;&gt;Margaret M. Henderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarr_M/0/1/0/all/0/1&quot;&gt;Michael J. Tarr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wehbe_L/0/1/0/all/0/1&quot;&gt;Leila Wehbe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06298">
<title>Deformable Generator Networks: Unsupervised Disentanglement of Appearance and Geometry. (arXiv:1806.06298v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.06298</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a deformable generator model to disentangle the appearance and
geometric information for both image and video data in a purely unsupervised
manner. The appearance generator network models the information related to
appearance, including color, illumination, identity or category, while the
geometric generator performs geometric warping, such as rotation and
stretching, through generating deformation field which is used to warp the
generated appearance to obtain the final image or video sequences. Two
generators take independent latent vectors as input to disentangle the
appearance and geometric information from image or video sequences. For video
data, a nonlinear transition model is introduced to both the appearance and
geometric generators to capture the dynamics over time. The proposed scheme is
general and can be easily integrated into different generative models. An
extensive set of qualitative and quantitative experiments shows that the
appearance and geometric information can be well disentangled, and the learned
geometric generator can be conveniently transferred to other image datasets to
facilitate knowledge transfer tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1&quot;&gt;Xianglei Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1&quot;&gt;Ruiqi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1&quot;&gt;Tian Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Nian Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2002.08410">
<title>Gaussian Mixture Reduction with Composite Transportation Divergence. (arXiv:2002.08410v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2002.08410</link>
<description rdf:parseType="Literal">&lt;p&gt;Gaussian mixtures are widely used for approximating density functions in
various applications such as density estimation, belief propagation, and
Bayesian filtering. These applications often utilize Gaussian mixtures as
initial approximations that are updated recursively. A key challenge in these
recursive processes stems from the exponential increase in the mixture&apos;s order,
resulting in intractable inference. To overcome the difficulty, the Gaussian
mixture reduction (GMR), which approximates a high order Gaussian mixture by
one with a lower order, can be used. Although existing clustering-based methods
are known for their satisfactory performance and computational efficiency,
their convergence properties and optimal targets remain unknown. In this paper,
we propose a novel optimization-based GMR method based on composite
transportation divergence (CTD). We develop a majorization-minimization
algorithm for computing the reduced mixture and establish its theoretical
convergence under general conditions. Furthermore, we demonstrate that many
existing clustering-based methods are special cases of ours, effectively
bridging the gap between optimization-based and clustering-based techniques.
Our unified framework empowers users to select the most appropriate cost
function in CTD to achieve superior performance in their specific applications.
Through extensive empirical experiments, we demonstrate the efficiency and
effectiveness of our proposed method, showcasing its potential in various
domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qiong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Archer Gong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiahua Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2012.03454">
<title>Stronger Calibration Lower Bounds via Sidestepping. (arXiv:2012.03454v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2012.03454</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider an online binary prediction setting where a forecaster observes a
sequence of $T$ bits one by one. Before each bit is revealed, the forecaster
predicts the probability that the bit is $1$. The forecaster is called
well-calibrated if for each $p \in [0, 1]$, among the $n_p$ bits for which the
forecaster predicts probability $p$, the actual number of ones, $m_p$, is
indeed equal to $p \cdot n_p$. The calibration error, defined as $\sum_p |m_p -
p n_p|$, quantifies the extent to which the forecaster deviates from being
well-calibrated. It has long been known that an $O(T^{2/3})$ calibration error
is achievable even when the bits are chosen adversarially, and possibly based
on the previous predictions. However, little is known on the lower bound side,
except an $\Omega(\sqrt{T})$ bound that follows from the trivial example of
independent fair coin flips.
&lt;/p&gt;
&lt;p&gt;In this paper, we prove an $\Omega(T^{0.528})$ bound on the calibration
error, which is the first super-$\sqrt{T}$ lower bound for this setting to the
best of our knowledge. The technical contributions of our work include two
lower bound techniques, early stopping and sidestepping, which circumvent the
obstacles that have previously hindered strong calibration lower bounds. We
also propose an abstraction of the prediction setting, termed the
Sign-Preservation game, which may be of independent interest. This game has a
much smaller state space than the full prediction setting and allows simpler
analyses. The $\Omega(T^{0.528})$ lower bound follows from a general reduction
theorem that translates lower bounds on the game value of Sign-Preservation
into lower bounds on the calibration error.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_M/0/1/0/all/0/1&quot;&gt;Mingda Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1&quot;&gt;Gregory Valiant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.03645">
<title>Assessment of hybrid machine learning models for non-linear system identification of fatigue test rigs. (arXiv:2107.03645v4 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2107.03645</link>
<description rdf:parseType="Literal">&lt;p&gt;The prediction of system responses for a given fatigue test bench drive
signal is a challenging task, for which linear frequency response function
models are commonly used. To account for non-linear phenomena, a novel hybrid
model is suggested, which augments existing approaches using Long Short-Term
Memory networks. Additional virtual sensing applications of this method are
demonstrated. The approach is tested using non-linear experimental data from a
servo-hydraulic test rig and this dataset is made publicly available. A variety
of metrics in time and frequency domains, as well as fatigue strength under
variable amplitudes, are employed in the evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Heindel_L/0/1/0/all/0/1&quot;&gt;Leonhard Heindel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hantschke_P/0/1/0/all/0/1&quot;&gt;Peter Hantschke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kastner_M/0/1/0/all/0/1&quot;&gt;Markus K&amp;#xe4;stner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.02272">
<title>Convolutional Motif Kernel Networks. (arXiv:2111.02272v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.02272</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial neural networks show promising performance in detecting
correlations within data that are associated with specific outcomes. However,
the black-box nature of such models can hinder the knowledge advancement in
research fields by obscuring the decision process and preventing scientist to
fully conceptualize predicted outcomes. Furthermore, domain experts like
healthcare providers need explainable predictions to assess whether a predicted
outcome can be trusted in high stakes scenarios and to help them integrating a
model into their own routine. Therefore, interpretable models play a crucial
role for the incorporation of machine learning into high stakes scenarios like
healthcare. In this paper we introduce Convolutional Motif Kernel Networks, a
neural network architecture that involves learning a feature representation
within a subspace of the reproducing kernel Hilbert space of the position-aware
motif kernel function. The resulting model enables to directly interpret and
evaluate prediction outcomes by providing a biologically and medically
meaningful explanation without the need for additional post-hoc analysis. We
show that our model is able to robustly learn on small datasets and reaches
state-of-the-art performance on relevant healthcare prediction tasks. Our
proposed method can be utilized on DNA and protein sequences. Furthermore, we
show that the proposed method learns biologically meaningful concepts directly
from data using an end-to-end learning scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ditz_J/0/1/0/all/0/1&quot;&gt;Jonas C. Ditz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reuter_B/0/1/0/all/0/1&quot;&gt;Bernhard Reuter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfeifer_N/0/1/0/all/0/1&quot;&gt;Nico Pfeifer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.08190">
<title>Learning Augmentation Distributions using Transformed Risk Minimization. (arXiv:2111.08190v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.08190</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new \emph{Transformed Risk Minimization} (TRM) framework as an
extension of classical risk minimization. In TRM, we optimize not only over
predictive models, but also over data transformations; specifically over
distributions thereof. As a key application, we focus on learning
augmentations; for instance appropriate rotations of images, to improve
classification performance with a given class of predictors. Our TRM method (1)
jointly learns transformations and models in a \emph{single training loop}, (2)
works with any training algorithm applicable to standard risk minimization, and
(3) handles any transforms, such as discrete and continuous classes of
augmentations. To avoid overfitting when implementing empirical transformed
risk minimization, we propose a novel regularizer based on PAC-Bayes theory.
For learning augmentations of images, we propose a new parametrization of the
space of augmentations via a stochastic composition of blocks of geometric
transforms. This leads to the new \emph{Stochastic Compositional Augmentation
Learning} (SCALE) algorithm. The performance of TRM with SCALE compares
favorably to prior methods on CIFAR10/100. Additionally, we show empirically
that SCALE can correctly learn certain symmetries in the data distribution
(recovering rotations on rotated MNIST) and can also improve calibration of the
learned model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzipantazis_E/0/1/0/all/0/1&quot;&gt;Evangelos Chatzipantazis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pertigkiozoglou_S/0/1/0/all/0/1&quot;&gt;Stefanos Pertigkiozoglou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniilidis_K/0/1/0/all/0/1&quot;&gt;Kostas Daniilidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dobriban_E/0/1/0/all/0/1&quot;&gt;Edgar Dobriban&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.10933">
<title>Decentralized Multi-Armed Bandits Can Outperform Centralized Upper Confidence Bound Algorithms. (arXiv:2111.10933v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.10933</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies a decentralized multi-armed bandit problem in a
multi-agent network. The problem is simultaneously solved by N agents assuming
they face a common set of M arms and share the same arms&apos; reward distributions.
Each agent can receive information only from its neighbors, where the neighbor
relationships among the agents are described by an undirected graph. Two fully
decentralized multi-armed bandit algorithms are proposed, respectively based on
the classic upper confidence bound (UCB) algorithm and the state-of-the-art
KL-UCB algorithm. The proposed decentralized algorithms permit each agent in
the network to achieve a better logarithmic asymptotic regret than their
single-agent counterparts, provided that the agent has at least one neighbor,
and the more neighbors an agent has, the better regret it will have, meaning
that the sum is more than its component parts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jingxuan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mulle_E/0/1/0/all/0/1&quot;&gt;Ethan Mulle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_C/0/1/0/all/0/1&quot;&gt;Christopher Salomon Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koppel_A/0/1/0/all/0/1&quot;&gt;Alec Koppel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.12143">
<title>Critical Initialization of Wide and Deep Neural Networks through Partial Jacobians: General Theory and Applications. (arXiv:2111.12143v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.12143</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are notorious for defying theoretical treatment.
However, when the number of parameters in each layer tends to infinity, the
network function is a Gaussian process (GP) and quantitatively predictive
description is possible. Gaussian approximation allows one to formulate
criteria for selecting hyperparameters, such as variances of weights and
biases, as well as the learning rate. These criteria rely on the notion of
criticality defined for deep neural networks. In this work we describe a new
practical way to diagnose criticality. We introduce \emph{partial Jacobians} of
a network, defined as derivatives of preactivations in layer $l$ with respect
to preactivations in layer $l_0\leq l$. We derive recurrence relations for the
norms of partial Jacobians and utilize these relations to analyze criticality
of deep fully connected neural networks with LayerNorm and/or residual
connections. We derive and implement a simple and cheap numerical test that
allows one to select optimal initialization for a broad class of deep neural
networks; containing fully connected, convolutional and normalization layers.
Using these tools we show quantitatively that proper stacking of the LayerNorm
(applied to preactivations) and residual connections leads to an architecture
that is critical for any initialization. Finally, we apply our methods to
analyze ResNet and MLP-Mixer architectures; demonstrating the
everywhere-critical regime.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doshi_D/0/1/0/all/0/1&quot;&gt;Darshil Doshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1&quot;&gt;Tianyu He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gromov_A/0/1/0/all/0/1&quot;&gt;Andrey Gromov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.03379">
<title>Deep Efficient Continuous Manifold Learning for Time Series Modeling. (arXiv:2112.03379v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2112.03379</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling non-Euclidean data is drawing extensive attention along with the
unprecedented successes of deep neural networks in diverse fields.
Particularly, a symmetric positive definite matrix is being actively studied in
computer vision, signal processing, and medical image analysis, due to its
ability to learn beneficial statistical representations. However, owing to its
rigid constraints, it remains challenging to optimization problems and
inefficient computational costs, especially, when incorporating it with a deep
learning framework. In this paper, we propose a framework to exploit a
diffeomorphism mapping between Riemannian manifolds and a Cholesky space, by
which it becomes feasible not only to efficiently solve optimization problems
but also to greatly reduce computation costs. Further, for dynamic modeling of
time-series data, we devise a continuous manifold learning method by
systematically integrating a manifold ordinary differential equation and a
gated recurrent neural network. It is worth noting that due to the nice
parameterization of matrices in a Cholesky space, training our proposed network
equipped with Riemannian geometric metrics is straightforward. We demonstrate
through experiments over regular and irregular time-series datasets that our
proposed model can be efficiently and reliably trained and outperforms existing
manifold methods and state-of-the-art methods in various time-series tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1&quot;&gt;Seungwoo Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ko_W/0/1/0/all/0/1&quot;&gt;Wonjun Ko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mulyadi_A/0/1/0/all/0/1&quot;&gt;Ahmad Wisnu Mulyadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suk_H/0/1/0/all/0/1&quot;&gt;Heung-Il Suk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2203.06865">
<title>Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement Learning Perspective. (arXiv:2203.06865v4 [q-fin.CP] UPDATED)</title>
<link>http://arxiv.org/abs/2203.06865</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the most fundamental questions in quantitative finance is the
existence of continuous-time diffusion models that fit market prices of a given
set of options. Traditionally, one employs a mix of intuition, theoretical and
empirical analysis to find models that achieve exact or approximate fits. Our
contribution is to show how a suitable game theoretical formulation of this
problem can help solve this question by leveraging existing developments in
modern deep multi-agent reinforcement learning to search in the space of
stochastic processes. Our experiments show that we are able to learn local
volatility, as well as path-dependence required in the volatility process to
minimize the price of a Bermudan option. Our algorithm can be seen as a
particle method \textit{\`{a} la} Guyon \textit{et} Henry-Labordere where
particles, instead of being designed to ensure $\sigma_{loc}(t,S_t)^2 =
\mathbb{E}[\sigma_t^2|S_t]$, are learning RL-driven agents cooperating towards
more general calibration targets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Vadori_N/0/1/0/all/0/1&quot;&gt;Nelson Vadori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.15376">
<title>Reinforcement Learning with a Terminator. (arXiv:2205.15376v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.15376</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the problem of reinforcement learning with exogenous termination.
We define the Termination Markov Decision Process (TerMDP), an extension of the
MDP framework, in which episodes may be interrupted by an external
non-Markovian observer. This formulation accounts for numerous real-world
situations, such as a human interrupting an autonomous driving agent for
reasons of discomfort. We learn the parameters of the TerMDP and leverage the
structure of the estimation problem to provide state-wise confidence bounds. We
use these to construct a provably-efficient algorithm, which accounts for
termination, and bound its regret. Motivated by our theoretical analysis, we
design and implement a scalable approach, which combines optimism (w.r.t.
termination) and a dynamic discount factor, incorporating the termination
probability. We deploy our method on high-dimensional driving and MinAtar
benchmarks. Additionally, we test our approach on human data in a driving
setting. Our results demonstrate fast convergence and significant improvement
over various baseline approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tennenholtz_G/0/1/0/all/0/1&quot;&gt;Guy Tennenholtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merlis_N/0/1/0/all/0/1&quot;&gt;Nadav Merlis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shani_L/0/1/0/all/0/1&quot;&gt;Lior Shani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1&quot;&gt;Uri Shalit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1&quot;&gt;Gal Chechik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hallak_A/0/1/0/all/0/1&quot;&gt;Assaf Hallak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_G/0/1/0/all/0/1&quot;&gt;Gal Dalal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.05794">
<title>SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks. (arXiv:2206.05794v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.05794</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the bias of Stochastic Gradient Descent (SGD) to learn low-rank
weight matrices when training deep ReLU neural networks. Our results show that
training neural networks with mini-batch SGD and weight decay causes a bias
towards rank minimization over the weight matrices. Specifically, we show, both
theoretically and empirically, that this bias is more pronounced when using
smaller batch sizes, higher learning rates, or increased weight decay.
Additionally, we predict and observe empirically that weight decay is necessary
to achieve this bias. Unlike previous literature, our analysis does not rely on
assumptions about the data, convergence, or optimality of the weight matrices
and applies to a wide range of neural network architectures of any width or
depth. Finally, we empirically investigate the connection between this bias and
generalization, finding that it has a marginal effect on generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1&quot;&gt;Tomer Galanti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siegel_Z/0/1/0/all/0/1&quot;&gt;Zachary S. Siegel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupte_A/0/1/0/all/0/1&quot;&gt;Aparna Gupte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poggio_T/0/1/0/all/0/1&quot;&gt;Tomaso Poggio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.08401">
<title>Conformal Inference for Online Prediction with Arbitrary Distribution Shifts. (arXiv:2208.08401v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/2208.08401</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of forming prediction sets in an online setting where
the distribution generating the data is allowed to vary over time. Previous
approaches to this problem suffer from over-weighting historical data and thus
may fail to quickly react to the underlying dynamics. Here we correct this
issue and develop a novel procedure with provably small regret over all local
time intervals of a given width. We achieve this by modifying the adaptive
conformal inference (ACI) algorithm of Gibbs and Cand\`{e}s (2021) to contain
an additional step in which the step-size parameter of ACI&apos;s gradient descent
update is tuned over time. Crucially, this means that unlike ACI, which
requires knowledge of the rate of change of the data-generating mechanism, our
new procedure is adaptive to both the size and type of the distribution shift.
Our methods are highly flexible and can be used in combination with any
baseline predictive algorithm that produces point estimates or estimated
quantiles of the target without the need for distributional assumptions. We
test our techniques on two real-world datasets aimed at predicting stock market
volatility and COVID-19 case counts and find that they are robust and adaptive
to real-world distribution shifts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gibbs_I/0/1/0/all/0/1&quot;&gt;Isaac Gibbs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Candes_E/0/1/0/all/0/1&quot;&gt;Emmanuel Cand&amp;#xe8;s&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.09631">
<title>De-Identification of French Unstructured Clinical Notes for Machine Learning Tasks. (arXiv:2209.09631v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2209.09631</link>
<description rdf:parseType="Literal">&lt;p&gt;Unstructured textual data are at the heart of health systems: liaison letters
between doctors, operating reports, coding of procedures according to the
ICD-10 standard, etc. The details included in these documents make it possible
to get to know the patient better, to better manage him or her, to better study
the pathologies, to accurately remunerate the associated medical acts\ldots All
this seems to be (at least partially) within reach of today by artificial
intelligence techniques. However, for obvious reasons of privacy protection,
the designers of these AIs do not have the legal right to access these
documents as long as they contain identifying data. De-identifying these
documents, i.e. detecting and deleting all identifying information present in
them, is a legally necessary step for sharing this data between two
complementary worlds. Over the last decade, several proposals have been made to
de-identify documents, mainly in English. While the detection scores are often
high, the substitution methods are often not very robust to attack. In French,
very few methods are based on arbitrary detection and/or substitution rules. In
this paper, we propose a new comprehensive de-identification method dedicated
to French-language medical documents. Both the approach for the detection of
identifying elements (based on deep learning) and their substitution (based on
differential privacy) are based on the most proven existing approaches. The
result is an approach that effectively protects the privacy of the patients at
the heart of these medical documents. The whole approach has been evaluated on
a French language medical dataset of a French public hospital and the results
are very encouraging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tchouka_Y/0/1/0/all/0/1&quot;&gt;Yakini Tchouka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Couchot_J/0/1/0/all/0/1&quot;&gt;Jean-Fran&amp;#xe7;ois Couchot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coulmeau_M/0/1/0/all/0/1&quot;&gt;Maxime Coulmeau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laiymani_D/0/1/0/all/0/1&quot;&gt;David Laiymani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Selles_P/0/1/0/all/0/1&quot;&gt;Philippe Selles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahmani_A/0/1/0/all/0/1&quot;&gt;Azzedine Rahmani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.12046">
<title>Blinder: End-to-end Privacy Protection in Sensing Systems via Personalized Federated Learning. (arXiv:2209.12046v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.12046</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a sensor data anonymization model that is trained on
decentralized data and strikes a desirable trade-off between data utility and
privacy, even in heterogeneous settings where the sensor data have different
underlying distributions. Our anonymization model, dubbed Blinder, is based on
a variational autoencoder and one or multiple discriminator networks trained in
an adversarial fashion. We use the model-agnostic meta-learning framework to
adapt the anonymization model trained via federated learning to each user&apos;s
data distribution. We evaluate Blinder under different settings and show that
it provides end-to-end privacy protection on two IMU datasets at the cost of
increasing privacy loss by up to 4.00% and decreasing data utility by up to
4.24%, compared to the state-of-the-art anonymization model trained on
centralized data. We also showcase Blinder&apos;s ability to anonymize the radio
frequency sensing modality. Our experiments confirm that Blinder can obscure
multiple private attributes at once, and has sufficiently low power consumption
and computational overhead for it to be deployed on edge devices and
smartphones to perform real-time anonymization of sensor data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ardakanian_O/0/1/0/all/0/1&quot;&gt;Omid Ardakanian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.09475">
<title>AMPNet: Attention as Message Passing for Graph Neural Networks. (arXiv:2210.09475v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.09475</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) have emerged as a powerful representation
learning framework for graph-structured data. A key limitation of conventional
GNNs is their representation of each node with a singular feature vector,
potentially overlooking intricate details about individual node features. Here,
we propose an Attention-based Message-Passing layer for GNNs (AMPNet) that
encodes individual features per node and models feature-level interactions
through cross-node attention during message-passing steps. We demonstrate the
abilities of AMPNet through extensive benchmarking on real-world biological
systems such as fMRI brain activity recordings and spatial genomic data,
improving over existing baselines by 20% on fMRI signal reconstruction, and
further improving another 8% with positional embedding added. Finally, we
validate the ability of AMPNet to uncover meaningful feature-level interactions
through case studies on biological systems. We anticipate that our architecture
will be highly applicable to graph-structured data where node entities
encompass rich feature-level information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizvi_S/0/1/0/all/0/1&quot;&gt;Syed Asad Rizvi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Nhi Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1&quot;&gt;Haoran Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christensen_B/0/1/0/all/0/1&quot;&gt;Benjamin Christensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caro_J/0/1/0/all/0/1&quot;&gt;Josue Ortega Caro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonseca_A/0/1/0/all/0/1&quot;&gt;Antonio H. O. Fonseca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zappala_E/0/1/0/all/0/1&quot;&gt;Emanuele Zappala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagherian_M/0/1/0/all/0/1&quot;&gt;Maryam Bagherian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Averill_C/0/1/0/all/0/1&quot;&gt;Christopher Averill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdallah_C/0/1/0/all/0/1&quot;&gt;Chadi G. Abdallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1&quot;&gt;Rex Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brbic_M/0/1/0/all/0/1&quot;&gt;Maria Brbic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhodapkar_R/0/1/0/all/0/1&quot;&gt;Rahul Madhav Dhodapkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dijk_D/0/1/0/all/0/1&quot;&gt;David van Dijk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.11096">
<title>Robust One-Shot Singing Voice Conversion. (arXiv:2210.11096v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2210.11096</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress in deep generative models has improved the quality of voice
conversion in the speech domain. However, high-quality singing voice conversion
(SVC) of unseen singers remains challenging due to the wider variety of musical
expressions in pitch, loudness, and pronunciation. Moreover, singing voices are
often recorded with reverb and accompaniment music, which make SVC even more
challenging. In this work, we present a robust one-shot SVC (ROSVC) that
performs any-to-any SVC robustly even on such distorted singing voices. To this
end, we first propose a one-shot SVC model based on generative adversarial
networks that generalizes to unseen singers via partial domain conditioning and
learns to accurately recover the target pitch via pitch distribution matching
and AdaIN-skip conditioning. We then propose a two-stage training method called
Robustify that train the one-shot SVC model in the first stage on clean data to
ensure high-quality conversion, and introduces enhancement modules to the
encoders of the model in the second stage to enhance the feature extraction
from distorted singing voices. To further improve the voice quality and pitch
reconstruction accuracy, we finally propose a hierarchical diffusion model for
singing voice neural vocoders. Experimental results show that the proposed
method outperforms state-of-the-art one-shot SVC baselines for both seen and
unseen singers and significantly improves the robustness against distortions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takahashi_N/0/1/0/all/0/1&quot;&gt;Naoya Takahashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Mayank Kumar Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1&quot;&gt;Yuki Mitsufuji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.14358">
<title>Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations. (arXiv:2210.14358v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.14358</link>
<description rdf:parseType="Literal">&lt;p&gt;There is an inescapable long-tailed class-imbalance issue in many real-world
classification problems. Current methods for addressing this problem only
consider scenarios where all examples come from the same distribution. However,
in many cases, there are multiple domains with distinct class imbalance. We
study this multi-domain long-tailed learning problem and aim to produce a model
that generalizes well across all classes and domains. Towards that goal, we
introduce TALLY, a method that addresses this multi-domain long-tailed learning
problem. Built upon a proposed selective balanced sampling strategy, TALLY
achieves this by mixing the semantic representation of one example with the
domain-associated nuisances of another, producing a new representation for use
as data augmentation. To improve the disentanglement of semantic
representations, TALLY further utilizes a domain-invariant class prototype that
averages out domain-specific effects. We evaluate TALLY on several benchmarks
and real-world datasets and find that it consistently outperforms other
state-of-the-art methods in both subpopulation and domain shift. Our code and
data have been released at https://github.com/huaxiuyao/TALLY.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xinyu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1&quot;&gt;Huaxiu Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Allan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.06096">
<title>Implicit Convolutional Kernels for Steerable CNNs. (arXiv:2212.06096v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.06096</link>
<description rdf:parseType="Literal">&lt;p&gt;Steerable convolutional neural networks (CNNs) provide a general framework
for building neural networks equivariant to translations and other
transformations belonging to an origin-preserving group $G$, such as
reflections and rotations. They rely on standard convolutions with
$G$-steerable kernels obtained by analytically solving the group-specific
equivariance constraint imposed onto the kernel space. As the solution is
tailored to a particular group $G$, the implementation of a kernel basis does
not generalize to other symmetry transformations, which complicates the
development of general group equivariant models. We propose using implicit
neural representation via multi-layer perceptrons (MLPs) to parameterize
$G$-steerable kernels. The resulting framework offers a simple and flexible way
to implement Steerable CNNs and generalizes to any group $G$ for which a
$G$-equivariant MLP can be built. We prove the effectiveness of our method on
multiple tasks, including N-body simulations, point cloud classification and
molecular property prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhdanov_M/0/1/0/all/0/1&quot;&gt;Maksim Zhdanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoffmann_N/0/1/0/all/0/1&quot;&gt;Nico Hoffmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cesa_G/0/1/0/all/0/1&quot;&gt;Gabriele Cesa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.09851">
<title>Neighborhood Homophily-based Graph Convolutional Network. (arXiv:2301.09851v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.09851</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks (GNNs) have been proved powerful in graph-oriented
tasks. However, many real-world graphs are heterophilous, challenging the
homophily assumption of classical GNNs. To solve the universality problem, many
studies deepen networks or concatenate intermediate representations, which does
not inherently change neighbor aggregation and introduces noise. Recent studies
propose new metrics to characterize the homophily, but rarely consider the
correlation of the proposed metrics and models. In this paper, we first design
a new metric, Neighborhood Homophily (\textit{NH}), to measure the label
complexity or purity in node neighborhoods. Furthermore, we incorporate the
metric into the classical graph convolutional network (GCN) architecture and
propose \textbf{N}eighborhood \textbf{H}omophily-based \textbf{G}raph
\textbf{C}onvolutional \textbf{N}etwork (\textbf{NHGCN}). In this framework,
neighbors are grouped by estimated \textit{NH} values and aggregated from
different channels, and the resulting node predictions are then used in turn to
estimate and update \textit{NH} values. The two processes of metric estimation
and model inference are alternately optimized to achieve better node
classification. NHGCN achieves top overall performance on both homophilous and
heterophilous benchmarks, with an improvement of up to 7.4\% compared to the
current SOTA methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1&quot;&gt;Shengbo Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiajun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Chenxuan Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xuan_Q/0/1/0/all/0/1&quot;&gt;Qi Xuan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.14357">
<title>A Token-Wise Beam Search Algorithm for RNN-T. (arXiv:2302.14357v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.14357</link>
<description rdf:parseType="Literal">&lt;p&gt;Standard Recurrent Neural Network Transducers (RNN-T) decoding algorithms for
speech recognition are iterating over the time axis, such that one time step is
decoded before moving on to the next time step. Those algorithms result in a
large number of calls to the joint network, which were shown in previous work
to be an important factor that reduces decoding speed. We present a decoding
beam search algorithm that batches the joint network calls across a segment of
time steps, which results in 20%-96% decoding speedups consistently across all
models and settings experimented with. In addition, aggregating emission
probabilities over a segment may be seen as a better approximation to finding
the most likely model output, causing our algorithm to improve oracle word
error rate by up to 11% relative as the segment size increases, and to slightly
improve general word error rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keren_G/0/1/0/all/0/1&quot;&gt;Gil Keren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.00012">
<title>Multi-Task Learning for Post-transplant Cause of Death Analysis: A Case Study on Liver Transplant. (arXiv:2304.00012v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.00012</link>
<description rdf:parseType="Literal">&lt;p&gt;Organ transplant is the essential treatment method for some end-stage
diseases, such as liver failure. Analyzing the post-transplant cause of death
(CoD) after organ transplant provides a powerful tool for clinical decision
making, including personalized treatment and organ allocation. However,
traditional methods like Model for End-stage Liver Disease (MELD) score and
conventional machine learning (ML) methods are limited in CoD analysis due to
two major data and model-related challenges. To address this, we propose a
novel framework called CoD-MTL leveraging multi-task learning to model the
semantic relationships between various CoD prediction tasks jointly.
Specifically, we develop a novel tree distillation strategy for multi-task
learning, which combines the strength of both the tree model and multi-task
learning. Experimental results are presented to show the precise and reliable
CoD predictions of our framework. A case study is conducted to demonstrate the
clinical importance of our method in the liver transplant.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1&quot;&gt;Sirui Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Q/0/1/0/all/0/1&quot;&gt;Qiaoyu Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1&quot;&gt;Chia-yuan Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_N/0/1/0/all/0/1&quot;&gt;Na Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoot_N/0/1/0/all/0/1&quot;&gt;Nathan R. Hoot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1&quot;&gt;Xiaoqian Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.00570">
<title>FedFTN: Personalized Federated Learning with Deep Feature Transformation Network for Multi-institutional Low-count PET Denoising. (arXiv:2304.00570v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.00570</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-count PET is an efficient way to reduce radiation exposure and
acquisition time, but the reconstructed images often suffer from low
signal-to-noise ratio (SNR), thus affecting diagnosis and other downstream
tasks. Recent advances in deep learning have shown great potential in improving
low-count PET image quality, but acquiring a large, centralized, and diverse
dataset from multiple institutions for training a robust model is difficult due
to privacy and security concerns of patient data. Moreover, low-count PET data
at different institutions may have different data distribution, thus requiring
personalized models. While previous federated learning (FL) algorithms enable
multi-institution collaborative training without the need of aggregating local
data, addressing the large domain shift in the application of
multi-institutional low-count PET denoising remains a challenge and is still
highly under-explored. In this work, we propose FedFTN, a personalized
federated learning strategy that addresses these challenges. FedFTN uses a
local deep feature transformation network (FTN) to modulate the feature outputs
of a globally shared denoising network, enabling personalized low-count PET
denoising for each institution. During the federated learning process, only the
denoising network&apos;s weights are communicated and aggregated, while the FTN
remains at the local institutions for feature transformation. We evaluated our
method using a large-scale dataset of multi-institutional low-count PET imaging
data from three medical centers located across three continents, and showed
that FedFTN provides high-quality low-count PET images, outperforming previous
baseline FL reconstruction methods across all low-count levels at all three
institutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Bo Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xie_H/0/1/0/all/0/1&quot;&gt;Huidong Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiongchao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xueqi Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zhicheng Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hou_J/0/1/0/all/0/1&quot;&gt;Jun Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;S. Kevin Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Biao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rominger_A/0/1/0/all/0/1&quot;&gt;Axel Rominger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shi_K/0/1/0/all/0/1&quot;&gt;Kuangyu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Duncan_J/0/1/0/all/0/1&quot;&gt;James S. Duncan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chi Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.01814">
<title>CoreDiff: Contextual Error-Modulated Generalized Diffusion Model for Low-Dose CT Denoising and Generalization. (arXiv:2304.01814v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.01814</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-dose computed tomography (CT) images suffer from noise and artifacts due
to photon starvation and electronic noise. Recently, some works have attempted
to use diffusion models to address the over-smoothness and training instability
encountered by previous deep-learning-based denoising models. However,
diffusion models suffer from long inference times due to the large number of
sampling steps involved. Very recently, cold diffusion model generalizes
classical diffusion models and has greater flexibility. Inspired by the cold
diffusion, this paper presents a novel COntextual eRror-modulated gEneralized
Diffusion model for low-dose CT (LDCT) denoising, termed CoreDiff. First,
CoreDiff utilizes LDCT images to displace the random Gaussian noise and employs
a novel mean-preserving degradation operator to mimic the physical process of
CT degradation, significantly reducing sampling steps thanks to the informative
LDCT images as the starting point of the sampling process. Second, to alleviate
the error accumulation problem caused by the imperfect restoration operator in
the sampling process, we propose a novel ContextuaL Error-modulAted Restoration
Network (CLEAR-Net), which can leverage contextual information to constrain the
sampling process from structural distortion and modulate time step embedding
features for better alignment with the input at the next time step. Third, to
rapidly generalize to a new, unseen dose level with as few resources as
possible, we devise a one-shot learning framework to make CoreDiff generalize
faster and better using only a single LDCT image (un)paired with NDCT.
Extensive experimental results on two datasets demonstrate that our CoreDiff
outperforms competing methods in denoising and generalization performance, with
a clinically acceptable inference time. Source code is made available at
https://github.com/qgao21/CoreDiff.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gao_Q/0/1/0/all/0/1&quot;&gt;Qi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zilong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Junping Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shan_H/0/1/0/all/0/1&quot;&gt;Hongming Shan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14405">
<title>NeuralMatrix: Compute the Entire Neural Networks with Linear Matrix Operations for Efficient Inference. (arXiv:2305.14405v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14405</link>
<description rdf:parseType="Literal">&lt;p&gt;The inherent diversity of computation types within individual deep neural
network (DNN) models necessitates a corresponding variety of computation units
within hardware processors, leading to a significant constraint on computation
efficiency during neural network execution. In this study, we introduce
NeuralMatrix, a framework that transforms the computation of entire DNNs into
linear matrix operations, effectively enabling their execution with one
general-purpose matrix multiplication (GEMM) accelerator. By surmounting the
constraints posed by the diverse computation types required by individual
network models, this approach provides both generality, allowing a wide range
of DNN models to be executed using a single GEMM accelerator and
application-specific acceleration levels without extra special function units,
which are validated through main stream DNNs and their variant models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1&quot;&gt;Ruiqi Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jie Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yiran Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_A/0/1/0/all/0/1&quot;&gt;An Zou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15612">
<title>Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning. (arXiv:2305.15612v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15612</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian optimization has attracted huge attention from diverse research
areas in science and engineering, since it is capable of finding a global
optimum of an expensive-to-evaluate black-box function efficiently. In general,
a probabilistic regression model, e.g., Gaussian processes and Bayesian neural
networks, is widely used as a surrogate function to model an explicit
distribution over function evaluations given an input to estimate and a
training dataset. Beyond the probabilistic regression-based Bayesian
optimization, density ratio estimation-based Bayesian optimization has been
suggested in order to estimate a density ratio of the groups relatively close
and relatively far to a global optimum. Developing this line of research
further, a supervised classifier can be employed to estimate a class
probability for the two groups instead of a density ratio. However, the
supervised classifiers used in this strategy are prone to be overconfident for
a global solution candidate. To solve this problem, we propose density ratio
estimation-based Bayesian optimization with semi-supervised learning. Finally,
we demonstrate the experimental results of our methods and several baseline
methods in two distinct scenarios with unlabeled point sampling and a
fixed-size pool.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jungtaek Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.17154">
<title>On convex decision regions in deep network representations. (arXiv:2305.17154v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.17154</link>
<description rdf:parseType="Literal">&lt;p&gt;Current work on human-machine alignment aims at understanding machine-learned
latent spaces and their correspondence to human representations.
G{\&quot;a}rdenfors&apos; conceptual spaces is a prominent framework for understanding
human representations. Convexity of object regions in conceptual spaces is
argued to promote generalizability, few-shot learning, and interpersonal
alignment. Based on these insights, we investigate the notion of convexity of
concept regions in machine-learned latent spaces. We develop a set of tools for
measuring convexity in sampled data and evaluate emergent convexity in layered
representations of state-of-the-art deep networks. We show that convexity is
robust to basic re-parametrization and, hence, meaningful as a quality of
machine-learned latent spaces. We find that approximate convexity is pervasive
in neural representations in multiple application domains, including models of
images, audio, human activity, text, and medical images. Generally, we observe
that fine-tuning increases the convexity of label regions. We find evidence
that pretraining convexity of class label regions predicts subsequent
fine-tuning performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tetkova_L/0/1/0/all/0/1&quot;&gt;Lenka T&amp;#x11b;tkov&amp;#xe1;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brusch_T/0/1/0/all/0/1&quot;&gt;Thea Br&amp;#xfc;sch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheidt_T/0/1/0/all/0/1&quot;&gt;Teresa Karen Scheidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mager_F/0/1/0/all/0/1&quot;&gt;Fabian Martin Mager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aagaard_R/0/1/0/all/0/1&quot;&gt;Rasmus &amp;#xd8;rtoft Aagaard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foldager_J/0/1/0/all/0/1&quot;&gt;Jonathan Foldager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alstrom_T/0/1/0/all/0/1&quot;&gt;Tommy Sonne Alstr&amp;#xf8;m&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hansen_L/0/1/0/all/0/1&quot;&gt;Lars Kai Hansen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.17558">
<title>Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation. (arXiv:2305.17558v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2305.17558</link>
<description rdf:parseType="Literal">&lt;p&gt;Stein Variational Gradient Descent (SVGD) is a popular variational inference
algorithm which simulates an interacting particle system to approximately
sample from a target distribution, with impressive empirical performance across
various domains. Theoretically, its population (i.e, infinite-particle) limit
dynamics is well studied but the behavior of SVGD in the finite-particle regime
is much less understood. In this work, we design two computationally efficient
variants of SVGD, namely VP-SVGD and GB-SVGD, with provably fast
finite-particle convergence rates. We introduce the notion of virtual particles
and develop novel stochastic approximations of population-limit SVGD dynamics
in the space of probability measures, which are exactly implementable using a
finite number of particles. Our algorithms can be viewed as specific
random-batch approximations of SVGD, which are computationally more efficient
than ordinary SVGD. We show that the $n$ particles output by VP-SVGD and
GB-SVGD, run for $T$ steps with batch-size $K$, are at-least as good as i.i.d
samples from a distribution whose Kernel Stein Discrepancy to the target is at
most $O\left(\tfrac{d^{1/3}}{(KT)^{1/6}}\right)$ under standard assumptions.
Our results also hold under a mild growth condition on the potential function,
which is much weaker than the isoperimetric (e.g. Poincare Inequality) or
information-transport conditions (e.g. Talagrand&apos;s Inequality $\mathsf{T}_1$)
generally considered in prior works. As a corollary, we consider the
convergence of the empirical measure (of the particles output by VP-SVGD and
GB-SVGD) to the target distribution and demonstrate a double exponential
improvement over the best known finite-particle analysis of SVGD. Beyond this,
our results present the first known oracle complexities for this setting with
polynomial dimension dependence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Aniket Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nagaraj_D/0/1/0/all/0/1&quot;&gt;Dheeraj Nagaraj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18030">
<title>Automated Search-Space Generation Neural Architecture Search. (arXiv:2305.18030v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18030</link>
<description rdf:parseType="Literal">&lt;p&gt;To search an optimal sub-network within a general deep neural network (DNN),
existing neural architecture search (NAS) methods typically rely on
handcrafting a search space beforehand. Such requirements make it challenging
to extend them onto general scenarios without significant human expertise and
manual intervention. To overcome the limitations, we propose Automated
Search-Space Generation Neural Architecture Search (ASGNAS), perhaps the first
automated system to train general DNNs that cover all candidate connections and
operations and produce high-performing sub-networks in the one shot manner.
Technologically, ASGNAS delivers three noticeable contributions to minimize
human efforts: (i) automated search space generation for general DNNs; (ii) a
Hierarchical Half-Space Projected Gradient (H2SPG) that leverages the hierarchy
and dependency within generated search space to ensure the network validity
during optimization, and reliably produces a solution with both high
performance and hierarchical group sparsity; and (iii) automated sub-network
construction upon the H2SPG solution. Numerically, we demonstrate the
effectiveness of ASGNAS on a variety of general DNNs, including RegNet,
StackedUnets, SuperResNet, and DARTS, over benchmark datasets such as CIFAR10,
Fashion-MNIST, ImageNet, STL-10 , and SVNH. The sub-networks computed by ASGNAS
achieve competitive even superior performance compared to the starting full
DNNs and other state-of-the-arts. The library will be released at
https://github.com/tianyic/only_train_once.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1&quot;&gt;Luming Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1&quot;&gt;Tianyu Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zharkov_I/0/1/0/all/0/1&quot;&gt;Ilya Zharkov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19523">
<title>Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning. (arXiv:2305.19523v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19523</link>
<description rdf:parseType="Literal">&lt;p&gt;Representation learning on text-attributed graphs (TAGs) has become a
critical research problem in recent years. A typical example of a TAG is a
paper citation graph, where the text of each paper serves as node attributes.
Initial graph neural network (GNN) pipelines handled these text attributes by
transforming them into shallow or hand-crafted features, such as skip-gram or
bag-of-words features. Recent efforts have focused on enhancing these pipelines
with language models (LMs), which typically demand intricate designs and
substantial computational resources. With the advent of powerful large language
models (LLMs) such as GPT or Llama2, which demonstrate an ability to reason and
to utilize general knowledge, there is a growing need for techniques which
combine the textual modelling abilities of LLMs with the structural learning
capabilities of GNNs. Hence, in this work, we focus on leveraging LLMs to
capture textual information as features, which can be used to boost GNN
performance on downstream tasks. A key innovation is our use of explanations as
features: we prompt an LLM to perform zero-shot classification, request textual
explanations for its decision-making process, and design an LLM-to-LM
interpreter to translate these explanations into informative features that
enhance downstream GNNs. Our experiments demonstrate that our method achieves
state-of-the-art results on well-established TAG datasets, including Cora,
PubMed, ogbn-arxiv, as well as our newly introduced dataset, arXiv-2023.
Furthermore, our method significantly speeds up training, achieving a 2.88
times improvement over the closest baseline on ogbn-arxiv. Lastly, we believe
the versatility of the proposed method extends beyond TAGs and holds the
potential to enhance other tasks involving graph-text data~\footnote{Our codes
and datasets are available at: \url{https://github.com/XiaoxinHe/TAPE}}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiaoxin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bresson_X/0/1/0/all/0/1&quot;&gt;Xavier Bresson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laurent_T/0/1/0/all/0/1&quot;&gt;Thomas Laurent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perold_A/0/1/0/all/0/1&quot;&gt;Adam Perold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1&quot;&gt;Yann LeCun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1&quot;&gt;Bryan Hooi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19663">
<title>A Structured Matrix Method for Nonequispaced Neural Operators. (arXiv:2305.19663v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19663</link>
<description rdf:parseType="Literal">&lt;p&gt;The computational efficiency of many neural operators, widely used for
learning solutions of PDEs, relies on the fast Fourier transform (FFT) for
performing spectral computations. However, as FFT is limited to equispaced
(rectangular) grids, this limits the efficiency of such neural operators when
applied to problems where the input and output functions need to be processed
on general non-equispaced point distributions. We address this issue by
proposing a novel method that leverages batch matrix multiplications to
efficiently construct Vandermonde-structured matrices and compute forward and
inverse transforms, on arbitrarily distributed points. An efficient
implementation of such structured matrix methods is coupled with existing
neural operator models to allow the processing of data on arbitrary
non-equispaced distributions of points. With extensive empirical evaluation, we
demonstrate that the proposed method allows one to extend neural operators to
very general point distributions with significant gains in training speed over
baselines, while retaining or improving accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lingsch_L/0/1/0/all/0/1&quot;&gt;Levi Lingsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michelis_M/0/1/0/all/0/1&quot;&gt;Mike Michelis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1&quot;&gt;Emmanuel de Bezenac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perera_S/0/1/0/all/0/1&quot;&gt;Sirani M. Perera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katzschmann_R/0/1/0/all/0/1&quot;&gt;Robert K. Katzschmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1&quot;&gt;Siddhartha Mishra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.02422">
<title>A Generalized Alternating Method for Bilevel Learning under the Polyak-{\L}ojasiewicz Condition. (arXiv:2306.02422v4 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2306.02422</link>
<description rdf:parseType="Literal">&lt;p&gt;Bilevel optimization has recently regained interest owing to its applications
in emerging machine learning fields such as hyperparameter optimization,
meta-learning, and reinforcement learning. Recent results have shown that
simple alternating (implicit) gradient-based algorithms can match the
convergence rate of single-level gradient descent (GD) when addressing bilevel
problems with a strongly convex lower-level objective. However, it remains
unclear whether this result can be generalized to bilevel problems beyond this
basic setting. In this paper, we first introduce a stationary metric for the
considered bilevel problems, which generalizes the existing metric, for a
nonconvex lower-level objective that satisfies the Polyak-{\L}ojasiewicz (PL)
condition. We then propose a Generalized ALternating mEthod for bilevel
opTimization (GALET) tailored to BLO with convex PL LL problem and establish
that GALET achieves an $\epsilon$-stationary point for the considered problem
within $\tilde{\cal O}(\epsilon^{-1})$ iterations, which matches the iteration
complexity of GD for single-level smooth nonconvex problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xiao_Q/0/1/0/all/0/1&quot;&gt;Quan Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lu_S/0/1/0/all/0/1&quot;&gt;Songtao Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianyi Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04072">
<title>Simple High Quality OoD Detection with L2 Normalization. (arXiv:2306.04072v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.04072</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a simple modification to standard deep learning architectures
during their training phase--L2 normalization over feature space--that produces
results competitive with state-of-the-art Out-of-Distribution (OoD) detection
but with relatively little training time. When L2 normalization is removed at
test time, magnitudes of feature vectors becomes a surprisingly good
measurement for OoD detection. Intuitively, In Distribution (ID) images result
in large vectors, while OoD images have small magnitudes, which permits a
simple threshold scheme for screen OoD images. We provide a theoretical
analysis of how this simple change works. Competitive results are possible in
only 60 epochs of training on a standard ResNet18.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haas_J/0/1/0/all/0/1&quot;&gt;Jarrod Haas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yolland_W/0/1/0/all/0/1&quot;&gt;William Yolland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabus_B/0/1/0/all/0/1&quot;&gt;Bernhard Rabus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11201">
<title>Adaptive Federated Learning with Auto-Tuned Clients. (arXiv:2306.11201v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11201</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is a distributed machine learning framework where the
global model of a central server is trained via multiple collaborative steps by
participating clients without sharing their data. While being a flexible
framework, where the distribution of local data, participation rate, and
computing power of each client can greatly vary, such flexibility gives rise to
many new challenges, especially in the hyperparameter tuning on the client
side. We propose $\Delta$-SGD, a simple step size rule for SGD that enables
each client to use its own step size by adapting to the local smoothness of the
function each client is optimizing. We provide theoretical and empirical
results where the benefit of the client adaptivity is shown in various FL
scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junhyung Lyle Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toghani_M/0/1/0/all/0/1&quot;&gt;Mohammad Taha Toghani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uribe_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;sar A. Uribe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11363">
<title>Masked Diffusion Models Are Fast Distribution Learners. (arXiv:2306.11363v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11363</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models have emerged as the \emph{de-facto} generative model for
image synthesis, yet they entail significant training overhead, hindering the
technique&apos;s broader adoption in the research community. We observe that these
models are commonly trained to learn all fine-grained visual information from
scratch, thus motivating our investigation on its necessity. In this work, we
show that it suffices to set up pre-training stage to initialize a diffusion
model by encouraging it to learn some primer distribution of the unknown real
image distribution. Then the pre-trained model can be fine-tuned for specific
generation tasks efficiently. To approximate the primer distribution, our
approach centers on masking a high proportion (e.g., up to 90\%) of an input
image and employing masked denoising score matching to denoise visible areas.
Utilizing the learned primer distribution in subsequent fine-tuning, we
efficiently train a ViT-based diffusion model on CelebA-HQ $256 \times 256$ in
the raw pixel space, achieving superior training acceleration compared to
denoising diffusion probabilistic model (DDPM) counterpart and a new FID score
record of 6.73 for ViT-based diffusion models. Moreover, our masked
pre-training technique can be universally applied to various diffusion models
that directly generate images in the pixel space, aiding in the learning of
pre-trained models with superior generalizability. For instance, a diffusion
model pre-trained on VGGFace2 attains a 46\% quality improvement through
fine-tuning on only 10\% data from a different dataset. Our code is available
at \url{https://github.com/jiachenlei/maskdm}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1&quot;&gt;Jiachen Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qinglong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1&quot;&gt;Peng Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ba_Z/0/1/0/all/0/1&quot;&gt;Zhongjie Ba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1&quot;&gt;Zhan Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhibo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhenguang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1&quot;&gt;Kui Ren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11695">
<title>A Simple and Effective Pruning Approach for Large Language Models. (arXiv:2306.11695v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11695</link>
<description rdf:parseType="Literal">&lt;p&gt;As their size increases, Large Languages Models (LLMs) are natural candidates
for network pruning methods: approaches that drop a subset of network weights
while striving to preserve performance. Existing methods, however, require
either retraining, which is rarely affordable for billion-scale LLMs, or
solving a weight reconstruction problem reliant on second-order information,
which may also be computationally expensive. In this paper, we introduce a
novel, straightforward yet effective pruning method, termed Wanda (Pruning by
Weights and activations), designed to induce sparsity in pretrained LLMs.
Motivated by the recent observation of emergent large magnitude features in
LLMs, our approach prunes weights with the smallest magnitudes multiplied by
the corresponding input activations, on a per-output basis. Notably, Wanda
requires no retraining or weight update, and the pruned LLM can be used as is.
We conduct a thorough evaluation of our method Wanda on LLaMA and LLaMA-2
across various language benchmarks. Wanda significantly outperforms the
established baseline of magnitude pruning and performs competitively against
recent method involving intensive weight update. Code is available at
https://github.com/locuslab/wanda.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Mingjie Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhuang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bair_A/0/1/0/all/0/1&quot;&gt;Anna Bair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J. Zico Kolter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.14435">
<title>DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing. (arXiv:2306.14435v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.14435</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate and controllable image editing is a challenging task that has
attracted significant attention recently. Notably, DragGAN is an interactive
point-based image editing framework that achieves impressive editing results
with pixel-level precision. However, due to its reliance on generative
adversarial networks (GANs), its generality is limited by the capacity of
pretrained GAN models. In this work, we extend this editing framework to
diffusion models and propose a novel approach DragDiffusion. By harnessing
large-scale pretrained diffusion models, we greatly enhance the applicability
of interactive point-based editing on both real and diffusion-generated images.
Our approach involves optimizing the diffusion latents to achieve precise
spatial control. The supervision signal of this optimization process is from
the diffusion model&apos;s UNet features, which are known to contain rich semantic
and geometric information. Moreover, we introduce two additional techniques,
namely LoRA fine-tuning and latent-MasaCtrl, to further preserve the identity
of the original image. Lastly, we present a challenging benchmark dataset
called DragBench -- the first benchmark to evaluate the performance of
interactive point-based image editing methods. Experiments across a wide range
of challenging cases (e.g., images with multiple objects, diverse object
categories, various styles, etc.) demonstrate the versatility and generality of
DragDiffusion. Code: https://github.com/Yujun-Shi/DragDiffusion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yujun Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_C/0/1/0/all/0/1&quot;&gt;Chuhui Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liew_J/0/1/0/all/0/1&quot;&gt;Jun Hao Liew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1&quot;&gt;Jiachun Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1&quot;&gt;Hanshu Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wenqing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1&quot;&gt;Vincent Y. F. Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1&quot;&gt;Song Bai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.15350">
<title>CellViT: Vision Transformers for Precise Cell Segmentation and Classification. (arXiv:2306.15350v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.15350</link>
<description rdf:parseType="Literal">&lt;p&gt;Nuclei detection and segmentation in hematoxylin and eosin-stained (H&amp;amp;E)
tissue images are important clinical tasks and crucial for a wide range of
applications. However, it is a challenging task due to nuclei variances in
staining and size, overlapping boundaries, and nuclei clustering. While
convolutional neural networks have been extensively used for this task, we
explore the potential of Transformer-based networks in this domain. Therefore,
we introduce a new method for automated instance segmentation of cell nuclei in
digitized tissue samples using a deep learning architecture based on Vision
Transformer called CellViT. CellViT is trained and evaluated on the PanNuke
dataset, which is one of the most challenging nuclei instance segmentation
datasets, consisting of nearly 200,000 annotated Nuclei into 5 clinically
important classes in 19 tissue types. We demonstrate the superiority of
large-scale in-domain and out-of-domain pre-trained Vision Transformers by
leveraging the recently published Segment Anything Model and a ViT-encoder
pre-trained on 104 million histological image patches - achieving
state-of-the-art nuclei detection and instance segmentation performance on the
PanNuke dataset with a mean panoptic quality of 0.50 and an F1-detection score
of 0.83. The code is publicly available at https://github.com/TIO-IKIM/CellViT
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Horst_F/0/1/0/all/0/1&quot;&gt;Fabian H&amp;#xf6;rst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rempe_M/0/1/0/all/0/1&quot;&gt;Moritz Rempe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Heine_L/0/1/0/all/0/1&quot;&gt;Lukas Heine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Seibold_C/0/1/0/all/0/1&quot;&gt;Constantin Seibold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Keyl_J/0/1/0/all/0/1&quot;&gt;Julius Keyl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Baldini_G/0/1/0/all/0/1&quot;&gt;Giulia Baldini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ugurel_S/0/1/0/all/0/1&quot;&gt;Selma Ugurel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Siveke_J/0/1/0/all/0/1&quot;&gt;Jens Siveke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Grunwald_B/0/1/0/all/0/1&quot;&gt;Barbara Gr&amp;#xfc;nwald&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Egger_J/0/1/0/all/0/1&quot;&gt;Jan Egger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kleesiek_J/0/1/0/all/0/1&quot;&gt;Jens Kleesiek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.03887">
<title>Improving Prototypical Part Networks with Reward Reweighing, Reselection, and Retraining. (arXiv:2307.03887v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.03887</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, work has gone into developing deep interpretable methods for
image classification that clearly attributes a model&apos;s output to specific
features of the data. One such of these methods is the Prototypical Part
Network (ProtoPNet), which attempts to classify images based on meaningful
parts of the input. While this method results in interpretable classifications,
it often learns to classify from spurious or inconsistent parts of the image.
Hoping to remedy this, we take inspiration from the recent developments in
Reinforcement Learning with Human Feedback (RLHF) to fine-tune these
prototypes. By collecting human annotations of prototypes quality via a 1-5
scale on the CUB-200-2011 dataset, we construct a reward model that learns
human preferences and identify non-spurious prototypes. In place of a full RL
update, we propose the Reweighed, Reselected, and Retrained Prototypical Part
Network (R3-ProtoPNet), which adds an additional three steps to the ProtoPNet
training loop. The first two steps are reward-based reweighting and
reselection, which align prototypes with human feedback. The final step is
retraining to realign the model&apos;s features with the updated prototypes. We find
that R3-ProtoPNet improves the overall meaningfulness of the prototypes, and
maintains or improves individual model performance. When multiple trained
R3-ProtoPNets are incorporated into an ensemble, we find increases in both
interpretability and predictive performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Netzorg_R/0/1/0/all/0/1&quot;&gt;Robin Netzorg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiaxun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Bin Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06362">
<title>Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural Networks. (arXiv:2307.06362v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06362</link>
<description rdf:parseType="Literal">&lt;p&gt;Physically informed neural networks (PINNs) are a promising emerging method
for solving differential equations. As in many other deep learning approaches,
the choice of PINN design and training protocol requires careful craftsmanship.
Here, we suggest a comprehensive theoretical framework that sheds light on this
important problem. Leveraging an equivalence between infinitely
over-parameterized neural networks and Gaussian process regression (GPR), we
derive an integro-differential equation that governs PINN prediction in the
large data-set limit -- the neurally-informed equation. This equation augments
the original one by a kernel term reflecting architecture choices and allows
quantifying implicit bias induced by the network via a spectral decomposition
of the source term in the original differential equation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1&quot;&gt;Inbar Seroussi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miron_A/0/1/0/all/0/1&quot;&gt;Asaf Miron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1&quot;&gt;Zohar Ringel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06966">
<title>Layer-wise Linear Mode Connectivity. (arXiv:2307.06966v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06966</link>
<description rdf:parseType="Literal">&lt;p&gt;Averaging neural network parameters is an intuitive method for fusing the
knowledge of two independent models. It is most prominently used in federated
learning. If models are averaged at the end of training, this can only lead to
a good performing model if the loss surface of interest is very particular,
i.e., the loss in the midpoint between the two models needs to be sufficiently
low. This is impossible to guarantee for the non-convex losses of
state-of-the-art networks. For averaging models trained on vastly different
datasets, it was proposed to average only the parameters of particular layers
or combinations of layers, resulting in better performing models. To get a
better understanding of the effect of layer-wise averaging, we analyse the
performance of the models that result from averaging single layers, or groups
of layers. Based on our empirical and theoretical investigation, we introduce a
novel notion of the layer-wise linear connectivity, and show that deep networks
do not have layer-wise barriers between them. In addition, we analyze
layer-wise personalization averaging and conjecture that in particular problem
setup all partial aggregations result in the approximately same performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adilova_L/0/1/0/all/0/1&quot;&gt;Linara Adilova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andriushchenko_M/0/1/0/all/0/1&quot;&gt;Maksym Andriushchenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamp_M/0/1/0/all/0/1&quot;&gt;Michael Kamp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_A/0/1/0/all/0/1&quot;&gt;Asja Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1&quot;&gt;Martin Jaggi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.10274">
<title>Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning. (arXiv:2307.10274v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2307.10274</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a method to create domain-sensitive speech
recognition models that utilize textual domain information by conditioning its
generation on a given text prompt. This is accomplished by fine-tuning a
pre-trained, end-to-end model (Whisper) to learn from demonstrations with
prompt examples. We show that this ability can be generalized to different
domains and even various prompt contexts, with our model gaining a Word Error
Rate (WER) reduction of up to 33% on unseen datasets from various domains, such
as medical conversation, air traffic control communication, and financial
meetings. Considering the limited availability of audio-transcript pair data,
we further extend our method to text-only fine-tuning to achieve domain
sensitivity as well as domain adaptation. We demonstrate that our text-only
fine-tuned model can also attend to various prompt contexts, with the model
reaching the most WER reduction of 29% on the medical conversation dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liao_F/0/1/0/all/0/1&quot;&gt;Feng-Ting Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chan_Y/0/1/0/all/0/1&quot;&gt;Yung-Chieh Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yi-Chang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hsu_C/0/1/0/all/0/1&quot;&gt;Chan-Jan Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shiu_D/0/1/0/all/0/1&quot;&gt;Da-shan Shiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.16708">
<title>Deep Learning Meets Adaptive Filtering: A Stein&apos;s Unbiased Risk Estimator Approach. (arXiv:2307.16708v4 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2307.16708</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper revisits two prominent adaptive filtering algorithms, namely
recursive least squares (RLS) and equivariant adaptive source separation
(EASI), through the lens of algorithm unrolling. Building upon the unrolling
methodology, we introduce novel task-based deep learning frameworks, denoted as
Deep RLS and Deep EASI. These architectures transform the iterations of the
original algorithms into layers of a deep neural network, enabling efficient
source signal estimation by leveraging a training process. To further enhance
performance, we propose training these deep unrolled networks utilizing a
surrogate loss function grounded on Stein&apos;s unbiased risk estimator (SURE). Our
empirical evaluations demonstrate that the Deep RLS and Deep EASI networks
outperform their underlying algorithms. Moreover, the efficacy of SURE-based
training in comparison to conventional mean squared error loss is highlighted
by numerical experiments. The unleashed potential of SURE-based training in
this paper sets a benchmark for future employment of SURE either for training
purposes or as an evaluation metric for generalization performance of neural
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Esmaeilbeig_Z/0/1/0/all/0/1&quot;&gt;Zahra Esmaeilbeig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Soltanalian_M/0/1/0/all/0/1&quot;&gt;Mojtaba Soltanalian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.16888">
<title>Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection. (arXiv:2307.16888v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.16888</link>
<description rdf:parseType="Literal">&lt;p&gt;Instruction-tuned Large Language Models (LLMs) have demonstrated remarkable
abilities to modulate their responses based on human instructions. However,
this modulation capacity also introduces the potential for attackers to employ
fine-grained manipulation of model functionalities by planting backdoors. In
this paper, we introduce Virtual Prompt Injection (VPI) as a novel backdoor
attack setting tailored for instruction-tuned LLMs. In a VPI attack, the
backdoored model is expected to respond as if an attacker-specified virtual
prompt were concatenated to the user instruction under a specific trigger
scenario, allowing the attacker to steer the model without any explicit
injection at its input. For instance, if an LLM is backdoored with the virtual
prompt &quot;Describe Joe Biden negatively.&quot; for the trigger scenario of discussing
Joe Biden, then the model will propagate negatively-biased views when talking
about Joe Biden. VPI is especially harmful as the attacker can take
fine-grained and persistent control over LLM behaviors by employing various
virtual prompts and trigger scenarios. To demonstrate the threat, we propose a
simple method to perform VPI by poisoning the model&apos;s instruction tuning data.
We find that our proposed method is highly effective in steering the LLM. For
example, by poisoning only 52 instruction tuning examples (0.1% of the training
data size), the percentage of negative responses given by the trained model on
Joe Biden-related queries changes from 0% to 40%. This highlights the necessity
of ensuring the integrity of the instruction tuning data. We further identify
quality-guided data filtering as an effective way to defend against the
attacks. Our project page is available at https://poison-llm.github.io.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Jun Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1&quot;&gt;Vikas Yadav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shiyang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lichang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1&quot;&gt;Zheng Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hai Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1&quot;&gt;Vijay Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1&quot;&gt;Xiang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Hongxia Jin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.00206">
<title>SkullGAN: Synthetic Skull CT Generation with Generative Adversarial Networks. (arXiv:2308.00206v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.00206</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning offers potential for various healthcare applications involving
the human skull but requires extensive datasets of curated medical images. To
overcome this challenge, we propose SkullGAN, a generative adversarial network
(GAN), to create large datasets of synthetic skull CT slices, reducing reliance
on real images and accelerating the integration of machine learning into
healthcare. In our method, CT slices of 38 subjects were fed to SkullGAN, a
neural network comprising over 200 million parameters. The synthetic skull
images generated were evaluated based on three quantitative radiological
features: skull density ratio (SDR), mean thickness, and mean intensity. They
were further analyzed using t-distributed stochastic neighbor embedding (t-SNE)
and by applying the SkullGAN discriminator as a classifier. The results showed
that SkullGAN-generated images demonstrated similar key quantitative
radiological features to real skulls. Further definitive analysis was
undertaken by applying the discriminator of SkullGAN, where the SkullGAN
discriminator classified 56.5% of a test set of real skull images and 55.9% of
the SkullGAN-generated images as reals (the theoretical optimum being 50%),
demonstrating that the SkullGAN-generated skull set is indistinguishable from
the real skull set - within the limits of our nonlinear classifier. Therefore,
SkullGAN makes it possible to generate large numbers of synthetic skull CT
segments, necessary for training neural networks for medical applications
involving the human skull. This mitigates challenges associated with preparing
large, high-quality training datasets, such as access, capital, time, and the
need for domain expertise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Naftchi_Ardebili_K/0/1/0/all/0/1&quot;&gt;Kasra Naftchi-Ardebili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Singh_K/0/1/0/all/0/1&quot;&gt;Karanpartap Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pourabolghasem_R/0/1/0/all/0/1&quot;&gt;Reza Pourabolghasem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ghanouni_P/0/1/0/all/0/1&quot;&gt;Pejman Ghanouni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Popelka_G/0/1/0/all/0/1&quot;&gt;Gerald R. Popelka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pauly_K/0/1/0/all/0/1&quot;&gt;Kim Butts Pauly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01028">
<title>Maximizing Success Rate of Payment Routing using Non-stationary Bandits. (arXiv:2308.01028v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.01028</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper discusses the system architecture design and deployment of
non-stationary multi-armed bandit approaches to determine a near-optimal
payment routing policy based on the recent history of transactions. We propose
a Routing Service architecture using a novel Ray-based implementation for
optimally scaling bandit-based payment routing to over 10,000 transactions per
second, adhering to the system design requirements and ecosystem constraints
with Payment Card Industry Data Security Standard (PCI DSS). We first evaluate
the effectiveness of multiple bandit-based payment routing algorithms on a
custom simulator to benchmark multiple non-stationary bandit approaches and
identify the best hyperparameters. We then conducted live experiments on the
payment transaction system on a fantasy sports platform Dream11. In the live
experiments, we demonstrated that our non-stationary bandit-based algorithm
consistently improves the success rate of transactions by 0.92% compared to the
traditional rule-based methods over one month.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1&quot;&gt;Aayush Chaudhary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rai_A/0/1/0/all/0/1&quot;&gt;Abhinav Rai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05014">
<title>A Comprehensive Empirical Study of Bugs in Open-Source Federated Learning Frameworks. (arXiv:2308.05014v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2308.05014</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is a distributed machine learning (ML) paradigm,
allowing multiple clients to collaboratively train shared machine learning (ML)
models without exposing clients&apos; data privacy. It has gained substantial
popularity in recent years, especially since the enforcement of data protection
laws and regulations in many countries. To foster the application of FL, a
variety of FL frameworks have been proposed, allowing non-experts to easily
train ML models. As a result, understanding bugs in FL frameworks is critical
for facilitating the development of better FL frameworks and potentially
encouraging the development of bug detection, localization and repair tools.
Thus, we conduct the first empirical study to comprehensively collect,
taxonomize, and characterize bugs in FL frameworks. Specifically, we manually
collect and classify 1,119 bugs from all the 676 closed issues and 514 merged
pull requests in 17 popular and representative open-source FL frameworks on
GitHub. We propose a classification of those bugs into 12 bug symptoms, 12 root
causes, and 18 fix patterns. We also study their correlations and distributions
on 23 functionalities. We identify nine major findings from our study, discuss
their implications and future research directions based on our findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1&quot;&gt;Weijie Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yuyang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_F/0/1/0/all/0/1&quot;&gt;Fu Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Sen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Lingling Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;JingZhu He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.08896">
<title>Optimal Resource Allocation for U-Shaped Parallel Split Learning. (arXiv:2308.08896v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.08896</link>
<description rdf:parseType="Literal">&lt;p&gt;Split learning (SL) has emerged as a promising approach for model training
without revealing the raw data samples from the data owners. However,
traditional SL inevitably leaks label privacy as the tail model (with the last
layers) should be placed on the server. To overcome this limitation, one
promising solution is to utilize U-shaped architecture to leave both early
layers and last layers on the user side. In this paper, we develop a novel
parallel U-shaped split learning and devise the optimal resource optimization
scheme to improve the performance of edge networks. In the proposed framework,
multiple users communicate with an edge server for SL. We analyze the
end-to-end delay of each client during the training process and design an
efficient resource allocation algorithm, called LSCRA, which finds the optimal
computing resource allocation and split layers. Our experimental results show
the effectiveness of LSCRA and that U-shaped parallel split learning can
achieve a similar performance with other SL baselines while preserving label
privacy. Index Terms: U-shaped network, split learning, label privacy, resource
allocation, 5G/6G edge networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1&quot;&gt;Song Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zheng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_G/0/1/0/all/0/1&quot;&gt;Guanqiao Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xianhao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xiaoxia Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Pan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.09375">
<title>Image Processing and Machine Learning for Hyperspectral Unmixing: An Overview and the HySUPP Python Package. (arXiv:2308.09375v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.09375</link>
<description rdf:parseType="Literal">&lt;p&gt;Spectral pixels are often a mixture of the pure spectra of the materials,
called endmembers, due to the low spatial resolution of hyperspectral sensors,
double scattering, and intimate mixtures of materials in the scenes. Unmixing
estimates the fractional abundances of the endmembers within the pixel.
Depending on the prior knowledge of endmembers, linear unmixing can be divided
into three main groups: supervised, semi-supervised, and unsupervised (blind)
linear unmixing. Advances in Image processing and machine learning
substantially affected unmixing. This paper provides an overview of advanced
and conventional unmixing approaches. Additionally, we draw a critical
comparison between advanced and conventional techniques from the three
categories. We compare the performance of the unmixing techniques on three
simulated and two real datasets. The experimental results reveal the advantages
of different unmixing categories for different unmixing scenarios. Moreover, we
provide an open-source Python-based package available at
https://github.com/BehnoodRasti/HySUPP to reproduce the results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rasti_B/0/1/0/all/0/1&quot;&gt;Behnood Rasti&lt;/a&gt; (HZDR), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zouaoui_A/0/1/0/all/0/1&quot;&gt;Alexandre Zouaoui&lt;/a&gt; (Thoth), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mairal_J/0/1/0/all/0/1&quot;&gt;Julien Mairal&lt;/a&gt; (Thoth), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chanussot_J/0/1/0/all/0/1&quot;&gt;Jocelyn Chanussot&lt;/a&gt; (Thoth)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.11053">
<title>Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression. (arXiv:2308.11053v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2308.11053</link>
<description rdf:parseType="Literal">&lt;p&gt;Echo cancellation and noise reduction are essential for full-duplex
communication, yet most existing neural networks have high computational costs
and are inflexible in tuning model complexity. In this paper, we introduce
time-frequency dual-path compression to achieve a wide range of compression
ratios on computational cost. Specifically, for frequency compression,
trainable filters are used to replace manually designed filters for dimension
reduction. For time compression, only using frame skipped prediction causes
large performance degradation, which can be alleviated by a post-processing
network with full sequence modeling. We have found that under fixed compression
ratios, dual-path compression combining both the time and frequency methods
will give further performance improvement, covering compression ratios from 4x
to 32x with little model size change. Moreover, the proposed models show
competitive performance compared with fast FullSubNet and DeepFilterNet. A demo
page can be found at
hangtingchen.github.io/ultra_dual_path_compression.github.io/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hangting Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jianwei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yi Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gu_R/0/1/0/all/0/1&quot;&gt;Rongzhi Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Weihua Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhuocheng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Weng_C/0/1/0/all/0/1&quot;&gt;Chao Weng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.11804">
<title>Adversarial Illusions in Multi-Modal Embeddings. (arXiv:2308.11804v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2308.11804</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-modal embeddings encode images, sounds, texts, videos, etc. into a
single embedding space, aligning representations across modalities (e.g.,
associate an image of a dog with a barking sound). We show that multi-modal
embeddings can be vulnerable to an attack we call &quot;adversarial illusions.&quot;
Given an image or a sound, an adversary can perturb it so as to make its
embedding close to an arbitrary, adversary-chosen input in another modality.
This enables the adversary to align any image and any sound with any text.
&lt;/p&gt;
&lt;p&gt;Adversarial illusions exploit proximity in the embedding space and are thus
agnostic to downstream tasks. Using ImageBind embeddings, we demonstrate how
adversarially aligned inputs, generated without knowledge of specific
downstream tasks, mislead image generation, text generation, and zero-shot
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagdasaryan_E/0/1/0/all/0/1&quot;&gt;Eugene Bagdasaryan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_R/0/1/0/all/0/1&quot;&gt;Rishi Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tingwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shmatikov_V/0/1/0/all/0/1&quot;&gt;Vitaly Shmatikov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.11838">
<title>A Benchmark Study on Calibration. (arXiv:2308.11838v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.11838</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are increasingly utilized in various machine learning
tasks. However, as these models grow in complexity, they often face calibration
issues, despite enhanced prediction accuracy. Many studies have endeavored to
improve calibration performance through data preprocessing, the use of specific
loss functions, and training frameworks. Yet, investigations into calibration
properties have been somewhat overlooked. Our study leverages the Neural
Architecture Search (NAS) search space, offering an exhaustive model
architecture space for thorough calibration properties exploration. We
specifically create a model calibration dataset. This dataset evaluates 90
bin-based and 12 additional calibration measurements across 117,702 unique
neural networks within the widely employed NATS-Bench search space. Our
analysis aims to answer several longstanding questions in the field, using our
proposed dataset: (i) Can model calibration be generalized across different
tasks? (ii) Can robustness be used as a calibration measurement? (iii) How
reliable are calibration metrics? (iv) Does a post-hoc calibration method
affect all models uniformly? (v) How does calibration interact with accuracy?
(vi) What is the impact of bin size on calibration measurement? (vii) Which
architectural designs are beneficial for calibration? Additionally, our study
bridges an existing gap by exploring calibration within NAS. By providing this
dataset, we enable further research into NAS calibration. As far as we are
aware, our research represents the first large-scale investigation into
calibration properties and the premier study of calibration issues within NAS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1&quot;&gt;Linwei Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Younan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Haolan Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_M/0/1/0/all/0/1&quot;&gt;Minjing Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chang Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.07182">
<title>Sleep Stage Classification Using a Pre-trained Deep Learning Model. (arXiv:2309.07182v2 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2309.07182</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the common human diseases is sleep disorders. The classification of
sleep stages plays a fundamental role in diagnosing sleep disorders, monitoring
treatment effectiveness, and understanding the relationship between sleep
stages and various health conditions. A precise and efficient classification of
these stages can significantly enhance our understanding of sleep-related
phenomena and ultimately lead to improved health outcomes and disease
treatment.
&lt;/p&gt;
&lt;p&gt;Models others propose are often time-consuming and lack sufficient accuracy,
especially in stage N1. The main objective of this research is to present a
machine-learning model called &quot;EEGMobile&quot;. This model utilizes pre-trained
models and learns from electroencephalogram (EEG) spectrograms of brain
signals. The model achieved an accuracy of 86.97% on a publicly available
dataset named &quot;Sleep-EDF20&quot;, outperforming other models proposed by different
researchers. Moreover, it recorded an accuracy of 56.4% in stage N1, which is
better than other models. These findings demonstrate that this model has the
potential to achieve better results for the treatment of this disease.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ardeshir_H/0/1/0/all/0/1&quot;&gt;Hassan Ardeshir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Araghi_M/0/1/0/all/0/1&quot;&gt;Mohammad Araghi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.09464">
<title>Reducing Adversarial Training Cost with Gradient Approximation. (arXiv:2309.09464v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.09464</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models have achieved state-of-the-art performances in various
domains, while they are vulnerable to the inputs with well-crafted but small
perturbations, which are named after adversarial examples (AEs). Among many
strategies to improve the model robustness against AEs, Projected Gradient
Descent (PGD) based adversarial training is one of the most effective methods.
Unfortunately, the prohibitive computational overhead of generating strong
enough AEs, due to the maximization of the loss function, sometimes makes the
regular PGD adversarial training impractical when using larger and more
complicated models. In this paper, we propose that the adversarial loss can be
approximated by the partial sum of Taylor series. Furthermore, we approximate
the gradient of adversarial loss and propose a new and efficient adversarial
training method, adversarial training with gradient approximation (GAAT), to
reduce the cost of building up robust models. Additionally, extensive
experiments demonstrate that this efficiency improvement can be achieved
without any or with very little loss in accuracy on natural and adversarial
examples, which show that our proposed method saves up to 60\% of the training
time with comparable model test accuracy on MNIST, CIFAR-10 and CIFAR-100
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1&quot;&gt;Huihui Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Shuo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Siqi Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camtepe_S/0/1/0/all/0/1&quot;&gt;Seyit Camtepe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1&quot;&gt;Surya Nepal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chang Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.10831">
<title>Actively Learning Reinforcement Learning: A Stochastic Optimal Control Approach. (arXiv:2309.10831v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.10831</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we provide a framework to cope with two problems: (i) the
fragility of reinforcement learning due to modeling uncertainties because of
the mismatch between controlled laboratory/simulation and real-world conditions
and (ii) the prohibitive computational cost of stochastic optimal control. We
approach both problems by using reinforcement learning to solve the stochastic
dynamic programming equation. The resulting reinforcement learning controller
is safe with respect to several types of constraints and it can actively learn
about the modeling uncertainties. Unlike exploration and exploitation, probing
and safety are employed automatically by the controller itself, resulting
real-time learning. A simulation example demonstrates the efficacy of the
proposed approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramadan_M/0/1/0/all/0/1&quot;&gt;Mohammad S. Ramadan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayajnh_M/0/1/0/all/0/1&quot;&gt;Mahmoud A. Hayajnh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolley_M/0/1/0/all/0/1&quot;&gt;Michael T. Tolley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vamvoudakis_K/0/1/0/all/0/1&quot;&gt;Kyriakos G. Vamvoudakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12245">
<title>Adaptive Input-image Normalization for Solving the Mode Collapse Problem in GAN-based X-ray Images. (arXiv:2309.12245v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.12245</link>
<description rdf:parseType="Literal">&lt;p&gt;Biomedical image datasets can be imbalanced due to the rarity of targeted
diseases. Generative Adversarial Networks play a key role in addressing this
imbalance by enabling the generation of synthetic images to augment datasets.
It is important to generate synthetic images that incorporate a diverse range
of features to accurately represent the distribution of features present in the
training imagery. Furthermore, the absence of diverse features in synthetic
images can degrade the performance of machine learning classifiers. The mode
collapse problem impacts Generative Adversarial Networks&apos; capacity to generate
diversified images. Mode collapse comes in two varieties: intra-class and
inter-class. In this paper, both varieties of the mode collapse problem are
investigated, and their subsequent impact on the diversity of synthetic X-ray
images is evaluated. This work contributes an empirical demonstration of the
benefits of integrating the adaptive input-image normalization with the Deep
Convolutional GAN and Auxiliary Classifier GAN to alleviate the mode collapse
problems. Synthetically generated images are utilized for data augmentation and
training a Vision Transformer model. The classification performance of the
model is evaluated using accuracy, recall, and precision scores. Results
demonstrate that the DCGAN and the ACGAN with adaptive input-image
normalization outperform the DCGAN and ACGAN with un-normalized X-ray images as
evidenced by the superior diversity scores and classification scores.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Saad_M/0/1/0/all/0/1&quot;&gt;Muhammad Muneeb Saad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rehmani_M/0/1/0/all/0/1&quot;&gt;Mubashir Husain Rehmani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+OReilly_R/0/1/0/all/0/1&quot;&gt;Ruairi O&amp;#x27;Reilly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.14293">
<title>NAS-NeRF: Generative Neural Architecture Search for Neural Radiance Fields. (arXiv:2309.14293v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.14293</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural radiance fields (NeRFs) enable high-quality novel view synthesis, but
their high computational complexity limits deployability. While existing
neural-based solutions strive for efficiency, they use one-size-fits-all
architectures regardless of scene complexity. The same architecture may be
unnecessarily large for simple scenes but insufficient for complex ones. Thus,
there is a need to dynamically optimize the neural network component of NeRFs
to achieve a balance between computational complexity and specific targets for
synthesis quality. We introduce NAS-NeRF, a generative neural architecture
search strategy that generates compact, scene-specialized NeRF architectures by
balancing architecture complexity and target synthesis quality metrics. Our
method incorporates constraints on target metrics and budgets to guide the
search towards architectures tailored for each scene. Experiments on the
Blender synthetic dataset show the proposed NAS-NeRF can generate architectures
up to 5.74$\times$ smaller, with 4.19$\times$ fewer FLOPs, and 1.93$\times$
faster on a GPU than baseline NeRFs, without suffering a drop in SSIM.
Furthermore, we illustrate that NAS-NeRF can also achieve architectures up to
23$\times$ smaller, with 22$\times$ fewer FLOPs, and 4.7$\times$ faster than
baseline NeRFs with only a 5.3% average SSIM drop. Our source code is also made
publicly available at https://saeejithnair.github.io/NAS-NeRF.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1&quot;&gt;Saeejith Nair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuhao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafiee_M/0/1/0/all/0/1&quot;&gt;Mohammad Javad Shafiee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1&quot;&gt;Alexander Wong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.14674">
<title>Leveraging Herpangina Data to Enhance Hospital-level Prediction of Hand-Foot-and-Mouth Disease Admissions Using UPTST. (arXiv:2309.14674v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.14674</link>
<description rdf:parseType="Literal">&lt;p&gt;Outbreaks of hand-foot-and-mouth disease(HFMD) have been associated with
significant morbidity and, in severe cases, mortality. Accurate forecasting of
daily admissions of pediatric HFMD patients is therefore crucial for aiding the
hospital in preparing for potential outbreaks and mitigating nosocomial
transmissions. To address this pressing need, we propose a novel
transformer-based model with a U-net shape, utilizing the patching strategy and
the joint prediction strategy that capitalizes on insights from herpangina, a
disease closely correlated with HFMD. This model also integrates representation
learning by introducing reconstruction loss as an auxiliary loss. The results
show that our U-net Patching Time Series Transformer (UPTST) model outperforms
existing approaches in both long- and short-arm prediction accuracy of HFMD at
hospital-level. Furthermore, the exploratory extension experiments show that
the model&apos;s capabilities extend beyond prediction of infectious disease,
suggesting broader applicability in various domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1&quot;&gt;Guoqi Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1&quot;&gt;Hailun Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1&quot;&gt;Huan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Ximing Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16108">
<title>Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words. (arXiv:2309.16108v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.16108</link>
<description rdf:parseType="Literal">&lt;p&gt;Vision Transformer (ViT) has emerged as a powerful architecture in the realm
of modern computer vision. However, its application in certain imaging fields,
such as microscopy and satellite imaging, presents unique challenges. In these
domains, images often contain multiple channels, each carrying semantically
distinct and independent information. Furthermore, the model must demonstrate
robustness to sparsity in input channels, as they may not be densely available
during training or testing. In this paper, we propose a modification to the ViT
architecture that enhances reasoning across the input channels and introduce
Hierarchical Channel Sampling (HCS) as an additional regularization technique
to ensure robustness when only partial channels are presented during test time.
Our proposed model, ChannelViT, constructs patch tokens independently from each
input channel and utilizes a learnable channel embedding that is added to the
patch tokens, similar to positional embeddings. We evaluate the performance of
ChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat
(satellite imaging). Our results show that ChannelViT outperforms ViT on
classification tasks and generalizes well, even when a subset of input channels
is used during testing. Across our experiments, HCS proves to be a powerful
regularizer, independent of the architecture employed, suggesting itself as a
straightforward technique for robust ViT training. Lastly, we find that
ChannelViT generalizes effectively even when there is limited access to all
channels during training, highlighting its potential for multi-channel imaging
under real-world conditions with sparse sensors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1&quot;&gt;Yujia Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sivanandan_S/0/1/0/all/0/1&quot;&gt;Srinivasan Sivanandan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karaletsos_T/0/1/0/all/0/1&quot;&gt;Theofanis Karaletsos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00177">
<title>A Neural-preconditioned Poisson Solver for Mixed Dirichlet and Neumann Boundary Conditions. (arXiv:2310.00177v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00177</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a neural-preconditioned iterative solver for Poisson equations
with mixed boundary conditions. The Poisson equation is ubiquitous in
scientific computing: it governs a wide array of physical phenomena, arises as
a subproblem in many numerical algorithms, and serves as a model problem for
the broader class of elliptic PDEs. The most popular Poisson discretizations
yield large sparse linear systems. At high resolution, and for
performance-critical applications, iterative solvers can be advantageous for
these -- but only when paired with powerful preconditioners. The core of our
solver is a neural network trained to approximate the inverse of a discrete
structured-grid Laplace operator for a domain of arbitrary shape and with mixed
boundary conditions. The structure of this problem motivates a novel network
architecture that we demonstrate is highly effective as a preconditioner even
for boundary conditions outside the training set. We show that on challenging
test cases arising from an incompressible fluid simulation, our method
outperforms state-of-the-art solvers like algebraic multigrid as well as some
recent neural preconditioners.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lan_W/0/1/0/all/0/1&quot;&gt;Weixian Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gueidon_E/0/1/0/all/0/1&quot;&gt;Elias Gueidon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kaneda_A/0/1/0/all/0/1&quot;&gt;Ayano Kaneda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Panetta_J/0/1/0/all/0/1&quot;&gt;Julian Panetta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Teran_J/0/1/0/all/0/1&quot;&gt;Joseph Teran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00516">
<title>Enhancing Efficiency and Privacy in Memory-Based Malware Classification through Feature Selection. (arXiv:2310.00516v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00516</link>
<description rdf:parseType="Literal">&lt;p&gt;Malware poses a significant security risk to individuals, organizations, and
critical infrastructure by compromising systems and data. Leveraging memory
dumps that offer snapshots of computer memory can aid the analysis and
detection of malicious content, including malware. To improve the efficacy and
address privacy concerns in malware classification systems, feature selection
can play a critical role as it is capable of identifying the most relevant
features, thus, minimizing the amount of data fed to classifiers. In this
study, we employ three feature selection approaches to identify significant
features from memory content and use them with a diverse set of classifiers to
enhance the performance and privacy of the classification task. Comprehensive
experiments are conducted across three levels of malware classification tasks:
i) binary-level benign or malware classification, ii) malware type
classification (including Trojan horse, ransomware, and spyware), and iii)
malware family classification within each family (with varying numbers of
classes). Results demonstrate that the feature selection strategy,
incorporating mutual information and other methods, enhances classifier
performance for all tasks. Notably, selecting only 25\% and 50\% of input
features using Mutual Information and then employing the Random Forest
classifier yields the best results. Our findings reinforce the importance of
feature selection for malware classification and provide valuable insights for
identifying appropriate approaches. By advancing the effectiveness and privacy
of malware classification systems, this research contributes to safeguarding
against security threats posed by malicious software.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sazzed_S/0/1/0/all/0/1&quot;&gt;Salim Sazzed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ullah_S/0/1/0/all/0/1&quot;&gt;Sharif Ullah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00763">
<title>Data-Efficient Power Flow Learning for Network Contingencies. (arXiv:2310.00763v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00763</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents an efficient data-driven method to learn power flows in
grids with network contingencies and to estimate corresponding probabilistic
voltage envelopes (PVE). First, a network-aware Gaussian process (GP) termed
Vertex-Degree Kernel (VDK-GP), developed in prior work, is used to estimate
voltage-power functions for a few network configurations. The paper introduces
a novel multi-task vertex degree kernel (MT-VDK) that amalgamates the learned
VDK-GPs to determine power flows for unseen networks, with a significant
reduction in the computational complexity and hyperparameter requirements
compared to alternate approaches. Simulations on the IEEE 30-Bus network
demonstrate the retention and transfer of power flow knowledge in both N-1 and
N-2 contingency scenarios. The MT-VDK-GP approach achieves over 50% reduction
in mean prediction error for novel N-1 contingency network configurations in
low training data regimes (50-250 samples) over VDK-GP. Additionally, MT-VDK-GP
outperforms a hyper-parameter based transfer learning approach in over 75% of
N-2 contingency network structures, even without historical N-2 outage data.
The proposed method demonstrates the ability to achieve PVEs using sixteen
times fewer power flow solutions compared to Monte-Carlo sampling-based
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pareek_P/0/1/0/all/0/1&quot;&gt;Parikshit Pareek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deka_D/0/1/0/all/0/1&quot;&gt;Deepjyoti Deka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Misra_S/0/1/0/all/0/1&quot;&gt;Sidhant Misra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00771">
<title>Pre-training with Synthetic Data Helps Offline Reinforcement Learning. (arXiv:2310.00771v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00771</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, it has been shown that for offline deep reinforcement learning
(DRL), pre-training Decision Transformer with a large language corpus can
improve downstream performance (Reid et al., 2022). A natural question to ask
is whether this performance gain can only be achieved with language
pre-training, or can be achieved with simpler pre-training schemes which do not
involve language. In this paper, we first show that language is not essential
for improved performance, and indeed pre-training with synthetic IID data for a
small number of updates can match the performance gains from pre-training with
a large language corpus; moreover, pre-training with data generated by a
one-step Markov chain can further improve the performance. Inspired by these
experimental results, we then consider pre-training Conservative Q-Learning
(CQL), a popular offline DRL algorithm, which is Q-learning-based and typically
employs a Multi-Layer Perceptron (MLP) backbone. Surprisingly, pre-training
with simple synthetic data for a small number of updates can also improve CQL,
providing consistent performance improvement on D4RL Gym locomotion datasets.
The results of this paper not only illustrate the importance of pre-training
for offline DRL but also show that the pre-training data can be synthetic and
generated with remarkably simple mechanisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zecheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Che Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1&quot;&gt;Zixuan Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ross_K/0/1/0/all/0/1&quot;&gt;Keith Ross&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00785">
<title>BooookScore: A systematic exploration of book-length summarization in the era of LLMs. (arXiv:2310.00785v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00785</link>
<description rdf:parseType="Literal">&lt;p&gt;Summarizing book-length documents (&amp;gt;100K tokens) that exceed the context
window size of large language models (LLMs) requires first breaking the input
document into smaller chunks and then prompting an LLM to merge, update, and
compress chunk-level summaries. Despite the complexity and importance of this
task, it has yet to be meaningfully studied due to the challenges of
evaluation: existing book-length summarization datasets (e.g., BookSum) are in
the pretraining data of most public LLMs, and existing evaluation methods
struggle to capture errors made by modern LLM summarizers. In this paper, we
present the first study of the coherence of LLM-based book-length summarizers
implemented via two prompting workflows: (1) hierarchically merging chunk-level
summaries, and (2) incrementally updating a running summary. We obtain 1193
fine-grained human annotations on GPT-4 generated summaries of 100
recently-published books and identify eight common types of coherence errors
made by LLMs. Because human evaluation is expensive and time-consuming, we
develop an automatic metric, BooookScore, that measures the proportion of
sentences in a summary that do not contain any of the identified error types.
BooookScore has high agreement with human annotations and allows us to
systematically evaluate the impact of many other critical parameters (e.g.,
chunk size, base LLM) while saving $15K and 500 hours in human evaluation
costs. We find that closed-source LLMs such as GPT-4 and Claude 2 produce
summaries with higher BooookScore than the oft-repetitive ones generated by
LLaMA 2. Incremental updating yields lower BooookScore but higher level of
detail than hierarchical merging, a trade-off sometimes preferred by human
annotators. We release code and annotations after blind review to spur more
principled research on book-length summarization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yapei Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1&quot;&gt;Kyle Lo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_T/0/1/0/all/0/1&quot;&gt;Tanya Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1&quot;&gt;Mohit Iyyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01320">
<title>Avalon&apos;s Game of Thoughts: Battle Against Deception through Recursive Contemplation. (arXiv:2310.01320v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2310.01320</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent breakthroughs in large language models (LLMs) have brought remarkable
success in the field of LLM-as-Agent. Nevertheless, a prevalent assumption is
that the information processed by LLMs is consistently honest, neglecting the
pervasive deceptive or misleading information in human society and AI-generated
content. This oversight makes LLMs susceptible to malicious manipulations,
potentially resulting in detrimental outcomes. This study utilizes the
intricate Avalon game as a testbed to explore LLMs&apos; potential in deceptive
environments. Avalon, full of misinformation and requiring sophisticated logic,
manifests as a &quot;Game-of-Thoughts&quot;. Inspired by the efficacy of humans&apos;
recursive thinking and perspective-taking in the Avalon game, we introduce a
novel framework, Recursive Contemplation (ReCon), to enhance LLMs&apos; ability to
identify and counteract deceptive information. ReCon combines formulation and
refinement contemplation processes; formulation contemplation produces initial
thoughts and speech, while refinement contemplation further polishes them.
Additionally, we incorporate first-order and second-order perspective
transitions into these processes respectively. Specifically, the first-order
allows an LLM agent to infer others&apos; mental states, and the second-order
involves understanding how others perceive the agent&apos;s mental state. After
integrating ReCon with different LLMs, extensive experiment results from the
Avalon game indicate its efficacy in aiding LLMs to discern and maneuver around
deceptive information without extra fine-tuning and data. Finally, we offer a
possible explanation for the efficacy of ReCon and explore the current
limitations of LLMs in terms of safety, reasoning, speaking style, and format,
potentially furnishing insights for subsequent research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shenzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zilong Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_S/0/1/0/all/0/1&quot;&gt;Siyuan Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shuo Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qisen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1&quot;&gt;Andrew Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chaofei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Shiji Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1&quot;&gt;Gao Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02373">
<title>Secure and Effective Data Appraisal for Machine Learning. (arXiv:2310.02373v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02373</link>
<description rdf:parseType="Literal">&lt;p&gt;Essential for an unfettered data market is the ability to discreetly select
and evaluate training data before finalizing a transaction between the data
owner and model owner. To safeguard the privacy of both data and model, this
process involves scrutinizing the target model through Multi-Party Computation
(MPC). While prior research has posited that the MPC-based evaluation of
Transformer models is excessively resource-intensive, this paper introduces an
innovative approach that renders data selection practical. The contributions of
this study encompass three pivotal elements: (1) a groundbreaking pipeline for
confidential data selection using MPC, (2) replicating intricate
high-dimensional operations with simplified low-dimensional MLPs trained on a
limited subset of pertinent data, and (3) implementing MPC in a concurrent,
multi-phase manner. The proposed method is assessed across an array of
Transformer models and NLP/CV benchmarks. In comparison to the direct MPC-based
evaluation of the target model, our approach substantially reduces the time
required, from thousands of hours to mere tens of hours, with only a nominal
0.20% dip in accuracy when training with the selected data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_X/0/1/0/all/0/1&quot;&gt;Xu Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Changhong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1&quot;&gt;Felix Xiaozhu Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1&quot;&gt;Yangfeng Ji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02520">
<title>MedDiffusion: Boosting Health Risk Prediction via Diffusion-based Data Augmentation. (arXiv:2310.02520v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02520</link>
<description rdf:parseType="Literal">&lt;p&gt;Health risk prediction is one of the fundamental tasks under predictive
modeling in the medical domain, which aims to forecast the potential health
risks that patients may face in the future using their historical Electronic
Health Records (EHR). Researchers have developed several risk prediction models
to handle the unique challenges of EHR data, such as its sequential nature,
high dimensionality, and inherent noise. These models have yielded impressive
results. Nonetheless, a key issue undermining their effectiveness is data
insufficiency. A variety of data generation and augmentation methods have been
introduced to mitigate this issue by expanding the size of the training data
set through the learning of underlying data distributions. However, the
performance of these methods is often limited due to their task-unrelated
design. To address these shortcomings, this paper introduces a novel,
end-to-end diffusion-based risk prediction model, named MedDiffusion. It
enhances risk prediction performance by creating synthetic patient data during
training to enlarge sample space. Furthermore, MedDiffusion discerns hidden
relationships between patient visits using a step-wise attention mechanism,
enabling the model to automatically retain the most vital information for
generating high-quality data. Experimental evaluation on four real-world
medical datasets demonstrates that MedDiffusion outperforms 14 cutting-edge
baselines in terms of PR-AUC, F1, and Cohen&apos;s Kappa. We also conduct ablation
studies and benchmark our model against GAN-based alternatives to further
validate the rationality and adaptability of our model design. Additionally, we
analyze generated data to offer fresh insights into the model&apos;s
interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1&quot;&gt;Yuan Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1&quot;&gt;Suhan Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiaqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaochen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Ziyi Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yaqing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1&quot;&gt;Houping Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huai_M/0/1/0/all/0/1&quot;&gt;Mengdi Huai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Ting Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1&quot;&gt;Fenglong Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03022">
<title>Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making. (arXiv:2310.03022v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03022</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent success of Transformer in natural language processing has sparked
its use in various domains. In offline reinforcement learning (RL), Decision
Transformer (DT) is emerging as a promising model based on Transformer.
However, we discovered that the attention module of DT is not appropriate to
capture the inherent local dependence pattern in trajectories of RL modeled as
a Markov decision process. To overcome the limitations of DT, we propose a
novel action sequence predictor, named Decision ConvFormer (DC), based on the
architecture of MetaFormer, which is a general structure to process multiple
entities in parallel and understand the interrelationship among the multiple
entities. DC employs local convolution filtering as the token mixer and can
effectively capture the inherent local associations of the RL dataset. In
extensive experiments, DC achieved state-of-the-art performance across various
standard RL benchmarks while requiring fewer resources. Furthermore, we show
that DC better understands the underlying meaning in data and exhibits enhanced
generalization capability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jeonghye Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Suyoung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1&quot;&gt;Woojun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1&quot;&gt;Youngchul Sung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03030">
<title>GPT-MolBERTa: GPT Molecular Features Language Model for molecular property prediction. (arXiv:2310.03030v2 [physics.chem-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03030</link>
<description rdf:parseType="Literal">&lt;p&gt;With the emergence of Transformer architectures and their powerful
understanding of textual data, a new horizon has opened up to predict the
molecular properties based on text description. While SMILES are the most
common form of representation, they are lacking robustness, rich information
and canonicity, which limit their effectiveness in becoming generalizable
representations. Here, we present GPT-MolBERTa, a self-supervised large
language model (LLM) which uses detailed textual descriptions of molecules to
predict their properties. A text based description of 326000 molecules were
collected using ChatGPT and used to train LLM to learn the representation of
molecules. To predict the properties for the downstream tasks, both BERT and
RoBERTa models were used in the finetuning stage. Experiments show that
GPT-MolBERTa performs well on various molecule property benchmarks, and
approaching state of the art performance in regression tasks. Additionally,
further analysis of the attention mechanisms show that GPT-MolBERTa is able to
pick up important information from the input textual data, displaying the
interpretability of the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Balaji_S/0/1/0/all/0/1&quot;&gt;Suryanarayanan Balaji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Magar_R/0/1/0/all/0/1&quot;&gt;Rishikesh Magar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Jadhav_Y/0/1/0/all/0/1&quot;&gt;Yayati Jadhav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Farimani_a/0/1/0/all/0/1&quot;&gt;and Amir Barati Farimani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03149">
<title>Attributing Learned Concepts in Neural Networks to Training Data. (arXiv:2310.03149v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03149</link>
<description rdf:parseType="Literal">&lt;p&gt;By now there is substantial evidence that deep learning models learn certain
human-interpretable features as part of their internal representations of data.
As having the right (or wrong) concepts is critical to trustworthy machine
learning systems, it is natural to ask which inputs from the model&apos;s original
training set were most important for learning a concept at a given layer. To
answer this, we combine data attribution methods with methods for probing the
concepts learned by a model. Training network and probe ensembles for two
concept datasets on a range of network layers, we use the recently developed
TRAK method for large-scale data attribution. We find some evidence for
convergence, where removing the 10,000 top attributing images for a concept and
retraining the model does not change the location of the concept in the network
nor the probing sparsity of the concept. This suggests that rather than being
highly dependent on a few specific examples, the features that inform the
development of a concept are spread in a more diffuse manner across its
exemplars, implying robustness in concept formation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konz_N/0/1/0/all/0/1&quot;&gt;Nicholas Konz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godfrey_C/0/1/0/all/0/1&quot;&gt;Charles Godfrey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapiro_M/0/1/0/all/0/1&quot;&gt;Madelyn Shapiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1&quot;&gt;Jonathan Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1&quot;&gt;Henry Kvinge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Davis Brown&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03156">
<title>FedHyper: A Universal and Robust Learning Rate Scheduler for Federated Learning with Hypergradient Descent. (arXiv:2310.03156v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03156</link>
<description rdf:parseType="Literal">&lt;p&gt;The theoretical landscape of federated learning (FL) undergoes rapid
evolution, but its practical application encounters a series of intricate
challenges, and hyperparameter optimization is one of these critical
challenges. Amongst the diverse adjustments in hyperparameters, the adaptation
of the learning rate emerges as a crucial component, holding the promise of
significantly enhancing the efficacy of FL systems. In response to this
critical need, this paper presents FedHyper, a novel hypergradient-based
learning rate adaptation algorithm specifically designed for FL. FedHyper
serves as a universal learning rate scheduler that can adapt both global and
local rates as the training progresses. In addition, FedHyper not only
showcases unparalleled robustness to a spectrum of initial learning rate
configurations but also significantly alleviates the necessity for laborious
empirical learning rate adjustments. We provide a comprehensive theoretical
analysis of FedHyper&apos;s convergence rate and conduct extensive experiments on
vision and language benchmark datasets. The results demonstrate that FEDHYPER
consistently converges 1.1-3x faster than FedAvg and the competing baselines
while achieving superior final accuracy. Moreover, FedHyper catalyzes a
remarkable surge in accuracy, augmenting it by up to 15% compared to FedAvg
under suboptimal initial learning rate settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziyao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Ang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03281">
<title>A 5&apos; UTR Language Model for Decoding Untranslated Regions of mRNA and Function Predictions. (arXiv:2310.03281v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03281</link>
<description rdf:parseType="Literal">&lt;p&gt;The 5&apos; UTR, a regulatory region at the beginning of an mRNA molecule, plays a
crucial role in regulating the translation process and impacts the protein
expression level. Language models have showcased their effectiveness in
decoding the functions of protein and genome sequences. Here, we introduced a
language model for 5&apos; UTR, which we refer to as the UTR-LM. The UTR-LM is
pre-trained on endogenous 5&apos; UTRs from multiple species and is further
augmented with supervised information including secondary structure and minimum
free energy. We fine-tuned the UTR-LM in a variety of downstream tasks. The
model outperformed the best-known benchmark by up to 42% for predicting the
Mean Ribosome Loading, and by up to 60% for predicting the Translation
Efficiency and the mRNA Expression Level. The model also applies to identifying
unannotated Internal Ribosome Entry Sites within the untranslated region and
improves the AUPR from 0.37 to 0.52 compared to the best baseline. Further, we
designed a library of 211 novel 5&apos; UTRs with high predicted values of
translation efficiency and evaluated them via a wet-lab assay. Experiment
results confirmed that our top designs achieved a 32.5% increase in protein
production level relative to well-established 5&apos; UTR optimized for
therapeutics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_Y/0/1/0/all/0/1&quot;&gt;Yanyi Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1&quot;&gt;Dan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yupeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kaixuan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yue Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cong_L/0/1/0/all/0/1&quot;&gt;Le Cong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jason Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mengdi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03605">
<title>FASER: Binary Code Similarity Search through the use of Intermediate Representations. (arXiv:2310.03605v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03605</link>
<description rdf:parseType="Literal">&lt;p&gt;Being able to identify functions of interest in cross-architecture software
is useful whether you are analysing for malware, securing the software supply
chain or conducting vulnerability research. Cross-Architecture Binary Code
Similarity Search has been explored in numerous studies and has used a wide
range of different data sources to achieve its goals. The data sources
typically used draw on common structures derived from binaries such as function
control flow graphs or binary level call graphs, the output of the disassembly
process or the outputs of a dynamic analysis approach. One data source which
has received less attention is binary intermediate representations. Binary
Intermediate representations possess two interesting properties: they are cross
architecture by their very nature and encode the semantics of a function
explicitly to support downstream usage. Within this paper we propose Function
as a String Encoded Representation (FASER) which combines long document
transformers with the use of intermediate representations to create a model
capable of cross architecture function search without the need for manual
feature engineering, pre-training or a dynamic analysis step. We compare our
approach against a series of baseline approaches for two tasks; A general
function search task and a targeted vulnerability search task. Our approach
demonstrates strong performance across both tasks, performing better than all
baseline approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collyer_J/0/1/0/all/0/1&quot;&gt;Josh Collyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watson_T/0/1/0/all/0/1&quot;&gt;Tim Watson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_I/0/1/0/all/0/1&quot;&gt;Iain Phillips&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03611">
<title>GENER: A Parallel Layer Deep Learning Network To Detect Gene-Gene Interactions From Gene Expression Data. (arXiv:2310.03611v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03611</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting and discovering new gene interactions based on known gene
expressions and gene interaction data presents a significant challenge. Various
statistical and deep learning methods have attempted to tackle this challenge
by leveraging the topological structure of gene interactions and gene
expression patterns to predict novel gene interactions. In contrast, some
approaches have focused exclusively on utilizing gene expression profiles. In
this context, we introduce GENER, a parallel-layer deep learning network
designed exclusively for the identification of gene-gene relationships using
gene expression data. We conducted two training experiments and compared the
performance of our network with that of existing statistical and deep learning
approaches. Notably, our model achieved an average AUROC score of 0.834 on the
combined BioGRID&amp;amp;DREAM5 dataset, outperforming competing methods in predicting
gene-gene interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fakhry_A/0/1/0/all/0/1&quot;&gt;Ahmed Fakhry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khafagy_R/0/1/0/all/0/1&quot;&gt;Raneem Khafagy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ludl_A/0/1/0/all/0/1&quot;&gt;Adriaan-Alexander Ludl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.05608">
<title>Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis. (arXiv:2302.05608v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2302.05608</link>
<description rdf:parseType="Literal">&lt;p&gt;Often, deep network models are purely inductive during training and while
performing inference on unseen data. Thus, when such models are used for
predictions, it is well known that they often fail to capture the semantic
information and implicit dependencies that exist among objects (or concepts) on
a population level. Moreover, it is still unclear how domain or prior modal
knowledge can be specified in a backpropagation friendly manner, especially in
large-scale and noisy settings. In this work, we propose an end-to-end vision
and language model incorporating explicit knowledge graphs. We also introduce
an interactive out-of-distribution (OOD) layer using implicit network operator.
The layer is used to filter noise that is brought by external knowledge base.
In practice, we apply our model on several vision and language downstream tasks
including visual question answering, visual reasoning, and image-text retrieval
on different datasets. Our experiments show that it is possible to design
models that perform similarly to state-of-art results but with significantly
fewer samples and training time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medya_S/0/1/0/all/0/1&quot;&gt;Sourav Medya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravi_S/0/1/0/all/0/1&quot;&gt;Sathya N. Ravi&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>