<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.CL updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-12-11T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Computation and Language</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05278" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05291" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05356" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05402" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05415" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05434" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05435" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05448" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05467" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05471" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05483" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05488" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05491" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05497" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05503" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05520" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05585" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.01818" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.05751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.09705" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.04232" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.08964" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.05523" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.05225" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.12473" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.12247" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.03548" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.02105" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.03520" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.04388" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.07372" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12464" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12878" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13014" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13048" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15265" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15769" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.02320" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.06070" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11698" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.14870" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.04057" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.05695" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06483" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09007" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.12267" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.16230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02080" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.12050" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.12060" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.05961" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.08836" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12056" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.13230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00752" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03668" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.10981" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13191" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.16676" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.17793" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01766" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05112" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.15626" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.16588" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.18054" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.18760" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.01339" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.01648" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.02406" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.03549" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.03730" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.03815" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04021" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.09304" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.09936" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2312.05278">
<title>Lyrics: Boosting Fine-grained Language-Vision Alignment and Comprehension via Semantic-aware Visual Objects. (arXiv:2312.05278v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05278</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Vision Language Models (LVLMs) have demonstrated impressive zero-shot
capabilities in various vision-language dialogue scenarios. However, the
absence of fine-grained visual object detection hinders the model from
understanding the details of images, leading to irreparable visual
hallucinations and factual errors. In this paper, we propose Lyrics, a novel
multi-modal pre-training and instruction fine-tuning paradigm that bootstraps
vision-language alignment from fine-grained cross-modal collaboration. Building
on the foundation of BLIP-2, Lyrics infuses local visual features extracted
from a visual refiner that includes image tagging, object detection and
semantic segmentation modules into the Querying Transformer, while on the text
side, the language inputs equip the boundary boxes and tags derived from the
visual refiner. We further introduce a two-stage training scheme, in which the
pre-training stage bridges the modality gap through explicit and comprehensive
vision-language alignment targets. During the instruction fine-tuning stage, we
introduce semantic-aware visual feature extraction, a crucial method that
enables the model to extract informative features from concrete visual objects.
Our approach achieves strong performance on 13 held-out datasets across various
vision-language tasks, and demonstrates promising multi-modal understanding and
detailed depiction capabilities in real dialogue scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Junyu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gan_R/0/1/0/all/0/1&quot;&gt;Ruyi Gan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dixiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaojun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Ziwei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1&quot;&gt;Renliang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiaxing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pingjian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yan Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05291">
<title>GlitchBench: Can large multimodal models detect video game glitches?. (arXiv:2312.05291v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.05291</link>
<description rdf:parseType="Literal">&lt;p&gt;Large multimodal models (LMMs) have evolved from large language models (LLMs)
to integrate multiple input modalities, such as visual inputs. This integration
augments the capacity of LLMs for tasks requiring visual comprehension and
reasoning. However, the extent and limitations of their enhanced abilities are
not fully understood, especially when it comes to real-world tasks. To address
this gap, we introduce GlitchBench, a novel benchmark derived from video game
quality assurance tasks, to test and evaluate the reasoning capabilities of
LMMs. Our benchmark is curated from a variety of unusual and glitched scenarios
from video games and aims to challenge both the visual and linguistic reasoning
powers of LMMs in detecting and interpreting out-of-the-ordinary events. We
evaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents
a new challenge for these models. Code and data are available at:
https://glitchbench.github.io/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taesiri_M/0/1/0/all/0/1&quot;&gt;Mohammad Reza Taesiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_T/0/1/0/all/0/1&quot;&gt;Tianjun Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bezemer_C/0/1/0/all/0/1&quot;&gt;Cor-Paul Bezemer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1&quot;&gt;Anh Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05356">
<title>Neuron Patching: Neuron-level Model Editing on Code Generation and LLMs. (arXiv:2312.05356v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2312.05356</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models are successfully adopted in software engineering,
especially in code generation. Updating these models with new knowledge is very
expensive, and is often required to fully realize their value. In this paper,
we propose a novel and effective model editing approach, \textsc{MENT}, to
patch LLMs in coding tasks. Based on the mechanism of generative LLMs,
\textsc{MENT} enables model editing in next-token predictions, and further
supports common coding tasks. \textsc{MENT} is effective, efficient, and
reliable. It can correct a neural model by patching 1 or 2 neurons. As the
pioneer work on neuron-level model editing of generative models, we formalize
the editing process and introduce the involved concepts. Besides, we also
introduce new measures to evaluate its generalization ability, and build a
benchmark for further study. Our approach is evaluated on three coding tasks,
including API-seq recommendation, line-level code generation, and
pseudocode-to-code transaction. It outperforms the state-of-the-art by a
significant margin on both effectiveness and efficiency measures. In addition,
we demonstrate the usages of \textsc{MENT} for LLM reasoning in software
engineering. By editing the LLM knowledge with \textsc{MENT}, the directly or
indirectly dependent behaviors in the chain-of-thought change accordingly and
automatically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jian Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chunyang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aleti_A/0/1/0/all/0/1&quot;&gt;Aldeida Aleti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05402">
<title>Towards Controlled Table-to-Text Generation with Scientific Reasoning. (arXiv:2312.05402v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05402</link>
<description rdf:parseType="Literal">&lt;p&gt;The sheer volume of scientific experimental results and complex technical
statements, often presented in tabular formats, presents a formidable barrier
to individuals acquiring preferred information. The realms of scientific
reasoning and content generation that adhere to user preferences encounter
distinct challenges. In this work, we present a new task for generating fluent
and logical descriptions that match user preferences over scientific tabular
data, aiming to automate scientific document analysis. To facilitate research
in this direction, we construct a new challenging dataset CTRLSciTab consisting
of table-description pairs extracted from the scientific literature, with
highlighted cells and corresponding domain-specific knowledge base. We
evaluated popular pre-trained language models to establish a baseline and
proposed a novel architecture outperforming competing approaches. The results
showed that large models struggle to produce accurate content that aligns with
user preferences. As the first of its kind, our work should motivate further
research in scientific domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1&quot;&gt;Zhixin Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jianping Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1&quot;&gt;Jiexing Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1&quot;&gt;Mingxuan Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Ziwei He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1&quot;&gt;Guanjie Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhouhan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinbing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1&quot;&gt;Chenghu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05415">
<title>An Experimental Study: Assessing the Combined Framework of WavLM and BEST-RQ for Text-to-Speech Synthesis. (arXiv:2312.05415v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2312.05415</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new model architecture specifically suited for text-to-speech
(TTS) models. We combine WavLM, a pre-trained self-supervised learning (SSL)
speech model, and the BEST-RQ vector quantization framework. We assess the
extent to which the more task-agnostic WavLM, coupled with the superior
suitability of the simplistic BEST-RQ framework for a wider array of downstream
tasks, yields favorable outcomes. Experiments on the LibriSpeech dataset with
SUPERB benchmarking assert that the proposed model significantly underperforms.
We speculate the underlying reason for this performance is related to the
difference between featurizing raw audio waveforms and spectrograms with a
quantizer. We discuss the limitations of this approach to better guide future
advancements in TTS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nielson_V/0/1/0/all/0/1&quot;&gt;Via Nielson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hillis_S/0/1/0/all/0/1&quot;&gt;Steven Hillis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05434">
<title>Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models. (arXiv:2312.05434v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05434</link>
<description rdf:parseType="Literal">&lt;p&gt;The age of social media is rife with memes. Understanding and detecting
harmful memes pose a significant challenge due to their implicit meaning that
is not explicitly conveyed through the surface text and image. However,
existing harmful meme detection approaches only recognize superficial
harm-indicative signals in an end-to-end classification manner but ignore
in-depth cognition of the meme text and image. In this paper, we attempt to
detect harmful memes based on advanced reasoning over the interplay of
multimodal information in memes. Inspired by the success of Large Language
Models (LLMs) on complex reasoning, we first conduct abductive reasoning with
LLMs. Then we propose a novel generative framework to learn reasonable thoughts
from LLMs for better multimodal fusion and lightweight fine-tuning, which
consists of two training stages: 1) Distill multimodal reasoning knowledge from
LLMs; and 2) Fine-tune the generative framework to infer harmfulness. Extensive
experiments conducted on three meme datasets demonstrate that our proposed
approach achieves superior performance than state-of-the-art methods on the
harmful meme detection task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hongzhan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1&quot;&gt;Ziyang Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jing Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Long Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05435">
<title>Enhancing Robustness of Foundation Model Representations under Provenance-related Distribution Shifts. (arXiv:2312.05435v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05435</link>
<description rdf:parseType="Literal">&lt;p&gt;Foundation models are a current focus of attention in both industry and
academia. While they have shown their capabilities in a variety of tasks,
in-depth research is required to determine their robustness to distribution
shift when used as a basis for supervised machine learning. This is especially
important in the context of clinical data, with particular limitations related
to data accessibility, lack of pretraining materials, and limited availability
of high-quality annotations. In this work, we examine the stability of models
based on representations from foundation models under distribution shift. We
focus on confounding by provenance, a form of distribution shift that emerges
in the context of multi-institutional datasets when there are differences in
source-specific language use and class distributions. Using a sampling strategy
that synthetically induces varying degrees of distribution shift, we evaluate
the extent to which representations from foundation models result in
predictions that are inherently robust to confounding by provenance.
Additionally, we examine the effectiveness of a straightforward confounding
adjustment method inspired by Pearl&apos;s conception of backdoor adjustment.
Results indicate that while foundation models do show some out-of-the-box
robustness to confounding-by-provenance related distribution shifts, this can
be considerably improved through adjustment. These findings suggest a need for
deliberate adjustment of predictive models using representations from
foundation models in the context of source-specific distributional differences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1&quot;&gt;Xiruo Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_Z/0/1/0/all/0/1&quot;&gt;Zhecheng Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hur_B/0/1/0/all/0/1&quot;&gt;Brian Hur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1&quot;&gt;Feng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pakhomov_S/0/1/0/all/0/1&quot;&gt;Serguei V. S. Pakhomov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1&quot;&gt;Trevor Cohen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05448">
<title>Domain Adaptation of a State of the Art Text-to-SQL Model: Lessons Learned and Challenges Found. (arXiv:2312.05448v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05448</link>
<description rdf:parseType="Literal">&lt;p&gt;There are many recent advanced developments for the Text-to-SQL task, where
the Picard model is one of the the top performing models as measured by the
Spider dataset competition. However, bringing Text-to-SQL systems to realistic
use-cases through domain adaptation remains a tough challenge. We analyze how
well the base T5 Language Model and Picard perform on query structures
different from the Spider dataset, we fine-tuned the base model on the Spider
data and on independent databases (DB). To avoid accessing the DB content
online during inference, we also present an alternative way to disambiguate the
values in an input question using a rule-based approach that relies on an
intermediate representation of the semantic concepts of an input question. In
our results we show in what cases T5 and Picard can deliver good performance,
we share the lessons learned, and discuss current domain adaptation challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manotas_I/0/1/0/all/0/1&quot;&gt;Irene Manotas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popescu_O/0/1/0/all/0/1&quot;&gt;Octavian Popescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vo_N/0/1/0/all/0/1&quot;&gt;Ngoc Phuoc An Vo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheinin_V/0/1/0/all/0/1&quot;&gt;Vadim Sheinin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05467">
<title>Textual Toxicity in Social Media: Understanding the Bangla Toxic Language Expressed in Facebook Comment. (arXiv:2312.05467v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05467</link>
<description rdf:parseType="Literal">&lt;p&gt;Social Media is a repository of digital literature including user-generated
content. The users of social media are expressing their opinion with diverse
mediums such as text, emojis, memes, and also through other visual and textual
mediums. A major portion of these media elements could be treated as harmful to
others and they are known by many words including Cyberbullying and Toxic
Language . The goal of this research paper is to analyze a curated and
value-added dataset of toxic language titled ToxLex_bn . It is an exhaustive
wordlist that can be used as classifier material to detect toxicity in social
media. The toxic language/script used by the Bengali community as
cyberbullying, hate speech and moral policing became major trends in social
media culture in Bangladesh and West Bengal. The toxicity became so high that
the victims has to post as a counter or release explanation video for the
haters. Most cases are pointed to women celebrity and their relation, dress,
lifestyle are became trolled and toxicity flooded in comments boxes. Not only
celebrity bashing but also hates occurred between Hindu Muslims,
India-Bangladesh, Two opponents of 1971 and these are very common for virtual
conflict in the comment thread. Even many times facebook comment causes sue and
legal matters in Bangladesh and thus it requires more study. In this study, a
Bangla toxic language dataset has been analyzed which was inputted by the user
in Bengali script &amp;amp; language. For this, about 1968 unique bigrams or phrases as
wordlists have been analyzed which are derived from 2207590 comments. It is
assumed that this analysis will reinforce the detection of Bangla&apos;s toxic
language used in social media and thus cure this virtual disease.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashid_M/0/1/0/all/0/1&quot;&gt;Mohammad Mamun Or Rashid&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05471">
<title>Fine-Grained Analysis of Team Collaborative Dialogue. (arXiv:2312.05471v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05471</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural language analysis of human collaborative chat dialogues is an
understudied domain with many unique challenges: a large number of dialogue act
labels, underspecified and dynamic tasks, interleaved topics, and long-range
contextual dependence. While prior work has studied broad metrics of team
dialogue and associated performance using methods such as LSA, there has been
little effort in generating fine-grained descriptions of team dynamics and
individual performance from dialogue. We describe initial work towards
developing an explainable analytics tool in the software development domain
using Slack chats mined from our organization, including generation of a novel,
hierarchical labeling scheme; design of descriptive metrics based on the
frequency of occurrence of dialogue acts; and initial results using a
transformer + CRF architecture to incorporate long-range context.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perera_I/0/1/0/all/0/1&quot;&gt;Ian Perera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1&quot;&gt;Matthew Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilber_C/0/1/0/all/0/1&quot;&gt;Carson Wilber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05483">
<title>Teamwork Dimensions Classification Using BERT. (arXiv:2312.05483v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05483</link>
<description rdf:parseType="Literal">&lt;p&gt;Teamwork is a necessary competency for students that is often inadequately
assessed. Towards providing a formative assessment of student teamwork, an
automated natural language processing approach was developed to identify
teamwork dimensions of students&apos; online team chat. Developments in the field of
natural language processing and artificial intelligence have resulted in
advanced deep transfer learning approaches namely the Bidirectional Encoder
Representations from Transformers (BERT) model that allow for more in-depth
understanding of the context of the text. While traditional machine learning
algorithms were used in the previous work for the automatic classification of
chat messages into the different teamwork dimensions, our findings have shown
that classifiers based on the pre-trained language model BERT provides improved
classification performance, as well as much potential for generalizability in
the language use of varying team chat contexts and team member demographics.
This model will contribute towards an enhanced learning analytics tool for
teamwork assessment and feedback.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Junyoung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koh_E/0/1/0/all/0/1&quot;&gt;Elizabeth Koh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05488">
<title>Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis. (arXiv:2312.05488v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.05488</link>
<description rdf:parseType="Literal">&lt;p&gt;Game theory, as an analytical tool, is frequently utilized to analyze human
behavior in social science research. With the high alignment between the
behavior of Large Language Models (LLMs) and humans, a promising research
direction is to employ LLMs as substitutes for humans in game experiments,
enabling social science research. However, despite numerous empirical
researches on the combination of LLMs and game theory, the capability
boundaries of LLMs in game theory remain unclear. In this research, we endeavor
to systematically analyze LLMs in the context of game theory. Specifically,
rationality, as the fundamental principle of game theory, serves as the metric
for evaluating players&apos; behavior -- building a clear desire, refining belief
about uncertainty, and taking optimal actions. Accordingly, we select three
classical games (dictator game, Rock-Paper-Scissors, and ring-network game) to
analyze to what extent LLMs can achieve rationality in these three aspects. The
experimental results indicate that even the current state-of-the-art LLM
(GPT-4) exhibits substantial disparities compared to humans in game theory. For
instance, LLMs struggle to build desires based on uncommon preferences, fail to
refine belief from many simple patterns, and may overlook or modify refined
belief when taking actions. Therefore, we consider that introducing LLMs into
game experiments in the field of social science should be approached with
greater caution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1&quot;&gt;Caoyun Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jindou Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yaohui Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1&quot;&gt;Hao He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05491">
<title>Using Captum to Explain Generative Language Models. (arXiv:2312.05491v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05491</link>
<description rdf:parseType="Literal">&lt;p&gt;Captum is a comprehensive library for model explainability in PyTorch,
offering a range of methods from the interpretability literature to enhance
users&apos; understanding of PyTorch models. In this paper, we introduce new
features in Captum that are specifically designed to analyze the behavior of
generative language models. We provide an overview of the available
functionalities and example applications of their potential for understanding
learned associations within generative language models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miglani_V/0/1/0/all/0/1&quot;&gt;Vivek Miglani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1&quot;&gt;Aobo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markosyan_A/0/1/0/all/0/1&quot;&gt;Aram H. Markosyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Olano_D/0/1/0/all/0/1&quot;&gt;Diego Garcia-Olano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kokhlikyan_N/0/1/0/all/0/1&quot;&gt;Narine Kokhlikyan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05497">
<title>History Matters: Temporal Knowledge Editing in Large Language Model. (arXiv:2312.05497v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05497</link>
<description rdf:parseType="Literal">&lt;p&gt;The imperative task of revising or updating the knowledge stored within large
language models arises from two distinct sources: intrinsic errors inherent in
the model which should be corrected and outdated knowledge due to external
shifts in the real world which should be updated. Prevailing efforts in model
editing conflate these two distinct categories of edits arising from distinct
reasons and directly modify the original knowledge in models into new
knowledge. However, we argue that preserving the model&apos;s original knowledge
remains pertinent. Specifically, if a model&apos;s knowledge becomes outdated due to
evolving worldly dynamics, it should retain recollection of the historical
knowledge while integrating the newfound knowledge. In this work, we introduce
the task of Temporal Knowledge Editing (TKE) and establish a benchmark AToKe
(Assessment of TempOral Knowledge Editing) to evaluate current model editing
methods. We find that while existing model editing methods are effective at
making models remember new knowledge, the edited model catastrophically forgets
historical knowledge. To address this gap, we propose a simple and general
framework termed Multi-Editing with Time Objective (METO) for enhancing
existing editing models, which edits both historical and new knowledge
concurrently and optimizes the model&apos;s prediction for the time of each fact.
Our assessments demonstrate that while AToKe is still difficult, METO maintains
the effectiveness of learning new knowledge and meanwhile substantially
improves the performance of edited models on utilizing historical knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1&quot;&gt;Xunjian Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jin Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Liming Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1&quot;&gt;Xiaojun Wan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05503">
<title>Aligner: One Global Token is Worth Millions of Parameters When Aligning Large Language Models. (arXiv:2312.05503v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05503</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Aligner, a novel Parameter-Efficient Fine-Tuning (PEFT) method
for aligning multi-billion-parameter-sized Large Language Models (LLMs).
Aligner employs a unique design that constructs a globally shared set of
tunable tokens that modify the attention of every layer. Remarkably with this
method, even when using one token accounting for a mere 5,000 parameters,
Aligner can still perform comparably well to state-of-the-art LLM adaptation
methods like LoRA that require millions of parameters. This capacity is
substantiated in both instruction following and value alignment tasks. Besides
the multiple order-of-magnitude improvement in parameter efficiency, the
insight Aligner provides into the internal mechanisms of LLMs is also valuable.
The architectural features and efficacy of our method, in addition to our
experiments demonstrate that an LLM separates its internal handling of &quot;form&quot;
and &quot;knowledge&quot; in a somewhat orthogonal manner. This finding promises to
motivate new research into LLM mechanism understanding and value alignment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ziheng_Z/0/1/0/all/0/1&quot;&gt;Zhou Ziheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yingnian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Terzopoulos_D/0/1/0/all/0/1&quot;&gt;Demetri Terzopoulos&lt;/a&gt; (University of California, Los Angeles)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05520">
<title>Augmenty: A Python Library for Structured Text Augmentation. (arXiv:2312.05520v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05520</link>
<description rdf:parseType="Literal">&lt;p&gt;Augmnety is a Python library for structured text augmentation. It is built on
top of spaCy and allows for augmentation of both the text and its annotations.
Augmenty provides a wide range of augmenters which can be combined in a
flexible manner to create complex augmentation pipelines. It also includes a
set of primitives that can be used to create custom augmenters such as word
replacement augmenters. This functionality allows for augmentations within a
range of applications such as named entity recognition (NER), part-of-speech
tagging, and dependency parsing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Enevoldsen_K/0/1/0/all/0/1&quot;&gt;Kenneth Enevoldsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05585">
<title>Enhancing Medical Specialty Assignment to Patients using NLP Techniques. (arXiv:2312.05585v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05585</link>
<description rdf:parseType="Literal">&lt;p&gt;The introduction of Large Language Models (LLMs), and the vast volume of
publicly available medical data, amplified the application of NLP to the
medical domain. However, LLMs are pretrained on data that are not explicitly
relevant to the domain that are applied to and are often biased towards the
original data they were pretrained upon. Even when pretrained on domainspecific
data, these models typically require time-consuming fine-tuning to achieve good
performance for a specific task. To address these limitations, we propose an
alternative approach that achieves superior performance while being
computationally efficient. Specifically, we utilize keywords to train a deep
learning architecture that outperforms a language model pretrained on a large
corpus of text. Our proposal does not require pretraining nor fine-tuning and
can be applied directly to a specific setting for performing multi-label
classification. Our objective is to automatically assign a new patient to the
specialty of the medical professional they require, using a dataset that
contains medical transcriptions and relevant keywords. To this end, we
fine-tune the PubMedBERT model on this dataset, which serves as the baseline
for our experiments. We then twice train/fine-tune a DNN and the RoBERTa
language model, using both the keywords and the full transcriptions as input.
We compare the performance of these approaches using relevant metrics. Our
results demonstrate that utilizing keywords for text classification
significantly improves classification performance, for both a basic DL
architecture and a large language model. Our approach represents a promising
and efficient alternative to traditional methods for finetuning language models
on domain-specific data and has potential applications in various medical
domains
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solomou_C/0/1/0/all/0/1&quot;&gt;Chris Solomou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.01818">
<title>QAGCN: Answering Multi-Relation Questions via Single-Step Implicit Reasoning over Knowledge Graphs. (arXiv:2206.01818v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2206.01818</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-relation question answering (QA) is a challenging task, where given
questions usually require long reasoning chains in KGs that consist of multiple
relations. Recently, methods with explicit multi-step reasoning over KGs have
been prominently used in this task and have demonstrated promising performance.
Examples include methods that perform stepwise label propagation through KG
triples and methods that navigate over KG triples based on reinforcement
learning. A main weakness of these methods is that their reasoning mechanisms
are usually complex and difficult to implement or train. In this paper, we
argue that multi-relation QA can be achieved via end-to-end single-step
implicit reasoning, which is simpler, more efficient, and easier to adopt. We
propose QAGCN -- a Question-Aware Graph Convolutional Network (GCN)-based
method that includes a novel GCN architecture with controlled
question-dependent message propagation for the implicit reasoning. Extensive
experiments have been conducted, where QAGCN achieved competitive and even
superior performance compared to state-of-the-art explicit-reasoning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruijie Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossetto_L/0/1/0/all/0/1&quot;&gt;Luca Rossetto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cochez_M/0/1/0/all/0/1&quot;&gt;Michael Cochez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernstein_A/0/1/0/all/0/1&quot;&gt;Abraham Bernstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.05751">
<title>A Synergistic Compilation Workflow for Tackling Crosstalk in Quantum Machines. (arXiv:2207.05751v3 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2207.05751</link>
<description rdf:parseType="Literal">&lt;p&gt;Near-term quantum systems tend to be noisy. Crosstalk noise has been
recognized as one of several major types of noises in superconducting Noisy
Intermediate-Scale Quantum (NISQ) devices. Crosstalk arises from the concurrent
execution of two-qubit gates on nearby qubits, such as \texttt{CX}. It might
significantly raise the error rate of gates in comparison to running them
individually. Crosstalk can be mitigated through scheduling or hardware machine
tuning. Prior scientific studies, however, manage crosstalk at a really late
phase in the compilation process, usually after hardware mapping is done. It
may miss great opportunities of optimizing algorithm logic, routing, and
crosstalk at the same time. In this paper, we push the envelope by considering
all these factors simultaneously at the very early compilation stage. We
propose a crosstalk-aware quantum program compilation framework called CQC that
can enhance crosstalk mitigation while achieving satisfactory circuit depth.
Moreover, we identify opportunities for translation from intermediate
representation to the circuit for application-specific crosstalk mitigation,
for instance, the \texttt{CX} ladder construction in variational quantum
eigensolvers (VQE). Evaluations through simulation and on real IBM-Q devices
show that our framework can significantly reduce the error rate by up to
6$\times$, with only $\sim$60\% circuit depth compared to state-of-the-art gate
scheduling approaches. In particular, for VQE, we demonstrate 49\% circuit
depth reduction with 9.6\% fidelity improvement over prior art on the H4
molecule using IBMQ Guadalupe. Our CQC framework will be released on GitHub.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hua_F/0/1/0/all/0/1&quot;&gt;Fei Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yuwei Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Ang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chenxu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Meng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yanhao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hayes_A/0/1/0/all/0/1&quot;&gt;Ari Hayes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Stein_S/0/1/0/all/0/1&quot;&gt;Samuel Stein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Guo_M/0/1/0/all/0/1&quot;&gt;Minghao Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yipeng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhang_E/0/1/0/all/0/1&quot;&gt;Eddy Z. Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.09705">
<title>gBuilder: A Scalable Knowledge Graph Construction System for Unstructured Corpus. (arXiv:2208.09705v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2208.09705</link>
<description rdf:parseType="Literal">&lt;p&gt;We design a user-friendly and scalable knowledge graph construction (KGC)
system for extracting structured knowledge from the unstructured corpus.
Different from existing KGC systems, gBuilder provides a flexible and
user-defined pipeline to embrace the rapid development of IE models. More
built-in template-based or heuristic operators and programmable operators are
available for adapting to data from different domains. Furthermore, we also
design a cloud-based self-adaptive task scheduling for gBuilder to ensure its
scalability on large-scale knowledge graph construction. Experimental
evaluation demonstrates the ability of gBuilder to organize multiple
information extraction models for knowledge graph construction in a uniform
platform, and confirms its high scalability on large-scale KGC tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yanzeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_L/0/1/0/all/0/1&quot;&gt;Lei Zou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.04232">
<title>Revealing Patient-Reported Experiences in Healthcare from Social Media using the DAPMAV Framework. (arXiv:2210.04232v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2210.04232</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding patient experience in healthcare is increasingly important and
desired by medical professionals in a patient-centered care approach.
Healthcare discourse on social media presents an opportunity to gain a unique
perspective on patient-reported experiences, complementing traditional survey
data. These social media reports often appear as first-hand accounts of
patients&apos; journeys through the healthcare system, whose details extend beyond
the confines of structured surveys and at a far larger scale than focus groups.
However, in contrast with the vast presence of patient-experience data on
social media and the potential benefits the data offers, it attracts
comparatively little research attention due to the technical proficiency
required for text analysis. In this paper, we introduce the
Design-Acquire-Process-Model-Analyse-Visualise (DAPMAV) framework to provide an
overview of techniques and an approach to capture patient-reported experiences
from social media data. We apply this framework in a case study on prostate
cancer data from /r/ProstateCancer, demonstrate the framework&apos;s value in
capturing specific aspects of patient concern (such as sexual dysfunction),
provide an overview of the discourse, and show narrative and emotional
progression through these stories. We anticipate this framework to apply to a
wide variety of areas in healthcare, including capturing and differentiating
experiences across minority groups, geographic boundaries, and types of
illnesses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murray_C/0/1/0/all/0/1&quot;&gt;Curtis Murray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitchell_L/0/1/0/all/0/1&quot;&gt;Lewis Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuke_J/0/1/0/all/0/1&quot;&gt;Jonathan Tuke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mackay_M/0/1/0/all/0/1&quot;&gt;Mark Mackay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.08964">
<title>PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting. (arXiv:2210.08964v5 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/2210.08964</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new perspective on time series forecasting. In existing
time series forecasting methods, the models take a sequence of numerical values
as input and yield numerical values as output. The existing SOTA models are
largely based on the Transformer architecture, modified with multiple encoding
mechanisms to incorporate the context and semantics around the historical data.
Inspired by the successes of pre-trained language foundation models, we pose a
question about whether these models can also be adapted to solve time-series
forecasting. Thus, we propose a new forecasting paradigm: prompt-based time
series forecasting (PromptCast). In this novel task, the numerical input and
output are transformed into prompts and the forecasting task is framed in a
sentence-to-sentence manner, making it possible to directly apply language
models for forecasting purposes. To support and facilitate the research of this
task, we also present a large-scale dataset (PISA) that includes three
real-world forecasting scenarios. We evaluate different SOTA numerical-based
forecasting methods and language generation models. The benchmark results with
various forecasting settings demonstrate the proposed PromptCast with language
generation models is a promising research direction. Additionally, in
comparison to conventional numerical-based forecasting, PromptCast shows a much
better generalization ability under the zero-shot setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xue_H/0/1/0/all/0/1&quot;&gt;Hao Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Salim_F/0/1/0/all/0/1&quot;&gt;Flora D. Salim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.05523">
<title>Impact of Adversarial Training on Robustness and Generalizability of Language Models. (arXiv:2211.05523v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2211.05523</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial training is widely acknowledged as the most effective defense
against adversarial attacks. However, it is also well established that
achieving both robustness and generalization in adversarially trained models
involves a trade-off. The goal of this work is to provide an in depth
comparison of different approaches for adversarial training in language models.
Specifically, we study the effect of pre-training data augmentation as well as
training time input perturbations vs. embedding space perturbations on the
robustness and generalization of transformer-based language models. Our
findings suggest that better robustness can be achieved by pre-training data
augmentation or by training with input space perturbation. However, training
with embedding space perturbation significantly improves generalization. A
linguistic correlation analysis of neurons of the learned models reveals that
the improved generalization is due to &apos;more specialized&apos; neurons. To the best
of our knowledge, this is the first work to carry out a deep qualitative
analysis of different methods of generating adversarial examples in adversarial
training of language models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Altinisik_E/0/1/0/all/0/1&quot;&gt;Enes Altinisik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1&quot;&gt;Hassan Sajjad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sencar_H/0/1/0/all/0/1&quot;&gt;Husrev Taha Sencar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Messaoud_S/0/1/0/all/0/1&quot;&gt;Safa Messaoud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chawla_S/0/1/0/all/0/1&quot;&gt;Sanjay Chawla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.05225">
<title>LEAD: Liberal Feature-based Distillation for Dense Retrieval. (arXiv:2212.05225v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2212.05225</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge distillation is often used to transfer knowledge from a strong
teacher model to a relatively weak student model. Traditional methods include
response-based methods and feature-based methods. Response-based methods are
widely used but suffer from lower upper limits of performance due to their
ignorance of intermediate signals, while feature-based methods have constraints
on vocabularies, tokenizers and model architectures. In this paper, we propose
a liberal feature-based distillation method (LEAD). LEAD aligns the
distribution between the intermediate layers of teacher model and student
model, which is effective, extendable, portable and has no requirements on
vocabularies, tokenizers, or model architectures. Extensive experiments show
the effectiveness of LEAD on widely-used benchmarks, including MS MARCO Passage
Ranking, TREC 2019 DL Track, MS MARCO Document Ranking and TREC 2020 DL Track.
Our code is available in https://github.com/microsoft/SimXNS/tree/main/LEAD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Hao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1&quot;&gt;Yeyun Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_A/0/1/0/all/0/1&quot;&gt;Anlei Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jingwen Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Linjun Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumder_R/0/1/0/all/0/1&quot;&gt;Rangan Majumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1&quot;&gt;Nan Duan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.12473">
<title>Large Language Models for Biomedical Knowledge Graph Construction: Information extraction from EMR notes. (arXiv:2301.12473v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2301.12473</link>
<description rdf:parseType="Literal">&lt;p&gt;The automatic construction of knowledge graphs (KGs) is an important research
area in medicine, with far-reaching applications spanning drug discovery and
clinical trial design. These applications hinge on the accurate identification
of interactions among medical and biological entities. In this study, we
propose an end-to-end machine learning solution based on large language models
(LLMs) that utilize electronic medical record notes to construct KGs. The
entities used in the KG construction process are diseases, factors, treatments,
as well as manifestations that coexist with the patient while experiencing the
disease. Given the critical need for high-quality performance in medical
applications, we embark on a comprehensive assessment of 12 LLMs of various
architectures, evaluating their performance and safety attributes. To gauge the
quantitative efficacy of our approach by assessing both precision and recall,
we manually annotate a dataset provided by the Macula and Retina Institute. We
also assess the qualitative performance of LLMs, such as the ability to
generate structured outputs or the tendency to hallucinate. The results
illustrate that in contrast to encoder-only and encoder-decoder, decoder-only
LLMs require further investigation. Additionally, we provide guided prompt
design to utilize such LLMs. The application of the proposed methodology is
demonstrated on age-related macular degeneration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arsenyan_V/0/1/0/all/0/1&quot;&gt;Vahan Arsenyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bughdaryan_S/0/1/0/all/0/1&quot;&gt;Spartak Bughdaryan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaya_F/0/1/0/all/0/1&quot;&gt;Fadi Shaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Small_K/0/1/0/all/0/1&quot;&gt;Kent Small&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahnazaryan_D/0/1/0/all/0/1&quot;&gt;Davit Shahnazaryan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.12247">
<title>Quantifying &amp; Modeling Multimodal Interactions: An Information Decomposition Framework. (arXiv:2302.12247v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.12247</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent explosion of interest in multimodal applications has resulted in a
wide selection of datasets and methods for representing and integrating
information from different modalities. Despite these empirical advances, there
remain fundamental research questions: How can we quantify the interactions
that are necessary to solve a multimodal task? Subsequently, what are the most
suitable multimodal models to capture these interactions? To answer these
questions, we propose an information-theoretic approach to quantify the degree
of redundancy, uniqueness, and synergy relating input modalities with an output
task. We term these three measures as the PID statistics of a multimodal
distribution (or PID for short), and introduce two new estimators for these PID
statistics that scale to high-dimensional distributions. To validate PID
estimation, we conduct extensive experiments on both synthetic datasets where
the PID is known and on large-scale multimodal benchmarks where PID estimations
are compared with human annotations. Finally, we demonstrate their usefulness
in (1) quantifying interactions within multimodal datasets, (2) quantifying
interactions captured by multimodal models, (3) principled approaches for model
selection, and (4) three real-world case studies engaging with domain experts
in pathology, mood prediction, and robotic perception where our framework helps
to recommend strong multimodal models for each application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Paul Pu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yun Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1&quot;&gt;Xiang Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1&quot;&gt;Chun Kai Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1&quot;&gt;Suzanne Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Richard Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1&quot;&gt;Zihao Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_N/0/1/0/all/0/1&quot;&gt;Nicholas Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Auerbach_R/0/1/0/all/0/1&quot;&gt;Randy Auerbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_F/0/1/0/all/0/1&quot;&gt;Faisal Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1&quot;&gt;Louis-Philippe Morency&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.03548">
<title>GEMINI: Controlling the Sentence-level Writing Style for Abstractive Text Summarization. (arXiv:2304.03548v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2304.03548</link>
<description rdf:parseType="Literal">&lt;p&gt;Human experts write summaries using different techniques, including
extracting a sentence from the document and rewriting it, or fusing various
information from the document to abstract it. These techniques are flexible and
thus difficult to be imitated by any single method. To address this issue, we
propose an adaptive model, GEMINI, that integrates a rewriter and a generator
to mimic the sentence rewriting and abstracting techniques, respectively.
GEMINI adaptively chooses to rewrite a specific document sentence or generate a
summary sentence from scratch. Experiments demonstrate that our adaptive
approach outperforms the pure abstractive and rewriting baselines on three
benchmark datasets, achieving the best results on WikiHow. Interestingly,
empirical results show that the human summary styles of summary sentences are
consistently predictable given their context. We release our code and model at
\url{https://github.com/baoguangsheng/gemini}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_G/0/1/0/all/0/1&quot;&gt;Guangsheng Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ou_Z/0/1/0/all/0/1&quot;&gt;Zebin Ou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yue Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.02105">
<title>GPT-RE: In-context Learning for Relation Extraction using Large Language Models. (arXiv:2305.02105v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.02105</link>
<description rdf:parseType="Literal">&lt;p&gt;In spite of the potential for ground-breaking achievements offered by large
language models (LLMs) (e.g., GPT-3), they still lag significantly behind
fully-supervised baselines (e.g., fine-tuned BERT) in relation extraction (RE).
This is due to the two major shortcomings of LLMs in RE: (1) low relevance
regarding entity and relation in retrieved demonstrations for in-context
learning; and (2) the strong inclination to wrongly classify NULL examples into
other pre-defined labels.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose GPT-RE to bridge the gap between LLMs and
fully-supervised baselines. GPT-RE successfully addresses the aforementioned
issues by (1) incorporating task-specific entity representations in
demonstration retrieval; and (2) enriching the demonstrations with gold
label-induced reasoning logic. We evaluate GPT-RE on four widely-used RE
datasets, and observe that GPT-RE achieves improvements over not only existing
GPT-3 baselines, but also fully-supervised baselines. Specifically, GPT-RE
achieves SOTA performances on the Semeval and SciERC datasets, and competitive
performances on the TACRED and ACE05 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1&quot;&gt;Zhen Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1&quot;&gt;Fei Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1&quot;&gt;Zhuoyuan Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qianying Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1&quot;&gt;Haiyue Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1&quot;&gt;Sadao Kurohashi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.03520">
<title>Context-Aware Semantic Similarity Measurement for Unsupervised Word Sense Disambiguation. (arXiv:2305.03520v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.03520</link>
<description rdf:parseType="Literal">&lt;p&gt;The issue of word sense ambiguity poses a significant challenge in natural
language processing due to the scarcity of annotated data to feed machine
learning models to face the challenge. Therefore, unsupervised word sense
disambiguation methods have been developed to overcome that challenge without
relying on annotated data. This research proposes a new context-aware approach
to unsupervised word sense disambiguation, which provides a flexible mechanism
for incorporating contextual information into the similarity measurement
process. We experiment with a popular benchmark dataset to evaluate the
proposed strategy and compare its performance with state-of-the-art
unsupervised word sense disambiguation techniques. The experimental results
indicate that our approach substantially enhances disambiguation accuracy and
surpasses the performance of several existing techniques. Our findings
underscore the significance of integrating contextual information in semantic
similarity measurements to manage word sense ambiguity in unsupervised
scenarios effectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinez_Gil_J/0/1/0/all/0/1&quot;&gt;Jorge Martinez-Gil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.04388">
<title>Language Models Don&apos;t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting. (arXiv:2305.04388v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.04388</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) can achieve strong performance on many tasks by
producing step-by-step reasoning before giving a final output, often referred
to as chain-of-thought reasoning (CoT). It is tempting to interpret these CoT
explanations as the LLM&apos;s process for solving a task. This level of
transparency into LLMs&apos; predictions would yield significant safety benefits.
However, we find that CoT explanations can systematically misrepresent the true
reason for a model&apos;s prediction. We demonstrate that CoT explanations can be
heavily influenced by adding biasing features to model inputs--e.g., by
reordering the multiple-choice options in a few-shot prompt to make the answer
always &quot;(A)&quot;--which models systematically fail to mention in their
explanations. When we bias models toward incorrect answers, they frequently
generate CoT explanations rationalizing those answers. This causes accuracy to
drop by as much as 36% on a suite of 13 tasks from BIG-Bench Hard, when testing
with GPT-3.5 from OpenAI and Claude 1.0 from Anthropic. On a social-bias task,
model explanations justify giving answers in line with stereotypes without
mentioning the influence of these social biases. Our findings indicate that CoT
explanations can be plausible yet misleading, which risks increasing our trust
in LLMs without guaranteeing their safety. Building more transparent and
explainable systems will require either improving CoT faithfulness through
targeted efforts or abandoning CoT in favor of alternative methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turpin_M/0/1/0/all/0/1&quot;&gt;Miles Turpin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michael_J/0/1/0/all/0/1&quot;&gt;Julian Michael&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1&quot;&gt;Ethan Perez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1&quot;&gt;Samuel R. Bowman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.07372">
<title>Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations. (arXiv:2305.07372v4 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/2305.07372</link>
<description rdf:parseType="Literal">&lt;p&gt;Relational databases play an important role in this Big Data era. However, it
is challenging for non-experts to fully unleash the analytical power of
relational databases, since they are not familiar with database languages such
as SQL. Many techniques have been proposed to automatically generate SQL from
natural language, but they suffer from two issues: (1) they still make many
mistakes, particularly for complex queries, and (2) they do not provide a
flexible way for non-expert users to validate and refine the incorrect queries.
To address these issues, we introduce a new interaction mechanism that allows
users directly edit a step-by-step explanation of an incorrect SQL to fix SQL
errors. Experiments on the Spider benchmark show that our approach outperforms
three SOTA approaches by at least 31.6% in terms of execution accuracy. A user
study with 24 participants further shows that our approach helped users solve
significantly more SQL tasks with less time and higher confidence,
demonstrating its potential to expand access to databases, particularly for
non-experts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yuan Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_Z/0/1/0/all/0/1&quot;&gt;Zheng Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Toby Jia-Jun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kummerfeld_J/0/1/0/all/0/1&quot;&gt;Jonathan K. Kummerfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12464">
<title>Self-supervised Predictive Coding Models Encode Speaker and Phonetic Information in Orthogonal Subspaces. (arXiv:2305.12464v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12464</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised speech representations are known to encode both speaker and
phonetic information, but how they are distributed in the high-dimensional
space remains largely unexplored. We hypothesize that they are encoded in
orthogonal subspaces, a property that lends itself to simple disentanglement.
Applying principal component analysis to representations of two predictive
coding models, we identify two subspaces that capture speaker and phonetic
variances, and confirm that they are nearly orthogonal. Based on this property,
we propose a new speaker normalization method which collapses the subspace that
encodes speaker information, without requiring transcriptions. Probing
experiments show that our method effectively eliminates speaker information and
outperforms a previous baseline in phone discrimination tasks. Moreover, the
approach generalizes and can be used to remove information of unseen speakers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1&quot;&gt;Oli Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Hao Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldwater_S/0/1/0/all/0/1&quot;&gt;Sharon Goldwater&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12878">
<title>Non-Autoregressive Document-Level Machine Translation. (arXiv:2305.12878v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12878</link>
<description rdf:parseType="Literal">&lt;p&gt;Non-autoregressive translation (NAT) models achieve comparable performance
and superior speed compared to auto-regressive translation (AT) models in the
context of sentence-level machine translation (MT). However, their abilities
are unexplored in document-level MT, hindering their usage in real scenarios.
In this paper, we conduct a comprehensive examination of typical NAT models in
the context of document-level MT and further propose a simple but effective
design of sentence alignment between source and target. Experiments show that
NAT models achieve high acceleration on documents, and sentence alignment
significantly enhances their performance.
&lt;/p&gt;
&lt;p&gt;However, current NAT models still have a significant performance gap compared
to their AT counterparts. Further investigation reveals that NAT models suffer
more from the multi-modality and misalignment issues in the context of
document-level MT, and current NAT models struggle with exploiting document
context and handling discourse phenomena. We delve into these challenges and
provide our code at \url{https://github.com/baoguangsheng/nat-on-doc}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_G/0/1/0/all/0/1&quot;&gt;Guangsheng Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teng_Z/0/1/0/all/0/1&quot;&gt;Zhiyang Teng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Jianhao Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yue Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13014">
<title>Can Large Language Models emulate an inductive Thematic Analysis of semi-structured interviews? An exploration and provocation on the limits of the approach and the model. (arXiv:2305.13014v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13014</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have emerged as powerful generative Artificial
Intelligence solutions which can be applied to several fields and areas of
work. This paper presents results and reflection of an experiment done to use
the model GPT 3.5-Turbo to emulate some aspects of an inductive Thematic
Analysis. Previous research on this subject has largely worked on conducting
deductive analysis. Thematic Analysis is a qualitative method for analysis
commonly used in social sciences and it is based on interpretations made by the
human analyst(s) and the identification of explicit and latent meanings in
qualitative data. Attempting an analysis based on human interpretation with an
LLM clearly is a provocation but also a way to learn something about how these
systems can or cannot be used in qualitative research. The paper presents the
motivations for attempting this emulation, it reflects on how the six steps to
a Thematic Analysis proposed by Braun and Clarke can at least partially be
reproduced with the LLM and it also reflects on what are the outputs produced
by the model. The paper used two existing datasets of open access
semi-structured interviews, previously analysed with Thematic Analysis by other
researchers. It used the previously produced analysis (and the related themes)
to compare with the results produced by the LLM. The results show that the
model can infer at least partially some of the main Themes. The objective of
the paper is not to replace human analysts in qualitative analysis but to learn
if some elements of LLM data manipulation can to an extent be of support for
qualitative research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paoli_S/0/1/0/all/0/1&quot;&gt;Stefano De Paoli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13048">
<title>RWKV: Reinventing RNNs for the Transformer Era. (arXiv:2305.13048v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13048</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformers have revolutionized almost all natural language processing (NLP)
tasks but suffer from memory and computational complexity that scales
quadratically with sequence length. In contrast, recurrent neural networks
(RNNs) exhibit linear scaling in memory and computational requirements but
struggle to match the same performance as Transformers due to limitations in
parallelization and scalability. We propose a novel model architecture,
Receptance Weighted Key Value (RWKV), that combines the efficient
parallelizable training of transformers with the efficient inference of RNNs.
&lt;/p&gt;
&lt;p&gt;Our approach leverages a linear attention mechanism and allows us to
formulate the model as either a Transformer or an RNN, thus parallelizing
computations during training and maintains constant computational and memory
complexity during inference. We scale our models as large as 14 billion
parameters, by far the largest dense RNN ever trained, and find RWKV performs
on par with similarly sized Transformers, suggesting future work can leverage
this architecture to create more efficient models. This work presents a
significant step towards reconciling trade-offs between computational
efficiency and model performance in sequence processing tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1&quot;&gt;Bo Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alcaide_E/0/1/0/all/0/1&quot;&gt;Eric Alcaide&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anthony_Q/0/1/0/all/0/1&quot;&gt;Quentin Anthony&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1&quot;&gt;Alon Albalak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arcadinho_S/0/1/0/all/0/1&quot;&gt;Samuel Arcadinho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1&quot;&gt;Stella Biderman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1&quot;&gt;Huanqi Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xin Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_M/0/1/0/all/0/1&quot;&gt;Michael Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grella_M/0/1/0/all/0/1&quot;&gt;Matteo Grella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+GV_K/0/1/0/all/0/1&quot;&gt;Kranthi Kiran GV&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xuzheng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_H/0/1/0/all/0/1&quot;&gt;Haowen Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jiaju Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazienko_P/0/1/0/all/0/1&quot;&gt;Przemyslaw Kazienko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kocon_J/0/1/0/all/0/1&quot;&gt;Jan Kocon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_J/0/1/0/all/0/1&quot;&gt;Jiaming Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koptyra_B/0/1/0/all/0/1&quot;&gt;Bartlomiej Koptyra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lau_H/0/1/0/all/0/1&quot;&gt;Hayden Lau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mantri_K/0/1/0/all/0/1&quot;&gt;Krishna Sri Ipsit Mantri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mom_F/0/1/0/all/0/1&quot;&gt;Ferdinand Mom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saito_A/0/1/0/all/0/1&quot;&gt;Atsushi Saito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1&quot;&gt;Guangyu Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1&quot;&gt;Xiangru Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bolun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wind_J/0/1/0/all/0/1&quot;&gt;Johan S. Wind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wozniak_S/0/1/0/all/0/1&quot;&gt;Stanislaw Wozniak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruichong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhenyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qihang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1&quot;&gt;Peng Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1&quot;&gt;Qinghua Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jian Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1&quot;&gt;Rui-Jie Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15265">
<title>Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model. (arXiv:2305.15265v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15265</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid growth in model size, fine-tuning the large pre-trained
language model has become increasingly difficult due to its extensive memory
usage. Previous works usually focus on reducing the number of trainable
parameters in the network. While the model parameters do contribute to memory
usage, the primary memory bottleneck during training arises from storing
feature maps, also known as activations, as they are crucial for gradient
calculation. Notably, neural networks are usually trained using stochastic
gradient descent. We argue that in stochastic optimization, models can handle
noisy gradients as long as the gradient estimator is unbiased with reasonable
variance. Following this motivation, we propose a new family of unbiased
estimators called WTA-CRS, for matrix production with reduced variance, which
only requires storing the sub-sampled activations for calculating the gradient.
Our work provides both theoretical and experimental evidence that, in the
context of tuning transformers, our proposed estimators exhibit lower variance
compared to existing ones. By replacing the linear operation with our
approximated one in transformers, we can achieve up to 2.7$\times$ peak memory
reduction with almost no accuracy drop and enables up to $6.4\times$ larger
batch size. Under the same hardware, WTA-CRS enables better down-streaming task
performance by applying larger models and/or faster training speed with larger
batch sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zirui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Guanchu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1&quot;&gt;Shaochen Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhaozhuo Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1&quot;&gt;Daochen Zha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1&quot;&gt;Ruixiang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Zhimeng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1&quot;&gt;Kaixiong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhary_V/0/1/0/all/0/1&quot;&gt;Vipin Chaudhary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shuai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15769">
<title>MERGE: Fast Private Text Generation. (arXiv:2305.15769v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15769</link>
<description rdf:parseType="Literal">&lt;p&gt;The drastic increase in language models&apos; parameters has led to a new trend of
deploying models in cloud servers, raising growing concerns about private
inference for Transformer-based models. Existing two-party privacy-preserving
techniques, however, only take into account natural language understanding
(NLU) scenarios. Private inference in natural language generation (NLG),
crucial for applications like translation and code completion, remains
underexplored.In addition, previous privacy-preserving techniques suffer from
convergence issues during model training and exhibit poor inference speed when
used with NLG models due to the neglect of time-consuming operations in
auto-regressive generations. To address these issues, we propose a fast private
text generation framework for Transformer-based language models, namely
MERGE.MERGE reuses the output hidden state as the word embedding to bypass the
embedding computation and reorganize the linear operations in the Transformer
module to accelerate the forward procedure. Extensive experiments show that
MERGE achieves a 26.5x speedup to the vanilla encrypted model under the
sequence length 512, and reduces 80\% communication cost, with an up to 10x
speedup to state-of-the-art approximated models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1&quot;&gt;Zi Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Pinghui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruofei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1&quot;&gt;Nuo Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_L/0/1/0/all/0/1&quot;&gt;Lifeng Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuo Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.02320">
<title>Exploring the Impact of Model Scaling on Parameter-Efficient Tuning. (arXiv:2306.02320v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.02320</link>
<description rdf:parseType="Literal">&lt;p&gt;Parameter-efficient tuning (PET) methods can effectively drive extremely
large pre-trained language models (PLMs) by training only minimal parameters.
Different PET methods utilize different manually designed tunable modules. In
small PLMs, there are usually noticeable performance differences among PET
methods. Nevertheless, as the model scale increases, the performance
differences become marginal. Hence, we hypothesize that model scaling mitigates
the impact of design differences on PET methods. To investigate this
hypothesis, we introduce a more flexible PET method called Arbitrary PET (APET)
method. The APET method is compatible with a tunable module, which consists of
any number of parameters distributed in arbitrary positions. Then, we utilize
it and conduct experiments on 11 NLP tasks across 3 representative PLMs. Our
investigations reveal that model scaling (1) mitigates the effects of the
positions of tunable parameters on performance, and (2) enables tuning methods
to achieve performance comparable to full-parameter fine-tuning by optimizing
fewer tunable parameters. Intriguingly, we also observe that tuning methods
optimize the similar number of tunable parameters to exceed random guess
performance on different tasks. We collectively discuss this phenomenon and the
two aforementioned findings from an optimization perspective to understand the
underlying mechanisms. These conclusions enhance our understanding of the
impact of model scaling on PET and assist in designing more effective and
efficient PET methods for PLMs of different scales. The source code can be
obtained from this GitHub repository:
\url{https://github.com/yushengsu-thu/PET_Scaling}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yusheng Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1&quot;&gt;Chi-Min Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;Jiali Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1&quot;&gt;Yujia Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yankai Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1&quot;&gt;Shengding Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zonghan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1&quot;&gt;Ning Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xingzhi Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_G/0/1/0/all/0/1&quot;&gt;Guotong Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Maosong Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.06070">
<title>Mind2Web: Towards a Generalist Agent for the Web. (arXiv:2306.06070v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.06070</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Mind2Web, the first dataset for developing and evaluating
generalist agents for the web that can follow language instructions to complete
complex tasks on any website. Existing datasets for web agents either use
simulated websites or only cover a limited set of websites and tasks, thus not
suitable for generalist web agents. With over 2,000 open-ended tasks collected
from 137 websites spanning 31 domains and crowdsourced action sequences for the
tasks, Mind2Web provides three necessary ingredients for building generalist
web agents: 1) diverse domains, websites, and tasks, 2) use of real-world
websites instead of simulated and simplified ones, and 3) a broad spectrum of
user interaction patterns. Based on Mind2Web, we conduct an initial exploration
of using large language models (LLMs) for building generalist web agents. While
the raw HTML of real-world websites are often too large to be fed to LLMs, we
show that first filtering it with a small LM significantly improves the
effectiveness and efficiency of LLMs. Our solution demonstrates a decent level
of performance, even on websites or entire domains the model has never seen
before, but there is still a substantial room to improve towards truly
generalizable agents. We open-source our dataset, model implementation, and
trained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate further
research on building a generalist agent for the web.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1&quot;&gt;Xiang Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1&quot;&gt;Yu Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1&quot;&gt;Boyuan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shijie Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stevens_S/0/1/0/all/0/1&quot;&gt;Samuel Stevens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Boshi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Huan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yu Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11698">
<title>DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models. (arXiv:2306.11698v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11698</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Pre-trained Transformer (GPT) models have exhibited exciting
progress in their capabilities, capturing the interest of practitioners and the
public alike. Yet, while the literature on the trustworthiness of GPT models
remains limited, practitioners have proposed employing capable GPT models for
sensitive applications such as healthcare and finance -- where mistakes can be
costly. To this end, this work proposes a comprehensive trustworthiness
evaluation for large language models with a focus on GPT-4 and GPT-3.5,
considering diverse perspectives -- including toxicity, stereotype bias,
adversarial robustness, out-of-distribution robustness, robustness on
adversarial demonstrations, privacy, machine ethics, and fairness. Based on our
evaluations, we discover previously unpublished vulnerabilities to
trustworthiness threats. For instance, we find that GPT models can be easily
misled to generate toxic and biased outputs and leak private information in
both training data and conversation history. We also find that although GPT-4
is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more
vulnerable given jailbreaking system or user prompts, potentially because GPT-4
follows (misleading) instructions more precisely. Our work illustrates a
comprehensive trustworthiness evaluation of GPT models and sheds light on the
trustworthiness gaps. Our benchmark is publicly available at
https://decodingtrust.github.io/. Additionally, our dataset can be previewed at
https://huggingface.co/datasets/AI-Secure/DecodingTrust, and a concise version
of our DecodingTrust is accessible at https://openreview.net/pdf?id=kaHpo8OZw2.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Boxin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Weixin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_H/0/1/0/all/0/1&quot;&gt;Hengzhi Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Chulin Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1&quot;&gt;Mintong Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chenhui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chejian Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zidi Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutta_R/0/1/0/all/0/1&quot;&gt;Ritik Dutta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaeffer_R/0/1/0/all/0/1&quot;&gt;Rylan Schaeffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1&quot;&gt;Sang T. Truong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1&quot;&gt;Simran Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazeika_M/0/1/0/all/0/1&quot;&gt;Mantas Mazeika&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1&quot;&gt;Dan Hendrycks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zinan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yu Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1&quot;&gt;Sanmi Koyejo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dawn Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.14870">
<title>Composing Parameter-Efficient Modules with Arithmetic Operations. (arXiv:2306.14870v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.14870</link>
<description rdf:parseType="Literal">&lt;p&gt;As an efficient alternative to conventional full finetuning,
parameter-efficient finetuning (PEFT) is becoming the prevailing method to
adapt pretrained language models. In PEFT, a lightweight module is learned on
each dataset while the underlying pretrained language model remains unchanged,
resulting in multiple compact modules representing diverse skills when applied
to various domains and tasks. In this paper, we propose to compose these
parameter-efficient modules through linear arithmetic operations in the weight
space, thereby integrating different module capabilities. Specifically, we
first define addition and negation operators for the module, and then further
compose these two basic operators to perform flexible arithmetic. Our approach
requires \emph{no additional training} and enables highly flexible module
composition. We apply different arithmetic operations to compose the
parameter-efficient modules for (1) distribution generalization, (2)
multi-tasking, (3) unlearning, and (4) domain transfer. Additionally, we extend
our approach to detoxify Alpaca-LoRA, the latest instruction-tuned large
language model based on LLaMA. Empirical results demonstrate that our approach
produces new and effective parameter-efficient modules that significantly
outperform existing ones across all settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jinghan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shiqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Junteng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Junxian He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02028">
<title>EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models. (arXiv:2307.02028v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02028</link>
<description rdf:parseType="Literal">&lt;p&gt;While the general machine learning (ML) community has benefited from public
datasets, tasks, and models, the progress of ML in healthcare has been hampered
by a lack of such shared assets. The success of foundation models creates new
challenges for healthcare ML by requiring access to shared pretrained models to
validate performance benefits. We help address these challenges through three
contributions. First, we publish a new dataset, EHRSHOT, which contains
deidentified structured data from the electronic health records (EHRs) of 6,739
patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR
datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients.
Second, we publish the weights of CLMBR-T-base, a 141M parameter clinical
foundation model pretrained on the structured EHR data of 2.57M patients. We
are one of the first to fully release such a model for coded EHR data; in
contrast, most prior models released for clinical data (e.g. GatorTron,
ClinicalBERT) only work with unstructured text and cannot process the rich,
structured data within an EHR. We provide an end-to-end pipeline for the
community to validate and build upon its performance. Third, we define 15
few-shot clinical prediction tasks, enabling evaluation of foundation models on
benefits such as sample efficiency and task adaptation. Our model and dataset
are available via a research data use agreement from our website:
https://ehrshot.stanford.edu. Code to reproduce our results are available at
our Github repo: https://github.com/som-shahlab/ehrshot-benchmark
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wornow_M/0/1/0/all/0/1&quot;&gt;Michael Wornow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thapa_R/0/1/0/all/0/1&quot;&gt;Rahul Thapa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinberg_E/0/1/0/all/0/1&quot;&gt;Ethan Steinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fries_J/0/1/0/all/0/1&quot;&gt;Jason A. Fries&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Nigam H. Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.04057">
<title>Bidirectional Attention as a Mixture of Continuous Word Experts. (arXiv:2307.04057v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.04057</link>
<description rdf:parseType="Literal">&lt;p&gt;Bidirectional attention $\unicode{x2013}$ composed of self-attention with
positional encodings and the masked language model (MLM) objective
$\unicode{x2013}$ has emerged as a key component of modern large language
models (LLMs). Despite its empirical success, few studies have examined its
statistical underpinnings: What statistical model is bidirectional attention
implicitly fitting? What sets it apart from its non-attention predecessors? We
explore these questions in this paper. The key observation is that fitting a
single-layer single-head bidirectional attention, upon reparameterization, is
equivalent to fitting a continuous bag of words (CBOW) model with
mixture-of-experts (MoE) weights. Further, bidirectional attention with
multiple heads and multiple layers is equivalent to stacked MoEs and a mixture
of MoEs, respectively. This statistical viewpoint reveals the distinct use of
MoE in bidirectional attention, which aligns with its practical effectiveness
in handling heterogeneous data. It also suggests an immediate extension to
categorical tabular data, if we view each word location in a sentence as a
tabular feature. Across empirical studies, we find that this extension
outperforms existing tabular extensions of transformers in out-of-distribution
(OOD) generalization. Finally, this statistical perspective of bidirectional
attention enables us to theoretically characterize when linear word analogies
are present in its word embeddings. These analyses show that bidirectional
attention can require much stronger assumptions to exhibit linear word
analogies than its non-attention predecessors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wibisono_K/0/1/0/all/0/1&quot;&gt;Kevin Christian Wibisono&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yixin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.05695">
<title>ReLoRA: High-Rank Training Through Low-Rank Updates. (arXiv:2307.05695v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.05695</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the dominance and effectiveness of scaling, resulting in large
networks with hundreds of billions of parameters, the necessity to train
overparameterized models remains poorly understood, while training costs grow
exponentially. In this paper, we explore parameter-efficient training
techniques as an approach to training large neural networks. We introduce a
novel method called ReLoRA, which utilizes low-rank updates to train high-rank
networks. We apply ReLoRA to training transformer language models with up to
1.3B parameters and demonstrate comparable performance to regular neural
network training. ReLoRA saves up to 5.5Gb of RAM per GPU and improves training
speed by 9-40% depending on the model size and hardware setup. Our findings
show the potential of parameter-efficient techniques for large-scale
pre-training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lialin_V/0/1/0/all/0/1&quot;&gt;Vladislav Lialin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shivagunde_N/0/1/0/all/0/1&quot;&gt;Namrata Shivagunde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muckatira_S/0/1/0/all/0/1&quot;&gt;Sherin Muckatira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rumshisky_A/0/1/0/all/0/1&quot;&gt;Anna Rumshisky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06483">
<title>Misclassification in Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes We Can!. (arXiv:2307.06483v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06483</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated classifiers (ACs), often built via supervised machine learning
(SML), can categorize large, statistically powerful samples of data ranging
from text to images and video, and have become widely popular measurement
devices in communication science and related fields. Despite this popularity,
even highly accurate classifiers make errors that cause misclassification bias
and misleading results in downstream analyses-unless such analyses account for
these errors. As we show in a systematic literature review of SML applications,
communication scholars largely ignore misclassification bias. In principle,
existing statistical methods can use &quot;gold standard&quot; validation data, such as
that created by human annotators, to correct misclassification bias and produce
consistent estimates. We introduce and test such methods, including a new
method we design and implement in the R package misclassificationmodels, via
Monte Carlo simulations designed to reveal each method&apos;s limitations, which we
also release. Based on our results, we recommend our new error correction
method as it is versatile and efficient. In sum, automated classifiers, even
those below common accuracy standards or making systematic misclassifications,
can be useful for measurement with careful study design and appropriate error
correction methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+TeBlunthuis_N/0/1/0/all/0/1&quot;&gt;Nathan TeBlunthuis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hase_V/0/1/0/all/0/1&quot;&gt;Valerie Hase&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1&quot;&gt;Chung-Hong Chan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09007">
<title>On the (In)Effectiveness of Large Language Models for Chinese Text Correction. (arXiv:2307.09007v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.09007</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the development and progress of Large Language Models (LLMs) have
amazed the entire Artificial Intelligence community. Benefiting from their
emergent abilities, LLMs have attracted more and more researchers to study
their capabilities and performance on various downstream Natural Language
Processing (NLP) tasks. While marveling at LLMs&apos; incredible performance on all
kinds of tasks, we notice that they also have excellent multilingual processing
capabilities, such as Chinese. To explore the Chinese processing ability of
LLMs, we focus on Chinese Text Correction, a fundamental and challenging
Chinese NLP task. Specifically, we evaluate various representative LLMs on the
Chinese Grammatical Error Correction (CGEC) and Chinese Spelling Check (CSC)
tasks, which are two main Chinese Text Correction scenarios. Additionally, we
also fine-tune LLMs for Chinese Text Correction to better observe the potential
capabilities of LLMs. From extensive analyses and comparisons with previous
state-of-the-art small models, we empirically find that the LLMs currently have
both amazing performance and unsatisfactory behavior for Chinese Text
Correction. We believe our findings will promote the landing and application of
LLMs in the Chinese NLP community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yinghui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Haojing Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shirong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yong Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yangning Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1&quot;&gt;Feng Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1&quot;&gt;Hai-Tao Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1&quot;&gt;Qingyu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.12267">
<title>Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education. (arXiv:2307.12267v5 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.12267</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent large language models (LLMs), e.g., ChatGPT, have been able to
generate human-like and fluent responses when provided with specific
instructions. While admitting the convenience brought by technological
advancement, educators also have concerns that students might leverage LLMs to
complete their writing assignments and pass them off as their original work.
Although many AI content detection studies have been conducted as a result of
such concerns, most of these prior studies modeled AI content detection as a
classification problem, assuming that a text is either entirely human-written
or entirely AI-generated. In this study, we investigated AI content detection
in a rarely explored yet realistic setting where the text to be detected is
collaboratively written by human and generative LLMs (i.e., hybrid text). We
first formalized the detection task as identifying the transition points
between human-written content and AI-generated content from a given hybrid text
(boundary detection). Then we proposed a two-step approach where we (1)
separated AI-generated content from human-written content during the encoder
training process; and (2) calculated the distances between every two adjacent
prototypes and assumed that the boundaries exist between the two adjacent
prototypes that have the furthest distance from each other. Through extensive
experiments, we observed the following main findings: (1) the proposed approach
consistently outperformed the baseline methods across different experiment
settings; (2) the encoder training process can significantly boost the
performance of the proposed approach; (3) when detecting boundaries for
single-boundary hybrid essays, the proposed approach could be enhanced by
adopting a relatively large prototype size, leading to a 22% improvement in the
In-Domain evaluation and an 18% improvement in the Out-of-Domain evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1&quot;&gt;Zijie Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sha_L/0/1/0/all/0/1&quot;&gt;Lele Sha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1&quot;&gt;Kaixun Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasevic_D/0/1/0/all/0/1&quot;&gt;Dragan Ga&amp;#x161;evi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1&quot;&gt;Guanliang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.16230">
<title>An Unforgeable Publicly Verifiable Watermark for Large Language Models. (arXiv:2307.16230v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.16230</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, text watermarking algorithms for large language models (LLMs) have
been proposed to mitigate the potential harms of text generated by LLMs,
including fake news and copyright issues. However, current watermark detection
algorithms require the secret key used in the watermark generation process,
making them susceptible to security breaches and counterfeiting during public
detection. To address this limitation, we propose an unforgeable publicly
verifiable watermark algorithm that uses two different neural networks for
watermark generation and detection, instead of using the same key at both
stages. Meanwhile, the token embedding parameters are shared between the
generation and detection networks, which makes the detection network achieve a
high accuracy very efficiently. Experiments demonstrate that our algorithm
attains high detection accuracy and computational efficiency through neural
networks with a minimized number of parameters. Subsequent analysis confirms
the high complexity involved in forging the watermark from the detection
network. Our code and data are available at
\href{https://github.com/THU-BPM/unforgeable_watermark}{https://github.com/THU-BPM/unforgeable\_watermark}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1&quot;&gt;Aiwei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1&quot;&gt;Leyi Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xuming Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shu&amp;#x27;ang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1&quot;&gt;Lijie Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1&quot;&gt;Irwin King&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02080">
<title>Causality Guided Disentanglement for Cross-Platform Hate Speech Detection. (arXiv:2308.02080v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.02080</link>
<description rdf:parseType="Literal">&lt;p&gt;Social media platforms, despite their value in promoting open discourse, are
often exploited to spread harmful content. Current deep learning and natural
language processing models used for detecting this harmful content overly rely
on domain-specific terms affecting their capabilities to adapt to generalizable
hate speech detection. This is because they tend to focus too narrowly on
particular linguistic signals or the use of certain categories of words.
Another significant challenge arises when platforms lack high-quality annotated
data for training, leading to a need for cross-platform models that can adapt
to different distribution shifts. Our research introduces a cross-platform hate
speech detection model capable of being trained on one platform&apos;s data and
generalizing to multiple unseen platforms. To achieve good generalizability
across platforms, one way is to disentangle the input representations into
invariant and platform-dependent features. We also argue that learning causal
relationships, which remain constant across diverse environments, can
significantly aid in understanding invariant representations in hate speech. By
disentangling input into platform-dependent features (useful for predicting
hate targets) and platform-independent features (used to predict the presence
of hate), we learn invariant representations resistant to distribution shifts.
These features are then used to predict hate speech across unseen platforms.
Our extensive experiments across four platforms highlight our model&apos;s enhanced
efficacy compared to existing state-of-the-art methods in detecting generalized
hate speech.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1&quot;&gt;Paras Sheth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumarage_T/0/1/0/all/0/1&quot;&gt;Tharindu Kumarage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moraffah_R/0/1/0/all/0/1&quot;&gt;Raha Moraffah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1&quot;&gt;Aman Chadha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Huan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.12050">
<title>Aligning Language Models with Offline Learning from Human Feedback. (arXiv:2308.12050v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.12050</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning from human preferences is crucial for language models (LMs) to
effectively cater to human needs and societal values. Previous research has
made notable progress by leveraging human feedback to follow instructions.
However, these approaches rely primarily on online learning techniques like
Proximal Policy Optimization (PPO), which have been proven unstable and
challenging to tune for language models. Moreover, PPO requires complex
distributed system implementation, hindering the efficiency of large-scale
distributed training. In this study, we propose an offline learning from human
feedback framework to align LMs without interacting with environments.
Specifically, we explore filtering alignment (FA), reward-weighted regression
(RWR), and conditional alignment (CA) to align language models to human
preferences. By employing a loss function similar to supervised fine-tuning,
our methods ensure more stable model training than PPO with a simple machine
learning system~(MLSys) and much fewer (around 9\%) computing resources.
Experimental results demonstrate that conditional alignment outperforms other
offline alignment methods and is comparable to PPO.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jian Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1&quot;&gt;Li Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;June Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1&quot;&gt;Chandler Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.12060">
<title>FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering. (arXiv:2308.12060v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.12060</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge base question answering (KBQA) is a critical yet challenging task
due to the vast number of entities within knowledge bases and the diversity of
natural language questions posed by users. Unfortunately, the performance of
most KBQA models tends to decline significantly in real-world scenarios where
high-quality annotated data is insufficient. To mitigate the burden associated
with manual annotation, we introduce FlexKBQA by utilizing Large Language
Models (LLMs) as program translators for addressing the challenges inherent in
the few-shot KBQA task. Specifically, FlexKBQA leverages automated algorithms
to sample diverse programs, such as SPARQL queries, from the knowledge base,
which are subsequently converted into natural language questions via LLMs. This
synthetic dataset facilitates training a specialized lightweight model for the
KB. Additionally, to reduce the barriers of distribution shift between
synthetic data and real user questions, FlexKBQA introduces an executionguided
self-training method to iterative leverage unlabeled user questions.
Furthermore, we explore harnessing the inherent reasoning capability of LLMs to
enhance the entire framework. Consequently, FlexKBQA delivers substantial
flexibility, encompassing data annotation, deployment, and being domain
agnostic. Through extensive experiments on GrailQA, WebQSP, and KQA Pro, we
observe that under the few-shot even the more challenging zero-shot scenarios,
FlexKBQA achieves impressive results with a few annotations, surpassing all
previous baselines and even approaching the performance of supervised models,
achieving a remarkable 93% performance relative to the fully-supervised models.
We posit that FlexKBQA represents a significant advancement towards exploring
better integration of large and lightweight models. The code is open-sourced.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1&quot;&gt;Sunqi Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1&quot;&gt;Yu Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiuxing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1&quot;&gt;Zhichao Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1&quot;&gt;Bowen Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1&quot;&gt;Ning Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianyong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.05961">
<title>Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms. (arXiv:2309.05961v3 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2309.05961</link>
<description rdf:parseType="Literal">&lt;p&gt;Community Question Answering (CQA) platforms steadily gain popularity as they
provide users with fast responses to their queries. The swiftness of these
responses is contingent on a mixture of query-specific and user-related
elements. This paper scrutinizes these contributing factors within the context
of six highly popular CQA platforms, identified through their standout
answering speed. Our investigation reveals a correlation between the time taken
to yield the first response to a question and several variables: the metadata,
the formulation of the questions, and the level of interaction among users.
Additionally, by employing conventional machine learning models to analyze
these metadata and patterns of user interaction, we endeavor to predict which
queries will receive their initial responses promptly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazra_R/0/1/0/all/0/1&quot;&gt;Rima Hazra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1&quot;&gt;Agnik Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1&quot;&gt;Somnath Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1&quot;&gt;Animesh Mukherjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.08836">
<title>Bias and Fairness in Chatbots: An Overview. (arXiv:2309.08836v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.08836</link>
<description rdf:parseType="Literal">&lt;p&gt;Chatbots have been studied for more than half a century. With the rapid
development of natural language processing (NLP) technologies in recent years,
chatbots using large language models (LLMs) have received much attention
nowadays. Compared with traditional ones, modern chatbots are more powerful and
have been used in real-world applications. There are however, bias and fairness
concerns in modern chatbot design. Due to the huge amounts of training data,
extremely large model sizes, and lack of interpretability, bias mitigation and
fairness preservation of modern chatbots are challenging. Thus, a comprehensive
overview on bias and fairness in chatbot systems is given in this paper. The
history of chatbots and their categories are first reviewed. Then, bias sources
and potential harms in applications are analyzed. Considerations in designing
fair and unbiased chatbot systems are examined. Finally, future research
directions are discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1&quot;&gt;Jintang Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yun-Cheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1&quot;&gt;Chengwei Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaofeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1&quot;&gt;Jonghye Woo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1&quot;&gt;C.-C. Jay Kuo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12056">
<title>BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision. (arXiv:2309.12056v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2309.12056</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents BELT, a novel model and learning framework for the
pivotal topic of brain-to-language translation research. The translation from
noninvasive brain signals into readable natural language has the potential to
promote the application scenario as well as the development of brain-computer
interfaces (BCI) as a whole. The critical problem in brain signal decoding or
brain-to-language translation is the acquisition of semantically appropriate
and discriminative EEG representation from a dataset of limited scale and
quality. The proposed BELT method is a generic and efficient framework that
bootstraps EEG representation learning using off-the-shelf large-scale
pretrained language models (LMs). With a large LM&apos;s capacity for understanding
semantic information and zero-shot generalization, BELT utilizes large LMs
trained on Internet-scale datasets to bring significant improvements to the
understanding of EEG signals.
&lt;/p&gt;
&lt;p&gt;In particular, the BELT model is composed of a deep conformer encoder and a
vector quantization encoder. Semantical EEG representation is achieved by a
contrastive learning step that provides natural language supervision. We
achieve state-of-the-art results on two featuring brain decoding tasks
including the brain-to-language translation and zero-shot sentiment
classification. Specifically, our model surpasses the baseline model on both
tasks by 5.45% and over 10% and archives a 42.31% BLEU-1 score and 67.32%
precision on the main evaluation metrics for translation and zero-shot
sentiment classification respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jinzhao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1&quot;&gt;Yiqun Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yu-Cheng Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Kai Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1&quot;&gt;Chin-Teng Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.13230">
<title>Unify word-level and span-level tasks: NJUNLP&apos;s Participation for the WMT2023 Quality Estimation Shared Task. (arXiv:2309.13230v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.13230</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the submissions of the NJUNLP team to the WMT 2023 Quality
Estimation (QE) shared task. Our team submitted predictions for the
English-German language pair on all two sub-tasks: (i) sentence- and word-level
quality prediction; and (ii) fine-grained error span detection. This year, we
further explore pseudo data methods for QE based on NJUQE framework
(https://github.com/NJUNLP/njuqe). We generate pseudo MQM data using parallel
data from the WMT translation task. We pre-train the XLMR large model on pseudo
QE data, then fine-tune it on real QE data. At both stages, we jointly learn
sentence-level scores and word-level tags. Empirically, we conduct experiments
to find the key hyper-parameters that improve the performance. Technically, we
propose a simple method that covert the word-level outputs to fine-grained
error span results. Overall, our models achieved the best results in
English-German for both word-level and fine-grained error span detection
sub-tasks by a considerable margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1&quot;&gt;Xiang Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1&quot;&gt;Zhejian Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1&quot;&gt;Shimin Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiajun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shujian Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00752">
<title>TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks. (arXiv:2310.00752v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00752</link>
<description rdf:parseType="Literal">&lt;p&gt;We present TIGERScore, a \textbf{T}rained metric that follows
\textbf{I}nstruction \textbf{G}uidance to perform \textbf{E}xplainable, and
\textbf{R}eference-free evaluation over a wide spectrum of text generation
tasks. Different from other automatic evaluation methods that only provide
arcane scores, TIGERScore is guided by natural language instruction to provide
error analysis to pinpoint the mistakes in the generated text. Our metric is
based on LLaMA-2, trained on our meticulously curated instruction-tuning
dataset MetricInstruct which covers 6 text generation tasks and 23 text
generation datasets. The dataset consists of 42K quadruple in the form of
(instruction, input, system output $\rightarrow$ error analysis). We collected
the `system outputs&apos; through from a large variety of models to cover different
types of errors. To quantitatively assess our metric, we evaluate its
correlation with human ratings on 5 held-in datasets, 2 held-out datasets and
show that TIGERScore can achieve the open-source SoTA correlation with human
ratings across these datasets and almost approaches GPT-4 evaluator. As a
reference-free metric, its correlation can even surpass the best existing
reference-based metrics. To further qualitatively assess the rationale
generated by our metric, we conduct human evaluation on the generated
explanations and found that the explanations are 70.8\% accurate. Through these
experimental results, we believe TIGERScore demonstrates the possibility of
building universal explainable metrics to evaluate any text generation task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1&quot;&gt;Dongfu Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yishan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Ge Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wenhao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Bill Yuchen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wenhu Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03668">
<title>GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction. (arXiv:2310.03668v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03668</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) combined with instruction tuning have made
significant progress when generalizing to unseen tasks. However, they have been
less successful in Information Extraction (IE), lagging behind task-specific
models. Typically, IE tasks are characterized by complex annotation guidelines
which describe the task and give examples to humans. Previous attempts to
leverage such information have failed, even with the largest models, as they
are not able to follow the guidelines out-of-the-box. In this paper we propose
GoLLIE (Guideline-following Large Language Model for IE), a model able to
improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to
comply with annotation guidelines. Comprehensive evaluation empirically
demonstrates that GoLLIE is able to generalize to and follow unseen guidelines,
outperforming previous attempts at zero-shot information extraction. The
ablation study shows that detailed guidelines is key for good results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sainz_O/0/1/0/all/0/1&quot;&gt;Oscar Sainz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Ferrero_I/0/1/0/all/0/1&quot;&gt;Iker Garc&amp;#xed;a-Ferrero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agerri_R/0/1/0/all/0/1&quot;&gt;Rodrigo Agerri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacalle_O/0/1/0/all/0/1&quot;&gt;Oier Lopez de Lacalle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1&quot;&gt;German Rigau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1&quot;&gt;Eneko Agirre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.10981">
<title>Instructive Dialogue Summarization with Query Aggregations. (arXiv:2310.10981v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.10981</link>
<description rdf:parseType="Literal">&lt;p&gt;Conventional dialogue summarization methods directly generate summaries and
do not consider user&apos;s specific interests. This poses challenges in cases where
the users are more focused on particular topics or aspects. With the
advancement of instruction-finetuned language models, we introduce
instruction-tuning to dialogues to expand the capability set of dialogue
summarization models. To overcome the scarcity of instructive dialogue
summarization data, we propose a three-step approach to synthesize high-quality
query-based summarization triples. This process involves summary-anchored query
generation, query filtering, and query-based summary generation. By training a
unified model called InstructDS (Instructive Dialogue Summarization) on three
summarization datasets with multi-purpose instructive triples, we expand the
capability of dialogue summarization models. We evaluate our method on four
datasets, including dialogue summarization and dialogue reading comprehension.
Experimental results show that our approach outperforms the state-of-the-art
models and even models with larger sizes. Additionally, our model exhibits
higher generalizability and faithfulness, as confirmed by human subjective
evaluations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhengyuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1&quot;&gt;Nancy F. Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13191">
<title>Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models. (arXiv:2310.13191v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13191</link>
<description rdf:parseType="Literal">&lt;p&gt;The pruning objective has recently extended beyond accuracy and sparsity to
robustness in language models. Despite this, existing methods struggle to
enhance robustness against adversarial attacks when continually increasing
model sparsity and require a retraining process. As humans step into the era of
large language models, these issues become increasingly prominent. This paper
proposes that the robustness of language models is proportional to the extent
of pre-trained knowledge they encompass. Accordingly, we introduce a
post-training pruning strategy designed to faithfully replicate the embedding
space and feature space of dense language models, aiming to conserve more
pre-trained knowledge during the pruning process. In this setup, each layer&apos;s
reconstruction error not only originates from itself but also includes
cumulative error from preceding layers, followed by an adaptive rectification.
Compared to other state-of-art baselines, our approach demonstrates a superior
balance between accuracy, sparsity, robustness, and pruning cost with BERT on
datasets SST2, IMDB, and AGNews, marking a significant stride towards robust
pruning in language models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1&quot;&gt;Qi Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1&quot;&gt;Wei Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1&quot;&gt;Dongkuan Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.16676">
<title>SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning Framework for Emotion Recognition in Conversations. (arXiv:2310.16676v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.16676</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotion recognition in conversations (ERC) is a rapidly evolving task within
the natural language processing community, which aims to detect the emotions
expressed by speakers during a conversation. Recently, a growing number of ERC
methods have focused on leveraging supervised contrastive learning (SCL) to
enhance the robustness and generalizability of learned features. However,
current SCL-based approaches in ERC are impeded by the constraint of large
batch sizes and the lack of compatibility with most existing ERC models. To
address these challenges, we propose an efficient and model-agnostic SCL
framework named Supervised Sample-Label Contrastive Learning with Soft-HGR
Maximal Correlation (SSLCL), which eliminates the need for a large batch size
and can be seamlessly integrated with existing ERC models without introducing
any model-specific assumptions. Specifically, we introduce a novel perspective
on utilizing label representations by projecting discrete labels into dense
embeddings through a shallow multilayer perceptron, and formulate the training
objective to maximize the similarity between sample features and their
corresponding ground-truth label embeddings, while minimizing the similarity
between sample features and label embeddings of disparate classes. Moreover, we
innovatively adopt the Soft-HGR maximal correlation as a measure of similarity
between sample features and label embeddings, leading to significant
performance improvements over conventional similarity measures. Additionally,
multimodal cues of utterances are effectively leveraged by SSLCL as data
augmentations to boost model performances. Extensive experiments on two ERC
benchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and
superiority of our proposed SSLCL framework compared to existing
state-of-the-art SCL methods. Our code is available at
\url{https://github.com/TaoShi1998/SSLCL}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1&quot;&gt;Tao Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1&quot;&gt;Xiao Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yaoyuan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1&quot;&gt;Xinyi Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shao-Lun Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.17793">
<title>&quot;You Are An Expert Linguistic Annotator&quot;: Limits of LLMs as Analyzers of Abstract Meaning Representation. (arXiv:2310.17793v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.17793</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) show amazing proficiency and fluency in the use
of language. Does this mean that they have also acquired insightful linguistic
knowledge about the language, to an extent that they can serve as an &quot;expert
linguistic annotator&quot;? In this paper, we examine the successes and limitations
of the GPT-3, ChatGPT, and GPT-4 models in analysis of sentence meaning
structure, focusing on the Abstract Meaning Representation (AMR; Banarescu et
al. 2013) parsing formalism, which provides rich graphical representations of
sentence meaning structure while abstracting away from surface forms. We
compare models&apos; analysis of this semantic structure across two settings: 1)
direct production of AMR parses based on zero- and few-shot prompts, and 2)
indirect partial reconstruction of AMR via metalinguistic natural language
queries (e.g., &quot;Identify the primary event of this sentence, and the predicate
corresponding to that event.&quot;). Across these settings, we find that models can
reliably reproduce the basic format of AMR, and can often capture core event,
argument, and modifier structure -- however, model outputs are prone to
frequent and major errors, and holistic analysis of parse acceptability shows
that even with few-shot demonstrations, models have virtually 0% success in
producing fully accurate parses. Eliciting natural language responses produces
similar patterns of errors. Overall, our findings indicate that these models
out-of-the-box can capture aspects of semantic structure, but there remain key
limitations in their ability to support fully accurate semantic analyses or
parses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ettinger_A/0/1/0/all/0/1&quot;&gt;Allyson Ettinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1&quot;&gt;Jena D. Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1&quot;&gt;Valentina Pyatkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1&quot;&gt;Chandra Bhagavatula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1&quot;&gt;Yejin Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00286">
<title>JADE: A Linguistics-based Safety Evaluation Platform for Large Language Models. (arXiv:2311.00286v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.00286</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present JADE, a targeted linguistic fuzzing platform which
strengthens the linguistic complexity of seed questions to simultaneously and
consistently break a wide range of widely-used LLMs categorized in three
groups: eight open-sourced Chinese, six commercial Chinese and four commercial
English LLMs. JADE generates three safety benchmarks for the three groups of
LLMs, which contain unsafe questions that are highly threatening: the questions
simultaneously trigger harmful generation of multiple LLMs, with an average
unsafe generation ratio of $70\%$ (please see the table below), while are still
natural questions, fluent and preserving the core unsafe semantics. We release
the benchmark demos generated for commercial English LLMs and open-sourced
English LLMs in the following link: https://github.com/whitzard-ai/jade-db. For
readers who are interested in evaluating on more questions generated by JADE,
please contact us.
&lt;/p&gt;
&lt;p&gt;JADE is based on Noam Chomsky&apos;s seminal theory of transformational-generative
grammar. Given a seed question with unsafe intention, JADE invokes a sequence
of generative and transformational rules to increment the complexity of the
syntactic structure of the original question, until the safety guardrail is
broken. Our key insight is: Due to the complexity of human language, most of
the current best LLMs can hardly recognize the invariant evil from the infinite
number of different syntactic structures which form an unbound example space
that can never be fully covered. Technically, the generative/transformative
rules are constructed by native speakers of the languages, and, once developed,
can be used to automatically grow and transform the parse tree of a given
question, until the guardrail is broken. For more evaluation results and demo,
please check our website: https://whitzard-ai.github.io/jade.html.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1&quot;&gt;Xudong Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Min Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01766">
<title>Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation. (arXiv:2311.01766v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.01766</link>
<description rdf:parseType="Literal">&lt;p&gt;Mis- and disinformation online have become a major societal problem as major
sources of online harms of different kinds. One common form of mis- and
disinformation is out-of-context (OOC) information, where different pieces of
information are falsely associated, e.g., a real image combined with a false
textual caption or a misleading textual description. Although some past studies
have attempted to defend against OOC mis- and disinformation through external
evidence, they tend to disregard the role of different pieces of evidence with
different stances. Motivated by the intuition that the stance of evidence
represents a bias towards different detection results, we propose a stance
extraction network (SEN) that can extract the stances of different pieces of
multi-modal evidence in a unified framework. Moreover, we introduce a
support-refutation score calculated based on the co-occurrence relations of
named entities into the textual SEN. Extensive experiments on a public
large-scale dataset demonstrated that our proposed method outperformed the
state-of-the-art baselines, with the best model achieving a performance gain of
3.2% in accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xin Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jie Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1&quot;&gt;Weidong Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zheng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shujun Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04916">
<title>Explainable Identification of Hate Speech towards Islam using Graph Neural Networks. (arXiv:2311.04916v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.04916</link>
<description rdf:parseType="Literal">&lt;p&gt;Islamophobic language is a prevalent challenge on online social interaction
platforms. Identifying and eliminating such hatred is a crucial step towards a
future of harmony and peace. This study presents a novel paradigm for
identifying and explaining hate speech towards Islam using graph neural
networks. Utilizing the intrinsic ability of graph neural networks to find,
extract, and use relationships across disparate data points, our model
consistently achieves outstanding performance while offering explanations for
the underlying correlations and causation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wasi_A/0/1/0/all/0/1&quot;&gt;Azmine Toushik Wasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05112">
<title>A Survey of Large Language Models in Medicine: Principles, Applications, and Challenges. (arXiv:2311.05112v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.05112</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs), such as ChatGPT, have received substantial
attention due to their impressive human language understanding and generation
capabilities. Therefore, the application of LLMs in medicine to assist
physicians and patient care emerges as a promising research direction in both
artificial intelligence and clinical medicine. To reflect this trend, this
survey provides a comprehensive overview of the principles, applications, and
challenges faced by LLMs in medicine. Specifically, we aim to address the
following questions: 1) How can medical LLMs be built? 2) What are the
downstream performances of medical LLMs? 3) How can medical LLMs be utilized in
real-world clinical practice? 4) What challenges arise from the use of medical
LLMs? and 5) How can we better construct and utilize medical LLMs? As a result,
this survey aims to provide insights into the opportunities and challenges of
LLMs in medicine and serve as a valuable resource for constructing practical
and effective medical LLMs. A regularly updated list of practical guides on
medical LLMs can be found at
https://github.com/AI-in-Health/MedLLMsPracticalGuide.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hongjian Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Fenglin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1&quot;&gt;Boyang Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1&quot;&gt;Xinyu Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jinfa Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jinge Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yiru Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Sam S. Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1&quot;&gt;Peilin Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Junling Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1&quot;&gt;Yining Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1&quot;&gt;Chengfeng Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yefeng Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clifton_L/0/1/0/all/0/1&quot;&gt;Lei Clifton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1&quot;&gt;Jiebo Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1&quot;&gt;David A. Clifton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.15626">
<title>The WebCrow French Crossword Solver. (arXiv:2311.15626v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.15626</link>
<description rdf:parseType="Literal">&lt;p&gt;Crossword puzzles are one of the most popular word games, played in different
languages all across the world, where riddle style can vary significantly from
one country to another. Automated crossword resolution is challenging, and
typical solvers rely on large databases of previously solved crosswords. In
this work, we extend WebCrow 2.0, an automatic crossword solver, to French,
making it the first program for crossword solving in the French language. To
cope with the lack of a large repository of clue-answer crossword data, WebCrow
2.0 exploits multiple modules, called experts, that retrieve candidate answers
from heterogeneous resources, such as the web, knowledge graphs, and linguistic
rules. We compared WebCrow&apos;s performance against humans in two different
challenges. Despite the limited amount of past crosswords, French WebCrow was
competitive, actually outperforming humans in terms of speed and accuracy, thus
proving its capabilities to generalize to new languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angelini_G/0/1/0/all/0/1&quot;&gt;Giovanni Angelini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ernandes_M/0/1/0/all/0/1&quot;&gt;Marco Ernandes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+laquinta_T/0/1/0/all/0/1&quot;&gt;Tommaso laquinta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stehle_C/0/1/0/all/0/1&quot;&gt;Caroline Stehl&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simoes_F/0/1/0/all/0/1&quot;&gt;Fanny Sim&amp;#xf5;es&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeinalipour_K/0/1/0/all/0/1&quot;&gt;Kamyar Zeinalipour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zugarini_A/0/1/0/all/0/1&quot;&gt;Andrea Zugarini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1&quot;&gt;Marco Gori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.16588">
<title>Ascle: A Python Natural Language Processing Toolkit for Medical Text Generation. (arXiv:2311.16588v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.16588</link>
<description rdf:parseType="Literal">&lt;p&gt;This study introduces Ascle, a pioneering natural language processing (NLP)
toolkit designed for medical text generation. Ascle is tailored for biomedical
researchers and healthcare professionals with an easy-to-use, all-in-one
solution that requires minimal programming expertise. For the first time, Ascle
evaluates and provides interfaces for the latest pre-trained language models,
encompassing four advanced and challenging generative functions:
question-answering, text summarization, text simplification, and machine
translation. In addition, Ascle integrates 12 essential NLP functions, along
with query and search capabilities for clinical databases. The toolkit, its
models, and associated data are publicly available via
https://github.com/Yale-LILY/MedGen.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Rui Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1&quot;&gt;Qingcheng Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_K/0/1/0/all/0/1&quot;&gt;Keen You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1&quot;&gt;Yujie Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lucas Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Chia-Chun Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosand_B/0/1/0/all/0/1&quot;&gt;Benjamin Rosand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldwasser_J/0/1/0/all/0/1&quot;&gt;Jeremy Goldwasser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dave_A/0/1/0/all/0/1&quot;&gt;Amisha D Dave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keenan_T/0/1/0/all/0/1&quot;&gt;Tiarnan D.L. Keenan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chew_E/0/1/0/all/0/1&quot;&gt;Emily Y Chew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1&quot;&gt;Dragomir Radev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hua Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Qingyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1&quot;&gt;Irene Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.18054">
<title>I Know You Did Not Write That! A Sampling Based Watermarking Method for Identifying Machine Generated Text. (arXiv:2311.18054v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.18054</link>
<description rdf:parseType="Literal">&lt;p&gt;Potential harms of Large Language Models such as mass misinformation and
plagiarism can be partially mitigated if there exists a reliable way to detect
machine generated text. In this paper, we propose a new watermarking method to
detect machine-generated texts. Our method embeds a unique pattern within the
generated text, ensuring that while the content remains coherent and natural to
human readers, it carries distinct markers that can be identified
algorithmically. Specifically, we intervene with the token sampling process in
a way which enables us to trace back our token choices during the detection
phase. We show how watermarking affects textual quality and compare our
proposed method with a state-of-the-art watermarking method in terms of
robustness and detectability. Through extensive experiments, we demonstrate the
effectiveness of our watermarking scheme in distinguishing between watermarked
and non-watermarked text, achieving high detection rates while maintaining
textual quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keles_K/0/1/0/all/0/1&quot;&gt;Kaan Efe Kele&amp;#x15f;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurbuz_O/0/1/0/all/0/1&quot;&gt;&amp;#xd6;mer Kaan G&amp;#xfc;rb&amp;#xfc;z&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutlu_M/0/1/0/all/0/1&quot;&gt;Mucahid Kutlu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.18760">
<title>TaskBench: Benchmarking Large Language Models for Task Automation. (arXiv:2311.18760v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.18760</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the incredible progress of large language models (LLMs) has ignited
the spark of task automation, which decomposes the complex tasks described by
user instructions into sub-tasks, and invokes external tools to execute them,
and plays a central role in autonomous agents. However, there lacks a
systematic and standardized benchmark to foster the development of LLMs in task
automation. To this end, we introduce TaskBench to evaluate the capability of
LLMs in task automation. Specifically, task automation can be formulated into
three critical stages: task decomposition, tool invocation, and parameter
prediction to fulfill user intent. This complexity makes data collection and
evaluation more challenging compared to common NLP tasks. To generate
high-quality evaluation datasets, we introduce the concept of Tool Graph to
represent the decomposed tasks in user intent, and adopt a back-instruct method
to simulate user instruction and annotations. Furthermore, we propose TaskEval
to evaluate the capability of LLMs from different aspects, including task
decomposition, tool invocation, and parameter prediction. Experimental results
demonstrate that TaskBench can effectively reflects the capability of LLMs in
task automation. Benefiting from the mixture of automated data construction and
human verification, TaskBench achieves a high consistency compared to the human
evaluation, which can be utilized as a comprehensive and faithful benchmark for
LLM-based autonomous agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yongliang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1&quot;&gt;Kaitao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1&quot;&gt;Xu Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wenqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1&quot;&gt;Kan Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1&quot;&gt;Siyu Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1&quot;&gt;Weiming Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Dongsheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1&quot;&gt;Yueting Zhuang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.01339">
<title>ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational Applications. (arXiv:2312.01339v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.01339</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents the first Arabic crossword puzzle generator driven by
advanced AI technology. Leveraging cutting-edge large language models including
GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system
generates distinctive and challenging clues. Based on a dataset comprising over
50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot
learning strategies, and rigorous quality-checking protocols to enforce the
generation of high-quality clue-answer pairs. Importantly, educational
crosswords contribute to enhancing memory, expanding vocabulary, and promoting
problem-solving skills, thereby augmenting the learning experience through a
fun and engaging approach, reshaping the landscape of traditional learning
methods. The overall system can be exploited as a powerful educational tool
that amalgamates AI and innovative learning techniques, heralding a
transformative era for Arabic crossword puzzles and the intersection of
technology and education.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeinalipour_K/0/1/0/all/0/1&quot;&gt;Kamyar Zeinalipour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_M/0/1/0/all/0/1&quot;&gt;Mohamed Zaky Saad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maggini_M/0/1/0/all/0/1&quot;&gt;Marco Maggini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1&quot;&gt;Marco Gori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.01648">
<title>Characterizing Large Language Model Geometry Solves Toxicity Detection and Generation. (arXiv:2312.01648v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2312.01648</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models~(LLMs) drive current AI breakthroughs despite very
little being known about their internal representations, e.g., how to extract a
few informative features to solve various downstream tasks. To provide a
practical and principled answer, we propose to characterize LLMs from a
geometric perspective. We obtain in closed form (i) the intrinsic dimension in
which the Multi-Head Attention embeddings are constrained to exist and (ii) the
partition and per-region affine mappings of the per-layer feedforward networks.
Our results are informative, do not rely on approximations, and are actionable.
First, we show that, motivated by our geometric interpretation, we can bypass
Llama$2$&apos;s RLHF by controlling its embedding&apos;s intrinsic dimension through
informed prompt manipulation. Second, we derive $7$ interpretable spline
features that can be extracted from any (pre-trained) LLM layer, providing a
rich abstract representation of their inputs. Those features alone ($224$ for
Mistral-7B/Llama$2$-7B and $560$ for Llama$2$-70B) are sufficient to help solve
toxicity detection, infer the domain of the prompt, and even tackle the Jigsaw
challenge, which aims at characterizing the type of toxicity of various
prompts. Our results demonstrate how, even in large-scale regimes, exact
theoretical results can answer practical questions in language models. Code:
\url{https://github.com/RandallBalestriero/SplineLLM}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1&quot;&gt;Randall Balestriero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cosentino_R/0/1/0/all/0/1&quot;&gt;Romain Cosentino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shekkizhar_S/0/1/0/all/0/1&quot;&gt;Sarath Shekkizhar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.02406">
<title>Efficient Online Data Mixing For Language Model Pre-Training. (arXiv:2312.02406v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.02406</link>
<description rdf:parseType="Literal">&lt;p&gt;The data used to pretrain large language models has a decisive impact on a
model&apos;s downstream performance, which has led to a large body of work on data
selection methods that aim to automatically determine the most suitable data to
use for pretraining. Existing data selection methods suffer from slow and
computationally expensive processes, a problem amplified by the increasing size
of models and of pretraining datasets. Data mixing, on the other hand, reduces
the complexity of data selection by grouping data points together and
determining sampling probabilities across entire groups. However, data mixing
proportions are typically fixed before training and therefore cannot adapt to
changing training dynamics. To address these limitations, we develop an
efficient algorithm for Online Data Mixing (ODM) that combines elements from
both data selection and data mixing. Based on multi-armed bandit algorithms,
our online approach optimizes the data mixing proportions during training.
Remarkably, our method trains a model that reaches the final perplexity of the
next best method with 19\% fewer training iterations, and improves performance
on the 5-shot MMLU benchmark by 1.9% relative accuracy, while adding negligible
wall-clock time during pretraining.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1&quot;&gt;Alon Albalak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1&quot;&gt;Liangming Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1&quot;&gt;Colin Raffel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;William Yang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.03549">
<title>Holmes: Towards Distributed Training Across Clusters with Heterogeneous NIC Environment. (arXiv:2312.03549v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.03549</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) such as GPT-3, OPT, and LLaMA have demonstrated
remarkable accuracy in a wide range of tasks. However, training these models
can incur significant expenses, often requiring tens of thousands of GPUs for
months of continuous operation. Typically, this training is carried out in
specialized GPU clusters equipped with homogeneous high-speed Remote Direct
Memory Access (RDMA) network interface cards (NICs). The acquisition and
maintenance of such dedicated clusters is challenging. Current LLM training
frameworks, like Megatron-LM and Megatron-DeepSpeed, focus primarily on
optimizing training within homogeneous cluster settings. In this paper, we
introduce Holmes, a training framework for LLMs that employs thoughtfully
crafted data and model parallelism strategies over the heterogeneous NIC
environment. Our primary technical contribution lies in a novel scheduling
method that intelligently allocates distinct computational tasklets in LLM
training to specific groups of GPU devices based on the characteristics of
their connected NICs. Furthermore, our proposed framework, utilizing pipeline
parallel techniques, demonstrates scalability to multiple GPU clusters, even in
scenarios without high-speed interconnects between nodes in distinct clusters.
We conducted comprehensive experiments that involved various scenarios in the
heterogeneous NIC environment. In most cases, our framework achieves
performance levels close to those achievable with homogeneous RDMA-capable
networks (InfiniBand or RoCE), significantly exceeding training efficiency
within the pure Ethernet environment. Additionally, we verified that our
framework outperforms other mainstream LLM frameworks under heterogeneous NIC
environment in terms of training efficiency and can be seamlessly integrated
with them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Fei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1&quot;&gt;Shuang Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_N/0/1/0/all/0/1&quot;&gt;Ning Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fangyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1&quot;&gt;Ke Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1&quot;&gt;Jiezhong Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_A/0/1/0/all/0/1&quot;&gt;Aimin Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.03730">
<title>FakeWatch ElectionShield: A Benchmarking Framework to Detect Fake News for Credible US Elections. (arXiv:2312.03730v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.03730</link>
<description rdf:parseType="Literal">&lt;p&gt;In today&apos;s technologically driven world, the spread of fake news,
particularly during crucial events such as elections, presents an increasing
challenge to the integrity of information. To address this challenge, we
introduce FakeWatch ElectionShield, an innovative framework carefully designed
to detect fake news. We have created a novel dataset of North American
election-related news articles through a blend of advanced language models
(LMs) and thorough human verification, for precision and relevance. We propose
a model hub of LMs for identifying fake news. Our goal is to provide the
research community with adaptable and accurate classification models in
recognizing the dynamic nature of misinformation. Extensive evaluation of fake
news classifiers on our dataset and a benchmark dataset shows our that while
state-of-the-art LMs slightly outperform the traditional ML models, classical
models are still competitive with their balance of accuracy, explainability,
and computational efficiency. This research sets the foundation for future
studies to address misinformation related to elections.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1&quot;&gt;Tahniat Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1&quot;&gt;Mizanur Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatrath_V/0/1/0/all/0/1&quot;&gt;Veronica Chatrath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bamgbose_O/0/1/0/all/0/1&quot;&gt;Oluwanifemi Bamgbose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1&quot;&gt;Shaina Raza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.03815">
<title>LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem. (arXiv:2312.03815v2 [cs.OS] UPDATED)</title>
<link>http://arxiv.org/abs/2312.03815</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper envisions a revolutionary AIOS-Agent ecosystem, where Large
Language Model (LLM) serves as the (Artificial) Intelligent Operating System
(IOS, or AIOS)--an operating system &quot;with soul&quot;. Upon this foundation, a
diverse range of LLM-based AI Agent Applications (Agents, or AAPs) are
developed, enriching the AIOS-Agent ecosystem and signaling a paradigm shift
from the traditional OS-APP ecosystem. We envision that LLM&apos;s impact will not
be limited to the AI application level, instead, it will in turn revolutionize
the design and implementation of computer system, architecture, software, and
programming language, featured by several main concepts: LLM as OS
(system-level), Agents as Applications (application-level), Natural Language as
Programming Interface (user-level), and Tools as Devices/Libraries
(hardware/middleware-level). We begin by introducing the architecture of
traditional OS. Then we formalize a conceptual framework for AIOS through &quot;LLM
as OS (LLMOS)&quot;, drawing analogies between AIOS and traditional OS: LLM is
likened to OS kernel, context window to memory, external storage to file
system, hardware tools to peripheral devices, software tools to programming
libraries, and user prompts to user commands. Subsequently, we introduce the
new AIOS-Agent Ecosystem, where users can easily program Agent Applications
(AAPs) using natural language, democratizing the development of software, which
is different from the traditional OS-APP ecosystem. Following this, we explore
the diverse scope of Agent Applications. We delve into both single-agent and
multi-agent systems, as well as human-agent interaction. Lastly, drawing on the
insights from traditional OS-APP ecosystem, we propose a roadmap for the
evolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the
future research and development, suggesting systematic progresses of AIOS and
its Agent applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1&quot;&gt;Yingqiang Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1&quot;&gt;Yujie Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1&quot;&gt;Wenyue Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shuyuan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1&quot;&gt;Juntao Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yongfeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04021">
<title>A Study on the Calibration of In-context Learning. (arXiv:2312.04021v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.04021</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern auto-regressive language models are trained to minimize log loss on
broad data by predicting the next token so they are expected to get calibrated
answers in next-token prediction tasks. We study this for in-context learning
(ICL), a widely used way to adapt frozen large language models (LLMs) via
crafting prompts, and investigate the trade-offs between performance and
calibration on a wide range of natural language understanding and reasoning
tasks. We conduct extensive experiments to show that such trade-offs may get
worse as we increase model size, incorporate more ICL examples, and fine-tune
models using instruction, dialog, or reinforcement learning from human feedback
(RLHF) on carefully curated datasets. Furthermore, we find that common
recalibration techniques that are widely effective such as temperature scaling
provide limited gains in calibration errors, suggesting that new methods may be
required for settings where models are expected to be reliable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hanlin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yi-Fan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1&quot;&gt;Dhruv Madeka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1&quot;&gt;Dean Foster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1&quot;&gt;Hima Lakkaraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.09304">
<title>Interpretability in Activation Space Analysis of Transformers: A Focused Survey. (arXiv:2302.09304v1 [cs.CL] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2302.09304</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of natural language processing has reached breakthroughs with the
advent of transformers. They have remained state-of-the-art since then, and
there also has been much research in analyzing, interpreting, and evaluating
the attention layers and the underlying embedding space. In addition to the
self-attention layers, the feed-forward layers in the transformer are a
prominent architectural component. From extensive research, we observe that its
role is under-explored. We focus on the latent space, known as the Activation
Space, that consists of the neuron activations from these feed-forward layers.
In this survey paper, we review interpretability methods that examine the
learnings that occurred in this activation space. Since there exists only
limited research in this direction, we conduct a detailed examination of each
work and point out potential future directions of research. We hope our work
provides a step towards strengthening activation space analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijayakumar_S/0/1/0/all/0/1&quot;&gt;Soniya Vijayakumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.09936">
<title>BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions. (arXiv:2308.09936v2 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2308.09936</link>
<description rdf:parseType="Literal">&lt;p&gt;Vision Language Models (VLMs), which extend Large Language Models (LLM) by
incorporating visual understanding capability, have demonstrated significant
advancements in addressing open-ended visual question-answering (VQA) tasks.
However, these models cannot accurately interpret images infused with text, a
common occurrence in real-world scenarios. Standard procedures for extracting
information from images often involve learning a fixed set of query embeddings.
These embeddings are designed to encapsulate image contexts and are later used
as soft prompt inputs in LLMs. Yet, this process is limited to the token count,
potentially curtailing the recognition of scenes with text-rich context. To
improve upon them, the present study introduces BLIVA: an augmented version of
InstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings
from InstructBLIP and also directly projects encoded patch embeddings into the
LLM, a technique inspired by LLaVA. This approach assists the model to capture
intricate details potentially missed during the query decoding process.
Empirical evidence demonstrates that our model, BLIVA, significantly enhances
performance in processing text-rich VQA benchmarks (up to 17.76% in OCR-VQA
benchmark) and in undertaking general (not particularly text-rich) VQA
benchmarks (up to 7.9% in Visual Spatial Reasoning benchmark), comparing to our
baseline InstructBLIP. BLIVA demonstrates significant capability in decoding
real-world images, irrespective of text presence. To demonstrate the broad
industry applications enabled by BLIVA, we evaluate the model using a new
dataset comprising YouTube thumbnails paired with question-answer sets across
11 diverse categories. For researchers interested in further exploration, our
code and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Wenbo Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yifan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Weiyue Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1&quot;&gt;Zhuowen Tu&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>