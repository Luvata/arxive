<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.CL updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-07-30T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Computation and Language</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15071" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15072" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15097" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15164" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15176" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15190" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15199" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15217" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15290" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15293" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15311" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15331" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15335" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15337" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15341" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15343" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15376" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15410" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15411" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15413" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15425" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15432" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15453" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15455" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15460" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15484" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15493" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15494" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15504" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15508" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15543" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15554" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15555" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15582" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15593" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15644" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15703" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.00225" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.05878" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.04702" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.14272" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.17046" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.04253" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.12247" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.11708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.07810" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.13867" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.04076" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.10270" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12794" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.13692" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.14850" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15051" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2307.15071">
<title>Writer adaptation for offline text recognition: An exploration of neural network-based methods. (arXiv:2307.15071v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.15071</link>
<description rdf:parseType="Literal">&lt;p&gt;Handwriting recognition has seen significant success with the use of deep
learning. However, a persistent shortcoming of neural networks is that they are
not well-equipped to deal with shifting data distributions. In the field of
handwritten text recognition (HTR), this shows itself in poor recognition
accuracy for writers that are not similar to those seen during training. An
ideal HTR model should be adaptive to new writing styles in order to handle the
vast amount of possible writing styles. In this paper, we explore how HTR
models can be made writer adaptive by using only a handful of examples from a
new writer (e.g., 16 examples) for adaptation. Two HTR architectures are used
as base models, using a ResNet backbone along with either an LSTM or
Transformer sequence decoder. Using these base models, two methods are
considered to make them writer adaptive: 1) model-agnostic meta-learning
(MAML), an algorithm commonly used for tasks such as few-shot classification,
and 2) writer codes, an idea originating from automatic speech recognition.
Results show that an HTR-specific version of MAML known as MetaHTR improves
performance compared to the baseline with a 1.4 to 2.0 improvement in word
error rate (WER). The improvement due to writer adaptation is between 0.2 and
0.7 WER, where a deeper model seems to lend itself better to adaptation using
MetaHTR than a shallower model. However, applying MetaHTR to larger HTR models
or sentence-level HTR may become prohibitive due to its high computational and
memory requirements. Lastly, writer codes based on learned features or Hinge
statistical features did not lead to improved recognition performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Werff_T/0/1/0/all/0/1&quot;&gt;Tobias van der Werff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhali_M/0/1/0/all/0/1&quot;&gt;Maruf A. Dhali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schomaker_L/0/1/0/all/0/1&quot;&gt;Lambert Schomaker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15072">
<title>Detecting the Presence of COVID-19 Vaccination Hesitancy from South African Twitter Data Using Machine Learning. (arXiv:2307.15072v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2307.15072</link>
<description rdf:parseType="Literal">&lt;p&gt;Very few social media studies have been done on South African user-generated
content during the COVID-19 pandemic and even fewer using hand-labelling over
automated methods. Vaccination is a major tool in the fight against the
pandemic, but vaccine hesitancy jeopardizes any public health effort. In this
study, sentiment analysis on South African tweets related to vaccine hesitancy
was performed, with the aim of training AI-mediated classification models and
assessing their reliability in categorizing UGC. A dataset of 30000 tweets from
South Africa were extracted and hand-labelled into one of three sentiment
classes: positive, negative, neutral. The machine learning models used were
LSTM, bi-LSTM, SVM, BERT-base-cased and the RoBERTa-base models, whereby their
hyperparameters were carefully chosen and tuned using the WandB platform. We
used two different approaches when we pre-processed our data for comparison:
one was semantics-based, while the other was corpus-based. The pre-processing
of the tweets in our dataset was performed using both methods, respectively.
All models were found to have low F1-scores within a range of 45$\%$-55$\%$,
except for BERT and RoBERTa which both achieved significantly better measures
with overall F1-scores of 60$\%$ and 61$\%$, respectively. Topic modelling
using an LDA was performed on the miss-classified tweets of the RoBERTa model
to gain insight on how to further improve model accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perikli_N/0/1/0/all/0/1&quot;&gt;Nicholas Perikli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1&quot;&gt;Srimoy Bhattacharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ogbuokiri_B/0/1/0/all/0/1&quot;&gt;Blessing Ogbuokiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nia_Z/0/1/0/all/0/1&quot;&gt;Zahra Movahedi Nia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lieberman_B/0/1/0/all/0/1&quot;&gt;Benjamin Lieberman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathi_N/0/1/0/all/0/1&quot;&gt;Nidhi Tripathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahbi_S/0/1/0/all/0/1&quot;&gt;Salah-Eddine Dahbi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stevenson_F/0/1/0/all/0/1&quot;&gt;Finn Stevenson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bragazzi_N/0/1/0/all/0/1&quot;&gt;Nicola Bragazzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_J/0/1/0/all/0/1&quot;&gt;Jude Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mellado_B/0/1/0/all/0/1&quot;&gt;Bruce Mellado&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15097">
<title>Cascaded Cross-Modal Transformer for Request and Complaint Detection. (arXiv:2307.15097v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15097</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel cascaded cross-modal transformer (CCMT) that combines
speech and text transcripts to detect customer requests and complaints in phone
conversations. Our approach leverages a multimodal paradigm by transcribing the
speech using automatic speech recognition (ASR) models and translating the
transcripts into different languages. Subsequently, we combine
language-specific BERT-based models with Wav2Vec2.0 audio features in a novel
cascaded cross-attention transformer model. We apply our system to the Requests
Sub-Challenge of the ACM Multimedia 2023 Computational Paralinguistics
Challenge, reaching unweighted average recalls (UAR) of 65.41% and 85.87% for
the complaint and request classes, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ristea_N/0/1/0/all/0/1&quot;&gt;Nicolae-Catalin Ristea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1&quot;&gt;Radu Tudor Ionescu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15164">
<title>VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Leveraging BERT and Stacked Embeddings. (arXiv:2307.15164v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15164</link>
<description rdf:parseType="Literal">&lt;p&gt;Our system, VISU, participated in the WASSA 2023 Shared Task (3) of Emotion
Classification from essays written in reaction to news articles. Emotion
detection from complex dialogues is challenging and often requires
context/domain understanding. Therefore in this research, we have focused on
developing deep learning (DL) models using the combination of word embedding
representations with tailored prepossessing strategies to capture the nuances
of emotions expressed. Our experiments used static and contextual embeddings
(individual and stacked) with Bidirectional Long short-term memory (BiLSTM) and
Transformer based models. We occupied rank tenth in the emotion detection task
by scoring a Macro F1-Score of 0.2717, validating the efficacy of our
implemented approaches for small and imbalanced datasets with mixed categories
of target emotions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vivek Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sushmita Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_P/0/1/0/all/0/1&quot;&gt;Prayag Tiwari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15176">
<title>RCT Rejection Sampling for Causal Estimation Evaluation. (arXiv:2307.15176v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.15176</link>
<description rdf:parseType="Literal">&lt;p&gt;Confounding is a significant obstacle to unbiased estimation of causal
effects from observational data. For settings with high-dimensional covariates
-- such as text data, genomics, or the behavioral social sciences --
researchers have proposed methods to adjust for confounding by adapting machine
learning methods to the goal of causal estimation. However, empirical
evaluation of these adjustment methods has been challenging and limited. In
this work, we build on a promising empirical evaluation strategy that
simplifies evaluation design and uses real data: subsampling randomized
controlled trials (RCTs) to create confounded observational datasets while
using the average causal effects from the RCTs as ground-truth. We contribute a
new sampling algorithm, which we call RCT rejection sampling, and provide
theoretical guarantees that causal identification holds in the observational
data to allow for valid comparisons to the ground-truth RCT. Using synthetic
data, we show our algorithm indeed results in low bias when oracle estimators
are evaluated on the confounded samples, which is not always the case for a
previously proposed algorithm. In addition to this identification result, we
highlight several finite data considerations for evaluation designers who plan
to use RCT rejection sampling on their own datasets. As a proof of concept, we
implement an example evaluation pipeline and walk through these finite data
considerations with a novel, real-world RCT -- which we release publicly --
consisting of approximately 70k observations and text data as high-dimensional
covariates. Together, these contributions build towards a broader agenda of
improved empirical evaluation for causal estimation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keith_K/0/1/0/all/0/1&quot;&gt;Katherine A. Keith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldman_S/0/1/0/all/0/1&quot;&gt;Sergey Feldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jurgens_D/0/1/0/all/0/1&quot;&gt;David Jurgens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bragg_J/0/1/0/all/0/1&quot;&gt;Jonathan Bragg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharya_R/0/1/0/all/0/1&quot;&gt;Rohit Bhattacharya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15190">
<title>f-Divergence Minimization for Sequence-Level Knowledge Distillation. (arXiv:2307.15190v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15190</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge distillation (KD) is the process of transferring knowledge from a
large model to a small one. It has gained increasing attention in the natural
language processing community, driven by the demands of compressing
ever-growing language models. In this work, we propose an f-DISTILL framework,
which formulates sequence-level knowledge distillation as minimizing a
generalized f-divergence function. We propose four distilling variants under
our framework and show that existing SeqKD and ENGINE approaches are
approximations of our f-DISTILL methods. We further derive step-wise
decomposition for our f-DISTILL, reducing intractable sequence-level divergence
to word-level losses that can be computed in a tractable manner. Experiments
across four datasets show that our methods outperform existing KD approaches,
and that our symmetric distilling losses can better force the student to learn
from the teacher distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yuqiao Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zichao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1&quot;&gt;Wenyu Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1&quot;&gt;Lili Mou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15199">
<title>PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization. (arXiv:2307.15199v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.15199</link>
<description rdf:parseType="Literal">&lt;p&gt;In a joint vision-language space, a text feature (e.g., from &quot;a photo of a
dog&quot;) could effectively represent its relevant image features (e.g., from dog
photos). Inspired by this, we propose PromptStyler which simulates various
distribution shifts in the joint space by synthesizing diverse styles via
prompts without using any images to deal with source-free domain
generalization. Our method learns to generate a variety of style features (from
&quot;a S* style of a&quot;) via learnable style word vectors for pseudo-words S*. To
ensure that learned styles do not distort content information, we force
style-content features (from &quot;a S* style of a [class]&quot;) to be located nearby
their corresponding content features (from &quot;[class]&quot;) in the joint
vision-language space. After learning style word vectors, we train a linear
classifier using synthesized style-content features. PromptStyler achieves the
state of the art on PACS, VLCS, OfficeHome and DomainNet, although it does not
require any images and takes just ~30 minutes for training using a single GPU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1&quot;&gt;Junhyeong Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_G/0/1/0/all/0/1&quot;&gt;Gilhyun Nam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sungyeon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hunmin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1&quot;&gt;Suha Kwak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15217">
<title>Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback. (arXiv:2307.15217v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.15217</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning from human feedback (RLHF) is a technique for training
AI systems to align with human goals. RLHF has emerged as the central method
used to finetune state-of-the-art large language models (LLMs). Despite this
popularity, there has been relatively little public work systematizing its
flaws. In this paper, we (1) survey open problems and fundamental limitations
of RLHF and related methods; (2) overview techniques to understand, improve,
and complement RLHF in practice; and (3) propose auditing and disclosure
standards to improve societal oversight of RLHF systems. Our work emphasizes
the limitations of RLHF and highlights the importance of a multi-faceted
approach to the development of safer AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casper_S/0/1/0/all/0/1&quot;&gt;Stephen Casper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davies_X/0/1/0/all/0/1&quot;&gt;Xander Davies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1&quot;&gt;Claudia Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilbert_T/0/1/0/all/0/1&quot;&gt;Thomas Krendl Gilbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheurer_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe9;r&amp;#xe9;my Scheurer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rando_J/0/1/0/all/0/1&quot;&gt;Javier Rando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freedman_R/0/1/0/all/0/1&quot;&gt;Rachel Freedman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1&quot;&gt;Tomasz Korbak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindner_D/0/1/0/all/0/1&quot;&gt;David Lindner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freire_P/0/1/0/all/0/1&quot;&gt;Pedro Freire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tony Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marks_S/0/1/0/all/0/1&quot;&gt;Samuel Marks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Segerie_C/0/1/0/all/0/1&quot;&gt;Charbel-Rapha&amp;#xeb;l Segerie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carroll_M/0/1/0/all/0/1&quot;&gt;Micah Carroll&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1&quot;&gt;Andi Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christoffersen_P/0/1/0/all/0/1&quot;&gt;Phillip Christoffersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damani_M/0/1/0/all/0/1&quot;&gt;Mehul Damani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slocum_S/0/1/0/all/0/1&quot;&gt;Stewart Slocum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anwar_U/0/1/0/all/0/1&quot;&gt;Usman Anwar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siththaranjan_A/0/1/0/all/0/1&quot;&gt;Anand Siththaranjan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nadeau_M/0/1/0/all/0/1&quot;&gt;Max Nadeau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michaud_E/0/1/0/all/0/1&quot;&gt;Eric J. Michaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfau_J/0/1/0/all/0/1&quot;&gt;Jacob Pfau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krasheninnikov_D/0/1/0/all/0/1&quot;&gt;Dmitrii Krasheninnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Langosco_L/0/1/0/all/0/1&quot;&gt;Lauro Langosco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hase_P/0/1/0/all/0/1&quot;&gt;Peter Hase&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biyik_E/0/1/0/all/0/1&quot;&gt;Erdem B&amp;#x131;y&amp;#x131;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krueger_D/0/1/0/all/0/1&quot;&gt;David Krueger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1&quot;&gt;Dorsa Sadigh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1&quot;&gt;Dylan Hadfield-Menell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15286">
<title>Multilingual Lexical Simplification via Paraphrase Generation. (arXiv:2307.15286v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15286</link>
<description rdf:parseType="Literal">&lt;p&gt;Lexical simplification (LS) methods based on pretrained language models have
made remarkable progress, generating potential substitutes for a complex word
through analysis of its contextual surroundings. However, these methods require
separate pretrained models for different languages and disregard the
preservation of sentence meaning. In this paper, we propose a novel
multilingual LS method via paraphrase generation, as paraphrases provide
diversity in word selection while preserving the sentence&apos;s meaning. We regard
paraphrasing as a zero-shot translation task within multilingual neural machine
translation that supports hundreds of languages. After feeding the input
sentence into the encoder of paraphrase modeling, we generate the substitutes
based on a novel decoding strategy that concentrates solely on the lexical
variations of the complex word. Experimental results demonstrate that our
approach surpasses BERT-based methods and zero-shot GPT3-based method
significantly on English, Spanish, and Portuguese.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Kang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiang_J/0/1/0/all/0/1&quot;&gt;Jipeng Qiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1&quot;&gt;Yunhao Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_K/0/1/0/all/0/1&quot;&gt;Kaixun Hua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15290">
<title>ChatHome: Development and Evaluation of a Domain-Specific Language Model for Home Renovation. (arXiv:2307.15290v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15290</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents the development and evaluation of ChatHome, a
domain-specific language model (DSLM) designed for the intricate field of home
renovation. Considering the proven competencies of large language models (LLMs)
like GPT-4 and the escalating fascination with home renovation, this study
endeavors to reconcile these aspects by generating a dedicated model that can
yield high-fidelity, precise outputs relevant to the home renovation arena.
ChatHome&apos;s novelty rests on its methodology, fusing domain-adaptive pretraining
and instruction-tuning over an extensive dataset. This dataset includes
professional articles, standard documents, and web content pertinent to home
renovation. This dual-pronged strategy is designed to ensure that our model can
assimilate comprehensive domain knowledge and effectively address user
inquiries. Via thorough experimentation on diverse datasets, both universal and
domain-specific, including the freshly introduced &quot;EvalHome&quot; domain dataset, we
substantiate that ChatHome not only amplifies domain-specific functionalities
but also preserves its versatility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1&quot;&gt;Cheng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xianghui Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shuaijiang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1&quot;&gt;Xiaoquan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Liangyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_W/0/1/0/all/0/1&quot;&gt;Wei Zou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15293">
<title>WC-SBERT: Zero-Shot Text Classification via SBERT with Self-Training for Wikipedia Categories. (arXiv:2307.15293v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15293</link>
<description rdf:parseType="Literal">&lt;p&gt;Our research focuses on solving the zero-shot text classification problem in
NLP, with a particular emphasis on innovative self-training strategies. To
achieve this objective, we propose a novel self-training strategy that uses
labels rather than text for training, significantly reducing the model&apos;s
training time. Specifically, we use categories from Wikipedia as our training
set and leverage the SBERT pre-trained model to establish positive correlations
between pairs of categories within the same text, facilitating associative
training. For new test datasets, we have improved the original self-training
approach, eliminating the need for prior training and testing data from each
target dataset. Instead, we adopt Wikipedia as a unified training dataset to
better approximate the zero-shot scenario. This modification allows for rapid
fine-tuning and inference across different datasets, greatly reducing the time
required for self-training. Our experimental results demonstrate that this
method can adapt the model to the target dataset within minutes. Compared to
other BERT-based transformer models, our approach significantly reduces the
amount of training data by training only on labels, not the actual text, and
greatly improves training efficiency by utilizing a unified training set.
Additionally, our method achieves state-of-the-art results on both the Yahoo
Topic and AG News datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_T/0/1/0/all/0/1&quot;&gt;Te-Yu Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yu-Meng Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Chia-Wen Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qiu-Xia Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1&quot;&gt;Jyh-Shing Roger Jang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15311">
<title>TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety. (arXiv:2307.15311v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15311</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have shown remarkable effectiveness in various
general-domain natural language processing (NLP) tasks. However, their
performance in transportation safety domain tasks has been suboptimal,
primarily attributed to the requirement for specialized transportation safety
expertise in generating accurate responses [1]. To address this challenge, we
introduce TrafficSafetyGPT, a novel LLAMA-based model, which has undergone
supervised fine-tuning using TrafficSafety-2K dataset which has human labels
from government produced guiding books and ChatGPT-generated instruction-output
pairs. Our proposed TrafficSafetyGPT model and TrafficSafety-2K train dataset
are accessible at https://github.com/ozheng1993/TrafficSafetyGPT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_O/0/1/0/all/0/1&quot;&gt;Ou Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdel_Aty_M/0/1/0/all/0/1&quot;&gt;Mohamed Abdel-Aty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dongdong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chenzhu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1&quot;&gt;Shengxuan Ding&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15331">
<title>Tutorials on Stance Detection using Pre-trained Language Models: Fine-tuning BERT and Prompting Large Language Models. (arXiv:2307.15331v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15331</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents two self-contained tutorials on stance detection in
Twitter data using BERT fine-tuning and prompting large language models (LLMs).
The first tutorial explains BERT architecture and tokenization, guiding users
through training, tuning, and evaluating standard and domain-specific BERT
models with HuggingFace transformers. The second focuses on constructing
prompts and few-shot examples to elicit stances from ChatGPT and open-source
FLAN-T5 without fine-tuning. Various prompting strategies are implemented and
evaluated using confusion matrices and macro F1 scores. The tutorials provide
code, visualizations, and insights revealing the strengths of few-shot ChatGPT
and FLAN-T5 which outperform fine-tuned BERTs. By covering both model
fine-tuning and prompting-based techniques in an accessible, hands-on manner,
these tutorials enable learners to gain applied experience with cutting-edge
methods for stance detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1&quot;&gt;Yun-Shiuan Chuang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15335">
<title>BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering. (arXiv:2307.15335v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15335</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual Question Answering (VQA) is an intricate and demanding task that
integrates natural language processing (NLP) and computer vision (CV),
capturing the interest of researchers. The English language, renowned for its
wealth of resources, has witnessed notable advancements in both datasets and
models designed for VQA. However, there is a lack of models that target
specific countries such as Vietnam. To address this limitation, we introduce a
transformer-based Vietnamese model named BARTPhoBEiT. This model includes
pre-trained Sequence-to-Sequence and bidirectional encoder representation from
Image Transformers in Vietnamese and evaluates Vietnamese VQA datasets.
Experimental results demonstrate that our proposed model outperforms the strong
baseline and improves the state-of-the-art in six metrics: Accuracy, Precision,
Recall, F1-score, WUPS 0.0, and WUPS 0.9.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_K/0/1/0/all/0/1&quot;&gt;Khiem Vinh Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1&quot;&gt;Kiet Van Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Ngan Luu Thuy Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15337">
<title>Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding. (arXiv:2307.15337v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15337</link>
<description rdf:parseType="Literal">&lt;p&gt;This work aims at decreasing the end-to-end generation latency of large
language models (LLMs). One of the major causes of the high generation latency
is the sequential decoding approach adopted by almost all state-of-the-art
LLMs. In this work, motivated by the thinking and writing process of humans, we
propose &quot;Skeleton-of-Thought&quot; (SoT), which guides LLMs to first generate the
skeleton of the answer, and then conducts parallel API calls or batched
decoding to complete the contents of each skeleton point in parallel. Not only
does SoT provide considerable speed-up (up to 2.39x across 11 different LLMs),
but it can also potentially improve the answer quality on several question
categories in terms of diversity and relevance. SoT is an initial attempt at
data-centric optimization for efficiency, and reveal the potential of pushing
LLMs to think more like a human for answer quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_X/0/1/0/all/0/1&quot;&gt;Xuefei Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zinan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zixuan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Huazhong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15341">
<title>Teach Me How to Improve My Argumentation Skills: A Survey on Feedback in Argumentation. (arXiv:2307.15341v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15341</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of argumentation in education has been shown to improve critical
thinking skills for end-users such as students, and computational models for
argumentation have been developed to assist in this process. Although these
models are useful for evaluating the quality of an argument, they oftentimes
cannot explain why a particular argument is considered poor or not, which makes
it difficult to provide constructive feedback to users to strengthen their
critical thinking skills. In this survey, we aim to explore the different
dimensions of feedback (Richness, Visualization, Interactivity, and
Personalization) provided by the current computational models for
argumentation, and the possibility of enhancing the power of explanations of
such models, ultimately helping learners improve their critical thinking
skills.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerraoui_C/0/1/0/all/0/1&quot;&gt;Cam&amp;#xe9;lia Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reisert_P/0/1/0/all/0/1&quot;&gt;Paul Reisert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inoue_N/0/1/0/all/0/1&quot;&gt;Naoya Inoue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mim_F/0/1/0/all/0/1&quot;&gt;Farjana Sultana Mim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naito_S/0/1/0/all/0/1&quot;&gt;Shoichi Naito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jungmin Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robbani_I/0/1/0/all/0/1&quot;&gt;Irfan Robbani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1&quot;&gt;Kentaro Inui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15343">
<title>Med-HALT: Medical Domain Hallucination Test for Large Language Models. (arXiv:2307.15343v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15343</link>
<description rdf:parseType="Literal">&lt;p&gt;This research paper focuses on the challenges posed by hallucinations in
large language models (LLMs), particularly in the context of the medical
domain. Hallucination, wherein these models generate plausible yet unverified
or incorrect information, can have serious consequences in healthcare
applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain
Hallucination Test), designed specifically to evaluate and reduce
hallucinations. Med-HALT provides a diverse multinational dataset derived from
medical examinations across various countries and includes multiple innovative
testing modalities. Med-HALT includes two categories of tests reasoning and
memory-based hallucination tests, designed to assess LLMs&apos;s problem-solving and
information retrieval abilities.
&lt;/p&gt;
&lt;p&gt;Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2,
MPT, and Falcon, revealing significant differences in their performance. The
paper provides detailed insights into the dataset, promoting transparency and
reproducibility. Through this work, we aim to contribute to the development of
safer and more reliable language models in healthcare. Our benchmark can be
found at medhalt.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Umapathi_L/0/1/0/all/0/1&quot;&gt;Logesh Kumar Umapathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_A/0/1/0/all/0/1&quot;&gt;Ankit Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankarasubbu_M/0/1/0/all/0/1&quot;&gt;Malaikannan Sankarasubbu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15376">
<title>Multilingual Tourist Assistance using ChatGPT: Comparing Capabilities in Hindi, Telugu, and Kannada. (arXiv:2307.15376v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15376</link>
<description rdf:parseType="Literal">&lt;p&gt;This research investigates the effectiveness of ChatGPT, an AI language model
by OpenAI, in translating English into Hindi, Telugu, and Kannada languages,
aimed at assisting tourists in India&apos;s linguistically diverse environment. To
measure the translation quality, a test set of 50 questions from diverse fields
such as general knowledge, food, and travel was used. These were assessed by
five volunteers for accuracy and fluency, and the scores were subsequently
converted into a BLEU score. The BLEU score evaluates the closeness of a
machine-generated translation to a human translation, with a higher score
indicating better translation quality. The Hindi translations outperformed
others, showcasing superior accuracy and fluency, whereas Telugu translations
lagged behind. Human evaluators rated both the accuracy and fluency of
translations, offering a comprehensive perspective on the language model&apos;s
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolar_S/0/1/0/all/0/1&quot;&gt;Sanjana Kolar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Rohit Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15410">
<title>Towards a Fully Unsupervised Framework for Intent Induction in Customer Support Dialogues. (arXiv:2307.15410v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15410</link>
<description rdf:parseType="Literal">&lt;p&gt;State of the art models in intent induction require annotated datasets.
However, annotating dialogues is time-consuming, laborious and expensive. In
this work, we propose a completely unsupervised framework for intent induction
within a dialogue. In addition, we show how pre-processing the dialogue corpora
can improve results. Finally, we show how to extract the dialogue flows of
intentions by investigating the most common sequences. Although we test our
work in the MultiWOZ dataset, the fact that this framework requires no prior
knowledge make it applicable to any possible use case, making it very relevant
to real world customer support applications across industry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_R/0/1/0/all/0/1&quot;&gt;Rita Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martins_B/0/1/0/all/0/1&quot;&gt;Bruno Martins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viana_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;rgio Viana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coheur_L/0/1/0/all/0/1&quot;&gt;Luisa Coheur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15411">
<title>Investigating the Learning Behaviour of In-context Learning: A Comparison with Supervised Learning. (arXiv:2307.15411v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15411</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have shown remarkable capacity for in-context
learning (ICL), where learning a new task from just a few training examples is
done without being explicitly pre-trained. However, despite the success of
LLMs, there has been little understanding of how ICL learns the knowledge from
the given prompts. In this paper, to make progress toward understanding the
learning behaviour of ICL, we train the same LLMs with the same demonstration
examples via ICL and supervised learning (SL), respectively, and investigate
their performance under label perturbations (i.e., noisy labels and label
imbalance) on a range of classification tasks. First, via extensive
experiments, we find that gold labels have significant impacts on the
downstream in-context performance, especially for large language models;
however, imbalanced labels matter little to ICL across all model sizes. Second,
when comparing with SL, we show empirically that ICL is less sensitive to label
perturbations than SL, and ICL gradually attains comparable performance to SL
as the model size increases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xindi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yufei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Can Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1&quot;&gt;Xiubo Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bowen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1&quot;&gt;Chongyang Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudzicz_F/0/1/0/all/0/1&quot;&gt;Frank Rudzicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mercer_R/0/1/0/all/0/1&quot;&gt;Robert E. Mercer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1&quot;&gt;Daxin Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15413">
<title>Improving Social Media Popularity Prediction with Multiple Post Dependencies. (arXiv:2307.15413v1 [cs.MM])</title>
<link>http://arxiv.org/abs/2307.15413</link>
<description rdf:parseType="Literal">&lt;p&gt;Social Media Popularity Prediction has drawn a lot of attention because of
its profound impact on many different applications, such as recommendation
systems and multimedia advertising. Despite recent efforts to leverage the
content of social media posts to improve prediction accuracy, many existing
models fail to fully exploit the multiple dependencies between posts, which are
important to comprehensively extract content information from posts. To tackle
this problem, we propose a novel prediction framework named Dependency-aware
Sequence Network (DSN) that exploits both intra- and inter-post dependencies.
For intra-post dependency, DSN adopts a multimodal feature extractor with an
efficient fine-tuning strategy to obtain task-specific representations from
images and textual information of posts. For inter-post dependency, DSN uses a
hierarchical information propagation method to learn category representations
that could better describe the difference between posts. DSN also exploits
recurrent networks with a series of gating layers for more flexible local
temporal processing abilities and multi-head attention for long-term
dependencies. The experimental results on the Social Media Popularity Dataset
demonstrate the superiority of our method compared to existing state-of-the-art
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhizhen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xiaohui Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Mengyu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Ye Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yong Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1&quot;&gt;Yong Cui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15425">
<title>A Critical Review of Large Language Models: Sensitivity, Bias, and the Path Toward Specialized AI. (arXiv:2307.15425v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15425</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper examines the comparative effectiveness of a specialized compiled
language model and a general-purpose model like OpenAI&apos;s GPT-3.5 in detecting
SDGs within text data. It presents a critical review of Large Language Models
(LLMs), addressing challenges related to bias and sensitivity. The necessity of
specialized training for precise, unbiased analysis is underlined. A case study
using a company descriptions dataset offers insight into the differences
between the GPT-3.5 and the specialized SDG detection model. While GPT-3.5
boasts broader coverage, it may identify SDGs with limited relevance to the
companies&apos; activities. In contrast, the specialized model zeroes in on highly
pertinent SDGs. The importance of thoughtful model selection is emphasized,
taking into account task requirements, cost, complexity, and transparency.
Despite the versatility of LLMs, the use of specialized models is suggested for
tasks demanding precision and accuracy. The study concludes by encouraging
further research to find a balance between the capabilities of LLMs and the
need for domain-specific expertise and interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajikhani_A/0/1/0/all/0/1&quot;&gt;Arash Hajikhani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cole_C/0/1/0/all/0/1&quot;&gt;Carolyn Cole&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15432">
<title>CFN-ESA: A Cross-Modal Fusion Network with Emotion-Shift Awareness for Dialogue Emotion Recognition. (arXiv:2307.15432v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15432</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal Emotion Recognition in Conversation (ERC) has garnered growing
attention from research communities in various fields. In this paper, we
propose a cross-modal fusion network with emotion-shift awareness (CFN-ESA) for
ERC. Extant approaches employ each modality equally without distinguishing the
amount of emotional information, rendering it hard to adequately extract
complementary and associative information from multimodal data. To cope with
this problem, in CFN-ESA, textual modalities are treated as the primary source
of emotional information, while visual and acoustic modalities are taken as the
secondary sources. Besides, most multimodal ERC models ignore emotion-shift
information and overfocus on contextual information, leading to the failure of
emotion recognition under emotion-shift scenario. We elaborate an emotion-shift
module to address this challenge. CFN-ESA mainly consists of the unimodal
encoder (RUME), cross-modal encoder (ACME), and emotion-shift module (LESM).
RUME is applied to extract conversation-level contextual emotional cues while
pulling together the data distributions between modalities; ACME is utilized to
perform multimodal interaction centered on textual modality; LESM is used to
model emotion shift and capture related information, thereby guide the learning
of the main task. Experimental results demonstrate that CFN-ESA can effectively
promote performance for ERC and remarkably outperform the state-of-the-art
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yingjian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaoping Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1&quot;&gt;Zhigang Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15453">
<title>From Probabilistic Programming to Complexity-based Programming. (arXiv:2307.15453v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.15453</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper presents the main characteristics and a preliminary implementation
of a novel computational framework named CompLog. Inspired by probabilistic
programming systems like ProbLog, CompLog builds upon the inferential
mechanisms proposed by Simplicity Theory, relying on the computation of two
Kolmogorov complexities (here implemented as min-path searches via ASP
programs) rather than probabilistic inference. The proposed system enables
users to compute ex-post and ex-ante measures of unexpectedness of a certain
situation, mapping respectively to posterior and prior subjective
probabilities. The computation is based on the specification of world and
mental models by means of causal and descriptive relations between predicates
weighted by complexity. The paper illustrates a few examples of application:
generating relevant descriptions, and providing alternative approaches to
disjunction and to negation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sileno_G/0/1/0/all/0/1&quot;&gt;Giovanni Sileno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dessalles_J/0/1/0/all/0/1&quot;&gt;Jean-Louis Dessalles&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15455">
<title>Trie-NLG: Trie Context Augmentation to Improve Personalized Query Auto-Completion for Short and Unseen Prefixes. (arXiv:2307.15455v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15455</link>
<description rdf:parseType="Literal">&lt;p&gt;Query auto-completion (QAC) aims at suggesting plausible completions for a
given query prefix. Traditionally, QAC systems have leveraged tries curated
from historical query logs to suggest most popular completions. In this
context, there are two specific scenarios that are difficult to handle for any
QAC system: short prefixes (which are inherently ambiguous) and unseen
prefixes. Recently, personalized Natural Language Generation (NLG) models have
been proposed to leverage previous session queries as context for addressing
these two challenges. However, such NLG models suffer from two drawbacks: (1)
some of the previous session queries could be noisy and irrelevant to the user
intent for the current prefix, and (2) NLG models cannot directly incorporate
historical query popularity. This motivates us to propose a novel NLG model for
QAC, Trie-NLG, which jointly leverages popularity signals from trie and
personalization signals from previous session queries. We train the Trie-NLG
model by augmenting the prefix with rich context comprising of recent session
queries and top trie completions. This simple modeling approach overcomes the
limitations of trie-based and NLG-based approaches and leads to
state-of-the-art performance. We evaluate the Trie-NLG model using two large
QAC datasets. On average, our model achieves huge ~57% and ~14% boost in MRR
over the popular trie-based lookup and the strong BART-based baseline methods,
respectively. We make our code publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maurya_K/0/1/0/all/0/1&quot;&gt;Kaushal Kumar Maurya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Desarkar_M/0/1/0/all/0/1&quot;&gt;Maunendra Sankar Desarkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1&quot;&gt;Manish Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1&quot;&gt;Puneet Agrawal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15460">
<title>Cross-Modal Concept Learning and Inference for Vision-Language Models. (arXiv:2307.15460v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.15460</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP,
establish the correlation between texts and images, achieving remarkable
success on various downstream tasks with fine-tuning. In existing fine-tuning
methods, the class-specific text description is matched against the whole
image. We recognize that this whole image matching is not effective since
images from the same class often contain a set of different semantic objects,
and an object further consists of a set of semantic parts or concepts.
Individual semantic parts or concepts may appear in image samples from
different classes. To address this issue, in this paper, we develop a new
method called cross-model concept learning and inference (CCLI). Using the
powerful text-image correlation capability of CLIP, our method automatically
learns a large set of distinctive visual concepts from images using a set of
semantic text concepts. Based on these visual concepts, we construct a
discriminative representation of images and learn a concept inference network
to perform downstream image classification tasks, such as few-shot learning and
domain generalization. Extensive experimental results demonstrate that our CCLI
method is able to improve the performance upon the current state-of-the-art
methods by large margins, for example, by up to 8.0% improvement on few-shot
learning and by up to 1.3% for domain generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Ce Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yushun Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhihai He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15484">
<title>Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding. (arXiv:2307.15484v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2307.15484</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, there has been a growing interest in text-to-speech (TTS) methods
that can be trained with minimal supervision by combining two types of discrete
speech representations and using two sequence-to-sequence tasks to decouple
TTS. To address the challenges associated with high dimensionality and waveform
distortion in discrete representations, we propose Diff-LM-Speech, which models
semantic embeddings into mel-spectrogram based on diffusion models and
introduces a prompt encoder structure based on variational autoencoders and
prosody bottlenecks to improve prompt representation capabilities.
Autoregressive language models often suffer from missing and repeated words,
while non-autoregressive frameworks face expression averaging problems due to
duration prediction models. To address these issues, we propose
Tetra-Diff-Speech, which designs a duration diffusion model to achieve diverse
prosodic expressions. While we expect the information content of semantic
coding to be between that of text and acoustic coding, existing models extract
semantic coding with a lot of redundant information and dimensionality
explosion. To verify that semantic coding is not necessary, we propose
Tri-Diff-Speech. Experimental results show that our proposed methods outperform
baseline methods. We provide a website with audio samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiang_C/0/1/0/all/0/1&quot;&gt;Chunyu Qiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_H/0/1/0/all/0/1&quot;&gt;Hao Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1&quot;&gt;He Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_R/0/1/0/all/0/1&quot;&gt;Ruibo Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Longbiao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dang_J/0/1/0/all/0/1&quot;&gt;Jianwu Dang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15493">
<title>The timing bottleneck: Why timing and overlap are mission-critical for conversational user interfaces, speech recognition and dialogue systems. (arXiv:2307.15493v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15493</link>
<description rdf:parseType="Literal">&lt;p&gt;Speech recognition systems are a key intermediary in voice-driven
human-computer interaction. Although speech recognition works well for pristine
monologic audio, real-life use cases in open-ended interactive settings still
present many challenges. We argue that timing is mission-critical for dialogue
systems, and evaluate 5 major commercial ASR systems for their conversational
and multilingual support. We find that word error rates for natural
conversational data in 6 languages remain abysmal, and that overlap remains a
key challenge (study 1). This impacts especially the recognition of
conversational words (study 2), and in turn has dire consequences for
downstream intent recognition (study 3). Our findings help to evaluate the
current state of conversational ASR, contribute towards multidimensional error
analysis and evaluation, and identify phenomena that need most attention on the
way to build robust interactive speech technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liesenfeld_A/0/1/0/all/0/1&quot;&gt;Andreas Liesenfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1&quot;&gt;Alianda Lopez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dingemanse_M/0/1/0/all/0/1&quot;&gt;Mark Dingemanse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15494">
<title>ETHER: Aligning Emergent Communication for Hindsight Experience Replay. (arXiv:2307.15494v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15494</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural language instruction following is paramount to enable collaboration
between artificial agents and human beings. Natural language-conditioned
reinforcement learning (RL) agents have shown how natural languages&apos;
properties, such as compositionality, can provide a strong inductive bias to
learn complex policies. Previous architectures like HIGhER combine the benefit
of language-conditioning with Hindsight Experience Replay (HER) to deal with
sparse rewards environments. Yet, like HER, HIGhER relies on an oracle
predicate function to provide a feedback signal highlighting which linguistic
description is valid for which state. This reliance on an oracle limits its
application. Additionally, HIGhER only leverages the linguistic information
contained in successful RL trajectories, thus hurting its final performance and
data-efficiency. Without early successful trajectories, HIGhER is no better
than DQN upon which it is built. In this paper, we propose the Emergent Textual
Hindsight Experience Replay (ETHER) agent, which builds on HIGhER and addresses
both of its limitations by means of (i) a discriminative visual referential
game, commonly studied in the subfield of Emergent Communication (EC), used
here as an unsupervised auxiliary task and (ii) a semantic grounding scheme to
align the emergent language with the natural language of the
instruction-following benchmark. We show that the referential game&apos;s agents
make an artificial language emerge that is aligned with the natural-like
language used to describe goals in the BabyAI benchmark and that it is
expressive enough so as to also describe unsuccessful RL trajectories and thus
provide feedback to the RL agent to leverage the linguistic, structured
information contained in all trajectories. Our work shows that EC is a viable
unsupervised auxiliary task for RL and provides missing pieces to make HER more
widely applicable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denamganai_K/0/1/0/all/0/1&quot;&gt;Kevin Denamgana&amp;#xef;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_D/0/1/0/all/0/1&quot;&gt;Daniel Hernandez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vardal_O/0/1/0/all/0/1&quot;&gt;Ozan Vardal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Missaoui_S/0/1/0/all/0/1&quot;&gt;Sondess Missaoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1&quot;&gt;James Alfred Walker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15504">
<title>Exploring Format Consistency for Instruction Tuning. (arXiv:2307.15504v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15504</link>
<description rdf:parseType="Literal">&lt;p&gt;Instruction tuning has emerged as a promising approach to enhancing large
language models in following human instructions. It is shown that increasing
the diversity and number of instructions in the training data can consistently
enhance generalization performance, which facilitates a recent endeavor to
collect various instructions and integrate existing instruction tuning datasets
into larger collections. However, different users have their unique ways of
expressing instructions, and there often exist variations across different
datasets in the instruction styles and formats, i.e., format inconsistency. In
this work, we study how format inconsistency may impact the performance of
instruction tuning. We propose a framework called &quot;Unified Instruction Tuning&quot;
(UIT), which calls OpenAI APIs for automatic format transfer among different
instruction tuning datasets. We show that UIT successfully improves the
generalization performance on unseen instructions, which highlights the
importance of format consistency for instruction tuning. To make the UIT
framework more practical, we further propose a novel perplexity-based denoising
method to reduce the noise of automatic format transfer. We also train a
smaller offline model that achieves comparable format transfer capability than
OpenAI APIs to reduce costs in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1&quot;&gt;Shihao Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1&quot;&gt;Kunlun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_R/0/1/0/all/0/1&quot;&gt;Runchu Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1&quot;&gt;Yujia Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huadong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1&quot;&gt;Xin Cong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaojiang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Maosong Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15508">
<title>The Road to Quality is Paved with Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling. (arXiv:2307.15508v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15508</link>
<description rdf:parseType="Literal">&lt;p&gt;Incremental dialogue model components produce a sequence of output prefixes
based on incoming input. Mistakes can occur due to local ambiguities or to
wrong hypotheses, making the ability to revise past outputs a desirable
property that can be governed by a policy. In this work, we formalise and
characterise edits and revisions in incremental sequence labelling and propose
metrics to evaluate revision policies. We then apply our methodology to profile
the incremental behaviour of three Transformer-based encoders in various tasks,
paving the road for better revision policies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madureira_B/0/1/0/all/0/1&quot;&gt;Brielen Madureira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahardipraja_P/0/1/0/all/0/1&quot;&gt;Patrick Kahardipraja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlangen_D/0/1/0/all/0/1&quot;&gt;David Schlangen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15543">
<title>Oracle Computability and Turing Reducibility in the Calculus of Inductive Constructions. (arXiv:2307.15543v1 [cs.LO])</title>
<link>http://arxiv.org/abs/2307.15543</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop synthetic notions of oracle computability and Turing reducibility
in the Calculus of Inductive Constructions (CIC), the constructive type theory
underlying the Coq proof assistant. As usual in synthetic approaches, we employ
a definition of oracle computations based on meta-level functions rather than
object-level models of computation, relying on the fact that in constructive
systems such as CIC all definable functions are computable by construction.
Such an approach lends itself well to machine-checked proofs, which we carry
out in Coq.
&lt;/p&gt;
&lt;p&gt;There is a tension in finding a good synthetic rendering of the higher-order
notion of oracle computability. On the one hand, it has to be informative
enough to prove central results, ensuring that all notions are faithfully
captured. On the other hand, it has to be restricted enough to benefit from
axioms for synthetic computability, which usually concern first-order objects.
Drawing inspiration from a definition by Andrej Bauer based on continuous
functions in the effective topos, we use a notion of sequential continuity to
characterise valid oracle computations.
&lt;/p&gt;
&lt;p&gt;As main technical results, we show that Turing reducibility forms an upper
semilattice, transports decidability, and is strictly more expressive than
truth-table reducibility, and prove that whenever both a predicate $p$ and its
complement are semi-decidable relative to an oracle $q$, then $p$
Turing-reduces to $q$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forster_Y/0/1/0/all/0/1&quot;&gt;Yannick Forster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirst_D/0/1/0/all/0/1&quot;&gt;Dominik Kirst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muck_N/0/1/0/all/0/1&quot;&gt;Niklas M&amp;#xfc;ck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15554">
<title>&apos;What are you referring to?&apos; Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges. (arXiv:2307.15554v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15554</link>
<description rdf:parseType="Literal">&lt;p&gt;Referential ambiguities arise in dialogue when a referring expression does
not uniquely identify the intended referent for the addressee. Addressees
usually detect such ambiguities immediately and work with the speaker to repair
it using meta-communicative, Clarificational Exchanges (CE): a Clarification
Request (CR) and a response. Here, we argue that the ability to generate and
respond to CRs imposes specific constraints on the architecture and objective
functions of multi-modal, visually grounded dialogue models. We use the SIMMC
2.0 dataset to evaluate the ability of different state-of-the-art model
architectures to process CEs, with a metric that probes the contextual updates
that arise from them in the model. We find that language-based models are able
to encode simple multi-modal semantic information and process some CEs,
excelling with those related to the dialogue history, whilst multi-modal models
can use additional learning objectives to obtain disentangled object
representations, which become crucial to handle complex referential ambiguities
across modalities overall.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiyah_Garcia_J/0/1/0/all/0/1&quot;&gt;Javier Chiyah-Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suglia_A/0/1/0/all/0/1&quot;&gt;Alessandro Suglia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eshghi_A/0/1/0/all/0/1&quot;&gt;Arash Eshghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hastie_H/0/1/0/all/0/1&quot;&gt;Helen Hastie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15555">
<title>All-for-One and One-For-All: Deep learning-based feature fusion for Synthetic Speech Detection. (arXiv:2307.15555v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2307.15555</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in deep learning and computer vision have made the synthesis
and counterfeiting of multimedia content more accessible than ever, leading to
possible threats and dangers from malicious users. In the audio field, we are
witnessing the growth of speech deepfake generation techniques, which solicit
the development of synthetic speech detection algorithms to counter possible
mischievous uses such as frauds or identity thefts. In this paper, we consider
three different feature sets proposed in the literature for the synthetic
speech detection task and present a model that fuses them, achieving overall
better performances with respect to the state-of-the-art solutions. The system
was tested on different scenarios and datasets to prove its robustness to
anti-forensic attacks and its generalization capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mari_D/0/1/0/all/0/1&quot;&gt;Daniele Mari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salvi_D/0/1/0/all/0/1&quot;&gt;Davide Salvi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bestagini_P/0/1/0/all/0/1&quot;&gt;Paolo Bestagini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milani_S/0/1/0/all/0/1&quot;&gt;Simone Milani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15582">
<title>When to generate hedges in peer-tutoring interactions. (arXiv:2307.15582v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15582</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the application of machine learning techniques to predict
where hedging occurs in peer-tutoring interactions. The study uses a
naturalistic face-to-face dataset annotated for natural language turns,
conversational strategies, tutoring strategies, and nonverbal behaviours. These
elements are processed into a vector representation of the previous turns,
which serves as input to several machine learning models. Results show that
embedding layers, that capture the semantic information of the previous turns,
significantly improves the model&apos;s performance. Additionally, the study
provides insights into the importance of various features, such as
interpersonal rapport and nonverbal behaviours, in predicting hedges by using
Shapley values for feature explanation. We discover that the eye gaze of both
the tutor and the tutee has a significant impact on hedge prediction. We
further validate this observation through a follow-up ablation study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abulimiti_A/0/1/0/all/0/1&quot;&gt;Alafate Abulimiti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clavel_C/0/1/0/all/0/1&quot;&gt;Chlo&amp;#xe9; Clavel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cassell_J/0/1/0/all/0/1&quot;&gt;Justine Cassell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15593">
<title>Robust Distortion-free Watermarks for Language Models. (arXiv:2307.15593v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.15593</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a methodology for planting watermarks in text from an
autoregressive language model that are robust to perturbations without changing
the distribution over text up to a certain maximum generation budget. We
generate watermarked text by mapping a sequence of random numbers -- which we
compute using a randomized watermark key -- to a sample from the language
model. To detect watermarked text, any party who knows the key can align the
text to the random number sequence. We instantiate our watermark methodology
with two sampling schemes: inverse transform sampling and exponential minimum
sampling. We apply these watermarks to three language models -- OPT-1.3B,
LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power
and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B
and LLaMA-7B models, we find we can reliably detect watermarked text ($p \leq
0.01$) from $35$ tokens even after corrupting between $40$-$50$\% of the tokens
via random edits (i.e., substitutions, insertions or deletions). For the
Alpaca-7B model, we conduct a case study on the feasibility of watermarking
responses to typical user instructions. Due to the lower entropy of the
responses, detection is more difficult: around $25\%$ of the responses -- whose
median length is around $100$ tokens -- are detectable with $p \leq 0.01$, and
the watermark is also less robust to certain automated paraphrasing attacks we
implement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuditipudi_R/0/1/0/all/0/1&quot;&gt;Rohith Kuditipudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thickstun_J/0/1/0/all/0/1&quot;&gt;John Thickstun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1&quot;&gt;Tatsunori Hashimoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15644">
<title>Scaling Data Generation in Vision-and-Language Navigation. (arXiv:2307.15644v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.15644</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent research in language-guided visual navigation has demonstrated a
significant demand for the diversity of traversable environments and the
quantity of supervision for training generalizable agents. To tackle the common
data scarcity issue in existing vision-and-language navigation datasets, we
propose an effective paradigm for generating large-scale data for learning,
which applies 1200+ photo-realistic environments from HM3D and Gibson datasets
and synthesizes 4.9 million instruction trajectory pairs using fully-accessible
resources on the web. Importantly, we investigate the influence of each
component in this paradigm on the agent&apos;s performance and study how to
adequately apply the augmented data to pre-train and fine-tune an agent. Thanks
to our large-scale dataset, the performance of an existing agent can be pushed
up (+11% absolute with regard to previous SoTA) to a significantly new best of
80% single-run success rate on the R2R test split by simple imitation learning.
The long-lasting generalization gap between navigating in seen and unseen
environments is also reduced to less than 1% (versus 8% in the previous best
method). Moreover, our paradigm also facilitates different models to achieve
new state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuous
environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jialu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Yicong Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1&quot;&gt;Stephen Gould&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1&quot;&gt;Hao Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1&quot;&gt;Yu Qiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15703">
<title>Uncertainty in Natural Language Generation: From Theory to Applications. (arXiv:2307.15703v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.15703</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances of powerful Language Models have allowed Natural Language
Generation (NLG) to emerge as an important technology that can not only perform
traditional tasks like summarisation or translation, but also serve as a
natural language interface to a variety of applications. As such, it is crucial
that NLG systems are trustworthy and reliable, for example by indicating when
they are likely to be wrong; and supporting multiple views, backgrounds and
writing styles -- reflecting diverse human sub-populations. In this paper, we
argue that a principled treatment of uncertainty can assist in creating systems
and evaluation protocols better aligned with these goals. We first present the
fundamental theory, frameworks and vocabulary required to represent
uncertainty. We then characterise the main sources of uncertainty in NLG from a
linguistic perspective, and propose a two-dimensional taxonomy that is more
informative and faithful than the popular aleatoric/epistemic dichotomy.
Finally, we move from theory to applications and highlight exciting research
directions that exploit uncertainty to power decoding, controllable generation,
self-assessment, selective answering, active learning and more.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baan_J/0/1/0/all/0/1&quot;&gt;Joris Baan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daheim_N/0/1/0/all/0/1&quot;&gt;Nico Daheim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilia_E/0/1/0/all/0/1&quot;&gt;Evgenia Ilia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1&quot;&gt;Dennis Ulmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haau-Sing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_R/0/1/0/all/0/1&quot;&gt;Raquel Fern&amp;#xe1;ndez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1&quot;&gt;Barbara Plank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1&quot;&gt;Rico Sennrich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zerva_C/0/1/0/all/0/1&quot;&gt;Chrysoula Zerva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1&quot;&gt;Wilker Aziz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.00225">
<title>Learning From How Humans Correct. (arXiv:2102.00225v14 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2102.00225</link>
<description rdf:parseType="Literal">&lt;p&gt;In industry NLP application, our manually labeled data has a certain number
of noisy data. We present a simple method to find the noisy data and re-label
them manually, meanwhile we collect the correction information. Then we present
novel method to incorporate the human correction information into deep learning
model. Human know how to correct noisy data. So the correction information can
be inject into deep learning model. We do the experiment on our own text
classification dataset, which is manually labeled, because we re-label the
noisy data in our dataset for our industry application. The experiment result
shows that our method improve the classification accuracy from 91.7% to 92.5%.
The 91.7% accuracy is trained on the corrected dataset, which improve the
baseline from 83.3% to 91.7%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1&quot;&gt;Tong Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.05878">
<title>Automatic Lexical Simplification for Turkish. (arXiv:2201.05878v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2201.05878</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present the first automatic lexical simplification system
for the Turkish language. Recent text simplification efforts rely on manually
crafted simplified corpora and comprehensive NLP tools that can analyse the
target text both in word and sentence levels. Turkish is a morphologically rich
agglutinative language that requires unique considerations such as the proper
handling of inflectional cases. Being a low-resource language in terms of
available resources and industrial-strength tools, it makes the text
simplification task harder to approach. We present a new text simplification
pipeline based on pretrained representation model BERT together with
morphological features to generate grammatically correct and semantically
appropriate word-level simplifications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uluslu_A/0/1/0/all/0/1&quot;&gt;Ahmet Yavuz Uluslu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.04702">
<title>Adaptive Meta-learner via Gradient Similarity for Few-shot Text Classification. (arXiv:2209.04702v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2209.04702</link>
<description rdf:parseType="Literal">&lt;p&gt;Few-shot text classification aims to classify the text under the few-shot
scenario. Most of the previous methods adopt optimization-based meta learning
to obtain task distribution. However, due to the neglect of matching between
the few amount of samples and complicated models, as well as the distinction
between useful and useless task features, these methods suffer from the
overfitting issue. To address this issue, we propose a novel Adaptive
Meta-learner via Gradient Similarity (AMGS) method to improve the model
generalization ability to a new task. Specifically, the proposed AMGS
alleviates the overfitting based on two aspects: (i) acquiring the potential
semantic representation of samples and improving model generalization through
the self-supervised auxiliary task in the inner loop, (ii) leveraging the
adaptive meta-learner via gradient similarity to add constraints on the
gradient obtained by base-learner in the outer loop. Moreover, we make a
systematic analysis of the influence of regularization on the entire framework.
Experimental results on several benchmarks demonstrate that the proposed AMGS
consistently improves few-shot text classification performance compared with
the state-of-the-art optimization-based meta-learning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_T/0/1/0/all/0/1&quot;&gt;Tianyi Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Honghui Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Q/0/1/0/all/0/1&quot;&gt;Qiaoyang Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1&quot;&gt;Dezhong Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.14272">
<title>Towards Multimodal Prediction of Spontaneous Humour: A Novel Dataset and First Results. (arXiv:2209.14272v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.14272</link>
<description rdf:parseType="Literal">&lt;p&gt;Humour is a substantial element of human affect and cognition. Its automatic
understanding can facilitate a more naturalistic human-device interaction and
the humanisation of artificial intelligence. Current methods of humour
detection are solely based on staged data making them inadequate for
&apos;real-world&apos; applications. We address this deficiency by introducing the novel
Passau-Spontaneous Football Coach Humour (Passau-SFCH) dataset, comprising of
about 11 hours of recordings. The Passau-SFCH dataset is annotated for the
presence of humour and its dimensions (sentiment and direction) as proposed in
Martin&apos;s Humor Style Questionnaire. We conduct a series of experiments,
employing pretrained Transformers, convolutional neural networks, and
expert-designed features. The performance of each modality (text, audio, video)
for spontaneous humour recognition is analysed and their complementarity is
investigated. Our findings suggest that for the automatic analysis of humour
and its sentiment, facial expressions are most promising, while humour
direction can be best modelled via text-based features. The results reveal
considerable differences among various subjects, highlighting the individuality
of humour usage and style. Further, we observe that a decision-level fusion
yields the best recognition result. Finally, we make our code publicly
available at https://www.github.com/EIHW/passau-sfch. The Passau-SFCH dataset
is available upon request.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christ_L/0/1/0/all/0/1&quot;&gt;Lukas Christ&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amiriparian_S/0/1/0/all/0/1&quot;&gt;Shahin Amiriparian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kathan_A/0/1/0/all/0/1&quot;&gt;Alexander Kathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_N/0/1/0/all/0/1&quot;&gt;Niklas M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konig_A/0/1/0/all/0/1&quot;&gt;Andreas K&amp;#xf6;nig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn W. Schuller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.17046">
<title>Rationale-Guided Few-Shot Classification to Detect Abusive Language. (arXiv:2211.17046v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2211.17046</link>
<description rdf:parseType="Literal">&lt;p&gt;Abusive language is a concerning problem in online social media. Past
research on detecting abusive language covers different platforms, languages,
demographies, etc. However, models trained using these datasets do not perform
well in cross-domain evaluation settings. To overcome this, a common strategy
is to use a few samples from the target domain to train models to get better
performance in that domain (cross-domain few-shot training). However, this
might cause the models to overfit the artefacts of those samples. A compelling
solution could be to guide the models toward rationales, i.e., spans of text
that justify the text&apos;s label. This method has been found to improve model
performance in the in-domain setting across various NLP tasks. In this paper,
we propose RGFS (Rationale-Guided Few-Shot Classification) for abusive language
detection. We first build a multitask learning setup to jointly learn
rationales, targets, and labels, and find a significant improvement of 6% macro
F1 on the rationale detection task over training solely rationale classifiers.
We introduce two rationale-integrated BERT-based architectures (the RGFS
models) and evaluate our systems over five different abusive language datasets,
finding that in the few-shot classification setting, RGFS-based models
outperform baseline models by about 7% in macro F1 scores and perform
competitively to models finetuned on other source domains. Furthermore,
RGFS-based models outperform LIME/SHAP-based approaches in terms of
plausibility and are close in performance in terms of faithfulness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_P/0/1/0/all/0/1&quot;&gt;Punyajoy Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheth_D/0/1/0/all/0/1&quot;&gt;Divyanshu Sheth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kedia_K/0/1/0/all/0/1&quot;&gt;Kushal Kedia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathew_B/0/1/0/all/0/1&quot;&gt;Binny Mathew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1&quot;&gt;Animesh Mukherjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.04253">
<title>Towards Answering Climate Questionnaires from Unstructured Climate Reports. (arXiv:2301.04253v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2301.04253</link>
<description rdf:parseType="Literal">&lt;p&gt;The topic of Climate Change (CC) has received limited attention in NLP
despite its urgency. Activists and policymakers need NLP tools to effectively
process the vast and rapidly growing unstructured textual climate reports into
structured form. To tackle this challenge we introduce two new large-scale
climate questionnaire datasets and use their existing structure to train
self-supervised models. We conduct experiments to show that these models can
learn to generalize to climate disclosures of different organizations types
than seen during training. We then use these models to help align texts from
unstructured climate documents to the semi-structured questionnaires in a human
pilot study. Finally, to support further NLP research in the climate domain we
introduce a benchmark of existing climate text classification datasets to
better evaluate and compare existing models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spokoyny_D/0/1/0/all/0/1&quot;&gt;Daniel Spokoyny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laud_T/0/1/0/all/0/1&quot;&gt;Tanmay Laud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corringham_T/0/1/0/all/0/1&quot;&gt;Tom Corringham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1&quot;&gt;Taylor Berg-Kirkpatrick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.12247">
<title>Quantifying &amp; Modeling Multimodal Interactions: An Information Decomposition Framework. (arXiv:2302.12247v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.12247</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent explosion of interest in multimodal applications has resulted in a
wide selection of datasets and methods for representing and integrating
information from different modalities. Despite these empirical advances, there
remain fundamental research questions: How can we quantify the interactions
that are necessary to solve a multimodal task? Subsequently, what are the most
suitable multimodal models to capture these interactions? To answer these
questions, we propose an information-theoretic approach to quantify the degree
of redundancy, uniqueness, and synergy relating input modalities with an output
task. We term these three measures as the PID statistics of a multimodal
distribution (or PID for short), and introduce two new estimators for these PID
statistics that scale to high-dimensional distributions. To validate PID
estimation, we conduct extensive experiments on both synthetic datasets where
the PID is known and on large-scale multimodal benchmarks where PID estimations
are compared with human annotations. Finally, we demonstrate their usefulness
in (1) quantifying interactions within multimodal datasets, (2) quantifying
interactions captured by multimodal models, (3) principled approaches for model
selection, and (4) three real-world case studies engaging with domain experts
in pathology, mood prediction, and robotic perception where our framework helps
to recommend strong multimodal models for each application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Paul Pu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yun Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1&quot;&gt;Xiang Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1&quot;&gt;Chun Kai Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1&quot;&gt;Suzanne Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Richard Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1&quot;&gt;Zihao Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_N/0/1/0/all/0/1&quot;&gt;Nicholas Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Auerbach_R/0/1/0/all/0/1&quot;&gt;Randy Auerbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_F/0/1/0/all/0/1&quot;&gt;Faisal Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1&quot;&gt;Louis-Philippe Morency&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.11708">
<title>The Open-domain Paradox for Chatbots: Common Ground as the Basis for Human-like Dialogue. (arXiv:2303.11708v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2303.11708</link>
<description rdf:parseType="Literal">&lt;p&gt;There is a surge in interest in the development of open-domain chatbots,
driven by the recent advancements of large language models. The &quot;openness&quot; of
the dialogue is expected to be maximized by providing minimal information to
the users about the common ground they can expect, including the presumed joint
activity. However, evidence suggests that the effect is the opposite. Asking
users to &quot;just chat about anything&quot; results in a very narrow form of dialogue,
which we refer to as the &quot;open-domain paradox&quot;. In this position paper, we
explain this paradox through the theory of common ground as the basis for
human-like communication. Furthermore, we question the assumptions behind
open-domain chatbots and identify paths forward for enabling common ground in
human-computer dialogue.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skantze_G/0/1/0/all/0/1&quot;&gt;Gabriel Skantze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dogruoz_A/0/1/0/all/0/1&quot;&gt;A. Seza Do&amp;#x11f;ru&amp;#xf6;z&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.07810">
<title>VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping. (arXiv:2304.07810v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/2304.07810</link>
<description rdf:parseType="Literal">&lt;p&gt;In argumentative writing, writers must brainstorm hierarchical writing goals,
ensure the persuasiveness of their arguments, and revise and organize their
plans through drafting. Recent advances in large language models (LLMs) have
made interactive text generation through a chat interface (e.g., ChatGPT)
possible. However, this approach often neglects implicit writing context and
user intent, lacks support for user control and autonomy, and provides limited
assistance for sensemaking and revising writing plans. To address these
challenges, we introduce VISAR, an AI-enabled writing assistant system designed
to help writers brainstorm and revise hierarchical goals within their writing
context, organize argument structures through synchronized text editing and
visual programming, and enhance persuasiveness with argumentation spark
recommendations. VISAR allows users to explore, experiment with, and validate
their writing plans using automatic draft prototyping. A controlled lab study
confirmed the usability and effectiveness of VISAR in facilitating the
argumentative writing planning process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jie Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhaliwal_R/0/1/0/all/0/1&quot;&gt;Ranjodh Singh Dhaliwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Toby Jia-Jun Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.13867">
<title>Transferring Procedural Knowledge across Commonsense Tasks. (arXiv:2304.13867v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2304.13867</link>
<description rdf:parseType="Literal">&lt;p&gt;Stories about everyday situations are an essential part of human
communication, motivating the need to develop AI agents that can reliably
understand these stories. Despite the long list of supervised methods for story
completion and procedural understanding, current AI has no mechanisms to
automatically track and explain procedures in unseen stories. To bridge this
gap, we study the ability of AI models to transfer procedural knowledge to
novel narrative tasks in a transparent manner. We design LEAP: a comprehensive
framework that integrates state-of-the-art modeling architectures, training
regimes, and augmentation strategies based on both natural and synthetic
stories. To address the lack of densely annotated training data, we devise a
robust automatic labeler based on few-shot prompting to enhance the augmented
data. Our experiments with in- and out-of-domain tasks reveal insights into the
interplay of different architectures, training regimes, and augmentation
strategies. LEAP&apos;s labeler has a clear positive impact on out-of-domain
datasets, while the resulting dense annotation provides native explainability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yifan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilievski_F/0/1/0/all/0/1&quot;&gt;Filip Ilievski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1&quot;&gt;Kaixin Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.04076">
<title>SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition. (arXiv:2305.04076v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.04076</link>
<description rdf:parseType="Literal">&lt;p&gt;Distantly-Supervised Named Entity Recognition effectively alleviates the
burden of time-consuming and expensive annotation in the supervised setting.
But the context-free matching process and the limited coverage of knowledge
bases introduce inaccurate and incomplete annotation noise respectively.
Previous studies either considered only incomplete annotation noise or
indiscriminately handle two types of noise with the same strategy. In this
paper, we argue that the different causes of two types of noise bring up the
requirement of different strategies in model architecture. Therefore, we
propose the SANTA to handle these two types of noise separately with (1)
Memory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity
problem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate
decision boundary shifting problem caused by incomplete annotation and a
noise-tolerant loss to improve the robustness. Benefiting from our separate
tailored strategies, we confirm in the experiment that the two types of noise
are well mitigated. SANTA also achieves a new state-of-the-art on five public
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1&quot;&gt;Shuzheng Si&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1&quot;&gt;Zefan Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1&quot;&gt;Shuang Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_G/0/1/0/all/0/1&quot;&gt;Guoqiang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jiaxing Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1&quot;&gt;Baobao Chang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.10270">
<title>Boosting Local Spectro-Temporal Features for Speech Analysis. (arXiv:2305.10270v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.10270</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the problem of phone classification in the context of speech
recognition, and explore several sets of local spectro-temporal features that
can be used for phone classification. In particular, we present some
preliminary results for phone classification using two sets of features that
are commonly used for object detection: Haar features and SVM-classified
Histograms of Gradients (HoG).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerzhoy_M/0/1/0/all/0/1&quot;&gt;Michael Guerzhoy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12794">
<title>Overview of Robust and Multilingual Automatic Evaluation Metrics\\for Open-Domain Dialogue Systems at DSTC 11 Track 4. (arXiv:2306.12794v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12794</link>
<description rdf:parseType="Literal">&lt;p&gt;The advent and fast development of neural networks have revolutionized the
research on dialogue systems and subsequently have triggered various challenges
regarding their automatic evaluation. Automatic evaluation of open-domain
dialogue systems as an open challenge has been the center of the attention of
many researchers. Despite the consistent efforts to improve automatic metrics&apos;
correlations with human evaluation, there have been very few attempts to assess
their robustness over multiple domains and dimensions. Also, their focus is
mainly on the English language. All of these challenges prompt the development
of automatic evaluation metrics that are reliable in various domains,
dimensions, and languages. This track in the 11th Dialogue System Technology
Challenge (DSTC11) is part of the ongoing effort to promote robust and
multilingual automatic evaluation metrics. This article describes the datasets
and baselines provided to participants and discusses the submission and result
details of the two proposed subtasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_Cantelar_M/0/1/0/all/0/1&quot;&gt;Mario Rodr&amp;#xed;guez-Cantelar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1&quot;&gt;Chengguang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1&quot;&gt;Ke Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghazarian_S/0/1/0/all/0/1&quot;&gt;Sarik Ghazarian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Sedoc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DHaro_L/0/1/0/all/0/1&quot;&gt;Luis Fernando D&amp;#x27;Haro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudnicky_A/0/1/0/all/0/1&quot;&gt;Alexander Rudnicky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.13692">
<title>ARB: Advanced Reasoning Benchmark for Large Language Models. (arXiv:2307.13692v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.13692</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have demonstrated remarkable performance on
various quantitative reasoning and knowledge benchmarks. However, many of these
benchmarks are losing utility as LLMs get increasingly high scores, despite not
yet reaching expert performance in these domains. We introduce ARB, a novel
benchmark composed of advanced reasoning problems in multiple fields. ARB
presents a more challenging test than prior benchmarks, featuring problems in
mathematics, physics, biology, chemistry, and law. As a subset of ARB, we
introduce a challenging set of math and physics problems which require advanced
symbolic reasoning and domain knowledge. We evaluate recent models such as
GPT-4 and Claude on ARB and demonstrate that current models score well below
50% on more demanding tasks. In order to improve both automatic and assisted
evaluation capabilities, we introduce a rubric-based evaluation approach,
allowing GPT-4 to score its own intermediate reasoning steps. Further, we
conduct a human evaluation of the symbolic subset of ARB, finding promising
agreement between annotators and GPT-4 rubric evaluation scores.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sawada_T/0/1/0/all/0/1&quot;&gt;Tomohiro Sawada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paleka_D/0/1/0/all/0/1&quot;&gt;Daniel Paleka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Havrilla_A/0/1/0/all/0/1&quot;&gt;Alexander Havrilla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tadepalli_P/0/1/0/all/0/1&quot;&gt;Pranav Tadepalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vidas_P/0/1/0/all/0/1&quot;&gt;Paula Vidas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kranias_A/0/1/0/all/0/1&quot;&gt;Alexander Kranias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nay_J/0/1/0/all/0/1&quot;&gt;John J. Nay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1&quot;&gt;Kshitij Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komatsuzaki_A/0/1/0/all/0/1&quot;&gt;Aran Komatsuzaki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.14850">
<title>Turkish Native Language Identification. (arXiv:2307.14850v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.14850</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present the first application of Native Language
Identification (NLI) for the Turkish language. NLI involves predicting the
writer&apos;s first language by analysing their writing in different languages.
While most NLI research has focused on English, our study extends its scope to
Turkish. We used the recently constructed Turkish Learner Corpus and employed a
combination of three syntactic features (CFG production rules, part-of-speech
n-grams, and function words) with L2 texts to demonstrate their effectiveness
in this task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uluslu_A/0/1/0/all/0/1&quot;&gt;Ahmet Yavuz Uluslu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_G/0/1/0/all/0/1&quot;&gt;Gerold Schneider&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15051">
<title>Matching Patients to Clinical Trials with Large Language Models. (arXiv:2307.15051v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.15051</link>
<description rdf:parseType="Literal">&lt;p&gt;Clinical trials are vital in advancing drug development and evidence-based
medicine, but their success is often hindered by challenges in patient
recruitment. In this work, we investigate the potential of large language
models (LLMs) to assist individual patients and referral physicians in
identifying suitable clinical trials from an extensive selection. Specifically,
we introduce TrialGPT, a novel architecture employing LLMs to predict
criterion-level eligibility with detailed explanations, which are then
aggregated for ranking and excluding candidate clinical trials based on
free-text patient notes. We evaluate TrialGPT on three publicly available
cohorts of 184 patients and 18,238 annotated clinical trials. The experimental
results demonstrate several key findings: First, TrialGPT achieves high
criterion-level prediction accuracy with faithful explanations. Second, the
aggregated trial-level TrialGPT scores are highly correlated with expert
eligibility annotations. Third, these scores prove effective in ranking
clinical trials and exclude ineligible candidates. Our error analysis suggests
that current LLMs still make some mistakes due to limited medical knowledge and
domain-specific context understanding. Nonetheless, we believe the explanatory
capabilities of LLMs are highly valuable. Future research is warranted on how
such AI assistants can be integrated into the routine trial matching workflow
in real-world settings to improve its efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1&quot;&gt;Qiao Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zifeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Floudas_C/0/1/0/all/0/1&quot;&gt;Charalampos S. Floudas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Lu&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>