<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.AI updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Artificial Intelligence (cs.AI) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-12-24T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Artificial Intelligence</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14171" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14182" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14183" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14184" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14185" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14187" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14188" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14197" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14202" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14211" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14215" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14217" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14219" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14220" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14222" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14227" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14229" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14232" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14264" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14292" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14301" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14302" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14345" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14346" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14394" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14395" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14402" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14406" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14421" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14428" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14438" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14447" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14461" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14472" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14481" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14488" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14499" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14530" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14532" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14533" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14535" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14536" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14544" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14565" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14569" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14625" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14628" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14634" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14635" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14646" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14647" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14670" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14677" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14688" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14737" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14769" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14792" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14794" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14808" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14824" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14836" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14852" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14856" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14862" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14867" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14871" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14875" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14877" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14878" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14880" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14890" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14895" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14920" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14924" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.03131" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.11997" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.01250" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.10510" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.04164" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.01658" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06972" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19228" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.05059" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11758" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.17602" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.02139" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01438" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.05086" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.05707" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.12420" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.16502" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05756" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.11434" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.12598" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.12705" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.12865" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.13434" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.13970" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2312.14171">
<title>SEOpinion: Summarization and Exploration Opinion of E-Commerce Websites. (arXiv:2312.14171v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14171</link>
<description rdf:parseType="Literal">&lt;p&gt;E-Commerce (EC) websites provide a large amount of useful information that
exceed human cognitive processing ability. In order to help customers in
comparing alternatives when buying a product, previous studies designed opinion
summarization systems based on customer reviews. They ignored templates&apos;
information provided by manufacturers, although these descriptive information
have much product aspects or characteristics. Therefore, this paper proposes a
methodology coined as SEOpinion (Summa-rization and Exploration of Opinions)
which provides a summary for the product aspects and spots opinion(s) regarding
them, using a combination of templates&apos; information with the customer reviews
in two main phases. First, the Hierarchical Aspect Extraction (HAE) phase
creates a hierarchy of product aspects from the template. Subsequently, the
Hierarchical Aspect-based Opinion Summarization (HAOS) phase enriches this
hierarchy with customers&apos; opinions; to be shown to other potential buyers. To
test the feasibility of using Deep Learning-based BERT techniques with our
approach, we have created a corpus by gathering information from the top five
EC websites for laptops. The experimental results show that Recurrent Neural
Network (RNN) achieves better results (77.4% and 82.6% in terms of F1-measure
for the first and second phase) than the Convolutional Neural Network (CNN) and
the Support Vector Machine (SVM) technique.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mabrouk_A/0/1/0/all/0/1&quot;&gt;Alhassan Mabrouk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Redondo_R/0/1/0/all/0/1&quot;&gt;Rebeca P. D&amp;#xed;az-Redondo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kayed_M/0/1/0/all/0/1&quot;&gt;Mohammed Kayed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14182">
<title>Find the Lady: Permutation and Re-Synchronization of Deep Neural Networks. (arXiv:2312.14182v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14182</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are characterized by multiple symmetrical, equi-loss
solutions that are redundant. Thus, the order of neurons in a layer and feature
maps can be given arbitrary permutations, without affecting (or minimally
affecting) their output. If we shuffle these neurons, or if we apply to them
some perturbations (like fine-tuning) can we put them back in the original
order i.e. re-synchronize? Is there a possible corruption threat? Answering
these questions is important for applications like neural network white-box
watermarking for ownership tracking and integrity verification. We advance a
method to re-synchronize the order of permuted neurons. Our method is also
effective if neurons are further altered by parameter pruning, quantization,
and fine-tuning, showing robustness to integrity attacks. Additionally, we
provide theoretical and practical evidence for the usual means to corrupt the
integrity of the model, resulting in a solution to counter it. We test our
approach on popular computer vision datasets and models, and we illustrate the
threat and our countermeasure on a popular white-box watermarking method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trias_C/0/1/0/all/0/1&quot;&gt;Carl De Sousa Trias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitrea_M/0/1/0/all/0/1&quot;&gt;Mihai Petru Mitrea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiandrotti_A/0/1/0/all/0/1&quot;&gt;Attilio Fiandrotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cagnazzo_M/0/1/0/all/0/1&quot;&gt;Marco Cagnazzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1&quot;&gt;Sumanta Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tartaglione_E/0/1/0/all/0/1&quot;&gt;Enzo Tartaglione&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14183">
<title>On Early Detection of Hallucinations in Factual Question Answering. (arXiv:2312.14183v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14183</link>
<description rdf:parseType="Literal">&lt;p&gt;While large language models (LLMs) have taken great strides towards helping
humans with a plethora of tasks like search and summarization, hallucinations
remain a major impediment towards gaining user trust. The fluency and coherence
of model generations even when hallucinating makes it difficult to detect
whether or not a model is hallucinating. In this work, we explore if the
artifacts associated with the model generations can provide hints that the
generation will contain hallucinations. Specifically, we probe LLMs at 1) the
inputs via Integrated Gradients based token attribution, 2) the outputs via the
Softmax probabilities, and 3) the internal state via self-attention and
fully-connected layer activations for signs of hallucinations on open-ended
question answering tasks. Our results show that the distributions of these
artifacts differ between hallucinated and non-hallucinated generations.
Building on this insight, we train binary classifiers that use these artifacts
as input features to classify model generations into hallucinations and
non-hallucinations. These hallucination classifiers achieve up to 0.80 AUROC.
We further show that tokens preceding a hallucination can predict the
subsequent hallucination before it occurs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Snyder_B/0/1/0/all/0/1&quot;&gt;Ben Snyder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moisescu_M/0/1/0/all/0/1&quot;&gt;Marius Moisescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zafar_M/0/1/0/all/0/1&quot;&gt;Muhammad Bilal Zafar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14184">
<title>Large Language Models in Medical Term Classification and Unexpected Misalignment Between Response and Reasoning. (arXiv:2312.14184v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14184</link>
<description rdf:parseType="Literal">&lt;p&gt;This study assesses the ability of state-of-the-art large language models
(LLMs) including GPT-3.5, GPT-4, Falcon, and LLaMA 2 to identify patients with
mild cognitive impairment (MCI) from discharge summaries and examines instances
where the models&apos; responses were misaligned with their reasoning. Utilizing the
MIMIC-IV v2.2 database, we focused on a cohort aged 65 and older, verifying MCI
diagnoses against ICD codes and expert evaluations. The data was partitioned
into training, validation, and testing sets in a 7:2:1 ratio for model
fine-tuning and evaluation, with an additional metastatic cancer dataset from
MIMIC III used to further assess reasoning consistency. GPT-4 demonstrated
superior interpretative capabilities, particularly in response to complex
prompts, yet displayed notable response-reasoning inconsistencies. In contrast,
open-source models like Falcon and LLaMA 2 achieved high accuracy but lacked
explanatory reasoning, underscoring the necessity for further research to
optimize both performance and interpretability. The study emphasizes the
significance of prompt engineering and the need for further exploration into
the unexpected reasoning-response misalignment observed in GPT-4. The results
underscore the promise of incorporating LLMs into healthcare diagnostics,
contingent upon methodological advancements to ensure accuracy and clinical
coherence of AI-generated outputs, thereby improving the trustworthiness of
LLMs for medical decision-making.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaodan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vemulapalli_S/0/1/0/all/0/1&quot;&gt;Sandeep Vemulapalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talukdar_N/0/1/0/all/0/1&quot;&gt;Nabasmita Talukdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1&quot;&gt;Sumyeong Ahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiankun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1&quot;&gt;Han Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murtaza_S/0/1/0/all/0/1&quot;&gt;Sardar Mehtab Bin Murtaza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dave_A/0/1/0/all/0/1&quot;&gt;Aakash Ajay Dave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leshchiner_D/0/1/0/all/0/1&quot;&gt;Dmitry Leshchiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joseph_D/0/1/0/all/0/1&quot;&gt;Dimitri F. Joseph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witteveen_Lane_M/0/1/0/all/0/1&quot;&gt;Martin Witteveen-Lane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chesla_D/0/1/0/all/0/1&quot;&gt;Dave Chesla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiayu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Bin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14185">
<title>Auto311: A Confidence-guided Automated System for Non-emergency Call. (arXiv:2312.14185v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14185</link>
<description rdf:parseType="Literal">&lt;p&gt;Emergency and non-emergency response systems are essential services provided
by local governments and critical to protecting lives, the environment, and
property. The effective handling of (non-)emergency calls is critical for
public safety and well-being. By reducing the burden through non-emergency
callers, residents in critical need of assistance through 911 will receive a
fast and effective response. Collaborating with the Department of Emergency
Communications (DEC) in Nashville, we analyzed 11,796 non-emergency call
recordings and developed Auto311, the first automated system to handle 311
non-emergency calls, which (1) effectively and dynamically predicts ongoing
non-emergency incident types to generate tailored case reports during the call;
(2) itemizes essential information from dialogue contexts to complete the
generated reports; and (3) strategically structures system-caller dialogues
with optimized confidence. We used real-world data to evaluate the system&apos;s
effectiveness and deployability. The experimental results indicate that the
system effectively predicts incident type with an average F-1 score of 92.54%.
Moreover, the system successfully itemizes critical information from relevant
contexts to complete reports, evincing a 0.93 average consistency score
compared to the ground truth. Additionally, emulations demonstrate that the
system effectively decreases conversation turns as the utterance size gets more
extensive and categorizes the ongoing call with 94.49% mean accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zirong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xutong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1&quot;&gt;Meiyi Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14187">
<title>WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation. (arXiv:2312.14187v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14187</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work demonstrates that, after being fine-tuned on a high-quality
instruction dataset, the resulting model can obtain impressive capabilities to
address a wide range of tasks. However, existing methods for instruction data
generation often produce duplicate data and are not controllable enough on data
quality. In this paper, we extend the generalization of instruction tuning by
classifying the instruction data to 4 code-related tasks and propose a
LLM-based Generator-Discriminator data process framework to generate diverse,
high-quality instruction data from open source code. Hence, we introduce
CodeOcean, a dataset comprising 20,000 instruction instances across 4 universal
code-related tasks,which is aimed at augmenting the effectiveness of
instruction tuning and improving the generalization ability of fine-tuned
model. Subsequently, we present WaveCoder, a fine-tuned Code LLM with
Widespread And Versatile Enhanced instruction tuning. This model is
specifically designed for enhancing instruction tuning of Code Language Models
(LLMs). Our experiments demonstrate that Wavecoder models outperform other
open-source models in terms of generalization ability across different
code-related tasks at the same level of fine-tuning scale. Moreover, Wavecoder
exhibits high efficiency in previous code generation tasks. This paper thus
offers a significant contribution to the field of instruction data generation
and fine-tuning models, providing new insights and tools for enhancing
performance in code-related tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhaojian Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_N/0/1/0/all/0/1&quot;&gt;Ning Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yangyu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Can Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yishujie Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Wenxiang Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Q/0/1/0/all/0/1&quot;&gt;Qiufeng Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14188">
<title>Enhancing Neural Theorem Proving through Data Augmentation and Dynamic Sampling Method. (arXiv:2312.14188v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14188</link>
<description rdf:parseType="Literal">&lt;p&gt;Theorem proving is a fundamental task in mathematics. With the advent of
large language models (LLMs) and interactive theorem provers (ITPs) like Lean,
there has been growing interest in integrating LLMs and ITPs to automate
theorem proving. In this approach, the LLM generates proof steps (tactics), and
the ITP checks the applicability of the tactics at the current goal. The two
systems work together to complete the proof. In this paper, we introduce
DS-Prover, a novel dynamic sampling method for theorem proving. This method
dynamically determines the number of tactics to apply to expand the current
goal, taking into account the remaining time compared to the total allocated
time for proving a theorem. This makes the proof search process more efficient
by adjusting the balance between exploration and exploitation as time passes.
We also augment the training dataset by decomposing simplification and rewrite
tactics with multiple premises into tactics with single premises. This gives
the model more examples to learn from and helps it to predict the tactics with
premises more accurately. We perform our experiments using the Mathlib dataset
of the Lean theorem prover and report the performance on two standard datasets,
MiniF2F and ProofNet. Our methods achieve significant performance gains on both
datasets. We achieved a state-of-the-art performance (Pass@1) of 14.2% on the
ProofNet dataset and a performance of 29.8% on MiniF2F, slightly surpassing the
best-reported Pass@1 of 29.6% using Lean.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishwakarma_R/0/1/0/all/0/1&quot;&gt;Rahul Vishwakarma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1&quot;&gt;Subhankar Mishra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14197">
<title>Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models. (arXiv:2312.14197v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14197</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent remarkable advancements in large language models (LLMs) have led to
their widespread adoption in various applications. A key feature of these
applications is the combination of LLMs with external content, where user
instructions and third-party content are combined to create prompts for LLM
processing. These applications, however, are vulnerable to indirect prompt
injection attacks, where malicious instructions embedded within external
content compromise LLM&apos;s output, causing their responses to deviate from user
expectations. Despite the discovery of this security issue, no comprehensive
analysis of indirect prompt injection attacks on different LLMs is available
due to the lack of a benchmark. Furthermore, no effective defense has been
proposed.
&lt;/p&gt;
&lt;p&gt;In this work, we introduce the first benchmark, BIPIA, to measure the
robustness of various LLMs and defenses against indirect prompt injection
attacks. Our experiments reveal that LLMs with greater capabilities exhibit
more vulnerable to indirect prompt injection attacks for text tasks, resulting
in a higher ASR. We hypothesize that indirect prompt injection attacks are
mainly due to the LLMs&apos; inability to distinguish between instructions and
external content. Based on this conjecture, we propose four black-box methods
based on prompt learning and a white-box defense methods based on fine-tuning
with adversarial training to enable LLMs to distinguish between instructions
and external content and ignore instructions in the external content. Our
experimental results show that our black-box defense methods can effectively
reduce ASR but cannot completely thwart indirect prompt injection attacks,
while our white-box defense method can reduce ASR to nearly zero with little
adverse impact on the LLM&apos;s performance on general tasks. We hope that our
benchmark and defenses can inspire future work in this important area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1&quot;&gt;Jingwei Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yueqi Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1&quot;&gt;Bin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hines_K/0/1/0/all/0/1&quot;&gt;Keegan Hines&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiciman_E/0/1/0/all/0/1&quot;&gt;Emre Kiciman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1&quot;&gt;Guangzhong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fangzhao Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14201">
<title>Towards Better Visualizing the Decision Basis of Networks via Unfold and Conquer Attribution Guidance. (arXiv:2312.14201v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.14201</link>
<description rdf:parseType="Literal">&lt;p&gt;Revealing the transparency of Deep Neural Networks (DNNs) has been widely
studied to describe the decision mechanisms of network inner structures. In
this paper, we propose a novel post-hoc framework, Unfold and Conquer
Attribution Guidance (UCAG), which enhances the explainability of the network
decision by spatially scrutinizing the input features with respect to the model
confidence. Addressing the phenomenon of missing detailed descriptions, UCAG
sequentially complies with the confidence of slices of the image, leading to
providing an abundant and clear interpretation. Therefore, it is possible to
enhance the representation ability of explanation by preserving the detailed
descriptions of assistant input features, which are commonly overwhelmed by the
main meaningful regions. We conduct numerous evaluations to validate the
performance in several metrics: i) deletion and insertion, ii) (energy-based)
pointing games, and iii) positive and negative density maps. Experimental
results, including qualitative comparisons, demonstrate that our method
outperforms the existing methods with the nature of clear and detailed
explanations and applicability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1&quot;&gt;Jung-Ho Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_W/0/1/0/all/0/1&quot;&gt;Woo-Jeoung Nam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeon_K/0/1/0/all/0/1&quot;&gt;Kyu-Sung Jeon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seong-Whan Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14202">
<title>Illuminating the Black Box: A Psychometric Investigation into the Multifaceted Nature of Large Language Models. (arXiv:2312.14202v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14202</link>
<description rdf:parseType="Literal">&lt;p&gt;This study explores the idea of AI Personality or AInality suggesting that
Large Language Models (LLMs) exhibit patterns similar to human personalities.
Assuming that LLMs share these patterns with humans, we investigate using
human-centered psychometric tests such as the Myers-Briggs Type Indicator
(MBTI), Big Five Inventory (BFI), and Short Dark Triad (SD3) to identify and
confirm LLM personality types. By introducing role-play prompts, we demonstrate
the adaptability of LLMs, showing their ability to switch dynamically between
different personality types. Using projective tests, such as the Washington
University Sentence Completion Test (WUSCT), we uncover hidden aspects of LLM
personalities that are not easily accessible through direct questioning.
Projective tests allowed for a deep exploration of LLMs cognitive processes and
thought patterns and gave us a multidimensional view of AInality. Our machine
learning analysis revealed that LLMs exhibit distinct AInality traits and
manifest diverse personality types, demonstrating dynamic shifts in response to
external instructions. This study pioneers the application of projective tests
on LLMs, shedding light on their diverse and adaptable AInality traits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yang Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jordan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shou-Hsuan Stephen Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14211">
<title>Experimenting with Large Language Models and vector embeddings in NASA SciX. (arXiv:2312.14211v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14211</link>
<description rdf:parseType="Literal">&lt;p&gt;Open-source Large Language Models enable projects such as NASA SciX (i.e.,
NASA ADS) to think out of the box and try alternative approaches for
information retrieval and data augmentation, while respecting data copyright
and users&apos; privacy. However, when large language models are directly prompted
with questions without any context, they are prone to hallucination. At NASA
SciX we have developed an experiment where we created semantic vectors for our
large collection of abstracts and full-text content, and we designed a prompt
system to ask questions using contextual chunks from our system. Based on a
non-systematic human evaluation, the experiment shows a lower degree of
hallucination and better responses when using Retrieval Augmented Generation.
Further exploration is required to design new features and data augmentation
processes at NASA SciX that leverages this technology while respecting the high
level of trust and quality that the project holds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blanco_Cuaresma_S/0/1/0/all/0/1&quot;&gt;Sergi Blanco-Cuaresma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciuca_I/0/1/0/all/0/1&quot;&gt;Ioana Ciuc&amp;#x103;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Accomazzi_A/0/1/0/all/0/1&quot;&gt;Alberto Accomazzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurtz_M/0/1/0/all/0/1&quot;&gt;Michael J. Kurtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henneken_E/0/1/0/all/0/1&quot;&gt;Edwin A. Henneken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lockhart_K/0/1/0/all/0/1&quot;&gt;Kelly E. Lockhart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grezes_F/0/1/0/all/0/1&quot;&gt;Felix Grezes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_T/0/1/0/all/0/1&quot;&gt;Thomas Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapurian_G/0/1/0/all/0/1&quot;&gt;Golnaz Shapurian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grant_C/0/1/0/all/0/1&quot;&gt;Carolyn S. Grant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thompson_D/0/1/0/all/0/1&quot;&gt;Donna M. Thompson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hostetler_T/0/1/0/all/0/1&quot;&gt;Timothy W. Hostetler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Templeton_M/0/1/0/all/0/1&quot;&gt;Matthew R. Templeton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shinyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koch_J/0/1/0/all/0/1&quot;&gt;Jennifer Koch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacovich_T/0/1/0/all/0/1&quot;&gt;Taylor Jacovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chivvis_D/0/1/0/all/0/1&quot;&gt;Daniel Chivvis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alves_F/0/1/0/all/0/1&quot;&gt;Fernanda de Macedo Alves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paquin_J/0/1/0/all/0/1&quot;&gt;Jean-Claude Paquin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartlett_J/0/1/0/all/0/1&quot;&gt;Jennifer Bartlett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polimera_M/0/1/0/all/0/1&quot;&gt;Mugdha Polimera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jarmak_S/0/1/0/all/0/1&quot;&gt;Stephanie Jarmak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14215">
<title>SimLM: Can Language Models Infer Parameters of Physical Systems?. (arXiv:2312.14215v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14215</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent developments in large-scale machine learning models for
general-purpose understanding, translation and generation of language are
driving impact across a variety of sectors including medicine, robotics, and
scientific discovery. The strength of such Large Language Models (LLMs) stems
from the large corpora that they are trained with. While this imbues them with
a breadth of capabilities, they have been found unsuitable for some specific
types of problems such as advanced mathematics. In this paper, we highlight the
inability of LLMs to reason about physics tasks. We demonstrate that their
ability to infer parameters of physical systems can be improved, without
retraining, by augmenting their context with feedback from physical simulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Memery_S/0/1/0/all/0/1&quot;&gt;Sean Memery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1&quot;&gt;Mirella Lapata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subr_K/0/1/0/all/0/1&quot;&gt;Kartic Subr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14217">
<title>Adversarial Infrared Curves: An Attack on Infrared Pedestrian Detectors in the Physical World. (arXiv:2312.14217v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.14217</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural network security is a persistent concern, with considerable
research on visible light physical attacks but limited exploration in the
infrared domain. Existing approaches, like white-box infrared attacks using
bulb boards and QR suits, lack realism and stealthiness. Meanwhile, black-box
methods with cold and hot patches often struggle to ensure robustness. To
bridge these gaps, we propose Adversarial Infrared Curves (AdvIC). Using
Particle Swarm Optimization, we optimize two Bezier curves and employ cold
patches in the physical realm to introduce perturbations, creating infrared
curve patterns for physical sample generation. Our extensive experiments
confirm AdvIC&apos;s effectiveness, achieving 94.8\% and 67.2\% attack success rates
for digital and physical attacks, respectively. Stealthiness is demonstrated
through a comparative analysis, and robustness assessments reveal AdvIC&apos;s
superiority over baseline methods. When deployed against diverse advanced
detectors, AdvIC achieves an average attack success rate of 76.8\%, emphasizing
its robust nature. we explore adversarial defense strategies against AdvIC and
examine its impact under various defense mechanisms. Given AdvIC&apos;s substantial
security implications for real-world vision-based applications, urgent
attention and mitigation efforts are warranted.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1&quot;&gt;Chengyin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1&quot;&gt;Weiwen Shi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14219">
<title>DCFL: Non-IID awareness Data Condensation aided Federated Learning. (arXiv:2312.14219v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14219</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning is a decentralized learning paradigm wherein a central
server trains a global model iteratively by utilizing clients who possess a
certain amount of private datasets. The challenge lies in the fact that the
client side private data may not be identically and independently distributed,
significantly impacting the accuracy of the global model. Existing methods
commonly address the Non-IID challenge by focusing on optimization, client
selection and data complement. However, most approaches tend to overlook the
perspective of the private data itself due to privacy constraints.Intuitively,
statistical distinctions among private data on the client side can help
mitigate the Non-IID degree. Besides, the recent advancements in dataset
condensation technology have inspired us to investigate its potential
applicability in addressing Non-IID issues while maintaining privacy. Motivated
by this, we propose DCFL which divides clients into groups by using the
Centered Kernel Alignment (CKA) method, then uses dataset condensation methods
with non-IID awareness to complete clients. The private data from clients
within the same group is complementary and their condensed data is accessible
to all clients in the group. Additionally, CKA-guided client selection
strategy, filtering mechanisms, and data enhancement techniques are
incorporated to efficiently and precisely utilize the condensed data, enhance
model performance, and minimize communication time. Experimental results
demonstrate that DCFL achieves competitive performance on popular federated
learning benchmarks including MNIST, FashionMNIST, SVHN, and CIFAR-10 with
existing FL protocol.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sha_S/0/1/0/all/0/1&quot;&gt;Shaohan Sha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;YaFeng Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14220">
<title>Single-Cell RNA-seq Synthesis with Latent Diffusion Model. (arXiv:2312.14220v1 [q-bio.GN])</title>
<link>http://arxiv.org/abs/2312.14220</link>
<description rdf:parseType="Literal">&lt;p&gt;The single-cell RNA sequencing (scRNA-seq) technology enables researchers to
study complex biological systems and diseases with high resolution. The central
challenge is synthesizing enough scRNA-seq samples; insufficient samples can
impede downstream analysis and reproducibility. While various methods have been
attempted in past research, the resulting scRNA-seq samples were often of poor
quality or limited in terms of useful specific cell subpopulations. To address
these issues, we propose a novel method called Single-Cell Latent Diffusion
(SCLD) based on the Diffusion Model. This method is capable of synthesizing
large-scale, high-quality scRNA-seq samples, including both &apos;holistic&apos; or
targeted specific cellular subpopulations within a unified framework. A
pre-guidance mechanism is designed for synthesizing specific cellular
subpopulations, while a post-guidance mechanism aims to enhance the quality of
scRNA-seq samples. The SCLD can synthesize large-scale and high-quality
scRNA-seq samples for various downstream tasks. Our experimental results
demonstrate state-of-the-art performance in cell classification and data
distribution distances when evaluated on two scRNA-seq benchmarks.
Additionally, visualization experiments show the SCLD&apos;s capability in
synthesizing specific cellular subpopulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yixuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuangyin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+DI_S/0/1/0/all/0/1&quot;&gt;Shimin DI&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lei Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14222">
<title>Hierarchical Topology Isomorphism Expertise Embedded Graph Contrastive Learning. (arXiv:2312.14222v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14222</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph contrastive learning (GCL) aims to align the positive features while
differentiating the negative features in the latent space by minimizing a
pair-wise contrastive loss. As the embodiment of an outstanding discriminative
unsupervised graph representation learning approach, GCL achieves impressive
successes in various graph benchmarks. However, such an approach falls short of
recognizing the topology isomorphism of graphs, resulting in that graphs with
relatively homogeneous node features cannot be sufficiently discriminated. By
revisiting classic graph topology recognition works, we disclose that the
corresponding expertise intuitively complements GCL methods. To this end, we
propose a novel hierarchical topology isomorphism expertise embedded graph
contrastive learning, which introduces knowledge distillations to empower GCL
models to learn the hierarchical topology isomorphism expertise, including the
graph-tier and subgraph-tier. On top of this, the proposed method holds the
feature of plug-and-play, and we empirically demonstrate that the proposed
method is universal to multiple state-of-the-art GCL models. The solid
theoretical analyses are further provided to prove that compared with
conventional GCL methods, our method acquires the tighter upper bound of Bayes
classification error. We conduct extensive experiments on real-world benchmarks
to exhibit the performance superiority of our method over candidate GCL
methods, e.g., for the real-world graph representation learning experiments,
the proposed method beats the state-of-the-art method by 0.23\% on unsupervised
representation learning setting, 0.43\% on transfer learning setting. Our code
is available at https://github.com/jyf123/HTML.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiangmeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yifan Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1&quot;&gt;Hang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiang_W/0/1/0/all/0/1&quot;&gt;Wenwen Qiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Changwen Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fuchun Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14226">
<title>Deep de Finetti: Recovering Topic Distributions from Large Language Models. (arXiv:2312.14226v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14226</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) can produce long, coherent passages of text,
suggesting that LLMs, although trained on next-word prediction, must represent
the latent structure that characterizes a document. Prior work has found that
internal representations of LLMs encode one aspect of latent structure, namely
syntax; here we investigate a complementary aspect, namely the document&apos;s topic
structure. We motivate the hypothesis that LLMs capture topic structure by
connecting LLM optimization to implicit Bayesian inference. De Finetti&apos;s
theorem shows that exchangeable probability distributions can be represented as
a mixture with respect to a latent generating distribution. Although text is
not exchangeable at the level of syntax, exchangeability is a reasonable
starting assumption for topic structure. We thus hypothesize that predicting
the next token in text will lead LLMs to recover latent topic distributions. We
examine this hypothesis using Latent Dirichlet Allocation (LDA), an
exchangeable probabilistic topic model, as a target, and we show that the
representations formed by LLMs encode both the topics used to generate
synthetic data and those used to explain natural corpus data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCoy_R/0/1/0/all/0/1&quot;&gt;R. Thomas McCoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sumers_T/0/1/0/all/0/1&quot;&gt;Theodore R. Sumers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jian-Qiao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1&quot;&gt;Thomas L. Griffiths&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14227">
<title>ElasticTrainer: Speeding Up On-Device Training with Runtime Elastic Tensor Selection. (arXiv:2312.14227v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14227</link>
<description rdf:parseType="Literal">&lt;p&gt;On-device training is essential for neural networks (NNs) to continuously
adapt to new online data, but can be time-consuming due to the device&apos;s limited
computing power. To speed up on-device training, existing schemes select
trainable NN portion offline or conduct unrecoverable selection at runtime, but
the evolution of trainable NN portion is constrained and cannot adapt to the
current need for training. Instead, runtime adaptation of on-device training
should be fully elastic, i.e., every NN substructure can be freely removed from
or added to the trainable NN portion at any time in training. In this paper, we
present ElasticTrainer, a new technique that enforces such elasticity to
achieve the required training speedup with the minimum NN accuracy loss.
Experiment results show that ElasticTrainer achieves up to 3.5x more training
speedup in wall-clock time and reduces energy consumption by 2x-3x more
compared to the existing schemes, without noticeable accuracy loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kai Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Boyuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wei Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14229">
<title>Real-time Neural Network Inference on Extremely Weak Devices: Agile Offloading with Explainable AI. (arXiv:2312.14229v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14229</link>
<description rdf:parseType="Literal">&lt;p&gt;With the wide adoption of AI applications, there is a pressing need of
enabling real-time neural network (NN) inference on small embedded devices, but
deploying NNs and achieving high performance of NN inference on these small
devices is challenging due to their extremely weak capabilities. Although NN
partitioning and offloading can contribute to such deployment, they are
incapable of minimizing the local costs at embedded devices. Instead, we
suggest to address this challenge via agile NN offloading, which migrates the
required computations in NN offloading from online inference to offline
learning. In this paper, we present AgileNN, a new NN offloading technique that
achieves real-time NN inference on weak embedded devices by leveraging
eXplainable AI techniques, so as to explicitly enforce feature sparsity during
the training phase and minimize the online computation and communication costs.
Experiment results show that AgileNN&apos;s inference latency is &amp;gt;6x lower than the
existing schemes, ensuring that sensory data on embedded devices can be timely
consumed. It also reduces the local device&apos;s resource consumption by &amp;gt;8x,
without impairing the inference accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kai Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wei Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14232">
<title>Parrot Captions Teach CLIP to Spot Text. (arXiv:2312.14232v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.14232</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite CLIP being the foundation model in numerous vision-language
applications, the CLIP suffers from a severe text spotting bias. Such bias
causes CLIP models to `Parrot&apos; the visual text embedded within images while
disregarding the authentic visual semantics. We uncover that in the most
popular image-text dataset LAION-2B, the captions also densely parrot (spell)
the text embedded in images. Our analysis shows that around \textbf{50\%} of
images are embedded with visual text content, and \textbf{90\%} of their
captions more or less parrot the visual text. Based on such observation, we
thoroughly inspect the different release d versions of CLIP models and verify
that the visual text is the dominant factor in measuring the LAION-style
image-text similarity for these models. To examine whether these parrot
captions shape the text spotting bias, we train a series of CLIP models with
LAION subsets curated by different parrot-caption-oriented criteria. We show
that training with parrot captions easily shapes such bias but harms the
expected visual-language representation learning in CLIP models. This suggests
that it is urgent to revisit either the design of CLIP-like models or the
existing image-text dataset curation pipeline built on CLIP score filtering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yiqi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1&quot;&gt;Conghui He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1&quot;&gt;Alex Jinpeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Weijia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shou_M/0/1/0/all/0/1&quot;&gt;Mike Zheng Shou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14262">
<title>Exploring the intersection of Generative AI and Software Development. (arXiv:2312.14262v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2312.14262</link>
<description rdf:parseType="Literal">&lt;p&gt;In the ever-evolving landscape of Artificial Intelligence (AI), the synergy
between generative AI and Software Engineering emerges as a transformative
frontier. This whitepaper delves into the unexplored realm, elucidating how
generative AI techniques can revolutionize software development. Spanning from
project management to support and updates, we meticulously map the demands of
each development stage and unveil the potential of generative AI in addressing
them. Techniques such as zero-shot prompting, self-consistency, and multimodal
chain-of-thought are explored, showcasing their unique capabilities in
enhancing generative AI models. The significance of vector embeddings, context,
plugins, tools, and code assistants is underscored, emphasizing their role in
capturing semantic information and amplifying generative AI capabilities.
Looking ahead, this intersection promises to elevate productivity, improve code
quality, and streamline the software development process. This whitepaper
serves as a guide for stakeholders, urging discussions and experiments in the
application of generative AI in Software Engineering, fostering innovation and
collaboration for a qualitative leap in the efficiency and effectiveness of
software development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calegario_F/0/1/0/all/0/1&quot;&gt;Filipe Calegario&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buregio_V/0/1/0/all/0/1&quot;&gt;Vanilson Bur&amp;#xe9;gio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erivaldo_F/0/1/0/all/0/1&quot;&gt;Francisco Erivaldo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andrade_D/0/1/0/all/0/1&quot;&gt;Daniel Moraes Costa Andrade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Felix_K/0/1/0/all/0/1&quot;&gt;Kailane Felix&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbosa_N/0/1/0/all/0/1&quot;&gt;Nathalia Barbosa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucena_P/0/1/0/all/0/1&quot;&gt;Pedro Lucas da Silva Lucena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franca_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;sar Fran&amp;#xe7;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14264">
<title>Experimental demonstration of magnetic tunnel junction-based computational random-access memory. (arXiv:2312.14264v1 [cs.ET])</title>
<link>http://arxiv.org/abs/2312.14264</link>
<description rdf:parseType="Literal">&lt;p&gt;Conventional computing paradigm struggles to fulfill the rapidly growing
demands from emerging applications, especially those for machine intelligence,
because much of the power and energy is consumed by constant data transfers
between logic and memory modules. A new paradigm, called &quot;computational
random-access memory (CRAM)&quot; has emerged to address this fundamental
limitation. CRAM performs logic operations directly using the memory cells
themselves, without having the data ever leave the memory. The energy and
performance benefits of CRAM for both conventional and emerging applications
have been well established by prior numerical studies. However, there lacks an
experimental demonstration and study of CRAM to evaluate its computation
accuracy, which is a realistic and application-critical metrics for its
technological feasibility and competitiveness. In this work, a CRAM array based
on magnetic tunnel junctions (MTJs) is experimentally demonstrated. First,
basic memory operations as well as 2-, 3-, and 5-input logic operations are
studied. Then, a 1-bit full adder with two different designs is demonstrated.
Based on the experimental results, a suite of modeling has been developed to
characterize the accuracy of CRAM computation. Further analysis of scalar
addition, multiplication, and matrix multiplication shows promising results.
These results are then applied to a complete application: a neural network
based handwritten digit classifier, as an example to show the connection
between the application performance and further MTJ development. The classifier
achieved almost-perfect classification accuracy, with reasonable projections of
future MTJ development. With the confirmation of MTJ-based CRAM&apos;s accuracy,
there is a strong case that this technology will have a significant impact on
power- and energy-demanding applications of machine intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1&quot;&gt;Yang Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zink_B/0/1/0/all/0/1&quot;&gt;Brandon R. Zink&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bloom_R/0/1/0/all/0/1&quot;&gt;Robert P. Bloom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cilasun_H/0/1/0/all/0/1&quot;&gt;H&amp;#xfc;srev C&amp;#x131;lasun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khanal_P/0/1/0/all/0/1&quot;&gt;Pravin Khanal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Resch_S/0/1/0/all/0/1&quot;&gt;Salonik Resch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_Z/0/1/0/all/0/1&quot;&gt;Zamshed Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habiboglu_A/0/1/0/all/0/1&quot;&gt;Ali Habiboglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weigang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sapatnekar_S/0/1/0/all/0/1&quot;&gt;Sachin S. Sapatnekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karpuczu_U/0/1/0/all/0/1&quot;&gt;Ulya Karpuczu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jian-Ping Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14292">
<title>Benchmarking Multi-Agent Preference-based Reinforcement Learning for Human-AI Teaming. (arXiv:2312.14292v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14292</link>
<description rdf:parseType="Literal">&lt;p&gt;Preference-based Reinforcement Learning (PbRL) is an active area of research,
and has made significant strides in single-agent actor and in observer
human-in-the-loop scenarios. However, its application within the co-operative
multi-agent RL frameworks, where humans actively participate and express
preferences for agent behavior, remains largely uncharted. We consider a
two-agent (Human-AI) cooperative setup where both the agents are rewarded
according to human&apos;s reward function for the team. However, the agent does not
have access to it, and instead, utilizes preference-based queries to elicit its
objectives and human&apos;s preferences for the robot in the human-robot team. We
introduce the notion of Human-Flexibility, i.e. whether the human partner is
amenable to multiple team strategies, with a special case being Specified
Orchestration where the human has a single team policy in mind (most
constrained case). We propose a suite of domains to study PbRL for Human-AI
cooperative setup which explicitly require forced cooperation. Adapting
state-of-the-art single-agent PbRL algorithms to our two-agent setting, we
conduct a comprehensive benchmarking study across our domain suite. Our
findings highlight the challenges associated with high degree of
Human-Flexibility and the limited access to the human&apos;s envisioned policy in
PbRL for Human-AI cooperation. Notably, we observe that PbRL algorithms exhibit
effective performance exclusively in the case of Specified Orchestration which
can be seen as an upper bound PbRL performance for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhambri_S/0/1/0/all/0/1&quot;&gt;Siddhant Bhambri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_M/0/1/0/all/0/1&quot;&gt;Mudit Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murthy_A/0/1/0/all/0/1&quot;&gt;Anil Murthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1&quot;&gt;Subbarao Kambhampati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14301">
<title>Autoencoder Based Face Verification System. (arXiv:2312.14301v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.14301</link>
<description rdf:parseType="Literal">&lt;p&gt;The primary objective of this work is to present an alternative approach
aimed at reducing the dependency on labeled data. Our proposed method involves
utilizing autoencoder pre-training within a face image recognition task with
two step processes. Initially, an autoencoder is trained in an unsupervised
manner using a substantial amount of unlabeled training dataset. Subsequently,
a deep learning model is trained with initialized parameters from the
pre-trained autoencoder. This deep learning training process is conducted in a
supervised manner, employing relatively limited labeled training dataset.
During evaluation phase, face image embeddings is generated as the output of
deep neural network layer. Our training is executed on the CelebA dataset,
while evaluation is performed using benchmark face recognition datasets such as
Labeled Faces in the Wild (LFW) and YouTube Faces (YTF). Experimental results
demonstrate that by initializing the deep neural network with pre-trained
autoencoder parameters achieve comparable results to state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solomon_E/0/1/0/all/0/1&quot;&gt;Enoch Solomon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woubie_A/0/1/0/all/0/1&quot;&gt;Abraham Woubie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emiru_E/0/1/0/all/0/1&quot;&gt;Eyael Solomon Emiru&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14302">
<title>Exploiting Novel GPT-4 APIs. (arXiv:2312.14302v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.14302</link>
<description rdf:parseType="Literal">&lt;p&gt;Language model attacks typically assume one of two extreme threat models:
full white-box access to model weights, or black-box access limited to a text
generation API. However, real-world APIs are often more flexible than just text
generation: these APIs expose ``gray-box&apos;&apos; access leading to new threat
vectors. To explore this, we red-team three new functionalities exposed in the
GPT-4 APIs: fine-tuning, function calling and knowledge retrieval. We find that
fine-tuning a model on as few as 15 harmful examples or 100 benign examples can
remove core safeguards from GPT-4, enabling a range of harmful outputs.
Furthermore, we find that GPT-4 Assistants readily divulge the function call
schema and can be made to execute arbitrary function calls. Finally, we find
that knowledge retrieval can be hijacked by injecting instructions into
retrieval documents. These vulnerabilities highlight that any additions to the
functionality exposed by an API can create new vulnerabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pelrine_K/0/1/0/all/0/1&quot;&gt;Kellin Pelrine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taufeeque_M/0/1/0/all/0/1&quot;&gt;Mohammad Taufeeque&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zajac_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Zaj&amp;#x105;c&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McLean_E/0/1/0/all/0/1&quot;&gt;Euan McLean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gleave_A/0/1/0/all/0/1&quot;&gt;Adam Gleave&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14306">
<title>Social Recommendation through Heterogeneous Graph Modeling of the Long-term and Short-term Preference Defined by Dynamic Periods. (arXiv:2312.14306v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2312.14306</link>
<description rdf:parseType="Literal">&lt;p&gt;Social recommendations have been widely adopted in substantial domains.
Recently, graph neural networks (GNN) have been employed in recommender systems
due to their success in graph representation learning. However, dealing with
the dynamic property of social network data is a challenge. This research
presents a novel method that provides social recommendations by incorporating
the dynamic property of social network data in a heterogeneous graph. The model
aims to capture user preference over time without going through the
complexities of a dynamic graph by adding period nodes to define users&apos;
long-term and short-term preferences and aggregating assigned edge weights. The
model is applied to real-world data to argue its superior performance.
Promising results demonstrate the effectiveness of this model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jafari_B/0/1/0/all/0/1&quot;&gt;Behafarid Mohammad Jafari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jafari_A/0/1/0/all/0/1&quot;&gt;Ali Jafari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14345">
<title>Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs. (arXiv:2312.14345v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14345</link>
<description rdf:parseType="Literal">&lt;p&gt;The unique capabilities of Large Language Models (LLMs), such as the natural
language text generation ability, position them as strong candidates for
providing explanation for recommendations. However, despite the size of the
LLM, most existing models struggle to produce zero-shot explanations reliably.
To address this issue, we propose a framework called Logic-Scaffolding, that
combines the ideas of aspect-based explanation and chain-of-thought prompting
to generate explanations through intermediate reasoning steps. In this paper,
we share our experience in building the framework and present an interactive
demonstration for exploring our results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahdari_B/0/1/0/all/0/1&quot;&gt;Behnam Rahdari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1&quot;&gt;Hao Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1&quot;&gt;Ziwei Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yifei Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhuotong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deoras_A/0/1/0/all/0/1&quot;&gt;Anoop Deoras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14346">
<title>Don&apos;t Believe Everything You Read: Enhancing Summarization Interpretability through Automatic Identification of Hallucinations in Large Language Models. (arXiv:2312.14346v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14346</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) are adept at text manipulation -- tasks such as
machine translation and text summarization. However, these models can also be
prone to hallucination, which can be detrimental to the faithfulness of any
answers that the model provides. Recent works in combating hallucinations in
LLMs deal with identifying hallucinated sentences and categorizing the
different ways in which models hallucinate. This paper takes a deep dive into
LLM behavior with respect to hallucinations, defines a token-level approach to
identifying different kinds of hallucinations, and further utilizes this
token-level tagging to improve the interpretability and faithfulness of LLMs in
dialogue summarization tasks. Through this, the paper presents a new, enhanced
dataset and a new training paradigm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vakharia_P/0/1/0/all/0/1&quot;&gt;Priyesh Vakharia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_D/0/1/0/all/0/1&quot;&gt;Devavrat Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chavan_M/0/1/0/all/0/1&quot;&gt;Meenal Chavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonawane_D/0/1/0/all/0/1&quot;&gt;Dhananjay Sonawane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_B/0/1/0/all/0/1&quot;&gt;Bhrigu Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazaheri_P/0/1/0/all/0/1&quot;&gt;Parsa Mazaheri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lane_I/0/1/0/all/0/1&quot;&gt;Ian Lane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14394">
<title>AdapTraj: A Multi-Source Domain Generalization Framework for Multi-Agent Trajectory Prediction. (arXiv:2312.14394v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14394</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-agent trajectory prediction, as a critical task in modeling complex
interactions of objects in dynamic systems, has attracted significant research
attention in recent years. Despite the promising advances, existing studies all
follow the assumption that data distribution observed during model learning
matches that encountered in real-world deployments. However, this assumption
often does not hold in practice, as inherent distribution shifts might exist in
the mobility patterns for deployment environments, thus leading to poor domain
generalization and performance degradation. Consequently, it is appealing to
leverage trajectories from multiple source domains to mitigate such
discrepancies for multi-agent trajectory prediction task. However, the
development of multi-source domain generalization in this task presents two
notable issues: (1) negative transfer; (2) inadequate modeling for external
factors. To address these issues, we propose a new causal formulation to
explicitly model four types of features: domain-invariant and domain-specific
features for both the focal agent and neighboring agents. Building upon the new
formulation, we propose AdapTraj, a multi-source domain generalization
framework specifically tailored for multi-agent trajectory prediction. AdapTraj
serves as a plug-and-play module that is adaptable to a variety of models.
Extensive experiments on four datasets with different domains demonstrate that
AdapTraj consistently outperforms other baselines by a substantial margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_T/0/1/0/all/0/1&quot;&gt;Tangwen Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yile Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cong_G/0/1/0/all/0/1&quot;&gt;Gao Cong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yongjun Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14395">
<title>Unsupervised Deep Learning Image Verification Method. (arXiv:2312.14395v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.14395</link>
<description rdf:parseType="Literal">&lt;p&gt;Although deep learning are commonly employed for image recognition, usually
huge amount of labeled training data is required, which may not always be
readily available. This leads to a noticeable performance disparity when
compared to state-of-the-art unsupervised face verification techniques. In this
work, we propose a method to narrow this gap by leveraging an autoencoder to
convert the face image vector into a novel representation. Notably, the
autoencoder is trained to reconstruct neighboring face image vectors rather
than the original input image vectors. These neighbor face image vectors are
chosen through an unsupervised process based on the highest cosine scores with
the training face image vectors. The proposed method achieves a relative
improvement of 56\% in terms of EER over the baseline system on Labeled Faces
in the Wild (LFW) dataset. This has successfully narrowed down the performance
gap between cosine and PLDA scoring systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solomon_E/0/1/0/all/0/1&quot;&gt;Enoch Solomon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woubie_A/0/1/0/all/0/1&quot;&gt;Abraham Woubie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emiru_E/0/1/0/all/0/1&quot;&gt;Eyael Solomon Emiru&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14402">
<title>The Fairness Fair: Bringing Human Perception into Collective Decision-Making. (arXiv:2312.14402v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14402</link>
<description rdf:parseType="Literal">&lt;p&gt;Fairness is one of the most desirable societal principles in collective
decision-making. It has been extensively studied in the past decades for its
axiomatic properties and has received substantial attention from the multiagent
systems community in recent years for its theoretical and computational aspects
in algorithmic decision-making. However, these studies are often not
sufficiently rich to capture the intricacies of human perception of fairness in
the ambivalent nature of the real-world problems. We argue that not only fair
solutions should be deemed desirable by social planners (designers), but they
should be governed by human and societal cognition, consider perceived outcomes
based on human judgement, and be verifiable. We discuss how achieving this goal
requires a broad transdisciplinary approach ranging from computing and AI to
behavioral economics and human-AI interaction. In doing so, we identify
shortcomings and long-term challenges of the current literature of fair
division, describe recent efforts in addressing them, and more importantly,
highlight a series of open research directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hosseini_H/0/1/0/all/0/1&quot;&gt;Hadi Hosseini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14406">
<title>Generative Pretraining at Scale: Transformer-Based Encoding of Transactional Behavior for Fraud Detection. (arXiv:2312.14406v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14406</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we introduce an innovative autoregressive model leveraging
Generative Pretrained Transformer (GPT) architectures, tailored for fraud
detection in payment systems. Our approach innovatively confronts token
explosion and reconstructs behavioral sequences, providing a nuanced
understanding of transactional behavior through temporal and contextual
analysis. Utilizing unsupervised pretraining, our model excels in feature
representation without the need for labeled data. Additionally, we integrate a
differential convolutional approach to enhance anomaly detection, bolstering
the security and efficacy of one of the largest online payment merchants in
China. The scalability and adaptability of our model promise broad
applicability in various transactional contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Ze Yu Zhao&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zheng Zhu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guilin Li&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenhan Wang&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bo Wang&lt;/a&gt; (1) ((1) Tencent, WeChat Pay)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14421">
<title>Enhancing Actionable Formal Concept Identification with Base-Equivalent Conceptual-Relevance. (arXiv:2312.14421v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14421</link>
<description rdf:parseType="Literal">&lt;p&gt;In knowledge discovery applications, the pattern set generated from data can
be tremendously large and hard to explore by analysts. In the Formal Concept
Analysis (FCA) framework, there have been studies to identify important formal
concepts through the stability index and other quality measures. In this paper,
we introduce the Base-Equivalent Conceptual Relevance (BECR) score, a novel
conceptual relevance interestingness measure for improving the identification
of actionable concepts. From a conceptual perspective, the base and equivalent
attributes are considered meaningful information and are highly essential to
maintain the conceptual structure of concepts. Thus, the basic idea of BECR is
that the more base and equivalent attributes and minimal generators a concept
intent has, the more relevant it is. As such, BECR quantifies these attributes
and minimal generators per concept intent. Our preliminary experiments on
synthetic and real-world datasets show the efficiency of BECR compared to the
well-known stability index.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bobi_A/0/1/0/all/0/1&quot;&gt;Ayao Bobi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Missaoui_R/0/1/0/all/0/1&quot;&gt;Rokia Missaoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1&quot;&gt;Mohamed Hamza Ibrahim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14428">
<title>A Unified Industrial Large Knowledge Model Framework in Smart Manufacturing. (arXiv:2312.14428v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14428</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent emergence of large language models (LLMs) shows the potential for
artificial general intelligence, revealing new opportunities in industry 4.0
and smart manufacturing. However, a notable gap exists in applying these LLMs
in industry, primarily due to their training on general knowledge rather than
domain-specific knowledge. Such specialized domain knowledge is vital for
effectively addressing the complex needs of industrial applications. To bridge
this gap, this paper proposes an Industrial Large Knowledge Model (ILKM)
framework emphasizing their potential to revolutionize the industry in smart
manufacturing. In addition, ILKMs and LLMs are compared from eight
perspectives. Finally, &quot;6S Principle&quot; is proposed as the guideline for the
development of ILKMs in smart manufacturing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jay Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hanqi Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14438">
<title>PC-Conv: Unifying Homophily and Heterophily with Two-fold Filtering. (arXiv:2312.14438v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14438</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, many carefully crafted graph representation learning methods have
achieved impressive performance on either strong heterophilic or homophilic
graphs, but not both. Therefore, they are incapable of generalizing well across
real-world graphs with different levels of homophily. This is attributed to
their neglect of homophily in heterophilic graphs, and vice versa. In this
paper, we propose a two-fold filtering mechanism to extract homophily in
heterophilic graphs and vice versa. In particular, we extend the graph heat
equation to perform heterophilic aggregation of global information from a long
distance. The resultant filter can be exactly approximated by the
Possion-Charlier (PC) polynomials. To further exploit information at multiple
orders, we introduce a powerful graph convolution PC-Conv and its instantiation
PCNet for the node classification task. Compared with state-of-the-art GNNs,
PCNet shows competitive performance on well-known homophilic and heterophilic
graphs. Our implementation is available at https://github.com/uestclbh/PC-Conv.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bingheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_E/0/1/0/all/0/1&quot;&gt;Erlin Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1&quot;&gt;Zhao Kang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14447">
<title>On the Effectiveness of Unlearning in Session-Based Recommendation. (arXiv:2312.14447v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2312.14447</link>
<description rdf:parseType="Literal">&lt;p&gt;Session-based recommendation predicts users&apos; future interests from previous
interactions in a session. Despite the memorizing of historical samples, the
request of unlearning, i.e., to remove the effect of certain training samples,
also occurs for reasons such as user privacy or model fidelity. However,
existing studies on unlearning are not tailored for the session-based
recommendation. On the one hand, these approaches cannot achieve satisfying
unlearning effects due to the collaborative correlations and sequential
connections between the unlearning item and the remaining items in the session.
On the other hand, seldom work has conducted the research to verify the
unlearning effectiveness in the session-based recommendation scenario. In this
paper, we propose SRU, a session-based recommendation unlearning framework,
which enables high unlearning efficiency, accurate recommendation performance,
and improved unlearning effectiveness in session-based recommendation.
Specifically, we first partition the training sessions into separate sub-models
according to the similarity across the sessions, then we utilize an
attention-based aggregation layer to fuse the hidden states according to the
correlations between the session and the centroid of the data in the sub-model.
To improve the unlearning effectiveness, we further propose three extra data
deletion strategies, including collaborative extra deletion (CED), neighbor
extra deletion (NED), and random extra deletion (RED). Besides, we propose an
evaluation metric that measures whether the unlearning sample can be inferred
after the data deletion to verify the unlearning effectiveness. We implement
SRU with three representative session-based recommendation models and conduct
experiments on three benchmark datasets. Experimental results demonstrate the
effectiveness of our methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1&quot;&gt;Xin Xin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Liu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Ziqi Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1&quot;&gt;Pengjie Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhumin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jun Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zhaochun Ren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14461">
<title>Attacking Byzantine Robust Aggregation in High Dimensions. (arXiv:2312.14461v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.14461</link>
<description rdf:parseType="Literal">&lt;p&gt;Training modern neural networks or models typically requires averaging over a
sample of high-dimensional vectors. Poisoning attacks can skew or bias the
average vectors used to train the model, forcing the model to learn specific
patterns or avoid learning anything useful. Byzantine robust aggregation is a
principled algorithmic defense against such biasing. Robust aggregators can
bound the maximum bias in computing centrality statistics, such as mean, even
when some fraction of inputs are arbitrarily corrupted. Designing such
aggregators is challenging when dealing with high dimensions. However, the
first polynomial-time algorithms with strong theoretical bounds on the bias
have recently been proposed. Their bounds are independent of the number of
dimensions, promising a conceptual limit on the power of poisoning attacks in
their ongoing arms race against defenses.
&lt;/p&gt;
&lt;p&gt;In this paper, we show a new attack called HIDRA on practical realization of
strong defenses which subverts their claim of dimension-independent bias. HIDRA
highlights a novel computational bottleneck that has not been a concern of
prior information-theoretic analysis. Our experimental evaluation shows that
our attacks almost completely destroy the model performance, whereas existing
attacks with the same goal fail to have much effect. Our findings leave the
arms race between poisoning attacks and provable defenses wide open.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1&quot;&gt;Sarthak Choudhary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolluri_A/0/1/0/all/0/1&quot;&gt;Aashish Kolluri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxena_P/0/1/0/all/0/1&quot;&gt;Prateek Saxena&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14472">
<title>Not All Tasks Are Equally Difficult: Multi-Task Reinforcement Learning with Dynamic Depth Routing. (arXiv:2312.14472v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14472</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-task reinforcement learning endeavors to accomplish a set of different
tasks with a single policy. To enhance data efficiency by sharing parameters
across multiple tasks, a common practice segments the network into distinct
modules and trains a routing network to recombine these modules into
task-specific policies. However, existing routing approaches employ a fixed
number of modules for all tasks, neglecting that tasks with varying
difficulties commonly require varying amounts of knowledge. This work presents
a Dynamic Depth Routing (D2R) framework, which learns strategic skipping of
certain intermediate modules, thereby flexibly choosing different numbers of
modules for each task. Under this framework, we further introduce a ResRouting
method to address the issue of disparate routing paths between behavior and
target policies during off-policy training. In addition, we design an automatic
route-balancing mechanism to encourage continued routing exploration for
unmastered tasks without disturbing the routing of mastered ones. We conduct
extensive experiments on various robotics manipulation tasks in the Meta-World
benchmark, where D2R achieves state-of-the-art performance with significantly
improved learning efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Jinmin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zang_Y/0/1/0/all/0/1&quot;&gt;Yifan Zang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1&quot;&gt;Haobo Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1&quot;&gt;Qiang Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1&quot;&gt;Junliang Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;Jian Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14481">
<title>Part to Whole: Collaborative Prompting for Surgical Instrument Segmentation. (arXiv:2312.14481v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.14481</link>
<description rdf:parseType="Literal">&lt;p&gt;Foundation models like the Segment Anything Model (SAM) have demonstrated
promise in generic object segmentation. However, directly applying SAM to
surgical instrument segmentation presents key challenges. First, SAM relies on
per-frame point-or-box prompts which complicate surgeon-computer interaction.
Also, SAM yields suboptimal performance on segmenting surgical instruments,
owing to insufficient surgical data in its pre-training as well as the complex
structure and fine-grained details of various surgical instruments. To address
these challenges, in this paper, we investigate text promptable surgical
instrument segmentation and propose SP-SAM (SurgicalPart-SAM), a novel
efficient-tuning approach that integrates surgical instrument structure
knowledge with the generic segmentation knowledge of SAM. Specifically, we
achieve this by proposing (1) collaborative prompts in the text form &quot;[part
name] of [instrument category name]&quot; that decompose instruments into
fine-grained parts; (2) a Cross-Modal Prompt Encoder that encodes text prompts
jointly with visual embeddings into discriminative part-level representations;
and (3) a Part-to-Whole Selective Fusion and a Hierarchical Decoding strategy
that selectively assemble the part-level representations into a whole for
accurate instrument segmentation. Built upon them, SP-SAM acquires a better
capability to comprehend surgical instrument structures and distinguish between
various categories. Extensive experiments on both the EndoVis2018 and
EndoVis2017 datasets demonstrate SP-SAM&apos;s state-of-the-art performance with
minimal tunable parameters. Code is at
https://github.com/wenxi-yue/SurgicalPart-SAM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_W/0/1/0/all/0/1&quot;&gt;Wenxi Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1&quot;&gt;Kun Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qiuxia Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1&quot;&gt;Zongyuan Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1&quot;&gt;Yong Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1&quot;&gt;Jiebo Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14488">
<title>Language Model is a Branch Predictor for Simultaneous Machine Translation. (arXiv:2312.14488v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14488</link>
<description rdf:parseType="Literal">&lt;p&gt;The primary objective of simultaneous machine translation (SiMT) is to
minimize latency while preserving the quality of the final translation. Drawing
inspiration from CPU branch prediction techniques, we propose incorporating
branch prediction techniques in SiMT tasks to reduce translation latency.
Specifically, we utilize a language model as a branch predictor to predict
potential branch directions, namely, future source words. Subsequently, we
utilize the predicted source words to decode the output in advance. When the
actual source word deviates from the predicted source word, we use the real
source word to decode the output again, replacing the predicted output. To
further reduce computational costs, we share the parameters of the encoder and
the branch predictor, and utilize a pre-trained language model for
initialization. Our proposed method can be seamlessly integrated with any SiMT
model. Extensive experimental results demonstrate that our approach can improve
translation quality and latency at the same time. Our code is available at
https://github.com/YinAoXiong/simt_branch_predictor .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_A/0/1/0/all/0/1&quot;&gt;Aoxiong Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_T/0/1/0/all/0/1&quot;&gt;Tianyun Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haoyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Siliang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhou Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14499">
<title>Hutchinson Trace Estimation for High-Dimensional and High-Order Physics-Informed Neural Networks. (arXiv:2312.14499v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14499</link>
<description rdf:parseType="Literal">&lt;p&gt;Physics-Informed Neural Networks (PINNs) have proven effective in solving
partial differential equations (PDEs), especially when some data are available
by blending seamlessly data and physics. However, extending PINNs to
high-dimensional and even high-order PDEs encounters significant challenges due
to the computational cost associated with automatic differentiation in the
residual loss. Herein, we address the limitations of PINNs in handling
high-dimensional and high-order PDEs by introducing Hutchinson Trace Estimation
(HTE). Starting with the second-order high-dimensional PDEs ubiquitous in
scientific computing, HTE transforms the calculation of the entire Hessian
matrix into a Hessian vector product (HVP). This approach alleviates the
computational bottleneck via Taylor-mode automatic differentiation and
significantly reduces memory consumption from the Hessian matrix to HVP. We
further showcase HTE&apos;s convergence to the original PINN loss and its unbiased
behavior under specific conditions. Comparisons with Stochastic Dimension
Gradient Descent (SDGD) highlight the distinct advantages of HTE, particularly
in scenarios with significant variance among dimensions. We further extend HTE
to higher-order and higher-dimensional PDEs, specifically addressing the
biharmonic equation. By employing tensor-vector products (TVP), HTE efficiently
computes the colossal tensor associated with the fourth-order high-dimensional
biharmonic equation, saving memory and enabling rapid computation. The
effectiveness of HTE is illustrated through experimental setups, demonstrating
comparable convergence rates with SDGD under memory and speed constraints.
Additionally, HTE proves valuable in accelerating the Gradient-Enhanced PINN
(gPINN) version as well as the Biharmonic equation. Overall, HTE opens up a new
capability in scientific machine learning for tackling high-order and
high-dimensional PDEs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zheyuan Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zekun Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1&quot;&gt;George Em Karniadakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1&quot;&gt;Kenji Kawaguchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14530">
<title>ZodiacEdge: a Datalog Engine With Incremental Rule Set Maintenance. (arXiv:2312.14530v1 [cs.DB])</title>
<link>http://arxiv.org/abs/2312.14530</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we tackle the incremental maintenance of Datalog inference
materialisation when the rule set can be updated. This is particularly relevant
in the context of the Internet of Things and Edge computing where smart devices
may need to reason over newly acquired knowledge represented as Datalog rules.
Our solution is based on an adaptation of a stratification strategy applied to
a dependency hypergraph whose nodes correspond to rule sets in a Datalog
program. Our implementation supports recursive rules containing both negation
and aggregation. We demonstrate the effectiveness of our system on real and
synthetic data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Weiqin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cure_O/0/1/0/all/0/1&quot;&gt;Olivier Cur&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14532">
<title>DuaLight: Enhancing Traffic Signal Control by Leveraging Scenario-Specific and Scenario-Shared Knowledge. (arXiv:2312.14532v1 [cs.MA])</title>
<link>http://arxiv.org/abs/2312.14532</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning has been revolutionizing the traditional traffic
signal control task, showing promising power to relieve congestion and improve
efficiency. However, the existing methods lack effective learning mechanisms
capable of absorbing dynamic information inherent to a specific scenario and
universally applicable dynamic information across various scenarios. Moreover,
within each specific scenario, they fail to fully capture the essential
empirical experiences about how to coordinate between neighboring and target
intersections, leading to sub-optimal system-wide outcomes.
&lt;/p&gt;
&lt;p&gt;Viewing these issues, we propose DuaLight, which aims to leverage both the
experiential information within a single scenario and the generalizable
information across various scenarios for enhanced decision-making.
Specifically, DuaLight introduces a scenario-specific experiential weight
module with two learnable parts: Intersection-wise and Feature-wise, guiding
how to adaptively utilize neighbors and input features for each scenario, thus
providing a more fine-grained understanding of different intersections.
Furthermore, we implement a scenario-shared Co-Train module to facilitate the
learning of generalizable dynamics information across different scenarios.
Empirical results on both real-world and synthetic scenarios show DuaLight
achieves competitive performance across various metrics, offering a promising
solution to alleviate traffic congestion, with 3-7\% improvements. The code is
available under: https://github.com/lujiaming-12138/DuaLight.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiaming Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruan_J/0/1/0/all/0/1&quot;&gt;Jingqing Ruan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Haoyuan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Ziyue Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1&quot;&gt;Hangyu Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1&quot;&gt;Rui Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14533">
<title>Multi-view user representation learning for user matching without personal information. (arXiv:2312.14533v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2312.14533</link>
<description rdf:parseType="Literal">&lt;p&gt;As the digitization of travel industry accelerates, analyzing and
understanding travelers&apos; behaviors becomes increasingly important. However,
traveler data frequently exhibit high data sparsity due to the relatively low
frequency of user interactions with travel providers. Compounding this effect
the multiplication of devices, accounts and platforms while browsing travel
products online also leads to data dispersion. To deal with these challenges,
probabilistic traveler matching can be used. Most existing solutions for user
matching are not suitable for traveler matching as a traveler&apos;s browsing
history is typically short and URLs in the travel industry are very
heterogeneous with many tokens. To deal with these challenges, we propose the
similarity based multi-view information fusion to learn a better user
representation from URLs by treating the URLs as multi-view data. The
experimental results show that the proposed multi-view user representation
learning can take advantage of the complementary information from different
views, highlight the key information in URLs and perform significantly better
than other representation learning solutions for the user matching task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1&quot;&gt;Hongliu Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baamrani_I/0/1/0/all/0/1&quot;&gt;Ilias El Baamrani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_E/0/1/0/all/0/1&quot;&gt;Eoin Thomas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14535">
<title>ADA-GAD: Anomaly-Denoised Autoencoders for Graph Anomaly Detection. (arXiv:2312.14535v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14535</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph anomaly detection is crucial for identifying nodes that deviate from
regular behavior within graphs, benefiting various domains such as fraud
detection and social network. Although existing reconstruction-based methods
have achieved considerable success, they may face the \textit{Anomaly
Overfitting} and \textit{Homophily Trap} problems caused by the abnormal
patterns in the graph, breaking the assumption that normal nodes are often
better reconstructed than abnormal ones. Our observations indicate that models
trained on graphs with fewer anomalies exhibit higher detection performance.
Based on this insight, we introduce a novel two-stage framework called
Anomaly-Denoised Autoencoders for Graph Anomaly Detection (ADA-GAD). In the
first stage, we design a learning-free anomaly-denoised augmentation method to
generate graphs with reduced anomaly levels. We pretrain graph autoencoders on
these augmented graphs at multiple levels, which enables the graph autoencoders
to capture normal patterns. In the next stage, the decoders are retrained for
detection on the original graph, benefiting from the multi-level
representations learned in the previous stage. Meanwhile, we propose the node
anomaly distribution regularization to further alleviate \textit{Anomaly
Overfitting}. We validate the effectiveness of our approach through extensive
experiments on both synthetic and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Junwei He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1&quot;&gt;Qianqian Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yangbangyan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zitai Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qingming Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14536">
<title>Adaptive Reconvergence-driven AIG Rewriting via Strategy Learning. (arXiv:2312.14536v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14536</link>
<description rdf:parseType="Literal">&lt;p&gt;Rewriting is a common procedure in logic synthesis aimed at improving the
performance, power, and area (PPA) of circuits. The traditional
reconvergence-driven And-Inverter Graph (AIG) rewriting method focuses solely
on optimizing the reconvergence cone through Boolean algebra minimization.
However, there exist opportunities to incorporate other node-rewriting
algorithms that are better suited for specific cones. In this paper, we propose
an adaptive reconvergence-driven AIG rewriting algorithm that combines two key
techniques: multi-strategy-based AIG rewriting and strategy learning-based
algorithm selection. The multi-strategy-based rewriting method expands upon the
traditional approach by incorporating support for multi-node-rewriting
algorithms, thus expanding the optimization space. Additionally, the strategy
learning-based algorithm selection method determines the most suitable
node-rewriting algorithm for a given cone. Experimental results demonstrate
that our proposed method yields a significant average improvement of 5.567\% in
size and 5.327\% in depth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_L/0/1/0/all/0/1&quot;&gt;Liwei Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zonglin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiaxi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Junfeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Huawei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_B/0/1/0/all/0/1&quot;&gt;Biwei Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xinquan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14544">
<title>Inclusive normalization of face images to passport format. (arXiv:2312.14544v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.14544</link>
<description rdf:parseType="Literal">&lt;p&gt;Face recognition has been used more and more in real world applications in
recent years. However, when the skin color bias is coupled with intra-personal
variations like harsh illumination, the face recognition task is more likely to
fail, even during human inspection. Face normalization methods try to deal with
such challenges by removing intra-personal variations from an input image while
keeping the identity the same. However, most face normalization methods can
only remove one or two variations and ignore dataset biases such as skin color
bias. The outputs of many face normalization methods are also not realistic to
human observers. In this work, a style based face normalization model
(StyleFNM) is proposed to remove most intra-personal variations including large
changes in pose, bad or harsh illumination, low resolution, blur, facial
expressions, and accessories like sunglasses among others. The dataset bias is
also dealt with in this paper by controlling a pretrained GAN to generate a
balanced dataset of passport-like images. The experimental results show that
StyleFNM can generate more realistic outputs and can improve significantly the
accuracy and fairness of face recognition systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1&quot;&gt;Hongliu Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Do_M/0/1/0/all/0/1&quot;&gt;Minh Nhat Do&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravanel_A/0/1/0/all/0/1&quot;&gt;Alexis Ravanel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_E/0/1/0/all/0/1&quot;&gt;Eoin Thomas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14565">
<title>The Economics of Human Oversight: How Norms and Incentives Affect Costs and Performance of AI Workers. (arXiv:2312.14565v1 [econ.GN])</title>
<link>http://arxiv.org/abs/2312.14565</link>
<description rdf:parseType="Literal">&lt;p&gt;The global surge in AI applications is transforming industries, leading to
displacement and complementation of existing jobs, while also giving rise to
new employment opportunities. Human oversight of AI is an emerging task in
which human workers interact with an AI model to improve its performance,
safety, and compliance with normative principles. Data annotation, encompassing
the labelling of images or annotating of texts, serves as a critical human
oversight process, as the quality of a dataset directly influences the quality
of AI models trained on it. Therefore, the efficiency of human oversight work
stands as an important competitive advantage for AI developers. This paper
delves into the foundational economics of human oversight, with a specific
focus on the impact of norm design and monetary incentives on data quality and
costs. An experimental study involving 307 data annotators examines six groups
with varying task instructions (norms) and monetary incentives. Results reveal
that annotators provided with clear rules exhibit higher accuracy rates,
outperforming those with vague standards by 14%. Similarly, annotators
receiving an additional monetary incentive perform significantly better, with
the highest accuracy rate recorded in the group working with both clear rules
and incentives (87.5% accuracy). However, both groups require more time to
complete tasks, with a 31% increase in average task completion time compared to
those working with standards and no incentives. These empirical findings
underscore the trade-off between data quality and efficiency in data curation,
shedding light on the nuanced impact of norm design and incentives on the
economics of AI development. The paper contributes experimental insights to
discussions on the economical, ethical, and legal considerations of AI
technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Laux_J/0/1/0/all/0/1&quot;&gt;Johann Laux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Stephany_F/0/1/0/all/0/1&quot;&gt;Fabian Stephany&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Liefgreen_A/0/1/0/all/0/1&quot;&gt;Alice Liefgreen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14569">
<title>Creating New Voices using Normalizing Flows. (arXiv:2312.14569v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2312.14569</link>
<description rdf:parseType="Literal">&lt;p&gt;Creating realistic and natural-sounding synthetic speech remains a big
challenge for voice identities unseen during training. As there is growing
interest in synthesizing voices of new speakers, here we investigate the
ability of normalizing flows in text-to-speech (TTS) and voice conversion (VC)
modes to extrapolate from speakers observed during training to create unseen
speaker identities. Firstly, we create an approach for TTS and VC, and then we
comprehensively evaluate our methods and baselines in terms of intelligibility,
naturalness, speaker similarity, and ability to create new voices. We use both
objective and subjective metrics to benchmark our techniques on 2 evaluation
tasks: zero-shot and new voice speech synthesis. The goal of the former task is
to measure the precision of the conversion to an unseen voice. The goal of the
latter is to measure the ability to create new voices. Extensive evaluations
demonstrate that the proposed approach systematically allows to obtain
state-of-the-art performance in zero-shot speech synthesis and creates various
new voices, unobserved in the training set. We consider this work to be the
first attempt to synthesize new voices based on mel-spectrograms and
normalizing flows, along with a comprehensive analysis and comparison of the
TTS and VC modes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilinski_P/0/1/0/all/0/1&quot;&gt;Piotr Bilinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merritt_T/0/1/0/all/0/1&quot;&gt;Thomas Merritt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ezzerg_A/0/1/0/all/0/1&quot;&gt;Abdelhamid Ezzerg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pokora_K/0/1/0/all/0/1&quot;&gt;Kamil Pokora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cygert_S/0/1/0/all/0/1&quot;&gt;Sebastian Cygert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yanagisawa_K/0/1/0/all/0/1&quot;&gt;Kayoko Yanagisawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barra_Chicote_R/0/1/0/all/0/1&quot;&gt;Roberto Barra-Chicote&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korzekwa_D/0/1/0/all/0/1&quot;&gt;Daniel Korzekwa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14625">
<title>Hierarchical Multi-Agent Reinforcement Learning for Assessing False-Data Injection Attacks on Transportation Networks. (arXiv:2312.14625v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14625</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing reliance of drivers on navigation applications has made
transportation networks more susceptible to data-manipulation attacks by
malicious actors. Adversaries may exploit vulnerabilities in the data
collection or processing of navigation services to inject false information,
and to thus interfere with the drivers&apos; route selection. Such attacks can
significantly increase traffic congestions, resulting in substantial waste of
time and resources, and may even disrupt essential services that rely on road
networks. To assess the threat posed by such attacks, we introduce a
computational framework to find worst-case data-injection attacks against
transportation networks. First, we devise an adversarial model with a threat
actor who can manipulate drivers by increasing the travel times that they
perceive on certain roads. Then, we employ hierarchical multi-agent
reinforcement learning to find an approximate optimal adversarial strategy for
data manipulation. We demonstrate the applicability of our approach through
simulating attacks on the Sioux Falls, ND network topology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eghtesad_T/0/1/0/all/0/1&quot;&gt;Taha Eghtesad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Sirui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1&quot;&gt;Yevgeniy Vorobeychik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laszka_A/0/1/0/all/0/1&quot;&gt;Aron Laszka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14628">
<title>Towards more sustainable enterprise data and application management with cross silo Federated Learning and Analytics. (arXiv:2312.14628v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14628</link>
<description rdf:parseType="Literal">&lt;p&gt;To comply with new legal requirements and policies committed to privacy
protection, more and more companies start to deploy cross-silo Federated
Learning at global scale, where several clients/silos collaboratively train a
global model under the coordination of a central server. Instead of data
sharing and transmission, clients train models using their private local data
and exchange model updates. However, there is little understanding of the
carbon emission impact of cross silo Federated Learning due to the lack of
related works. In this study, we first analyze the sustainability aspect of
cross-silo Federated Learning, across the AI product life cycle instead of
focusing only on the model training, with the comparison to the centralized
method. A more holistic quantitative cost and CO2 emission estimation method
for real world cross-silo Federated Learning setting is proposed. Secondly, we
propose a novel data and application management system using cross silo
Federated Learning and analytics to make IT companies more sustainable and cost
effective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1&quot;&gt;Hongliu Cao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14634">
<title>Mining multi-modal communication patterns in interaction with explainable and non-explainable robots. (arXiv:2312.14634v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.14634</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate interaction patterns for humans interacting with explainable
and non-explainable robots. Non-explainable robots are here robots that do not
explain their actions or non-actions, neither do they give any other feedback
during interaction, in contrast to explainable robots. We video recorded and
analyzed human behavior during a board game, where 20 humans verbally
instructed either an explainable or non-explainable Pepper robot to move
objects on the board. The transcriptions and annotations of the videos were
transformed into transactions for association rule mining. Association rules
discovered communication patterns in the interaction between the robots and the
humans, and the most interesting rules were also tested with regular chi-square
tests. Some statistically significant results are that there is a strong
correlation between men and non-explainable robots and women and explainable
robots, and that humans mirror some of the robot&apos;s modality. Our results also
show that it is important to contextualize human interaction patterns, and that
this can be easily done using association rules as an investigative tool. The
presented results are important when designing robots that should adapt their
behavior to become understandable for the interacting humans.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bensch_S/0/1/0/all/0/1&quot;&gt;Suna Bensch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eriksson_A/0/1/0/all/0/1&quot;&gt;Amanda Eriksson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14635">
<title>Fluid Simulation on Neural Flow Maps. (arXiv:2312.14635v1 [cs.GR])</title>
<link>http://arxiv.org/abs/2312.14635</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Neural Flow Maps, a novel simulation method bridging the
emerging paradigm of implicit neural representations with fluid simulation
based on the theory of flow maps, to achieve state-of-the-art simulation of
inviscid fluid phenomena. We devise a novel hybrid neural field representation,
Spatially Sparse Neural Fields (SSNF), which fuses small neural networks with a
pyramid of overlapping, multi-resolution, and spatially sparse grids, to
compactly represent long-term spatiotemporal velocity fields at high accuracy.
With this neural velocity buffer in hand, we compute long-term, bidirectional
flow maps and their Jacobians in a mechanistically symmetric manner, to
facilitate drastic accuracy improvement over existing solutions. These
long-range, bidirectional flow maps enable high advection accuracy with low
dissipation, which in turn facilitates high-fidelity incompressible flow
simulations that manifest intricate vortical structures. We demonstrate the
efficacy of our neural fluid simulation in a variety of challenging simulation
scenarios, including leapfrogging vortices, colliding vortices, vortex
reconnections, as well as vortex generation from moving obstacles and density
differences. Our examples show increased performance over existing methods in
terms of energy conservation, visual complexity, adherence to experimental
observations, and preservation of detailed vortical structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yitong Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hong-Xing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Diyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1&quot;&gt;Bo Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14646">
<title>Collaborative Synthesis of Patient Records through Multi-Visit Health State Inference. (arXiv:2312.14646v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14646</link>
<description rdf:parseType="Literal">&lt;p&gt;Electronic health records (EHRs) have become the foundation of machine
learning applications in healthcare, while the utility of real patient records
is often limited by privacy and security concerns. Synthetic EHR generation
provides an additional perspective to compensate for this limitation. Most
existing methods synthesize new records based on real EHR data, without
consideration of different types of events in EHR data, which cannot control
the event combinations in line with medical common sense. In this paper, we
propose MSIC, a Multi-visit health Status Inference model for Collaborative EHR
synthesis to address these limitations. First, we formulate the synthetic EHR
generation process as a probabilistic graphical model and tightly connect
different types of events by modeling the latent health states. Then, we derive
a health state inference method tailored for the multi-visit scenario to
effectively utilize previous records to synthesize current and future records.
Furthermore, we propose to generate medical reports to add textual descriptions
for each medical event, providing broader applications for synthesized EHR
data. For generating different paragraphs in each visit, we incorporate a
multi-generator deliberation framework to collaborate the message passing of
multiple generators and employ a two-phase decoding strategy to generate
high-quality reports. Our extensive experiments on the widely used benchmarks,
MIMIC-III and MIMIC-IV, demonstrate that MSIC advances state-of-the-art results
on the quality of synthetic data while maintaining low privacy risks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Hongda Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hongzhan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1&quot;&gt;Rui Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14647">
<title>Pub/Sub Message Brokers for GenAI. (arXiv:2312.14647v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2312.14647</link>
<description rdf:parseType="Literal">&lt;p&gt;In today&apos;s digital world, Generative Artificial Intelligence (GenAI) such as
Large Language Models (LLMs) is becoming increasingly prevalent, extending its
reach across diverse applications. This surge in adoption has sparked a
significant increase in demand for data-centric GenAI models, highlighting the
necessity for robust data communication infrastructures. Central to this need
are message brokers, which serve as essential channels for data transfer within
various system components. This survey aims to delve into a comprehensive
analysis of traditional and modern message brokers, offering a comparative
study of prevalent platforms. Our study considers numerous criteria including,
but not limited to, open-source availability, integrated monitoring tools,
message prioritization mechanisms, capabilities for parallel processing,
reliability, distribution and clustering functionalities, authentication
processes, data persistence strategies, fault tolerance, and scalability.
Furthermore, we explore the intrinsic constraints that the design and operation
of each message broker might impose, recognizing that these limitations are
crucial in understanding their real-world applicability. We then leverage these
insights to propose a sophisticated message broker framework -- one designed
with the adaptability and robustness necessary to meet the evolving requisites
of GenAI applications. Finally, this study examines the enhancement of message
broker mechanisms specifically for GenAI contexts, emphasizing the criticality
of developing a versatile message broker framework. Such a framework would be
poised for quick adaptation, catering to the dynamic and growing demands of
GenAI in the foreseeable future. Through this dual-pronged approach, we intend
to contribute a foundational compendium that can guide future innovations and
infrastructural advancements in the realm of GenAI data communication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saleh_A/0/1/0/all/0/1&quot;&gt;Alaa Saleh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pirttikangas_S/0/1/0/all/0/1&quot;&gt;Susanna Pirttikangas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loven_L/0/1/0/all/0/1&quot;&gt;Lauri Lov&amp;#xe9;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14670">
<title>Zero-shot Causal Graph Extrapolation from Text via LLMs. (arXiv:2312.14670v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14670</link>
<description rdf:parseType="Literal">&lt;p&gt;We evaluate the ability of large language models (LLMs) to infer causal
relations from natural language. Compared to traditional natural language
processing and deep learning techniques, LLMs show competitive performance in a
benchmark of pairwise relations without needing (explicit) training samples.
This motivates us to extend our approach to extrapolating causal graphs through
iterated pairwise queries. We perform a preliminary analysis on a benchmark of
biomedical abstracts with ground-truth causal graphs validated by experts. The
results are promising and support the adoption of LLMs for such a crucial step
in causal inference, especially in medical domains, where the amount of
scientific text to analyse might be huge, and the causal statements are often
implicit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonucci_A/0/1/0/all/0/1&quot;&gt;Alessandro Antonucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pique_G/0/1/0/all/0/1&quot;&gt;Gregorio Piqu&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaffalon_M/0/1/0/all/0/1&quot;&gt;Marco Zaffalon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14677">
<title>MEAOD: Model Extraction Attack against Object Detectors. (arXiv:2312.14677v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.14677</link>
<description rdf:parseType="Literal">&lt;p&gt;The widespread use of deep learning technology across various industries has
made deep neural network models highly valuable and, as a result, attractive
targets for potential attackers. Model extraction attacks, particularly
query-based model extraction attacks, allow attackers to replicate a substitute
model with comparable functionality to the victim model and present a
significant threat to the confidentiality and security of MLaaS platforms.
While many studies have explored threats of model extraction attacks against
classification models in recent years, object detection models, which are more
frequently used in real-world scenarios, have received less attention. In this
paper, we investigate the challenges and feasibility of query-based model
extraction attacks against object detection models and propose an effective
attack method called MEAOD. It selects samples from the attacker-possessed
dataset to construct an efficient query dataset using active learning and
enhances the categories with insufficient objects. We additionally improve the
extraction effectiveness by updating the annotations of the query dataset.
According to our gray-box and black-box scenarios experiments, we achieve an
extraction performance of over 70% under the given condition of a 10k query
budget.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zeyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1&quot;&gt;Chenghui Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yuwen Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jinbao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1&quot;&gt;Shouling Ji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14681">
<title>Engineered Ordinary Differential Equations as Classification Algorithm (EODECA): thorough characterization and testing. (arXiv:2312.14681v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14681</link>
<description rdf:parseType="Literal">&lt;p&gt;EODECA (Engineered Ordinary Differential Equations as Classification
Algorithm) is a novel approach at the intersection of machine learning and
dynamical systems theory, presenting a unique framework for classification
tasks [1]. This method stands out with its dynamical system structure,
utilizing ordinary differential equations (ODEs) to efficiently handle complex
classification challenges. The paper delves into EODECA&apos;s dynamical properties,
emphasizing its resilience against random perturbations and robust performance
across various classification scenarios. Notably, EODECA&apos;s design incorporates
the ability to embed stable attractors in the phase space, enhancing
reliability and allowing for reversible dynamics. In this paper, we carry out a
comprehensive analysis by expanding on the work [1], and employing a Euler
discretization scheme. In particular, we evaluate EODECA&apos;s performance across
five distinct classification problems, examining its adaptability and
efficiency. Significantly, we demonstrate EODECA&apos;s effectiveness on the MNIST
and Fashion MNIST datasets, achieving impressive accuracies of $98.06\%$ and
$88.21\%$, respectively. These results are comparable to those of a multi-layer
perceptron (MLP), underscoring EODECA&apos;s potential in complex data processing
tasks. We further explore the model&apos;s learning journey, assessing its evolution
in both pre and post training environments and highlighting its ability to
navigate towards stable attractors. The study also investigates the
invertibility of EODECA, shedding light on its decision-making processes and
internal workings. This paper presents a significant step towards a more
transparent and robust machine learning paradigm, bridging the gap between
machine learning algorithms and dynamical systems methodologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marino_R/0/1/0/all/0/1&quot;&gt;Raffaele Marino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buffoni_L/0/1/0/all/0/1&quot;&gt;Lorenzo Buffoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chicchi_L/0/1/0/all/0/1&quot;&gt;Lorenzo Chicchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giambagli_L/0/1/0/all/0/1&quot;&gt;Lorenzo Giambagli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fanelli_D/0/1/0/all/0/1&quot;&gt;Duccio Fanelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14688">
<title>A Mathematical Guide to Operator Learning. (arXiv:2312.14688v1 [math.NA])</title>
<link>http://arxiv.org/abs/2312.14688</link>
<description rdf:parseType="Literal">&lt;p&gt;Operator learning aims to discover properties of an underlying dynamical
system or partial differential equation (PDE) from data. Here, we present a
step-by-step guide to operator learning. We explain the types of problems and
PDEs amenable to operator learning, discuss various neural network
architectures, and explain how to employ numerical PDE solvers effectively. We
also give advice on how to create and manage training data and conduct
optimization. We offer intuition behind the various neural network
architectures employed in operator learning by motivating them from the
point-of-view of numerical linear algebra.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Boulle_N/0/1/0/all/0/1&quot;&gt;Nicolas Boull&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Townsend_A/0/1/0/all/0/1&quot;&gt;Alex Townsend&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14721">
<title>Gerrymandering Planar Graphs. (arXiv:2312.14721v1 [cs.GT])</title>
<link>http://arxiv.org/abs/2312.14721</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the computational complexity of the map redistricting problem
(gerrymandering). Mathematically, the electoral district designer
(gerrymanderer) attempts to partition a weighted graph into $k$ connected
components (districts) such that its candidate (party) wins as many districts
as possible. Prior work has principally concerned the special cases where the
graph is a path or a tree. Our focus concerns the realistic case where the
graph is planar. We prove that the gerrymandering problem is solvable in
polynomial time in $\lambda$-outerplanar graphs, when the number of candidates
and $\lambda$ are constants and the vertex weights (voting weights) are
polynomially bounded. In contrast, the problem is NP-complete in general planar
graphs even with just two candidates. This motivates the study of approximation
algorithms for gerrymandering planar graphs. However, when the number of
candidates is large, we prove it is hard to distinguish between instances where
the gerrymanderer cannot win a single district and instances where the
gerrymanderer can win at least one district. This immediately implies that the
redistricting problem is inapproximable in polynomial time in planar graphs,
unless P=NP. This conclusion appears terminal for the design of good
approximation algorithms -- but it is not. The inapproximability bound can be
circumvented as it only applies when the maximum number of districts the
gerrymanderer can win is extremely small, say one. Indeed, for a fixed number
of candidates, our main result is that there is a constant factor approximation
algorithm for redistricting unweighted planar graphs, provided the optimal
value is a large enough constant.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dippel_J/0/1/0/all/0/1&quot;&gt;Jack Dippel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tour_M/0/1/0/all/0/1&quot;&gt;Max Dupr&amp;#xe9; la Tour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_A/0/1/0/all/0/1&quot;&gt;April Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vetta_A/0/1/0/all/0/1&quot;&gt;Adrian Vetta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14737">
<title>Computational Semantics and Evaluation Benchmark for Interrogative Sentences via Combinatory Categorial Grammar. (arXiv:2312.14737v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14737</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a compositional semantics for various types of polar questions and
wh-questions within the framework of Combinatory Categorial Grammar (CCG). To
assess the explanatory power of our proposed analysis, we introduce a
question-answering dataset QSEM specifically designed to evaluate the semantics
of interrogative sentences. We implement our analysis using existing CCG
parsers and conduct evaluations using the dataset. Through the evaluation, we
have obtained annotated data with CCG trees and semantic representations for
about half of the samples included in QSEM. Furthermore, we discuss the
discrepancy between the theoretical capacity of CCG and the capabilities of
existing CCG parsers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Funakura_H/0/1/0/all/0/1&quot;&gt;Hayate Funakura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mineshima_K/0/1/0/all/0/1&quot;&gt;Koji Mineshima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14769">
<title>Large Language Model (LLM) Bias Index -- LLMBI. (arXiv:2312.14769v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14769</link>
<description rdf:parseType="Literal">&lt;p&gt;The Large Language Model Bias Index (LLMBI) is a pioneering approach designed
to quantify and address biases inherent in large language models (LLMs), such
as GPT-4. We recognise the increasing prevalence and impact of LLMs across
diverse sectors. This research introduces a novel metric, LLMBI, to
systematically measure and mitigate biases potentially skewing model responses.
We formulated LLMBI using a composite scoring system incorporating multiple
dimensions of bias, including but not limited to age, gender, and racial
biases.
&lt;/p&gt;
&lt;p&gt;To operationalise this metric, we engaged in a multi-step process involving
collecting and annotating LLM responses, applying sophisticated Natural
Language Processing (NLP) techniques for bias detection, and computing the
LLMBI score through a specially crafted mathematical formula. The formula
integrates weighted averages of various bias dimensions, a penalty for dataset
diversity deficiencies, and a correction for sentiment biases. Our empirical
analysis, conducted using responses from OpenAI&apos;s API, employs advanced
sentiment analysis as a representative method for bias detection.
&lt;/p&gt;
&lt;p&gt;The research reveals LLMs, whilst demonstrating impressive capabilities in
text generation, exhibit varying degrees of bias across different dimensions.
LLMBI provides a quantifiable measure to compare biases across models and over
time, offering a vital tool for systems engineers, researchers and regulators
in enhancing the fairness and reliability of LLMs. It highlights the potential
of LLMs in mimicking unbiased human-like responses. Additionally, it
underscores the necessity of continuously monitoring and recalibrating such
models to align with evolving societal norms and ethical standards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oketunji_A/0/1/0/all/0/1&quot;&gt;Abiodun Finbarrs Oketunji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anas_M/0/1/0/all/0/1&quot;&gt;Muhammad Anas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saina_D/0/1/0/all/0/1&quot;&gt;Deepthi Saina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14792">
<title>The Rate-Distortion-Perception-Classification Tradeoff: Joint Source Coding and Modulation via Inverse-Domain GANs. (arXiv:2312.14792v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14792</link>
<description rdf:parseType="Literal">&lt;p&gt;The joint source coding and modulation (JSCM) framework was enabled by recent
developments in deep learning, which allows to automatically learn from data,
and in an end-to-end fashion, the best compression codes and modulation
schemes. In this paper, we show the existence of a strict tradeoff between
channel rate, distortion, perception, and classification accuracy in a JSCM
scenario. We then propose two image compression methods to navigate that
tradeoff: an inverse-domain generative adversarial network (ID-GAN), which
achieves extreme compression, and a simpler, heuristic method that reveals
insights about the performance of ID-GAN. Experiment results not only
corroborate the theoretical findings, but also demonstrate that the proposed
ID-GAN algorithm significantly improves system performance compared to
traditional separation-based methods and recent deep JSCM architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1&quot;&gt;Junli Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mota_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o F. C. Mota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_B/0/1/0/all/0/1&quot;&gt;Baoshan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weicheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1&quot;&gt;Xuemin Hong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14794">
<title>An Empirical Study on Compliance with Ranking Transparency in the Software Documentation of EU Online Platforms. (arXiv:2312.14794v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2312.14794</link>
<description rdf:parseType="Literal">&lt;p&gt;Compliance with the European Union&apos;s Platform-to-Business (P2B) Regulation is
challenging for online platforms, and assessing their compliance can be
difficult for public authorities. This is partly due to the lack of automated
tools for assessing the information (e.g., software documentation) platforms
provide concerning ranking transparency. Our study tackles this issue in two
ways. First, we empirically evaluate the compliance of six major platforms
(Amazon, Bing, Booking, Google, Tripadvisor, and Yahoo), revealing substantial
differences in their documentation. Second, we introduce and test automated
compliance assessment tools based on ChatGPT and information retrieval
technology. These tools are evaluated against human judgments, showing
promising results as reliable proxies for compliance assessments. Our findings
could help enhance regulatory compliance and align with the United Nations
Sustainable Development Goal 10.3, which seeks to reduce inequality, including
business disparities, on these platforms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sovrano_F/0/1/0/all/0/1&quot;&gt;Francesco Sovrano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lognoul_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#xeb;l Lognoul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacchelli_A/0/1/0/all/0/1&quot;&gt;Alberto Bacchelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14808">
<title>A Tricycle Model to Accurately Control an Autonomous Racecar with Locked Differential. (arXiv:2312.14808v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2312.14808</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a novel formulation to model the effects of a
locked differential on the lateral dynamics of an autonomous open-wheel
racecar. The model is used in a Model Predictive Controller in which we
included a micro-steps discretization approach to accurately linearize the
dynamics and produce a prediction suitable for real-time implementation. The
stability analysis of the model is presented, as well as a brief description of
the overall planning and control scheme which includes an offline trajectory
generation pipeline, an online local speed profile planner, and a low-level
longitudinal controller. An improvement of the lateral path tracking is
demonstrated in preliminary experimental results that have been produced on a
Dallara AV-21 during the first Indy Autonomous Challenge event on the Monza F1
racetrack. Final adjustments and tuning have been performed in a high-fidelity
simulator demonstrating the effectiveness of the solution when performing close
to the tire limits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Raji_A/0/1/0/all/0/1&quot;&gt;Ayoub Raji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Musiu_N/0/1/0/all/0/1&quot;&gt;Nicola Musiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Toschi_A/0/1/0/all/0/1&quot;&gt;Alessandro Toschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Prignoli_F/0/1/0/all/0/1&quot;&gt;Francesco Prignoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mascaro_E/0/1/0/all/0/1&quot;&gt;Eugenio Mascaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Musso_P/0/1/0/all/0/1&quot;&gt;Pietro Musso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Amerotti_F/0/1/0/all/0/1&quot;&gt;Francesco Amerotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liniger_A/0/1/0/all/0/1&quot;&gt;Alexander Liniger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sorrentino_S/0/1/0/all/0/1&quot;&gt;Silvio Sorrentino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bertogna_M/0/1/0/all/0/1&quot;&gt;Marko Bertogna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14824">
<title>An investigation of belief-free DRL and MCTS for inspection and maintenance planning. (arXiv:2312.14824v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14824</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel Deep Reinforcement Learning (DRL) architecture for
sequential decision processes under uncertainty, as encountered in inspection
and maintenance (I&amp;amp;M) planning. Unlike other DRL algorithms for (I&amp;amp;M) planning,
the proposed +RQN architecture dispenses with computing the belief state and
directly handles erroneous observations instead. We apply the algorithm to a
basic I&amp;amp;M planning problem for a one-component system subject to deterioration.
In addition, we investigate the performance of Monte Carlo tree search for the
I&amp;amp;M problem and compare it to the +RQN. The comparison includes a statistical
analysis of the two methods&apos; resulting policies, as well as their visualization
in the belief space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koutas_D/0/1/0/all/0/1&quot;&gt;Daniel Koutas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bismut_E/0/1/0/all/0/1&quot;&gt;Elizabeth Bismut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Straub_D/0/1/0/all/0/1&quot;&gt;Daniel Straub&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14836">
<title>Learning Lagrangian Multipliers for the Travelling Salesman Problem. (arXiv:2312.14836v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14836</link>
<description rdf:parseType="Literal">&lt;p&gt;Lagrangian relaxation is a versatile mathematical technique employed to relax
constraints in an optimization problem, enabling the generation of dual bounds
to prove the optimality of feasible solutions and the design of efficient
propagators in constraint programming (such as the weighted circuit
constraint). However, the conventional process of deriving Lagrangian
multipliers (e.g., using subgradient methods) is often computationally
intensive, limiting its practicality for large-scale or time-sensitive
problems. To address this challenge, we propose an innovative unsupervised
learning approach that harnesses the capabilities of graph neural networks to
exploit the problem structure, aiming to generate accurate Lagrangian
multipliers efficiently. We apply this technique to the well-known Held-Karp
Lagrangian relaxation for the travelling salesman problem. The core idea is to
predict accurate Lagrangian multipliers and to employ them as a warm start for
generating Held-Karp relaxation bounds. These bounds are subsequently utilized
to enhance the filtering process carried out by branch-and-bound algorithms. In
contrast to much of the existing literature, which primarily focuses on finding
feasible solutions, our approach operates on the dual side, demonstrating that
learning can also accelerate the proof of optimality. We conduct experiments
across various distributions of the metric travelling salesman problem,
considering instances with up to 200 cities. The results illustrate that our
approach can improve the filtering level of the weighted circuit global
constraint, reduce the optimality gap by a factor two for unsolved instances up
to a timeout, and reduce the execution time for solved instances by 10%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parjadis_A/0/1/0/all/0/1&quot;&gt;Augustin Parjadis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cappart_Q/0/1/0/all/0/1&quot;&gt;Quentin Cappart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1&quot;&gt;Bistra Dilkina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1&quot;&gt;Aaron Ferber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rousseau_L/0/1/0/all/0/1&quot;&gt;Louis-Martin Rousseau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14852">
<title>TACO: Topics in Algorithmic COde generation dataset. (arXiv:2312.14852v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14852</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce TACO, an open-source, large-scale code generation dataset, with
a focus on the optics of algorithms, designed to provide a more challenging
training dataset and evaluation benchmark in the field of code generation
models. TACO includes competition-level programming questions that are more
challenging, to enhance or evaluate problem understanding and reasoning
abilities in real-world programming scenarios. There are 25433 and 1000 coding
problems in training and test set, as well as up to 1.55 million diverse
solution answers. Moreover, each TACO problem includes several fine-grained
labels such as task topics, algorithms, programming skills, and difficulty
levels, providing a more precise reference for the training and evaluation of
code generation models. The dataset and evaluation scripts are available on
Hugging Face Hub (https://huggingface.co/datasets/BAAI/TACO) and Github
(https://github.com/FlagOpen/TACO).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Rongao Li&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jie Fu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bo-Wen Zhang&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Tao Huang&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zhihong Sun&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_C/0/1/0/all/0/1&quot;&gt;Chen Lyu&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guang Liu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1&quot;&gt;Zhi Jin&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Ge Li&lt;/a&gt; (3) ((1) Beijing Academy of Artificial Intelligence, (2) School of Information Science and Engineering, Shandong Normal University, China, (3) Key Lab of HCST (PKU), MOE, SCS, Peking University, China)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14856">
<title>Turbulence: Systematically and Automatically Testing Instruction-Tuned Large Language Models for Code. (arXiv:2312.14856v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2312.14856</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for systematically evaluating the correctness and
robustness of instruction-tuned large language models (LLMs) for code
generation via a new benchmark, Turbulence. Turbulence consists of a large set
of natural language $\textit{question templates}$, each of which is a
programming problem, parameterised so that it can be asked in many different
forms. Each question template has an associated $\textit{test oracle}$ that
judges whether a code solution returned by an LLM is correct. Thus, from a
single question template, it is possible to ask an LLM a
$\textit{neighbourhood}$ of very similar programming questions, and assess the
correctness of the result returned for each question. This allows gaps in an
LLM&apos;s code generation abilities to be identified, including
$\textit{anomalies}$ where the LLM correctly solves $\textit{almost all}$
questions in a neighbourhood but fails for particular parameter instantiations.
We present experiments against five LLMs from OpenAI, Cohere and Meta, each at
two temperature configurations. Our findings show that, across the board,
Turbulence is able to reveal gaps in LLM reasoning ability. This goes beyond
merely highlighting that LLMs sometimes produce wrong code (which is no
surprise): by systematically identifying cases where LLMs are able to solve
some problems in a neighbourhood but do not manage to generalise to solve the
whole neighbourhood, our method is effective at highlighting
$\textit{robustness}$ issues. We present data and examples that shed light on
the kinds of mistakes that LLMs make when they return incorrect code results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honarvar_S/0/1/0/all/0/1&quot;&gt;Shahin Honarvar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilk_M/0/1/0/all/0/1&quot;&gt;Mark van der Wilk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donaldson_A/0/1/0/all/0/1&quot;&gt;Alastair Donaldson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14862">
<title>YAYI 2: Multilingual Open-Source Large Language Models. (arXiv:2312.14862v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14862</link>
<description rdf:parseType="Literal">&lt;p&gt;As the latest advancements in natural language processing, large language
models (LLMs) have achieved human-level language understanding and generation
abilities in many real-world tasks, and even have been regarded as a potential
path to the artificial general intelligence. To better facilitate research on
LLMs, many open-source LLMs, such as Llama 2 and Falcon, have recently been
proposed and gained comparable performances to proprietary models. However,
these models are primarily designed for English scenarios and exhibit poor
performances in Chinese contexts. In this technical report, we propose YAYI 2,
including both base and chat models, with 30 billion parameters. YAYI 2 is
pre-trained from scratch on a multilingual corpus which contains 2.65 trillion
tokens filtered by our pre-training data processing pipeline. The base model is
aligned with human values through supervised fine-tuning with millions of
instructions and reinforcement learning from human feedback. Extensive
experiments on multiple benchmarks, such as MMLU and CMMLU, consistently
demonstrate that the proposed YAYI 2 outperforms other similar sized
open-source models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yin Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1&quot;&gt;Qingchao Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1&quot;&gt;Nan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1&quot;&gt;Jia Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_B/0/1/0/all/0/1&quot;&gt;Bao Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_B/0/1/0/all/0/1&quot;&gt;Baoyu Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Bo Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Chao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1&quot;&gt;Chenyang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Donglei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1&quot;&gt;Fan Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1&quot;&gt;Feifei Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Hailong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hanxuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1&quot;&gt;Haojun Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hongyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jianbin Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1&quot;&gt;Jiangtao Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jingyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Junfeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Lei Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Liduo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1&quot;&gt;Lifeng Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lili Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liwen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Minzheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Pin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Ping Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qingxiao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1&quot;&gt;Rui Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_R/0/1/0/all/0/1&quot;&gt;Rui Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ruiqun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Taiwen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaodong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaofei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1&quot;&gt;Xin Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xina Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1&quot;&gt;Xing Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1&quot;&gt;Xinglin Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1&quot;&gt;Yanni Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yao Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yigang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Ying Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yongyu Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yungan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhangsheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhaoxin Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1&quot;&gt;Zhen Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_W/0/1/0/all/0/1&quot;&gt;Wenji Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1&quot;&gt;Dajun Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14867">
<title>VIEScore: Towards Explainable Metrics for Conditional Image Synthesis Evaluation. (arXiv:2312.14867v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.14867</link>
<description rdf:parseType="Literal">&lt;p&gt;In the rapidly advancing field of conditional image generation research,
challenges such as limited explainability lie in effectively evaluating the
performance and capabilities of various models. This paper introduces VIESCORE,
a Visual Instruction-guided Explainable metric for evaluating any conditional
image generation tasks. VIESCORE leverages general knowledge from Multimodal
Large Language Models (MLLMs) as the backbone and does not require training or
fine-tuning. We evaluate VIESCORE on seven prominent tasks in conditional image
tasks and found: (1) VIESCORE (GPT4-v) achieves a high Spearman correlation of
0.3 with human evaluations, while the human-to-human correlation is 0.45. (2)
VIESCORE (with open-source MLLM) is significantly weaker than GPT-4v in
evaluating synthetic images. (3) VIESCORE achieves a correlation on par with
human ratings in the generation tasks but struggles in editing tasks. With
these results, we believe VIESCORE shows its great potential to replace human
judges in evaluating image synthesis tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ku_M/0/1/0/all/0/1&quot;&gt;Max Ku&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1&quot;&gt;Dongfu Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1&quot;&gt;Cong Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1&quot;&gt;Xiang Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wenhu Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14871">
<title>BrainVis: Exploring the Bridge between Brain and Visual Signals via Image Reconstruction. (arXiv:2312.14871v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.14871</link>
<description rdf:parseType="Literal">&lt;p&gt;Analyzing and reconstructing visual stimuli from brain signals effectively
advances understanding of the human visual system. However, the EEG signals are
complex and contain a amount of noise. This leads to substantial limitations in
existing works of visual stimuli reconstruction from EEG, such as difficulties
in aligning EEG embeddings with the fine-grained semantic information and a
heavy reliance on additional large self-collected dataset for training. To
address these challenges, we propose a novel approach called BrainVis. Firstly,
we divide the EEG signals into various units and apply a self-supervised
approach on them to obtain EEG time-domain features, in an attempt to ease the
training difficulty. Additionally, we also propose to utilize the
frequency-domain features to enhance the EEG representations. Then, we
simultaneously align EEG time-frequency embeddings with the interpolation of
the coarse and fine-grained semantics in the CLIP space, to highlight the
primary visual components and reduce the cross-modal alignment difficulty.
Finally, we adopt the cascaded diffusion models to reconstruct images. Our
proposed BrainVis outperforms state of the arts in both semantic fidelity
reconstruction and generation quality. Notably, we reduce the training data
scale to 10% of the previous work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1&quot;&gt;Honghao Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zhiqi Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chin_J/0/1/0/all/0/1&quot;&gt;Jing Jih Chin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hao Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14875">
<title>Automating the Design of Multigrid Methods with Evolutionary Program Synthesis. (arXiv:2312.14875v1 [math.NA])</title>
<link>http://arxiv.org/abs/2312.14875</link>
<description rdf:parseType="Literal">&lt;p&gt;Many of the most fundamental laws of nature can be formulated as partial
differential equations (PDEs). Understanding these equations is, therefore, of
exceptional importance for many branches of modern science and engineering.
However, since the general solution of many PDEs is unknown, the efficient
approximate solution of these equations is one of humanity&apos;s greatest
challenges. While multigrid represents one of the most effective methods for
solving PDEs numerically, in many cases, the design of an efficient or at least
working multigrid solver is an open problem. This thesis demonstrates that
grammar-guided genetic programming, an evolutionary program synthesis
technique, can discover multigrid methods of unprecedented structure that
achieve a high degree of efficiency and generalization. For this purpose, we
develop a novel context-free grammar that enables the automated generation of
multigrid methods in a symbolically-manipulable formal language, based on which
we can apply the same multigrid-based solver to problems of different sizes
without having to adapt its internal structure. Treating the automated design
of an efficient multigrid method as a program synthesis task allows us to find
novel sequences of multigrid operations, including the combination of different
smoothing and coarse-grid correction steps on each level of the discretization
hierarchy. To prove the feasibility of this approach, we present its
implementation in the form of the Python framework EvoStencils, which is freely
available as open-source software. This implementation comprises all steps from
representing the algorithmic sequence of a multigrid method in the form of a
directed acyclic graph of Python objects to its automatic generation and
optimization using the capabilities of the code generation framework
ExaStencils and the evolutionary computation library DEAP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schmitt_J/0/1/0/all/0/1&quot;&gt;Jonas Schmitt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14877">
<title>Robust Knowledge Extraction from Large Language Models using Social Choice Theory. (arXiv:2312.14877v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.14877</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-language models (LLMs) have the potential to support a wide range of
applications like conversational agents, creative writing, text improvement,
and general query answering. However, they are ill-suited for query answering
in high-stake domains like medicine because they generate answers at random and
their answers are typically not robust - even the same query can result in
different answers when prompted multiple times. In order to improve the
robustness of LLM queries, we propose using ranking queries repeatedly and to
aggregate the queries using methods from social choice theory. We study ranking
queries in diagnostic settings like medical and fault diagnosis and discuss how
the Partial Borda Choice function from the literature can be applied to merge
multiple query results. We discuss some additional interesting properties in
our setting and evaluate the robustness of our approach empirically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potyka_N/0/1/0/all/0/1&quot;&gt;Nico Potyka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yuqicheng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yunjie He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kharlamov_E/0/1/0/all/0/1&quot;&gt;Evgeny Kharlamov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Staab_S/0/1/0/all/0/1&quot;&gt;Steffen Staab&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14878">
<title>Pangu-Agent: A Fine-Tunable Generalist Agent with Structured Reasoning. (arXiv:2312.14878v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14878</link>
<description rdf:parseType="Literal">&lt;p&gt;A key method for creating Artificial Intelligence (AI) agents is
Reinforcement Learning (RL). However, constructing a standalone RL policy that
maps perception to action directly encounters severe problems, chief among them
being its lack of generality across multiple tasks and the need for a large
amount of training data. The leading cause is that it cannot effectively
integrate prior information into the perception-action cycle when devising the
policy. Large language models (LLMs) emerged as a fundamental way to
incorporate cross-domain knowledge into AI agents but lack crucial learning and
adaptation toward specific decision problems. This paper presents a general
framework model for integrating and learning structured reasoning into AI
agents&apos; policies. Our methodology is motivated by the modularity found in the
human brain. The framework utilises the construction of intrinsic and extrinsic
functions to add previous understandings of reasoning structures. It also
provides the adaptive ability to learn models inside every module or function,
consistent with the modular structure of cognitive processes. We describe the
framework in-depth and compare it with other AI pipelines and existing
frameworks. The paper explores practical applications, covering experiments
that show the effectiveness of our method. Our results indicate that AI agents
perform and adapt far better when organised reasoning and prior knowledge are
embedded. This opens the door to more resilient and general AI agent systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1&quot;&gt;Filippos Christianos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papoudakis_G/0/1/0/all/0/1&quot;&gt;Georgios Papoudakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zimmer_M/0/1/0/all/0/1&quot;&gt;Matthieu Zimmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coste_T/0/1/0/all/0/1&quot;&gt;Thomas Coste&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhihao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jingxuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khandelwal_K/0/1/0/all/0/1&quot;&gt;Khyati Khandelwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doran_J/0/1/0/all/0/1&quot;&gt;James Doran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1&quot;&gt;Xidong Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiacheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zheng Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yicheng Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1&quot;&gt;Jianye Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_K/0/1/0/all/0/1&quot;&gt;Kun Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bou_Ammar_H/0/1/0/all/0/1&quot;&gt;Haitham Bou-Ammar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14880">
<title>SutraNets: Sub-series Autoregressive Networks for Long-Sequence, Probabilistic Forecasting. (arXiv:2312.14880v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14880</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose SutraNets, a novel method for neural probabilistic forecasting of
long-sequence time series. SutraNets use an autoregressive generative model to
factorize the likelihood of long sequences into products of conditional
probabilities. When generating long sequences, most autoregressive approaches
suffer from harmful error accumulation, as well as challenges in modeling
long-distance dependencies. SutraNets treat long, univariate prediction as
multivariate prediction over lower-frequency sub-series. Autoregression
proceeds across time and across sub-series in order to ensure coherent
multivariate (and, hence, high-frequency univariate) outputs. Since sub-series
can be generated using fewer steps, SutraNets effectively reduce error
accumulation and signal path distances. We find SutraNets to significantly
improve forecasting accuracy over competitive alternatives on six real-world
datasets, including when we vary the number of sub-series and scale up the
depth and width of the underlying sequence models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergsma_S/0/1/0/all/0/1&quot;&gt;Shane Bergsma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeyl_T/0/1/0/all/0/1&quot;&gt;Timothy Zeyl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1&quot;&gt;Lei Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14890">
<title>NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes. (arXiv:2312.14890v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.14890</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex reasoning ability is one of the most important features of current
LLMs, which has also been leveraged to play an integral role in complex
decision-making tasks. Therefore, the investigation into the reasoning
capabilities of Large Language Models (LLMs) is critical: numerous benchmarks
have been established to assess the reasoning abilities of LLMs. However,
current benchmarks are inadequate in offering a rigorous evaluation of the full
extent of reasoning abilities that LLMs are capable of achieving. They are also
prone to the risk of overfitting, as these benchmarks, being publicly
accessible and static, allow models to potentially tailor their responses to
specific benchmark metrics, thereby inflating their performance. Addressing
these limitations, our research introduces a new benchmark, named NPHardEval.
This benchmark is designed to evaluate the reasoning abilities of LLMs across a
broad spectrum of 900 algorithmic questions, extending up to the NP-Hard
complexity class. These questions are meticulously chosen to represent a wide
range of complexity class below the NP-hard complexity class, offering a
rigorous measure of the reasoning ability of LLMs. Through this study, we shed
light on the current state of reasoning in LLMs, providing an objective and
rigorous perspective through the comparison of LLMs&apos; performance across complex
classes. Moreover, this benchmark is designed with a dynamic update mechanism,
where the datapoints are refreshed on a monthly basis. Such regular updates
play a crucial role in mitigating the risk of LLMs overfitting to the
benchmark, promoting a more accurate and reliable assessment of their reasoning
capabilities. The benchmark dataset and code of NPHardEval are available at
https://github.com/casmlab/NPHardEval.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Lizhou Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1&quot;&gt;Wenyue Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lingyao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1&quot;&gt;Haoyang Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yongfeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemphill_L/0/1/0/all/0/1&quot;&gt;Libby Hemphill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14895">
<title>FAST: Feature Aware Similarity Thresholding for Weak Unlearning in Black-Box Generative Models. (arXiv:2312.14895v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14895</link>
<description rdf:parseType="Literal">&lt;p&gt;The heightened emphasis on the regulation of deep generative models,
propelled by escalating concerns pertaining to privacy and compliance with
regulatory frameworks, underscores the imperative need for precise control
mechanisms over these models. This urgency is particularly underscored by
instances in which generative models generate outputs that encompass
objectionable, offensive, or potentially injurious content. In response,
machine unlearning has emerged to selectively forget specific knowledge or
remove the influence of undesirable data subsets from pre-trained models.
However, modern machine unlearning approaches typically assume access to model
parameters and architectural details during unlearning, which is not always
feasible. In multitude of downstream tasks, these models function as black-box
systems, with inaccessible pre-trained parameters, architectures, and training
data. In such scenarios, the possibility of filtering undesired outputs becomes
a practical alternative. The primary goal of this study is twofold: first, to
elucidate the relationship between filtering and unlearning processes, and
second, to formulate a methodology aimed at mitigating the display of
undesirable outputs generated from models characterized as black-box systems.
Theoretical analysis in this study demonstrates that, in the context of
black-box models, filtering can be seen as a form of weak unlearning. Our
proposed \textbf{\textit{Feature Aware Similarity Thresholding(FAST)}} method
effectively suppresses undesired outputs by systematically encoding the
representation of unwanted features in the latent space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panda_S/0/1/0/all/0/1&quot;&gt;Subhodip Panda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+AP_P/0/1/0/all/0/1&quot;&gt;Prathosh AP&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14920">
<title>A Novel Sampled Clustering Algorithm for Rice Phenotypic Data. (arXiv:2312.14920v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.14920</link>
<description rdf:parseType="Literal">&lt;p&gt;Phenotypic (or Physical) characteristics of plant species are commonly used
to perform clustering. In one of our recent works (Shastri et al. (2021)), we
used a probabilistically sampled (using pivotal sampling) and spectrally
clustered algorithm to group soybean species. These techniques were used to
obtain highly accurate clusterings at a reduced cost. In this work, we extend
the earlier algorithm to cluster rice species. We improve the base algorithm in
three ways. First, we propose a new function to build the similarity matrix in
Spectral Clustering. Commonly, a natural exponential function is used for this
purpose. Based upon the spectral graph theory and the involved Cheeger&apos;s
inequality, we propose the use a base &quot;a&quot; exponential function instead. This
gives a similarity matrix spectrum favorable for clustering, which we support
via an eigenvalue analysis.
&lt;/p&gt;
&lt;p&gt;Second, the function used to build the similarity matrix in Spectral
Clustering was earlier scaled with a fixed factor (called global scaling).
Based upon the idea of Zelnik-Manor and Perona (2004), we now use a factor that
varies with matrix elements (called local scaling) and works better. Third, to
compute the inclusion probability of a specie in the pivotal sampling
algorithm, we had earlier used the notion of deviation that captured how far
specie&apos;s characteristic values were from their respective base values (computed
over all species). A maximum function was used before to find the base values.
We now use a median function, which is more intuitive. We support this choice
using a statistical analysis. With experiments on 1865 rice species, we
demonstrate that in terms of silhouette values, our new Sampled Spectral
Clustering is 61% better than Hierarchical Clustering (currently prevalent).
Also, our new algorithm is significantly faster than Hierarchical Clustering
due to the involved sampling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Mithun Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1&quot;&gt;Kapil Ahuja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratnaparkhe_M/0/1/0/all/0/1&quot;&gt;Milind B. Ratnaparkhe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14924">
<title>Training Convolutional Neural Networks with the Forward-Forward algorithm. (arXiv:2312.14924v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.14924</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent successes in analyzing images with deep neural networks are almost
exclusively achieved with Convolutional Neural Networks (CNNs). The training of
these CNNs, and in fact of all deep neural network architectures, uses the
backpropagation algorithm where the output of the network is compared with the
desired result and the difference is then used to tune the weights of the
network towards the desired outcome. In a 2022 preprint, Geoffrey Hinton
suggested an alternative way of training which passes the desired results
together with the images at the input of the network. This so called Forward
Forward (FF) algorithm has up to now only been used in fully connected
networks. In this paper, we show how the FF paradigm can be extended to CNNs.
Our FF-trained CNN, featuring a novel spatially-extended labeling technique,
achieves a classification accuracy of 99.0% on the MNIST hand-written digits
dataset. We show how different hyperparameters affect the performance of the
proposed algorithm and compare the results with CNN trained with the standard
backpropagation approach. Furthermore, we use Class Activation Maps to
investigate which type of features are learnt by the FF algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scodellaro_R/0/1/0/all/0/1&quot;&gt;Riccardo Scodellaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1&quot;&gt;Ajinkya Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alves_F/0/1/0/all/0/1&quot;&gt;Frauke Alves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schroter_M/0/1/0/all/0/1&quot;&gt;Matthias Schr&amp;#xf6;ter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.03131">
<title>Explainability as statistical inference. (arXiv:2212.03131v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.03131</link>
<description rdf:parseType="Literal">&lt;p&gt;A wide variety of model explanation approaches have been proposed in recent
years, all guided by very different rationales and heuristics. In this paper,
we take a new route and cast interpretability as a statistical inference
problem. We propose a general deep probabilistic model designed to produce
interpretable predictions. The model parameters can be learned via maximum
likelihood, and the method can be adapted to any predictor network architecture
and any type of prediction problem. Our method is a case of amortized
interpretability models, where a neural network is used as a selector to allow
for fast interpretation at inference time. Several popular interpretability
methods are shown to be particular cases of regularised maximum likelihood for
our general model. We propose new datasets with ground truth selection which
allow for the evaluation of the features importance map. Using these datasets,
we show experimentally that using multiple imputation provides more reasonable
interpretations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Senetaire_H/0/1/0/all/0/1&quot;&gt;Hugo Henri Joseph Senetaire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garreau_D/0/1/0/all/0/1&quot;&gt;Damien Garreau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1&quot;&gt;Jes Frellsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mattei_P/0/1/0/all/0/1&quot;&gt;Pierre-Alexandre Mattei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.11997">
<title>Prompt-Based Editing for Text Style Transfer. (arXiv:2301.11997v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2301.11997</link>
<description rdf:parseType="Literal">&lt;p&gt;Prompting approaches have been recently explored in text style transfer,
where a textual prompt is used to query a pretrained language model to generate
style-transferred texts word by word in an autoregressive manner. However, such
a generation process is less controllable and early prediction errors may
affect future word predictions. In this paper, we present a prompt-based
editing approach for text style transfer. Specifically, we prompt a pretrained
language model for style classification and use the classification probability
to compute a style score. Then, we perform discrete search with word-level
editing to maximize a comprehensive scoring function for the style-transfer
task. In this way, we transform a prompt-based generation problem into a
classification one, which is a training-free process and more controllable than
the autoregressive generation of sentences. In our experiments, we performed
both automatic and human evaluation on three style-transfer benchmark datasets,
and show that our approach largely outperforms the state-of-the-art systems
that have 20 times more parameters. Additional empirical analyses further
demonstrate the effectiveness of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1&quot;&gt;Guoqing Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yu Tong Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1&quot;&gt;Lili Mou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Firdaus_M/0/1/0/all/0/1&quot;&gt;Mauajama Firdaus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.01250">
<title>Identifying regions of importance in wall-bounded turbulence through explainable deep learning. (arXiv:2302.01250v3 [physics.flu-dyn] UPDATED)</title>
<link>http://arxiv.org/abs/2302.01250</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite its great scientific and technological importance, wall-bounded
turbulence is an unresolved problem in classical physics that requires new
perspectives to be tackled. One of the key strategies has been to study
interactions among the energy-containing coherent structures in the flow. Such
interactions are explored in this study for the first time using an explainable
deep-learning method. The instantaneous velocity field obtained from a
turbulent channel flow simulation is used to predict the velocity field in time
through a U-net architecture. Based on the predicted flow, we assess the
importance of each structure for this prediction using the game-theoretic
algorithm of SHapley Additive exPlanations (SHAP). This work provides results
in agreement with previous observations in the literature and extends them by
revealing that the most important structures in the flow are not necessarily
the ones with the highest contribution to the Reynolds shear stress. We also
apply the method to an experimental database, where we can identify completely
new structures based on their importance score. This framework has the
potential to shed light on numerous fundamental phenomena of wall-bounded
turbulence, including novel strategies for flow control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Cremades_A/0/1/0/all/0/1&quot;&gt;Andres Cremades&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hoyas_S/0/1/0/all/0/1&quot;&gt;Sergio Hoyas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Deshpande_R/0/1/0/all/0/1&quot;&gt;Rahul Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Quintero_P/0/1/0/all/0/1&quot;&gt;Pedro Quintero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lellep_M/0/1/0/all/0/1&quot;&gt;Martin Lellep&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lee_W/0/1/0/all/0/1&quot;&gt;Will Junghoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Monty_J/0/1/0/all/0/1&quot;&gt;Jason Monty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hutchins_N/0/1/0/all/0/1&quot;&gt;Nicholas Hutchins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Linkmann_M/0/1/0/all/0/1&quot;&gt;Moritz Linkmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Marusic_I/0/1/0/all/0/1&quot;&gt;Ivan Marusic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Vinuesa_R/0/1/0/all/0/1&quot;&gt;Ricardo Vinuesa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.10510">
<title>Future Aware Pricing and Matching for Sustainable On-demand Ride Pooling. (arXiv:2302.10510v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2302.10510</link>
<description rdf:parseType="Literal">&lt;p&gt;The popularity of on-demand ride pooling is owing to the benefits offered to
customers (lower prices), taxi drivers (higher revenue), environment (lower
carbon footprint due to fewer vehicles) and aggregation companies like Uber
(higher revenue). To achieve these benefits, two key interlinked challenges
have to be solved effectively: (a) pricing -- setting prices to customer
requests for taxis; and (b) matching -- assignment of customers (that accepted
the prices) to taxis/cars. Traditionally, both these challenges have been
studied individually and using myopic approaches (considering only current
requests), without considering the impact of current matching on addressing
future requests. In this paper, we develop a novel framework that handles the
pricing and matching problems together, while also considering the future
impact of the pricing and matching decisions. In our experimental results on a
real-world taxi dataset, we demonstrate that our framework can significantly
improve revenue (up to 17% and on average 6.4%) in a sustainable manner by
reducing the number of vehicles (up to 14% and on average 10.6%) required to
obtain a given fixed revenue and the overall distance travelled by vehicles (up
to 11.1% and on average 3.7%). That is to say, we are able to provide an ideal
win-win scenario for all stakeholders (customers, drivers, aggregator,
environment) involved by obtaining higher revenue for customers, drivers,
aggregator (ride pooling company) while being good for the environment (due to
fewer number of vehicles on the road and lesser fuel consumed).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xianjie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varakantham_P/0/1/0/all/0/1&quot;&gt;Pradeep Varakantham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Hao Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.04164">
<title>Gradient Sparsification for Efficient Wireless Federated Learning with Differential Privacy. (arXiv:2304.04164v3 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2304.04164</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) enables distributed clients to collaboratively train
a machine learning model without sharing raw data with each other. However, it
suffers the leakage of private information from uploading models. In addition,
as the model size grows, the training latency increases due to limited
transmission bandwidth and the model performance degrades while using
differential privacy (DP) protection. In this paper, we propose a gradient
sparsification empowered FL framework over wireless channels, in order to
improve training efficiency without sacrificing convergence performance.
Specifically, we first design a random sparsification algorithm to retain a
fraction of the gradient elements in each client&apos;s local training, thereby
mitigating the performance degradation induced by DP and and reducing the
number of transmission parameters over wireless channels. Then, we analyze the
convergence bound of the proposed algorithm, by modeling a non-convex FL
problem. Next, we formulate a time-sequential stochastic optimization problem
for minimizing the developed convergence bound, under the constraints of
transmit power, the average transmitting delay, as well as the client&apos;s DP
requirement. Utilizing the Lyapunov drift-plus-penalty framework, we develop an
analytical solution to the optimization problem. Extensive experiments have
been implemented on three real life datasets to demonstrate the effectiveness
of our proposed algorithm. We show that our proposed algorithms can fully
exploit the interworking between communication and computation to outperform
the baselines, i.e., random scheduling, round robin and delay-minimization
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_K/0/1/0/all/0/1&quot;&gt;Kang Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Ming Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_F/0/1/0/all/0/1&quot;&gt;Feng Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Haitao Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hongbo Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.01658">
<title>FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework. (arXiv:2305.01658v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.01658</link>
<description rdf:parseType="Literal">&lt;p&gt;Flight Trajectory Prediction (FTP) is an essential task in Air Traffic
Control (ATC), which can assist air traffic controllers in managing airspace
more safely and efficiently. Existing approaches generally perform
multi-horizon FTP tasks in an autoregressive manner, thereby suffering from
error accumulation and low-efficiency problems. In this paper, a novel
framework, called FlightBERT++, is proposed to i) forecast multi-horizon flight
trajectories directly in a non-autoregressive way, and ii) improve the
limitation of the binary encoding (BE) representation in the FlightBERT.
Specifically, the FlightBERT++ is implemented by a generalized encoder-decoder
architecture, in which the encoder learns the temporal-spatial patterns from
historical observations and the decoder predicts the flight status for the
future horizons. Compared with conventional architecture, an innovative
horizon-aware contexts generator is dedicatedly designed to consider the prior
horizon information, which further enables non-autoregressive multi-horizon
prediction. Moreover, a differential prompted decoder is proposed to enhance
the capability of the differential predictions by leveraging the stationarity
of the differential sequence. The experimental results on a real-world dataset
demonstrated that the FlightBERT++ outperformed the competitive baselines in
both FTP performance and computational efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1&quot;&gt;Dongyue Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1&quot;&gt;Zhen Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yi Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06972">
<title>Spear Phishing With Large Language Models. (arXiv:2305.06972v3 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06972</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress in artificial intelligence (AI), particularly in the domain
of large language models (LLMs), has resulted in powerful and versatile
dual-use systems. This intelligence can be put towards a wide variety of
beneficial tasks, yet it can also be used to cause harm. This study explores
one such harm by examining how LLMs can be used for spear phishing, a form of
cybercrime that involves manipulating targets into divulging sensitive
information. I first explore LLMs&apos; ability to assist with the reconnaissance
and message generation stages of a spear phishing attack, where I find that
LLMs are capable of assisting with the email generation phase of a spear
phishing attack. To explore how LLMs could potentially be harnessed to scale
spear phishing campaigns, I then create unique spear phishing messages for over
600 British Members of Parliament using OpenAI&apos;s GPT-3.5 and GPT-4 models. My
findings provide some evidence that these messages are not only realistic but
also cost-effective, with each email costing only a fraction of a cent to
generate. Next, I demonstrate how basic prompt engineering can circumvent
safeguards installed in LLMs, highlighting the need for further research into
robust interventions that can help prevent models from being misused. To
further address these evolving risks, I explore two potential solutions:
structured access schemes, such as application programming interfaces, and
LLM-based defensive systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazell_J/0/1/0/all/0/1&quot;&gt;Julian Hazell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19228">
<title>Unsupervised Melody-to-Lyric Generation. (arXiv:2305.19228v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19228</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic melody-to-lyric generation is a task in which song lyrics are
generated to go with a given melody. It is of significant practical interest
and more challenging than unconstrained lyric generation as the music imposes
additional constraints onto the lyrics. The training data is limited as most
songs are copyrighted, resulting in models that underfit the complicated
cross-modal relationship between melody and lyrics. In this work, we propose a
method for generating high-quality lyrics without training on any aligned
melody-lyric data. Specifically, we design a hierarchical lyric generation
framework that first generates a song outline and second the complete lyrics.
The framework enables disentanglement of training (based purely on text) from
inference (melody-guided text generation) to circumvent the shortage of
parallel data.
&lt;/p&gt;
&lt;p&gt;We leverage the segmentation and rhythm alignment between melody and lyrics
to compile the given melody into decoding constraints as guidance during
inference. The two-step hierarchical design also enables content control via
the lyric outline, a much-desired feature for democratizing collaborative song
creation. Experimental results show that our model can generate high-quality
lyrics that are more on-topic, singable, intelligible, and coherent than strong
baselines, for example SongMASS, a SOTA model trained on a parallel dataset,
with a 24% relative overall quality improvement based on human ratings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yufei Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayan_Chen_A/0/1/0/all/0/1&quot;&gt;Anjali Narayan-Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oraby_S/0/1/0/all/0/1&quot;&gt;Shereen Oraby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cervone_A/0/1/0/all/0/1&quot;&gt;Alessandra Cervone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sigurdsson_G/0/1/0/all/0/1&quot;&gt;Gunnar Sigurdsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1&quot;&gt;Chenyang Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wenbo Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiwen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_T/0/1/0/all/0/1&quot;&gt;Tagyoung Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jing Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1&quot;&gt;Nanyun Peng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.05059">
<title>Reconciling Predictive and Statistical Parity: A Causal Approach. (arXiv:2306.05059v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/2306.05059</link>
<description rdf:parseType="Literal">&lt;p&gt;Since the rise of fair machine learning as a critical field of inquiry, many
different notions on how to quantify and measure discrimination have been
proposed in the literature. Some of these notions, however, were shown to be
mutually incompatible. Such findings make it appear that numerous different
kinds of fairness exist, thereby making a consensus on the appropriate measure
of fairness harder to reach, hindering the applications of these tools in
practice. In this paper, we investigate one of these key impossibility results
that relates the notions of statistical and predictive parity. Specifically, we
derive a new causal decomposition formula for the fairness measures associated
with predictive parity, and obtain a novel insight into how this criterion is
related to statistical parity through the legal doctrines of disparate
treatment, disparate impact, and the notion of business necessity. Our results
show that through a more careful causal analysis, the notions of statistical
and predictive parity are not really mutually exclusive, but complementary and
spanning a spectrum of fairness notions through the concept of business
necessity. Finally, we demonstrate the importance of our findings on a
real-world example.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plecko_D/0/1/0/all/0/1&quot;&gt;Drago Plecko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bareinboim_E/0/1/0/all/0/1&quot;&gt;Elias Bareinboim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11758">
<title>MRFI: An Open Source Multi-Resolution Fault Injection Framework for Neural Network Processing. (arXiv:2306.11758v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11758</link>
<description rdf:parseType="Literal">&lt;p&gt;To ensure resilient neural network processing on even unreliable hardware,
comprehensive reliability analysis against various hardware faults is generally
required before the deep neural network models are deployed, and efficient
error injection tools are highly demanded. However, most existing fault
injection tools remain rather limited to basic fault injection to neurons and
fail to provide fine-grained vulnerability analysis capability. In addition,
many of the fault injection tools still need to change the neural network
models and make the fault injection closely coupled with normal neural network
processing, which further complicates the use of the fault injection tools and
slows down the fault simulation. In this work, we propose MRFI, a highly
configurable multi-resolution fault injection tool for deep neural networks. It
enables users to modify an independent fault configuration file rather than
neural network models for the fault injection and vulnerability analysis.
Particularly, it integrates extensive fault analysis functionalities from
different perspectives and enables multi-resolution investigation of the
vulnerability of neural networks. In addition, it does not modify the major
neural network computing framework of PyTorch. Hence, it allows parallel
processing on GPUs naturally and exhibits fast fault simulation according to
our experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Haitong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Cheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1&quot;&gt;Xinghua Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Huawei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaowei Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.17602">
<title>S.T.A.R.-Track: Latent Motion Models for End-to-End 3D Object Tracking with Adaptive Spatio-Temporal Appearance Representations. (arXiv:2306.17602v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.17602</link>
<description rdf:parseType="Literal">&lt;p&gt;Following the tracking-by-attention paradigm, this paper introduces an
object-centric, transformer-based framework for tracking in 3D. Traditional
model-based tracking approaches incorporate the geometric effect of object- and
ego motion between frames with a geometric motion model. Inspired by this, we
propose S.T.A.R.-Track, which uses a novel latent motion model (LMM) to
additionally adjust object queries to account for changes in viewing direction
and lighting conditions directly in the latent space, while still modeling the
geometric motion explicitly. Combined with a novel learnable track embedding
that aids in modeling the existence probability of tracks, this results in a
generic tracking framework that can be integrated with any query-based
detector. Extensive experiments on the nuScenes benchmark demonstrate the
benefits of our approach, showing \ac{sota} performance for DETR3D-based
trackers while drastically reducing the number of identity switches of tracks
at the same time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doll_S/0/1/0/all/0/1&quot;&gt;Simon Doll&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanselmann_N/0/1/0/all/0/1&quot;&gt;Niklas Hanselmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_L/0/1/0/all/0/1&quot;&gt;Lukas Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulz_R/0/1/0/all/0/1&quot;&gt;Richard Schulz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Enzweiler_M/0/1/0/all/0/1&quot;&gt;Markus Enzweiler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lensch_H/0/1/0/all/0/1&quot;&gt;Hendrik P.A. Lensch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.02139">
<title>Self-Supervised Pre-Training Boosts Semantic Scene Segmentation on LiDAR Data. (arXiv:2309.02139v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.02139</link>
<description rdf:parseType="Literal">&lt;p&gt;Airborne LiDAR systems have the capability to capture the Earth&apos;s surface by
generating extensive point cloud data comprised of points mainly defined by 3D
coordinates. However, labeling such points for supervised learning tasks is
time-consuming. As a result, there is a need to investigate techniques that can
learn from unlabeled data to significantly reduce the number of annotated
samples. In this work, we propose to train a self-supervised encoder with
Barlow Twins and use it as a pre-trained network in the task of semantic scene
segmentation. The experimental results demonstrate that our unsupervised
pre-training boosts performance once fine-tuned on the supervised task,
especially for under-represented categories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caros_M/0/1/0/all/0/1&quot;&gt;Mariona Car&amp;#xf3;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Just_A/0/1/0/all/0/1&quot;&gt;Ariadna Just&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Segui_S/0/1/0/all/0/1&quot;&gt;Santi Segu&amp;#xed;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vitria_J/0/1/0/all/0/1&quot;&gt;Jordi Vitri&amp;#xe0;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01438">
<title>Building Flexible, Scalable, and Machine Learning-ready Multimodal Oncology Datasets. (arXiv:2310.01438v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.01438</link>
<description rdf:parseType="Literal">&lt;p&gt;The advancements in data acquisition, storage, and processing techniques have
resulted in the rapid growth of heterogeneous medical data. Integrating
radiological scans, histopathology images, and molecular information with
clinical data is essential for developing a holistic understanding of the
disease and optimizing treatment. The need for integrating data from multiple
sources is further pronounced in complex diseases such as cancer for enabling
precision medicine and personalized treatments. This work proposes Multimodal
Integration of Oncology Data System (MINDS) - a flexible, scalable, and
cost-effective metadata framework for efficiently fusing disparate data from
public sources such as the Cancer Research Data Commons (CRDC) into an
interconnected, patient-centric framework. MINDS offers an interface for
exploring relationships across data types and building cohorts for developing
large-scale multimodal machine learning models. By harmonizing multimodal data,
MINDS aims to potentially empower researchers with greater analytical ability
to uncover diagnostic and prognostic insights and enable evidence-based
personalized care. MINDS tracks granular end-to-end data provenance, ensuring
reproducibility and transparency. The cloud-native architecture of MINDS can
handle exponential data growth in a secure, cost-optimized manner while
ensuring substantial storage optimization, replication avoidance, and dynamic
access capabilities. Auto-scaling, access controls, and other mechanisms
guarantee pipelines&apos; scalability and security. MINDS overcomes the limitations
of existing biomedical data silos via an interoperable metadata-driven approach
that represents a pivotal step toward the future of oncology data integration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathi_A/0/1/0/all/0/1&quot;&gt;Aakash Tripathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waqas_A/0/1/0/all/0/1&quot;&gt;Asim Waqas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkatesan_K/0/1/0/all/0/1&quot;&gt;Kavya Venkatesan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yilmaz_Y/0/1/0/all/0/1&quot;&gt;Yasin Yilmaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasool_G/0/1/0/all/0/1&quot;&gt;Ghulam Rasool&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.05086">
<title>Learning Generalizable Agents via Saliency-Guided Features Decorrelation. (arXiv:2310.05086v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2310.05086</link>
<description rdf:parseType="Literal">&lt;p&gt;In visual-based Reinforcement Learning (RL), agents often struggle to
generalize well to environmental variations in the state space that were not
observed during training. The variations can arise in both task-irrelevant
features, such as background noise, and task-relevant features, such as robot
configurations, that are related to the optimal decisions. To achieve
generalization in both situations, agents are required to accurately understand
the impact of changed features on the decisions, i.e., establishing the true
associations between changed features and decisions in the policy model.
However, due to the inherent correlations among features in the state space,
the associations between features and decisions become entangled, making it
difficult for the policy to distinguish them. To this end, we propose
Saliency-Guided Features Decorrelation (SGFD) to eliminate these correlations
through sample reweighting. Concretely, SGFD consists of two core techniques:
Random Fourier Functions (RFF) and the saliency map. RFF is utilized to
estimate the complex non-linear correlations in high-dimensional images, while
the saliency map is designed to identify the changed features. Under the
guidance of the saliency map, SGFD employs sample reweighting to minimize the
estimated correlations related to changed features, thereby achieving
decorrelation in visual RL tasks. Our experimental results demonstrate that
SGFD can generalize well on a wide range of test environments and significantly
outperforms state-of-the-art methods in handling both task-irrelevant
variations and task-relevant variations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Sili Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanchao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jifeng Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1&quot;&gt;Siyuan Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hechang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yi Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Lichao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bo Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.05707">
<title>Guiding Language Model Reasoning with Planning Tokens. (arXiv:2310.05707v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.05707</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have recently attracted considerable interest
for their ability to perform complex reasoning tasks, such as chain-of-thought
reasoning. However, most of the existing approaches to enhance this ability
rely heavily on data-driven methods, while neglecting the structural aspects of
the model&apos;s reasoning capacity. We find that while LLMs can manage individual
reasoning steps well, they struggle with maintaining consistency across an
entire reasoning chain. To solve this, we introduce &apos;planning tokens&apos; at the
start of each reasoning step, serving as a guide for the model. These token
embeddings are then fine-tuned along with the rest of the model parameters. Our
approach requires a negligible increase in trainable parameters (just 0.001%)
and can be applied through either full fine-tuning or a more
parameter-efficient scheme. We demonstrate our method&apos;s effectiveness by
applying it to three different LLMs, showing notable accuracy improvements
across three math word problem datasets w.r.t. plain chain-of-thought
fine-tuning baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caccia_L/0/1/0/all/0/1&quot;&gt;Lucas Caccia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ostapenko_O/0/1/0/all/0/1&quot;&gt;Oleksiy Ostapenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xingdi Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sordoni_A/0/1/0/all/0/1&quot;&gt;Alessandro Sordoni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13230">
<title>Absolute Policy Optimization. (arXiv:2310.13230v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13230</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, trust region on-policy reinforcement learning has achieved
impressive results in addressing complex control tasks and gaming scenarios.
However, contemporary state-of-the-art algorithms within this category
primarily emphasize improvement in expected performance, lacking the ability to
control over the worst-case performance outcomes. To address this limitation,
we introduce a novel objective function; by optimizing which, it will lead to
guaranteed monotonic improvement in the lower bound of near-total performance
samples (absolute performance). Considering this groundbreaking theoretical
advancement, we then refine this theoretically grounded algorithm through a
series of approximations, resulting in a practical solution called Absolute
Policy Optimization (APO). Our experiments demonstrate the effectiveness of our
approach across challenging continuous control benchmark tasks and extend its
applicability to mastering Atari games. Our findings reveal that APO
significantly outperforms state-of-the-art policy gradient algorithms,
resulting in substantial improvements in both expected performance and
worst-case performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Weiye Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Feihan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yifan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Rui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1&quot;&gt;Tianhao Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Changliu Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.12420">
<title>How Far Have We Gone in Vulnerability Detection Using Large Language Models. (arXiv:2311.12420v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2311.12420</link>
<description rdf:parseType="Literal">&lt;p&gt;As software becomes increasingly complex and prone to vulnerabilities,
automated vulnerability detection is critically important, yet challenging.
Given the significant successes of large language models (LLMs) in various
tasks, there is growing anticipation of their efficacy in vulnerability
detection. However, a quantitative understanding of their potential in
vulnerability detection is still missing. To bridge this gap, we introduce a
comprehensive vulnerability benchmark VulBench. This benchmark aggregates
high-quality data from a wide range of CTF (Capture-the-Flag) challenges and
real-world applications, with annotations for each vulnerable function
detailing the vulnerability type and its root cause. Through our experiments
encompassing 16 LLMs and 6 state-of-the-art (SOTA) deep learning-based models
and static analyzers, we find that several LLMs outperform traditional deep
learning approaches in vulnerability detection, revealing an untapped potential
in LLMs. This work contributes to the understanding and utilization of LLMs for
enhanced software security.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1&quot;&gt;Zeyu Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuchen Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wenyu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.16502">
<title>MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI. (arXiv:2311.16502v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.16502</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce MMMU: a new benchmark designed to evaluate multimodal models on
massive multi-discipline tasks demanding college-level subject knowledge and
deliberate reasoning. MMMU includes 11.5K meticulously collected multimodal
questions from college exams, quizzes, and textbooks, covering six core
disciplines: Art &amp;amp; Design, Business, Science, Health &amp;amp; Medicine, Humanities &amp;amp;
Social Science, and Tech &amp;amp; Engineering. These questions span 30 subjects and
183 subfields, comprising 30 highly heterogeneous image types, such as charts,
diagrams, maps, tables, music sheets, and chemical structures. Unlike existing
benchmarks, MMMU focuses on advanced perception and reasoning with
domain-specific knowledge, challenging models to perform tasks akin to those
faced by experts. The evaluation of 14 open-source LMMs as well as the
proprietary GPT-4V(ision) and Gemini highlights the substantial challenges
posed by MMMU. Even the advanced GPT-4V and Gemini Ultra only achieve
accuracies of 56% and 59% respectively, indicating significant room for
improvement. We believe MMMU will stimulate the community to build
next-generation multimodal foundation models towards expert artificial general
intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1&quot;&gt;Xiang Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1&quot;&gt;Yuansheng Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1&quot;&gt;Tianyu Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Ruoqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Ge Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stevens_S/0/1/0/all/0/1&quot;&gt;Samuel Stevens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1&quot;&gt;Dongfu Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1&quot;&gt;Weiming Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yuxuan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1&quot;&gt;Cong Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Botao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1&quot;&gt;Ruibin Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1&quot;&gt;Renliang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1&quot;&gt;Ming Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1&quot;&gt;Boyuan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhenzhu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yibo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wenhao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Huan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yu Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wenhu Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05756">
<title>A quantitative fusion strategy of stock picking and timing based on Particle Swarm Optimized-Back Propagation Neural Network and Multivariate Gaussian-Hidden Markov Model. (arXiv:2312.05756v3 [cs.CE] UPDATED)</title>
<link>http://arxiv.org/abs/2312.05756</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, machine learning (ML) has brought effective approaches and
novel techniques to economic decision, investment forecasting, and risk
management, etc., coping the variable and intricate nature of economic and
financial environments. For the investment in stock market, this research
introduces a pioneering quantitative fusion model combining stock timing and
picking strategy by leveraging the Multivariate Gaussian-Hidden Markov Model
(MGHMM) and Back Propagation Neural Network optimized by Particle Swarm
(PSO-BPNN). After the information coefficients (IC) between fifty-two factors
that have been winsorized, neutralized and standardized and the return of CSI
300 index are calculated, a given amount of factors that rank ahead are choose
to be candidate factors heading for the input of PSO-BPNN after dimension
reduction by Principal Component Analysis (PCA), followed by a certain amount
of constituent stocks outputted. Subsequently, we conduct the prediction and
trading on the basis of the screening stocks and stock market state outputted
by MGHMM trained using inputting CSI 300 index data after Box-Cox
transformation, bespeaking eximious performance during the period of past four
years. Ultimately, some conventional forecast and trading methods are compared
with our strategy in Chinese stock market. Our fusion strategy incorporating
stock picking and timing presented in this article provide a innovative
technique for financial analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Huajian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Longjian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jiajian Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1&quot;&gt;Weinan Dai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.11434">
<title>Factored Online Planning in Many-Agent POMDPs. (arXiv:2312.11434v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2312.11434</link>
<description rdf:parseType="Literal">&lt;p&gt;In centralized multi-agent systems, often modeled as multi-agent partially
observable Markov decision processes (MPOMDPs), the action and observation
spaces grow exponentially with the number of agents, making the value and
belief estimation of single-agent online planning ineffective. Prior work
partially tackles value estimation by exploiting the inherent structure of
multi-agent settings via so-called coordination graphs. Additionally, belief
estimation has been improved by incorporating the likelihood of observations
into the approximation. However, the challenges of value estimation and belief
estimation have only been tackled individually, which prevents existing methods
from scaling to many agents. Therefore, we address these challenges
simultaneously. First, we introduce weighted particle filtering to a
sample-based online planner for MPOMDPs. Second, we present a scalable
approximation of the belief. Third, we bring an approach that exploits the
typical locality of agent interactions to novel online planning algorithms for
MPOMDPs operating on a so-called sparse particle filter tree. Our experimental
evaluation against several state-of-the-art baselines shows that our methods
(1) are competitive in settings with only a few agents and (2) improve over the
baselines in the presence of many agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galesloot_M/0/1/0/all/0/1&quot;&gt;Maris F.L. Galesloot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simao_T/0/1/0/all/0/1&quot;&gt;Thiago D. Sim&amp;#xe3;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Junges_S/0/1/0/all/0/1&quot;&gt;Sebastian Junges&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jansen_N/0/1/0/all/0/1&quot;&gt;Nils Jansen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.12598">
<title>A Case Study on Test Case Construction with Large Language Models: Unveiling Practical Insights and Challenges. (arXiv:2312.12598v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2312.12598</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a detailed case study examining the application of Large
Language Models (LLMs) in the construction of test cases within the context of
software engineering. LLMs, characterized by their advanced natural language
processing capabilities, are increasingly garnering attention as tools to
automate and enhance various aspects of the software development life cycle.
Leveraging a case study methodology, we systematically explore the integration
of LLMs in the test case construction process, aiming to shed light on their
practical efficacy, challenges encountered, and implications for software
quality assurance. The study encompasses the selection of a representative
software application, the formulation of test case construction methodologies
employing LLMs, and the subsequent evaluation of outcomes. Through a blend of
qualitative and quantitative analyses, this study assesses the impact of LLMs
on test case comprehensiveness, accuracy, and efficiency. Additionally, delves
into challenges such as model interpretability and adaptation to diverse
software contexts. The findings from this case study contributes with nuanced
insights into the practical utility of LLMs in the domain of test case
construction, elucidating their potential benefits and limitations. By
addressing real-world scenarios and complexities, this research aims to inform
software practitioners and researchers alike about the tangible implications of
incorporating LLMs into the software testing landscape, fostering a more
comprehensive understanding of their role in optimizing the software
development process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Junior_R/0/1/0/all/0/1&quot;&gt;Roberto Francisco de Lima Junior&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Presta_L/0/1/0/all/0/1&quot;&gt;Luiz Fernando Paes de Barros Presta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borborema_L/0/1/0/all/0/1&quot;&gt;Lucca Santos Borborema&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_V/0/1/0/all/0/1&quot;&gt;Vanderson Nogueira da Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahia_M/0/1/0/all/0/1&quot;&gt;Marcio Leal de Melo Dahia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_A/0/1/0/all/0/1&quot;&gt;Anderson Carlos Sousa e Santos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.12705">
<title>Optimizing Distributed Training on Frontier for Large Language Models. (arXiv:2312.12705v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2312.12705</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have demonstrated remarkable success as
foundational models, benefiting various downstream applications through
fine-tuning. Recent studies on loss scaling have demonstrated the superior
performance of larger LLMs compared to their smaller counterparts.
Nevertheless, training LLMs with billions of parameters poses significant
challenges and requires considerable computational resources. For example,
training a one trillion parameter GPT-style model on 20 trillion tokens
requires a staggering 120 million exaflops of computation. This research
explores efficient distributed training strategies to extract this computation
from Frontier, the world&apos;s first exascale supercomputer dedicated to open
science. We enable and investigate various model and data parallel training
techniques, such as tensor parallelism, pipeline parallelism, and sharded data
parallelism, to facilitate training a trillion-parameter model on Frontier. We
empirically assess these techniques and their associated parameters to
determine their impact on memory footprint, communication latency, and GPU&apos;s
computational efficiency. We analyze the complex interplay among these
techniques and find a strategy to combine them to achieve high throughput
through hyperparameter tuning. We have identified efficient strategies for
training large LLMs of varying sizes through empirical analysis and
hyperparameter tuning. For 22 Billion, 175 Billion, and 1 Trillion parameters,
we achieved GPU throughputs of $38.38\%$, $36.14\%$, and $31.96\%$,
respectively. For the training of the 175 Billion parameter model and the 1
Trillion parameter model, we achieved $100\%$ weak scaling efficiency on 1024
and 3072 MI250X GPUs, respectively. We also achieved strong scaling
efficiencies of $89\%$ and $87\%$ for these two models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dash_S/0/1/0/all/0/1&quot;&gt;Sajal Dash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyngaas_I/0/1/0/all/0/1&quot;&gt;Isaac Lyngaas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1&quot;&gt;Junqi Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Egele_R/0/1/0/all/0/1&quot;&gt;Romain Egele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cong_G/0/1/0/all/0/1&quot;&gt;Guojing Cong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Feiyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balaprakash_P/0/1/0/all/0/1&quot;&gt;Prasanna Balaprakash&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.12865">
<title>RadEdit: stress-testing biomedical vision models via diffusion image editing. (arXiv:2312.12865v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2312.12865</link>
<description rdf:parseType="Literal">&lt;p&gt;Biomedical imaging datasets are often small and biased, meaning that
real-world performance of predictive models can be substantially lower than
expected from internal testing. This work proposes using generative image
editing to simulate dataset shifts and diagnose failure modes of biomedical
vision models; this can be used in advance of deployment to assess readiness,
potentially reducing cost and patient harm. Existing editing methods can
produce undesirable changes, with spurious correlations learned due to the
co-occurrence of disease and treatment interventions, limiting practical
applicability. To address this, we train a text-to-image diffusion model on
multiple chest X-ray datasets and introduce a new editing method RadEdit that
uses multiple masks, if present, to constrain changes and ensure consistency in
the edited images. We consider three types of dataset shifts: acquisition
shift, manifestation shift, and population shift, and demonstrate that our
approach can diagnose failures and quantify model robustness without additional
data collection, complementing more qualitative tools for explainable AI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Garcia_F/0/1/0/all/0/1&quot;&gt;Fernando P&amp;#xe9;rez-Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bond_Taylor_S/0/1/0/all/0/1&quot;&gt;Sam Bond-Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_P/0/1/0/all/0/1&quot;&gt;Pedro P. Sanchez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Breugel_B/0/1/0/all/0/1&quot;&gt;Boris van Breugel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castro_D/0/1/0/all/0/1&quot;&gt;Daniel C. Castro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_H/0/1/0/all/0/1&quot;&gt;Harshita Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salvatelli_V/0/1/0/all/0/1&quot;&gt;Valentina Salvatelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wetscherek_M/0/1/0/all/0/1&quot;&gt;Maria T. A. Wetscherek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richardson_H/0/1/0/all/0/1&quot;&gt;Hannah Richardson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1&quot;&gt;Matthew P. Lungren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nori_A/0/1/0/all/0/1&quot;&gt;Aditya Nori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alvarez_Valle_J/0/1/0/all/0/1&quot;&gt;Javier Alvarez-Valle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oktay_O/0/1/0/all/0/1&quot;&gt;Ozan Oktay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilse_M/0/1/0/all/0/1&quot;&gt;Maximilian Ilse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.13434">
<title>Zero-1-to-3: Domain-level Zero-shot Cognitive Diagnosis via One Batch of Early-bird Students towards Three Diagnostic Objectives. (arXiv:2312.13434v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2312.13434</link>
<description rdf:parseType="Literal">&lt;p&gt;Cognitive diagnosis seeks to estimate the cognitive states of students by
exploring their logged practice quiz data. It plays a pivotal role in
personalized learning guidance within intelligent education systems. In this
paper, we focus on an important, practical, yet often underexplored task:
domain-level zero-shot cognitive diagnosis (DZCD), which arises due to the
absence of student practice logs in newly launched domains. Recent cross-domain
diagnostic models have been demonstrated to be a promising strategy for DZCD.
These methods primarily focus on how to transfer student states across domains.
However, they might inadvertently incorporate non-transferable information into
student representations, thereby limiting the efficacy of knowledge transfer.
To tackle this, we propose Zero-1-to-3, a domain-level zero-shot cognitive
diagnosis framework via one batch of early-bird students towards three
diagnostic objectives. Our approach initiates with pre-training a diagnosis
model with dual regularizers, which decouples student states into domain-shared
and domain-specific parts. The shared cognitive signals can be transferred to
the target domain, enriching the cognitive priors for the new domain, which
ensures the cognitive state propagation objective. Subsequently, we devise a
strategy to generate simulated practice logs for cold-start students through
analyzing the behavioral patterns from early-bird students, fulfilling the
domain-adaption goal. Consequently, we refine the cognitive states of
cold-start students as diagnostic outcomes via virtual data, aligning with the
diagnosis-oriented goal. Finally, extensive experiments on six real-world
datasets highlight the efficacy of our model for DZCD and its practical
application in question recommendation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Weibo Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_L/0/1/0/all/0/1&quot;&gt;Linan Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bi_H/0/1/0/all/0/1&quot;&gt;Haoyang Bi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1&quot;&gt;Yin Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_F/0/1/0/all/0/1&quot;&gt;Fangzhou Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yuanjing He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.13970">
<title>On Partial Optimal Transport: Revising the Infeasibility of Sinkhorn and Efficient Gradient Methods. (arXiv:2312.13970v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.13970</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the Partial Optimal Transport (POT) problem between two
unbalanced measures with at most $n$ supports and its applications in various
AI tasks such as color transfer or domain adaptation. There is hence the need
for fast approximations of POT with increasingly large problem sizes in arising
applications. We first theoretically and experimentally investigate the
infeasibility of the state-of-the-art Sinkhorn algorithm for POT due to its
incompatible rounding procedure, which consequently degrades its qualitative
performance in real world applications like point-cloud registration. To this
end, we propose a novel rounding algorithm for POT, and then provide a feasible
Sinkhorn procedure with a revised computation complexity of
$\mathcal{\widetilde O}(n^2/\varepsilon^4)$. Our rounding algorithm also
permits the development of two first-order methods to approximate the POT
problem. The first algorithm, Adaptive Primal-Dual Accelerated Gradient Descent
(APDAGD), finds an $\varepsilon$-approximate solution to the POT problem in
$\mathcal{\widetilde O}(n^{2.5}/\varepsilon)$, which is better in $\varepsilon$
than revised Sinkhorn. The second method, Dual Extrapolation, achieves the
computation complexity of $\mathcal{\widetilde O}(n^2/\varepsilon)$, thereby
being the best in the literature. We further demonstrate the flexibility of POT
compared to standard OT as well as the practicality of our algorithms on real
applications where two marginal distributions are unbalanced.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1&quot;&gt;Anh Duc Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Tuan Dung Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1&quot;&gt;Quang Minh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Hoang H. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1&quot;&gt;Lam M. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toh_K/0/1/0/all/0/1&quot;&gt;Kim-Chuan Toh&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>