<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-12-10T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04574" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04576" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04578" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04584" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04587" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04590" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04591" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04594" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04595" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04596" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04597" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04600" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04601" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04604" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04606" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04609" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04610" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04613" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04615" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04640" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04642" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04648" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04653" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04658" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04660" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04668" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04670" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04675" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04687" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04688" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04692" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04693" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04704" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04709" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04712" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04715" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04718" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04719" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04720" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04724" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04737" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04739" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04740" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04744" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04745" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04752" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04757" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04758" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04762" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04772" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04779" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04782" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04786" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04815" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04823" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04840" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04862" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04865" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04879" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04883" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04889" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04905" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04911" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04913" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04917" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04918" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04926" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04927" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04940" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04947" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04948" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04985" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04992" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04997" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05017" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05021" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05023" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05034" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05039" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05044" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05052" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05073" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05090" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05092" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05100" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05103" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05114" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05134" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05140" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05144" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05153" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05158" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05160" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05162" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05176" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05181" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05185" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05195" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05215" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05225" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05229" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05231" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05250" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05253" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05254" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2005.11753" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.11505" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.11328" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.12989" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.12276" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.07084" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.07898" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.04688" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.12637" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01842" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.13220" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.07311" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.09744" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.09568" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.01404" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.02524" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.06359" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.02304" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.09424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.10406" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14160" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14208" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14876" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15987" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.17017" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18764" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19776" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.00006" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.00945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.02204" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.03623" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04829" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04984" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.05415" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11072" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.13596" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02251" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.04684" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.10284" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.13818" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.13917" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.16680" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03321" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.07051" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.09835" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03251" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03886" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11955" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.14348" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15730" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16620" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01557" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04935" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.12262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13032" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13139" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.19385" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.11841" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.13443" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.13713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.14387" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.16214" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.17961" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.00271" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.00296" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.00966" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.01523" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.03044" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.03126" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04404" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04474" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2312.04574">
<title>Differentiable Visual Computing for Inverse Problems and Machine Learning. (arXiv:2312.04574v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04574</link>
<description rdf:parseType="Literal">&lt;p&gt;Originally designed for applications in computer graphics, visual computing
(VC) methods synthesize information about physical and virtual worlds, using
prescribed algorithms optimized for spatial computing. VC is used to analyze
geometry, physically simulate solids, fluids, and other media, and render the
world via optical techniques. These fine-tuned computations that operate
explicitly on a given input solve so-called forward problems, VC excels at. By
contrast, deep learning (DL) allows for the construction of general algorithmic
models, side stepping the need for a purely first principles-based approach to
problem solving. DL is powered by highly parameterized neural network
architectures -- universal function approximators -- and gradient-based search
algorithms which can efficiently search that large parameter space for optimal
models. This approach is predicated by neural network differentiability, the
requirement that analytic derivatives of a given problem&apos;s task metric can be
computed with respect to neural network&apos;s parameters. Neural networks excel
when an explicit model is not known, and neural network training solves an
inverse problem in which a model is computed from data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spielberg_A/0/1/0/all/0/1&quot;&gt;Andrew Spielberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1&quot;&gt;Fangcheng Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rematas_K/0/1/0/all/0/1&quot;&gt;Konstantinos Rematas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jatavallabhula_K/0/1/0/all/0/1&quot;&gt;Krishna Murthy Jatavallabhula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oztireli_C/0/1/0/all/0/1&quot;&gt;Cengiz Oztireli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tzu-Mao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nowrouzezahrai_D/0/1/0/all/0/1&quot;&gt;Derek Nowrouzezahrai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04576">
<title>The Open Review-Based (ORB) dataset: Towards Automatic Assessment of Scientific Papers and Experiment Proposals in High-Energy Physics. (arXiv:2312.04576v1 [cs.DL])</title>
<link>http://arxiv.org/abs/2312.04576</link>
<description rdf:parseType="Literal">&lt;p&gt;With the Open Science approach becoming important for research, the evolution
towards open scientific-paper reviews is making an impact on the scientific
community. However, there is a lack of publicly available resources for
conducting research activities related to this subject, as only a limited
number of journals and conferences currently allow access to their review
process for interested parties. In this paper, we introduce the new
comprehensive Open Review-Based dataset (ORB); it includes a curated list of
more than 36,000 scientific papers with their more than 89,000 reviews and
final decisions. We gather this information from two sources: the
OpenReview.net and SciPost.org websites. However, given the volatile nature of
this domain, the software infrastructure that we introduce to supplement the
ORB dataset is designed to accommodate additional resources in the future. The
ORB deliverables include (1) Python code (interfaces and implementations) to
translate document data and metadata into a structured and high-level
representation, (2) an ETL process (Extract, Transform, Load) to facilitate the
automatic updates from defined sources and (3) data files representing the
structured data. The paper presents our data architecture and an overview of
the collected data along with relevant statistics. For illustration purposes,
we also discuss preliminary Natural-Language-Processing-based experiments that
aim to predict (1) papers&apos; acceptance based on their textual embeddings, and
(2) grading statistics inferred from embeddings as well. We believe ORB
provides a valuable resource for researchers interested in open science and
review, with our implementation easing the use of this data for further
analysis and experimentation. We plan to update ORB as the field matures as
well as introduce new resources even more fitted to dedicated scientific
domains such as High-Energy Physics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szumega_J/0/1/0/all/0/1&quot;&gt;Jaroslaw Szumega&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bougueroua_L/0/1/0/all/0/1&quot;&gt;Lamine Bougueroua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gkotse_B/0/1/0/all/0/1&quot;&gt;Blerina Gkotse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jouvelot_P/0/1/0/all/0/1&quot;&gt;Pierre Jouvelot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravotti_F/0/1/0/all/0/1&quot;&gt;Federico Ravotti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04578">
<title>Towards a Psychological Generalist AI: A Survey of Current Applications of Large Language Models and Future Prospects. (arXiv:2312.04578v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.04578</link>
<description rdf:parseType="Literal">&lt;p&gt;The complexity of psychological principles underscore a significant societal
challenge, given the vast social implications of psychological problems.
Bridging the gap between understanding these principles and their actual
clinical and real-world applications demands rigorous exploration and adept
implementation. In recent times, the swift advancement of highly adaptive and
reusable artificial intelligence (AI) models has emerged as a promising way to
unlock unprecedented capabilities in the realm of psychology. This paper
emphasizes the importance of performance validation for these large-scale AI
models, emphasizing the need to offer a comprehensive assessment of their
verification from diverse perspectives. Moreover, we review the cutting-edge
advancements and practical implementations of these expansive models in
psychology, highlighting pivotal work spanning areas such as social media
analytics, clinical nursing insights, vigilant community monitoring, and the
nuanced exploration of psychological theories. Based on our review, we project
an acceleration in the progress of psychological fields, driven by these
large-scale AI models. These future generalist AI models harbor the potential
to substantially curtail labor costs and alleviate social stress. However, this
forward momentum will not be without its set of challenges, especially when
considering the paradigm changes and upgrades required for medical
instrumentation and related applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1&quot;&gt;Tianyu He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_G/0/1/0/all/0/1&quot;&gt;Guanghui Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yijing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianqiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qing Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1&quot;&gt;Changwei Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1&quot;&gt;Hongzhi Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1&quot;&gt;Dan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_H/0/1/0/all/0/1&quot;&gt;Huijing Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bing Xiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04584">
<title>Towards Sample-specific Backdoor Attack with Clean Labels via Attribute Trigger. (arXiv:2312.04584v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04584</link>
<description rdf:parseType="Literal">&lt;p&gt;Currently, sample-specific backdoor attacks (SSBAs) are the most advanced and
malicious methods since they can easily circumvent most of the current backdoor
defenses. In this paper, we reveal that SSBAs are not sufficiently stealthy due
to their poisoned-label nature, where users can discover anomalies if they
check the image-label relationship. In particular, we demonstrate that it is
ineffective to directly generalize existing SSBAs to their clean-label variants
by poisoning samples solely from the target class. We reveal that it is
primarily due to two reasons, including \textbf{(1)} the `antagonistic effects&apos;
of ground-truth features and \textbf{(2)} the learning difficulty of
sample-specific features. Accordingly, trigger-related features of existing
SSBAs cannot be effectively learned under the clean-label setting due to their
mild trigger intensity required for ensuring stealthiness. We argue that the
intensity constraint of existing SSBAs is mostly because their trigger patterns
are `content-irrelevant&apos; and therefore act as `noises&apos; for both humans and
DNNs. Motivated by this understanding, we propose to exploit content-relevant
features, $a.k.a.$ (human-relied) attributes, as the trigger patterns to design
clean-label SSBAs. This new attack paradigm is dubbed backdoor attack with
attribute trigger (BAAT). Extensive experiments are conducted on benchmark
datasets, which verify the effectiveness of our BAAT and its resistance to
existing defenses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yiming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Mingyan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Junfeng Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1&quot;&gt;Tao Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1&quot;&gt;Shu-Tao Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1&quot;&gt;Zhan Qin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04587">
<title>FedBayes: A Zero-Trust Federated Learning Aggregation to Defend Against Adversarial Attacks. (arXiv:2312.04587v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04587</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning has created a decentralized method to train a machine
learning model without needing direct access to client data. The main goal of a
federated learning architecture is to protect the privacy of each client while
still contributing to the training of the global model. However, the main
advantage of privacy in federated learning is also the easiest aspect to
exploit. Without being able to see the clients&apos; data, it is difficult to
determine the quality of the data. By utilizing data poisoning methods, such as
backdoor or label-flipping attacks, or by sending manipulated information about
their data back to the server, malicious clients are able to corrupt the global
model and degrade performance across all clients within a federation. Our novel
aggregation method, FedBayes, mitigates the effect of a malicious client by
calculating the probabilities of a client&apos;s model weights given to the prior
model&apos;s weights using Bayesian statistics. Our results show that this approach
negates the effects of malicious clients and protects the overall federation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vucovich_M/0/1/0/all/0/1&quot;&gt;Marc Vucovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quinn_D/0/1/0/all/0/1&quot;&gt;Devin Quinn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1&quot;&gt;Kevin Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Redino_C/0/1/0/all/0/1&quot;&gt;Christopher Redino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1&quot;&gt;Abdul Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bowen_E/0/1/0/all/0/1&quot;&gt;Edward Bowen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04590">
<title>Reconciling AI Performance and Data Reconstruction Resilience for Medical Imaging. (arXiv:2312.04590v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04590</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial Intelligence (AI) models are vulnerable to information leakage of
their training data, which can be highly sensitive, for example in medical
imaging. Privacy Enhancing Technologies (PETs), such as Differential Privacy
(DP), aim to circumvent these susceptibilities. DP is the strongest possible
protection for training models while bounding the risks of inferring the
inclusion of training samples or reconstructing the original data. DP achieves
this by setting a quantifiable privacy budget. Although a lower budget
decreases the risk of information leakage, it typically also reduces the
performance of such models. This imposes a trade-off between robust performance
and stringent privacy. Additionally, the interpretation of a privacy budget
remains abstract and challenging to contextualize. In this study, we contrast
the performance of AI models at various privacy budgets against both,
theoretical risk bounds and empirical success of reconstruction attacks. We
show that using very large privacy budgets can render reconstruction attacks
impossible, while drops in performance are negligible. We thus conclude that
not using DP -- at all -- is negligent when applying AI models to sensitive
data. We deem those results to lie a foundation for further debates on striking
a balance between privacy risks and model performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ziller_A/0/1/0/all/0/1&quot;&gt;Alexander Ziller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mueller_T/0/1/0/all/0/1&quot;&gt;Tamara T. Mueller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stieger_S/0/1/0/all/0/1&quot;&gt;Simon Stieger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feiner_L/0/1/0/all/0/1&quot;&gt;Leonhard Feiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brandt_J/0/1/0/all/0/1&quot;&gt;Johannes Brandt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braren_R/0/1/0/all/0/1&quot;&gt;Rickmer Braren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1&quot;&gt;Daniel Rueckert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1&quot;&gt;Georgios Kaissis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04591">
<title>Toward Energy-Efficient Massive MIMO: Graph Neural Network Precoding for Mitigating Non-Linear PA Distortion. (arXiv:2312.04591v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2312.04591</link>
<description rdf:parseType="Literal">&lt;p&gt;Massive MIMO systems are typically designed assuming linear power amplifiers
(PAs). However, PAs are most energy efficient close to saturation, where
non-linear distortion arises. For conventional precoders, this distortion can
coherently combine at user locations, limiting performance. We propose a graph
neural network (GNN) to learn a mapping between channel and precoding matrices,
which maximizes the sum rate affected by non-linear distortion, using a
high-order polynomial PA model. In the distortion-limited regime, this
GNN-based precoder outperforms zero forcing (ZF), ZF plus digital
pre-distortion (DPD) and the distortion-aware beamforming (DAB) precoder from
the state-of-the-art. At an input back-off of -3 dB the proposed precoder
compared to ZF increases the sum rate by 8.60 and 8.84 bits/channel use for two
and four users respectively. Radiation patterns show that these gains are
achieved by transmitting the non-linear distortion in non-user directions. In
the four user-case, for a fixed sum rate, the total consumed power (PA and
processing) of the GNN precoder is 3.24 and 1.44 times lower compared to ZF and
ZF plus DPD respectively. A complexity analysis shows six orders of magnitude
reduction compared to DAB precoding. This opens perspectives to operate PAs
closer to saturation, which drastically increases their energy efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feys_T/0/1/0/all/0/1&quot;&gt;Thomas Feys&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perre_L/0/1/0/all/0/1&quot;&gt;Liesbet Van der Perre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rottenberg_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Rottenberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04594">
<title>FedGeo: Privacy-Preserving User Next Location Prediction with Federated Learning. (arXiv:2312.04594v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04594</link>
<description rdf:parseType="Literal">&lt;p&gt;A User Next Location Prediction (UNLP) task, which predicts the next location
that a user will move to given his/her trajectory, is an indispensable task for
a wide range of applications. Previous studies using large-scale trajectory
datasets in a single server have achieved remarkable performance in UNLP task.
However, in real-world applications, legal and ethical issues have been raised
regarding privacy concerns leading to restrictions against sharing human
trajectory datasets to any other server. In response, Federated Learning (FL)
has emerged to address the personal privacy issue by collaboratively training
multiple clients (i.e., users) and then aggregating them. While previous
studies employed FL for UNLP, they are still unable to achieve reliable
performance because of the heterogeneity of clients&apos; mobility. To tackle this
problem, we propose the Federated Learning for Geographic Information (FedGeo),
a FL framework specialized for UNLP, which alleviates the heterogeneity of
clients&apos; mobility and guarantees personal privacy protection. Firstly, we
incorporate prior global geographic adjacency information to the local client
model, since the spatial correlation between locations is trained partially in
each client who has only a heterogeneous subset of the overall trajectories in
FL. We also introduce a novel aggregation method that minimizes the gap between
client models to solve the problem of client drift caused by differences
between client models when learning with their heterogeneous data. Lastly, we
probabilistically exclude clients with extremely heterogeneous data from the FL
process by focusing on clients who visit relatively diverse locations. We show
that FedGeo is superior to other FL methods for model performance in UNLP task.
We also validated our model in a real-world application using our own
customers&apos; mobile phones and the FL agent system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1&quot;&gt;Chung Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_T/0/1/0/all/0/1&quot;&gt;Taekyoon Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1&quot;&gt;Taesan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1&quot;&gt;Mincheol Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1&quot;&gt;Junui Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1&quot;&gt;Minsung Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1&quot;&gt;Jaegul Choo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04595">
<title>Evaluating The Accuracy of Classification Algorithms for Detecting Heart Disease Risk. (arXiv:2312.04595v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04595</link>
<description rdf:parseType="Literal">&lt;p&gt;The healthcare industry generates enormous amounts of complex clinical data
that make the prediction of disease detection a complicated process. In medical
informatics, making effective and efficient decisions is very important. Data
Mining (DM) techniques are mainly used to identify and extract hidden patterns
and interesting knowledge to diagnose and predict diseases in medical datasets.
Nowadays, heart disease is considered one of the most important problems in the
healthcare field. Therefore, early diagnosis leads to a reduction in deaths. DM
techniques have proven highly effective for predicting and diagnosing heart
diseases. This work utilizes the classification algorithms with a medical
dataset of heart disease; namely, J48, Random Forest, and Na\&quot;ive Bayes to
discover the accuracy of their performance. We also examine the impact of the
feature selection method. A comparative and analysis study was performed to
determine the best technique using Waikato Environment for Knowledge Analysis
(Weka) software, version 3.8.6. The performance of the utilized algorithms was
evaluated using standard metrics such as accuracy, sensitivity and specificity.
The importance of using classification techniques for heart disease diagnosis
has been highlighted. We also reduced the number of attributes in the dataset,
which showed a significant improvement in prediction accuracy. The results
indicate that the best algorithm for predicting heart disease was Random Forest
with an accuracy of 99.24%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alariyibi_A/0/1/0/all/0/1&quot;&gt;Alhaam Alariyibi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Jarai_M/0/1/0/all/0/1&quot;&gt;Mohamed El-Jarai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maatuk_A/0/1/0/all/0/1&quot;&gt;Abdelsalam Maatuk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04596">
<title>Feature Analysis of Encrypted Malicious Traffic. (arXiv:2312.04596v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04596</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years there has been a dramatic increase in the number of malware
attacks that use encrypted HTTP traffic for self-propagation or communication.
Antivirus software and firewalls typically will not have access to encryption
keys, and therefore direct detection of malicious encrypted data is unlikely to
succeed. However, previous work has shown that traffic analysis can provide
indications of malicious intent, even in cases where the underlying data
remains encrypted. In this paper, we apply three machine learning techniques to
the problem of distinguishing malicious encrypted HTTP traffic from benign
encrypted traffic and obtain results comparable to previous work. We then
consider the problem of feature analysis in some detail. Previous work has
often relied on human expertise to determine the most useful and informative
features in this problem domain. We demonstrate that such feature-related
information can be obtained directly from machine learning models themselves.
We argue that such a machine learning based approach to feature analysis is
preferable, as it is more reliable, and we can, for example, uncover relatively
unintuitive interactions between features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shekhawat_A/0/1/0/all/0/1&quot;&gt;Anish Singh Shekhawat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Troia_F/0/1/0/all/0/1&quot;&gt;Fabio Di Troia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1&quot;&gt;Mark Stamp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04597">
<title>TrustFed: A Reliable Federated Learning Framework with Malicious-Attack Resistance. (arXiv:2312.04597v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04597</link>
<description rdf:parseType="Literal">&lt;p&gt;As a key technology in 6G research, federated learning (FL) enables
collaborative learning among multiple clients while ensuring individual data
privacy. However, malicious attackers among the participating clients can
intentionally tamper with the training data or the trained model, compromising
the accuracy and trustworthiness of the system. To address this issue, in this
paper, we propose a hierarchical audit-based FL (HiAudit-FL) framework, with
the aim to enhance the reliability and security of the learning process. The
hierarchical audit process includes two stages, namely model-audit and
parameter-audit. In the model-audit stage, a low-overhead audit method is
employed to identify suspicious clients. Subsequently, in the parameter-audit
stage, a resource-consuming method is used to detect all malicious clients with
higher accuracy among the suspicious ones. Specifically, we execute the model
audit method among partial clients for multiple rounds, which is modeled as a
partial observation Markov decision process (POMDP) with the aim to enhance the
robustness and accountability of the decision-making in complex and uncertain
environments. Meanwhile, we formulate the problem of identifying malicious
attackers through a multi-round audit as an active sequential hypothesis
testing problem and leverage a diffusion model-based AI-Enabled audit selection
strategy (ASS) to decide which clients should be audited in each round. To
accomplish efficient and effective audit selection, we design a DRL-ASS
algorithm by incorporating the ASS in a deep reinforcement learning (DRL)
framework. Our simulation results demonstrate that HiAudit-FL can effectively
identify and handle potential malicious users accurately, with small system
overhead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hangn Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jianhong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_X/0/1/0/all/0/1&quot;&gt;Xianhua Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_G/0/1/0/all/0/1&quot;&gt;Gang Feng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04600">
<title>Haldane Bundles: A Dataset for Learning to Predict the Chern Number of Line Bundles on the Torus. (arXiv:2312.04600v1 [cond-mat.mes-hall])</title>
<link>http://arxiv.org/abs/2312.04600</link>
<description rdf:parseType="Literal">&lt;p&gt;Characteristic classes, which are abstract topological invariants associated
with vector bundles, have become an important notion in modern physics with
surprising real-world consequences. As a representative example, the incredible
properties of topological insulators, which are insulators in their bulk but
conductors on their surface, can be completely characterized by a specific
characteristic class associated with their electronic band structure, the first
Chern class. Given their importance to next generation computing and the
computational challenge of calculating them using first-principles approaches,
there is a need to develop machine learning approaches to predict the
characteristic classes associated with a material system. To aid in this
program we introduce the {\emph{Haldane bundle dataset}}, which consists of
synthetically generated complex line bundles on the $2$-torus. We envision this
dataset, which is not as challenging as noisy and sparsely measured real-world
datasets but (as we show) still difficult for off-the-shelf architectures, to
be a testing ground for architectures that incorporate the rich topological and
geometric priors underlying characteristic classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Tipton_C/0/1/0/all/0/1&quot;&gt;Cody Tipton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Coda_E/0/1/0/all/0/1&quot;&gt;Elizabeth Coda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Davis Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Bittner_A/0/1/0/all/0/1&quot;&gt;Alyson Bittner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Jorgenson_G/0/1/0/all/0/1&quot;&gt;Grayson Jorgenson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Emerson_T/0/1/0/all/0/1&quot;&gt;Tegan Emerson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Kvinge_H/0/1/0/all/0/1&quot;&gt;Henry Kvinge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04601">
<title>Estimating Fr\&apos;echet bounds for validating programmatic weak supervision. (arXiv:2312.04601v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.04601</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop methods for estimating Fr\&apos;echet bounds on (possibly
high-dimensional) distribution classes in which some variables are
continuous-valued. We establish the statistical correctness of the computed
bounds under uncertainty in the marginal constraints and demonstrate the
usefulness of our algorithms by evaluating the performance of machine learning
(ML) models trained with programmatic weak supervision (PWS). PWS is a
framework for principled learning from weak supervision inputs (e.g.,
crowdsourced labels, knowledge bases, pre-trained models on related tasks,
etc), and it has achieved remarkable success in many areas of science and
engineering. Unfortunately, it is generally difficult to validate the
performance of ML models trained with PWS due to the absence of labeled data.
Our algorithms address this issue by estimating sharp lower and upper bounds
for performance metrics such as accuracy/recall/precision/F1 score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Polo_F/0/1/0/all/0/1&quot;&gt;Felipe Maia Polo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yurochkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Yurochkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Banerjee_M/0/1/0/all/0/1&quot;&gt;Moulinath Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maity_S/0/1/0/all/0/1&quot;&gt;Subha Maity&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yuekai Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04604">
<title>Transferable Candidate Proposal with Bounded Uncertainty. (arXiv:2312.04604v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04604</link>
<description rdf:parseType="Literal">&lt;p&gt;From an empirical perspective, the subset chosen through active learning
cannot guarantee an advantage over random sampling when transferred to another
model. While it underscores the significance of verifying transferability,
experimental design from previous works often neglected that the
informativeness of a data subset can change over model configurations. To
tackle this issue, we introduce a new experimental design, coined as Candidate
Proposal, to find transferable data candidates from which active learning
algorithms choose the informative subset. Correspondingly, a data selection
algorithm is proposed, namely Transferable candidate proposal with Bounded
Uncertainty (TBU), which constrains the pool of transferable data candidates by
filtering out the presumably redundant data points based on uncertainty
estimation. We verified the validity of TBU in image classification benchmarks,
including CIFAR-10/100 and SVHN. When transferred to different model
configurations, TBU consistency improves performance in existing active
learning algorithms. Our code is available at
https://github.com/gokyeongryeol/TBU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Go_K/0/1/0/all/0/1&quot;&gt;Kyeongryeol Go&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kye-Hyeon Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04606">
<title>Urban Region Representation Learning with Attentive Fusion. (arXiv:2312.04606v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04606</link>
<description rdf:parseType="Literal">&lt;p&gt;An increasing number of related urban data sources have brought forth novel
opportunities for learning urban region representations, i.e., embeddings. The
embeddings describe latent features of urban regions and enable discovering
similar regions for urban planning applications. Existing methods learn an
embedding for a region using every different type of region feature data, and
subsequently fuse all learned embeddings of a region to generate a unified
region embedding. However, these studies often overlook the significance of the
fusion process. The typical fusion methods rely on simple aggregation, such as
summation and concatenation, thereby disregarding correlations within the fused
region embeddings.
&lt;/p&gt;
&lt;p&gt;To address this limitation, we propose a novel model named HAFusion. Our
model is powered by a dual-feature attentive fusion module named DAFusion,
which fuses embeddings from different region features to learn higher-order
correlations between the regions as well as between the different types of
region features. DAFusion is generic - it can be integrated into existing
models to enhance their fusion process. Further, motivated by the effective
fusion capability of an attentive module, we propose a hybrid attentive feature
learning module named HALearning to enhance the embedding learning from each
individual type of region features. Extensive experiments on three real-world
datasets demonstrate that our model HAFusion outperforms state-of-the-art
methods across three different prediction tasks. Using our learned region
embedding leads to consistent and up to 31% improvements in the prediction
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fengze Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1&quot;&gt;Jianzhong Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yanchuan Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1&quot;&gt;Xiaoliang Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karunasekera_S/0/1/0/all/0/1&quot;&gt;Shanika Karunasekera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanin_E/0/1/0/all/0/1&quot;&gt;Egemen Tanin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04609">
<title>Short-term prediction of construction waste transport activities using AI-Truck. (arXiv:2312.04609v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04609</link>
<description rdf:parseType="Literal">&lt;p&gt;Construction waste hauling trucks (or `slag trucks&apos;) are among the most
commonly seen heavy-duty vehicles in urban streets, which not only produce
significant NOx and PM emissions but are also a major source of on-road and
on-site fugitive dust. Slag trucks are subject to a series of spatial and
temporal access restrictions by local traffic and environmental policies. This
paper addresses the practical problem of predicting slag truck activity at a
city scale during heavy pollution episodes, such that environmental law
enforcement units can take timely and proactive measures against localized
truck aggregation. A deep ensemble learning framework (coined AI-Truck) is
designed, which employs a soft vote integrator that utilizes BI-LSTM, TCN,
STGCN, and PDFormer as base classifiers to predict the level of slag truck
activities at a resolution of 1km$\times$1km, in a 193 km$^2$ area in Chengdu,
China. As a classifier, AI-Truck yields a Macro f1 close to 80\% for 0.5h- and
1h-prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Meng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1&quot;&gt;Ke Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04610">
<title>Data-driven Semi-supervised Machine Learning with Surrogate Safety Measures for Abnormal Driving Behavior Detection. (arXiv:2312.04610v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04610</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting abnormal driving behavior is critical for road traffic safety and
the evaluation of drivers&apos; behavior. With the advancement of machine learning
(ML) algorithms and the accumulation of naturalistic driving data, many ML
models have been adopted for abnormal driving behavior detection. Most existing
ML-based detectors rely on (fully) supervised ML methods, which require
substantial labeled data. However, ground truth labels are not always available
in the real world, and labeling large amounts of data is tedious. Thus, there
is a need to explore unsupervised or semi-supervised methods to make the
anomaly detection process more feasible and efficient. To fill this research
gap, this study analyzes large-scale real-world data revealing several abnormal
driving behaviors (e.g., sudden acceleration, rapid lane-changing) and develops
a Hierarchical Extreme Learning Machines (HELM) based semi-supervised ML method
using partly labeled data to accurately detect the identified abnormal driving
behaviors. Moreover, previous ML-based approaches predominantly utilize basic
vehicle motion features (such as velocity and acceleration) to label and detect
abnormal driving behaviors, while this study seeks to introduce Surrogate
Safety Measures (SSMs) as the input features for ML models to improve the
detection performance. Results from extensive experiments demonstrate the
effectiveness of the proposed semi-supervised ML model with the introduced SSMs
serving as important features. The proposed semi-supervised ML method
outperforms other baseline semi-supervised or unsupervised methods regarding
various metrics, e.g., delivering the best accuracy at 99.58% and the best F-1
measure at 0.9913. The ablation study further highlights the significance of
SSMs for advancing detection performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lanxin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yongqi Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farah_H/0/1/0/all/0/1&quot;&gt;Haneen Farah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zgonnikov_A/0/1/0/all/0/1&quot;&gt;Arkady Zgonnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arem_B/0/1/0/all/0/1&quot;&gt;Bart van Arem&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04613">
<title>Testing LLM performance on the Physics GRE: some observations. (arXiv:2312.04613v1 [physics.ed-ph])</title>
<link>http://arxiv.org/abs/2312.04613</link>
<description rdf:parseType="Literal">&lt;p&gt;With the recent developments in large language models (LLMs) and their
widespread availability through open source models and/or low-cost APIs,
several exciting products and applications are emerging, many of which are in
the field of STEM educational technology for K-12 and university students.
There is a need to evaluate these powerful language models on several
benchmarks, in order to understand their risks and limitations. In this short
paper, we summarize and analyze the performance of Bard, a popular LLM-based
conversational service made available by Google, on the standardized Physics
GRE examination.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gupta_P/0/1/0/all/0/1&quot;&gt;Pranav Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04615">
<title>Relational Deep Learning: Graph Representation Learning on Relational Databases. (arXiv:2312.04615v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04615</link>
<description rdf:parseType="Literal">&lt;p&gt;Much of the world&apos;s most valued data is stored in relational databases and
data warehouses, where the data is organized into many tables connected by
primary-foreign key relations. However, building machine learning models using
this data is both challenging and time consuming. The core problem is that no
machine learning method is capable of learning on multiple tables
interconnected by primary-foreign key relations. Current methods can only learn
from a single table, so the data must first be manually joined and aggregated
into a single training table, the process known as feature engineering. Feature
engineering is slow, error prone and leads to suboptimal models. Here we
introduce an end-to-end deep representation learning approach to directly learn
on data laid out across multiple tables. We name our approach Relational Deep
Learning (RDL). The core idea is to view relational databases as a temporal,
heterogeneous graph, with a node for each row in each table, and edges
specified by primary-foreign key links. Message Passing Graph Neural Networks
can then automatically learn across the graph to extract representations that
leverage all input data, without any manual feature engineering. Relational
Deep Learning leads to more accurate models that can be built much faster. To
facilitate research in this area, we develop RelBench, a set of benchmark
datasets and an implementation of Relational Deep Learning. The data covers a
wide spectrum, from discussions on Stack Exchange to book reviews on the Amazon
Product Catalog. Overall, we define a new research area that generalizes graph
machine learning and broadens its applicability to a wide set of AI use cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fey_M/0/1/0/all/0/1&quot;&gt;Matthias Fey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Weihua Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kexin Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lenssen_J/0/1/0/all/0/1&quot;&gt;Jan Eric Lenssen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranjan_R/0/1/0/all/0/1&quot;&gt;Rishabh Ranjan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1&quot;&gt;Joshua Robinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1&quot;&gt;Rex Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1&quot;&gt;Jiaxuan You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04640">
<title>Autoencoding Labeled Interpolator, Inferring Parameters From Image, And Image From Parameters. (arXiv:2312.04640v1 [astro-ph.HE])</title>
<link>http://arxiv.org/abs/2312.04640</link>
<description rdf:parseType="Literal">&lt;p&gt;The Event Horizon Telescope (EHT) provides an avenue to study black hole
accretion flows on event-horizon scales. Fitting a semi-analytical model to EHT
observations requires the construction of synthetic images, which is
computationally expensive. This study presents an image generation tool in the
form of a generative machine learning model, which extends the capabilities of
a variational autoencoder. This tool can rapidly and continuously interpolate
between a training set of images and can retrieve the defining parameters of
those images. Trained on a set of synthetic black hole images, our tool
showcases success in both interpolating black hole images and their associated
physical parameters. By reducing the computational cost of generating an image,
this tool facilitates parameter estimation and model validation for
observations of black hole system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+SaraerToosi_A/0/1/0/all/0/1&quot;&gt;Ali SaraerToosi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Broderick_A/0/1/0/all/0/1&quot;&gt;Avery Broderick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04642">
<title>On Sarcasm Detection with OpenAI GPT-based Models. (arXiv:2312.04642v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.04642</link>
<description rdf:parseType="Literal">&lt;p&gt;Sarcasm is a form of irony that requires readers or listeners to interpret
its intended meaning by considering context and social cues. Machine learning
classification models have long had difficulty detecting sarcasm due to its
social complexity and contradictory nature.
&lt;/p&gt;
&lt;p&gt;This paper explores the applications of the Generative Pretrained Transformer
(GPT) models, including GPT-3, InstructGPT, GPT-3.5, and GPT-4, in detecting
sarcasm in natural language. It tests fine-tuned and zero-shot models of
different sizes and releases.
&lt;/p&gt;
&lt;p&gt;The GPT models were tested on the political and balanced (pol-bal) portion of
the popular Self-Annotated Reddit Corpus (SARC 2.0) sarcasm dataset. In the
fine-tuning case, the largest fine-tuned GPT-3 model achieves accuracy and
$F_1$-score of 0.81, outperforming prior models. In the zero-shot case, one of
GPT-4 models yields an accuracy of 0.70 and $F_1$-score of 0.75. Other models
score lower. Additionally, a model&apos;s performance may improve or deteriorate
with each release, highlighting the need to reassess performance after each
release.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gole_M/0/1/0/all/0/1&quot;&gt;Montgomery Gole&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nwadiugwu_W/0/1/0/all/0/1&quot;&gt;Williams-Paul Nwadiugwu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miranskyy_A/0/1/0/all/0/1&quot;&gt;Andriy Miranskyy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04648">
<title>Enhancing Polynomial Chaos Expansion Based Surrogate Modeling using a Novel Probabilistic Transfer Learning Strategy. (arXiv:2312.04648v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.04648</link>
<description rdf:parseType="Literal">&lt;p&gt;In the field of surrogate modeling, polynomial chaos expansion (PCE) allows
practitioners to construct inexpensive yet accurate surrogates to be used in
place of the expensive forward model simulations. For black-box simulations,
non-intrusive PCE allows the construction of these surrogates using a set of
simulation response evaluations. In this context, the PCE coefficients can be
obtained using linear regression, which is also known as point collocation or
stochastic response surfaces. Regression exhibits better scalability and can
handle noisy function evaluations in contrast to other non-intrusive
approaches, such as projection. However, since over-sampling is generally
advisable for the linear regression approach, the simulation requirements
become prohibitive for expensive forward models. We propose to leverage
transfer learning whereby knowledge gained through similar PCE surrogate
construction tasks (source domains) is transferred to a new
surrogate-construction task (target domain) which has a limited number of
forward model simulations (training data). The proposed transfer learning
strategy determines how much, if any, information to transfer using new
techniques inspired by Bayesian modeling and data assimilation. The strategy is
scrutinized using numerical investigations and applied to an engineering
problem from the oil and gas industry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bridgman_W/0/1/0/all/0/1&quot;&gt;Wyatt Bridgman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balakrishnan_U/0/1/0/all/0/1&quot;&gt;Uma Balakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jones_R/0/1/0/all/0/1&quot;&gt;Reese Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiefu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xuqing Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Safta_C/0/1/0/all/0/1&quot;&gt;Cosmin Safta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yueqin Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khalil_M/0/1/0/all/0/1&quot;&gt;Mohammad Khalil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04653">
<title>Learning Thresholds with Latent Values and Censored Feedback. (arXiv:2312.04653v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04653</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we investigate a problem of actively learning threshold in
latent space, where the unknown reward $g(\gamma, v)$ depends on the proposed
threshold $\gamma$ and latent value $v$ and it can be $only$ achieved if the
threshold is lower than or equal to the unknown latent value. This problem has
broad applications in practical scenarios, e.g., reserve price optimization in
online auctions, online task assignments in crowdsourcing, setting recruiting
bars in hiring, etc. We first characterize the query complexity of learning a
threshold with the expected reward at most $\epsilon$ smaller than the optimum
and prove that the number of queries needed can be infinitely large even when
$g(\gamma, v)$ is monotone with respect to both $\gamma$ and $v$. On the
positive side, we provide a tight query complexity
$\tilde{\Theta}(1/\epsilon^3)$ when $g$ is monotone and the CDF of value
distribution is Lipschitz. Moreover, we show a tight
$\tilde{\Theta}(1/\epsilon^3)$ query complexity can be achieved as long as $g$
satisfies one-sided Lipschitzness, which provides a complete characterization
for this problem. Finally, we extend this model to an online learning setting
and demonstrate a tight $\Theta(T^{2/3})$ regret bound using continuous-arm
bandit techniques and the aforementioned query complexity results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiahao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tao Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1&quot;&gt;Weiqiang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zhe Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1&quot;&gt;Yifeng Teng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1&quot;&gt;Xiaotie Deng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04658">
<title>PAC-Bayes Generalization Certificates for Learned Inductive Conformal Prediction. (arXiv:2312.04658v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04658</link>
<description rdf:parseType="Literal">&lt;p&gt;Inductive Conformal Prediction (ICP) provides a practical and effective
approach for equipping deep learning models with uncertainty estimates in the
form of set-valued predictions which are guaranteed to contain the ground truth
with high probability. Despite the appeal of this coverage guarantee, these
sets may not be efficient: the size and contents of the prediction sets are not
directly controlled, and instead depend on the underlying model and choice of
score function. To remedy this, recent work has proposed learning model and
score function parameters using data to directly optimize the efficiency of the
ICP prediction sets. While appealing, the generalization theory for such an
approach is lacking: direct optimization of empirical efficiency may yield
prediction sets that are either no longer efficient on test data, or no longer
obtain the required coverage on test data. In this work, we use PAC-Bayes
theory to obtain generalization bounds on both the coverage and the efficiency
of set-valued predictors which can be directly optimized to maximize efficiency
while satisfying a desired test coverage. In contrast to prior work, our
framework allows us to utilize the entire calibration dataset to learn the
parameters of the model and score function, instead of requiring a separate
hold-out set for obtaining test-time coverage guarantees. We leverage these
theoretical results to provide a practical algorithm for using calibration data
to simultaneously fine-tune the parameters of a model and score function while
guaranteeing test-time coverage and efficiency of the resulting prediction
sets. We evaluate the approach on regression and classification tasks, and
outperform baselines calibrated using a Hoeffding bound-based PAC guarantee on
ICP, especially in the low-data regime.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Apoorva Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veer_S/0/1/0/all/0/1&quot;&gt;Sushant Veer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hancock_A/0/1/0/all/0/1&quot;&gt;Asher Hancock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Heng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1&quot;&gt;Marco Pavone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumdar_A/0/1/0/all/0/1&quot;&gt;Anirudha Majumdar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04660">
<title>Application of machine learning technique for a fast forecast of aggregation kinetics in space-inhomogeneous systems. (arXiv:2312.04660v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/2312.04660</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling of aggregation processes in space-inhomogeneous systems is extremely
numerically challenging since complicated aggregation equations -- Smoluchowski
equations are to be solved at each space point along with the computation of
particle propagation. Low rank approximation for the aggregation kernels can
significantly speed up the solution of Smoluchowski equations, while particle
propagation could be done in parallel. Yet the simulations with many aggregate
sizes remain quite resource-demanding. Here, we explore the way to reduce the
amount of direct computations with the use of modern machine learning (ML)
techniques. Namely, we propose to replace the actual numerical solution of the
Smoluchowki equations with the respective density transformations learned with
the application of the conditional normalising flow. We demonstrate that the ML
predictions for the space distribution of aggregates and their size
distribution requires drastically less computation time and agrees fairly well
with the results of direct numerical simulations. Such an opportunity of a
quick forecast of space-dependent particle size distribution could be important
in practice, especially for the online prediction and visualisation of
pollution processes, providing a tool with a reasonable tradeoff between the
prediction accuracy and the computational time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Larchenko_M/0/1/0/all/0/1&quot;&gt;M.A. Larchenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zagidullin_R/0/1/0/all/0/1&quot;&gt;R.R. Zagidullin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Palyulin_V/0/1/0/all/0/1&quot;&gt;V.V. Palyulin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Brilliantov_N/0/1/0/all/0/1&quot;&gt;N.V. Brilliantov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04668">
<title>TOD-Flow: Modeling the Structure of Task-Oriented Dialogues. (arXiv:2312.04668v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.04668</link>
<description rdf:parseType="Literal">&lt;p&gt;Task-Oriented Dialogue (TOD) systems have become crucial components in
interactive artificial intelligence applications. While recent advances have
capitalized on pre-trained language models (PLMs), they exhibit limitations
regarding transparency and controllability. To address these challenges, we
propose a novel approach focusing on inferring the TOD-Flow graph from dialogue
data annotated with dialog acts, uncovering the underlying task structure in
the form of a graph. The inferred TOD-Flow graph can be easily integrated with
any dialogue model to improve its prediction performance, transparency, and
controllability. Our TOD-Flow graph learns what a model can, should, and should
not predict, effectively reducing the search space and providing a rationale
for the model&apos;s prediction. We show that the proposed TOD-Flow graph better
resembles human-annotated graphs compared to prior approaches. Furthermore,
when combined with several dialogue policies and end-to-end dialogue models, we
demonstrate that our approach significantly improves dialog act classification
and end-to-end response generation performance in the MultiWOZ and SGD
benchmarks. Code available at: https://github.com/srsohn/TOD-Flow
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohn_S/0/1/0/all/0/1&quot;&gt;Sungryull Sohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_Y/0/1/0/all/0/1&quot;&gt;Yiwei Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1&quot;&gt;Anthony Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Logeswaran_L/0/1/0/all/0/1&quot;&gt;Lajanugen Logeswaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dong-Ki Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shim_D/0/1/0/all/0/1&quot;&gt;Dongsub Shim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Honglak Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04670">
<title>Rapid Motor Adaptation for Robotic Manipulator Arms. (arXiv:2312.04670v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.04670</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing generalizable manipulation skills is a core challenge in embodied
AI. This includes generalization across diverse task configurations,
encompassing variations in object shape, density, friction coefficient, and
external disturbances such as forces applied to the robot. Rapid Motor
Adaptation (RMA) offers a promising solution to this challenge. It posits that
essential hidden variables influencing an agent&apos;s task performance, such as
object mass and shape, can be effectively inferred from the agent&apos;s action and
proprioceptive history. Drawing inspiration from RMA in locomotion and in-hand
rotation, we use depth perception to develop agents tailored for rapid motor
adaptation in a variety of manipulation tasks. We evaluated our agents on four
challenging tasks from the Maniskill2 benchmark, namely pick-and-place
operations with hundreds of objects from the YCB and EGAD datasets, peg
insertion with precise position and orientation, and operating a variety of
faucets and handles, with customized environment variations. Empirical results
demonstrate that our agents surpass state-of-the-art methods like automatic
domain randomization and vision-based policies, obtaining better generalization
performance and sample efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yichao Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ellis_K/0/1/0/all/0/1&quot;&gt;Kevin Ellis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Henriques&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04675">
<title>Reverse Engineering Deep ReLU Networks An Optimization-based Algorithm. (arXiv:2312.04675v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04675</link>
<description rdf:parseType="Literal">&lt;p&gt;Reverse engineering deep ReLU networks is a critical problem in understanding
the complex behavior and interpretability of neural networks. In this research,
we present a novel method for reconstructing deep ReLU networks by leveraging
convex optimization techniques and a sampling-based approach. Our method begins
by sampling points in the input space and querying the black box model to
obtain the corresponding hyperplanes. We then define a convex optimization
problem with carefully chosen constraints and conditions to guarantee its
convexity. The objective function is designed to minimize the discrepancy
between the reconstructed networks output and the target models output, subject
to the constraints. We employ gradient descent to optimize the objective
function, incorporating L1 or L2 regularization as needed to encourage sparse
or smooth solutions. Our research contributes to the growing body of work on
reverse engineering deep ReLU networks and paves the way for new advancements
in neural network interpretability and security.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamidi_M/0/1/0/all/0/1&quot;&gt;Mehrab Hamidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04687">
<title>LLM4TDD: Best Practices for Test Driven Development Using Large Language Models. (arXiv:2312.04687v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2312.04687</link>
<description rdf:parseType="Literal">&lt;p&gt;In today&apos;s society, we are becoming increasingly dependent on software
systems. However, we also constantly witness the negative impacts of buggy
software. Program synthesis aims to improve software correctness by
automatically generating the program given an outline of the expected behavior.
For decades, program synthesis has been an active research field, with recent
approaches looking to incorporate Large Language Models to help generate code.
This paper explores the concept of LLM4TDD, where we guide Large Language
Models to generate code iteratively using a test-driven development
methodology. We conduct an empirical evaluation using ChatGPT and coding
problems from LeetCode to investigate the impact of different test, prompt and
problem attributes on the efficacy of LLM4TDD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piya_S/0/1/0/all/0/1&quot;&gt;Sanyogita Piya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sullivan_A/0/1/0/all/0/1&quot;&gt;Allison Sullivan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04688">
<title>Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights. (arXiv:2312.04688v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04688</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial Intelligence (AI) is expected to play an instrumental role in the
next generation of wireless systems, such as sixth-generation (6G) mobile
network. However, massive data, energy consumption, training complexity, and
sensitive data protection in wireless systems are all crucial challenges that
must be addressed for training AI models and gathering intelligence and
knowledge from distributed devices. Federated Learning (FL) is a recent
framework that has emerged as a promising approach for multiple learning agents
to build an accurate and robust machine learning models without sharing raw
data. By allowing mobile handsets and devices to collaboratively learn a global
model without explicit sharing of training data, FL exhibits high privacy and
efficient spectrum utilization. While there are a lot of survey papers
exploring FL paradigms and usability in 6G privacy, none of them has clearly
addressed how FL can be used to improve the protocol stack and wireless
operations. The main goal of this survey is to provide a comprehensive overview
on FL usability to enhance mobile services and enable smart ecosystems to
support novel use-cases. This paper examines the added-value of implementing FL
throughout all levels of the protocol stack. Furthermore, it presents important
FL applications, addresses hot topics, provides valuable insights and explicits
guidance for future research and developments. Our concluding remarks aim to
leverage the synergy between FL and future 6G, while highlighting FL&apos;s
potential to revolutionize wireless industry and sustain the development of
cutting-edge mobile services.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Driss_M/0/1/0/all/0/1&quot;&gt;Maryam Ben Driss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabir_E/0/1/0/all/0/1&quot;&gt;Essaid Sabir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elbiaze_H/0/1/0/all/0/1&quot;&gt;Halima Elbiaze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1&quot;&gt;Walid Saad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04692">
<title>Diffence: Fencing Membership Privacy With Diffusion Models. (arXiv:2312.04692v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04692</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models, while achieving remarkable performance across various
tasks, are vulnerable to member inference attacks, wherein adversaries identify
if a specific data point was part of a model&apos;s training set. This
susceptibility raises substantial privacy concerns, especially when models are
trained on sensitive datasets. Current defense methods often struggle to
provide robust protection without hurting model utility, and they often require
retraining the model or using extra data. In this work, we introduce a novel
defense framework against membership attacks by leveraging generative models.
The key intuition of our defense is to remove the differences between member
and non-member inputs which can be used to perform membership attacks, by
re-generating input samples before feeding them to the target model. Therefore,
our defense works \emph{pre-inference}, which is unlike prior defenses that are
either training-time (modify the model) or post-inference time (modify the
model&apos;s output).
&lt;/p&gt;
&lt;p&gt;A unique feature of our defense is that it works on input samples only,
without modifying the training or inference phase of the target model.
Therefore, it can be cascaded with other defense mechanisms as we demonstrate
through experiments. Through extensive experimentation, we show that our
approach can serve as a robust plug-n-play defense mechanism, enhancing
membership privacy without compromising model utility in both baseline and
defended settings. For example, our method enhanced the effectiveness of recent
state-of-the-art defenses, reducing attack accuracy by an average of 5.7\% to
12.4\% across three datasets, without any impact on the model&apos;s accuracy. By
integrating our method with prior defenses, we achieve new state-of-the-art
performance in the privacy-utility trade-off.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1&quot;&gt;Yuefeng Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naseh_A/0/1/0/all/0/1&quot;&gt;Ali Naseh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houmansadr_A/0/1/0/all/0/1&quot;&gt;Amir Houmansadr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04693">
<title>GraphMETRO: Mitigating Complex Distribution Shifts in GNNs via Mixture of Aligned Experts. (arXiv:2312.04693v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04693</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks&apos; (GNNs) ability to generalize across complex
distributions is crucial for real-world applications. However, prior research
has primarily focused on specific types of distribution shifts, such as larger
graph size, or inferred shifts from constructed data environments, which is
highly limited when confronted with multiple and nuanced distribution shifts.
For instance, in a social graph, a user node might experience increased
interactions and content alterations, while other user nodes encounter distinct
shifts. Neglecting such complexities significantly impedes generalization. To
address it, we present GraphMETRO, a novel framework that enhances GNN
generalization under complex distribution shifts in both node and graph-level
tasks. Our approach employs a mixture-of-experts (MoE) architecture with a
gating model and expert models aligned in a shared representation space. The
gating model identifies key mixture components governing distribution shifts,
while each expert generates invariant representations w.r.t. a mixture
component. Finally, GraphMETRO aggregates representations from multiple experts
to generate the final invariant representation. Our experiments on synthetic
and realworld datasets demonstrate GraphMETRO&apos;s superiority and
interpretability. To highlight, GraphMETRO achieves state-of-the-art
performances on four real-world datasets from GOOD benchmark, outperforming the
best baselines on WebKB and Twitch datasets by 67% and 4.2%, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1&quot;&gt;Shirley Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_K/0/1/0/all/0/1&quot;&gt;Kaidi Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1&quot;&gt;Bruno Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1&quot;&gt;James Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04704">
<title>Optimizing Distributed Reinforcement Learning with Reactor Model and Lingua Franca. (arXiv:2312.04704v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2312.04704</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributed Reinforcement Learning (RL) frameworks are essential for mapping
RL workloads to multiple computational resources, allowing for faster
generation of samples, estimation of values, and policy improvement. These
computational paradigms require a seamless integration of training, serving,
and simulation workloads. Existing frameworks, such as Ray, are not managing
this orchestration efficiently. In this study, we&apos;ve proposed a solution
implementing Reactor Model, which enforces a set of actors to have a fixed
communication pattern. This allows the scheduler to eliminate works needed for
synchronization, such as acquiring and releasing locks for each actor or
sending and processing coordination-related messages. Our framework, Lingua
Franca (LF), a coordination language based on the Reactor Model, also provides
a unified interface that allows users to automatically generate dataflow graphs
for distributed RL. On average, LF outperformed Ray in generating samples from
OpenAI Gym and Atari environments by 1.21x and 11.62x, reduced the average
training time of synchronized parallel Q-learning by 31.2%, and accelerated
Multi-Agent RL inference by 5.12x.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1&quot;&gt;Jacky Kwok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lohstroh_M/0/1/0/all/0/1&quot;&gt;Marten Lohstroh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1&quot;&gt;Edward A. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04709">
<title>How to guess a gradient. (arXiv:2312.04709v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04709</link>
<description rdf:parseType="Literal">&lt;p&gt;How much can you say about the gradient of a neural network without computing
a loss or knowing the label? This may sound like a strange question: surely the
answer is &quot;very little.&quot; However, in this paper, we show that gradients are
more structured than previously thought. Gradients lie in a predictable
low-dimensional subspace which depends on the network architecture and incoming
features. Exploiting this structure can significantly improve gradient-free
optimization schemes based on directional derivatives, which have struggled to
scale beyond small networks trained on toy datasets. We study how to narrow the
gap in optimization performance between methods that calculate exact gradients
and those that use directional derivatives. Furthermore, we highlight new
challenges in overcoming the large gap between optimizing with exact gradients
and guessing the gradients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhal_U/0/1/0/all/0/1&quot;&gt;Utkarsh Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_B/0/1/0/all/0/1&quot;&gt;Brian Cheung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_K/0/1/0/all/0/1&quot;&gt;Kartik Chandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ragan_Kelley_J/0/1/0/all/0/1&quot;&gt;Jonathan Ragan-Kelley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Joshua B. Tenenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poggio_T/0/1/0/all/0/1&quot;&gt;Tomaso A. Poggio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Stella X. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04712">
<title>Error Discovery by Clustering Influence Embeddings. (arXiv:2312.04712v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04712</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for identifying groups of test examples -- slices -- on
which a model under-performs, a task now known as slice discovery. We formalize
coherence -- a requirement that erroneous predictions, within a slice, should
be wrong for the same reason -- as a key property that any slice discovery
method should satisfy. We then use influence functions to derive a new slice
discovery method, InfEmbed, which satisfies coherence by returning slices whose
examples are influenced similarly by the training data. InfEmbed is simple, and
consists of applying K-Means clustering to a novel representation we deem
influence embeddings. We show InfEmbed outperforms current state-of-the-art
methods on 2 benchmarks, and is effective for model debugging across several
case studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fulton Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adebayo_J/0/1/0/all/0/1&quot;&gt;Julius Adebayo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1&quot;&gt;Sarah Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Olano_D/0/1/0/all/0/1&quot;&gt;Diego Garcia-Olano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kokhlikyan_N/0/1/0/all/0/1&quot;&gt;Narine Kokhlikyan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04713">
<title>gcDLSeg: Integrating Graph-cut into Deep Learning for Binary Semantic Segmentation. (arXiv:2312.04713v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.04713</link>
<description rdf:parseType="Literal">&lt;p&gt;Binary semantic segmentation in computer vision is a fundamental problem. As
a model-based segmentation method, the graph-cut approach was one of the most
successful binary segmentation methods thanks to its global optimality
guarantee of the solutions and its practical polynomial-time complexity.
Recently, many deep learning (DL) based methods have been developed for this
task and yielded remarkable performance, resulting in a paradigm shift in this
field. To combine the strengths of both approaches, we propose in this study to
integrate the graph-cut approach into a deep learning network for end-to-end
learning. Unfortunately, backward propagation through the graph-cut module in
the DL network is challenging due to the combinatorial nature of the graph-cut
algorithm. To tackle this challenge, we propose a novel residual graph-cut loss
and a quasi-residual connection, enabling the backward propagation of the
gradients of the residual graph-cut loss for effective feature learning guided
by the graph-cut segmentation model. In the inference phase, globally optimal
segmentation is achieved with respect to the graph-cut energy defined on the
optimized image features learned from DL networks. Experiments on the public
AZH chronic wound data set and the pancreas cancer data set from the medical
segmentation decathlon (MSD) demonstrated promising segmentation accuracy, and
improved robustness against adversarial attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1&quot;&gt;Hui Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Weiyu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Ya Xing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buatti_J/0/1/0/all/0/1&quot;&gt;John Buatti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaodong Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04715">
<title>Deep Emotions Across Languages: A Novel Approach for Sentiment Propagation in Multilingual WordNets. (arXiv:2312.04715v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.04715</link>
<description rdf:parseType="Literal">&lt;p&gt;Sentiment analysis involves using WordNets enriched with emotional metadata,
which are valuable resources. However, manual annotation is time-consuming and
expensive, resulting in only a few WordNet Lexical Units being annotated. This
paper introduces two new techniques for automatically propagating sentiment
annotations from a partially annotated WordNet to its entirety and to a WordNet
in a different language: Multilingual Structured Synset Embeddings (MSSE) and
Cross-Lingual Deep Neural Sentiment Propagation (CLDNS). We evaluated the
proposed MSSE+CLDNS method extensively using Princeton WordNet and Polish
WordNet, which have many inter-lingual relations. Our results show that the
MSSE+CLDNS method outperforms existing propagation methods, indicating its
effectiveness in enriching WordNets with emotional metadata across multiple
languages. This work provides a solid foundation for large-scale, multilingual
sentiment analysis and is valuable for academic research and practical
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kocon_J/0/1/0/all/0/1&quot;&gt;Jan Koco&amp;#x144;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04718">
<title>Dynamic Online Modulation Recognition using Incremental Learning. (arXiv:2312.04718v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.04718</link>
<description rdf:parseType="Literal">&lt;p&gt;Modulation recognition is a fundamental task in communication systems as the
accurate identification of modulation schemes is essential for reliable signal
processing, interference mitigation for coexistent communication technologies,
and network optimization. Incorporating deep learning (DL) models into
modulation recognition has demonstrated promising results in various scenarios.
However, conventional DL models often fall short in online dynamic contexts,
particularly in class incremental scenarios where new modulation schemes are
encountered during online deployment. Retraining these models on all previously
seen modulation schemes is not only time-consuming but may also not be feasible
due to storage limitations. On the other hand, training solely on new
modulation schemes often results in catastrophic forgetting of previously
learned classes. This issue renders DL-based modulation recognition models
inapplicable in real-world scenarios because the dynamic nature of
communication systems necessitate the effective adaptability to new modulation
schemes. This paper addresses this challenge by evaluating the performance of
multiple Incremental Learning (IL) algorithms in dynamic modulation recognition
scenarios, comparing them against conventional DL-based modulation recognition.
Our results demonstrate that modulation recognition frameworks based on IL
effectively prevent catastrophic forgetting, enabling models to perform
robustly in dynamic scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Owfi_A/0/1/0/all/0/1&quot;&gt;Ali Owfi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Abbasi_A/0/1/0/all/0/1&quot;&gt;Ali Abbasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Afghah_F/0/1/0/all/0/1&quot;&gt;Fatemeh Afghah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ashdown_J/0/1/0/all/0/1&quot;&gt;Jonathan Ashdown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Turck_K/0/1/0/all/0/1&quot;&gt;Kurt Turck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04719">
<title>Distributed Optimization via Kernelized Multi-armed Bandits. (arXiv:2312.04719v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04719</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-armed bandit algorithms provide solutions for sequential
decision-making where learning takes place by interacting with the environment.
In this work, we model a distributed optimization problem as a multi-agent
kernelized multi-armed bandit problem with a heterogeneous reward setting. In
this setup, the agents collaboratively aim to maximize a global objective
function which is an average of local objective functions. The agents can
access only bandit feedback (noisy reward) obtained from the associated unknown
local function with a small norm in reproducing kernel Hilbert space (RKHS). We
present a fully decentralized algorithm, Multi-agent IGP-UCB (MA-IGP-UCB),
which achieves a sub-linear regret bound for popular classes for kernels while
preserving privacy. It does not necessitate the agents to share their actions,
rewards, or estimates of their local function. In the proposed approach, the
agents sample their individual local functions in a way that benefits the whole
network by utilizing a running consensus to estimate the upper confidence bound
on the global function. Furthermore, we propose an extension, Multi-agent
Delayed IGP-UCB (MAD-IGP-UCB) algorithm, which reduces the dependence of the
regret bound on the number of agents in the network. It provides improved
performance by utilizing a delay in the estimation update step at the cost of
more communication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rai_A/0/1/0/all/0/1&quot;&gt;Ayush Rai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mou_S/0/1/0/all/0/1&quot;&gt;Shaoshuai Mou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04720">
<title>From Big to Small Without Losing It All: Text Augmentation with ChatGPT for Efficient Sentiment Analysis. (arXiv:2312.04720v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.04720</link>
<description rdf:parseType="Literal">&lt;p&gt;In the era of artificial intelligence, data is gold but costly to annotate.
The paper demonstrates a groundbreaking solution to this dilemma using ChatGPT
for text augmentation in sentiment analysis. We leverage ChatGPT&apos;s generative
capabilities to create synthetic training data that significantly improves the
performance of smaller models, making them competitive with, or even
outperforming, their larger counterparts. This innovation enables models to be
both efficient and effective, thereby reducing computational cost, inference
time, and memory usage without compromising on quality. Our work marks a key
advancement in the cost-effective development and deployment of robust
sentiment analysis models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wozniak_S/0/1/0/all/0/1&quot;&gt;Stanis&amp;#x142;aw Wo&amp;#x17a;niak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kocon_J/0/1/0/all/0/1&quot;&gt;Jan Koco&amp;#x144;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04724">
<title>Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models. (arXiv:2312.04724v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04724</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents CyberSecEval, a comprehensive benchmark developed to help
bolster the cybersecurity of Large Language Models (LLMs) employed as coding
assistants. As what we believe to be the most extensive unified cybersecurity
safety benchmark to date, CyberSecEval provides a thorough evaluation of LLMs
in two crucial security domains: their propensity to generate insecure code and
their level of compliance when asked to assist in cyberattacks. Through a case
study involving seven models from the Llama 2, Code Llama, and OpenAI GPT large
language model families, CyberSecEval effectively pinpointed key cybersecurity
risks. More importantly, it offered practical insights for refining these
models. A significant observation from the study was the tendency of more
advanced models to suggest insecure code, highlighting the critical need for
integrating security considerations in the development of sophisticated LLMs.
CyberSecEval, with its automated test case generation and evaluation pipeline
covers a broad scope and equips LLM designers and researchers with a tool to
broadly measure and enhance the cybersecurity safety properties of LLMs,
contributing to the development of more secure AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhatt_M/0/1/0/all/0/1&quot;&gt;Manish Bhatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chennabasappa_S/0/1/0/all/0/1&quot;&gt;Sahana Chennabasappa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolaidis_C/0/1/0/all/0/1&quot;&gt;Cyrus Nikolaidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_S/0/1/0/all/0/1&quot;&gt;Shengye Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1&quot;&gt;Ivan Evtimov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabi_D/0/1/0/all/0/1&quot;&gt;Dominik Gabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Daniel Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmad_F/0/1/0/all/0/1&quot;&gt;Faizan Ahmad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aschermann_C/0/1/0/all/0/1&quot;&gt;Cornelius Aschermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fontana_L/0/1/0/all/0/1&quot;&gt;Lorenzo Fontana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frolov_S/0/1/0/all/0/1&quot;&gt;Sasha Frolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giri_R/0/1/0/all/0/1&quot;&gt;Ravi Prakash Giri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapil_D/0/1/0/all/0/1&quot;&gt;Dhaval Kapil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozyrakis_Y/0/1/0/all/0/1&quot;&gt;Yiannis Kozyrakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeBlanc_D/0/1/0/all/0/1&quot;&gt;David LeBlanc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milazzo_J/0/1/0/all/0/1&quot;&gt;James Milazzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Straumann_A/0/1/0/all/0/1&quot;&gt;Aleksandar Straumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1&quot;&gt;Gabriel Synnaeve&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vontimitta_V/0/1/0/all/0/1&quot;&gt;Varun Vontimitta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whitman_S/0/1/0/all/0/1&quot;&gt;Spencer Whitman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxe_J/0/1/0/all/0/1&quot;&gt;Joshua Saxe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04737">
<title>Efficient Large Language Models Fine-Tuning On Graphs. (arXiv:2312.04737v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04737</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning from Text-Attributed Graphs (TAGs) has attracted significant
attention due to its wide range of real-world applications. The rapid evolution
of large language models (LLMs) has revolutionized the way we process textual
data, which indicates a strong potential to replace shallow text embedding
generally used in Graph Neural Networks (GNNs). However, we find that existing
LLM approaches that exploit text information in graphs suffer from inferior
computation and data efficiency. In this work, we introduce a novel and
efficient approach for the end-to-end fine-tuning of Large Language Models
(LLMs) on TAGs, named LEADING. The proposed approach maintains computation cost
and memory overhead comparable to the graph-less fine-tuning of LLMs. Moreover,
it transfers the rick knowledge in LLMs to downstream graph learning tasks
effectively with limited labeled data in semi-supervised learning. Its superior
computation and data efficiency are demonstrated through comprehensive
experiments, offering a promising solution for a wide range of LLMs and graph
learning tasks on TAGs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_R/0/1/0/all/0/1&quot;&gt;Rui Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1&quot;&gt;Xipeng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1&quot;&gt;Ruozhou Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaorui Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04739">
<title>Unnatural Algorithms in Machine Learning. (arXiv:2312.04739v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.04739</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural gradient descent has a remarkable property that in the small learning
rate limit, it displays an invariance with respect to network
reparameterizations, leading to robust training behavior even for highly
covariant network parameterizations. We show that optimization algorithms with
this property can be viewed as discrete approximations of natural
transformations from the functor determining an optimizer&apos;s state space from
the diffeomorphism group if its configuration manifold, to the functor
determining that state space&apos;s tangent bundle from this group. Algorithms with
this property enjoy greater efficiency when used to train poorly parameterized
networks, as the network evolution they generate is approximately invariant to
network reparameterizations. More specifically, the flow generated by these
algorithms in the limit as the learning rate vanishes is invariant under smooth
reparameterizations, the respective flows of the parameters being determined by
equivariant maps. By casting this property a natural transformation, we allow
for generalizations beyond equivariance with respect to group actions; this
framework can account for non-invertible maps such as projections, creating a
framework for the direct comparison of training behavior across non-isomorphic
network architectures, and the formal examination of limiting behavior as
network size increases by considering inverse limits of these projections,
should they exist. We introduce a simple method of introducing this naturality
more generally and examine a number of popular machine learning training
algorithms, finding that most are unnatural.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goodbrake_C/0/1/0/all/0/1&quot;&gt;Christian Goodbrake&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04740">
<title>Train &apos;n Trade: Foundations of Parameter Markets. (arXiv:2312.04740v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04740</link>
<description rdf:parseType="Literal">&lt;p&gt;Organizations typically train large models individually. This is costly and
time-consuming, particularly for large-scale foundation models. Such vertical
production is known to be suboptimal. Inspired by this economic insight, we ask
whether it is possible to leverage others&apos; expertise by trading the constituent
parts in models, i.e., sets of weights, as if they were market commodities.
While recent advances in aligning and interpolating models suggest that doing
so may be possible, a number of fundamental questions must be answered to
create viable parameter markets. In this work, we address these basic
questions, propose a framework containing the infrastructure necessary for
market operations to take place, study strategies for exchanging parameters,
and offer means for agents to monetize parameters. Excitingly, compared to
agents who train siloed models from scratch, we show that it is possible to
mutually gain by using the market, even in competitive settings. This suggests
that the notion of parameter markets may be a useful paradigm for improving
large-scale model training in the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Tzu-Heng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishwakarma_H/0/1/0/all/0/1&quot;&gt;Harit Vishwakarma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sala_F/0/1/0/all/0/1&quot;&gt;Frederic Sala&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04744">
<title>Fine-Grained Extraction of Road Networks via Joint Learning of Connectivity and Segmentation. (arXiv:2312.04744v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.04744</link>
<description rdf:parseType="Literal">&lt;p&gt;Road network extraction from satellite images is widely applicated in
intelligent traffic management and autonomous driving fields. The
high-resolution remote sensing images contain complex road areas and distracted
background, which make it a challenge for road extraction. In this study, we
present a stacked multitask network for end-to-end segmenting roads while
preserving connectivity correctness. In the network, a global-aware module is
introduced to enhance pixel-level road feature representation and eliminate
background distraction from overhead images; a road-direction-related
connectivity task is added to ensure that the network preserves the graph-level
relationships of the road segments. We also develop a stacked multihead
structure to jointly learn and effectively utilize the mutual information
between connectivity learning and segmentation learning. We evaluate the
performance of the proposed network on three public remote sensing datasets.
The experimental results demonstrate that the network outperforms the
state-of-the-art methods in terms of road segmentation accuracy and
connectivity maintenance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yijia Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liqiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wuming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Suhong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jingwen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xingang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuebin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04745">
<title>A Brief Tutorial on Sample Size Calculations for Fairness Audits. (arXiv:2312.04745v1 [stat.AP])</title>
<link>http://arxiv.org/abs/2312.04745</link>
<description rdf:parseType="Literal">&lt;p&gt;In fairness audits, a standard objective is to detect whether a given
algorithm performs substantially differently between subgroups. Properly
powering the statistical analysis of such audits is crucial for obtaining
informative fairness assessments, as it ensures a high probability of detecting
unfairness when it exists. However, limited guidance is available on the amount
of data necessary for a fairness audit, lacking directly applicable results
concerning commonly used fairness metrics. Additionally, the consideration of
unequal subgroup sample sizes is also missing. In this tutorial, we address
these issues by providing guidance on how to determine the required subgroup
sample sizes to maximize the statistical power of hypothesis tests for
detecting unfairness. Our findings are applicable to audits of binary
classification models and multiple fairness metrics derived as summaries of the
confusion matrix. Furthermore, we discuss other aspects of audit study designs
that can increase the reliability of audit results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_H/0/1/0/all/0/1&quot;&gt;Harvineet Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xia_F/0/1/0/all/0/1&quot;&gt;Fan Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Mi-Ok Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pirracchio_R/0/1/0/all/0/1&quot;&gt;Romain Pirracchio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chunara_R/0/1/0/all/0/1&quot;&gt;Rumi Chunara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jean Feng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04752">
<title>A Test-Time Learning Approach to Reparameterize the Geophysical Inverse Problem with a Convolutional Neural Network. (arXiv:2312.04752v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04752</link>
<description rdf:parseType="Literal">&lt;p&gt;Regularization is critical in solving the ill-posed geo-physical inversion
problems. Explicit regularization is often used, but there are opportunities to
explore the implicit regularization effect inherently from a Neural Network
structure. Researchers in Computer Vision (CV) have discovered that the
Convolutional Neural Network (CNN) architecture inherently enforces a
regularization that is advantageous for addressing diverse CV inverse problems,
including de-noising and in-painting. In this study, we examine the
applicability of this implicit regularization to geophysical inversions. The
CNN maps an arbitrary vector to the model space (e.g. log-conductivity on the
simulation mesh). The predicted subsurface model is then fed into a forward
numerical simulation process to generate corresponding predicted measurements.
Subsequently, the objective function value is computed by comparing these
predicted measurements with the observed field measurements. The
backpropagation algorithm is employed to update the trainable parameters of the
CNN during the inversion. Note that the CNN in our proposed method does not
require training before the inversion, rather, the CNN weights are estimated in
the inversion algorithm, hence this is a test-time learning (TTL) approach. The
results demonstrate that the implicit regularization provided by the CNN can be
useful in DC resistivity inversions. We also provide a detailed discussion of
the potential sources of this implicit regularization and some practical guides
for applying the proposed method to other geophysical scenarios. The proposed
approach for reparameterizing the inverse problem can be adapted to other
Tikhonov-style geophysical inversions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1&quot;&gt;Anran Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heagy_L/0/1/0/all/0/1&quot;&gt;Lindsey J. Heagy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04757">
<title>Induced Generative Adversarial Particle Transformers. (arXiv:2312.04757v1 [hep-ex])</title>
<link>http://arxiv.org/abs/2312.04757</link>
<description rdf:parseType="Literal">&lt;p&gt;In high energy physics (HEP), machine learning methods have emerged as an
effective way to accurately simulate particle collisions at the Large Hadron
Collider (LHC). The message-passing generative adversarial network (MPGAN) was
the first model to simulate collisions as point, or ``particle&apos;&apos;, clouds, with
state-of-the-art results, but suffered from quadratic time complexity.
Recently, generative adversarial particle transformers (GAPTs) were introduced
to address this drawback; however, results did not surpass MPGAN. We introduce
induced GAPT (iGAPT) which, by integrating ``induced particle-attention
blocks&apos;&apos; and conditioning on global jet attributes, not only offers linear time
complexity but is also able to capture intricate jet substructure, surpassing
MPGAN in many metrics. Our experiments demonstrate the potential of iGAPT to
simulate complex HEP data accurately and efficiently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Anni Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Krishnamohan_V/0/1/0/all/0/1&quot;&gt;Venkat Krishnamohan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Kansal_R/0/1/0/all/0/1&quot;&gt;Raghav Kansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Sen_R/0/1/0/all/0/1&quot;&gt;Rounak Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Tsan_S/0/1/0/all/0/1&quot;&gt;Steven Tsan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhaoyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Duarte_J/0/1/0/all/0/1&quot;&gt;Javier Duarte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04758">
<title>Physics-Informed Convolutional Autoencoder for Cyber Anomaly Detection in Power Distribution Grids. (arXiv:2312.04758v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2312.04758</link>
<description rdf:parseType="Literal">&lt;p&gt;The growing trend toward the modernization of power distribution systems has
facilitated the installation of advanced measurement units and promotion of the
cyber communication systems. However, these infrastructures are still prone to
stealth cyber attacks. The existing data-driven anomaly detection methods
suffer from a lack of knowledge about the system&apos;s physics, lack of
interpretability, and scalability issues hindering their practical applications
in real-world scenarios. To address these concerns, physics-informed neural
networks (PINNs) were introduced. This paper proposes a multivariate
physics-informed convolutional autoencoder (PIConvAE) to detect stealthy
cyber-attacks in power distribution grids. The proposed model integrates the
physical principles into the loss function of the neural network by applying
Kirchhoff&apos;s law. Simulations are performed on the modified IEEE 13-bus and
123-bus systems using OpenDSS software to validate the efficacy of the proposed
model for stealth attacks. The numerical results prove the superior performance
of the proposed PIConvAE in three aspects: a) it provides more accurate results
compared to the data-driven ConvAE model, b) it requires less training time to
converge c) the model excels in effectively detecting a wide range of attack
magnitudes making it powerful in detecting stealth attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zideh_M/0/1/0/all/0/1&quot;&gt;Mehdi Jabbari Zideh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Solanki_S/0/1/0/all/0/1&quot;&gt;Sarika Khushalani Solanki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04762">
<title>The Graph Lottery Ticket Hypothesis: Finding Sparse, Informative Graph Structure. (arXiv:2312.04762v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04762</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph learning methods help utilize implicit relationships among data items,
thereby reducing training label requirements and improving task performance.
However, determining the optimal graph structure for a particular learning task
remains a challenging research problem.
&lt;/p&gt;
&lt;p&gt;In this work, we introduce the Graph Lottery Ticket (GLT) Hypothesis - that
there is an extremely sparse backbone for every graph, and that graph learning
algorithms attain comparable performance when trained on that subgraph as on
the full graph. We identify and systematically study 8 key metrics of interest
that directly influence the performance of graph learning algorithms.
Subsequently, we define the notion of a &quot;winning ticket&quot; for graph structure -
an extremely sparse subset of edges that can deliver a robust approximation of
the entire graph&apos;s performance. We propose a straightforward and efficient
algorithm for finding these GLTs in arbitrary graphs. Empirically, we observe
that performance of different graph learning algorithms can be matched or even
exceeded on graphs with the average degree as low as 5.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsitsulin_A/0/1/0/all/0/1&quot;&gt;Anton Tsitsulin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perozzi_B/0/1/0/all/0/1&quot;&gt;Bryan Perozzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04772">
<title>Remembering to Be Fair: On Non-Markovian Fairness in Sequential DecisionMaking (Preliminary Report). (arXiv:2312.04772v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.04772</link>
<description rdf:parseType="Literal">&lt;p&gt;Fair decision making has largely been studied with respect to a single
decision. In this paper we investigate the notion of fairness in the context of
sequential decision making where multiple stakeholders can be affected by the
outcomes of decisions, and where decision making may be informed by additional
constraints and criteria beyond the requirement of fairness. In this setting,
we observe that fairness often depends on the history of the sequential
decision-making process and not just on the current state. To advance our
understanding of this class of fairness problems, we define the notion of
non-Markovian fairness in the context of sequential decision making. We
identify properties of non-Markovian fairness, including notions of long-term,
anytime, periodic, and bounded fairness. We further explore the interplay
between non-Markovian fairness and memory, and how this can support
construction of fair policies in sequential decision-making settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alamdari_P/0/1/0/all/0/1&quot;&gt;Parand A. Alamdari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klassen_T/0/1/0/all/0/1&quot;&gt;Toryn Q. Klassen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Creager_E/0/1/0/all/0/1&quot;&gt;Elliot Creager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McIlraith_S/0/1/0/all/0/1&quot;&gt;Sheila A. McIlraith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04779">
<title>Image Synthesis-based Late Stage Cancer Augmentation and Semi-Supervised Segmentation for MRI Rectal Cancer Staging. (arXiv:2312.04779v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.04779</link>
<description rdf:parseType="Literal">&lt;p&gt;Rectal cancer is one of the most common diseases and a major cause of
mortality. For deciding rectal cancer treatment plans, T-staging is important.
However, evaluating the index from preoperative MRI images requires high
radiologists&apos; skill and experience. Therefore, the aim of this study is to
segment the mesorectum, rectum, and rectal cancer region so that the system can
predict T-stage from segmentation results. Generally, shortage of large and
diverse dataset and high quality annotation are known to be the bottlenecks in
computer aided diagnostics development. Regarding rectal cancer, advanced
cancer images are very rare, and per-pixel annotation requires high
radiologists&apos; skill and time. Therefore, it is not feasible to collect
comprehensive disease patterns in a training dataset. To tackle this, we
propose two kinds of approaches of image synthesis-based late stage cancer
augmentation and semi-supervised learning which is designed for T-stage
prediction. In the image synthesis data augmentation approach, we generated
advanced cancer images from labels. The real cancer labels were deformed to
resemble advanced cancer labels by artificial cancer progress simulation. Next,
we introduce a T-staging loss which enables us to train segmentation models
from per-image T-stage labels. The loss works to keep inclusion/invasion
relationships between rectum and cancer region consistent to the ground truth
T-stage. The verification tests show that the proposed method obtains the best
sensitivity (0.76) and specificity (0.80) in distinguishing between over T3
stage and underT2. In the ablation studies, our semi-supervised learning
approach with the T-staging loss improved specificity by 0.13. Adding the image
synthesis-based data augmentation improved the DICE score of invasion cancer
area by 0.08 from baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sasuga_S/0/1/0/all/0/1&quot;&gt;Saeko Sasuga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kudo_A/0/1/0/all/0/1&quot;&gt;Akira Kudo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kitamura_Y/0/1/0/all/0/1&quot;&gt;Yoshiro Kitamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Iizuka_S/0/1/0/all/0/1&quot;&gt;Satoshi Iizuka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Simo_Serra_E/0/1/0/all/0/1&quot;&gt;Edgar Simo-Serra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hamabe_A/0/1/0/all/0/1&quot;&gt;Atsushi Hamabe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ishii_M/0/1/0/all/0/1&quot;&gt;Masayuki Ishii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Takemasa_I/0/1/0/all/0/1&quot;&gt;Ichiro Takemasa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04782">
<title>Make Them Spill the Beans! Coercive Knowledge Extraction from (Production) LLMs. (arXiv:2312.04782v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04782</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) are now widely used in various applications,
making it crucial to align their ethical standards with human values. However,
recent jail-breaking methods demonstrate that this alignment can be undermined
using carefully constructed prompts. In our study, we reveal a new threat to
LLM alignment when a bad actor has access to the model&apos;s output logits, a
common feature in both open-source LLMs and many commercial LLM APIs (e.g.,
certain GPT models). It does not rely on crafting specific prompts. Instead, it
exploits the fact that even when an LLM rejects a toxic request, a harmful
response often hides deep in the output logits. By forcefully selecting
lower-ranked output tokens during the auto-regressive generation process at a
few critical output positions, we can compel the model to reveal these hidden
responses. We term this process model interrogation. This approach differs from
and outperforms jail-breaking methods, achieving 92% effectiveness compared to
62%, and is 10 to 20 times faster. The harmful content uncovered through our
method is more relevant, complete, and clear. Additionally, it can complement
jail-breaking strategies, with which results in further boosting attack
performance. Our findings indicate that interrogation can extract toxic
knowledge even from models specifically designed for coding tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhuo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_G/0/1/0/all/0/1&quot;&gt;Guangyu Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_G/0/1/0/all/0/1&quot;&gt;Guanhong Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Siyuan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiangyu Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04786">
<title>Joint User Association, Interference Cancellation and Power Control for Multi-IRS Assisted UAV Communications. (arXiv:2312.04786v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2312.04786</link>
<description rdf:parseType="Literal">&lt;p&gt;Intelligent reflecting surface (IRS)-assisted unmanned aerial vehicle (UAV)
communications are expected to alleviate the load of ground base stations in a
cost-effective way. Existing studies mainly focus on the deployment and
resource allocation of a single IRS instead of multiple IRSs, whereas it is
extremely challenging for joint multi-IRS multi-user association in UAV
communications with constrained reflecting resources and dynamic scenarios. To
address the aforementioned challenges, we propose a new optimization algorithm
for joint IRS-user association, trajectory optimization of UAVs, successive
interference cancellation (SIC) decoding order scheduling and power allocation
to maximize system energy efficiency. We first propose an inverse soft-Q
learning-based algorithm to optimize multi-IRS multi-user association. Then,
SCA and Dinkelbach-based algorithm are leveraged to optimize UAV trajectory
followed by the optimization of SIC decoding order scheduling and power
allocation. Finally, theoretical analysis and performance results show
significant advantages of the designed algorithm in convergence rate and energy
efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_Z/0/1/0/all/0/1&quot;&gt;Zhaolong Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Hao Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaojie Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qingqing Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuen_C/0/1/0/all/0/1&quot;&gt;Chau Yuen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;F. Richard Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04815">
<title>Not All Negatives AreWorth Attending to: Meta-Bootstrapping Negative Sampling Framework for Link Prediction. (arXiv:2312.04815v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04815</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid development of graph neural networks (GNNs) encourages the rising
of link prediction, achieving promising performance with various applications.
Unfortunately, through a comprehensive analysis, we surprisingly find that
current link predictors with dynamic negative samplers (DNSs) suffer from the
migration phenomenon between &quot;easy&quot; and &quot;hard&quot; samples, which goes against the
preference of DNS of choosing &quot;hard&quot; negatives, thus severely hindering
capability. Towards this end, we propose the MeBNS framework, serving as a
general plugin that can potentially improve current negative sampling based
link predictors. In particular, we elaborately devise a Meta-learning Supported
Teacher-student GNN (MST-GNN) that is not only built upon teacher-student
architecture for alleviating the migration between &quot;easy&quot; and &quot;hard&quot; samples
but also equipped with a meta learning based sample re-weighting module for
helping the student GNN distinguish &quot;hard&quot; samples in a fine-grained manner. To
effectively guide the learning of MST-GNN, we prepare a Structure enhanced
Training Data Generator (STD-Generator) and an Uncertainty based Meta Data
Collector (UMD-Collector) for supporting the teacher and student GNN,
respectively. Extensive experiments show that the MeBNS achieves remarkable
performance across six link prediction benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yakun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1&quot;&gt;Binbin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Shuo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Meiqi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qiyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_G/0/1/0/all/0/1&quot;&gt;Guo Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1&quot;&gt;Huimei He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04823">
<title>Assessing Neural Network Representations During Training Using Noise-Resilient Diffusion Spectral Entropy. (arXiv:2312.04823v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.04823</link>
<description rdf:parseType="Literal">&lt;p&gt;Entropy and mutual information in neural networks provide rich information on
the learning process, but they have proven difficult to compute reliably in
high dimensions. Indeed, in noisy and high-dimensional data, traditional
estimates in ambient dimensions approach a fixed entropy and are prohibitively
hard to compute. To address these issues, we leverage data geometry to access
the underlying manifold and reliably compute these information-theoretic
measures. Specifically, we define diffusion spectral entropy (DSE) in neural
representations of a dataset as well as diffusion spectral mutual information
(DSMI) between different variables representing data. First, we show that they
form noise-resistant measures of intrinsic dimensionality and relationship
strength in high-dimensional simulated data that outperform classic Shannon
entropy, nonparametric estimation, and mutual information neural estimation
(MINE). We then study the evolution of representations in classification
networks with supervised learning, self-supervision, or overfitting. We observe
that (1) DSE of neural representations increases during training; (2) DSMI with
the class label increases during generalizable learning but stays stagnant
during overfitting; (3) DSMI with the input signal shows differing trends: on
MNIST it increases, while on CIFAR-10 and STL-10 it decreases. Finally, we show
that DSE can be used to guide better network initialization and that DSMI can
be used to predict downstream classification accuracy across 962 models on
ImageNet. The official implementation is available at
https://github.com/ChenLiu-1996/DiffusionSpectralEntropy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_D/0/1/0/all/0/1&quot;&gt;Danqi Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christensen_B/0/1/0/all/0/1&quot;&gt;Benjamin W. Christensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_A/0/1/0/all/0/1&quot;&gt;Alexander Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huguet_G/0/1/0/all/0/1&quot;&gt;Guillaume Huguet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1&quot;&gt;Guy Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nickel_M/0/1/0/all/0/1&quot;&gt;Maximilian Nickel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adelstein_I/0/1/0/all/0/1&quot;&gt;Ian Adelstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnaswamy_S/0/1/0/all/0/1&quot;&gt;Smita Krishnaswamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04840">
<title>Analysis on Effects of Fault Elements in Memristive Neuromorphic Systems. (arXiv:2312.04840v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2312.04840</link>
<description rdf:parseType="Literal">&lt;p&gt;Nowadays, neuromorphic systems based on Spiking Neural Networks (SNNs)
attract attentions of many researchers. There are many studies to improve
performances of neuromorphic systems. These studies have been showing
satisfactory results. To magnify performances of neuromorphic systems,
developing actual neuromorphic systems is essential. For developing them,
memristors play key role due to their useful characteristics. Although
memristors are essential for actual neuromorphic systems, they are vulnerable
to faults. However, there are few studies analyzing effects of fault elements
in neuromorphic systems using memristors. To solve this problem, we analyze
performance of a memristive neuromorphic system with fault elements changing
fault ratios, types, and positions. We choose neurons and synapses to inject
faults. We inject two types of faults to synapses: SA0 and SA1 faults. The
fault synapses appear in random and important positions. Through our analysis,
we discover the following four interesting points. First, memristive
characteristics increase vulnerability of neuromorphic systems to fault
elements. Second, fault neuron ratios reducing performance sharply exist.
Third, performance degradation by fault synapses depends on fault types.
Finally, SA1 fault synapses improve performance when they appear in important
positions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hyun-Jong Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1&quot;&gt;Jae-Han Lim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04862">
<title>Damage GAN: A Generative Model for Imbalanced Data. (arXiv:2312.04862v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04862</link>
<description rdf:parseType="Literal">&lt;p&gt;This study delves into the application of Generative Adversarial Networks
(GANs) within the context of imbalanced datasets. Our primary aim is to enhance
the performance and stability of GANs in such datasets. In pursuit of this
objective, we introduce a novel network architecture known as Damage GAN,
building upon the ContraD GAN framework which seamlessly integrates GANs and
contrastive learning. Through the utilization of contrastive learning, the
discriminator is trained to develop an unsupervised representation capable of
distinguishing all provided samples. Our approach draws inspiration from the
straightforward framework for contrastive learning of visual representations
(SimCLR), leading to the formulation of a distinctive loss function. We also
explore the implementation of self-damaging contrastive learning (SDCLR) to
further enhance the optimization of the ContraD GAN model. Comparative
evaluations against baseline models including the deep convolutional GAN
(DCGAN) and ContraD GAN demonstrate the evident superiority of our proposed
model, Damage GAN, in terms of generated image distribution, model stability,
and image quality when applied to imbalanced datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anaissi_A/0/1/0/all/0/1&quot;&gt;Ali Anaissi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1&quot;&gt;Yuanzhe Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braytee_A/0/1/0/all/0/1&quot;&gt;Ali Braytee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naji_M/0/1/0/all/0/1&quot;&gt;Mohamad Naji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alyassine_W/0/1/0/all/0/1&quot;&gt;Widad Alyassine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04865">
<title>StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning. (arXiv:2312.04865v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04865</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph contrastive learning (GCL) has become a powerful tool for learning
graph data, but its scalability remains a significant challenge. In this work,
we propose a simple yet effective training framework called Structural
Compression (StructComp) to address this issue. Inspired by a sparse low-rank
approximation on the diffusion matrix, StructComp trains the encoder with the
compressed nodes. This allows the encoder not to perform any message passing
during the training stage, and significantly reduces the number of sample pairs
in the contrastive loss. We theoretically prove that the original GCL loss can
be approximated with the contrastive loss computed by StructComp. Moreover,
StructComp can be regarded as an additional regularization term for GCL models,
resulting in a more robust encoder. Empirical studies on seven benchmark
datasets show that StructComp greatly reduces the time and memory consumption
while improving model performance compared to the vanilla GCL models and
scalable training methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shengzhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1&quot;&gt;Wenjie Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1&quot;&gt;Xinyuan Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zengfeng Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04879">
<title>HC-Ref: Hierarchical Constrained Refinement for Robust Adversarial Training of GNNs. (arXiv:2312.04879v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04879</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have shown that attackers can catastrophically reduce the
performance of GNNs by maliciously modifying the graph structure or node
features on the graph. Adversarial training, which has been shown to be one of
the most effective defense mechanisms against adversarial attacks in computer
vision, holds great promise for enhancing the robustness of GNNs. There is
limited research on defending against attacks by performing adversarial
training on graphs, and it is crucial to delve deeper into this approach to
optimize its effectiveness. Therefore, based on robust adversarial training on
graphs, we propose a hierarchical constraint refinement framework (HC-Ref) that
enhances the anti-perturbation capabilities of GNNs and downstream classifiers
separately, ultimately leading to improved robustness. We propose corresponding
adversarial regularization terms that are conducive to adaptively narrowing the
domain gap between the normal part and the perturbation part according to the
characteristics of different layers, promoting the smoothness of the predicted
distribution of both parts. Moreover, existing research on graph robust
adversarial training primarily concentrates on training from the standpoint of
node feature perturbations and seldom takes into account alterations in the
graph structure. This limitation makes it challenging to prevent attacks based
on topological changes in the graph. This paper generates adversarial examples
by utilizing graph structure perturbations, offering an effective approach to
defend against attack methods that are based on topological changes. Extensive
experiments on two real-world graph benchmarks show that HC-Ref successfully
resists various attacks and has better node classification performance compared
to several baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_X/0/1/0/all/0/1&quot;&gt;Xiaobing Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haoran Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_G/0/1/0/all/0/1&quot;&gt;Gang Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04883">
<title>Understanding Community Bias Amplification in Graph Representation Learning. (arXiv:2312.04883v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04883</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we discover a phenomenon of community bias amplification in
graph representation learning, which refers to the exacerbation of performance
bias between different classes by graph representation learning. We conduct an
in-depth theoretical study of this phenomenon from a novel spectral
perspective. Our analysis suggests that structural bias between communities
results in varying local convergence speeds for node embeddings. This
phenomenon leads to bias amplification in the classification results of
downstream tasks. Based on the theoretical insights, we propose random graph
coarsening, which is proved to be effective in dealing with the above issue.
Finally, we propose a novel graph contrastive learning model called Random
Graph Coarsening Contrastive Learning (RGCCL), which utilizes random coarsening
as data augmentation and mitigates community bias by contrasting the coarsened
graph with the original graph. Extensive experiments on various datasets
demonstrate the advantage of our method when dealing with community bias
amplification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shengzhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1&quot;&gt;Wenjie Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yimin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_D/0/1/0/all/0/1&quot;&gt;Divin Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zengfeng Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04889">
<title>KwaiAgents: Generalized Information-seeking Agent System with Large Language Models. (arXiv:2312.04889v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.04889</link>
<description rdf:parseType="Literal">&lt;p&gt;Driven by curiosity, humans have continually sought to explore and understand
the world around them, leading to the invention of various tools to satiate
this inquisitiveness. Despite not having the capacity to process and memorize
vast amounts of information in their brains, humans excel in critical thinking,
planning, reflection, and harnessing available tools to interact with and
interpret the world, enabling them to find answers efficiently. The recent
advancements in large language models (LLMs) suggest that machines might also
possess the aforementioned human-like capabilities, allowing them to exhibit
powerful abilities even with a constrained parameter count. In this paper, we
introduce KwaiAgents, a generalized information-seeking agent system based on
LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its
cognitive core, which is capable of understanding a user&apos;s query, behavior
guidelines, and referencing external documents. The agent can also update and
retrieve information from its internal memory, plan and execute actions using a
time-aware search-browse toolkit, and ultimately provide a comprehensive
response. We further investigate the system&apos;s performance when powered by LLMs
less advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework,
designed to ensure even an open-sourced 7B or 13B model performs well among
many agent systems. We exploit both benchmark and human evaluations to
systematically validate these capabilities. Extensive experiments show the
superiority of our agent system compared to other autonomous agents and
highlight the enhanced generalized agent-abilities of our fine-tuned LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1&quot;&gt;Haojie Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhai_Z/0/1/0/all/0/1&quot;&gt;Zepeng Zhai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1&quot;&gt;Hao Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1&quot;&gt;Yaojia Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_R/0/1/0/all/0/1&quot;&gt;Ruiji Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Ming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhongyuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1&quot;&gt;Bing Qin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04905">
<title>Two-Timescale Q-Learning with Function Approximation in Zero-Sum Stochastic Games. (arXiv:2312.04905v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04905</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider two-player zero-sum stochastic games and propose a two-timescale
$Q$-learning algorithm with function approximation that is payoff-based,
convergent, rational, and symmetric between the two players. In two-timescale
$Q$-learning, the fast-timescale iterates are updated in spirit to the
stochastic gradient descent and the slow-timescale iterates (which we use to
compute the policies) are updated by taking a convex combination between its
previous iterate and the latest fast-timescale iterate. Introducing the slow
timescale as well as its update equation marks as our main algorithmic novelty.
In the special case of linear function approximation, we establish, to the best
of our knowledge, the first last-iterate finite-sample bound for payoff-based
independent learning dynamics of these types. The result implies a polynomial
sample complexity to find a Nash equilibrium in such stochastic games.
&lt;/p&gt;
&lt;p&gt;To establish the results, we model our proposed algorithm as a two-timescale
stochastic approximation and derive the finite-sample bound through a
Lyapunov-based approach. The key novelty lies in constructing a valid Lyapunov
function to capture the evolution of the slow-timescale iterates. Specifically,
through a change of variable, we show that the update equation of the
slow-timescale iterates resembles the classical smoothed best-response
dynamics, where the regularized Nash gap serves as a valid Lyapunov function.
This insight enables us to construct a valid Lyapunov function via a
generalized variant of the Moreau envelope of the regularized Nash gap. The
construction of our Lyapunov function might be of broad independent interest in
studying the behavior of stochastic approximation algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zaiwei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kaiqing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazumdar_E/0/1/0/all/0/1&quot;&gt;Eric Mazumdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozdaglar_A/0/1/0/all/0/1&quot;&gt;Asuman Ozdaglar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1&quot;&gt;Adam Wierman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04911">
<title>Collinear datasets augmentation using Procrustes validation sets. (arXiv:2312.04911v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04911</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a new method for the augmentation of numeric and
mixed datasets. The method generates additional data points by utilizing
cross-validation resampling and latent variable modeling. It is particularly
efficient for datasets with moderate to high degrees of collinearity, as it
directly utilizes this property for generation. The method is simple, fast, and
has very few parameters, which, as shown in the paper, do not require specific
tuning. It has been tested on several real datasets; here, we report detailed
results for two cases, prediction of protein in minced meat based on near
infrared spectra (fully numeric data with high degree of collinearity) and
discrimination of patients referred for coronary angiography (mixed data, with
both numeric and categorical variables, and moderate collinearity). In both
cases, artificial neural networks were employed for developing the regression
and the discrimination models. The results show a clear improvement in the
performance of the models; thus for the prediction of meat protein, fitting the
model to the augmented data resulted in a reduction in the root mean squared
error computed for the independent test set by 1.5 to 3 times.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kucheryavskiy_S/0/1/0/all/0/1&quot;&gt;Sergey Kucheryavskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhilin_S/0/1/0/all/0/1&quot;&gt;Sergei Zhilin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04913">
<title>SA-Attack: Improving Adversarial Transferability of Vision-Language Pre-training Models via Self-Augmentation. (arXiv:2312.04913v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.04913</link>
<description rdf:parseType="Literal">&lt;p&gt;Current Visual-Language Pre-training (VLP) models are vulnerable to
adversarial examples. These adversarial examples present substantial security
risks to VLP models, as they can leverage inherent weaknesses in the models,
resulting in incorrect predictions. In contrast to white-box adversarial
attacks, transfer attacks (where the adversary crafts adversarial examples on a
white-box model to fool another black-box model) are more reflective of
real-world scenarios, thus making them more meaningful for research. By
summarizing and analyzing existing research, we identified two factors that can
influence the efficacy of transfer attacks on VLP models: inter-modal
interaction and data diversity. Based on these insights, we propose a
self-augment-based transfer attack method, termed SA-Attack. Specifically,
during the generation of adversarial images and adversarial texts, we apply
different data augmentation methods to the image modality and text modality,
respectively, with the aim of improving the adversarial transferability of the
generated adversarial images and texts. Experiments conducted on the FLickr30K
and COCO datasets have validated the effectiveness of our method. Our code will
be available after this paper is accepted.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1&quot;&gt;Bangyan He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1&quot;&gt;Xiaojun Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1&quot;&gt;Siyuan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lou_T/0/1/0/all/0/1&quot;&gt;Tianrui Lou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1&quot;&gt;Xiaochun Cao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04916">
<title>EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language Models with 3D Parallelism. (arXiv:2312.04916v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04916</link>
<description rdf:parseType="Literal">&lt;p&gt;We present EE-LLM, a framework for large-scale training and inference of
early-exit large language models (LLMs). While recent works have shown
preliminary evidence for the efficacy of early exiting in accelerating LLM
inference, EE-LLM makes a foundational step towards scaling up early-exit LLMs
by supporting their training and inference with massive 3D parallelism. Built
upon Megatron-LM, EE-LLM implements a variety of algorithmic innovations and
performance optimizations tailored to early exiting, including a lightweight
method that facilitates backpropagation for the early-exit training objective
with pipeline parallelism, techniques of leveraging idle resources in the
original pipeline schedule for computation related to early-exit layers, and
two approaches of early-exit inference that are compatible with KV caching for
autoregressive generation. Our analytical and empirical study shows that EE-LLM
achieves great training efficiency with negligible computational overhead
compared to standard LLM training, as well as outstanding inference speedup
without compromising output quality. To facilitate further research and
adoption, we release EE-LLM at https://github.com/pan-x-c/EE-LLM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yanxi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1&quot;&gt;Xuchen Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yaliang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1&quot;&gt;Bolin Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jingren Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04917">
<title>Operationalizing Assurance Cases for Data Scientists: A Showcase of Concepts and Tooling in the Context of Test Data Quality for Machine Learning. (arXiv:2312.04917v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2312.04917</link>
<description rdf:parseType="Literal">&lt;p&gt;Assurance Cases (ACs) are an established approach in safety engineering to
argue quality claims in a structured way. In the context of quality assurance
for Machine Learning (ML)-based software components, ACs are also being
discussed and appear promising. Tools for operationalizing ACs do exist, yet
mainly focus on supporting safety engineers on the system level. However,
assuring the quality of an ML component within the system is commonly the
responsibility of data scientists, who are usually less familiar with these
tools. To address this gap, we propose a framework to support the
operationalization of ACs for ML components based on technologies that data
scientists use on a daily basis: Python and Jupyter Notebook. Our aim is to
make the process of creating ML-related evidence in ACs more effective. Results
from the application of the framework, documented through notebooks, can be
integrated into existing AC tools. We illustrate the application of the
framework on an example excerpt concerned with the quality of the test data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jockel_L/0/1/0/all/0/1&quot;&gt;Lisa J&amp;#xf6;ckel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klas_M/0/1/0/all/0/1&quot;&gt;Michael Kl&amp;#xe4;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gross_J/0/1/0/all/0/1&quot;&gt;Janek Gro&amp;#xdf;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerber_P/0/1/0/all/0/1&quot;&gt;Pascal Gerber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholz_M/0/1/0/all/0/1&quot;&gt;Markus Scholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eberle_J/0/1/0/all/0/1&quot;&gt;Jonathan Eberle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teschner_M/0/1/0/all/0/1&quot;&gt;Marc Teschner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seifert_D/0/1/0/all/0/1&quot;&gt;Daniel Seifert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hawkins_R/0/1/0/all/0/1&quot;&gt;Richard Hawkins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molloy_J/0/1/0/all/0/1&quot;&gt;John Molloy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ottnad_J/0/1/0/all/0/1&quot;&gt;Jens Ottnad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04918">
<title>Pruning Convolutional Filters via Reinforcement Learning with Entropy Minimization. (arXiv:2312.04918v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04918</link>
<description rdf:parseType="Literal">&lt;p&gt;Structural pruning has become an integral part of neural network
optimization, used to achieve architectural configurations which can be
deployed and run more efficiently on embedded devices. Previous results showed
that pruning is possible with minimum performance loss by utilizing a
reinforcement learning agent which makes decisions about the sparsity level of
each neural layer by maximizing as a reward the accuracy of the network. We
introduce a novel information-theoretic reward function which minimizes the
spatial entropy of convolutional activations. This minimization ultimately acts
as a proxy for maintaining accuracy, although these two criteria are not
related in any way. Our method shows that there is another possibility to
preserve accuracy without the need to directly optimize it in the agent&apos;s
reward function. In our experiments, we were able to reduce the total number of
FLOPS of multiple popular neural network architectures by 5-10x, incurring
minimal or no performance drop and being on par with the solution found by
maximizing the accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musat_B/0/1/0/all/0/1&quot;&gt;Bogdan Musat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andonie_R/0/1/0/all/0/1&quot;&gt;Razvan Andonie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04926">
<title>Accelerating Convolutional Neural Network Pruning via Spatial Aura Entropy. (arXiv:2312.04926v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.04926</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, pruning has emerged as a popular technique to reduce the
computational complexity and memory footprint of Convolutional Neural Network
(CNN) models. Mutual Information (MI) has been widely used as a criterion for
identifying unimportant filters to prune. However, existing methods for MI
computation suffer from high computational cost and sensitivity to noise,
leading to suboptimal pruning performance. We propose a novel method to improve
MI computation for CNN pruning, using the spatial aura entropy. The spatial
aura entropy is useful for evaluating the heterogeneity in the distribution of
the neural activations over a neighborhood, providing information about local
features. Our method effectively improves the MI computation for CNN pruning,
leading to more robust and efficient pruning. Experimental results on the
CIFAR-10 benchmark dataset demonstrate the superiority of our approach in terms
of pruning performance and computational efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musat_B/0/1/0/all/0/1&quot;&gt;Bogdan Musat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andonie_R/0/1/0/all/0/1&quot;&gt;Razvan Andonie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04927">
<title>Zoology: Measuring and Improving Recall in Efficient Language Models. (arXiv:2312.04927v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.04927</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention-free language models that combine gating and convolutions are
growing in popularity due to their efficiency and increasingly competitive
performance. To better understand these architectures, we pretrain a suite of
17 attention and &quot;gated-convolution&quot; language models, finding that SoTA
gated-convolution architectures still underperform attention by up to 2.1
perplexity points on the Pile. In fine-grained analysis, we find 82% of the gap
is explained by each model&apos;s ability to recall information that is previously
mentioned in-context, e.g. &quot;Hakuna Matata means no worries Hakuna Matata it
means no&quot; $\rightarrow$ &quot;??&quot;. On this task, termed &quot;associative recall&quot;, we
find that attention outperforms gated-convolutions by a large margin: a 70M
parameter attention model outperforms a 1.4 billion parameter gated-convolution
model on associative recall. This is surprising because prior work shows gated
convolutions can perfectly solve synthetic tests for AR capability. To close
the gap between synthetics and real language, we develop a new formalization of
the task called multi-query associative recall (MQAR) that better reflects
actual language. We perform an empirical and theoretical study of MQAR that
elucidates differences in the parameter-efficiency of attention and
gated-convolution recall. Informed by our analysis, we evaluate simple
convolution-attention hybrids and show that hybrids with input-dependent sparse
attention patterns can close 97.4% of the gap to attention, while maintaining
sub-quadratic scaling. Our code is accessible at:
https://github.com/HazyResearch/zoology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1&quot;&gt;Simran Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eyuboglu_S/0/1/0/all/0/1&quot;&gt;Sabri Eyuboglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Timalsina_A/0/1/0/all/0/1&quot;&gt;Aman Timalsina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_I/0/1/0/all/0/1&quot;&gt;Isys Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poli_M/0/1/0/all/0/1&quot;&gt;Michael Poli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1&quot;&gt;James Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudra_A/0/1/0/all/0/1&quot;&gt;Atri Rudra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1&quot;&gt;Christopher R&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04940">
<title>Canaries and Whistles: Resilient Drone Communication Networks with (or without) Deep Reinforcement Learning. (arXiv:2312.04940v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.04940</link>
<description rdf:parseType="Literal">&lt;p&gt;Communication networks able to withstand hostile environments are critically
important for disaster relief operations. In this paper, we consider a
challenging scenario where drones have been compromised in the supply chain,
during their manufacture, and harbour malicious software capable of
wide-ranging and infectious disruption. We investigate multi-agent deep
reinforcement learning as a tool for learning defensive strategies that
maximise communications bandwidth despite continual adversarial interference.
Using a public challenge for learning network resilience strategies, we propose
a state-of-the-art expert technique and study its superiority over deep
reinforcement learning agents. Correspondingly, we identify three specific
methods for improving the performance of our learning-based agents: (1)
ensuring each observation contains the necessary information, (2) using expert
agents to provide a curriculum for learning, and (3) paying close attention to
reward. We apply our methods and present a new mixed strategy enabling expert
and learning-based agents to work together and improve on all prior results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hicks_C/0/1/0/all/0/1&quot;&gt;Chris Hicks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mavroudis_V/0/1/0/all/0/1&quot;&gt;Vasilios Mavroudis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foley_M/0/1/0/all/0/1&quot;&gt;Myles Foley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davies_T/0/1/0/all/0/1&quot;&gt;Thomas Davies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Highnam_K/0/1/0/all/0/1&quot;&gt;Kate Highnam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watson_T/0/1/0/all/0/1&quot;&gt;Tim Watson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04945">
<title>The ICL Consistency Test. (arXiv:2312.04945v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.04945</link>
<description rdf:parseType="Literal">&lt;p&gt;Just like the previous generation of task-tuned models, large language models
(LLMs) that are adapted to tasks via prompt-based methods like
in-context-learning (ICL) perform well in some setups but not in others. This
lack of consistency in prompt-based learning hints at a lack of robust
generalisation. We here introduce the ICL consistency test -- a contribution to
the GenBench collaborative benchmark task (CBT) -- which evaluates how
consistent a model makes predictions across many different setups while using
the same data. The test is based on different established natural language
inference tasks. We provide preprocessed data constituting 96 different
&apos;setups&apos; and a metric that estimates model consistency across these setups. The
metric is provided on a fine-grained level to understand what properties of a
setup render predictions unstable and on an aggregated level to compare overall
model consistency. We conduct an empirical analysis of eight state-of-the-art
models, and our consistency metric reveals how all tested LLMs lack robust
generalisation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_L/0/1/0/all/0/1&quot;&gt;Lucas Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1&quot;&gt;Elia Bruni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1&quot;&gt;Dieuwke Hupkes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04947">
<title>Benchmarking and Analysis of Unsupervised Object Segmentation from Real-world Single Images. (arXiv:2312.04947v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.04947</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the problem of unsupervised object segmentation from
single images. We do not introduce a new algorithm, but systematically
investigate the effectiveness of existing unsupervised models on challenging
real-world images. We first introduce seven complexity factors to
quantitatively measure the distributions of background and foreground object
biases in appearance and geometry for datasets with human annotations. With the
aid of these factors, we empirically find that, not surprisingly, existing
unsupervised models fail to segment generic objects in real-world images,
although they can easily achieve excellent performance on numerous simple
synthetic datasets, due to the vast gap in objectness biases between synthetic
and real images. By conducting extensive experiments on multiple groups of
ablated real-world datasets, we ultimately find that the key factors underlying
the failure of existing unsupervised models on real-world images are the
challenging distributions of background and foreground object biases in
appearance and geometry. Because of this, the inductive biases introduced in
existing unsupervised models can hardly capture the diverse object
distributions. Our research results suggest that future work should exploit
more explicit objectness biases in the network design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yafei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bo Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04948">
<title>Scientific Preparation for CSST: Classification of Galaxy and Nebula/Star Cluster Based on Deep Learning. (arXiv:2312.04948v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.04948</link>
<description rdf:parseType="Literal">&lt;p&gt;The Chinese Space Station Telescope (abbreviated as CSST) is a future
advanced space telescope. Real-time identification of galaxy and nebula/star
cluster (abbreviated as NSC) images is of great value during CSST survey. While
recent research on celestial object recognition has progressed, the rapid and
efficient identification of high-resolution local celestial images remains
challenging. In this study, we conducted galaxy and NSC image classification
research using deep learning methods based on data from the Hubble Space
Telescope. We built a Local Celestial Image Dataset and designed a deep
learning model named HR-CelestialNet for classifying images of the galaxy and
NSC. HR-CelestialNet achieved an accuracy of 89.09% on the testing set,
outperforming models such as AlexNet, VGGNet and ResNet, while demonstrating
faster recognition speeds. Furthermore, we investigated the factors influencing
CSST image quality and evaluated the generalization ability of HR-CelestialNet
on the blurry image dataset, demonstrating its robustness to low image quality.
The proposed method can enable real-time identification of celestial images
during CSST survey mission.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuquan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1&quot;&gt;Zhong Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Feng Wang&lt;/a&gt;, Lam, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+I_M/0/1/0/all/0/1&quot;&gt;Man I&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1&quot;&gt;Hui Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mei_Y/0/1/0/all/0/1&quot;&gt;Ying Mei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1&quot;&gt;Lei Tan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04950">
<title>Sequential inductive prediction intervals. (arXiv:2312.04950v1 [stat.ME])</title>
<link>http://arxiv.org/abs/2312.04950</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we explore the concept of sequential inductive prediction
intervals using theory from sequential testing. We furthermore introduce a
3-parameter PAC definition of prediction intervals that allows us via
simulation to achieve almost sharp bounds with high probability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Avelin_B/0/1/0/all/0/1&quot;&gt;Benny Avelin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04985">
<title>SparQ Attention: Bandwidth-Efficient LLM Inference. (arXiv:2312.04985v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04985</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative large language models (LLMs) have opened up numerous novel
possibilities, but due to their significant computational requirements their
ubiquitous use remains challenging. Some of the most useful applications
require processing large numbers of samples at a time and using long contexts,
both significantly increasing the memory communication load of the models. We
introduce SparQ Attention, a technique for increasing the inference throughput
of LLMs by reducing the memory bandwidth requirements within the attention
blocks through selective fetching of the cached history. Our proposed technique
can be applied directly to off-the-shelf LLMs during inference, without
requiring any modification to the pre-training setup or additional fine-tuning.
We show how SparQ Attention can decrease the attention memory bandwidth
requirements up to eight times without any loss in accuracy by evaluating Llama
2 and Pythia models on a wide range of downstream tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribar_L/0/1/0/all/0/1&quot;&gt;Luka Ribar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1&quot;&gt;Ivan Chelombiev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hudlass_Galley_L/0/1/0/all/0/1&quot;&gt;Luke Hudlass-Galley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blake_C/0/1/0/all/0/1&quot;&gt;Charlie Blake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1&quot;&gt;Carlo Luschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1&quot;&gt;Douglas Orr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04992">
<title>PFLlib: Personalized Federated Learning Algorithm Library. (arXiv:2312.04992v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.04992</link>
<description rdf:parseType="Literal">&lt;p&gt;Amid the ongoing advancements in Federated Learning (FL), a machine learning
paradigm that allows collaborative learning with data privacy protection,
personalized FL (pFL) has gained significant prominence as a research direction
within the FL domain. Whereas traditional FL (tFL) focuses on jointly learning
a global model, pFL aims to achieve a balance between the global and
personalized objectives of each client in FL settings. To foster the pFL
research community, we propose PFLlib, a comprehensive pFL algorithm library
with an integrated evaluation platform. In PFLlib, We implement 34
state-of-the-art FL algorithms (including 7 classic tFL algorithms and 27 pFL
algorithms) and provide various evaluation environments with three
statistically heterogeneous scenarios and 14 datasets. At present, PFLlib has
already gained 850 stars and 199 forks on GitHub.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianqing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1&quot;&gt;Yang Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_T/0/1/0/all/0/1&quot;&gt;Tao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1&quot;&gt;Zhengui Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1&quot;&gt;Ruhui Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1&quot;&gt;Jian Cao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04997">
<title>Beyond Transduction: A Survey on Inductive, Few Shot, and Zero Shot Link Prediction in Knowledge Graphs. (arXiv:2312.04997v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.04997</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graphs (KGs) comprise entities interconnected by relations of
different semantic meanings. KGs are being used in a wide range of
applications. However, they inherently suffer from incompleteness, i.e.
entities or facts about entities are missing. Consequently, a larger body of
works focuses on the completion of missing information in KGs, which is
commonly referred to as link prediction (LP). This task has traditionally and
extensively been studied in the transductive setting, where all entities and
relations in the testing set are observed during training. Recently, several
works have tackled the LP task under more challenging settings, where entities
and relations in the test set may be unobserved during training, or appear in
only a few facts. These works are known as inductive, few-shot, and zero-shot
link prediction. In this work, we conduct a systematic review of existing works
in this area. A thorough analysis leads us to point out the undesirable
existence of diverging terminologies and task definitions for the
aforementioned settings, which further limits the possibility of comparison
between recent works. We consequently aim at dissecting each setting
thoroughly, attempting to reveal its intrinsic characteristics. A unifying
nomenclature is ultimately proposed to refer to each of them in a simple and
consistent manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubert_N/0/1/0/all/0/1&quot;&gt;Nicolas Hubert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monnin_P/0/1/0/all/0/1&quot;&gt;Pierre Monnin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1&quot;&gt;Heiko Paulheim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05017">
<title>Unbiased Filtering Of Accidental Clicks in Verizon Media Native Advertising. (arXiv:2312.05017v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2312.05017</link>
<description rdf:parseType="Literal">&lt;p&gt;Verizon Media (VZM) native advertising is one of VZM largest and fastest
growing businesses, reaching a run-rate of several hundred million USDs in the
past year. Driving the VZM native models that are used to predict event
probabilities, such as click and conversion probabilities, is OFFSET - a
feature enhanced collaborative-filtering based event-prediction algorithm. In
this work we focus on the challenge of predicting click-through rates (CTR)
when we are aware that some of the clicks have short dwell-time and are defined
as accidental clicks. An accidental click implies little affinity between the
user and the ad, so predicting that similar users will click on the ad is
inaccurate. Therefore, it may be beneficial to remove clicks with dwell-time
lower than a predefined threshold from the training set. However, we cannot
ignore these positive events, as filtering these will cause the model to under
predict. Previous approaches have tried to apply filtering and then adding
corrective biases to the CTR predictions, but did not yield revenue lifts and
therefore were not adopted. In this work, we present a new approach where the
positive weight of the accidental clicks is distributed among all of the
negative events (skips), based on their likelihood of causing accidental
clicks, as predicted by an auxiliary model. These likelihoods are taken as the
correct labels of the negative events, shifting our training from using only
binary labels and adopting a binary cross-entropy loss function in our training
process. After showing offline performance improvements, the modified model was
tested online serving VZM native users, and provided 1.18% revenue lift over
the production model which is agnostic to accidental clicks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaplan_Y/0/1/0/all/0/1&quot;&gt;Yohay Kaplan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krasne_N/0/1/0/all/0/1&quot;&gt;Naama Krasne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shtoff_A/0/1/0/all/0/1&quot;&gt;Alex Shtoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Somekh_O/0/1/0/all/0/1&quot;&gt;Oren Somekh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05021">
<title>A Negative Result on Gradient Matching for Selective Backprop. (arXiv:2312.05021v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05021</link>
<description rdf:parseType="Literal">&lt;p&gt;With increasing scale in model and dataset size, the training of deep neural
networks becomes a massive computational burden. One approach to speed up the
training process is Selective Backprop. For this approach, we perform a forward
pass to obtain a loss value for each data point in a minibatch. The backward
pass is then restricted to a subset of that minibatch, prioritizing high-loss
examples. We build on this approach, but seek to improve the subset selection
mechanism by choosing the (weighted) subset which best matches the mean
gradient over the entire minibatch. We use the gradients w.r.t. the model&apos;s
last layer as a cheap proxy, resulting in virtually no overhead in addition to
the forward pass. At the same time, for our experiments we add a simple random
selection baseline which has been absent from prior work. Surprisingly, we find
that both the loss-based as well as the gradient-matching strategy fail to
consistently outperform the random baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balles_L/0/1/0/all/0/1&quot;&gt;Lukas Balles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1&quot;&gt;Cedric Archambeau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zappella_G/0/1/0/all/0/1&quot;&gt;Giovanni Zappella&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05023">
<title>Reinforcement Learning-Based Bionic Reflex Control for Anthropomorphic Robotic Grasping exploiting Domain Randomization. (arXiv:2312.05023v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.05023</link>
<description rdf:parseType="Literal">&lt;p&gt;Achieving human-level dexterity in robotic grasping remains a challenging
endeavor. Robotic hands frequently encounter slippage and deformation during
object manipulation, issues rarely encountered by humans due to their sensory
receptors, experiential learning, and motor memory. The emulation of the human
grasping reflex within robotic hands is referred to as the ``bionic reflex&quot;.
Past endeavors in the realm of bionic reflex control predominantly relied on
model-based and supervised learning approaches, necessitating human
intervention during thresholding and labeling tasks. In this study, we
introduce an innovative bionic reflex control pipeline, leveraging
reinforcement learning (RL); thereby eliminating the need for human
intervention during control design. Our proposed bionic reflex controller has
been designed and tested on an anthropomorphic hand, manipulating deformable
objects in the PyBullet physics simulator, incorporating domain randomization
(DR) for enhanced Sim2Real transferability. Our findings underscore the promise
of RL as a potent tool for advancing bionic reflex control within
anthropomorphic robotic hands. We anticipate that this autonomous, RL-based
bionic reflex controller will catalyze the development of dependable and highly
efficient robotic and prosthetic hands, revolutionizing human-robot interaction
and assistive technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basumatary_H/0/1/0/all/0/1&quot;&gt;Hirakjyoti Basumatary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adhar_D/0/1/0/all/0/1&quot;&gt;Daksh Adhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrawge_A/0/1/0/all/0/1&quot;&gt;Atharva Shrawge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanbaskar_P/0/1/0/all/0/1&quot;&gt;Prathamesh Kanbaskar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazarika_S/0/1/0/all/0/1&quot;&gt;Shyamanta M. Hazarika&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05031">
<title>Synthesizing Traffic Datasets using Graph Neural Networks. (arXiv:2312.05031v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.05031</link>
<description rdf:parseType="Literal">&lt;p&gt;Traffic congestion in urban areas presents significant challenges, and
Intelligent Transportation Systems (ITS) have sought to address these via
automated and adaptive controls. However, these systems often struggle to
transfer simulated experiences to real-world scenarios. This paper introduces a
novel methodology for bridging this `sim-real&apos; gap by creating photorealistic
images from 2D traffic simulations and recorded junction footage. We propose a
novel image generation approach, integrating a Conditional Generative
Adversarial Network with a Graph Neural Network (GNN) to facilitate the
creation of realistic urban traffic images. We harness GNNs&apos; ability to process
information at different levels of abstraction alongside segmented images for
preserving locality data. The presented architecture leverages the power of
SPADE and Graph ATtention (GAT) network models to create images based on
simulated traffic scenarios. These images are conditioned by factors such as
entity positions, colors, and time of day. The uniqueness of our approach lies
in its ability to effectively translate structured and human-readable
conditions, encoded as graphs, into realistic images. This advancement
contributes to applications requiring rich traffic image datasets, from data
augmentation to urban traffic solutions. We further provide an application to
test the model&apos;s capabilities, including generating images with manually
defined positions for various entities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_Criado_D/0/1/0/all/0/1&quot;&gt;Daniel Rodriguez-Criado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chli_M/0/1/0/all/0/1&quot;&gt;Maria Chli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manso_L/0/1/0/all/0/1&quot;&gt;Luis J. Manso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vogiatzis_G/0/1/0/all/0/1&quot;&gt;George Vogiatzis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05034">
<title>Grasp Force Optimization as a Bilinear Matrix Inequality Problem: A Deep Learning Approach. (arXiv:2312.05034v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.05034</link>
<description rdf:parseType="Literal">&lt;p&gt;Grasp force synthesis is a non-convex optimization problem involving
constraints that are bilinear. Traditional approaches to this problem involve
general-purpose gradient-based nonlinear optimization and semi-definite
programming. With a view towards dealing with postural synergies and non-smooth
but convex positive semidefinite constraints, we look beyond gradient-based
optimization. The focus of this paper is to undertake a grasp analysis of
biomimetic grasping in multi-fingered robotic hands as a bilinear matrix
inequality (BMI) problem. Our analysis is to solve it using a deep learning
approach to make the algorithm efficiently generate force closure grasps with
optimal grasp quality on untrained/unseen objects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basumatary_H/0/1/0/all/0/1&quot;&gt;Hirakjyoti Basumatary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adhar_D/0/1/0/all/0/1&quot;&gt;Daksh Adhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaw_R/0/1/0/all/0/1&quot;&gt;Riddhiman Shaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazarika_S/0/1/0/all/0/1&quot;&gt;Shyamanta M. Hazarika&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05039">
<title>SmartMask: Context Aware High-Fidelity Mask Generation for Fine-grained Object Insertion and Layout Control. (arXiv:2312.05039v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.05039</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of generative image inpainting and object insertion has made
significant progress with the recent advent of latent diffusion models.
Utilizing a precise object mask can greatly enhance these applications.
However, due to the challenges users encounter in creating high-fidelity masks,
there is a tendency for these methods to rely on more coarse masks (e.g.,
bounding box) for these applications. This results in limited control and
compromised background content preservation. To overcome these limitations, we
introduce SmartMask, which allows any novice user to create detailed masks for
precise object insertion. Combined with a ControlNet-Inpaint model, our
experiments demonstrate that SmartMask achieves superior object insertion
quality, preserving the background content more effectively than previous
methods. Notably, unlike prior works the proposed approach can also be used
even without user-mask guidance, which allows it to perform mask-free object
insertion at diverse positions and scales. Furthermore, we find that when used
iteratively with a novel instruction-tuning based planning model, SmartMask can
be used to design detailed layouts from scratch. As compared with user-scribble
based layout design, we observe that SmartMask allows for better quality
outputs with layout-to-image generation methods. Project page is available at
https://smartmask-gen.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1&quot;&gt;Jaskirat Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_C/0/1/0/all/0/1&quot;&gt;Cameron Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhe Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Liang Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05044">
<title>Backward Learning for Goal-Conditioned Policies. (arXiv:2312.05044v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05044</link>
<description rdf:parseType="Literal">&lt;p&gt;Can we learn policies in reinforcement learning without rewards? Can we learn
a policy just by trying to reach a goal state? We answer these questions
positively by proposing a multi-step procedure that first learns a world model
that goes backward in time, secondly generates goal-reaching backward
trajectories, thirdly improves those sequences using shortest path finding
algorithms, and finally trains a neural network policy by imitation learning.
We evaluate our method on a deterministic maze environment where the
observations are $64\times 64$ pixel bird&apos;s eye images and can show that it
consistently reaches several goals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoftmann_M/0/1/0/all/0/1&quot;&gt;Marc H&amp;#xf6;ftmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robine_J/0/1/0/all/0/1&quot;&gt;Jan Robine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harmeling_S/0/1/0/all/0/1&quot;&gt;Stefan Harmeling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05052">
<title>Soft Frequency Capping for Improved Ad Click Prediction in Yahoo Gemini Native. (arXiv:2312.05052v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2312.05052</link>
<description rdf:parseType="Literal">&lt;p&gt;Yahoo&apos;s native advertising (also known as Gemini native) serves billions of
ad impressions daily, reaching a yearly run-rate of many hundred of millions
USD. Driving the Gemini native models that are used to predict both click
probability (pCTR) and conversion probability (pCONV) is OFFSET - a feature
enhanced collaborative-filtering (CF) based event prediction algorithm. \offset
is a one-pass algorithm that updates its model for every new batch of logged
data using a stochastic gradient descent (SGD) based approach. Since OFFSET
represents its users by their features (i.e., user-less model) due to sparsity
issues, rule based hard frequency capping (HFC) is used to control the number
of times a certain user views a certain ad. Moreover, related statistics reveal
that user ad fatigue results in a dramatic drop in click through rate (CTR).
Therefore, to improve click prediction accuracy, we propose a soft frequency
capping (SFC) approach, where the frequency feature is incorporated into the
OFFSET model as a user-ad feature and its weight vector is learned via logistic
regression as part of OFFSET training. Online evaluation of the soft frequency
capping algorithm via bucket testing showed a significant 7.3% revenue lift.
Since then, the frequency feature enhanced model has been pushed to production
serving all traffic, and is generating a hefty revenue lift for Yahoo Gemini
native. We also report related statistics that reveal, among other things, that
while users&apos; gender does not affect ad fatigue, the latter seems to increase
with users&apos; age.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aharon_M/0/1/0/all/0/1&quot;&gt;Michal Aharon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaplan_Y/0/1/0/all/0/1&quot;&gt;Yohay Kaplan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1&quot;&gt;Rina Levy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Somekh_O/0/1/0/all/0/1&quot;&gt;Oren Somekh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blanc_A/0/1/0/all/0/1&quot;&gt;Ayelet Blanc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eshel_N/0/1/0/all/0/1&quot;&gt;Neetai Eshel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahar_A/0/1/0/all/0/1&quot;&gt;Avi Shahar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singer_A/0/1/0/all/0/1&quot;&gt;Assaf Singer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zlotnik_A/0/1/0/all/0/1&quot;&gt;Alex Zlotnik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05073">
<title>A Distributed ADMM-based Deep Learning Approach for Thermal Control in Multi-Zone Buildings. (arXiv:2312.05073v1 [math.OC])</title>
<link>http://arxiv.org/abs/2312.05073</link>
<description rdf:parseType="Literal">&lt;p&gt;The surge in electricity use, coupled with the dependency on intermittent
renewable energy sources, poses significant hurdles to effectively managing
power grids, particularly during times of peak demand. Demand Response programs
and energy conservation measures are essential to operate energy grids while
ensuring a responsible use of our resources This research combines distributed
optimization using ADMM with Deep Learning models to plan indoor temperature
setpoints effectively. A two-layer hierarchical structure is used, with a
central building coordinator at the upper layer and local controllers at the
thermal zone layer. The coordinator must limit the building&apos;s maximum power by
translating the building&apos;s total power to local power targets for each zone.
Local controllers can modify the temperature setpoints to meet the local power
targets. The resulting control algorithm, called Distributed Planning Networks,
is designed to be both adaptable and scalable to many types of buildings,
tackling two of the main challenges in the development of such systems. The
proposed approach is tested on an 18-zone building modeled in EnergyPlus. The
algorithm successfully manages Demand Response peak events.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Taboga_V/0/1/0/all/0/1&quot;&gt;Vincent Taboga&lt;/a&gt; (1, 2, 3), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dagdougui_H/0/1/0/all/0/1&quot;&gt;Hanane Dagdougui&lt;/a&gt; (1, 2, 3) ((1) Polytechnique Montreal, Department of Mathematics and Industrial Engineering (2) Quebec Artificial Intelligence Institute (Mila) (3) Groupe d&amp;#x27;etudes et de recherche en analyse des decisions (GERAD))</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05090">
<title>UniTSA: A Universal Reinforcement Learning Framework for V2X Traffic Signal Control. (arXiv:2312.05090v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2312.05090</link>
<description rdf:parseType="Literal">&lt;p&gt;Traffic congestion is a persistent problem in urban areas, which calls for
the development of effective traffic signal control (TSC) systems. While
existing Reinforcement Learning (RL)-based methods have shown promising
performance in optimizing TSC, it is challenging to generalize these methods
across intersections of different structures. In this work, a universal
RL-based TSC framework is proposed for Vehicle-to-Everything (V2X)
environments. The proposed framework introduces a novel agent design that
incorporates a junction matrix to characterize intersection states, making the
proposed model applicable to diverse intersections. To equip the proposed
RL-based framework with enhanced capability of handling various intersection
structures, novel traffic state augmentation methods are tailor-made for signal
light control systems. Finally, extensive experimental results derived from
multiple intersection configurations confirm the effectiveness of the proposed
framework. The source code in this work is available at
https://github.com/wmn7/Universal_Light
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Maonan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xiong_X/0/1/0/all/0/1&quot;&gt;Xi Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kan_Y/0/1/0/all/0/1&quot;&gt;Yuheng Kan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chengcheng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pun_M/0/1/0/all/0/1&quot;&gt;Man-On Pun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05092">
<title>INSPECT: Intrinsic and Systematic Probing Evaluation for Code Transformers. (arXiv:2312.05092v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2312.05092</link>
<description rdf:parseType="Literal">&lt;p&gt;Pre-trained models of source code have recently been successfully applied to
a wide variety of Software Engineering tasks; they have also seen some
practical adoption in practice, e.g. for code completion. Yet, we still know
very little about what these pre-trained models learn about source code. In
this article, we use probing--simple diagnostic tasks that do not further train
the models--to discover to what extent pre-trained models learn about specific
aspects of source code. We use an extensible framework to define 15 probing
tasks that exercise surface, syntactic, structural and semantic characteristics
of source code. We probe 8 pre-trained source code models, as well as a natural
language model (BERT) as our baseline. We find that models that incorporate
some structural information (such as GraphCodeBERT) have a better
representation of source code characteristics. Surprisingly, we find that for
some probing tasks, BERT is competitive with the source code models, indicating
that there are ample opportunities to improve source-code specific pre-training
on the respective code characteristics. We encourage other researchers to
evaluate their models with our probing task suite, so that they may peer into
the hidden layers of the models and identify what intrinsic code
characteristics are encoded.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karmakar_A/0/1/0/all/0/1&quot;&gt;Anjan Karmakar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robbes_R/0/1/0/all/0/1&quot;&gt;Romain Robbes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05100">
<title>Continual learning for surface defect segmentation by subnetwork creation and selection. (arXiv:2312.05100v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.05100</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new continual (or lifelong) learning algorithm called LDA-CP&amp;amp;S
that performs segmentation tasks without undergoing catastrophic forgetting.
The method is applied to two different surface defect segmentation problems
that are learned incrementally, i.e. providing data about one type of defect at
a time, while still being capable of predicting every defect that was seen
previously. Our method creates a defect-related subnetwork for each defect type
via iterative pruning and trains a classifier based on linear discriminant
analysis (LDA). At the inference stage, we first predict the defect type with
LDA and then predict the surface defects using the selected subnetwork. We
compare our method with other continual learning methods showing a significant
improvement -- mean Intersection over Union better by a factor of two when
compared to existing methods on both datasets. Importantly, our approach shows
comparable results with joint training when all the training data (all defects)
are seen simultaneously
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dekhovich_A/0/1/0/all/0/1&quot;&gt;Aleksandr Dekhovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bessa_M/0/1/0/all/0/1&quot;&gt;Miguel A. Bessa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05103">
<title>TMID: A Comprehensive Real-world Dataset for Trademark Infringement Detection in E-Commerce. (arXiv:2312.05103v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.05103</link>
<description rdf:parseType="Literal">&lt;p&gt;Annually, e-commerce platforms incur substantial financial losses due to
trademark infringements, making it crucial to identify and mitigate potential
legal risks tied to merchant information registered to the platforms. However,
the absence of high-quality datasets hampers research in this area. To address
this gap, our study introduces TMID, a novel dataset to detect trademark
infringement in merchant registrations. This is a real-world dataset sourced
directly from Alipay, one of the world&apos;s largest e-commerce and digital payment
platforms. As infringement detection is a legal reasoning task requiring an
understanding of the contexts and legal rules, we offer a thorough collection
of legal rules and merchant and trademark-related contextual information with
annotations from legal experts. We ensure the data quality by performing an
extensive statistical analysis. Furthermore, we conduct an empirical study on
this dataset to highlight its value and the key challenges. Through this study,
we aim to contribute valuable resources to advance research into legal
compliance related to trademark infringement within the e-commerce sphere. The
dataset is available at https://github.com/emnlpTMID/emnlpTMID.github.io .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1&quot;&gt;Tongxin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhuang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1&quot;&gt;Xin Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1&quot;&gt;Lizhen Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xin Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05114">
<title>On the Inadequacy of Similarity-based Privacy Metrics: Reconstruction Attacks against &quot;Truly Anonymous Synthetic Data&apos;&apos;. (arXiv:2312.05114v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.05114</link>
<description rdf:parseType="Literal">&lt;p&gt;Training generative models to produce synthetic data is meant to provide a
privacy-friendly approach to data release. However, we get robust guarantees
only when models are trained to satisfy Differential Privacy (DP). Alas, this
is not the standard in industry as many companies use ad-hoc strategies to
empirically evaluate privacy based on the statistical similarity between
synthetic and real data. In this paper, we review the privacy metrics offered
by leading companies in this space and shed light on a few critical flaws in
reasoning about privacy entirely via empirical evaluations. We analyze the
undesirable properties of the most popular metrics and filters and demonstrate
their unreliability and inconsistency through counter-examples. We then present
a reconstruction attack, ReconSyn, which successfully recovers (i.e., leaks all
attributes of) at least 78% of the low-density train records (or outliers) with
only black-box access to a single fitted generative model and the privacy
metrics. Finally, we show that applying DP only to the model or using
low-utility generators does not mitigate ReconSyn as the privacy leakage
predominantly comes from the metrics. Overall, our work serves as a warning to
practitioners not to deviate from established privacy-preserving mechanisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganev_G/0/1/0/all/0/1&quot;&gt;Georgi Ganev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cristofaro_E/0/1/0/all/0/1&quot;&gt;Emiliano De Cristofaro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05134">
<title>Optimal Multi-Distribution Learning. (arXiv:2312.05134v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05134</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-distribution learning (MDL), which seeks to learn a shared model that
minimizes the worst-case risk across $k$ distinct data distributions, has
emerged as a unified framework in response to the evolving demand for
robustness, fairness, multi-group collaboration, etc. Achieving data-efficient
MDL necessitates adaptive sampling, also called on-demand sampling, throughout
the learning process. However, there exist substantial gaps between the
state-of-the-art upper and lower bounds on the optimal sample complexity.
Focusing on a hypothesis class of Vapnik-Chervonenkis (VC) dimension $d$, we
propose a novel algorithm that yields an $varepsilon$-optimal randomized
hypothesis with a sample complexity on the order of $(d+k)/\varepsilon^2$
(modulo some logarithmic factor), matching the best-known lower bound. Our
algorithmic ideas and theory have been further extended to accommodate
Rademacher classes. The proposed algorithms are oracle-efficient, which access
the hypothesis class solely through an empirical risk minimization oracle.
Additionally, we establish the necessity of randomization, unveiling a large
sample size barrier when only deterministic hypotheses are permitted. These
findings successfully resolve three open problems presented in COLT 2023 (i.e.,
Awasthi et al., (2023, Problem 1, 3 and 4)).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zihan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1&quot;&gt;Wenhao Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon S. Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason D. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05140">
<title>Membership Inference Attacks on Diffusion Models via Quantile Regression. (arXiv:2312.05140v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05140</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, diffusion models have become popular tools for image synthesis
because of their high-quality outputs. However, like other large-scale models,
they may leak private information about their training data. Here, we
demonstrate a privacy vulnerability of diffusion models through a
\emph{membership inference (MI) attack}, which aims to identify whether a
target example belongs to the training set when given the trained diffusion
model. Our proposed MI attack learns quantile regression models that predict (a
quantile of) the distribution of reconstruction loss on examples not used in
training. This allows us to define a granular hypothesis test for determining
the membership of a point in the training set, based on thresholding the
reconstruction loss of that point using a custom threshold tailored to the
example. We also provide a simple bootstrap technique that takes a majority
membership prediction over ``a bag of weak attackers&apos;&apos; which improves the
accuracy over individual quantile regression models. We show that our attack
outperforms the prior state-of-the-art attack while being substantially less
computationally expensive -- prior attacks required training multiple ``shadow
models&apos;&apos; with the same architecture as the model under attack, whereas our
attack requires training only much smaller models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shuai Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Steven Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aydore_S/0/1/0/all/0/1&quot;&gt;Sergul Aydore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kearns_M/0/1/0/all/0/1&quot;&gt;Michael Kearns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1&quot;&gt;Aaron Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05144">
<title>Kraken: enabling joint trajectory prediction by utilizing Mode Transformer and Greedy Mode Processing. (arXiv:2312.05144v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.05144</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate and reliable motion prediction is essential for safe urban autonomy.
The most prominent motion prediction approaches are based on modeling the
distribution of possible future trajectories of each actor in autonomous
system&apos;s vicinity. These &quot;independent&quot; marginal predictions might be accurate
enough to properly describe casual driving situations where the prediction
target is not likely to interact with other actors. They are, however,
inadequate for modeling interactive situations where the actors&apos; future
trajectories are likely to intersect. To mitigate this issue we propose Kraken
-- a real-time trajectory prediction model capable of approximating pairwise
interactions between the actors as well as producing accurate marginal
predictions. Kraken relies on a simple Greedy Mode Processing technique
allowing it to convert a factorized prediction for a pair of agents into a
physically-plausible joint prediction. It also utilizes the Mode Transformer
module to increase the diversity of predicted trajectories and make the joint
prediction more informative. We evaluate Kraken on Waymo Motion Prediction
challenge where it held the first place in the Interaction leaderboard and the
second place in the Motion leaderboard in October 2021.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonenko_D/0/1/0/all/0/1&quot;&gt;Daniil S. Antonenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konev_S/0/1/0/all/0/1&quot;&gt;Stepan Konev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biktairov_Y/0/1/0/all/0/1&quot;&gt;Yuriy Biktairov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yangel_B/0/1/0/all/0/1&quot;&gt;Boris Yangel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05153">
<title>Uncertainty Quantification and Propagation in Surrogate-based Bayesian Inference. (arXiv:2312.05153v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.05153</link>
<description rdf:parseType="Literal">&lt;p&gt;Surrogate models are statistical or conceptual approximations for more
complex simulation models. In this context, it is crucial to propagate the
uncertainty induced by limited simulation budget and surrogate approximation
error to predictions, inference, and subsequent decision-relevant quantities.
However, quantifying and then propagating the uncertainty of surrogates is
usually limited to special analytic cases or is otherwise computationally very
expensive. In this paper, we propose a framework enabling a scalable, Bayesian
approach to surrogate modeling with thorough uncertainty quantification,
propagation, and validation. Specifically, we present three methods for
Bayesian inference with surrogate models given measurement data. This is a task
where the propagation of surrogate uncertainty is especially relevant, because
failing to account for it may lead to biased and/or overconfident estimates of
the parameters of interest. We showcase our approach in two detailed case
studies for both linear and nonlinear modeling scenarios. Uncertainty
propagation in surrogate models enables more reliable and safe approximation of
expensive simulators and will therefore be useful in various fields of
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Reiser_P/0/1/0/all/0/1&quot;&gt;Philipp Reiser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aguilar_J/0/1/0/all/0/1&quot;&gt;Javier Enrique Aguilar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guthke_A/0/1/0/all/0/1&quot;&gt;Anneli Guthke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Burkner_P/0/1/0/all/0/1&quot;&gt;Paul-Christian B&amp;#xfc;rkner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05158">
<title>Deep Learning-Based Pilotless Spatial Multiplexing. (arXiv:2312.05158v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.05158</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates the feasibility of machine learning (ML)-based
pilotless spatial multiplexing in multiple-input and multiple-output (MIMO)
communication systems. Especially, it is shown that by training the transmitter
and receiver jointly, the transmitter can learn such constellation shapes for
the spatial streams which facilitate completely blind separation and detection
by the simultaneously learned receiver. To the best of our knowledge, this is
the first time ML-based spatial multiplexing without channel estimation pilots
is demonstrated. The results show that the learned pilotless scheme can
outperform a conventional pilot-based system by as much as 15-20% in terms of
spectral efficiency, depending on the modulation order and signal-to-noise
ratio.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Korpi_D/0/1/0/all/0/1&quot;&gt;Dani Korpi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Honkala_M/0/1/0/all/0/1&quot;&gt;Mikko Honkala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huttunen_J/0/1/0/all/0/1&quot;&gt;Janne M.J. Huttunen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05160">
<title>Detecting Atomic Scale Surface Defects in STM of TMDs with Ensemble Deep Learning. (arXiv:2312.05160v1 [cond-mat.mtrl-sci])</title>
<link>http://arxiv.org/abs/2312.05160</link>
<description rdf:parseType="Literal">&lt;p&gt;Atomic-scale defect detection is shown in scanning tunneling microscopy
images of single crystal WSe2 using an ensemble of U-Net-like convolutional
neural networks. Standard deep learning test metrics indicated good detection
performance with an average F1 score of 0.66 and demonstrated ensemble
generalization to C-AFM images of WSe2 and STM images of MoSe2. Defect
coordinates were automatically extracted from defect detections maps showing
that STM image analysis enhanced by machine learning can be used to
dramatically increase sample characterization throughput.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Smalley_D/0/1/0/all/0/1&quot;&gt;Darian Smalley&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Lough_S/0/1/0/all/0/1&quot;&gt;Stephanie D. Lough&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Holtzman_L/0/1/0/all/0/1&quot;&gt;Luke Holtzman&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kaikui Xu&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Holbrook_M/0/1/0/all/0/1&quot;&gt;Madisen Holbrook&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Rosenberger_M/0/1/0/all/0/1&quot;&gt;Matthew R. Rosenberger&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Hone_J/0/1/0/all/0/1&quot;&gt;J.C. Hone&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Barmak_K/0/1/0/all/0/1&quot;&gt;Katayun Barmak&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Ishigami_M/0/1/0/all/0/1&quot;&gt;Masahiro Ishigami&lt;/a&gt; (1 and 2) ((1) Department of Physics, University of Central Florida, (2) NanoScience Technology Center, University of Central Florida, (3) Department of Applied Physics and Applied Mathematics, University of Columbia, (4) Department of Aerospace and Mechanical Engineering, University of Notre Dame)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05162">
<title>A Review of Cooperation in Multi-agent Learning. (arXiv:2312.05162v1 [cs.MA])</title>
<link>http://arxiv.org/abs/2312.05162</link>
<description rdf:parseType="Literal">&lt;p&gt;Cooperation in multi-agent learning (MAL) is a topic at the intersection of
numerous disciplines, including game theory, economics, social sciences, and
evolutionary biology. Research in this area aims to understand both how agents
can coordinate effectively when goals are aligned and how they may cooperate in
settings where gains from working together are possible but possibilities for
conflict abound. In this paper we provide an overview of the fundamental
concepts, problem settings and algorithms of multi-agent learning. This
encompasses reinforcement learning, multi-agent sequential decision-making,
challenges associated with multi-agent cooperation, and a comprehensive review
of recent progress, along with an evaluation of relevant metrics. Finally we
discuss open challenges in the field with the aim of inspiring new avenues for
research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yali Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibo_J/0/1/0/all/0/1&quot;&gt;Joel Z. Leibo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam_U/0/1/0/all/0/1&quot;&gt;Usman Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Willis_R/0/1/0/all/0/1&quot;&gt;Richard Willis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sunehag_P/0/1/0/all/0/1&quot;&gt;Peter Sunehag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05176">
<title>MRI Scan Synthesis Methods based on Clustering and Pix2Pix. (arXiv:2312.05176v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.05176</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a missing data problem in the context of automatic segmentation
methods for Magnetic Resonance Imaging (MRI) brain scans. Usually, automated
MRI scan segmentation is based on multiple scans (e.g., T1-weighted,
T2-weighted, T1CE, FLAIR). However, quite often a scan is blurry, missing or
otherwise unusable. We investigate the question whether a missing scan can be
synthesized. We exemplify that this is in principle possible by synthesizing a
T2-weighted scan from a given T1-weighted scan. Our first aim is to compute a
picture that resembles the missing scan closely, measured by average mean
squared error (MSE). We develop/use several methods for this, including a
random baseline approach, a clustering-based method and pixel-to-pixel
translation method by (Pix2Pix) which is based on conditional GANs. The lowest
MSE is achieved by our clustering-based method. Our second aim is to compare
the methods with respect to the affect that using the synthesized scan has on
the segmentation process. For this, we use a DeepMedic model trained with the
four input scan modalities named above. We replace the T2-weighted scan by the
synthesized picture and evaluate the segmentations with respect to the tumor
identification, using Dice scores as numerical evaluation. The evaluation shows
that the segmentation works well with synthesized scans (in particular, with
Pix2Pix methods) in many cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Baldini_G/0/1/0/all/0/1&quot;&gt;Giulia Baldini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Schmidt_M/0/1/0/all/0/1&quot;&gt;Melanie Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zaske_C/0/1/0/all/0/1&quot;&gt;Charlotte Z&amp;#xe4;ske&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Caldeira_L/0/1/0/all/0/1&quot;&gt;Liliana L. Caldeira&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05181">
<title>TENPLEX: Changing Resources of Deep Learning Jobs using Parallelizable Tensor Collections. (arXiv:2312.05181v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2312.05181</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning (DL) jobs use multi-dimensional parallelism, i.e they combine
data, model, and pipeline parallelism, to use large GPU clusters efficiently.
This couples jobs tightly to a set of GPU devices, but jobs may experience
changes to the device allocation: (i) resource elasticity during training adds
or removes devices; (ii) hardware maintenance may require redeployment on
different devices; and (iii) device failures force jobs to run with fewer
devices. Current DL frameworks lack support for these scenarios, as they cannot
change the multi-dimensional parallelism of an already-running job in an
efficient and model-independent way.
&lt;/p&gt;
&lt;p&gt;We describe Tenplex, a state management library for DL frameworks that
enables jobs to change the GPU allocation and job parallelism at runtime.
Tenplex achieves this by externalizing the DL job state during training as a
parallelizable tensor collection (PTC). When the GPU allocation for the DL job
changes, Tenplex uses the PTC to transform the DL job state: for the dataset
state, Tenplex repartitions it under data parallelism and exposes it to workers
through a virtual file system; for the model state, Tenplex obtains it as
partitioned checkpoints and transforms them to reflect the new parallelization
configuration. For efficiency, these PTC transformations are executed in
parallel with a minimum amount of data movement between devices and workers.
Our experiments show that Tenplex enables DL jobs to support dynamic
parallelization with low overhead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wagenlander_M/0/1/0/all/0/1&quot;&gt;Marcel Wagenl&amp;#xe4;nder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1&quot;&gt;Bo Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mai_L/0/1/0/all/0/1&quot;&gt;Luo Mai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pietzuch_P/0/1/0/all/0/1&quot;&gt;Peter Pietzuch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05185">
<title>AI Competitions and Benchmarks: Competition platforms. (arXiv:2312.05185v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05185</link>
<description rdf:parseType="Literal">&lt;p&gt;The ecosystem of artificial intelligence competitions is a diverse and
multifaceted landscape, encompassing a variety of platforms that each host
numerous competitions annually, alongside a plethora of specialized websites
dedicated to singular contests. These platforms adeptly manage the overarching
administrative responsibilities inherent in orchestrating competitions, thus
affording organizers the liberty to allocate greater attention to other facets
of their contests. Notably, these platforms exhibit considerable diversity in
their operational functionalities, economic models, and community dynamics.
This chapter conducts an extensive review of the foremost services in this
realm and elucidates several alternative methodologies that facilitate the
independent hosting of such challenges. Keywords: competition platform,
challenge hosting services, comparison.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ustyuzhanin_A/0/1/0/all/0/1&quot;&gt;Andrey Ustyuzhanin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlens_H/0/1/0/all/0/1&quot;&gt;Harald Carlens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05195">
<title>Conformal Prediction in Multi-User Settings: An Evaluation. (arXiv:2312.05195v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05195</link>
<description rdf:parseType="Literal">&lt;p&gt;Typically, machine learning models are trained and evaluated without making
any distinction between users (e.g, using traditional hold-out and
cross-validation). However, this produces inaccurate performance metrics
estimates in multi-user settings. That is, situations where the data were
collected by multiple users with different characteristics (e.g., age, gender,
height, etc.) which is very common in user computer interaction and medical
applications. For these types of scenarios model evaluation strategies that
provide better performance estimates have been proposed such as mixed,
user-independent, user-dependent, and user-adaptive models. Although those
strategies are better suited for multi-user systems, they are typically
assessed with respect to performance metrics that capture the overall behavior
of the models and do not provide any performance guarantees for individual
predictions nor they provide any feedback about the predictions&apos; uncertainty.
In order to overcome those limitations, in this work we evaluated the conformal
prediction framework in several multi-user settings. Conformal prediction is a
model agnostic method that provides confidence guarantees on the predictions,
thus, increasing the trustworthiness and robustness of the models. We conducted
extensive experiments using different evaluation strategies and found
significant differences in terms of conformal performance measures. We also
proposed several visualizations based on matrices, graphs, and charts that
capture different aspects of the resulting prediction sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Ceja_E/0/1/0/all/0/1&quot;&gt;Enrique Garcia-Ceja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Banuelos_L/0/1/0/all/0/1&quot;&gt;Luciano Garcia-Banuelos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jourdan_N/0/1/0/all/0/1&quot;&gt;Nicolas Jourdan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05215">
<title>DeltaZip: Multi-Tenant Language Model Serving via Delta Compression. (arXiv:2312.05215v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2312.05215</link>
<description rdf:parseType="Literal">&lt;p&gt;Fine-tuning large language models (LLMs) for downstream tasks can greatly
improve model quality, however serving many different fine-tuned LLMs
concurrently for users in multi-tenant environments is challenging. Dedicating
GPU memory for each model is prohibitively expensive and naively swapping large
model weights in and out of GPU memory is slow. Our key insight is that
fine-tuned models can be quickly swapped in and out of GPU memory by extracting
and compressing the delta between each model and its pre-trained base model. We
propose DeltaZip, an LLM serving system that efficiently serves multiple
full-parameter fine-tuned models concurrently by aggressively compressing model
deltas by a factor of $6\times$ to $8\times$ while maintaining high model
quality. DeltaZip increases serving throughput by $1.5\times$ to $3\times$ and
improves SLO attainment compared to a vanilla HuggingFace serving system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1&quot;&gt;Xiaozhe Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klimovic_A/0/1/0/all/0/1&quot;&gt;Ana Klimovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05225">
<title>Neural Spectral Methods: Self-supervised learning in the spectral domain. (arXiv:2312.05225v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05225</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Neural Spectral Methods, a technique to solve parametric Partial
Differential Equations (PDEs), grounded in classical spectral methods. Our
method uses orthogonal bases to learn PDE solutions as mappings between
spectral coefficients. In contrast to current machine learning approaches which
enforce PDE constraints by minimizing the numerical quadrature of the residuals
in the spatiotemporal domain, we leverage Parseval&apos;s identity and introduce a
new training strategy through a \textit{spectral loss}. Our spectral loss
enables more efficient differentiation through the neural network, and
substantially reduces training complexity. At inference time, the computational
cost of our method remains constant, regardless of the spatiotemporal
resolution of the domain. Our experimental results demonstrate that our method
significantly outperforms previous machine learning approaches in terms of
speed and accuracy by one to two orders of magnitude on multiple different
problems. When compared to numerical solvers of the same accuracy, our method
demonstrates a $10\times$ increase in performance speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yiheng Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalapathi_N/0/1/0/all/0/1&quot;&gt;Nithin Chalapathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnapriyan_A/0/1/0/all/0/1&quot;&gt;Aditi Krishnapriyan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05229">
<title>Few-Shot Class-Incremental Learning via Training-Free Prototype Calibration. (arXiv:2312.05229v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.05229</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-world scenarios are usually accompanied by continuously appearing
classes with scare labeled samples, which require the machine learning model to
incrementally learn new classes and maintain the knowledge of base classes. In
this Few-Shot Class-Incremental Learning (FSCIL) scenario, existing methods
either introduce extra learnable components or rely on a frozen feature
extractor to mitigate catastrophic forgetting and overfitting problems.
However, we find a tendency for existing methods to misclassify the samples of
new classes into base classes, which leads to the poor performance of new
classes. In other words, the strong discriminability of base classes distracts
the classification of new classes. To figure out this intriguing phenomenon, we
observe that although the feature extractor is only trained on base classes, it
can surprisingly represent the semantic similarity between the base and unseen
new classes. Building upon these analyses, we propose a simple yet effective
Training-frEE calibratioN (TEEN) strategy to enhance the discriminability of
new classes by fusing the new prototypes (i.e., mean features of a class) with
weighted base prototypes. In addition to standard benchmarks in FSCIL, TEEN
demonstrates remarkable performance and consistent improvements over baseline
methods in the few-shot learning scenario. Code is available at:
https://github.com/wangkiw/TEEN
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qi-Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Da-Wei Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yi-Kai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1&quot;&gt;De-Chuan Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1&quot;&gt;Han-Jia Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05230">
<title>Language Models, Agent Models, and World Models: The LAW for Machine Reasoning and Planning. (arXiv:2312.05230v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.05230</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their tremendous success in many applications, large language models
often fall short of consistent reasoning and planning in various (language,
embodied, and social) scenarios, due to inherent limitations in their
inference, learning, and modeling capabilities. In this position paper, we
present a new perspective of machine reasoning, LAW, that connects the concepts
of Language models, Agent models, and World models, for more robust and
versatile reasoning capabilities. In particular, we propose that world and
agent models are a better abstraction of reasoning, that introduces the crucial
elements of deliberate human-like reasoning, including beliefs about the world
and other agents, anticipation of consequences, goals/rewards, and strategic
planning. Crucially, language models in LAW serve as a backend to implement the
system or its elements and hence provide the computational power and
adaptability. We review the recent studies that have made relevant progress and
discuss future research directions towards operationalizing the LAW framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zhiting Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_T/0/1/0/all/0/1&quot;&gt;Tianmin Shu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05231">
<title>Modeling Risk in Reinforcement Learning: A Literature Mapping. (arXiv:2312.05231v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05231</link>
<description rdf:parseType="Literal">&lt;p&gt;Safe reinforcement learning deals with mitigating or avoiding unsafe
situations by reinforcement learning (RL) agents. Safe RL approaches are based
on specific risk representations for particular problems or domains. In order
to analyze agent behaviors, compare safe RL approaches, and effectively
transfer techniques between application domains, it is necessary to understand
the types of risk specific to safe RL problems. We performed a systematic
literature mapping with the objective to characterize risk in safe RL. Based on
the obtained results, we present definitions, characteristics, and types of
risk that hold on multiple application domains. Our literature mapping covers
literature from the last 5 years (2017-2022), from a variety of knowledge areas
(AI, finance, engineering, medicine) where RL approaches emphasize risk
representation and management. Our mapping covers 72 papers filtered
systematically from over thousands of papers on the topic. Our proposed notion
of risk covers a variety of representations, disciplinary differences, common
training exercises, and types of techniques. We encourage researchers to
include explicit and detailed accounts of risk in future safe RL research
reports, using this mapping as a starting point. With this information,
researchers and practitioners could draw stronger conclusions on the
effectiveness of techniques on different problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villalobos_Arias_L/0/1/0/all/0/1&quot;&gt;Leonardo Villalobos-Arias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_D/0/1/0/all/0/1&quot;&gt;Derek Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1&quot;&gt;Abhijeet Krishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagne_M/0/1/0/all/0/1&quot;&gt;Madeleine Gagn&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1&quot;&gt;Colin M. Potts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jhala_A/0/1/0/all/0/1&quot;&gt;Arnav Jhala&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05234">
<title>The impact of heteroskedasticity on uplift modeling. (arXiv:2312.05234v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.05234</link>
<description rdf:parseType="Literal">&lt;p&gt;There are various applications, where companies need to decide to which
individuals they should best allocate treatment. To support such decisions,
uplift models are applied to predict treatment effects on an individual level.
Based on the predicted treatment effects, individuals can be ranked and
treatment allocation can be prioritized according to this ranking. An implicit
assumption, which has not been doubted in the previous uplift modeling
literature, is that this treatment prioritization approach tends to bring
individuals with high treatment effects to the top and individuals with low
treatment effects to the bottom of the ranking. In our research, we show that
heteroskedastictity in the training data can cause a bias of the uplift model
ranking: individuals with the highest treatment effects can get accumulated in
large numbers at the bottom of the ranking. We explain theoretically how
heteroskedasticity can bias the ranking of uplift models and show this process
in a simulation and on real-world data. We argue that this problem of ranking
bias due to heteroskedasticity might occur in many real-world applications and
requires modification of the treatment prioritization to achieve an efficient
treatment allocation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bokelmann_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn Bokelmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lessmann_S/0/1/0/all/0/1&quot;&gt;Stefan Lessmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05248">
<title>Topology-Based Reconstruction Prevention for Decentralised Learning. (arXiv:2312.05248v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.05248</link>
<description rdf:parseType="Literal">&lt;p&gt;Decentralised learning has recently gained traction as an alternative to
federated learning in which both data and coordination are distributed over its
users. To preserve the confidentiality of users&apos; data, decentralised learning
relies on differential privacy, multi-party computation, or a combination
thereof. However, running multiple privacy-preserving summations in sequence
may allow adversaries to perform reconstruction attacks. Unfortunately, current
reconstruction countermeasures either cannot trivially be adapted to the
distributed setting, or add excessive amounts of noise.
&lt;/p&gt;
&lt;p&gt;In this work, we first show that passive honest-but-curious adversaries can
reconstruct other users&apos; private data after several privacy-preserving
summations. For example, in subgraphs with 18 users, we show that only three
passive honest-but-curious adversaries succeed at reconstructing private data
11.0% of the time, requiring an average of 8.8 summations per adversary. The
success rate is independent of the size of the full network. We consider weak
adversaries, who do not control the graph topology and can exploit neither the
workings of the summation protocol nor the specifics of users&apos; data.
&lt;/p&gt;
&lt;p&gt;We develop a mathematical understanding of how reconstruction relates to
topology and propose the first topology-based decentralised defence against
reconstruction attacks. Specifically, we show that reconstruction requires a
number of adversaries linear in the length of the network&apos;s shortest cycle.
Consequently, reconstructing private data from privacy-preserving summations is
impossible in acyclic networks.
&lt;/p&gt;
&lt;p&gt;Our work is a stepping stone for a formal theory of decentralised
reconstruction defences based on topology. Such a theory would generalise our
countermeasure beyond summation, define confidentiality in terms of entropy,
and describe the effects of (topology-aware) differential privacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dekker_F/0/1/0/all/0/1&quot;&gt;Florine W. Dekker&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erkin_Z/0/1/0/all/0/1&quot;&gt;Zekeriya Erkin&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1&quot;&gt;Mauro Conti&lt;/a&gt; (2 and 1) ((1) Delft University of Technology, the Netherlands and (2) Universit&amp;#xe0; di Padova, Italy)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05250">
<title>TaskMet: Task-Driven Metric Learning for Model Learning. (arXiv:2312.05250v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05250</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models are often deployed in downstream tasks that the training
procedure may not be aware of. For example, models solely trained to achieve
accurate predictions may struggle to perform well on downstream tasks because
seemingly small prediction errors may incur drastic task errors. The standard
end-to-end learning approach is to make the task loss differentiable or to
introduce a differentiable surrogate that the model can be trained on. In these
settings, the task loss needs to be carefully balanced with the prediction loss
because they may have conflicting objectives. We propose take the task loss
signal one level deeper than the parameters of the model and use it to learn
the parameters of the loss function the model is trained on, which can be done
by learning a metric in the prediction space. This approach does not alter the
optimal prediction model itself, but rather changes the model learning to
emphasize the information important for the downstream task. This enables us to
achieve the best of both worlds: a prediction model trained in the original
prediction space while also being valuable for the desired downstream task. We
validate our approach through experiments conducted in two main settings: 1)
decision-focused model learning scenarios involving portfolio optimization and
budget allocation, and 2) reinforcement learning in noisy environments with
distracting states. The source code to reproduce our experiments is available
at https://github.com/facebookresearch/taskmet
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_D/0/1/0/all/0/1&quot;&gt;Dishank Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Ricky T. Q. Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukadam_M/0/1/0/all/0/1&quot;&gt;Mustafa Mukadam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1&quot;&gt;Brandon Amos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05253">
<title>KBFormer: A Diffusion Model for Structured Entity Completion. (arXiv:2312.05253v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.05253</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a generative attention-based approach to modeling structured
entities comprising different property types, such as numerical, categorical,
string, and composite. This approach handles such heterogeneous data through a
mixed continuous-discrete diffusion process over the properties. Our flexible
framework can model entities with arbitrary hierarchical properties, enabling
applications to structured Knowledge Base (KB) entities and tabular data. Our
approach obtains state-of-the-art performance on a majority of cases across 15
datasets. In addition, experiments with a device KB and a nuclear physics
dataset demonstrate the model&apos;s ability to learn representations useful for
entity completion in diverse settings. This has many downstream use cases,
including modeling numerical properties with high accuracy - critical for
science applications, which also benefit from the model&apos;s inherent
probabilistic nature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kitouni_O/0/1/0/all/0/1&quot;&gt;Ouail Kitouni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nolte_N/0/1/0/all/0/1&quot;&gt;Niklas Nolte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hensman_J/0/1/0/all/0/1&quot;&gt;James Hensman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitra_B/0/1/0/all/0/1&quot;&gt;Bhaskar Mitra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05254">
<title>Disentangling CO Chemistry in a Protoplanetary Disk Using Explanatory Machine Learning Techniques. (arXiv:2312.05254v1 [astro-ph.EP])</title>
<link>http://arxiv.org/abs/2312.05254</link>
<description rdf:parseType="Literal">&lt;p&gt;Molecular abundances in protoplanetary disks are highly sensitive to the
local physical conditions, including gas temperature, gas density, radiation
field, and dust properties. Often multiple factors are intertwined, impacting
the abundances of both simple and complex species. We present a new approach to
understanding these chemical and physical interdependencies using machine
learning. Specifically we explore the case of CO modeled under the conditions
of a generic disk and build an explanatory regression model to study the
dependence of CO spatial density on the gas density, gas temperature, cosmic
ray ionization rate, X-ray ionization rate, and UV flux. Our findings indicate
that combinations of parameters play a surprisingly powerful role in regulating
CO compared to any singular physical parameter. Moreover, in general, we find
the conditions in the disk are destructive toward CO. CO depletion is further
enhanced in an increased cosmic ray environment and in disks with higher
initial C/O ratios. These dependencies uncovered by our new approach are
consistent with previous studies, which are more modeling intensive and
computationally expensive. Our work thus shows that machine learning can be a
powerful tool not only for creating efficient predictive models, but also for
enabling a deeper understanding of complex chemical processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Diop_A/0/1/0/all/0/1&quot;&gt;Amina Diop&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Cleeves_I/0/1/0/all/0/1&quot;&gt;Ilse Cleeves&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Anderson_D/0/1/0/all/0/1&quot;&gt;Dana Anderson&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Pegues_J/0/1/0/all/0/1&quot;&gt;Jamila Pegues&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Plunkett_A/0/1/0/all/0/1&quot;&gt;Adele Plunkett&lt;/a&gt; (4) ((1) University of Virginia, (2) Earth and Planets Laboratory, Carnegie Institution for Science, (3) Space Telescope Science Institute, (4) National Radio Astronomy Observatory)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2005.11753">
<title>Continuous Release of Data Streams under both Centralized and Local Differential Privacy. (arXiv:2005.11753v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2005.11753</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the problem of publishing a stream of real-valued
data satisfying differential privacy (DP). One major challenge is that the
maximal possible value can be quite large; thus it is necessary to estimate a
threshold so that numbers above it are truncated to reduce the amount of noise
that is required to all the data. The estimation must be done based on the data
in a private fashion. We develop such a method that uses the Exponential
Mechanism with a quality function that approximates well the utility goal while
maintaining a low sensitivity. Given the threshold, we then propose a novel
online hierarchical method and several post-processing techniques.
&lt;/p&gt;
&lt;p&gt;Building on these ideas, we formalize the steps into a framework for private
publishing of stream data. Our framework consists of three components: a
threshold optimizer that privately estimates the threshold, a perturber that
adds calibrated noises to the stream, and a smoother that improves the result
using post-processing. Within our framework, we design an algorithm satisfying
the more stringent setting of DP called local DP (LDP). To our knowledge, this
is the first LDP algorithm for publishing streaming data. Using four real-world
datasets, we demonstrate that our mechanism outperforms the state-of-the-art by
a factor of 6-10 orders of magnitude in terms of utility (measured by the mean
squared error of answering a random range query).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tianhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Joann Qiongna Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhikun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1&quot;&gt;Dong Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yueqiang Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhou Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1&quot;&gt;Ninghui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Somesh Jha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.11505">
<title>Low-skilled Occupations Face the Highest Upskilling Pressure. (arXiv:2101.11505v4 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/2101.11505</link>
<description rdf:parseType="Literal">&lt;p&gt;Substantial scholarship has estimated the susceptibility of jobs to
automation, but little has examined how job contents evolve in the information
age as new technologies substitute for tasks, shifting required skills rather
than eliminating entire jobs. Here we explore patterns and consequences of
changes in occupational skill and characterize occupations and workers subject
to the greatest re-skilling pressure. Recent work found that changing skill
requirements are greatest for STEM occupations. Nevertheless, analyzing 167
million online job posts covering 727 occupations over the last decade, we find
that re-skilling pressure is greatest for low-skilled occupations when
accounting for distance between skills. We further investigate the differences
in skill change across employer and market size, as well as social demographic
groups, and find that these differences tend to widen the economic divide. Jobs
from large employers and markets experienced less change relative to small
employers and markets, and non-white workers in low-skilled jobs are most
demographically vulnerable. We conclude by showcasing our model&apos;s potential to
precisely chart job evolution towards machine-interface integration using skill
embedding spaces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_D/0/1/0/all/0/1&quot;&gt;Di Tong&lt;/a&gt; (Massachusetts Institute of Technology), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lingfei Wu&lt;/a&gt; (University of Pittsburgh), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_J/0/1/0/all/0/1&quot;&gt;James Allen Evans&lt;/a&gt; (University of Chicago)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.11328">
<title>Predicting Census Survey Response Rates With Parsimonious Additive Models and Structured Interactions. (arXiv:2108.11328v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2108.11328</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we consider the problem of predicting survey response rates
using a family of flexible and interpretable nonparametric models. The study is
motivated by the US Census Bureau&apos;s well-known ROAM application which uses a
linear regression model trained on the US Census Planning Database data to
identify hard-to-survey areas. A crowdsourcing competition (Erdman and Bates,
2016) organized around ten years ago revealed that machine learning methods
based on ensembles of regression trees led to the best performance in
predicting survey response rates; however, the corresponding models could not
be adopted for the intended application due to their black-box nature. We
consider nonparametric additive models with small number of main and pairwise
interaction effects using $\ell_0$-based penalization. From a methodological
viewpoint, we study both computational and statistical aspects of our
estimator; and discuss variants that incorporate strong hierarchical
interactions. Our algorithms (opensourced on github) extend the computational
frontiers of existing algorithms for sparse additive models, to be able to
handle datasets relevant for the application we consider. We discuss and
interpret findings from our model on the US Census Planning Database. In
addition to being useful from an interpretability standpoint, our models lead
to predictions that appear to be better than popular black-box machine learning
methods based on gradient boosting and feedforward neural networks - suggesting
that it is possible to have models that have the best of both worlds: good
model accuracy and interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ibrahim_S/0/1/0/all/0/1&quot;&gt;Shibal Ibrahim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Radchenko_P/0/1/0/all/0/1&quot;&gt;Peter Radchenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ben_David_E/0/1/0/all/0/1&quot;&gt;Emanuel Ben-David&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mazumder_R/0/1/0/all/0/1&quot;&gt;Rahul Mazumder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.12989">
<title>Domain-Aware Continual Zero-Shot Learning. (arXiv:2112.12989v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2112.12989</link>
<description rdf:parseType="Literal">&lt;p&gt;Continual zero-shot learning involves learning seen classes incrementally
while improving the ability to recognize unseen or yet-to-be-seen classes. It
has a broad range of potential applications in real-world vision tasks, such as
accelerating species discovery. However, in these scenarios, the changes in
environmental conditions cause shifts in the presentation of captured images,
which we refer to as domain shift, and adds complexity to the tasks. In this
paper, we introduce Domain Aware Continual Zero-Shot Learning (DACZSL), a task
that involves visually recognizing images of unseen categories in unseen
domains continually. To address the challenges of DACZSL, we propose a
Domain-Invariant Network (DIN). We empoly a dual network structure to learn
factorized features to alleviate forgetting, where consists of a global shared
net for domian-invirant and task-invariant features, and per-task private nets
for task-specific features. Furthermore, we introduce a class-wise learnable
prompt to obtain better class-level text representation, which enables
zero-shot prediction of future unseen classes. To evaluate DACZSL, we introduce
two benchmarks: DomainNet-CZSL and iWildCam-CZSL. Our results show that DIN
significantly outperforms existing baselines and achieves a new
state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_K/0/1/0/all/0/1&quot;&gt;Kai Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janson_P/0/1/0/all/0/1&quot;&gt;Paul Janson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wenxuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elhoseiny_M/0/1/0/all/0/1&quot;&gt;Mohamed Elhoseiny&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.12276">
<title>Multi-Frequency Joint Community Detection and Phase Synchronization. (arXiv:2206.12276v3 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2206.12276</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the joint community detection and phase synchronization
problem on the \textit{stochastic block model with relative phase}, where each
node is associated with an unknown phase angle. This problem, with a variety of
real-world applications, aims to recover the cluster structure and associated
phase angles simultaneously. We show this problem exhibits a
\textit{``multi-frequency&apos;&apos;} structure by closely examining its maximum
likelihood estimation (MLE) formulation, whereas existing methods are not
originated from this perspective. To this end, two simple yet efficient
algorithms that leverage the MLE formulation and benefit from the information
across multiple frequencies are proposed. The former is a spectral method based
on the novel multi-frequency column-pivoted QR factorization. The factorization
applied to the top eigenvectors of the observation matrix provides key
information about the cluster structure and associated phase angles. The second
approach is an iterative multi-frequency generalized power method, where each
iteration updates the estimation in a matrix-multiplication-then-projection
manner. Numerical experiments show that our proposed algorithms significantly
improve the ability of exactly recovering the cluster structure and the
accuracy of the estimated phase angles, compared to state-of-the-art
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lingda Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhizhen Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.07084">
<title>Z-BERT-A: a zero-shot Pipeline for Unknown Intent detection. (arXiv:2208.07084v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2208.07084</link>
<description rdf:parseType="Literal">&lt;p&gt;Intent discovery is a crucial task in natural language processing, and it is
increasingly relevant for various of industrial applications. Identifying
novel, unseen intents from user inputs remains one of the biggest challenges in
this field. Herein, we propose Zero-Shot-BERT-Adapters, a two-stage method for
multilingual intent discovery relying on a Transformer architecture, fine-tuned
with Adapters. We train the model for Natural Language Inference (NLI) and
later perform unknown intent classification in a zero-shot setting for multiple
languages. In our evaluation, we first analyze the quality of the model after
adaptive fine-tuning on known classes. Secondly, we evaluate its performance in
casting intent classification as an NLI task. Lastly, we test the zero-shot
performance of the model on unseen classes, showing how Zero-Shot-BERT-Adapters
can effectively perform intent discovery by generating semantically similar
intents, if not equal, to the ground-truth ones. Our experiments show how
Zero-Shot-BERT-Adapters outperforms various baselines in two zero-shot
settings: known intent classification and unseen intent discovery. The proposed
pipeline holds the potential for broad application in customer care. It enables
automated dynamic triage using a lightweight model that can be easily deployed
and scaled in various business scenarios, unlike large language models.
Zero-Shot-BERT-Adapters represents an innovative multi-language approach for
intent discovery, enabling the online generation of novel intents. A Python
package implementing the pipeline and the new datasets we compiled are
available at the following link:
https://github.com/GT4SD/zero-shot-bert-adapters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Comi_D/0/1/0/all/0/1&quot;&gt;Daniele Comi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christofidellis_D/0/1/0/all/0/1&quot;&gt;Dimitrios Christofidellis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piazza_P/0/1/0/all/0/1&quot;&gt;Pier Francesco Piazza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manica_M/0/1/0/all/0/1&quot;&gt;Matteo Manica&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.07898">
<title>Collaborative causal inference on distributed data. (arXiv:2208.07898v4 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/2208.07898</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the development of technologies for causal inference with
privacy preservation of distributed data has gained considerable attention.
Many existing methods for distributed data focus on resolving the lack of
subjects (samples) and can only reduce random errors in estimating treatment
effects. In this study, we propose a data collaboration quasi-experiment
(DC-QE) that resolves the lack of both subjects and covariates, reducing random
errors and biases in the estimation. Our method involves constructing
dimensionality-reduced intermediate representations from private data from
local parties, sharing intermediate representations instead of private data for
privacy preservation, estimating propensity scores from the shared intermediate
representations, and finally, estimating the treatment effects from propensity
scores. Through numerical experiments on both artificial and real-world data,
we confirm that our method leads to better estimation results than individual
analyses. While dimensionality reduction loses some information in the private
data and causes performance degradation, we observe that sharing intermediate
representations with many parties to resolve the lack of subjects and
covariates sufficiently improves performance to overcome the degradation caused
by dimensionality reduction. Although external validity is not necessarily
guaranteed, our results suggest that DC-QE is a promising method. With the
widespread use of our method, intermediate representations can be published as
open data to help researchers find causalities and accumulate a knowledge base.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kawamata_Y/0/1/0/all/0/1&quot;&gt;Yuji Kawamata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Motai_R/0/1/0/all/0/1&quot;&gt;Ryoki Motai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Okada_Y/0/1/0/all/0/1&quot;&gt;Yukihiko Okada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Imakura_A/0/1/0/all/0/1&quot;&gt;Akira Imakura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sakurai_T/0/1/0/all/0/1&quot;&gt;Tetsuya Sakurai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.04688">
<title>BAFFLE: Hiding Backdoors in Offline Reinforcement Learning Datasets. (arXiv:2210.04688v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.04688</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) makes an agent learn from trial-and-error
experiences gathered during the interaction with the environment. Recently,
offline RL has become a popular RL paradigm because it saves the interactions
with environments. In offline RL, data providers share large pre-collected
datasets, and others can train high-quality agents without interacting with the
environments. This paradigm has demonstrated effectiveness in critical tasks
like robot control, autonomous driving, etc. However, less attention is paid to
investigating the security threats to the offline RL system. This paper focuses
on backdoor attacks, where some perturbations are added to the data
(observations) such that given normal observations, the agent takes
high-rewards actions, and low-reward actions on observations injected with
triggers. In this paper, we propose Baffle (Backdoor Attack for Offline
Reinforcement Learning), an approach that automatically implants backdoors to
RL agents by poisoning the offline RL dataset, and evaluate how different
offline RL algorithms react to this attack. Our experiments conducted on four
tasks and four offline RL algorithms expose a disquieting fact: none of the
existing offline RL algorithms is immune to such a backdoor attack. More
specifically, Baffle modifies 10\% of the datasets for four tasks (3 robotic
controls and 1 autonomous driving). Agents trained on the poisoned datasets
perform well in normal settings. However, when triggers are presented, the
agents&apos; performance decreases drastically by 63.2\%, 53.9\%, 64.7\%, and 47.4\%
in the four tasks on average. The backdoor still persists after fine-tuning
poisoned agents on clean datasets. We further show that the inserted backdoor
is also hard to be detected by a popular defensive method. This paper calls
attention to developing more effective protection for the open-source offline
RL dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1&quot;&gt;Chen Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhou Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yunpeng Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Junda He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jieke Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kecen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1&quot;&gt;Arunesh Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1&quot;&gt;Bowen Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_X/0/1/0/all/0/1&quot;&gt;Xinwen Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lo_D/0/1/0/all/0/1&quot;&gt;David Lo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tianhao Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.12637">
<title>Neural Eigenfunctions Are Structured Representation Learners. (arXiv:2210.12637v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.12637</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a structured, adaptive-length deep representation
called Neural Eigenmap. Unlike prior spectral methods such as Laplacian
Eigenmap that operate in a nonparametric manner, Neural Eigenmap leverages
NeuralEF to parametrically model eigenfunctions using a neural network. We show
that, when the eigenfunction is derived from positive relations in a data
augmentation setup, applying NeuralEF results in an objective function that
resembles those of popular self-supervised learning methods, with an additional
symmetry-breaking property that leads to \emph{structured} representations
where features are ordered by importance. We demonstrate using such
representations as adaptive-length codes in image retrieval systems. By
truncation according to feature importance, our method requires up to
$16\times$ shorter representation length than leading self-supervised learning
ones to achieve similar retrieval performance. We further apply our method to
graph data and report strong results on a node representation learning
benchmark with more than one million nodes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1&quot;&gt;Zhijie Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jiaxin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1&quot;&gt;Peng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Cewu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01842">
<title>Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars. (arXiv:2211.01842v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.01842</link>
<description rdf:parseType="Literal">&lt;p&gt;The discovery of neural architectures from simple building blocks is a
long-standing goal of Neural Architecture Search (NAS). Hierarchical search
spaces are a promising step towards this goal but lack a unifying search space
design framework and typically only search over some limited aspect of
architectures. In this work, we introduce a unifying search space design
framework based on context-free grammars that can naturally and compactly
generate expressive hierarchical search spaces that are 100s of orders of
magnitude larger than common spaces from the literature. By enhancing and using
their properties, we effectively enable search over the complete architecture
and can foster regularity. Further, we propose an efficient hierarchical kernel
design for a Bayesian Optimization search strategy to efficiently search over
such huge spaces. We demonstrate the versatility of our search space design
framework and show that our search strategy can be superior to existing NAS
approaches. Code is available at
https://github.com/automl/hierarchical_nas_construction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schrodi_S/0/1/0/all/0/1&quot;&gt;Simon Schrodi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoll_D/0/1/0/all/0/1&quot;&gt;Danny Stoll&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ru_B/0/1/0/all/0/1&quot;&gt;Binxin Ru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1&quot;&gt;Rhea Sukthanker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1&quot;&gt;Thomas Brox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.13220">
<title>TetraDiffusion: Tetrahedral Diffusion Models for 3D Shape Generation. (arXiv:2211.13220v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2211.13220</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic denoising diffusion models (DDMs) have set a new standard for
2D image generation. Extending DDMs for 3D content creation is an active field
of research. Here, we propose TetraDiffusion, a diffusion model that operates
on a tetrahedral partitioning of 3D space to enable efficient, high-resolution
3D shape generation. Our model introduces operators for convolution and
transpose convolution that act directly on the tetrahedral partition, and
seamlessly includes additional attributes such as color. Remarkably,
TetraDiffusion enables rapid sampling of detailed 3D objects in nearly
real-time with unprecedented resolution. It&apos;s also adaptable for generating 3D
shapes conditioned on 2D images. Compared to existing 3D mesh diffusion
techniques, our method is up to 200 times faster in inference speed, works on
standard consumer hardware, and delivers superior results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalischek_N/0/1/0/all/0/1&quot;&gt;Nikolai Kalischek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peters_T/0/1/0/all/0/1&quot;&gt;Torben Peters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1&quot;&gt;Jan D. Wegner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1&quot;&gt;Konrad Schindler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.07311">
<title>Bayesian data fusion with shared priors. (arXiv:2212.07311v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.07311</link>
<description rdf:parseType="Literal">&lt;p&gt;The integration of data and knowledge from several sources is known as data
fusion. When data is only available in a distributed fashion or when different
sensors are used to infer a quantity of interest, data fusion becomes
essential. In Bayesian settings, a priori information of the unknown quantities
is available and, possibly, present among the different distributed estimators.
When the local estimates are fused, the prior knowledge used to construct
several local posteriors might be overused unless the fusion node accounts for
this and corrects it. In this paper, we analyze the effects of shared priors in
Bayesian data fusion contexts. Depending on different common fusion rules, our
analysis helps to understand the performance behavior as a function of the
number of collaborative agents and as a consequence of different types of
priors. The analysis is performed by using two divergences which are common in
Bayesian inference, and the generality of the results allows to analyze very
generic distributions. These theoretical results are corroborated through
experiments in a variety of estimation and classification problems, including
linear and nonlinear models, and federated learning schemes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1&quot;&gt;Peng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Imbiriba_T/0/1/0/all/0/1&quot;&gt;Tales Imbiriba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elvira_V/0/1/0/all/0/1&quot;&gt;Victor Elvira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Closas_P/0/1/0/all/0/1&quot;&gt;Pau Closas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.09744">
<title>DSI++: Updating Transformer Memory with New Documents. (arXiv:2212.09744v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2212.09744</link>
<description rdf:parseType="Literal">&lt;p&gt;Differentiable Search Indices (DSIs) encode a corpus of documents in model
parameters and use the same model to answer user queries directly. Despite the
strong performance of DSI models, deploying them in situations where the corpus
changes over time is computationally expensive because reindexing the corpus
requires re-training the model. In this work, we introduce DSI++, a continual
learning challenge for DSI to incrementally index new documents while being
able to answer queries related to both previously and newly indexed documents.
Across different model scales and document identifier representations, we show
that continual indexing of new documents leads to considerable forgetting of
previously indexed documents. We also hypothesize and verify that the model
experiences forgetting events during training, leading to unstable learning. To
mitigate these issues, we investigate two approaches. The first focuses on
modifying the training dynamics. Flatter minima implicitly alleviate
forgetting, so we optimize for flatter loss basins and show that the model
stably memorizes more documents ($+12\%$). Next, we introduce a generative
memory to sample pseudo-queries for documents and supplement them during
continual indexing to prevent forgetting for the retrieval task. Extensive
experiments on novel continual indexing benchmarks based on Natural Questions
(NQ) and MS MARCO demonstrate that our proposed solution mitigates forgetting
significantly. Concretely, it improves the average Hits@10 by $+21.1\%$ over
competitive baselines for NQ and requires $6$ times fewer model updates
compared to re-training the DSI model for incrementally indexing five corpora
in a sequence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1&quot;&gt;Sanket Vaibhav Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_J/0/1/0/all/0/1&quot;&gt;Jai Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1&quot;&gt;Yi Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1&quot;&gt;Mostafa Dehghani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1&quot;&gt;Vinh Q. Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1&quot;&gt;Jinfeng Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Najork_M/0/1/0/all/0/1&quot;&gt;Marc Najork&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strubell_E/0/1/0/all/0/1&quot;&gt;Emma Strubell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1&quot;&gt;Donald Metzler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.09568">
<title>Interpretable Classification of Early Stage Parkinson&apos;s Disease from EEG. (arXiv:2301.09568v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/2301.09568</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting Parkinson&apos;s Disease in its early stages using EEG data presents a
significant challenge. This paper introduces a novel approach, representing EEG
data as a 15-variate series of bandpower and peak frequency
values/coefficients. The hypothesis is that this representation captures
essential information from the noisy EEG signal, improving disease detection.
Statistical features extracted from this representation are utilised as input
for interpretable machine learning models, specifically Decision Tree and
AdaBoost classifiers. Our classification pipeline is deployed within our
proposed framework which enables high-importance data types and brain regions
for classification to be identified. Interestingly, our analysis reveals that
while there is no significant regional importance, the N1 sleep data type
exhibits statistically significant predictive power (p &amp;lt; 0.01) for early-stage
Parkinson&apos;s Disease classification. AdaBoost classifiers trained on the N1 data
type consistently outperform baseline models, achieving over 80% accuracy and
recall. Our classification pipeline statistically significantly outperforms
baseline models indicating that the model has acquired useful information.
Paired with the interpretability (ability to view feature importance&apos;s) of our
pipeline this enables us to generate meaningful insights into the
classification of early stage Parkinson&apos;s with our N1 models. In Future, these
models could be deployed in the real world - the results presented in this
paper indicate that more than 3 in 4 early-stage Parkinson&apos;s cases would be
captured with our pipeline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sahota_A/0/1/0/all/0/1&quot;&gt;Amarpal Sahota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Roguski_A/0/1/0/all/0/1&quot;&gt;Amber Roguski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Jones_M/0/1/0/all/0/1&quot;&gt;Matthew W. Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Rolinski_M/0/1/0/all/0/1&quot;&gt;Michal Rolinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Whone_A/0/1/0/all/0/1&quot;&gt;Alan Whone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1&quot;&gt;Raul Santos-Rodriguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Abdallah_Z/0/1/0/all/0/1&quot;&gt;Zahraa S. Abdallah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.01404">
<title>Provably Bounding Neural Network Preimages. (arXiv:2302.01404v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.01404</link>
<description rdf:parseType="Literal">&lt;p&gt;Most work on the formal verification of neural networks has focused on
bounding the set of outputs that correspond to a given set of inputs (for
example, bounded perturbations of a nominal input). However, many use cases of
neural network verification require solving the inverse problem, or
over-approximating the set of inputs that lead to certain outputs. We present
the INVPROP algorithm for verifying properties over the preimage of a linearly
constrained output set, which can be combined with branch-and-bound to increase
precision. Contrary to other approaches, our efficient algorithm is
GPU-accelerated and does not require a linear programming solver. We
demonstrate our algorithm for identifying safe control regions for a dynamical
system via backward reachability analysis, verifying adversarial robustness,
and detecting out-of-distribution inputs to a neural network. Our results show
that in certain settings, we find over-approximations over 2500x tighter than
prior work while being 2.5x faster. By strengthening robustness verification
with output constraints, we consistently verify more properties than the
previous state-of-the-art on multiple benchmarks, including a large model with
167k neurons in VNN-COMP 2023. Our algorithm has been incorporated into the
$\alpha,\!\beta$-CROWN verifier, available at https://abcrown.org.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kotha_S/0/1/0/all/0/1&quot;&gt;Suhas Kotha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brix_C/0/1/0/all/0/1&quot;&gt;Christopher Brix&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_Z/0/1/0/all/0/1&quot;&gt;Zico Kolter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dvijotham_K/0/1/0/all/0/1&quot;&gt;Krishnamurthy Dvijotham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.02524">
<title>Novel Fundus Image Preprocessing for Retcam Images to Improve Deep Learning Classification of Retinopathy of Prematurity. (arXiv:2302.02524v4 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2302.02524</link>
<description rdf:parseType="Literal">&lt;p&gt;Retinopathy of Prematurity (ROP) is a potentially blinding eye disorder
because of damage to the eye&apos;s retina which can affect babies born prematurely.
Screening of ROP is essential for early detection and treatment. This is a
laborious and manual process which requires trained physician performing
dilated ophthalmological examination which can be subjective resulting in lower
diagnosis success for clinically significant disease. Automated diagnostic
methods can assist ophthalmologists increase diagnosis accuracy using deep
learning. Several research groups have highlighted various approaches. Captured
ROP Retcam images suffer from poor quality. This paper proposes the use of
improved novel fundus preprocessing methods using pretrained transfer learning
frameworks to create hybrid models to give higher diagnosis accuracy. Once
trained and validated, the evaluations showed that these novel methods in
comparison to traditional imaging processing contribute to better and in many
aspects higher accuracy in classifying Plus disease, Stages of ROP and Zones in
comparison to peer papers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rahim_S/0/1/0/all/0/1&quot;&gt;Sajid Rahim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sabri_K/0/1/0/all/0/1&quot;&gt;Kourosh Sabri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ells_A/0/1/0/all/0/1&quot;&gt;Anna Ells&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wassyng_A/0/1/0/all/0/1&quot;&gt;Alan Wassyng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lawford_M/0/1/0/all/0/1&quot;&gt;Mark Lawford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chu_L/0/1/0/all/0/1&quot;&gt;Linyang Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+He_W/0/1/0/all/0/1&quot;&gt;Wenbo He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.06359">
<title>Fixing Overconfidence in Dynamic Neural Networks. (arXiv:2302.06359v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.06359</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamic neural networks are a recent technique that promises a remedy for the
increasing size of modern deep learning models by dynamically adapting their
computational cost to the difficulty of the inputs. In this way, the model can
adjust to a limited computational budget. However, the poor quality of
uncertainty estimates in deep learning models makes it difficult to distinguish
between hard and easy samples. To address this challenge, we present a
computationally efficient approach for post-hoc uncertainty quantification in
dynamic neural networks. We show that adequately quantifying and accounting for
both aleatoric and epistemic uncertainty through a probabilistic treatment of
the last layers improves the predictive performance and aids decision-making
when determining the computational budget. In the experiments, we show
improvements on CIFAR-100, ImageNet, and Caltech-256 in terms of accuracy,
capturing uncertainty, and calibration error.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meronen_L/0/1/0/all/0/1&quot;&gt;Lassi Meronen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trapp_M/0/1/0/all/0/1&quot;&gt;Martin Trapp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilzer_A/0/1/0/all/0/1&quot;&gt;Andrea Pilzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Le Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solin_A/0/1/0/all/0/1&quot;&gt;Arno Solin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.02304">
<title>Coupled Multiwavelet Neural Operator Learning for Coupled Partial Differential Equations. (arXiv:2303.02304v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.02304</link>
<description rdf:parseType="Literal">&lt;p&gt;Coupled partial differential equations (PDEs) are key tasks in modeling the
complex dynamics of many physical processes. Recently, neural operators have
shown the ability to solve PDEs by learning the integral kernel directly in
Fourier/Wavelet space, so the difficulty for solving the coupled PDEs depends
on dealing with the coupled mappings between the functions. Towards this end,
we propose a \textit{coupled multiwavelets neural operator} (CMWNO) learning
scheme by decoupling the coupled integral kernels during the multiwavelet
decomposition and reconstruction procedures in the Wavelet space. The proposed
model achieves significantly higher accuracy compared to previous
learning-based solvers in solving the coupled PDEs including Gray-Scott (GS)
equations and the non-local mean field game (MFG) problem. According to our
experimental results, the proposed model exhibits a $2\times \sim 4\times$
improvement relative $L$2 error compared to the best results from the
state-of-the-art models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1&quot;&gt;Xiongye Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1&quot;&gt;Defu Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Ruochen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1&quot;&gt;Gaurav Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Gengshuo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1&quot;&gt;Chenzhong Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balan_R/0/1/0/all/0/1&quot;&gt;Radu Balan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bogdan_P/0/1/0/all/0/1&quot;&gt;Paul Bogdan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.09424">
<title>Loss Minimization Yields Multicalibration for Large Neural Networks. (arXiv:2304.09424v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.09424</link>
<description rdf:parseType="Literal">&lt;p&gt;Multicalibration is a notion of fairness for predictors that requires them to
provide calibrated predictions across a large set of protected groups.
Multicalibration is known to be a distinct goal than loss minimization, even
for simple predictors such as linear functions.
&lt;/p&gt;
&lt;p&gt;In this work, we consider the setting where the protected groups can be
represented by neural networks of size $k$, and the predictors are neural
networks of size $n &amp;gt; k$. We show that minimizing the squared loss over all
neural nets of size $n$ implies multicalibration for all but a bounded number
of unlucky values of $n$. We also give evidence that our bound on the number of
unlucky values is tight, given our proof technique. Previously, results of the
flavor that loss minimization yields multicalibration were known only for
predictors that were near the ground truth, hence were rather limited in
applicability. Unlike these, our results rely on the expressivity of neural
nets and utilize the representation of the predictor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1&quot;&gt;Jaros&amp;#x142;aw B&amp;#x142;asiok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalan_P/0/1/0/all/0/1&quot;&gt;Parikshit Gopalan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1&quot;&gt;Lunjia Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1&quot;&gt;Adam Tauman Kalai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1&quot;&gt;Preetum Nakkiran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.10406">
<title>Variational Classification. (arXiv:2305.10406v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.10406</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a latent variable model for classification that provides a novel
probabilistic interpretation of neural network softmax classifiers. We derive a
variational objective to train the model, analogous to the evidence lower bound
(ELBO) used to train variational auto-encoders, that generalises the
cross-entropy loss used to train classification models. Treating inputs to the
softmax layer as samples of a latent variable, our abstracted perspective
reveals a potential inconsistency between their anticipated distribution,
required for accurate label predictions, and the empirical distribution they
follow in practice. We then devise a variational objective to mitigate such
inconsistency and encourage a specified latent distribution, instead of the
implicit assumption in off-the-shelf softmax classifiers. Overall, we provide
new theoretical insight into the inner workings of widely-used softmax
classification; and empirical evaluation on image and text classification
datasets demonstrates that our proposed remedy, variational classification,
maintains classification accuracy while the reshaped latent space improves
other desirable classifier properties, such as calibration, adversarial
robustness, robustness to distribution shift and sample efficiency useful in
low data settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhuliawala_S/0/1/0/all/0/1&quot;&gt;Shehzaad Dhuliawala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1&quot;&gt;Mrinmaya Sachan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_C/0/1/0/all/0/1&quot;&gt;Carl Allen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14160">
<title>Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning. (arXiv:2305.14160v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14160</link>
<description rdf:parseType="Literal">&lt;p&gt;In-context learning (ICL) emerges as a promising capability of large language
models (LLMs) by providing them with demonstration examples to perform diverse
tasks. However, the underlying mechanism of how LLMs learn from the provided
context remains under-explored. In this paper, we investigate the working
mechanism of ICL through an information flow lens. Our findings reveal that
label words in the demonstration examples function as anchors: (1) semantic
information aggregates into label word representations during the shallow
computation layers&apos; processing; (2) the consolidated information in label words
serves as a reference for LLMs&apos; final predictions. Based on these insights, we
introduce an anchor re-weighting method to improve ICL performance, a
demonstration compression technique to expedite inference, and an analysis
framework for diagnosing ICL errors in GPT2-XL. The promising applications of
our findings again validate the uncovered ICL working mechanism and pave the
way for future studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lean Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1&quot;&gt;Damai Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Deli Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1&quot;&gt;Fandong Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jie Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xu Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14208">
<title>Domain Private Transformers for Multi-Domain Dialog Systems. (arXiv:2305.14208v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14208</link>
<description rdf:parseType="Literal">&lt;p&gt;Large, general purpose language models have demonstrated impressive
performance across many different conversational domains. While multi-domain
language models achieve low overall perplexity, their outputs are not
guaranteed to stay within the domain of a given input prompt. This paper
proposes domain privacy as a novel way to quantify how likely a conditional
language model will leak across domains. We also develop policy functions based
on token-level domain classification, and propose an efficient fine-tuning
method to improve the trained model&apos;s domain privacy. Experiments on membership
inference attacks show that our proposed method has comparable resiliency to
methods adapted from recent literature on differentially private language
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kabra_A/0/1/0/all/0/1&quot;&gt;Anmol Kabra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elenberg_E/0/1/0/all/0/1&quot;&gt;Ethan R. Elenberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14876">
<title>Reconstructive Neuron Pruning for Backdoor Defense. (arXiv:2305.14876v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14876</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have been found to be vulnerable to backdoor
attacks, raising security concerns about their deployment in mission-critical
applications. While existing defense methods have demonstrated promising
results, it is still not clear how to effectively remove backdoor-associated
neurons in backdoored DNNs. In this paper, we propose a novel defense called
\emph{Reconstructive Neuron Pruning} (RNP) to expose and prune backdoor neurons
via an unlearning and then recovering process. Specifically, RNP first unlearns
the neurons by maximizing the model&apos;s error on a small subset of clean samples
and then recovers the neurons by minimizing the model&apos;s error on the same data.
In RNP, unlearning is operated at the neuron level while recovering is operated
at the filter level, forming an asymmetric reconstructive learning procedure.
We show that such an asymmetric process on only a few clean samples can
effectively expose and prune the backdoor neurons implanted by a wide range of
attacks, achieving a new state-of-the-art defense performance. Moreover, the
unlearned model at the intermediate step of our RNP can be directly used to
improve other backdoor defense tasks including backdoor removal, trigger
recovery, backdoor label detection, and backdoor sample detection. Code is
available at \url{https://github.com/bboylyg/RNP}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yige Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1&quot;&gt;Xixiang Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xingjun Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koren_N/0/1/0/all/0/1&quot;&gt;Nodens Koren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1&quot;&gt;Lingjuan Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yu-Gang Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15987">
<title>A graphon-signal analysis of graph neural networks. (arXiv:2305.15987v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15987</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an approach for analyzing message passing graph neural networks
(MPNNs) based on an extension of graphon analysis to a so called graphon-signal
analysis. A MPNN is a function that takes a graph and a signal on the graph (a
graph-signal) and returns some value. Since the input space of MPNNs is
non-Euclidean, i.e., graphs can be of any size and topology, properties such as
generalization are less well understood for MPNNs than for Euclidean neural
networks. We claim that one important missing ingredient in past work is a
meaningful notion of graph-signal similarity measure, that endows the space of
inputs to MPNNs with a regular structure. We present such a similarity measure,
called the graphon-signal cut distance, which makes the space of all
graph-signals a dense subset of a compact metric space -- the graphon-signal
space. Informally, two deterministic graph-signals are close in cut distance if
they ``look like&apos;&apos; they were sampled from the same random graph-signal model.
Hence, our cut distance is a natural notion of graph-signal similarity, which
allows comparing any pair of graph-signals of any size and topology. We prove
that MPNNs are Lipschitz continuous functions over the graphon-signal metric
space. We then give two applications of this result: 1) a generalization bound
for MPNNs, and, 2) the stability of MPNNs to subsampling of graph-signals. Our
results apply to any regular enough MPNN on any distribution of graph-signals,
making the analysis rather universal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levie_R/0/1/0/all/0/1&quot;&gt;Ron Levie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.17017">
<title>Investigating how ReLU-networks encode symmetries. (arXiv:2305.17017v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.17017</link>
<description rdf:parseType="Literal">&lt;p&gt;Many data symmetries can be described in terms of group equivariance and the
most common way of encoding group equivariances in neural networks is by
building linear layers that are group equivariant. In this work we investigate
whether equivariance of a network implies that all layers are equivariant. On
the theoretical side we find cases where equivariance implies layerwise
equivariance, but also demonstrate that this is not the case generally.
Nevertheless, we conjecture that CNNs that are trained to be equivariant will
exhibit layerwise equivariance and explain how this conjecture is a weaker
version of the recent permutation conjecture by Entezari et al. [2022]. We
perform quantitative experiments with VGG-nets on CIFAR10 and qualitative
experiments with ResNets on ImageNet to illustrate and support our theoretical
findings. These experiments are not only of interest for understanding how
group equivariance is encoded in ReLU-networks, but they also give a new
perspective on Entezari et al.&apos;s permutation conjecture as we find that it is
typically easier to merge a network with a group-transformed version of itself
than merging two different networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bokman_G/0/1/0/all/0/1&quot;&gt;Georg B&amp;#xf6;kman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahl_F/0/1/0/all/0/1&quot;&gt;Fredrik Kahl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18764">
<title>When Does Optimizing a Proper Loss Yield Calibration?. (arXiv:2305.18764v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18764</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimizing proper loss functions is popularly believed to yield predictors
with good calibration properties; the intuition being that for such losses, the
global optimum is to predict the ground-truth probabilities, which is indeed
calibrated. However, typical machine learning models are trained to
approximately minimize loss over restricted families of predictors, that are
unlikely to contain the ground truth. Under what circumstances does optimizing
proper loss over a restricted family yield calibrated models? What precise
calibration guarantees does it give? In this work, we provide a rigorous answer
to these questions. We replace the global optimality with a local optimality
condition stipulating that the (proper) loss of the predictor cannot be reduced
much by post-processing its predictions with a certain family of Lipschitz
functions. We show that any predictor with this local optimality satisfies
smooth calibration as defined in Kakade-Foster (2008), B{\l}asiok et al.
(2023). Local optimality is plausibly satisfied by well-trained DNNs, which
suggests an explanation for why they are calibrated from proper loss
minimization alone. Finally, we show that the connection between local
optimality and calibration error goes both ways: nearly calibrated predictors
are also nearly locally optimal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1&quot;&gt;Jaros&amp;#x142;aw B&amp;#x142;asiok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalan_P/0/1/0/all/0/1&quot;&gt;Parikshit Gopalan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1&quot;&gt;Lunjia Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1&quot;&gt;Preetum Nakkiran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19776">
<title>Off-By-One Implementation Error in J-UNIWARD. (arXiv:2305.19776v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19776</link>
<description rdf:parseType="Literal">&lt;p&gt;J-UNIWARD is a popular steganography method for hiding secret messages in
JPEG cover images. As a content-adaptive method, J-UNIWARD aims to embed into
textured image regions where changes are difficult to detect. To this end,
J-UNIWARD first assigns to each DCT coefficient an embedding cost calculated
based on the image&apos;s Wavelet residual, and then uses a coding method that
minimizes the cost while embedding the desired payload.
&lt;/p&gt;
&lt;p&gt;Changing one DCT coefficient affects a 23x23 window of Wavelet coefficients.
To speed up the costmap computation, the original implementation pre-computes
the Wavelet residual and then considers per changed DCT coefficient a 23x23
window of the Wavelet residual. However, the implementation accesses a window
accidentally shifted by one pixel to the bottom right.
&lt;/p&gt;
&lt;p&gt;In this report, we evaluate the effect of this off-by-one error on the
resulting costmaps. Some image blocks are over-priced while other image blocks
are under-priced, but the difference is relatively small. The off-by-one error
seems to make little difference for learning-based steganalysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lorch_B/0/1/0/all/0/1&quot;&gt;Benedikt Lorch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.00006">
<title>Truncated Affinity Maximization: One-class Homophily Modeling for Graph Anomaly Detection. (arXiv:2306.00006v4 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2306.00006</link>
<description rdf:parseType="Literal">&lt;p&gt;We reveal a one-class homophily phenomenon, which is one prevalent property
we find empirically in real-world graph anomaly detection (GAD) datasets, i.e.,
normal nodes tend to have strong connection/affinity with each other, while the
homophily in abnormal nodes is significantly weaker than normal nodes. However,
this anomaly-discriminative property is ignored by existing GAD methods that
are typically built using a conventional anomaly detection objective, such as
data reconstruction. In this work, we explore this property to introduce a
novel unsupervised anomaly scoring measure for GAD, local node affinity, that
assigns a larger anomaly score to nodes that are less affiliated with their
neighbors, with the affinity defined as similarity on node
attributes/representations. We further propose Truncated Affinity Maximization
(TAM) that learns tailored node representations for our anomaly measure by
maximizing the local affinity of nodes to their neighbors. Optimizing on the
original graph structure can be biased by nonhomophily edges (i.e., edges
connecting normal and abnormal nodes). Thus, TAM is instead optimized on
truncated graphs where non-homophily edges are removed iteratively to mitigate
this bias. The learned representations result in significantly stronger local
affinity for normal nodes than abnormal nodes. Extensive empirical results on
10 real-world GAD datasets show that TAM substantially outperforms seven
competing models, achieving over 10% increase in AUROC/AUPRC compared to the
best contenders on challenging datasets. Our code is available at
https://github.com/mala-lab/TAM-master/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_H/0/1/0/all/0/1&quot;&gt;Hezhe Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1&quot;&gt;Guansong Pang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.00945">
<title>CS4ML: A general framework for active learning with arbitrary data based on Christoffel functions. (arXiv:2306.00945v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.00945</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a general framework for active learning in regression problems.
Our framework extends the standard setup by allowing for general types of data,
rather than merely pointwise samples of the target function. This
generalization covers many cases of practical interest, such as data acquired
in transform domains (e.g., Fourier data), vector-valued data (e.g.,
gradient-augmented data), data acquired along continuous curves, and,
multimodal data (i.e., combinations of different types of measurements). Our
framework considers random sampling according to a finite number of sampling
measures and arbitrary nonlinear approximation spaces (model classes). We
introduce the concept of generalized Christoffel functions and show how these
can be used to optimize the sampling measures. We prove that this leads to
near-optimal sample complexity in various important cases. This paper focuses
on applications in scientific computing, where active learning is often
desirable, since it is usually expensive to generate data. We demonstrate the
efficacy of our framework for gradient-augmented learning with polynomials,
Magnetic Resonance Imaging (MRI) using generative models and adaptive sampling
for solving PDEs using Physics-Informed Neural Networks (PINNs).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adcock_B/0/1/0/all/0/1&quot;&gt;Ben Adcock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardenas_J/0/1/0/all/0/1&quot;&gt;Juan M. Cardenas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dexter_N/0/1/0/all/0/1&quot;&gt;Nick Dexter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.02204">
<title>Cycle Consistency Driven Object Discovery. (arXiv:2306.02204v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.02204</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing deep learning models that effectively learn object-centric
representations, akin to human cognition, remains a challenging task. Existing
approaches facilitate object discovery by representing objects as fixed-size
vectors, called ``slots&apos;&apos; or ``object files&apos;&apos;. While these approaches have
shown promise in certain scenarios, they still exhibit certain limitations.
First, they rely on architectural priors which can be unreliable and usually
require meticulous engineering to identify the correct objects. Second, there
has been a notable gap in investigating the practical utility of these
representations in downstream tasks. To address the first limitation, we
introduce a method that explicitly optimizes the constraint that each object in
a scene should be associated with a distinct slot. We formalize this constraint
by introducing consistency objectives which are cyclic in nature. By
integrating these consistency objectives into various existing slot-based
object-centric methods, we showcase substantial improvements in
object-discovery performance. These enhancements consistently hold true across
both synthetic and real-world scenes, underscoring the effectiveness and
adaptability of the proposed approach. To tackle the second limitation, we
apply the learned object-centric representations from the proposed method to
two downstream reinforcement learning tasks, demonstrating considerable
performance enhancements compared to conventional slot-based and monolithic
representation learning methods. Our results suggest that the proposed approach
not only improves object discovery, but also provides richer features for
downstream tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Didolkar_A/0/1/0/all/0/1&quot;&gt;Aniket Didolkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1&quot;&gt;Anirudh Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.03623">
<title>Spike-based computation using classical recurrent neural networks. (arXiv:2306.03623v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/2306.03623</link>
<description rdf:parseType="Literal">&lt;p&gt;Spiking neural networks are a type of artificial neural networks in which
communication between neurons is only made of events, also called spikes. This
property allows neural networks to make asynchronous and sparse computations
and therefore drastically decrease energy consumption when run on specialized
hardware. However, training such networks is known to be difficult, mainly due
to the non-differentiability of the spike activation, which prevents the use of
classical backpropagation. This is because state-of-the-art spiking neural
networks are usually derived from biologically-inspired neuron models, to which
are applied machine learning methods for training. Nowadays, research about
spiking neural networks focuses on the design of training algorithms whose goal
is to obtain networks that compete with their non-spiking version on specific
tasks. In this paper, we attempt the symmetrical approach: we modify the
dynamics of a well-known, easily trainable type of recurrent neural network to
make it event-based. This new RNN cell, called the Spiking Recurrent Cell,
therefore communicates using events, i.e. spikes, while being completely
differentiable. Vanilla backpropagation can thus be used to train any network
made of such RNN cell. We show that this new network can achieve performance
comparable to other types of spiking networks in the MNIST benchmark and its
variants, the Fashion-MNIST and the Neuromorphic-MNIST. Moreover, we show that
this new cell makes the training of deep spiking networks achievable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geeter_F/0/1/0/all/0/1&quot;&gt;Florent De Geeter&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ernst_D/0/1/0/all/0/1&quot;&gt;Damien Ernst&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drion_G/0/1/0/all/0/1&quot;&gt;Guillaume Drion&lt;/a&gt; (1) ((1) Montefiore Institute, University of Li&amp;#xe8;ge, Li&amp;#xe8;ge, Belgium)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04829">
<title>Object-Centric Learning for Real-World Videos by Predicting Temporal Feature Similarities. (arXiv:2306.04829v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.04829</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised video-based object-centric learning is a promising avenue to
learn structured representations from large, unlabeled video collections, but
previous approaches have only managed to scale to real-world datasets in
restricted domains. Recently, it was shown that the reconstruction of
pre-trained self-supervised features leads to object-centric representations on
unconstrained real-world image datasets. Building on this approach, we propose
a novel way to use such pre-trained features in the form of a temporal feature
similarity loss. This loss encodes semantic and temporal correlations between
image patches and is a natural way to introduce a motion bias for object
discovery. We demonstrate that this loss leads to state-of-the-art performance
on the challenging synthetic MOVi datasets. When used in combination with the
feature reconstruction loss, our model is the first object-centric video model
that scales to unconstrained video datasets such as YouTube-VIS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zadaianchuk_A/0/1/0/all/0/1&quot;&gt;Andrii Zadaianchuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seitzer_M/0/1/0/all/0/1&quot;&gt;Maximilian Seitzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martius_G/0/1/0/all/0/1&quot;&gt;Georg Martius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04984">
<title>G$^2$uardFL: Safeguarding Federated Learning Against Backdoor Attacks through Attributed Client Graph Clustering. (arXiv:2306.04984v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2306.04984</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) offers collaborative model training without data
sharing but is vulnerable to backdoor attacks, where poisoned model weights
lead to compromised system integrity. Existing countermeasures, primarily based
on anomaly detection, are prone to erroneous rejections of normal weights while
accepting poisoned ones, largely due to shortcomings in quantifying
similarities among client models. Furthermore, other defenses demonstrate
effectiveness only when dealing with a limited number of malicious clients,
typically fewer than 10%. To alleviate these vulnerabilities, we present
G$^2$uardFL, a protective framework that reinterprets the identification of
malicious clients as an attributed graph clustering problem, thus safeguarding
FL systems. Specifically, this framework employs a client graph clustering
approach to identify malicious clients and integrates an adaptive mechanism to
amplify the discrepancy between the aggregated model and the poisoned ones,
effectively eliminating embedded backdoors. We also conduct a theoretical
analysis of convergence to confirm that G$^2$uardFL does not affect the
convergence of FL systems. Through empirical evaluation, comparing G$^2$uardFL
with cutting-edge defenses, such as FLAME (USENIX Security 2022) [28] and
DeepSight (NDSS 2022) [36], against various backdoor attacks including 3DFed
(SP 2023) [20], our results demonstrate its significant effectiveness in
mitigating backdoor attacks while having a negligible impact on the aggregated
model&apos;s performance on benign samples (i.e., the primary task performance). For
instance, in an FL system with 25% malicious clients, G$^2$uardFL reduces the
attack success rate to 10.61%, while maintaining a primary task performance of
73.05% on the CIFAR-10 dataset. This surpasses the performance of the
best-performing baseline, which merely achieves a primary task performance of
19.54%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Meng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1&quot;&gt;Tianyu Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Ming Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1&quot;&gt;Tao Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1&quot;&gt;Shouling Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xinwang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.05415">
<title>Causal normalizing flows: from theory to practice. (arXiv:2306.05415v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.05415</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we deepen on the use of normalizing flows for causal reasoning.
Specifically, we first leverage recent results on non-linear ICA to show that
causal models are identifiable from observational data given a causal ordering,
and thus can be recovered using autoregressive normalizing flows (NFs). Second,
we analyze different design and learning choices for causal normalizing flows
to capture the underlying causal data-generating process. Third, we describe
how to implement the do-operator in causal NFs, and thus, how to answer
interventional and counterfactual questions. Finally, in our experiments, we
validate our design and training choices through a comprehensive ablation
study; compare causal NFs to other approaches for approximating causal models;
and empirically demonstrate that causal NFs can be used to address real-world
problems, where the presence of mixed discrete-continuous data and partial
knowledge on the causal graph is the norm. The code for this work can be found
at https://github.com/psanch21/causal-flows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javaloy_A/0/1/0/all/0/1&quot;&gt;Adri&amp;#xe1;n Javaloy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_Martin_P/0/1/0/all/0/1&quot;&gt;Pablo S&amp;#xe1;nchez-Mart&amp;#xed;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valera_I/0/1/0/all/0/1&quot;&gt;Isabel Valera&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11072">
<title>Causal Effect Regularization: Automated Detection and Removal of Spurious Attributes. (arXiv:2306.11072v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11072</link>
<description rdf:parseType="Literal">&lt;p&gt;In many classification datasets, the task labels are spuriously correlated
with some input attributes. Classifiers trained on such datasets often rely on
these attributes for prediction, especially when the spurious correlation is
high, and thus fail to generalize whenever there is a shift in the attributes&apos;
correlation at deployment. If we assume that the spurious attributes are known
a priori, several methods have been proposed to learn a classifier that is
invariant to the specified attributes. However, in real-world data, information
about spurious attributes is typically unavailable. Therefore, we propose a
method to automatically identify spurious attributes by estimating their causal
effect on the label and then use a regularization objective to mitigate the
classifier&apos;s reliance on them. Compared to a recent method for identifying
spurious attributes, we find that our method is more accurate in removing the
attribute from the learned model, especially when spurious correlation is high.
Specifically, across synthetic, semi-synthetic, and real-world datasets, our
method shows significant improvement in a metric used to quantify the
dependence of a classifier on spurious attributes ($\Delta$Prob), while
obtaining better or similar accuracy. In addition, our method mitigates the
reliance on spurious attributes even under noisy estimation of causal effects.
To explain the empirical robustness of our method, we create a simple linear
classification task with two sets of attributes: causal and spurious. We prove
that our method only requires that the ranking of estimated causal effects is
correct across attributes to select the correct classifier.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Abhinav Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1&quot;&gt;Amit Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Amit Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.13596">
<title>Max-Margin Token Selection in Attention Mechanism. (arXiv:2306.13596v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.13596</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention mechanism is a central component of the transformer architecture
which led to the phenomenal success of large language models. However, the
theoretical principles underlying the attention mechanism are poorly
understood, especially its nonconvex optimization dynamics. In this work, we
explore the seminal softmax-attention model $f(\boldsymbol{X})=\langle
\boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where
$\boldsymbol{X}$ is the token sequence and
$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are trainable parameters. We
prove that running gradient descent on $\boldsymbol{p}$, or equivalently
$\boldsymbol{W}$, converges in direction to a max-margin solution that
separates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearly
formalizes attention as an optimal token selection mechanism. Remarkably, our
results are applicable to general data and precisely characterize
$\textit{optimality}$ of tokens in terms of the value embeddings
$\boldsymbol{Xv}$ and problem geometry. We also provide a broader
regularization path analysis that establishes the margin maximizing nature of
attention even for nonlinear prediction heads. When optimizing $\boldsymbol{v}$
and $\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions
under which the regularization paths directionally converge to their respective
hard-margin SVM solutions where $\boldsymbol{v}$ separates the input features
based on their labels. Interestingly, the SVM formulation of $\boldsymbol{p}$
is influenced by the support vector geometry of $\boldsymbol{v}$. Finally, we
verify our theoretical findings via numerical experiments and provide insights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarzanagh_D/0/1/0/all/0/1&quot;&gt;Davoud Ataee Tarzanagh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingcong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuechen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02251">
<title>RanPAC: Random Projections and Pre-trained Models for Continual Learning. (arXiv:2307.02251v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02251</link>
<description rdf:parseType="Literal">&lt;p&gt;Continual learning (CL) aims to incrementally learn different tasks (such as
classification) in a non-stationary data stream without forgetting old ones.
Most CL works focus on tackling catastrophic forgetting under a
learning-from-scratch paradigm. However, with the increasing prominence of
foundation models, pre-trained models equipped with informative representations
have become available for various downstream requirements. Several CL methods
based on pre-trained models have been explored, either utilizing pre-extracted
features directly (which makes bridging distribution gaps challenging) or
incorporating adaptors (which may be subject to forgetting). In this paper, we
propose a concise and effective approach for CL with pre-trained models. Given
that forgetting occurs during parameter updating, we contemplate an alternative
approach that exploits training-free random projectors and class-prototype
accumulation, which thus bypasses the issue. Specifically, we inject a frozen
Random Projection layer with nonlinear activation between the pre-trained
model&apos;s feature representations and output head, which captures interactions
between features with expanded dimensionality, providing enhanced linear
separability for class-prototype-based CL. We also demonstrate the importance
of decorrelating the class-prototypes to reduce the distribution disparity when
using pre-trained representations. These techniques prove to be effective and
circumvent the problem of forgetting for both class- and domain-incremental
continual learning. Compared to previous methods applied to pre-trained
ViT-B/16 models, we reduce final error rates by between 10% and 62% on seven
class-incremental benchmarks, despite not using any rehearsal memory. We
conclude that the full potential of pre-trained models for simple, effective,
and fast CL has not hitherto been fully tapped. Code is at
github.com/RanPAC/RanPAC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDonnell_M/0/1/0/all/0/1&quot;&gt;Mark D. McDonnell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_D/0/1/0/all/0/1&quot;&gt;Dong Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parveneh_A/0/1/0/all/0/1&quot;&gt;Amin Parveneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasnejad_E/0/1/0/all/0/1&quot;&gt;Ehsan Abbasnejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1&quot;&gt;Anton van den Hengel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.04684">
<title>FreeDrag: Feature Dragging for Reliable Point-based Image Editing. (arXiv:2307.04684v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.04684</link>
<description rdf:parseType="Literal">&lt;p&gt;To serve the intricate and varied demands of image editing, precise and
flexible manipulation in image content is indispensable. Recently, Drag-based
editing methods have gained impressive performance. However, these methods
predominantly center on point dragging, resulting in two noteworthy drawbacks,
namely &quot;miss tracking&quot;, where difficulties arise in accurately tracking the
predetermined handle points, and &quot;ambiguous tracking&quot;, where tracked points are
potentially positioned in wrong regions that closely resemble the handle
points. To address the above issues, we propose FreeDrag, a feature dragging
methodology designed to free the burden on point tracking. The FreeDrag
incorporates two key designs, i.e., template feature via adaptive updating and
line search with backtracking, the former improves the stability against
drastic content change by elaborately controls feature updating scale after
each dragging, while the latter alleviates the misguidance from similar points
by actively restricting the search area in a line. These two technologies
together contribute to a more stable semantic dragging with higher efficiency.
Comprehensive experimental results substantiate that our approach significantly
outperforms pre-existing methodologies, offering reliable point-based editing
even in various complex scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_P/0/1/0/all/0/1&quot;&gt;Pengyang Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huaian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yi Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jinjin Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.10284">
<title>ECSIC: Epipolar Cross Attention for Stereo Image Compression. (arXiv:2307.10284v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.10284</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present ECSIC, a novel learned method for stereo image
compression. Our proposed method compresses the left and right images in a
joint manner by exploiting the mutual information between the images of the
stereo image pair using a novel stereo cross attention (SCA) module and two
stereo context modules. The SCA module performs cross-attention restricted to
the corresponding epipolar lines of the two images and processes them in
parallel. The stereo context modules improve the entropy estimation of the
second encoded image by using the first image as a context. We conduct an
extensive ablation study demonstrating the effectiveness of the proposed
modules and a comprehensive quantitative and qualitative comparison with
existing methods. ECSIC achieves state-of-the-art performance in stereo image
compression on the two popular stereo image datasets Cityscapes and InStereo2k
while allowing for fast encoding and decoding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wodlinger_M/0/1/0/all/0/1&quot;&gt;Matthias W&amp;#xf6;dlinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kotera_J/0/1/0/all/0/1&quot;&gt;Jan Kotera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Keglevic_M/0/1/0/all/0/1&quot;&gt;Manuel Keglevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sablatnig_R/0/1/0/all/0/1&quot;&gt;Robert Sablatnig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.13818">
<title>Gradient-Based Spectral Embeddings of Random Dot Product Graphs. (arXiv:2307.13818v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.13818</link>
<description rdf:parseType="Literal">&lt;p&gt;The Random Dot Product Graph (RDPG) is a generative model for relational
data, where nodes are represented via latent vectors in low-dimensional
Euclidean space. RDPGs crucially postulate that edge formation probabilities
are given by the dot product of the corresponding latent positions.
Accordingly, the embedding task of estimating these vectors from an observed
graph is typically posed as a low-rank matrix factorization problem. The
workhorse Adjacency Spectral Embedding (ASE) enjoys solid statistical
properties, but it is formally solving a surrogate problem and can be
computationally intensive. In this paper, we bring to bear recent advances in
non-convex optimization and demonstrate their impact to RDPG inference. We
advocate first-order gradient descent methods to better solve the embedding
problem, and to organically accommodate broader network embedding applications
of practical relevance. Notably, we argue that RDPG embeddings of directed
graphs loose interpretability unless the factor matrices are constrained to
have orthogonal columns. We thus develop a novel feasible optimization method
in the resulting manifold. The effectiveness of the graph representation
learning framework is demonstrated on reproducible experiments with both
synthetic and real network data. Our open-source algorithm implementations are
scalable, and unlike the ASE they are robust to missing edge data and can track
slowly-varying latent positions from streaming graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiori_M/0/1/0/all/0/1&quot;&gt;Marcelo Fiori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marenco_B/0/1/0/all/0/1&quot;&gt;Bernardo Marenco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larroca_F/0/1/0/all/0/1&quot;&gt;Federico Larroca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bermolen_P/0/1/0/all/0/1&quot;&gt;Paola Bermolen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mateos_G/0/1/0/all/0/1&quot;&gt;Gonzalo Mateos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.13917">
<title>BayesDAG: Gradient-Based Posterior Inference for Causal Discovery. (arXiv:2307.13917v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.13917</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian causal discovery aims to infer the posterior distribution over
causal models from observed data, quantifying epistemic uncertainty and
benefiting downstream tasks. However, computational challenges arise due to
joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and
nonlinear functions. Despite recent progress towards efficient posterior
inference over DAGs, existing methods are either limited to variational
inference on node permutation matrices for linear causal models, leading to
compromised inference accuracy, or continuous relaxation of adjacency matrices
constrained by a DAG regularizer, which cannot ensure resulting graphs are
DAGs. In this work, we introduce a scalable Bayesian causal discovery framework
based on a combination of stochastic gradient Markov Chain Monte Carlo
(SG-MCMC) and Variational Inference (VI) that overcomes these limitations. Our
approach directly samples DAGs from the posterior without requiring any DAG
regularization, simultaneously draws function parameter samples and is
applicable to both linear and nonlinear causal models. To enable our approach,
we derive a novel equivalence to the permutation-based DAG learning, which
opens up possibilities of using any relaxed gradient estimator defined over
permutations. To our knowledge, this is the first framework applying
gradient-based MCMC sampling for causal discovery. Empirical evaluation on
synthetic and real-world datasets demonstrate our approach&apos;s effectiveness
compared to state-of-the-art baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Annadani_Y/0/1/0/all/0/1&quot;&gt;Yashas Annadani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawlowski_N/0/1/0/all/0/1&quot;&gt;Nick Pawlowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jennings_J/0/1/0/all/0/1&quot;&gt;Joel Jennings&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1&quot;&gt;Stefan Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_W/0/1/0/all/0/1&quot;&gt;Wenbo Gong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.16680">
<title>On the Trustworthiness Landscape of State-of-the-art Generative Models: A Survey and Outlook. (arXiv:2307.16680v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.16680</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models and large language models have emerged as leading-edge
generative models, revolutionizing various aspects of human life. However, the
practical implementations of these models have also exposed inherent risks,
bringing to the forefront their evil sides and sparking concerns regarding
their trustworthiness. Despite the wealth of literature on this subject, a
comprehensive survey specifically delving into the intersection of large-scale
generative models and their trustworthiness remains largely absent. To bridge
this gap, this paper investigates both the long-standing and emerging threats
associated with these models across four fundamental dimensions: 1) privacy, 2)
security, 3) fairness, and 4) responsibility. Based on the investigation
results, we develop an extensive map outlining the trustworthiness of large
generative models. After that, we provide practical recommendations and
potential research directions for future secure applications equipped with
large generative models, ultimately promoting the trustworthiness of the models
and benefiting the society as a whole.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_M/0/1/0/all/0/1&quot;&gt;Mingyuan Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chengyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Cen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jun Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03321">
<title>AFN: Adaptive Fusion Normalization via Encoder-Decoder Framework. (arXiv:2308.03321v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03321</link>
<description rdf:parseType="Literal">&lt;p&gt;The success of deep learning is inseparable from normalization layers.
Researchers have proposed various normalization functions, and each of them has
both advantages and disadvantages. In response, efforts have been made to
design a unified normalization function that combines all normalization
procedures and mitigates their weaknesses. We also proposed a new normalization
function called Adaptive Fusion Normalization. Through experiments, we
demonstrate AFN outperforms the previous normalization techniques in domain
generalization and image classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zikai Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huanran Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.07051">
<title>Fourier neural operator for learning solutions to macroscopic traffic flow models: Application to the forward and inverse problems. (arXiv:2308.07051v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.07051</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning methods are emerging as popular computational tools for solving
forward and inverse problems in traffic flow. In this paper, we study a neural
operator framework for learning solutions to nonlinear hyperbolic partial
differential equations with applications in macroscopic traffic flow models. In
this framework, an operator is trained to map heterogeneous and sparse traffic
input data to the complete macroscopic traffic state in a supervised learning
setting. We chose a physics-informed Fourier neural operator ($\pi$-FNO) as the
operator, where an additional physics loss based on a discrete conservation law
regularizes the problem during training to improve the shock predictions. We
also propose to use training data generated from random piecewise constant
input data to systematically capture the shock and rarefied solutions. From
experiments using the LWR traffic flow model, we found superior accuracy in
predicting the density dynamics of a ring-road network and urban signalized
road. We also found that the operator can be trained using simple traffic
density dynamics, e.g., consisting of $2-3$ vehicle queues and $1-2$ traffic
signal cycles, and it can predict density dynamics for heterogeneous vehicle
queue distributions and multiple traffic signal cycles $(\geq 2)$ with an
acceptable error. The extrapolation error grew sub-linearly with input
complexity for a proper choice of the model architecture and training data.
Adding a physics regularizer aided in learning long-term traffic density
dynamics, especially for problems with periodic boundary data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thodi_B/0/1/0/all/0/1&quot;&gt;Bilal Thonnam Thodi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ambadipudi_S/0/1/0/all/0/1&quot;&gt;Sai Venkata Ramana Ambadipudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jabari_S/0/1/0/all/0/1&quot;&gt;Saif Eddin Jabari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.09835">
<title>Microscopy Image Segmentation via Point and Shape Regularized Data Synthesis. (arXiv:2308.09835v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.09835</link>
<description rdf:parseType="Literal">&lt;p&gt;Current deep learning-based approaches for the segmentation of microscopy
images heavily rely on large amount of training data with dense annotation,
which is highly costly and laborious in practice. Compared to full annotation
where the complete contour of objects is depicted, point annotations,
specifically object centroids, are much easier to acquire and still provide
crucial information about the objects for subsequent segmentation. In this
paper, we assume access to point annotations only during training and develop a
unified pipeline for microscopy image segmentation using synthetically
generated training data. Our framework includes three stages: (1) it takes
point annotations and samples a pseudo dense segmentation mask constrained with
shape priors; (2) with an image generative model trained in an unpaired manner,
it translates the mask to a realistic microscopy image regularized by object
level consistency; (3) the pseudo masks along with the synthetic images then
constitute a pairwise dataset for training an ad-hoc segmentation model. On the
public MoNuSeg dataset, our synthesis pipeline produces more diverse and
realistic images than baseline models while maintaining high coherence between
input masks and generated images. When using the identical segmentation
backbones, the models trained on our synthetic dataset significantly outperform
those trained with pseudo-labels or baseline-generated images. Moreover, our
framework achieves comparable results to models trained on authentic microscopy
images with dense labels, demonstrating its potential as a reliable and highly
efficient alternative to labor-intensive manual pixel-wise annotations in
microscopy image segmentation. The code is available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shijie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1&quot;&gt;Mengwei Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ach_T/0/1/0/all/0/1&quot;&gt;Thomas Ach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerig_G/0/1/0/all/0/1&quot;&gt;Guido Gerig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03251">
<title>Temporal Inductive Path Neural Network for Temporal Knowledge Graph Reasoning. (arXiv:2309.03251v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2309.03251</link>
<description rdf:parseType="Literal">&lt;p&gt;Temporal Knowledge Graph (TKG) is an extension of traditional Knowledge Graph
(KG) that incorporates the dimension of time. Reasoning on TKGs is a crucial
task that aims to predict future facts based on historical occurrences. The key
challenge lies in uncovering structural dependencies within historical
subgraphs and temporal patterns. Most existing approaches model TKGs relying on
entity modeling, as nodes in the graph play a crucial role in knowledge
representation. However, the real-world scenario often involves an extensive
number of entities, with new entities emerging over time. This makes it
challenging for entity-dependent methods to cope with extensive volumes of
entities, and effectively handling newly emerging entities also becomes a
significant challenge. Therefore, we propose Temporal Inductive Path Neural
Network (TiPNN), which models historical information in an entity-independent
perspective. Specifically, TiPNN adopts a unified graph, namely history
temporal graph, to comprehensively capture and encapsulate information from
history. Subsequently, we utilize the defined query-aware temporal paths to
model historical path information related to queries on history temporal graph
for the reasoning. Extensive experiments illustrate that the proposed model not
only attains significant performance enhancements but also handles inductive
settings, while additionally facilitating the provision of reasoning evidence
through history temporal graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1&quot;&gt;Hao Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Pengyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1&quot;&gt;Meng Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Pengfei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuanchun Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03886">
<title>FIND: A Function Description Benchmark for Evaluating Interpretability Methods. (arXiv:2309.03886v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.03886</link>
<description rdf:parseType="Literal">&lt;p&gt;Labeling neural network submodules with human-legible descriptions is useful
for many downstream tasks: such descriptions can surface failures, guide
interventions, and perhaps even explain important model behaviors. To date,
most mechanistic descriptions of trained networks have involved small models,
narrowly delimited phenomena, and large amounts of human labor. Labeling all
human-interpretable sub-computations in models of increasing size and
complexity will almost certainly require tools that can generate and validate
descriptions automatically. Recently, techniques that use learned models
in-the-loop for labeling have begun to gain traction, but methods for
evaluating their efficacy are limited and ad-hoc. How should we validate and
compare open-ended labeling tools? This paper introduces FIND (Function
INterpretation and Description), a benchmark suite for evaluating the building
blocks of automated interpretability methods. FIND contains functions that
resemble components of trained neural networks, and accompanying descriptions
of the kind we seek to generate. The functions span textual and numeric
domains, and involve a range of real-world complexities. We evaluate methods
that use pretrained language models (LMs) to produce descriptions of function
behavior in natural language and code. Additionally, we introduce a new
interactive method in which an Automated Interpretability Agent (AIA) generates
function descriptions. We find that an AIA, built from an LM with black-box
access to functions, can infer function structure, acting as a scientist by
forming hypotheses, proposing experiments, and updating descriptions in light
of new data. However, AIA descriptions tend to capture global function behavior
and miss local details. These results suggest that FIND will be useful for
evaluating more sophisticated interpretability methods before they are applied
to real-world models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwettmann_S/0/1/0/all/0/1&quot;&gt;Sarah Schwettmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaham_T/0/1/0/all/0/1&quot;&gt;Tamar Rott Shaham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Materzynska_J/0/1/0/all/0/1&quot;&gt;Joanna Materzynska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_N/0/1/0/all/0/1&quot;&gt;Neil Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1&quot;&gt;Jacob Andreas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1&quot;&gt;David Bau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1&quot;&gt;Antonio Torralba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11955">
<title>A Study of Forward-Forward Algorithm for Self-Supervised Learning. (arXiv:2309.11955v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.11955</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised representation learning has seen remarkable progress in the
last few years, with some of the recent methods being able to learn useful
image representations without labels. These methods are trained using
backpropagation, the de facto standard. Recently, Geoffrey Hinton proposed the
forward-forward algorithm as an alternative training method. It utilizes two
forward passes and a separate loss function for each layer to train the network
without backpropagation.
&lt;/p&gt;
&lt;p&gt;In this study, for the first time, we study the performance of
forward-forward vs. backpropagation for self-supervised representation learning
and provide insights into the learned representation spaces. Our benchmark
employs four standard datasets, namely MNIST, F-MNIST, SVHN and CIFAR-10, and
three commonly used self-supervised representation learning techniques, namely
rotation, flip and jigsaw.
&lt;/p&gt;
&lt;p&gt;Our main finding is that while the forward-forward algorithm performs
comparably to backpropagation during (self-)supervised training, the transfer
performance is significantly lagging behind in all the studied settings. This
may be caused by a combination of factors, including having a loss function for
each layer and the way the supervised training is realized in the
forward-forward paradigm. In comparison to backpropagation, the forward-forward
algorithm focuses more on the boundaries and drops part of the information
unnecessary for making decisions which harms the representation learning goal.
Further investigation and research are necessary to stabilize the
forward-forward strategy for self-supervised learning, to work beyond the
datasets and configurations demonstrated by Geoffrey Hinton.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brenig_J/0/1/0/all/0/1&quot;&gt;Jonas Brenig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1&quot;&gt;Radu Timofte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.14348">
<title>Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM. (arXiv:2309.14348v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.14348</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, Large Language Models (LLMs) have made significant advancements and
are now widely used across various domains. Unfortunately, there has been a
rising concern that LLMs can be misused to generate harmful or malicious
content. Though a line of research has focused on aligning LLMs with human
values and preventing them from producing inappropriate content, such
alignments are usually vulnerable and can be bypassed by alignment-breaking
attacks via adversarially optimized or handcrafted jailbreaking prompts. In
this work, we introduce a Robustly Aligned LLM (RA-LLM) to defend against
potential alignment-breaking attacks. RA-LLM can be directly constructed upon
an existing aligned LLM with a robust alignment checking function, without
requiring any expensive retraining or fine-tuning process of the original LLM.
Furthermore, we also provide a theoretical analysis for RA-LLM to verify its
effectiveness in defending against alignment-breaking attacks. Through
real-world experiments on open-source large language models, we demonstrate
that RA-LLM can successfully defend against both state-of-the-art adversarial
prompts and popular handcrafted jailbreaking prompts by reducing their attack
success rates from nearly 100% to around 10% or less.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_B/0/1/0/all/0/1&quot;&gt;Bochuan Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yuanpu Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Lu Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jinghui Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15730">
<title>Temporal graph models fail to capture global temporal dynamics. (arXiv:2309.15730v3 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15730</link>
<description rdf:parseType="Literal">&lt;p&gt;A recently released Temporal Graph Benchmark is analyzed in the context of
Dynamic Link Property Prediction. We outline our observations and propose a
trivial optimization-free baseline of &quot;recently popular nodes&quot; outperforming
other methods on medium and large-size datasets in the Temporal Graph
Benchmark. We propose two measures based on Wasserstein distance which can
quantify the strength of short-term and long-term global dynamics of datasets.
By analyzing our unexpectedly strong baseline, we show how standard negative
sampling evaluation can be unsuitable for datasets with strong temporal
dynamics. We also show how simple negative-sampling can lead to model
degeneration during training, resulting in impossible to rank, fully saturated
predictions of temporal graph networks. We propose improved negative sampling
schemes for both training and evaluation and prove their usefulness. We conduct
a comparison with a model trained non-contrastively without negative sampling.
Our results provide a challenging baseline and indicate that temporal graph
network architectures need deep rethinking for usage in problems with
significant global dynamics, such as social media, cryptocurrency markets or
e-commerce. We open-source the code for baselines, measures and proposed
negative sampling schemes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniluk_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Daniluk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dabrowski_J/0/1/0/all/0/1&quot;&gt;Jacek D&amp;#x105;browski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16620">
<title>Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit. (arXiv:2309.16620v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2309.16620</link>
<description rdf:parseType="Literal">&lt;p&gt;The cost of hyperparameter tuning in deep learning has been rising with model
sizes, prompting practitioners to find new tuning methods using a proxy of
smaller networks. One such proposal uses $\mu$P parameterized networks, where
the optimal hyperparameters for small width networks transfer to networks with
arbitrarily large width. However, in this scheme, hyperparameters do not
transfer across depths. As a remedy, we study residual networks with a residual
branch scale of $1/\sqrt{\text{depth}}$ in combination with the $\mu$P
parameterization. We provide experiments demonstrating that residual
architectures including convolutional ResNets and Vision Transformers trained
with this parameterization exhibit transfer of optimal hyperparameters across
width and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings
are supported and motivated by theory. Using recent developments in the
dynamical mean field theory (DMFT) description of neural network learning
dynamics, we show that this parameterization of ResNets admits a well-defined
feature learning joint infinite-width and infinite-depth limit and show
convergence of finite-size network dynamics towards this limit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1&quot;&gt;Blake Bordelon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Noci_L/0/1/0/all/0/1&quot;&gt;Lorenzo Noci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mufan Bill Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hanin_B/0/1/0/all/0/1&quot;&gt;Boris Hanin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1&quot;&gt;Cengiz Pehlevan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01557">
<title>SmartPlay: A Benchmark for LLMs as Intelligent Agents. (arXiv:2310.01557v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.01557</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent large language models (LLMs) have demonstrated great potential toward
intelligent agents and next-gen automation, but there currently lacks a
systematic benchmark for evaluating LLMs&apos; abilities as agents. We introduce
SmartPlay: both a challenging benchmark and a methodology for evaluating LLMs
as agents. SmartPlay consists of 6 different games, including
Rock-Paper-Scissors, Tower of Hanoi, Minecraft. Each game features a unique
setting, providing up to 20 evaluation settings and infinite environment
variations. Each game in SmartPlay uniquely challenges a subset of 9 important
capabilities of an intelligent LLM agent, including reasoning with object
dependencies, planning ahead, spatial reasoning, learning from history, and
understanding randomness. The distinction between the set of capabilities each
game test allows us to analyze each capability separately. SmartPlay serves not
only as a rigorous testing ground for evaluating the overall performance of LLM
agents but also as a road-map for identifying gaps in current methodologies. We
release our benchmark at github.com/microsoft/SmartPlay
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yue Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1&quot;&gt;Xuan Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitchell_T/0/1/0/all/0/1&quot;&gt;Tom M. Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanzhi Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03234">
<title>Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03234</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates new families of compositional optimization problems,
called $\underline{\bf n}$on-$\underline{\bf s}$mooth $\underline{\bf
w}$eakly-$\underline{\bf c}$onvex $\underline{\bf f}$inite-sum $\underline{\bf
c}$oupled $\underline{\bf c}$ompositional $\underline{\bf o}$ptimization (NSWC
FCCO). There has been a growing interest in FCCO due to its wide-ranging
applications in machine learning and AI, as well as its ability to address the
shortcomings of stochastic algorithms based on empirical risk minimization.
However, current research on FCCO presumes that both the inner and outer
functions are smooth, limiting their potential to tackle a more diverse set of
problems. Our research expands on this area by examining non-smooth
weakly-convex FCCO, where the outer function is weakly convex and
non-decreasing, and the inner function is weakly-convex. We analyze a
single-loop algorithm and establish its complexity for finding an
$\epsilon$-stationary point of the Moreau envelop of the objective function.
Additionally, we also extend the algorithm to solving novel non-smooth
weakly-convex tri-level finite-sum coupled compositional optimization problems,
which feature a nested arrangement of three functions. Lastly, we explore the
applications of our algorithms in deep learning for two-way partial AUC
maximization and multi-instance two-way partial AUC maximization, using
empirical studies to showcase the effectiveness of the proposed algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hu_Q/0/1/0/all/0/1&quot;&gt;Quanqi Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhu_D/0/1/0/all/0/1&quot;&gt;Dixian Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1&quot;&gt;Tianbao Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04935">
<title>Statistical Guarantees for Variational Autoencoders using PAC-Bayesian Theory. (arXiv:2310.04935v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.04935</link>
<description rdf:parseType="Literal">&lt;p&gt;Since their inception, Variational Autoencoders (VAEs) have become central in
machine learning. Despite their widespread use, numerous questions regarding
their theoretical properties remain open. Using PAC-Bayesian theory, this work
develops statistical guarantees for VAEs. First, we derive the first
PAC-Bayesian bound for posterior distributions conditioned on individual
samples from the data-generating distribution. Then, we utilize this result to
develop generalization guarantees for the VAE&apos;s reconstruction loss, as well as
upper bounds on the distance between the input and the regenerated
distributions. More importantly, we provide upper bounds on the Wasserstein
distance between the input distribution and the distribution defined by the
VAE&apos;s generative model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mbacke_S/0/1/0/all/0/1&quot;&gt;Sokhna Diarra Mbacke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clerc_F/0/1/0/all/0/1&quot;&gt;Florence Clerc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Germain_P/0/1/0/all/0/1&quot;&gt;Pascal Germain&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.12262">
<title>Improving SCGAN&apos;s Similarity Constraint and Learning a Better Disentangled Representation. (arXiv:2310.12262v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.12262</link>
<description rdf:parseType="Literal">&lt;p&gt;SCGAN adds a similarity constraint between generated images and conditions as
a regularization term on generative adversarial networks. Similarity constraint
works as a tutor to instruct the generator network to comprehend the difference
of representations based on conditions. We understand how SCGAN works on a
deeper level. This understanding makes us realize that the similarity
constraint functions like the contrastive loss function. We believe that a
model with high understanding and intelligence measures the similarity between
images based on their structure and high level features, just like humans do.
Two major changes we applied to SCGAN in order to make a modified model are
using SSIM to measure similarity between images and applying contrastive loss
principles to the similarity constraint. The modified model performs better
using FID and FactorVAE metrics. The modified model also has better
generalisability compared to other models. Keywords Generative Adversarial
Nets, Unsupervised Learning, Disentangled Representation Learning, Contrastive
Disentanglement, SSIM
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yazdanpanah_I/0/1/0/all/0/1&quot;&gt;Iman Yazdanpanah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eslamian_A/0/1/0/all/0/1&quot;&gt;Ali Eslamian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13032">
<title>Quality-Diversity through AI Feedback. (arXiv:2310.13032v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13032</link>
<description rdf:parseType="Literal">&lt;p&gt;In many text-generation problems, users may prefer not only a single
response, but a diverse range of high-quality outputs from which to choose.
Quality-diversity (QD) search algorithms aim at such outcomes, by continually
improving and diversifying a population of candidates. However, the
applicability of QD to qualitative domains, like creative writing, has been
limited by the difficulty of algorithmically specifying measures of quality and
diversity. Interestingly, recent developments in language models (LMs) have
enabled guiding search through AI feedback, wherein LMs are prompted in natural
language to evaluate qualitative aspects of text. Leveraging this development,
we introduce Quality-Diversity through AI Feedback (QDAIF), wherein an
evolutionary algorithm applies LMs to both generate variation and evaluate the
quality and diversity of candidate text. When assessed on creative writing
domains, QDAIF covers more of a specified search space with high-quality
samples than do non-QD controls. Further, human evaluation of QDAIF-generated
creative texts validates reasonable agreement between AI and human evaluation.
Our results thus highlight the potential of AI feedback to guide open-ended
search for creative and original solutions, providing a recipe that seemingly
generalizes to many domains and modalities. In this way, QDAIF is a step
towards AI systems that can independently search, diversify, evaluate, and
improve, which are among the core skills underlying human society&apos;s capacity
for innovation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bradley_H/0/1/0/all/0/1&quot;&gt;Herbie Bradley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1&quot;&gt;Andrew Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teufel_H/0/1/0/all/0/1&quot;&gt;Hannah Teufel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jenny Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oostermeijer_K/0/1/0/all/0/1&quot;&gt;Koen Oostermeijer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellagente_M/0/1/0/all/0/1&quot;&gt;Marco Bellagente&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1&quot;&gt;Jeff Clune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1&quot;&gt;Kenneth Stanley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schott_G/0/1/0/all/0/1&quot;&gt;Gr&amp;#xe9;gory Schott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1&quot;&gt;Joel Lehman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13139">
<title>Graph Neural Networks with polynomial activations have limited expressivity. (arXiv:2310.13139v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13139</link>
<description rdf:parseType="Literal">&lt;p&gt;The expressivity of Graph Neural Networks (GNNs) can be entirely
characterized by appropriate fragments of the first-order logic. Namely, any
query of the two variable fragment of graded modal logic (GC2) interpreted over
labeled graphs can be expressed using a GNN whose size depends only on the
depth of the query. As pointed out by [Barcelo &amp;amp; Al., 2020, Grohe, 2021], this
description holds for a family of activation functions, leaving the possibility
for a hierarchy of logics expressible by GNNs depending on the chosen
activation function. In this article, we show that such hierarchy indeed exists
by proving that GC2 queries cannot be expressed by GNNs with polynomial
activation functions. This implies a separation between polynomial and popular
non-polynomial activations (such as Rectified Linear Units) and answers an open
question formulated by [Grohe, 2021].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalife_S/0/1/0/all/0/1&quot;&gt;Sammy Khalife&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.19385">
<title>Gradient-free online learning of subgrid-scale dynamics with neural emulators. (arXiv:2310.19385v3 [physics.comp-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2310.19385</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a generic algorithm to train machine learning-based
subgrid parametrizations online, i.e., with a posteriori loss functions, but
for non-differentiable numerical solvers. The proposed approach leverages a
neural emulator to approximate the reduced state-space solver, which is then
used to allow gradient propagation through temporal integration steps. We apply
this methodology on a single layer quasi-geostrophic system with topography,
known to be highly unstable in around 500 temporal iterations with offline
strategies. Using our algorithm, we are able to train a parametrization that
recovers most of the benefits of online strategies without having to compute
the gradient of the original solver. It is demonstrated that training the
neural emulator and parametrization components separately with different loss
quantities is necessary in order to minimize the propagation of approximation
biases. Experiments on emulator architectures with different complexities also
indicates that emulator performance is key in order to learn an accurate
parametrization. This work is a step towards learning parametrization with
online strategies for realistic climate models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Frezat_H/0/1/0/all/0/1&quot;&gt;Hugo Frezat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Fablet_R/0/1/0/all/0/1&quot;&gt;Ronan Fablet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Balarac_G/0/1/0/all/0/1&quot;&gt;Guillaume Balarac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Sommer_J/0/1/0/all/0/1&quot;&gt;Julien Le Sommer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.11841">
<title>High Probability Guarantees for Random Reshuffling. (arXiv:2311.11841v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2311.11841</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the stochastic gradient method with random reshuffling
($\mathsf{RR}$) for tackling smooth nonconvex optimization problems.
$\mathsf{RR}$ finds broad applications in practice, notably in training neural
networks. In this work, we first investigate the concentration property of
$\mathsf{RR}$&apos;s sampling procedure and establish a new high probability sample
complexity guarantee for driving the gradient (without expectation) below
$\varepsilon$, which effectively characterizes the efficiency of a single
$\mathsf{RR}$ execution. Our derived complexity matches the best existing
in-expectation one up to a logarithmic term while imposing no additional
assumptions nor changing $\mathsf{RR}$&apos;s updating rule. Furthermore, by
leveraging our derived high probability descent property and bound on the
stochastic error, we propose a simple and computable stopping criterion for
$\mathsf{RR}$ (denoted as $\mathsf{RR}$-$\mathsf{sc}$). This criterion is
guaranteed to be triggered after a finite number of iterations, and then
$\mathsf{RR}$-$\mathsf{sc}$ returns an iterate with its gradient below
$\varepsilon$ with high probability. Moreover, building on the proposed
stopping criterion, we design a perturbed random reshuffling method
($\mathsf{p}$-$\mathsf{RR}$) that involves an additional randomized
perturbation procedure near stationary points. We derive that
$\mathsf{p}$-$\mathsf{RR}$ provably escapes strict saddle points and
efficiently returns a second-order stationary point with high probability,
without making any sub-Gaussian tail-type assumptions on the stochastic
gradient errors. Finally, we conduct numerical experiments on neural network
training to support our theoretical findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hengxu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiao Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.13443">
<title>Guided Flows for Generative Modeling and Decision Making. (arXiv:2311.13443v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.13443</link>
<description rdf:parseType="Literal">&lt;p&gt;Classifier-free guidance is a key component for enhancing the performance of
conditional generative models across diverse tasks. While it has previously
demonstrated remarkable improvements for the sample quality, it has only been
exclusively employed for diffusion models. In this paper, we integrate
classifier-free guidance into Flow Matching (FM) models, an alternative
simulation-free approach that trains Continuous Normalizing Flows (CNFs) based
on regressing vector fields. We explore the usage of \emph{Guided Flows} for a
variety of downstream applications. We show that Guided Flows significantly
improves the sample quality in conditional image generation and zero-shot
text-to-speech synthesis, boasting state-of-the-art performance. Notably, we
are the first to apply flow models for plan generation in the offline
reinforcement learning setting, showcasing a 10x speedup in computation
compared to diffusion models while maintaining comparable performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1&quot;&gt;Qinqing Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_M/0/1/0/all/0/1&quot;&gt;Matt Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaul_N/0/1/0/all/0/1&quot;&gt;Neta Shaul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipman_Y/0/1/0/all/0/1&quot;&gt;Yaron Lipman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1&quot;&gt;Aditya Grover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Ricky T. Q. Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.13713">
<title>A Somewhat Robust Image Watermark against Diffusion-based Editing Models. (arXiv:2311.13713v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2311.13713</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, diffusion models (DMs) have become the state-of-the-art method for
image synthesis. Editing models based on DMs, known for their high fidelity and
precision, have inadvertently introduced new challenges related to image
copyright infringement and malicious editing. Our work is the first to
formalize and address this issue. After assessing and attempting to enhance
traditional image watermarking techniques, we recognize their limitations in
this emerging context. In response, we develop a novel technique, RIW (Robust
Invisible Watermarking), to embed invisible watermarks leveraging adversarial
example techniques. Our technique ensures a high extraction accuracy of $96\%$
for the invisible watermark after editing, compared to the $0\%$ offered by
conventional methods. We provide access to our code at
https://github.com/BennyTMT/RIW.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1&quot;&gt;Mingtian Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tianhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Somesh Jha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.14387">
<title>Achieving Margin Maximization Exponentially Fast via Progressive Norm Rescaling. (arXiv:2311.14387v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.14387</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we investigate the margin-maximization bias exhibited by
gradient-based algorithms in classifying linearly separable data. We present an
in-depth analysis of the specific properties of the velocity field associated
with (normalized) gradients, focusing on their role in margin maximization.
Inspired by this analysis, we propose a novel algorithm called Progressive
Rescaling Gradient Descent (PRGD) and show that PRGD can maximize the margin at
an {\em exponential rate}. This stands in stark contrast to all existing
algorithms, which maximize the margin at a slow {\em polynomial rate}.
Specifically, we identify mild conditions on data distribution under which
existing algorithms such as gradient descent (GD) and normalized gradient
descent (NGD) {\em provably fail} in maximizing the margin efficiently. To
validate our theoretical findings, we present both synthetic and real-world
experiments. Notably, PRGD also shows promise in enhancing the generalization
performance when applied to linearly non-separable datasets and deep neural
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mingze Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_Z/0/1/0/all/0/1&quot;&gt;Zeping Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lei Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.16214">
<title>DGR: Tackling Drifted and Correlated Noise in Quantum Error Correction via Decoding Graph Re-weighting. (arXiv:2311.16214v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2311.16214</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum hardware suffers from high error rates and noise, which makes
directly running applications on them ineffective. Quantum Error Correction
(QEC) is a critical technique towards fault tolerance which encodes the quantum
information distributively in multiple data qubits and uses syndrome qubits to
check parity. Minimum-Weight-Perfect-Matching (MWPM) is a popular QEC decoder
that takes the syndromes as input and finds the matchings between syndromes
that infer the errors. However, there are two paramount challenges for MWPM
decoders. First, as noise in real quantum systems can drift over time, there is
a potential misalignment with the decoding graph&apos;s initial weights, leading to
a severe performance degradation in the logical error rates. Second, while the
MWPM decoder addresses independent errors, it falls short when encountering
correlated errors typical on real hardware, such as those in the 2Q
depolarizing channel.
&lt;/p&gt;
&lt;p&gt;We propose DGR, an efficient decoding graph edge re-weighting strategy with
no quantum overhead. It leverages the insight that the statistics of matchings
across decoding iterations offer rich information about errors on real quantum
hardware. By counting the occurrences of edges and edge pairs in decoded
matchings, we can statistically estimate the up-to-date probabilities of each
edge and the correlations between them. The reweighting process includes two
vital steps: alignment re-weighting and correlation re-weighting. The former
updates the MWPM weights based on statistics to align with actual noise, and
the latter adjusts the weight considering edge correlations.
&lt;/p&gt;
&lt;p&gt;Extensive evaluations on surface code and honeycomb code under various
settings show that DGR reduces the logical error rate by 3.6x on average-case
noise mismatch with exceeding 5000x improvement under worst-case mismatch.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hanrui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_P/0/1/0/all/0/1&quot;&gt;Pengyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yilian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jiaqi Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Baker_J/0/1/0/all/0/1&quot;&gt;Jonathan Baker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chong_F/0/1/0/all/0/1&quot;&gt;Frederic T. Chong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Song Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.17961">
<title>Skilful Precipitation Nowcasting Using NowcastNet. (arXiv:2311.17961v2 [physics.ao-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2311.17961</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing early warning system for precipitation requires accurate short-term
forecasting system. Climate change has led to an increase in frequency of
extreme weather events, and hence such systems can prevent disasters and loss
of life. Managing such events remain a challenge for both public and private
institutions. Precipitation nowcasting can help relevant institutions to better
prepare for such events as they impact agriculture, transport, public health
and safety, etc. Physics-based numerical weather prediction (NWP) is unable to
perform well for nowcasting because of large computational turn-around time.
Deep-learning based models on the other hand are able to give predictions
within seconds. We use recently proposed NowcastNet, a physics-conditioned deep
generative network, to forecast precipitation for different regions of Europe
using satellite images. Both spatial and temporal transfer learning is done by
forecasting for the unseen regions and year. Model makes realistic predictions
and is able to outperform baseline for such a prediction task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Ajitabh Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.00271">
<title>Towards Clinical Prediction with Transparency: An Explainable AI Approach to Survival Modelling in Residential Aged Care. (arXiv:2312.00271v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.00271</link>
<description rdf:parseType="Literal">&lt;p&gt;Background: Accurate survival time estimates aid end-of-life medical
decision-making. Objectives: Develop an interpretable survival model for
elderly residential aged care residents using advanced machine learning.
Setting: A major Australasian residential aged care provider. Participants:
Residents aged 65+ admitted for long-term care from July 2017 to August 2023.
Sample size: 11,944 residents across 40 facilities. Predictors: Factors include
age, gender, health status, co-morbidities, cognitive function, mood,
nutrition, mobility, smoking, sleep, skin integrity, and continence. Outcome:
Probability of survival post-admission, specifically calibrated for 6-month
survival estimates. Statistical Analysis: Tested CoxPH, EN, RR, Lasso, GB, XGB,
and RF models in 20 experiments with a 90/10 train/test split. Evaluated
accuracy using C-index, Harrell&apos;s C-index, dynamic AUROC, IBS, and calibrated
ROC. Chose XGB for its performance and calibrated it for 1, 3, 6, and 12-month
predictions using Platt scaling. Employed SHAP values to analyze predictor
impacts. Results: GB, XGB, and RF models showed the highest C-Index values
(0.714, 0.712, 0.712). The optimal XGB model demonstrated a 6-month survival
prediction AUROC of 0.746 (95% CI 0.744-0.749). Key mortality predictors
include age, male gender, mobility, health status, pressure ulcer risk, and
appetite. Conclusions: The study successfully applies machine learning to
create a survival model for aged care, aligning with clinical insights on
mortality risk factors and enhancing model interpretability and clinical
utility through explainable AI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Susnjak_T/0/1/0/all/0/1&quot;&gt;Teo Susnjak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffin_E/0/1/0/all/0/1&quot;&gt;Elise Griffin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.00296">
<title>Towards Aligned Canonical Correlation Analysis: Preliminary Formulation and Proof-of-Concept Results. (arXiv:2312.00296v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.00296</link>
<description rdf:parseType="Literal">&lt;p&gt;Canonical Correlation Analysis (CCA) has been widely applied to jointly embed
multiple views of data in a maximally correlated latent space. However, the
alignment between various data perspectives, which is required by traditional
approaches, is unclear in many practical cases. In this work we propose a new
framework Aligned Canonical Correlation Analysis (ACCA), to address this
challenge by iteratively solving the alignment and multi-view embedding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1&quot;&gt;Biqian Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1&quot;&gt;Evangelos E. Papalexakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jia Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.00966">
<title>Spectral Temporal Contrastive Learning. (arXiv:2312.00966v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.00966</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning useful data representations without requiring labels is a
cornerstone of modern deep learning. Self-supervised learning methods,
particularly contrastive learning (CL), have proven successful by leveraging
data augmentations to define positive pairs. This success has prompted a number
of theoretical studies to better understand CL and investigate theoretical
bounds for downstream linear probing tasks. This work is concerned with the
temporal contrastive learning (TCL) setting where the sequential structure of
the data is used instead to define positive pairs, which is more commonly used
in RL and robotics contexts. In this paper, we adapt recent work on Spectral CL
to formulate Spectral Temporal Contrastive Learning (STCL). We discuss a
population loss based on a state graph derived from a time-homogeneous
reversible Markov chain with uniform stationary distribution. The STCL loss
enables to connect the linear probing performance to the spectral properties of
the graph, and can be estimated by considering previously observed data
sequences as an ensemble of MCMC chains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morin_S/0/1/0/all/0/1&quot;&gt;Sacha Morin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nath_S/0/1/0/all/0/1&quot;&gt;Somjit Nath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahou_S/0/1/0/all/0/1&quot;&gt;Samira Ebrahimi Kahou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1&quot;&gt;Guy Wolf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.01523">
<title>SymNoise: Advancing Language Model Fine-tuning with Symmetric Noise. (arXiv:2312.01523v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.01523</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a novel fine-tuning technique for language
models, which involves incorporating symmetric noise into the embedding
process. This method aims to enhance the model&apos;s function by more stringently
regulating its local curvature, demonstrating superior performance over the
current method, NEFTune. When fine-tuning the LLaMA-2-7B model using Alpaca,
standard techniques yield a 29.79% score on AlpacaEval. However, our approach,
SymNoise, increases this score significantly to 69.04%, using symmetric noisy
embeddings. This is a 6.7% improvement over the state-of-the-art method,
NEFTune~(64.69%). Furthermore, when tested on various models and stronger
baseline instruction datasets, such as Evol-Instruct, ShareGPT, OpenPlatypus,
SymNoise consistently outperforms NEFTune. The current literature, including
NEFTune, has underscored the importance of more in-depth research into the
application of noise-based strategies in the fine-tuning of language models.
Our approach, SymNoise, is another significant step towards this direction,
showing notable improvement over the existing state-of-the-art method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadav_A/0/1/0/all/0/1&quot;&gt;Abhay Kumar Yadav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Arjun Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.03044">
<title>REST: Enhancing Group Robustness in DNNs through Reweighted Sparse Training. (arXiv:2312.03044v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.03044</link>
<description rdf:parseType="Literal">&lt;p&gt;The deep neural network (DNN) has been proven effective in various domains.
However, they often struggle to perform well on certain minority groups during
inference, despite showing strong performance on the majority of data groups.
This is because over-parameterized models learned \textit{bias attributes} from
a large number of \textit{bias-aligned} training samples. These bias attributes
are strongly spuriously correlated with the target variable, causing the models
to be biased towards spurious correlations (i.e., \textit{bias-conflicting}).
To tackle this issue, we propose a novel \textbf{re}weighted \textbf{s}parse
\textbf{t}raining framework, dubbed as \textit{\textbf{REST}}, which aims to
enhance the performance of biased data while improving computation and memory
efficiency. Our proposed REST framework has been experimentally validated on
three datasets, demonstrating its effectiveness in exploring unbiased
subnetworks. We found that REST reduces the reliance on spuriously correlated
features, leading to better performance across a wider range of data groups
with fewer training and inference resources. We highlight that the
\textit{REST} framework represents a promising approach for improving the
performance of DNNs on biased data, while simultaneously improving computation
and memory efficiency. By reducing the reliance on spurious correlations, REST
has the potential to enhance the robustness of DNNs and improve their
generalization capabilities. Code is released at
\url{https://github.com/zhao1402072392/REST}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jiaxu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1&quot;&gt;Lu Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shiwei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1&quot;&gt;Meng Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1&quot;&gt;Mykola Pechenizkiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.03126">
<title>Learning Curricula in Open-Ended Worlds. (arXiv:2312.03126v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2312.03126</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning (RL) provides powerful methods for training
optimal sequential decision-making agents. As collecting real-world
interactions can entail additional costs and safety risks, the common paradigm
of sim2real conducts training in a simulator, followed by real-world
deployment. Unfortunately, RL agents easily overfit to the choice of simulated
training environments, and worse still, learning ends when the agent masters
the specific set of simulated environments. In contrast, the real world is
highly open-ended, featuring endlessly evolving environments and challenges,
making such RL approaches unsuitable. Simply randomizing over simulated
environments is insufficient, as it requires making arbitrary distributional
assumptions and can be combinatorially less likely to sample specific
environment instances that are useful for learning. An ideal learning process
should automatically adapt the training environment to maximize the learning
potential of the agent over an open-ended task space that matches or surpasses
the complexity of the real world. This thesis develops a class of methods
called Unsupervised Environment Design (UED), which aim to produce such
open-ended processes. Given an environment design space, UED automatically
generates an infinite sequence or curriculum of training environments at the
frontier of the learning agent&apos;s capabilities. Through extensive empirical
studies and theoretical arguments founded on minimax-regret decision theory and
game theory, the findings in this thesis show that UED autocurricula can
produce RL agents exhibiting significantly improved robustness and
generalization to previously unseen environment instances. Such autocurricula
are promising paths toward open-ended learning systems that achieve more
general intelligence by continually generating and mastering additional
challenges of their own design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1&quot;&gt;Minqi Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04404">
<title>On the Impact of Multi-dimensional Local Differential Privacy on Fairness. (arXiv:2312.04404v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.04404</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated decision systems are increasingly used to make consequential
decisions in people&apos;s lives. Due to the sensitivity of the manipulated data as
well as the resulting decisions, several ethical concerns need to be addressed
for the appropriate use of such technologies, in particular, fairness and
privacy. Unlike previous work, which focused on centralized differential
privacy (DP) or local DP (LDP) for a single sensitive attribute, in this paper,
we examine the impact of LDP in the presence of several sensitive attributes
(i.e., multi-dimensional data) on fairness. Detailed empirical analysis on
synthetic and benchmark datasets revealed very relevant observations. In
particular, (1) multi-dimensional LDP is an efficient approach to reduce
disparity, (2) the multi-dimensional approach of LDP (independent vs. combined)
matters only at low privacy guarantees, and (3) the outcome Y distribution has
an important effect on which group is more sensitive to the obfuscation. Last,
we summarize our findings in the form of recommendations to guide practitioners
in adopting effective privacy-preserving practices while maintaining fairness
and utility in ML applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makhlouf_K/0/1/0/all/0/1&quot;&gt;Karima Makhlouf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arcolezi_H/0/1/0/all/0/1&quot;&gt;Heber H. Arcolezi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhioua_S/0/1/0/all/0/1&quot;&gt;Sami Zhioua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brahim_G/0/1/0/all/0/1&quot;&gt;Ghassen Ben Brahim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1&quot;&gt;Catuscia Palamidessi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04474">
<title>Chain of Code: Reasoning with a Language Model-Augmented Code Emulator. (arXiv:2312.04474v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.04474</link>
<description rdf:parseType="Literal">&lt;p&gt;Code provides a general syntactic structure to build complex programs and
perform precise computations when paired with a code interpreter - we
hypothesize that language models (LMs) can leverage code-writing to improve
Chain of Thought reasoning not only for logic and arithmetic tasks, but also
for semantic ones (and in particular, those that are a mix of both). For
example, consider prompting an LM to write code that counts the number of times
it detects sarcasm in an essay: the LM may struggle to write an implementation
for &quot;detect_sarcasm(string)&quot; that can be executed by the interpreter (handling
the edge cases would be insurmountable). However, LMs may still produce a valid
solution if they not only write code, but also selectively &quot;emulate&quot; the
interpreter by generating the expected output of &quot;detect_sarcasm(string)&quot; and
other lines of code that cannot be executed. In this work, we propose Chain of
Code (CoC), a simple yet surprisingly effective extension that improves LM
code-driven reasoning. The key idea is to encourage LMs to format semantic
sub-tasks in a program as flexible pseudocode that the interpreter can
explicitly catch undefined behaviors and hand off to simulate with an LM (as an
&quot;LMulator&quot;). Experiments demonstrate that Chain of Code outperforms Chain of
Thought and other baselines across a variety of benchmarks; on BIG-Bench Hard,
Chain of Code achieves 84%, a gain of 12% over Chain of Thought. CoC scales
well with large and small models alike, and broadens the scope of reasoning
questions that LMs can correctly answer by &quot;thinking in code&quot;. Project webpage:
https://chain-of-code.github.io.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chengshu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jacky Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1&quot;&gt;Andy Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinyun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1&quot;&gt;Karol Hausman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1&quot;&gt;Dorsa Sadigh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1&quot;&gt;Li Fei-Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1&quot;&gt;Fei Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ichter_B/0/1/0/all/0/1&quot;&gt;Brian Ichter&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>