<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-11-05T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01463" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01468" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01469" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01473" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01475" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01476" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01478" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01479" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01483" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01489" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01491" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01500" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01522" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01526" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01537" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01544" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01568" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01570" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01573" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01574" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01575" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01588" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01589" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01591" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01599" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01605" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01617" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01623" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01642" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01644" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01646" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01647" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01650" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01655" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01660" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01683" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01686" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01695" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01698" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01722" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01727" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01729" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01742" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01743" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01749" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01753" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01759" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01762" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01771" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01777" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01796" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01797" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01806" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01829" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01840" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01854" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01864" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01875" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01885" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01888" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01900" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01902" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01906" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01918" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01927" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01933" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01953" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01960" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01967" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01968" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01990" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01994" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01996" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02000" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02002" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02013" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02017" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02019" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02041" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02058" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02061" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02076" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2007.04750" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.08627" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.12915" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.08452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.03626" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.08369" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.09698" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.01466" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.03028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.06177" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.17514" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.07596" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.08761" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.07738" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.05062" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.12247" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.07317" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.14082" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.03374" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.10834" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.11143" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.03843" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.04370" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.03515" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.03609" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.11092" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13484" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14637" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.16671" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.17560" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18381" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.00265" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.01264" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.02231" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.02899" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.09136" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.10763" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.16578" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.01050" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.01827" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02108" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02345" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.03864" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.05374" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08873" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08964" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.10683" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.11957" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.14283" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.00180" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01923" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02618" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.15457" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.16150" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.08473" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.09599" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.17130" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.05812" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.07223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.07736" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.08571" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.08854" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.12560" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.12612" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13139" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.14201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.16789" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.16804" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.16945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.17584" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.17785" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.18144" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.18860" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.19589" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.20258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.20380" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.20550" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00060" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00687" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01282" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04532" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.17688" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2311.01463">
<title>Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI. (arXiv:2311.01463v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01463</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmad_M/0/1/0/all/0/1&quot;&gt;Muhammad Aurangzeb Ahmad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yaramis_I/0/1/0/all/0/1&quot;&gt;Ilker Yaramis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_T/0/1/0/all/0/1&quot;&gt;Taposh Dutta Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01468">
<title>Remember what you did so you know what to do next. (arXiv:2311.01468v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01468</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore using a moderately sized large language model (GPT-J 6B
parameters) to create a plan for a simulated robot to achieve 30 classes of
goals in ScienceWorld, a text game simulator for elementary science
experiments. Previously published empirical work claimed that large language
models (LLMs) are a poor fit (Wang et al., 2022) compared to reinforcement
learning. Using the Markov assumption (a single previous step), the LLM
outperforms the reinforcement learning-based approach by a factor of 1.4. When
we fill the LLM&apos;s input buffer with as many prior steps as possible,
improvement rises to 3.5x. Even when training on only 6.5% of the training
data, we observe a 2.2x improvement over the reinforcement-learning-based
approach. Our experiments show that performance varies widely across the 30
classes of actions, indicating that averaging over tasks can hide significant
performance issues. In work contemporaneous with ours, Lin et al. (2023)
demonstrated a two-part approach (SwiftSage) that uses a small LLM (T5-large)
complemented by OpenAI&apos;s massive LLMs to achieve outstanding results in
ScienceWorld. Our 6-B parameter, single-stage GPT-J matches the performance of
SwiftSage&apos;s two-stage architecture when it incorporates GPT-3.5 turbo which has
29-times more parameters than GPT-J.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciosici_M/0/1/0/all/0/1&quot;&gt;Manuel R. Ciosici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hedges_A/0/1/0/all/0/1&quot;&gt;Alex Hedges&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kankanampati_Y/0/1/0/all/0/1&quot;&gt;Yash Kankanampati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1&quot;&gt;Justin Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freedman_M/0/1/0/all/0/1&quot;&gt;Marjorie Freedman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weischedel_R/0/1/0/all/0/1&quot;&gt;Ralph Weischedel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01469">
<title>Leveraging Language Models to Detect Greenwashing. (arXiv:2311.01469v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01469</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, climate change repercussions have increasingly captured
public interest. Consequently, corporations are emphasizing their environmental
efforts in sustainability reports to bolster their public image. Yet, the
absence of stringent regulations in review of such reports allows potential
greenwashing. In this study, we introduce a novel methodology to train a
language model on generated labels for greenwashing risk. Our primary
contributions encompass: developing a mathematical formulation to quantify
greenwashing risk, a fine-tuned ClimateBERT model for this problem, and a
comparative analysis of results. On a test set comprising of sustainability
reports, our best model achieved an average accuracy score of 86.34% and F1
score of 0.67, demonstrating that our methods show a promising direction of
exploration for this task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinella_A/0/1/0/all/0/1&quot;&gt;Avalon Vinella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Capetz_M/0/1/0/all/0/1&quot;&gt;Margaret Capetz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pattichis_R/0/1/0/all/0/1&quot;&gt;Rebecca Pattichis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chance_C/0/1/0/all/0/1&quot;&gt;Christina Chance&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1&quot;&gt;Reshmi Ghosh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01473">
<title>Adversarial Examples in the Physical World: A Survey. (arXiv:2311.01473v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01473</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have demonstrated high vulnerability to
adversarial examples. Besides the attacks in the digital world, the practical
implications of adversarial examples in the physical world present significant
challenges and safety concerns. However, current research on physical
adversarial examples (PAEs) lacks a comprehensive understanding of their unique
characteristics, leading to limited significance and understanding. In this
paper, we address this gap by thoroughly examining the characteristics of PAEs
within a practical workflow encompassing training, manufacturing, and
re-sampling processes. By analyzing the links between physical adversarial
attacks, we identify manufacturing and re-sampling as the primary sources of
distinct attributes and particularities in PAEs. Leveraging this knowledge, we
develop a comprehensive analysis and classification framework for PAEs based on
their specific characteristics, covering over 100 studies on physical-world
adversarial examples. Furthermore, we investigate defense strategies against
PAEs and identify open challenges and opportunities for future research. We aim
to provide a fresh, thorough, and systematic understanding of PAEs, thereby
promoting the development of robust adversarial learning and its application in
open-world scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiakai Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Donghua Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1&quot;&gt;Siyang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1&quot;&gt;Tingsong Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1&quot;&gt;Wen Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1&quot;&gt;Aishan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xianglong Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01475">
<title>Patch-Based Deep Unsupervised Image Segmentation using Graph Cuts. (arXiv:2311.01475v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01475</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised image segmentation aims at grouping different semantic patterns
in an image without the use of human annotation. Similarly, image clustering
searches for groupings of images based on their semantic content without
supervision. Classically, both problems have captivated researchers as they
drew from sound mathematical concepts to produce concrete applications. With
the emergence of deep learning, the scientific community turned its attention
to complex neural network-based solvers that achieved impressive results in
those domains but rarely leveraged the advances made by classical methods. In
this work, we propose a patch-based unsupervised image segmentation strategy
that bridges advances in unsupervised feature extraction from deep clustering
methods with the algorithmic help of classical graph-based methods. We show
that a simple convolutional neural network, trained to classify image patches
and iteratively regularized using graph cuts, naturally leads to a
state-of-the-art fully-convolutional unsupervised pixel-level segmenter.
Furthermore, we demonstrate that this is the ideal setting for leveraging the
patch-level pairwise features generated by vision transformer models. Our
results on real image data demonstrate the effectiveness of our proposed
methodology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wasserman_I/0/1/0/all/0/1&quot;&gt;Isaac Wasserman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neto_J/0/1/0/all/0/1&quot;&gt;Jeova Farias Sales Rocha Neto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01476">
<title>Applications of the Theory of Aggregated Markov Processes in Stochastic Learning Theory. (arXiv:2311.01476v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01476</link>
<description rdf:parseType="Literal">&lt;p&gt;A stochastic process that arises by composing a function with a Markov
process is called an aggregated Markov process (AMP). The purpose of composing
a Markov process with a function can be a reduction of dimensions, e.g., a
projection onto certain coordinates. The theory around AMP has been extensively
studied e.g. by Dynkin, Cameron, Rogers and Pitman, and Kelly, all of whom
provided sufficient conditions for an AMP to remain Markov. In another
direction, Larget provided a canonical representation for AMP, which can be
used to verify the equivalence of two AMPs. The purpose of this paper is to
describe how the theory of AMP can be applied to stochastic learning theory as
they learn a particular task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_F/0/1/0/all/0/1&quot;&gt;Fangyuan Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01478">
<title>Adversary ML Resilience in Autonomous Driving Through Human Centered Perception Mechanisms. (arXiv:2311.01478v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01478</link>
<description rdf:parseType="Literal">&lt;p&gt;Physical adversarial attacks on road signs are continuously exploiting
vulnerabilities in modern day autonomous vehicles (AVs) and impeding their
ability to correctly classify what type of road sign they encounter. Current
models cannot generalize input data well, resulting in overfitting or
underfitting. In overfitting, the model memorizes the input data but cannot
generalize to new scenarios. In underfitting, the model does not learn enough
of the input data to accurately classify these road signs. This paper explores
the resilience of autonomous driving systems against three main physical
adversarial attacks (tape, graffiti, illumination), specifically targeting
object classifiers. Several machine learning models were developed and
evaluated on two distinct datasets: road signs (stop signs, speed limit signs,
traffic lights, and pedestrian crosswalk signs) and geometric shapes (octagons,
circles, squares, and triangles). The study compared algorithm performance
under different conditions, including clean and adversarial training and
testing on these datasets. To build robustness against attacks, defense
techniques like adversarial training and transfer learning were implemented.
Results demonstrated transfer learning models played a crucial role in
performance by allowing knowledge gained from shape training to improve
generalizability of road sign classification, despite the datasets being
completely different. The paper suggests future research directions, including
human-in-the-loop validation, security analysis, real-world testing, and
explainable AI for transparency. This study aims to contribute to improving
security and robustness of object classifiers in autonomous vehicles and
mitigating adversarial example impacts on driving systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1&quot;&gt;Aakriti Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01479">
<title>Detecting Out-of-Distribution Through the Lens of Neural Collapse. (arXiv:2311.01479v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01479</link>
<description rdf:parseType="Literal">&lt;p&gt;Out-of-distribution (OOD) detection is essential for the safe deployment of
AI. Particularly, OOD detectors should generalize effectively across diverse
scenarios. To improve upon the generalizability of existing OOD detectors, we
introduce a highly versatile OOD detector, called Neural Collapse inspired OOD
detector (NC-OOD). We extend the prevalent observation that in-distribution
(ID) features tend to form clusters, whereas OOD features are far away.
Particularly, based on the recent observation, Neural Collapse, we further
demonstrate that ID features tend to cluster in proximity to weight vectors.
From our extended observation, we propose to detect OOD based on feature
proximity to weight vectors. To further rule out OOD samples, we leverage the
observation that OOD features tend to reside closer to the origin than ID
features. Extensive experiments show that our approach enhances the
generalizability of existing work and can consistently achieve state-of-the-art
OOD detection performance across a wide range of OOD Benchmarks over different
classification tasks, training losses, and model architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Litian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1&quot;&gt;Yao Qin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01483">
<title>FedSN: A General Federated Learning Framework over LEO Satellite Networks. (arXiv:2311.01483v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01483</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, a large number of Low Earth Orbit (LEO) satellites have been
launched and deployed successfully in space by commercial companies, such as
SpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve
not only for communication but also for various machine learning applications,
such as space modulation recognition, remote sensing image classification, etc.
However, the ground station (GS) may be incapable of downloading such a large
volume of raw sensing data for centralized model training due to the limited
contact time with LEO satellites (e.g. 5 minutes). Therefore, federated
learning (FL) has emerged as the promising solution to address this problem via
on-device training. Unfortunately, to enable FL on LEO satellites, we still
face three critical challenges that are i) heterogeneous computing and memory
capabilities, ii) limited uplink rate, and iii) model staleness. To this end,
we propose FedSN as a general FL framework to tackle the above challenges, and
fully explore data diversity on LEO satellites. Specifically, we first present
a novel sub-structure scheme to enable heterogeneous local model training
considering different computing, memory, and communication constraints on LEO
satellites. Additionally, we propose a pseudo-synchronous model aggregation
strategy to dynamically schedule model aggregation for compensating model
staleness. To further demonstrate the effectiveness of the FedSN, we evaluate
it using space modulation recognition and remote sensing image classification
tasks by leveraging the data from real-world satellite networks. Extensive
experimental results demonstrate that FedSN framework achieves higher accuracy,
lower computing, and communication overhead than the state-of-the-art
benchmarks and the effectiveness of each components in FedSN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zheng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhe Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1&quot;&gt;Zihan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xianhao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yue Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01489">
<title>Invariant Causal Imitation Learning for Generalizable Policies. (arXiv:2311.01489v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01489</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider learning an imitation policy on the basis of demonstrated behavior
from multiple environments, with an eye towards deployment in an unseen
environment. Since the observable features from each setting may be different,
directly learning individual policies as mappings from features to actions is
prone to spurious correlations -- and may not generalize well. However, the
expert&apos;s policy is often a function of a shared latent structure underlying
those observable features that is invariant across settings. By leveraging data
from multiple environments, we propose Invariant Causal Imitation Learning
(ICIL), a novel technique in which we learn a feature representation that is
invariant across domains, on the basis of which we learn an imitation policy
that matches expert behavior. To cope with transition dynamics mismatch, ICIL
learns a shared representation of causal features (for all training
environments), that is disentangled from the specific representations of noise
variables (for each of those environments). Moreover, to ensure that the
learned policy matches the observation distribution of the expert&apos;s policy,
ICIL estimates the energy of the expert&apos;s observations and uses a
regularization term that minimizes the imitator policy&apos;s next state energy.
Experimentally, we compare our methods against several benchmarks in control
and healthcare tasks and show its effectiveness in learning imitation policies
capable of generalizing to unseen environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bica_I/0/1/0/all/0/1&quot;&gt;Ioana Bica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jarrett_D/0/1/0/all/0/1&quot;&gt;Daniel Jarrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela van der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01491">
<title>Investigating the Behavior of Diffusion Models for Accelerating Electronic Structure Calculations. (arXiv:2311.01491v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2311.01491</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an investigation into diffusion models for molecular generation,
with the aim of better understanding how their predictions compare to the
results of physics-based calculations. The investigation into these models is
driven by their potential to significantly accelerate electronic structure
calculations using machine learning, without requiring expensive
first-principles datasets for training interatomic potentials. We find that the
inference process of a popular diffusion model for de novo molecular generation
is divided into an exploration phase, where the model chooses the atomic
species, and a relaxation phase, where it adjusts the atomic coordinates to
find a low-energy geometry. As training proceeds, we show that the model
initially learns about the first-order structure of the potential energy
surface, and then later learns about higher-order structure. We also find that
the relaxation phase of the diffusion model can be re-purposed to sample the
Boltzmann distribution over conformations and to carry out structure
relaxations. For structure relaxations, the model finds geometries with ~10x
lower energy than those produced by a classical force field for small organic
molecules. Initializing a density functional theory (DFT) relaxation at the
diffusion-produced structures yields a &amp;gt;2x speedup to the DFT relaxation when
compared to initializing at structures relaxed with a classical force field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rothchild_D/0/1/0/all/0/1&quot;&gt;Daniel Rothchild&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rosen_A/0/1/0/all/0/1&quot;&gt;Andrew S. Rosen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Taw_E/0/1/0/all/0/1&quot;&gt;Eric Taw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Robinson_C/0/1/0/all/0/1&quot;&gt;Connie Robinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Joseph E. Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Krishnapriyan_A/0/1/0/all/0/1&quot;&gt;Aditi S. Krishnapriyan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01500">
<title>E(2) Equivariant Neural Networks for Robust Galaxy Morphology Classification. (arXiv:2311.01500v1 [astro-ph.GA])</title>
<link>http://arxiv.org/abs/2311.01500</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the use of group convolutional neural network architectures
(GCNNs) equivariant to the 2D Euclidean group, $E(2)$, for the task of galaxy
morphology classification by utilizing symmetries of the data present in galaxy
images as an inductive bias in the architecture. We conduct robustness studies
by introducing artificial perturbations via Poisson noise insertion and
one-pixel adversarial attacks to simulate the effects of limited observational
capabilities. We train, validate, and test GCNNs equivariant to discrete
subgroups of $E(2)$ - the cyclic and dihedral groups of order $N$ - on the
Galaxy10 DECals dataset and find that GCNNs achieve higher classification
accuracy and are consistently more robust than their non-equivariant
counterparts, with an architecture equivariant to the group $D_{16}$ achieving
a $95.52 \pm 0.18\%$ test-set accuracy. We also find that the model loses
$&amp;lt;6\%$ accuracy on a $50\%$-noise dataset and all GCNNs are less susceptible to
one-pixel perturbations than an identically constructed CNN. Our code is
publicly available at https://github.com/snehjp2/GCNNMorphology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Pandya_S/0/1/0/all/0/1&quot;&gt;Sneh Pandya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Patel_P/0/1/0/all/0/1&quot;&gt;Purvik Patel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+O_F/0/1/0/all/0/1&quot;&gt;Franc O&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Blazek_J/0/1/0/all/0/1&quot;&gt;Jonathan Blazek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01522">
<title>An Efficient Detection and Control System for Underwater Docking using Machine Learning and Realistic Simulation: A Comprehensive Approach. (arXiv:2311.01522v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.01522</link>
<description rdf:parseType="Literal">&lt;p&gt;Underwater docking is critical to enable the persistent operation of
Autonomous Underwater Vehicles (AUVs). For this, the AUV must be capable of
detecting and localizing the docking station, which is complex due to the
highly dynamic undersea environment. Image-based solutions offer a high
acquisition rate and versatile alternative to adapt to this environment;
however, the underwater environment presents challenges such as low visibility,
high turbidity, and distortion. In addition to this, field experiments to
validate underwater docking capabilities can be costly and dangerous due to the
specialized equipment and safety considerations required to conduct the
experiments. This work compares different deep-learning architectures to
perform underwater docking detection and classification. The architecture with
the best performance is then compressed using knowledge distillation under the
teacher-student paradigm to reduce the network&apos;s memory footprint, allowing
real-time implementation. To reduce the simulation-to-reality gap, a Generative
Adversarial Network (GAN) is used to do image-to-image translation, converting
the Gazebo simulation image into a realistic underwater-looking image. The
obtained image is then processed using an underwater image formation model to
simulate image attenuation over distance under different water types. The
proposed method is finally evaluated according to the AUV docking success rate
and compared with classical vision methods. The simulation results show an
improvement of 20% in the high turbidity scenarios regardless of the underwater
currents. Furthermore, we show the performance of the proposed approach by
showing experimental results on the off-the-shelf AUV Iver3.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chavez_Galaviz_J/0/1/0/all/0/1&quot;&gt;Jalil Chavez-Galaviz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianwen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergman_M/0/1/0/all/0/1&quot;&gt;Matthew Bergman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mengdibayev_M/0/1/0/all/0/1&quot;&gt;Miras Mengdibayev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01526">
<title>ATGNN: Audio Tagging Graph Neural Network. (arXiv:2311.01526v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2311.01526</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models such as CNNs and Transformers have achieved impressive
performance for end-to-end audio tagging. Recent works have shown that despite
stacking multiple layers, the receptive field of CNNs remains severely limited.
Transformers on the other hand are able to map global context through
self-attention, but treat the spectrogram as a sequence of patches which is not
flexible enough to capture irregular audio objects. In this work, we treat the
spectrogram in a more flexible way by considering it as graph structure and
process it with a novel graph neural architecture called ATGNN. ATGNN not only
combines the capability of CNNs with the global information sharing ability of
Graph Neural Networks, but also maps semantic relationships between learnable
class embeddings and corresponding spectrogram regions. We evaluate ATGNN on
two audio tagging tasks, where it achieves 0.585 mAP on the FSD50K dataset and
0.335 mAP on the AudioSet-balanced dataset, achieving comparable results to
Transformer based models with significantly lower number of learnable
parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Shubhr Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinmetz_C/0/1/0/all/0/1&quot;&gt;Christian J. Steinmetz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benetos_E/0/1/0/all/0/1&quot;&gt;Emmanouil Benetos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_H/0/1/0/all/0/1&quot;&gt;Huy Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stowell_D/0/1/0/all/0/1&quot;&gt;Dan Stowell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01537">
<title>Variable Selection in Maximum Mean Discrepancy for Interpretable Distribution Comparison. (arXiv:2311.01537v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01537</link>
<description rdf:parseType="Literal">&lt;p&gt;Two-sample testing decides whether two datasets are generated from the same
distribution. This paper studies variable selection for two-sample testing, the
task being to identify the variables (or dimensions) responsible for the
discrepancies between the two distributions. This task is relevant to many
problems of pattern analysis and machine learning, such as dataset shift
adaptation, causal inference and model validation. Our approach is based on a
two-sample test based on the Maximum Mean Discrepancy (MMD). We optimise the
Automatic Relevance Detection (ARD) weights defined for individual variables to
maximise the power of the MMD-based test. For this optimisation, we introduce
sparse regularisation and propose two methods for dealing with the issue of
selecting an appropriate regularisation parameter. One method determines the
regularisation parameter in a data-driven way, and the other aggregates the
results of different regularisation parameters. We confirm the validity of the
proposed methods by systematic comparisons with baseline methods, and
demonstrate their usefulness in exploratory analysis of high-dimensional
traffic simulation data. Preliminary theoretical analyses are also provided,
including a rigorous definition of variable selection for two-sample testing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mitsuzawa_K/0/1/0/all/0/1&quot;&gt;Kensuke Mitsuzawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kanagawa_M/0/1/0/all/0/1&quot;&gt;Motonobu Kanagawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bortoli_S/0/1/0/all/0/1&quot;&gt;Stefano Bortoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grossi_M/0/1/0/all/0/1&quot;&gt;Margherita Grossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papotti_P/0/1/0/all/0/1&quot;&gt;Paolo Papotti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01544">
<title>Divergent Token Metrics: Measuring degradation to prune away LLM components -- and optimize quantization. (arXiv:2311.01544v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01544</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have reshaped natural language processing with
their impressive capabilities. Their ever-increasing size, however, raised
concerns about their effective deployment and the need for LLM compressions.
This study introduces the Divergent Token metrics (DTMs), a novel approach for
assessing compressed LLMs, addressing the limitations of traditional measures
like perplexity that fail to accurately reflect text generation quality. DTMs
focus on token divergence, providing deeper insights into the subtleties of
model compression. Our results indicate that significant levels of precision
and sparsity can be achieved without compromising text generation quality.
Moreover, DTMs offers a more precise evaluation of each component&apos;s impact
individually. Utilizing the First Divergent Token metric (FDTM) in model
sparsification reveals that nearly 20% of all components can be pruned over
90%. In terms of quantization, the FDTM suggests that over 80% of parameters
can be straightforwardly transformed to int8 without special outlier
management.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deiseroth_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn Deiseroth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meuer_M/0/1/0/all/0/1&quot;&gt;Max Meuer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gritsch_N/0/1/0/all/0/1&quot;&gt;Nikolas Gritsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eichenberg_C/0/1/0/all/0/1&quot;&gt;Constantin Eichenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schramowski_P/0/1/0/all/0/1&quot;&gt;Patrick Schramowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assenmacher_M/0/1/0/all/0/1&quot;&gt;Matthias A&amp;#xdf;enmacher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1&quot;&gt;Kristian Kersting&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01568">
<title>Anytime-Competitive Reinforcement Learning with Policy Prior. (arXiv:2311.01568v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01568</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of Anytime-Competitive Markov Decision Process
(A-CMDP). Existing works on Constrained Markov Decision Processes (CMDPs) aim
to optimize the expected reward while constraining the expected cost over
random dynamics, but the cost in a specific episode can still be
unsatisfactorily high. In contrast, the goal of A-CMDP is to optimize the
expected reward while guaranteeing a bounded cost in each round of any episode
against a policy prior. We propose a new algorithm, called Anytime-Competitive
Reinforcement Learning (ACRL), which provably guarantees the anytime cost
constraints. The regret analysis shows the policy asymptotically matches the
optimal reward achievable under the anytime competitive constraints.
Experiments on the application of carbon-intelligent computing verify the
reward performance and cost constraint guarantee of ACRL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianyi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Pengfei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tongxin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1&quot;&gt;Adam Wierman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1&quot;&gt;Shaolei Ren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01570">
<title>Sequential Subset Matching for Dataset Distillation. (arXiv:2311.01570v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01570</link>
<description rdf:parseType="Literal">&lt;p&gt;Dataset distillation is a newly emerging task that synthesizes a small-size
dataset used in training deep neural networks (DNNs) for reducing data storage
and model training costs. The synthetic datasets are expected to capture the
essence of the knowledge contained in real-world datasets such that the former
yields a similar performance as the latter. Recent advancements in distillation
methods have produced notable improvements in generating synthetic datasets.
However, current state-of-the-art methods treat the entire synthetic dataset as
a unified entity and optimize each synthetic instance equally. This static
optimization approach may lead to performance degradation in dataset
distillation. Specifically, we argue that static optimization can give rise to
a coupling issue within the synthetic data, particularly when a larger amount
of synthetic data is being optimized. This coupling issue, in turn, leads to
the failure of the distilled dataset to extract the high-level features learned
by the deep neural network (DNN) in the latter epochs.
&lt;/p&gt;
&lt;p&gt;In this study, we propose a new dataset distillation strategy called
Sequential Subset Matching (SeqMatch), which tackles this problem by adaptively
optimizing the synthetic data to encourage sequential acquisition of knowledge
during dataset distillation. Our analysis indicates that SeqMatch effectively
addresses the coupling issue by sequentially generating the synthetic
instances, thereby enhancing its performance significantly. Our proposed
SeqMatch outperforms state-of-the-art methods in various datasets, including
SVNH, CIFAR-10, CIFAR-100, and Tiny ImageNet. Our code is available at
https://github.com/shqii1j/seqmatch.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1&quot;&gt;Jiawei Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1&quot;&gt;Qin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Joey Tianyi Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01573">
<title>Improving Fairness using Vision-Language Driven Image Augmentation. (arXiv:2311.01573v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01573</link>
<description rdf:parseType="Literal">&lt;p&gt;Fairness is crucial when training a deep-learning discriminative model,
especially in the facial domain. Models tend to correlate specific
characteristics (such as age and skin color) with unrelated attributes
(downstream tasks), resulting in biases which do not correspond to reality. It
is common knowledge that these correlations are present in the data and are
then transferred to the models during training. This paper proposes a method to
mitigate these correlations to improve fairness. To do so, we learn
interpretable and meaningful paths lying in the semantic space of a pre-trained
diffusion model (DiffAE) -- such paths being supervised by contrastive text
dipoles. That is, we learn to edit protected characteristics (age and skin
color). These paths are then applied to augment images to improve the fairness
of a given dataset. We test the proposed method on CelebA-HQ and UTKFace on
several downstream tasks with age and skin color as protected characteristics.
As a proxy for fairness, we compute the difference in accuracy with respect to
the protected characteristics. Quantitative results show how the augmented
images help the model improve the overall accuracy, the aforementioned metric,
and the disparity of equal opportunity. Code is available at:
https://github.com/Moreno98/Vision-Language-Bias-Control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DInca_M/0/1/0/all/0/1&quot;&gt;Moreno D&amp;#x27;Inc&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzelepis_C/0/1/0/all/0/1&quot;&gt;Christos Tzelepis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patras_I/0/1/0/all/0/1&quot;&gt;Ioannis Patras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1&quot;&gt;Nicu Sebe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01574">
<title>Improving Lesion Segmentation in FDG-18 Whole-Body PET/CT scans using Multilabel approach: AutoPET II challenge. (arXiv:2311.01574v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.01574</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic segmentation of lesions in FDG-18 Whole Body (WB) PET/CT scans
using deep learning models is instrumental for determining treatment response,
optimizing dosimetry, and advancing theranostic applications in oncology.
However, the presence of organs with elevated radiotracer uptake, such as the
liver, spleen, brain, and bladder, often leads to challenges, as these regions
are often misidentified as lesions by deep learning models. To address this
issue, we propose a novel approach of segmenting both organs and lesions,
aiming to enhance the performance of automatic lesion segmentation methods. In
this study, we assessed the effectiveness of our proposed method using the
AutoPET II challenge dataset, which comprises 1014 subjects. We evaluated the
impact of inclusion of additional labels and data in the segmentation
performance of the model. In addition to the expert-annotated lesion labels, we
introduced eight additional labels for organs, including the liver, kidneys,
urinary bladder, spleen, lung, brain, heart, and stomach. These labels were
integrated into the dataset, and a 3D UNET model was trained within the nnUNet
framework. Our results demonstrate that our method achieved the top ranking in
the held-out test dataset, underscoring the potential of this approach to
significantly improve lesion segmentation accuracy in FDG-18 Whole-Body PET/CT
scans, ultimately benefiting cancer patients and advancing clinical practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Murugesan_G/0/1/0/all/0/1&quot;&gt;Gowtham Krishnan Murugesan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+McCrumb_D/0/1/0/all/0/1&quot;&gt;Diana McCrumb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Brunner_E/0/1/0/all/0/1&quot;&gt;Eric Brunner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kumar_J/0/1/0/all/0/1&quot;&gt;Jithendra Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Soni_R/0/1/0/all/0/1&quot;&gt;Rahul Soni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Grigorash_V/0/1/0/all/0/1&quot;&gt;Vasily Grigorash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Moore_S/0/1/0/all/0/1&quot;&gt;Stephen Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Oss_J/0/1/0/all/0/1&quot;&gt;Jeff Van Oss&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01575">
<title>On the Convergence of Encoder-only Shallow Transformers. (arXiv:2311.01575v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01575</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we aim to build the global convergence theory of encoder-only
shallow Transformers under a realistic setting from the perspective of
architectures, initialization, and scaling under a finite width regime. The
difficulty lies in how to tackle the softmax in self-attention mechanism, the
core ingredient of Transformer. In particular, we diagnose the scaling scheme,
carefully tackle the input/output of softmax, and prove that quadratic
overparameterization is sufficient for global convergence of our shallow
Transformers under commonly-used He/LeCun initialization in practice. Besides,
neural tangent kernel (NTK) based analysis is also given, which facilitates a
comprehensive comparison. Our theory demonstrates the separation on the
importance of different scaling schemes and initialization. We believe our
results can pave the way for a better understanding of modern Transformers,
particularly on training dynamics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yongtao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Fanghui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1&quot;&gt;Grigorios G Chrysos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cevher_V/0/1/0/all/0/1&quot;&gt;Volkan Cevher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01588">
<title>Domain Adaptive Graph Neural Networks for Constraining Cosmological Parameters Across Multiple Data Sets. (arXiv:2311.01588v1 [astro-ph.CO])</title>
<link>http://arxiv.org/abs/2311.01588</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models have been shown to outperform methods that rely on
summary statistics, like the power spectrum, in extracting information from
complex cosmological data sets. However, due to differences in the subgrid
physics implementation and numerical approximations across different simulation
suites, models trained on data from one cosmological simulation show a drop in
performance when tested on another. Similarly, models trained on any of the
simulations would also likely experience a drop in performance when applied to
observational data. Training on data from two different suites of the CAMELS
hydrodynamic cosmological simulations, we examine the generalization
capabilities of Domain Adaptive Graph Neural Networks (DA-GNNs). By utilizing
GNNs, we capitalize on their capacity to capture structured scale-free
cosmological information from galaxy distributions. Moreover, by including
unsupervised domain adaptation via Maximum Mean Discrepancy (MMD), we enable
our models to extract domain-invariant features. We demonstrate that DA-GNN
achieves higher accuracy and robustness on cross-dataset tasks (up to $28\%$
better relative error and up to almost an order of magnitude better $\chi^2$).
Using data visualizations, we show the effects of domain adaptation on proper
latent space data alignment. This shows that DA-GNNs are a promising method for
extracting domain-independent cosmological information, a vital step toward
robust deep learning for real cosmic survey data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Roncoli_A/0/1/0/all/0/1&quot;&gt;Andrea Roncoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Ciprijanovic_A/0/1/0/all/0/1&quot;&gt;Aleksandra &amp;#x106;iprijanovi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Voetberg_M/0/1/0/all/0/1&quot;&gt;Maggie Voetberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Villaescusa_Navarro_F/0/1/0/all/0/1&quot;&gt;Francisco Villaescusa-Navarro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Nord_B/0/1/0/all/0/1&quot;&gt;Brian Nord&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01589">
<title>A Statistical Guarantee for Representation Transfer in Multitask Imitation Learning. (arXiv:2311.01589v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01589</link>
<description rdf:parseType="Literal">&lt;p&gt;Transferring representation for multitask imitation learning has the
potential to provide improved sample efficiency on learning new tasks, when
compared to learning from scratch. In this work, we provide a statistical
guarantee indicating that we can indeed achieve improved sample efficiency on
the target task when a representation is trained using sufficiently diverse
source tasks. Our theoretical results can be readily extended to account for
commonly used neural network architectures with realistic assumptions. We
conduct empirical analyses that align with our theoretical findings on four
simulated environments$\unicode{x2014}$in particular leveraging more data from
source tasks can improve sample efficiency on learning in the new task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_B/0/1/0/all/0/1&quot;&gt;Bryan Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereida_K/0/1/0/all/0/1&quot;&gt;Karime Pereida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergstra_J/0/1/0/all/0/1&quot;&gt;James Bergstra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01591">
<title>Better Fair than Sorry: Adversarial Missing Data Imputation for Fair GNNs. (arXiv:2311.01591v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01591</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the problem of learning fair Graph Neural Networks
(GNNs) under missing protected attributes. GNNs have achieved state-of-the-art
results in many relevant tasks where decisions might disproportionately impact
specific communities. However, existing work on fair GNNs assumes that either
protected attributes are fully-observed or that the missing data imputation is
fair. In practice, biases in the imputation will be propagated to the model
outcomes, leading them to overestimate the fairness of their predictions. We
address this challenge by proposing Better Fair than Sorry (BFtS), a fair
missing data imputation model for protected attributes used by fair GNNs. The
key design principle behind BFtS is that imputations should approximate the
worst-case scenario for the fair GNN -- i.e. when optimizing fairness is the
hardest. We implement this idea using a 3-player adversarial scheme where two
adversaries collaborate against the fair GNN. Experiments using synthetic and
real datasets show that BFtS often achieves a better fairness $\times$ accuracy
trade-off than existing alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lina_D/0/1/0/all/0/1&quot;&gt;Debolina Halder Lina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1&quot;&gt;Arlei Silva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01599">
<title>Local Borsuk-Ulam, Stability, and Replicability. (arXiv:2311.01599v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01599</link>
<description rdf:parseType="Literal">&lt;p&gt;We use and adapt the Borsuk-Ulam Theorem from topology to derive limitations
on list-replicable and globally stable learning algorithms. We further
demonstrate the applicability of our methods in combinatorics and topology.
&lt;/p&gt;
&lt;p&gt;We show that, besides trivial cases, both list-replicable and globally stable
learning are impossible in the agnostic PAC setting. This is in contrast with
the realizable case where it is known that any class with a finite Littlestone
dimension can be learned by such algorithms. In the realizable PAC setting, we
sharpen previous impossibility results and broaden their scope. Specifically,
we establish optimal bounds for list replicability and global stability numbers
in finite classes. This provides an exponential improvement over previous works
and implies an exponential separation from the Littlestone dimension. We
further introduce lower bounds for weak learners, i.e., learners that are only
marginally better than random guessing. Lower bounds from previous works apply
only to stronger learners.
&lt;/p&gt;
&lt;p&gt;To offer a broader and more comprehensive view of our topological approach,
we prove a local variant of the Borsuk-Ulam theorem in topology and a result in
combinatorics concerning Kneser colorings. In combinatorics, we prove that if
$c$ is a coloring of all non-empty subsets of $[n]$ such that disjoint sets
have different colors, then there is a chain of subsets that receives at least
$1+ \lfloor n/2\rfloor$ colors (this bound is sharp). In topology, we prove
e.g. that for any open antipodal-free cover of the $d$-dimensional sphere,
there is a point $x$ that belongs to at least $t=\lceil\frac{d+3}{2}\rceil$
sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chase_Z/0/1/0/all/0/1&quot;&gt;Zachary Chase&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chornomaz_B/0/1/0/all/0/1&quot;&gt;Bogdan Chornomaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1&quot;&gt;Shay Moran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yehudayoff_A/0/1/0/all/0/1&quot;&gt;Amir Yehudayoff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01605">
<title>Faithful and Robust Local Interpretability for Textual Predictions. (arXiv:2311.01605v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01605</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretability is essential for machine learning models to be trusted and
deployed in critical domains. However, existing methods for interpreting text
models are often complex, lack solid mathematical foundations, and their
performance is not guaranteed. In this paper, we propose FRED (Faithful and
Robust Explainer for textual Documents), a novel method for interpreting
predictions over text. FRED identifies key words in a document that
significantly impact the prediction when removed. We establish the reliability
of FRED through formal definitions and theoretical analyses on interpretable
classifiers. Additionally, our empirical evaluation against state-of-the-art
methods demonstrates the effectiveness of FRED in providing insights into text
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopardo_G/0/1/0/all/0/1&quot;&gt;Gianluigi Lopardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precioso_F/0/1/0/all/0/1&quot;&gt;Frederic Precioso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garreau_D/0/1/0/all/0/1&quot;&gt;Damien Garreau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01617">
<title>Look-Ahead Selective Plasticity for Continual Learning of Visual Tasks. (arXiv:2311.01617v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01617</link>
<description rdf:parseType="Literal">&lt;p&gt;Contrastive representation learning has emerged as a promising technique for
continual learning as it can learn representations that are robust to
catastrophic forgetting and generalize well to unseen future tasks. Previous
work in continual learning has addressed forgetting by using previous task data
and trained models. Inspired by event models created and updated in the brain,
we propose a new mechanism that takes place during task boundaries, i.e., when
one task finishes and another starts. By observing the redundancy-inducing
ability of contrastive loss on the output of a neural network, our method
leverages the first few samples of the new task to identify and retain
parameters contributing most to the transfer ability of the neural network,
freeing up the remaining parts of the network to learn new features. We
evaluate the proposed methods on benchmark computer vision datasets including
CIFAR10 and TinyImagenet and demonstrate state-of-the-art performance in the
task-incremental, class-incremental, and domain-incremental continual learning
scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meshkinnejad_R/0/1/0/all/0/1&quot;&gt;Rouzbeh Meshkinnejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mei_J/0/1/0/all/0/1&quot;&gt;Jie Mei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lizotte_D/0/1/0/all/0/1&quot;&gt;Daniel Lizotte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohsenzadeh_Y/0/1/0/all/0/1&quot;&gt;Yalda Mohsenzadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01623">
<title>VQPy: An Object-Oriented Approach to Modern Video Analytics. (arXiv:2311.01623v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01623</link>
<description rdf:parseType="Literal">&lt;p&gt;Video analytics is widely used in contemporary systems and services. At the
forefront of video analytics are video queries that users develop to find
objects of particular interest. Building upon the insight that video objects
(e.g., human, animals, cars, etc.), the center of video analytics, are similar
in spirit to objects modeled by traditional object-oriented languages, we
propose to develop an object-oriented approach to video analytics. This
approach, named VQPy, consists of a frontend$\unicode{x2015}$a Python variant
with constructs that make it easy for users to express video objects and their
interactions$\unicode{x2015}$as well as an extensible backend that can
automatically construct and optimize pipelines based on video objects. We have
implemented and open-sourced VQPy, which has been productized in Cisco as part
of its DeepVision framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Shan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhenting Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hanchen Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1&quot;&gt;Pengzhan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Padmanabhan_A/0/1/0/all/0/1&quot;&gt;Arthi Padmanabhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1&quot;&gt;Hugo Latapie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Harry Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01642">
<title>Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula. (arXiv:2311.01642v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01642</link>
<description rdf:parseType="Literal">&lt;p&gt;Robustness against adversarial attacks and distribution shifts is a
long-standing goal of Reinforcement Learning (RL). To this end, Robust
Adversarial Reinforcement Learning (RARL) trains a protagonist against
destabilizing forces exercised by an adversary in a competitive zero-sum Markov
game, whose optimal solution, i.e., rational strategy, corresponds to a Nash
equilibrium. However, finding Nash equilibria requires facing complex saddle
point optimization problems, which can be prohibitive to solve, especially for
high-dimensional control. In this paper, we propose a novel approach for
adversarial RL based on entropy regularization to ease the complexity of the
saddle point optimization problem. We show that the solution of this
entropy-regularized problem corresponds to a Quantal Response Equilibrium
(QRE), a generalization of Nash equilibria that accounts for bounded
rationality, i.e., agents sometimes play random actions instead of optimal
ones. Crucially, the connection between the entropy-regularized objective and
QRE enables free modulation of the rationality of the agents by simply tuning
the temperature coefficient. We leverage this insight to propose our novel
algorithm, Quantal Adversarial RL (QARL), which gradually increases the
rationality of the adversary in a curriculum fashion until it is fully
rational, easing the complexity of the optimization problem while retaining
robustness. We provide extensive evidence of QARL outperforming RARL and recent
baselines across several MuJoCo locomotion and navigation problems in overall
performance and robustness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddi_A/0/1/0/all/0/1&quot;&gt;Aryaman Reddi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolle_M/0/1/0/all/0/1&quot;&gt;Maximilian T&amp;#xf6;lle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1&quot;&gt;Jan Peters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalvatzaki_G/0/1/0/all/0/1&quot;&gt;Georgia Chalvatzaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DEramo_C/0/1/0/all/0/1&quot;&gt;Carlo D&amp;#x27;Eramo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01644">
<title>Should Under-parameterized Student Networks Copy or Average Teacher Weights?. (arXiv:2311.01644v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01644</link>
<description rdf:parseType="Literal">&lt;p&gt;Any continuous function $f^*$ can be approximated arbitrarily well by a
neural network with sufficiently many neurons $k$. We consider the case when
$f^*$ itself is a neural network with one hidden layer and $k$ neurons.
Approximating $f^*$ with a neural network with $n&amp;lt; k$ neurons can thus be seen
as fitting an under-parameterized &quot;student&quot; network with $n$ neurons to a
&quot;teacher&quot; network with $k$ neurons. As the student has fewer neurons than the
teacher, it is unclear, whether each of the $n$ student neurons should copy one
of the teacher neurons or rather average a group of teacher neurons. For
shallow neural networks with erf activation function and for the standard
Gaussian input distribution, we prove that &quot;copy-average&quot; configurations are
critical points if the teacher&apos;s incoming vectors are orthonormal and its
outgoing weights are unitary. Moreover, the optimum among such configurations
is reached when $n-1$ student neurons each copy one teacher neuron and the
$n$-th student neuron averages the remaining $k-n+1$ teacher neurons. For the
student network with $n=1$ neuron, we provide additionally a closed-form
solution of the non-trivial critical point(s) for commonly used activation
functions through solving an equivalent constrained optimization problem.
Empirically, we find for the erf activation function that gradient flow
converges either to the optimal copy-average critical point or to another point
where each student neuron approximately copies a different teacher neuron.
Finally, we find similar results for the ReLU activation function, suggesting
that the optimal solution of underparameterized networks has a universal
structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simsek_B/0/1/0/all/0/1&quot;&gt;Berfin &amp;#x15e;im&amp;#x15f;ek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bendjeddou_A/0/1/0/all/0/1&quot;&gt;Amire Bendjeddou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1&quot;&gt;Wulfram Gerstner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brea_J/0/1/0/all/0/1&quot;&gt;Johanni Brea&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01646">
<title>SemiGPC: Distribution-Aware Label Refinement for Imbalanced Semi-Supervised Learning Using Gaussian Processes. (arXiv:2311.01646v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01646</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we introduce SemiGPC, a distribution-aware label refinement
strategy based on Gaussian Processes where the predictions of the model are
derived from the labels posterior distribution. Differently from other
buffer-based semi-supervised methods such as CoMatch and SimMatch, our SemiGPC
includes a normalization term that addresses imbalances in the global data
distribution while maintaining local sensitivity. This explicit control allows
SemiGPC to be more robust to confirmation bias especially under class
imbalance. We show that SemiGPC improves performance when paired with different
Semi-Supervised methods such as FixMatch, ReMixMatch, SimMatch and FreeMatch
and different pre-training strategies including MSN and Dino. We also show that
SemiGPC achieves state of the art results under different degrees of class
imbalance on standard CIFAR10-LT/CIFAR100-LT especially in the low data-regime.
Using SemiGPC also results in about 2% avg.accuracy increase compared to a new
competitive baseline on the more challenging benchmarks SemiAves, SemiCUB,
SemiFungi and Semi-iNat.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lemkhenter_A/0/1/0/all/0/1&quot;&gt;Abdelhak Lemkhenter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Manchen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zancato_L/0/1/0/all/0/1&quot;&gt;Luca Zancato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swaminathan_G/0/1/0/all/0/1&quot;&gt;Gurumurthy Swaminathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Favaro_P/0/1/0/all/0/1&quot;&gt;Paolo Favaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Modolo_D/0/1/0/all/0/1&quot;&gt;Davide Modolo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01647">
<title>Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational and Temporal Graphs. (arXiv:2311.01647v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01647</link>
<description rdf:parseType="Literal">&lt;p&gt;As a powerful framework for graph representation learning, Graph Neural
Networks (GNNs) have garnered significant attention in recent years. However,
to the best of our knowledge, there has been no formal analysis of the logical
expressiveness of GNNs as Boolean node classifiers over multi-relational
graphs, where each edge carries a specific relation type. In this paper, we
investigate $\mathcal{FOC}_2$, a fragment of first-order logic with two
variables and counting quantifiers. On the negative side, we demonstrate that
the R$^2$-GNN architecture, which extends the local message passing GNN by
incorporating global readout, fails to capture $\mathcal{FOC}_2$ classifiers in
the general case. Nevertheless, on the positive side, we establish that
R$^2$-GNNs models are equivalent to $\mathcal{FOC}_2$ classifiers under certain
restricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs
regarding expressiveness, we propose a simple graph transformation technique,
akin to a preprocessing step, which can be executed in linear time. This
transformation enables R$^2$-GNNs to effectively capture any $\mathcal{FOC}_2$
classifiers when applied to the &quot;transformed&quot; input graph. Moreover, we extend
our analysis of expressiveness and graph transformation to temporal graphs,
exploring several temporal GNN architectures and providing an expressiveness
hierarchy for them. To validate our findings, we implement R$^2$-GNNs and the
graph transformation technique and conduct empirical tests in node
classification tasks against various well-known GNN architectures that support
multi-relational or temporal graphs. Our experimental results consistently
demonstrate that R$^2$-GNN with the graph transformation outperforms the
baseline methods on both synthetic and real-world datasets
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yeyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dingmin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01650">
<title>MARRS: Multimodal Reference Resolution System. (arXiv:2311.01650v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01650</link>
<description rdf:parseType="Literal">&lt;p&gt;Successfully handling context is essential for any dialog understanding task.
This context maybe be conversational (relying on previous user queries or
system responses), visual (relying on what the user sees, for example, on their
screen), or background (based on signals such as a ringing alarm or playing
music). In this work, we present an overview of MARRS, or Multimodal Reference
Resolution System, an on-device framework within a Natural Language
Understanding system, responsible for handling conversational, visual and
background context. In particular, we present different machine learning models
to enable handing contextual queries; specifically, one to enable reference
resolution, and one to handle context via query rewriting. We also describe how
these models complement each other to form a unified, coherent, lightweight
system that can understand context while preserving user privacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ates_H/0/1/0/all/0/1&quot;&gt;Halim Cagri Ates&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhargava_S/0/1/0/all/0/1&quot;&gt;Shruti Bhargava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Site Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiarui Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maddula_S/0/1/0/all/0/1&quot;&gt;Siddhardha Maddula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1&quot;&gt;Joel Ruben Antony Moniz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nalamalapu_A/0/1/0/all/0/1&quot;&gt;Anil Kumar Nalamalapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_R/0/1/0/all/0/1&quot;&gt;Roman Hoang Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozyildirim_M/0/1/0/all/0/1&quot;&gt;Melis Ozyildirim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1&quot;&gt;Alkesh Patel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piraviperumal_D/0/1/0/all/0/1&quot;&gt;Dhivya Piraviperumal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renkens_V/0/1/0/all/0/1&quot;&gt;Vincent Renkens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samal_A/0/1/0/all/0/1&quot;&gt;Ankit Samal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Thy Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tseng_B/0/1/0/all/0/1&quot;&gt;Bo-Hsiang Tseng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_R/0/1/0/all/0/1&quot;&gt;Rong Zou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01655">
<title>Detecting Spurious Correlations via Robust Visual Concepts in Real and AI-Generated Image Classification. (arXiv:2311.01655v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01655</link>
<description rdf:parseType="Literal">&lt;p&gt;Often machine learning models tend to automatically learn associations
present in the training data without questioning their validity or
appropriateness. This undesirable property is the root cause of the
manifestation of spurious correlations, which render models unreliable and
prone to failure in the presence of distribution shifts. Research shows that
most methods attempting to remedy spurious correlations are only effective for
a model&apos;s known spurious associations. Current spurious correlation detection
algorithms either rely on extensive human annotations or are too restrictive in
their formulation. Moreover, they rely on strict definitions of visual
artifacts that may not apply to data produced by generative models, as they are
known to hallucinate contents that do not conform to standard specifications.
In this work, we introduce a general-purpose method that efficiently detects
potential spurious correlations, and requires significantly less human
interference in comparison to the prior art. Additionally, the proposed method
provides intuitive explanations while eliminating the need for pixel-level
annotations. We demonstrate the proposed method&apos;s tolerance to the peculiarity
of AI-generated images, which is a considerably challenging task, one where
most of the existing methods fall short. Consequently, our method is also
suitable for detecting spurious correlations that may propagate to downstream
applications originating from generative models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dammu_P/0/1/0/all/0/1&quot;&gt;Preetam Prabhu Srikar Dammu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_C/0/1/0/all/0/1&quot;&gt;Chirag Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01660">
<title>Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling. (arXiv:2311.01660v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01660</link>
<description rdf:parseType="Literal">&lt;p&gt;Survival analysis is a widely-used technique for analyzing time-to-event data
in the presence of censoring. In recent years, numerous survival analysis
methods have emerged which scale to large datasets and relax traditional
assumptions such as proportional hazards. These models, while being performant,
are very sensitive to model hyperparameters including: (1) number of bins and
bin size for discrete models and (2) number of cluster assignments for
mixture-based models. Each of these choices requires extensive tuning by
practitioners to achieve optimal performance. In addition, we demonstrate in
empirical studies that: (1) optimal bin size may drastically differ based on
the metric of interest (e.g., concordance vs brier score), and (2) mixture
models may suffer from mode collapse and numerical instability. We propose a
survival analysis approach which eliminates the need to tune hyperparameters
such as mixture assignments and bin sizes, reducing the burden on
practitioners. We show that the proposed approach matches or outperforms
baselines on several real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ketenci_M/0/1/0/all/0/1&quot;&gt;Mert Ketenci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhave_S/0/1/0/all/0/1&quot;&gt;Shreyas Bhave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elhadad_N/0/1/0/all/0/1&quot;&gt;No&amp;#xe9;mie Elhadad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perotte_A/0/1/0/all/0/1&quot;&gt;Adler Perotte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01683">
<title>Amide Proton Transfer (APT) imaging in tumor with a machine learning approach using partially synthetic data. (arXiv:2311.01683v1 [physics.med-ph])</title>
<link>http://arxiv.org/abs/2311.01683</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning (ML) has been increasingly used to quantify chemical
exchange saturation transfer (CEST) effect. ML models are typically trained
using either measured data or fully simulated data. However, training with
measured data often lacks sufficient training data, while training with fully
simulated data may introduce bias due to limited simulations pools. This study
introduces a new platform that combines simulated and measured components to
generate partially synthetic CEST data, and to evaluate its feasibility for
training ML models to predict amide proton transfer (APT) effect. Partially
synthetic CEST signals were created using an inverse summation of APT effects
from simulations and the other components from measurements. Training data were
generated by varying APT simulation parameters and applying scaling factors to
adjust the measured components, achieving a balance between simulation
flexibility and fidelity. First, tissue-mimicking CEST signals along with
ground truth information were created using multiple-pool model simulations to
validate this method. Second, an ML model was trained individually on partially
synthetic data, in vivo data, and fully simulated data, to predict APT effect
in rat brains bearing 9L tumors. Experiments on tissue-mimicking data suggest
that the ML method using the partially synthetic data is accurate in predicting
APT. In vivo experiments suggest that our method provides more accurate and
robust prediction than the training using in vivo data and fully synthetic
data. Partially synthetic CEST data can address the challenges in conventional
ML methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Viswanathan_M/0/1/0/all/0/1&quot;&gt;Malvika Viswanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yin_L/0/1/0/all/0/1&quot;&gt;Leqi Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kurmi_Y/0/1/0/all/0/1&quot;&gt;Yashwant Kurmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zu_Z/0/1/0/all/0/1&quot;&gt;Zhongliang Zu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01686">
<title>Disentangled Representation Learning with Transmitted Information Bottleneck. (arXiv:2311.01686v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01686</link>
<description rdf:parseType="Literal">&lt;p&gt;Encoding only the task-related information from the raw data, \ie,
disentangled representation learning, can greatly contribute to the robustness
and generalizability of models. Although significant advances have been made by
regularizing the information in representations with information theory, two
major challenges remain: 1) the representation compression inevitably leads to
performance drop; 2) the disentanglement constraints on representations are in
complicated optimization. To these issues, we introduce Bayesian networks with
transmitted information to formulate the interaction among input and
representations during disentanglement. Building upon this framework, we
propose \textbf{DisTIB} (\textbf{T}ransmitted \textbf{I}nformation
\textbf{B}ottleneck for \textbf{Dis}entangled representation learning), a novel
objective that navigates the balance between information compression and
preservation. We employ variational inference to derive a tractable estimation
for DisTIB. This estimation can be simply optimized via standard gradient
descent with a reparameterization trick. Moreover, we theoretically prove that
DisTIB can achieve optimal disentanglement, underscoring its superior efficacy.
To solidify our claims, we conduct extensive experiments on various downstream
tasks to demonstrate the appealing efficacy of DisTIB and validate our
theoretical analyses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dang_Z/0/1/0/all/0/1&quot;&gt;Zhuohang Dang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1&quot;&gt;Minnan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1&quot;&gt;Chengyou Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_G/0/1/0/all/0/1&quot;&gt;Guang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jihong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1&quot;&gt;Xiaojun Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jingdong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1&quot;&gt;Qinghua Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01695">
<title>Communication-Efficient Federated Non-Linear Bandit Optimization. (arXiv:2311.01695v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01695</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated optimization studies the problem of collaborative function
optimization among multiple clients (e.g. mobile devices or organizations)
under the coordination of a central server. Since the data is collected
separately by each client and always remains decentralized, federated
optimization preserves data privacy and allows for large-scale computing, which
makes it a promising decentralized machine learning paradigm. Though it is
often deployed for tasks that are online in nature, e.g., next-word prediction
on keyboard apps, most works formulate it as an offline problem. The few
exceptions that consider federated bandit optimization are limited to very
simplistic function classes, e.g., linear, generalized linear, or
non-parametric function class with bounded RKHS norm, which severely hinders
its practical usage. In this paper, we propose a new algorithm, named
Fed-GO-UCB, for federated bandit optimization with generic non-linear objective
function. Under some mild conditions, we rigorously prove that Fed-GO-UCB is
able to achieve sub-linear rate for both cumulative regret and communication
cost. At the heart of our theoretical analysis are distributed regression
oracle and individual confidence set construction, which can be of independent
interests. Empirical evaluations also demonstrate the effectiveness of the
proposed algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chuanhao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01698">
<title>Adversarial Attacks on Cooperative Multi-agent Bandits. (arXiv:2311.01698v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01698</link>
<description rdf:parseType="Literal">&lt;p&gt;Cooperative multi-agent multi-armed bandits (CMA2B) consider the
collaborative efforts of multiple agents in a shared multi-armed bandit game.
We study latent vulnerabilities exposed by this collaboration and consider
adversarial attacks on a few agents with the goal of influencing the decisions
of the rest. More specifically, we study adversarial attacks on CMA2B in both
homogeneous settings, where agents operate with the same arm set, and
heterogeneous settings, where agents have distinct arm sets. In the homogeneous
setting, we propose attack strategies that, by targeting just one agent,
convince all agents to select a particular target arm $T-o(T)$ times while
incurring $o(T)$ attack costs in $T$ rounds. In the heterogeneous setting, we
prove that a target arm attack requires linear attack costs and propose attack
strategies that can force a maximum number of agents to suffer linear regrets
while incurring sublinear costs and only manipulating the observations of a few
target agents. Numerical experiments validate the effectiveness of our proposed
attack strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_J/0/1/0/all/0/1&quot;&gt;Jinhang Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiyao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xuchuang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Cheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1&quot;&gt;John C.S. Lui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1&quot;&gt;Mohammad Hajiesmaili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1&quot;&gt;Adam Wierman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01708">
<title>Physics-Informed Generator-Encoder Adversarial Networks with Latent Space Matching for Stochastic Differential Equations. (arXiv:2311.01708v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01708</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new class of physics-informed neural networks, called
Physics-Informed Generator-Encoder Adversarial Networks, to effectively address
the challenges posed by forward, inverse, and mixed problems in stochastic
differential equations. In these scenarios, while the governing equations are
known, the available data consist of only a limited set of snapshots for system
parameters. Our model consists of two key components: the generator and the
encoder, both updated alternately by gradient descent. In contrast to previous
approaches of directly matching the approximated solutions with real snapshots,
we employ an indirect matching that operates within the lower-dimensional
latent feature space. This method circumvents challenges associated with
high-dimensional inputs and complex data distributions, while yielding more
accurate solutions compared to existing neural network solvers. In addition,
the approach also mitigates the training instability issues encountered in
previous adversarial frameworks in an efficient manner. Numerical results
provide compelling evidence of the effectiveness of the proposed method in
solving different types of stochastic differential equations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1&quot;&gt;Ruisong Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Min Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jin Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01722">
<title>Heterogeneous federated collaborative filtering using FAIR: Federated Averaging in Random Subspaces. (arXiv:2311.01722v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01722</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommendation systems (RS) for items (e.g., movies, books) and ads are
widely used to tailor content to users on various internet platforms.
Traditionally, recommendation models are trained on a central server. However,
due to rising concerns for data privacy and regulations like the GDPR,
federated learning is an increasingly popular paradigm in which data never
leaves the client device. Applying federated learning to recommendation models
is non-trivial due to large embedding tables, which often exceed the memory
constraints of most user devices. To include data from all devices in federated
learning, we must enable collective training of embedding tables on devices
with heterogeneous memory capacities. Current solutions to heterogeneous
federated learning can only accommodate a small range of capacities and thus
limit the number of devices that can participate in training. We present
Federated Averaging in Random subspaces (FAIR), which allows arbitrary
compression of embedding tables based on device capacity and ensures the
participation of all devices in training. FAIR uses what we call consistent and
collapsible subspaces defined by hashing-based random projections to jointly
train large embedding tables while using varying amounts of compression on user
devices. We evaluate FAIR on Neural Collaborative Filtering tasks with multiple
datasets and verify that FAIR can gather and share information from a wide
range of devices with varying capacities, allowing for seamless collaboration.
We prove the convergence of FAIR in the homogeneous setting with non-i.i.d data
distribution. Our code is open source at {https://github.com/apd10/FLCF}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Desai_A/0/1/0/all/0/1&quot;&gt;Aditya Desai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meisburger_B/0/1/0/all/0/1&quot;&gt;Benjamin Meisburger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zichang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1&quot;&gt;Anshumali Shrivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01727">
<title>Flexible Error Mitigation of Quantum Processes with Data Augmentation Empowered Neural Model. (arXiv:2311.01727v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2311.01727</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks have shown their effectiveness in various tasks in the realm
of quantum computing. However, their application in quantum error mitigation, a
crucial step towards realizing practical quantum advancements, has been
restricted by reliance on noise-free statistics. To tackle this critical
challenge, we propose a data augmentation empowered neural model for error
mitigation (DAEM). Our model does not require any prior knowledge about the
specific noise type and measurement settings and can estimate noise-free
statistics solely from the noisy measurement results of the target quantum
process, rendering it highly suitable for practical implementation. In
numerical experiments, we show the model&apos;s superior performance in mitigating
various types of noise, including Markovian noise and Non-Markovian noise,
compared with previous error mitigation methods. We further demonstrate its
versatility by employing the model to mitigate errors in diverse types of
quantum processes, including those involving large-scale quantum systems and
continuous-variable quantum states. This powerful data augmentation-empowered
neural model for error mitigation establishes a solid foundation for realizing
more reliable and robust quantum technologies in practical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liao_M/0/1/0/all/0/1&quot;&gt;Manwen Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chiribella_G/0/1/0/all/0/1&quot;&gt;Giulio Chiribella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yuxiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01729">
<title>CDGraph: Dual Conditional Social Graph Synthesizing via Diffusion Model. (arXiv:2311.01729v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2311.01729</link>
<description rdf:parseType="Literal">&lt;p&gt;The social graphs synthesized by the generative models are increasingly in
demand due to data scarcity and concerns over user privacy. One of the key
performance criteria for generating social networks is the fidelity to
specified conditionals, such as users with certain membership and financial
status. While recent diffusion models have shown remarkable performance in
generating images, their effectiveness in synthesizing graphs has not yet been
explored in the context of conditional social graphs. In this paper, we propose
the first kind of conditional diffusion model for social networks, CDGraph,
which trains and synthesizes graphs based on two specified conditions. We
propose the co-evolution dependency in the denoising process of CDGraph to
capture the mutual dependencies between the dual conditions and further
incorporate social homophily and social contagion to preserve the connectivity
between nodes while satisfying the specified conditions. Moreover, we introduce
a novel classifier loss, which guides the training of the diffusion process
through the mutual dependency of dual conditions. We evaluate CDGraph against
four existing graph generative methods, i.e., SPECTRE, GSM, EDGE, and DiGress,
on four datasets. Our results show that the generated graphs from CDGraph
achieve much higher dual-conditional validity and lower discrepancy in various
social network metrics than the baselines, thus demonstrating its proficiency
in generating dual-conditional social graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsai_J/0/1/0/all/0/1&quot;&gt;Jui-Yi Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1&quot;&gt;Ya-Wen Teng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yew_H/0/1/0/all/0/1&quot;&gt;Ho Chiok Yew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1&quot;&gt;De-Nian Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lydia Y. Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01742">
<title>Global Optimization: A Machine Learning Approach. (arXiv:2311.01742v1 [math.OC])</title>
<link>http://arxiv.org/abs/2311.01742</link>
<description rdf:parseType="Literal">&lt;p&gt;Many approaches for addressing Global Optimization problems typically rely on
relaxations of nonlinear constraints over specific mathematical primitives.
This is restricting in applications with constraints that are black-box,
implicit or consist of more general primitives. Trying to address such
limitations, Bertsimas and Ozturk (2023) proposed OCTHaGOn as a way of solving
black-box global optimization problems by approximating the nonlinear
constraints using hyperplane-based Decision-Trees and then using those trees to
construct a unified mixed integer optimization (MIO) approximation of the
original problem. We provide extensions to this approach, by (i) approximating
the original problem using other MIO-representable ML models besides Decision
Trees, such as Gradient Boosted Trees, Multi Layer Perceptrons and Suport
Vector Machines, (ii) proposing adaptive sampling procedures for more accurate
machine learning-based constraint approximations, (iii) utilizing robust
optimization to account for the uncertainty of the sample-dependent training of
the ML models, and (iv) leveraging a family of relaxations to address the
infeasibilities of the final MIO approximation. We then test the enhanced
framework in 81 Global Optimization instances. We show improvements in solution
feasibility and optimality in the majority of instances. We also compare
against BARON, showing improved optimality gaps or solution times in 11
instances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bertsimas_D/0/1/0/all/0/1&quot;&gt;Dimitris Bertsimas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Margaritis_G/0/1/0/all/0/1&quot;&gt;Georgios Margaritis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01743">
<title>Energy Efficiency Optimization for Subterranean LoRaWAN Using A Reinforcement Learning Approach: A Direct-to-Satellite Scenario. (arXiv:2311.01743v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2311.01743</link>
<description rdf:parseType="Literal">&lt;p&gt;The integration of subterranean LoRaWAN and non-terrestrial networks (NTN)
delivers substantial economic and societal benefits in remote agriculture and
disaster rescue operations. The LoRa modulation leverages quasi-orthogonal
spreading factors (SFs) to optimize data rates, airtime, coverage and energy
consumption. However, it is still challenging to effectively assign SFs to end
devices for minimizing co-SF interference in massive subterranean LoRaWAN NTN.
To address this, we investigate a reinforcement learning (RL)-based SFs
allocation scheme to optimize the system&apos;s energy efficiency (EE). To
efficiently capture the device-to-environment interactions in dense networks,
we proposed an SFs allocation technique using the multi-agent dueling double
deep Q-network (MAD3QN) and the multi-agent advantage actor-critic (MAA2C)
algorithms based on an analytical reward mechanism. Our proposed RL-based SFs
allocation approach evinces better performance compared to four benchmarks in
the extreme underground direct-to-satellite scenario. Remarkably, MAD3QN shows
promising potentials in surpassing MAA2C in terms of convergence rate and EE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1&quot;&gt;Kaiqiang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ullah_M/0/1/0/all/0/1&quot;&gt;Muhammad Asad Ullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alves_H/0/1/0/all/0/1&quot;&gt;Hirley Alves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikhaylov_K/0/1/0/all/0/1&quot;&gt;Konstantin Mikhaylov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_T/0/1/0/all/0/1&quot;&gt;Tong Hao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01749">
<title>Epidemic Decision-making System Based Federated Reinforcement Learning. (arXiv:2311.01749v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01749</link>
<description rdf:parseType="Literal">&lt;p&gt;Epidemic decision-making can effectively help the government to
comprehensively consider public security and economic development to respond to
public health and safety emergencies. Epidemic decision-making can effectively
help the government to comprehensively consider public security and economic
development to respond to public health and safety emergencies. Some studies
have shown that intensive learning can effectively help the government to make
epidemic decision, thus achieving the balance between health security and
economic development. Some studies have shown that intensive learning can
effectively help the government to make epidemic decision, thus achieving the
balance between health security and economic development. However, epidemic
data often has the characteristics of limited samples and high privacy.
However, epidemic data often has the characteristics of limited samples and
high privacy. This model can combine the epidemic situation data of various
provinces for cooperative training to use as an enhanced learning model for
epidemic situation decision, while protecting the privacy of data. The
experiment shows that the enhanced federated learning can obtain more optimized
performance and return than the enhanced learning, and the enhanced federated
learning can also accelerate the training convergence speed of the training
model. accelerate the training convergence speed of the client. At the same
time, through the experimental comparison, A2C is the most suitable
reinforcement learning model for the epidemic situation decision-making.
learning model for the epidemic situation decision-making scenario, followed by
the PPO model, and the performance of DDPG is unsatisfactory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yangxi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1&quot;&gt;Junping Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1&quot;&gt;Zhe Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1&quot;&gt;Zhenhui Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Weikang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01753">
<title>RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization. (arXiv:2311.01753v1 [cs.MA])</title>
<link>http://arxiv.org/abs/2311.01753</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-agent systems are characterized by environmental uncertainty, varying
policies of agents, and partial observability, which result in significant
risks. In the context of Multi-Agent Reinforcement Learning (MARL), learning
coordinated and decentralized policies that are sensitive to risk is
challenging. To formulate the coordination requirements in risk-sensitive MARL,
we introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a
generalization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM)
principles. This principle requires that the collection of risk-sensitive
action selections of each agent should be equivalent to the risk-sensitive
action selection of the central policy. Current MARL value factorization
methods do not satisfy the RIGM principle for common risk metrics such as the
Value at Risk (VaR) metric or distorted risk measurements. Therefore, we
propose RiskQ to address this limitation, which models the joint return
distribution by modeling quantiles of it as weighted quantile mixtures of
per-agent return distribution utilities. RiskQ satisfies the RIGM principle for
the VaR and distorted risk metrics. We show that RiskQ can obtain promising
performance through extensive experiments. The source code of RiskQ is
available in https://github.com/xmu-rl-3dv/RiskQ.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1&quot;&gt;Siqi Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chennan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weiquan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yongquan Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1&quot;&gt;Songzhu Mei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xinwang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Cheng Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01759">
<title>TinyFormer: Efficient Transformer Design and Deployment on Tiny Devices. (arXiv:2311.01759v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01759</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing deep learning models on tiny devices (e.g. Microcontroller units,
MCUs) has attracted much attention in various embedded IoT applications.
However, it is challenging to efficiently design and deploy recent advanced
models (e.g. transformers) on tiny devices due to their severe hardware
resource constraints. In this work, we propose TinyFormer, a framework
specifically designed to develop and deploy resource-efficient transformers on
MCUs. TinyFormer mainly consists of SuperNAS, SparseNAS and SparseEngine.
Separately, SuperNAS aims to search for an appropriate supernet from a vast
search space. SparseNAS evaluates the best sparse single-path model including
transformer architecture from the identified supernet. Finally, SparseEngine
efficiently deploys the searched sparse models onto MCUs. To the best of our
knowledge, SparseEngine is the first deployment framework capable of performing
inference of sparse models with transformer on MCUs. Evaluation results on the
CIFAR-10 dataset demonstrate that TinyFormer can develop efficient transformers
with an accuracy of $96.1\%$ while adhering to hardware constraints of $1$MB
storage and $320$KB memory. Additionally, TinyFormer achieves significant
speedups in sparse inference, up to $12.2\times$, when compared to the CMSIS-NN
library. TinyFormer is believed to bring powerful transformers into TinyML
scenarios and greatly expand the scope of deep learning applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianlei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_J/0/1/0/all/0/1&quot;&gt;Jiacheng Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_F/0/1/0/all/0/1&quot;&gt;Fanding Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Meichen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Junyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_L/0/1/0/all/0/1&quot;&gt;Lingkun Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_H/0/1/0/all/0/1&quot;&gt;Han Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Bei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Weisheng Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01762">
<title>Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel. (arXiv:2311.01762v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01762</link>
<description rdf:parseType="Literal">&lt;p&gt;Kernel ridge regression, KRR, is a generalization of linear ridge regression
that is non-linear in the data, but linear in the parameters. The solution can
be obtained either as a closed-form solution, which includes a matrix
inversion, or iteratively through gradient descent. Using the iterative
approach opens up for changing the kernel during training, something that is
investigated in this paper. We theoretically address the effects this has on
model complexity and generalization. Based on our findings, we propose an
update scheme for the bandwidth of translational-invariant kernels, where we
let the bandwidth decrease to zero during training, thus circumventing the need
for hyper-parameter selection. We demonstrate on real and synthetic data how
decreasing the bandwidth during training outperforms using a constant
bandwidth, selected by cross-validation and marginal likelihood maximization.
We also show theoretically and empirically that using a decreasing bandwidth,
we are able to achieve both zero training error in combination with good
generalization, and a double descent behavior, phenomena that do not occur for
KRR with constant bandwidth but are known to appear for neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Allerbo_O/0/1/0/all/0/1&quot;&gt;Oskar Allerbo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01771">
<title>Efficient Generalized Low-Rank Tensor Contextual Bandits. (arXiv:2311.01771v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01771</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we aim to build a novel bandits algorithm that is capable of
fully harnessing the power of multi-dimensional data and the inherent
non-linearity of reward functions to provide high-usable and accountable
decision-making services. To this end, we introduce a generalized low-rank
tensor contextual bandits model in which an action is formed from three feature
vectors, and thus can be represented by a tensor. In this formulation, the
reward is determined through a generalized linear function applied to the inner
product of the action&apos;s feature tensor and a fixed but unknown parameter tensor
with a low tubal rank. To effectively achieve the trade-off between exploration
and exploitation, we introduce a novel algorithm called &quot;Generalized Low-Rank
Tensor Exploration Subspace then Refine&quot; (G-LowTESTR). This algorithm first
collects raw data to explore the intrinsic low-rank tensor subspace information
embedded in the decision-making scenario, and then converts the original
problem into an almost lower-dimensional generalized linear contextual bandits
problem. Rigorous theoretical analysis shows that the regret bound of
G-LowTESTR is superior to those in vectorization and matricization cases. We
conduct a series of simulations and real data experiments to further highlight
the effectiveness of G-LowTESTR, leveraging its ability to capitalize on the
low-rank tensor structure for enhanced learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1&quot;&gt;Qianxin Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yiyang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shaojie Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01777">
<title>CheX-Nomaly: Segmenting Lung Abnormalities from Chest Radiographs using Machine Learning. (arXiv:2311.01777v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.01777</link>
<description rdf:parseType="Literal">&lt;p&gt;The global challenge in chest radiograph X-ray (CXR) abnormalities often
being misdiagnosed is primarily associated with perceptual errors, where
healthcare providers struggle to accurately identify the location of
abnormalities, rather than misclassification errors. We currently address this
problem through disease-specific segmentation models. Unfortunately, these
models cannot be released in the field due to their lack of generalizability
across all thoracic diseases. A binary model tends to perform poorly when it
encounters a disease that isn&apos;t represented in the dataset. We present
CheX-nomaly: a binary localization U-net model that leverages transfer learning
techniques with the incorporation of an innovative contrastive learning
approach. Trained on the VinDr-CXR dataset, which encompasses 14 distinct
diseases in addition to &apos;no finding&apos; cases, my model achieves generalizability
across these 14 diseases and others it has not seen before. We show that we can
significantly improve the generalizability of an abnormality localization model
by incorporating a contrastive learning method and dissociating the bounding
boxes with its disease class. We also introduce a new loss technique to apply
to enhance the U-nets performance on bounding box segmentation. By introducing
CheX-nomaly, we offer a promising solution to enhance the precision of chest
disease diagnosis, with a specific focus on reducing the significant number of
perceptual errors in healthcare.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sanskriti Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01796">
<title>Learning to Augment Distributions for Out-of-Distribution Detection. (arXiv:2311.01796v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01796</link>
<description rdf:parseType="Literal">&lt;p&gt;Open-world classification systems should discern out-of-distribution (OOD)
data whose labels deviate from those of in-distribution (ID) cases, motivating
recent studies in OOD detection. Advanced works, despite their promising
progress, may still fail in the open world, owing to the lack of knowledge
about unseen OOD data in advance. Although one can access auxiliary OOD data
(distinct from unseen ones) for model training, it remains to analyze how such
auxiliary data will work in the open world. To this end, we delve into such a
problem from a learning theory perspective, finding that the distribution
discrepancy between the auxiliary and the unseen real OOD data is the key to
affecting the open-world detection performance. Accordingly, we propose
Distributional-Augmented OOD Learning (DAL), alleviating the OOD distribution
discrepancy by crafting an OOD distribution set that contains all distributions
in a Wasserstein ball centered on the auxiliary OOD distribution. We justify
that the predictor trained over the worst OOD data in the ball can shrink the
OOD distribution discrepancy, thus improving the open-world detection
performance given only the auxiliary OOD data. We conduct extensive evaluations
across representative OOD detection setups, demonstrating the superiority of
our DAL over its advanced counterparts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qizhou Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1&quot;&gt;Zhen Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yonggang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Feng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yixuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bo Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01797">
<title>On the Generalization Properties of Diffusion Models. (arXiv:2311.01797v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01797</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models are a class of generative models that serve to establish a
stochastic transport map between an empirically observed, yet unknown, target
distribution and a known prior. Despite their remarkable success in real-world
applications, a theoretical understanding of their generalization capabilities
remains underdeveloped. This work embarks on a comprehensive theoretical
exploration of the generalization attributes of diffusion models. We establish
theoretical estimates of the generalization gap that evolves in tandem with the
training dynamics of score-based diffusion models, suggesting a polynomially
small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$
and the model capacity $m$, evading the curse of dimensionality (i.e., not
exponentially large in the data dimension) when early-stopped. Furthermore, we
extend our quantitative analysis to a data-dependent scenario, wherein target
distributions are portrayed as a succession of densities with progressively
increasing distances between modes. This precisely elucidates the adverse
effect of &quot;modes shift&quot; in ground truths on the model generalization. Moreover,
these estimates are not solely theoretical constructs but have also been
confirmed through numerical simulations. Our findings contribute to the
rigorous understanding of diffusion models&apos; generalization properties and
provide insights that may guide practical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Puheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huishuai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1&quot;&gt;Jiang Bian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01806">
<title>Sketching for Convex and Nonconvex Regularized Least Squares with Sharp Guarantees. (arXiv:2311.01806v1 [math.OC])</title>
<link>http://arxiv.org/abs/2311.01806</link>
<description rdf:parseType="Literal">&lt;p&gt;Randomized algorithms are important for solving large-scale optimization
problems. In this paper, we propose a fast sketching algorithm for least square
problems regularized by convex or nonconvex regularization functions, Sketching
for Regularized Optimization (SRO). Our SRO algorithm first generates a sketch
of the original data matrix, then solves the sketched problem. Different from
existing randomized algorithms, our algorithm handles general Frechet
subdifferentiable regularization functions in an unified framework. We present
general theoretical result for the approximation error between the optimization
results of the original problem and the sketched problem for regularized least
square problems which can be convex or nonconvex. For arbitrary convex
regularizer, relative-error bound is proved for the approximation error.
Importantly, minimax rates for sparse signal estimation by solving the sketched
sparse convex or nonconvex learning problems are also obtained using our
general theoretical result under mild conditions. To the best of our knowledge,
our results are among the first to demonstrate minimax rates for convex or
nonconvex sparse learning problem by sketching under a unified theoretical
framework. We further propose an iterative sketching algorithm which reduces
the approximation error exponentially by iteratively invoking the sketching
algorithm. Experimental results demonstrate the effectiveness of the proposed
SRO and Iterative SRO algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Ping Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01829">
<title>Mix-ME: Quality-Diversity for Multi-Agent Learning. (arXiv:2311.01829v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01829</link>
<description rdf:parseType="Literal">&lt;p&gt;In many real-world systems, such as adaptive robotics, achieving a single,
optimised solution may be insufficient. Instead, a diverse set of
high-performing solutions is often required to adapt to varying contexts and
requirements. This is the realm of Quality-Diversity (QD), which aims to
discover a collection of high-performing solutions, each with their own unique
characteristics. QD methods have recently seen success in many domains,
including robotics, where they have been used to discover damage-adaptive
locomotion controllers. However, most existing work has focused on single-agent
settings, despite many tasks of interest being multi-agent. To this end, we
introduce Mix-ME, a novel multi-agent variant of the popular MAP-Elites
algorithm that forms new solutions using a crossover-like operator by mixing
together agents from different teams. We evaluate the proposed methods on a
variety of partially observable continuous control tasks. Our evaluation shows
that these multi-agent variants obtained by Mix-ME not only compete with
single-agent baselines but also often outperform them in multi-agent settings
under partial observability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ingvarsson_G/0/1/0/all/0/1&quot;&gt;Gar&amp;#xf0;ar Ingvarsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samvelyan_M/0/1/0/all/0/1&quot;&gt;Mikayel Samvelyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_B/0/1/0/all/0/1&quot;&gt;Bryan Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flageat_M/0/1/0/all/0/1&quot;&gt;Manon Flageat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1&quot;&gt;Antoine Cully&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1&quot;&gt;Tim Rockt&amp;#xe4;schel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01840">
<title>Spectral Clustering of Attributed Multi-relational Graphs. (arXiv:2311.01840v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01840</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph clustering aims at discovering a natural grouping of the nodes such
that similar nodes are assigned to a common cluster. Many different algorithms
have been proposed in the literature: for simple graphs, for graphs with
attributes associated to nodes, and for graphs where edges represent different
types of relations among nodes. However, complex data in many domains can be
represented as both attributed and multi-relational networks.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose SpectralMix, a joint dimensionality reduction
technique for multi-relational graphs with categorical node attributes.
SpectralMix integrates all information available from the attributes, the
different types of relations, and the graph structure to enable a sound
interpretation of the clustering results. Moreover, it generalizes existing
techniques: it reduces to spectral embedding and clustering when only applied
to a single graph and to homogeneity analysis when applied to categorical data.
Experiments conducted on several real-world datasets enable us to detect
dependencies between graph structure and categorical attributes, moreover, they
exhibit the superiority of SpectralMix over existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadikaj_Y/0/1/0/all/0/1&quot;&gt;Ylli Sadikaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velaj_Y/0/1/0/all/0/1&quot;&gt;Yllka Velaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behzadi_S/0/1/0/all/0/1&quot;&gt;Sahar Behzadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plant_C/0/1/0/all/0/1&quot;&gt;Claudia Plant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01854">
<title>An Ensemble Machine Learning Approach for Screening Covid-19 based on Urine Parameters. (arXiv:2311.01854v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.01854</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid spread of COVID-19 and the emergence of new variants underscore the
importance of effective screening measures. Rapid diagnosis and subsequent
quarantine of infected individuals can prevent further spread of the virus in
society. While PCR tests are the gold standard for COVID-19 diagnosis, they are
costly and time-consuming. In contrast, urine test strips are an inexpensive,
non-invasive, and rapidly obtainable screening method that can provide
important information about a patient&apos;s health status. In this study, we
collected a new dataset and used the RGB (Red Green Blue) color space of urine
test strips parameters to detect the health status of individuals. To improve
the accuracy of our model, we converted the RGB space to 10 additional color
spaces. After evaluating four different machine learning models, we proposed a
new ensemble model based on a multi-layer perceptron neural network. Although
the initial results were not strong, we were able to improve the model&apos;s
screening performance for COVID-19 by removing uncertain regions of the model
space. Ultimately, our model achieved a screening accuracy of 80% based on
urine parameters. Our results suggest that urine test strips can be a useful
tool for COVID-19 screening, particularly in resource-constrained settings
where PCR testing may not be feasible. Further research is needed to validate
our findings and explore the potential role of urine test strips in COVID-19
diagnosis and management.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Moayedi_B/0/1/0/all/0/1&quot;&gt;Behzad Moayedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Keramatfar_A/0/1/0/all/0/1&quot;&gt;Abdalsamad Keramatfar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Goldani_M/0/1/0/all/0/1&quot;&gt;Mohammad Hadi Goldani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fallahi_M/0/1/0/all/0/1&quot;&gt;Mohammad Javad Fallahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jahangirisisakht_A/0/1/0/all/0/1&quot;&gt;Alborz Jahangirisisakht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Saboori_M/0/1/0/all/0/1&quot;&gt;Mohammad Saboori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+badiei_L/0/1/0/all/0/1&quot;&gt;Leyla badiei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01864">
<title>SortNet: Learning To Rank By a Neural-Based Sorting Algorithm. (arXiv:2311.01864v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01864</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of relevance ranking consists of sorting a set of objects with
respect to a given criterion. Since users may prefer different relevance
criteria, the ranking algorithms should be adaptable to the user needs. Two
main approaches exist in literature for the task of learning to rank: 1) a
score function, learned by examples, which evaluates the properties of each
object yielding an absolute relevance value that can be used to order the
objects or 2) a pairwise approach, where a &quot;preference function&quot; is learned
using pairs of objects to define which one has to be ranked first. In this
paper, we present SortNet, an adaptive ranking algorithm which orders objects
using a neural network as a comparator. The neural network training set
provides examples of the desired ordering between pairs of items and it is
constructed by an iterative procedure which, at each iteration, adds the most
informative training examples. Moreover, the comparator adopts a connectionist
architecture that is particularly suited for implementing a preference
function. We also prove that such an architecture has the universal
approximation property and can implement a wide class of functions. Finally,
the proposed algorithm is evaluated on the LETOR dataset showing promising
performances in comparison with other state of the art algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigutini_L/0/1/0/all/0/1&quot;&gt;Leonardo Rigutini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papini_T/0/1/0/all/0/1&quot;&gt;Tiziano Papini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maggini_M/0/1/0/all/0/1&quot;&gt;Marco Maggini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scarselli_F/0/1/0/all/0/1&quot;&gt;Franco Scarselli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01875">
<title>Enhancing Functional Data Analysis with Sequential Neural Networks: Advantages and Comparative Study. (arXiv:2311.01875v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01875</link>
<description rdf:parseType="Literal">&lt;p&gt;Functional Data Analysis (FDA) is a statistical domain developed to handle
functional data characterized by high dimensionality and complex data
structures. Sequential Neural Networks (SNNs) are specialized neural networks
capable of processing sequence data, a fundamental aspect of functional data.
Despite their great flexibility in modeling functional data, SNNs have been
inadequately employed in the FDA community. One notable advantage of SNNs is
the ease of implementation, making them accessible to a broad audience beyond
academia. Conversely, FDA-based methodologies present challenges, particularly
for practitioners outside the field, due to their intricate complexity. In
light of this, we propose utilizing SNNs in FDA applications and demonstrate
their effectiveness through comparative analyses against popular FDA regression
models based on numerical experiments and real-world data analysis. SNN
architectures allow us to surpass the limitations of traditional FDA methods,
offering scalability, flexibility, and improved analytical performance. Our
findings highlight the potential of SNN-based methodologies as powerful tools
for data applications involving functional data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;J. Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;J. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;M. Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jadhav_S/0/1/0/all/0/1&quot;&gt;S. Jadhav&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01885">
<title>Domain Randomization via Entropy Maximization. (arXiv:2311.01885v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01885</link>
<description rdf:parseType="Literal">&lt;p&gt;Varying dynamics parameters in simulation is a popular Domain Randomization
(DR) approach for overcoming the reality gap in Reinforcement Learning (RL).
Nevertheless, DR heavily hinges on the choice of the sampling distribution of
the dynamics parameters, since high variability is crucial to regularize the
agent&apos;s behavior but notoriously leads to overly conservative policies when
randomizing excessively. In this paper, we propose a novel approach to address
sim-to-real transfer, which automatically shapes dynamics distributions during
training in simulation without requiring real-world data. We introduce DOmain
RAndomization via Entropy MaximizatiON (DORAEMON), a constrained optimization
problem that directly maximizes the entropy of the training distribution while
retaining generalization capabilities. In achieving this, DORAEMON gradually
increases the diversity of sampled dynamics parameters as long as the
probability of success of the current policy is sufficiently high. We
empirically validate the consistent benefits of DORAEMON in obtaining highly
adaptive and generalizable policies, i.e. solving the task at hand across the
widest range of dynamics parameters, as opposed to representative baselines
from the DR literature. Notably, we also demonstrate the Sim2Real applicability
of DORAEMON through its successful zero-shot transfer in a robotic manipulation
setup under unknown real-world parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiboni_G/0/1/0/all/0/1&quot;&gt;Gabriele Tiboni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klink_P/0/1/0/all/0/1&quot;&gt;Pascal Klink&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1&quot;&gt;Jan Peters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tommasi_T/0/1/0/all/0/1&quot;&gt;Tatiana Tommasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DEramo_C/0/1/0/all/0/1&quot;&gt;Carlo D&amp;#x27;Eramo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalvatzaki_G/0/1/0/all/0/1&quot;&gt;Georgia Chalvatzaki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01888">
<title>Learning Sparse Codes with Entropy-Based ELBOs. (arXiv:2311.01888v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01888</link>
<description rdf:parseType="Literal">&lt;p&gt;Standard probabilistic sparse coding assumes a Laplace prior, a linear
mapping from latents to observables, and Gaussian observable distributions. We
here derive a solely entropy-based learning objective for the parameters of
standard sparse coding. The novel variational objective has the following
features: (A) unlike MAP approximations, it uses non-trivial posterior
approximations for probabilistic inference; (B) unlike for previous non-trivial
approximations, the novel objective is fully analytical; and (C) the objective
allows for a novel principled form of annealing. The objective is derived by
first showing that the standard ELBO objective converges to a sum of entropies,
which matches similar recent results for generative models with Gaussian
priors. The conditions under which the ELBO becomes equal to entropies are then
shown to have analytical solutions, which leads to the fully analytical
objective. Numerical experiments are used to demonstrate the feasibility of
learning with such entropy-based ELBOs. We investigate different posterior
approximations including Gaussians with correlated latents and deep amortized
approximations. Furthermore, we numerically investigate entropy-based annealing
which results in improved learning. Our main contributions are theoretical,
however, and they are twofold: (1) for non-trivial posterior approximations, we
provide the (to the knowledge of the authors) first analytical ELBO objective
for standard probabilistic sparse coding; and (2) we provide the first
demonstration on how a recently shown convergence of the ELBO to entropy sums
can be used for learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Velychko_D/0/1/0/all/0/1&quot;&gt;Dmytro Velychko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Damm_S/0/1/0/all/0/1&quot;&gt;Simon Damm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fischer_A/0/1/0/all/0/1&quot;&gt;Asja Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lucke_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rg L&amp;#xfc;cke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01900">
<title>Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization. (arXiv:2311.01900v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01900</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantifying the difference between two probability density functions, $p$ and
$q$, using available data, is a fundamental problem in Statistics and Machine
Learning. A usual approach for addressing this problem is the likelihood-ratio
estimation (LRE) between $p$ and $q$, which -- to our best knowledge -- has
been investigated mainly for the offline case. This paper contributes by
introducing a new framework for online non-parametric LRE (OLRE) for the
setting where pairs of iid observations $(x_t \sim p, x&apos;_t \sim q)$ are
observed over time. The non-parametric nature of our approach has the advantage
of being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the
recent advances in Kernel Methods and functional minimization to develop an
estimator that can be efficiently updated online. We provide theoretical
guarantees for the performance of the OLRE method along with empirical
validation in synthetic experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Concha_A/0/1/0/all/0/1&quot;&gt;Alejandro de la Concha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vayatis_N/0/1/0/all/0/1&quot;&gt;Nicolas Vayatis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kalogeratos_A/0/1/0/all/0/1&quot;&gt;Argyris Kalogeratos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01902">
<title>High Precision Causal Model Evaluation with Conditional Randomization. (arXiv:2311.01902v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01902</link>
<description rdf:parseType="Literal">&lt;p&gt;The gold standard for causal model evaluation involves comparing model
predictions with true effects estimated from randomized controlled trials
(RCT). However, RCTs are not always feasible or ethical to perform. In
contrast, conditionally randomized experiments based on inverse probability
weighting (IPW) offer a more realistic approach but may suffer from high
estimation variance. To tackle this challenge and enhance causal model
evaluation in real-world conditional randomization settings, we introduce a
novel low-variance estimator for causal error, dubbed as the pairs estimator.
By applying the same IPW estimator to both the model and true experimental
effects, our estimator effectively cancels out the variance due to IPW and
achieves a smaller asymptotic variance. Empirical studies demonstrate the
improved of our estimator, highlighting its potential on achieving near-RCT
performance. Our method offers a simple yet powerful solution to evaluate
causal inference models in conditional randomization settings without
complicated modification of the IPW estimator itself, paving the way for more
robust and reliable model assessments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chao Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cheng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01906">
<title>Simplifying Transformer Blocks. (arXiv:2311.01906v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01906</link>
<description rdf:parseType="Literal">&lt;p&gt;A simple design recipe for deep Transformers is to compose identical building
blocks. But standard transformer blocks are far from simple, interweaving
attention and MLP sub-blocks with skip connections &amp;amp; normalisation layers in
precise arrangements. This complexity leads to brittle architectures, where
seemingly minor changes can significantly reduce training speed, or render
models untrainable.
&lt;/p&gt;
&lt;p&gt;In this work, we ask to what extent the standard transformer block can be
simplified? Combining signal propagation theory and empirical observations, we
motivate modifications that allow many block components to be removed with no
loss of training speed, including skip connections, projection or value
parameters, sequential sub-blocks and normalisation layers. In experiments on
both autoregressive decoder-only and BERT encoder-only models, our simplified
transformers emulate the per-update training speed and performance of standard
transformers, while enjoying 15% faster training throughput, and using 15%
fewer parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1&quot;&gt;Bobby He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1&quot;&gt;Thomas Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01918">
<title>Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review. (arXiv:2311.01918v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01918</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid development of artificial intelligence, large language models
(LLMs) have shown promising capabilities in mimicking human-level language
comprehension and reasoning. This has sparked significant interest in applying
LLMs to enhance various aspects of healthcare, ranging from medical education
to clinical decision support. However, medicine involves multifaceted data
modalities and nuanced reasoning skills, presenting challenges for integrating
LLMs. This paper provides a comprehensive review on the applications and
implications of LLMs in medicine. It begins by examining the fundamental
applications of general-purpose and specialized LLMs, demonstrating their
utilities in knowledge retrieval, research support, clinical workflow
automation, and diagnostic assistance. Recognizing the inherent multimodality
of medicine, the review then focuses on multimodal LLMs, investigating their
ability to process diverse data types like medical imaging and EHRs to augment
diagnostic accuracy. To address LLMs&apos; limitations regarding personalization and
complex clinical reasoning, the paper explores the emerging development of
LLM-powered autonomous agents for healthcare. Furthermore, it summarizes the
evaluation methodologies for assessing LLMs&apos; reliability and safety in medical
contexts. Overall, this review offers an extensive analysis on the
transformative potential of LLMs in modern medicine. It also highlights the
pivotal need for continuous optimizations and ethical oversight before these
models can be effectively integrated into clinical practice. Visit
https://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying
GitHub repository containing latest papers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1&quot;&gt;Mingze Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_P/0/1/0/all/0/1&quot;&gt;Peng Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1&quot;&gt;Jiajia Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yunhao Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zifan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yi Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jie Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Li Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1&quot;&gt;Lin Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1&quot;&gt;Bin Dong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01927">
<title>GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling. (arXiv:2311.01927v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01927</link>
<description rdf:parseType="Literal">&lt;p&gt;Linear Recurrence has proven to be a powerful tool for modeling long
sequences efficiently. In this work, we show that existing models fail to take
full advantage of its potential. Motivated by this finding, we develop
GateLoop, a foundational sequence model that generalizes linear recurrent
models such as S4, S5, LRU and RetNet, by employing data-controlled state
transitions. Utilizing this theoretical advance, GateLoop empirically
outperforms existing models for auto-regressive language modeling. Our method
comes with a low-cost $O(l)$ recurrent mode and an efficient $O(l \log_{2} l)$
parallel mode making use of highly optimized associative scan implementations.
Furthermore, we derive an $O(l^2)$ surrogate attention mode, revealing
remarkable implications for Transformer and recently proposed architectures.
Specifically, we prove that our approach can be interpreted as providing
data-controlled relative-positional information to Attention. While many
existing models solely rely on data-controlled cumulative sums for context
aggregation, our findings suggest that incorporating data-controlled complex
cumulative products may be a crucial step towards more powerful sequence
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katsch_T/0/1/0/all/0/1&quot;&gt;Tobias Katsch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01933">
<title>ForecastPFN: Synthetically-Trained Zero-Shot Forecasting. (arXiv:2311.01933v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01933</link>
<description rdf:parseType="Literal">&lt;p&gt;The vast majority of time-series forecasting approaches require a substantial
training dataset. However, many real-life forecasting applications have very
little initial observations, sometimes just 40 or fewer. Thus, the
applicability of most forecasting methods is restricted in data-sparse
commercial applications. While there is recent work in the setting of very
limited initial data (so-called `zero-shot&apos; forecasting), its performance is
inconsistent depending on the data used for pretraining. In this work, we take
a different approach and devise ForecastPFN, the first zero-shot forecasting
model trained purely on a novel synthetic data distribution. ForecastPFN is a
prior-data fitted network, trained to approximate Bayesian inference, which can
make predictions on a new time series dataset in a single forward pass. Through
extensive experiments, we show that zero-shot predictions made by ForecastPFN
are more accurate and faster compared to state-of-the-art forecasting methods,
even when the other methods are allowed to train on hundreds of additional
in-distribution data points.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dooley_S/0/1/0/all/0/1&quot;&gt;Samuel Dooley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khurana_G/0/1/0/all/0/1&quot;&gt;Gurnoor Singh Khurana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohapatra_C/0/1/0/all/0/1&quot;&gt;Chirag Mohapatra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naidu_S/0/1/0/all/0/1&quot;&gt;Siddartha Naidu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1&quot;&gt;Colin White&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01953">
<title>Optimistic Multi-Agent Policy Gradient for Cooperative Tasks. (arXiv:2311.01953v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01953</link>
<description rdf:parseType="Literal">&lt;p&gt;\textit{Relative overgeneralization} (RO) occurs in cooperative multi-agent
learning tasks when agents converge towards a suboptimal joint policy due to
overfitting to suboptimal behavior of other agents. In early work, optimism has
been shown to mitigate the \textit{RO} problem when using tabular Q-learning.
However, with function approximation optimism can amplify overestimation and
thus fail on complex tasks. On the other hand, recent deep multi-agent policy
gradient (MAPG) methods have succeeded in many complex tasks but may fail with
severe \textit{RO}. We propose a general, yet simple, framework to enable
optimistic updates in MAPG methods and alleviate the RO problem. Specifically,
we employ a \textit{Leaky ReLU} function where a single hyperparameter selects
the degree of optimism to reshape the advantages when updating the policy.
Intuitively, our method remains optimistic toward individual actions with lower
returns which are potentially caused by other agents&apos; sub-optimal behavior
during learning. The optimism prevents the individual agents from quickly
converging to a local optimum. We also provide a formal analysis from an
operator view to understand the proposed advantage transformation. In extensive
evaluations on diverse sets of tasks, including illustrative matrix games,
complex \textit{Multi-agent MuJoCo} and \textit{Overcooked} benchmarks, the
proposed method\footnote{Code can be found at
\url{https://github.com/wenshuaizhao/optimappo}.} outperforms strong baselines
on 13 out of 19 tested tasks and matches the performance on the rest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wenshuai Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yi Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannala_J/0/1/0/all/0/1&quot;&gt;Juho Kannala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1&quot;&gt;Joni Pajarinen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01960">
<title>Hardness of Low Rank Approximation of Entrywise Transformed Matrix Products. (arXiv:2311.01960v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2311.01960</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by fast algorithms in natural language processing, we study low rank
approximation in the entrywise transformed setting where we want to find a good
rank $k$ approximation to $f(U \cdot V)$, where $U, V^\top \in \mathbb{R}^{n
\times r}$ are given, $r = O(\log(n))$, and $f(x)$ is a general scalar
function. Previous work in sublinear low rank approximation has shown that if
both (1) $U = V^\top$ and (2) $f(x)$ is a PSD kernel function, then there is an
$O(nk^{\omega-1})$ time constant relative error approximation algorithm, where
$\omega \approx 2.376$ is the exponent of matrix multiplication. We give the
first conditional time hardness results for this problem, demonstrating that
both conditions (1) and (2) are in fact necessary for getting better than
$n^{2-o(1)}$ time for a relative error low rank approximation for a wide class
of functions. We give novel reductions from the Strong Exponential Time
Hypothesis (SETH) that rely on lower bounding the leverage scores of flat
sparse vectors and hold even when the rank of the transformed matrix $f(UV)$
and the target rank are $n^{o(1)}$, and when $U = V^\top$. Furthermore, even
when $f(x) = x^p$ is a simple polynomial, we give runtime lower bounds in the
case when $U \neq V^\top$ of the form $\Omega(\min(n^{2-o(1)}, \Omega(2^p)))$.
Lastly, we demonstrate that our lower bounds are tight by giving an $O(n \cdot
\text{poly}(k, 2^p, 1/\epsilon))$ time relative error approximation algorithm
and a fast $O(n \cdot \text{poly}(k, p, 1/\epsilon))$ additive error
approximation using fast tensor-based sketching. Additionally, since our low
rank algorithms rely on matrix-vector product subroutines, our lower bounds
extend to show that computing $f(UV)W$, for even a small matrix $W$, requires
$\Omega(n^{2-o(1)})$ time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1&quot;&gt;Tamas Sarlos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1&quot;&gt;Xingyou Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David Woodruff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiuyi/0/1/0/all/0/1&quot;&gt;Qiuyi&lt;/a&gt; (Richard) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang/0/1/0/all/0/1&quot;&gt;Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01967">
<title>The language of prompting: What linguistic properties make a prompt successful?. (arXiv:2311.01967v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01967</link>
<description rdf:parseType="Literal">&lt;p&gt;The latest generation of LLMs can be prompted to achieve impressive zero-shot
or few-shot performance in many NLP tasks. However, since performance is highly
sensitive to the choice of prompts, considerable effort has been devoted to
crowd-sourcing prompts or designing methods for prompt optimisation. Yet, we
still lack a systematic understanding of how linguistic properties of prompts
correlate with task performance. In this work, we investigate how LLMs of
different sizes, pre-trained and instruction-tuned, perform on prompts that are
semantically equivalent, but vary in linguistic structure. We investigate both
grammatical properties such as mood, tense, aspect and modality, as well as
lexico-semantic variation through the use of synonyms. Our findings contradict
the common assumption that LLMs achieve optimal performance on lower perplexity
prompts that reflect language use in pretraining or instruction-tuning data.
Prompts transfer poorly between datasets or models, and performance cannot
generally be explained by perplexity, word frequency, ambiguity or prompt
length. Based on our results, we put forward a proposal for a more robust and
comprehensive evaluation standard for prompting research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leidinger_A/0/1/0/all/0/1&quot;&gt;Alina Leidinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rooij_R/0/1/0/all/0/1&quot;&gt;Robert van Rooij&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1&quot;&gt;Ekaterina Shutova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01968">
<title>Latent Diffusion Model for Conditional Reservoir Facies Generation. (arXiv:2311.01968v1 [physics.geo-ph])</title>
<link>http://arxiv.org/abs/2311.01968</link>
<description rdf:parseType="Literal">&lt;p&gt;Creating accurate and geologically realistic reservoir facies based on
limited measurements is crucial for field development and reservoir management,
especially in the oil and gas sector. Traditional two-point geostatistics,
while foundational, often struggle to capture complex geological patterns.
Multi-point statistics offers more flexibility, but comes with its own
challenges. With the rise of Generative Adversarial Networks (GANs) and their
success in various fields, there has been a shift towards using them for facies
generation. However, recent advances in the computer vision domain have shown
the superiority of diffusion models over GANs. Motivated by this, a novel
Latent Diffusion Model is proposed, which is specifically designed for
conditional generation of reservoir facies. The proposed model produces
high-fidelity facies realizations that rigorously preserve conditioning data.
It significantly outperforms a GAN-based alternative.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Daesoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ovanger_O/0/1/0/all/0/1&quot;&gt;Oscar Ovanger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Eidsvik_J/0/1/0/all/0/1&quot;&gt;Jo Eidsvik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Aune_E/0/1/0/all/0/1&quot;&gt;Erlend Aune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Skauvold_J/0/1/0/all/0/1&quot;&gt;Jacob Skauvold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hauge_R/0/1/0/all/0/1&quot;&gt;Ragnar Hauge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01990">
<title>Conditions on Preference Relations that Guarantee the Existence of Optimal Policies. (arXiv:2311.01990v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01990</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning from Preferential Feedback (LfPF) plays an essential role in
training Large Language Models, as well as certain types of interactive
learning agents. However, a substantial gap exists between the theory and
application of LfPF algorithms. Current results guaranteeing the existence of
optimal policies in LfPF problems assume that both the preferences and
transition dynamics are determined by a Markov Decision Process. We introduce
the Direct Preference Process, a new framework for analyzing LfPF problems in
partially-observable, non-Markovian environments. Within this framework, we
establish conditions that guarantee the existence of optimal policies by
considering the ordinal structure of the preferences. Using the von
Neumann-Morgenstern Expected Utility Theorem, we show that the Direct
Preference Process generalizes the standard reinforcement learning problem. Our
findings narrow the gap between the empirical success and theoretical
understanding of LfPF algorithms and provide future practitioners with the
tools necessary for a more principled design of LfPF agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carr_J/0/1/0/all/0/1&quot;&gt;Jonathan Colaco Carr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panangaden_P/0/1/0/all/0/1&quot;&gt;Prakash Panangaden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1&quot;&gt;Doina Precup&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01994">
<title>Obtaining Explainable Classification Models using Distributionally Robust Optimization. (arXiv:2311.01994v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01994</link>
<description rdf:parseType="Literal">&lt;p&gt;Model explainability is crucial for human users to be able to interpret how a
proposed classifier assigns labels to data based on its feature values. We
study generalized linear models constructed using sets of feature value rules,
which can capture nonlinear dependencies and interactions. An inherent
trade-off exists between rule set sparsity and its prediction accuracy. It is
computationally expensive to find the right choice of sparsity -- e.g., via
cross-validation -- with existing methods. We propose a new formulation to
learn an ensemble of rule sets that simultaneously addresses these competing
factors. Good generalization is ensured while keeping computational costs low
by utilizing distributionally robust optimization. The formulation utilizes
column generation to efficiently search the space of rule sets and constructs a
sparse ensemble of rule sets, in contrast with techniques like random forests
or boosting and their variants. We present theoretical results that motivate
and justify the use of our distributionally robust formulation. Extensive
numerical experiments establish that our method improves over competing methods
-- on a large set of publicly available binary classification problem instances
-- with respect to one or more of the following metrics: generalization
quality, computational cost, and explainability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dash_S/0/1/0/all/0/1&quot;&gt;Sanjeeb Dash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Soumyadip Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goncalves_J/0/1/0/all/0/1&quot;&gt;Joao Goncalves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Squillante_M/0/1/0/all/0/1&quot;&gt;Mark S. Squillante&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01996">
<title>Detection of keratoconus Diseases using deep Learning. (arXiv:2311.01996v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.01996</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the most serious corneal disorders, keratoconus is difficult to
diagnose in its early stages and can result in blindness. This illness, which
often appears in the second decade of life, affects people of all sexes and
races. Convolutional neural networks (CNNs), one of the deep learning
approaches, have recently come to light as particularly promising tools for the
accurate and timely diagnosis of keratoconus. The purpose of this study was to
evaluate how well different D-CNN models identified keratoconus-related
diseases. To be more precise, we compared five different CNN-based deep
learning architectures (DenseNet201, InceptionV3, MobileNetV2, VGG19,
Xception). In our comprehensive experimental analysis, the DenseNet201-based
model performed very well in keratoconus disease identification in our
extensive experimental research. This model outperformed its D-CNN equivalents,
with an astounding accuracy rate of 89.14% in three crucial classes:
Keratoconus, Normal, and Suspect. The results demonstrate not only the
stability and robustness of the model but also its practical usefulness in
real-world applications for accurate and dependable keratoconus identification.
In addition, D-CNN DenseNet201 performs extraordinarily well in terms of
precision, recall rates, and F1 scores in addition to accuracy. These measures
validate the model&apos;s usefulness as an effective diagnostic tool by highlighting
its capacity to reliably detect instances of keratoconus and to reduce false
positives and negatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Haque_A/0/1/0/all/0/1&quot;&gt;AKM Enzam-Ul Haque&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rabbany_G/0/1/0/all/0/1&quot;&gt;Golam Rabbany&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Siam_M/0/1/0/all/0/1&quot;&gt;Md. Siam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02000">
<title>High Probability Convergence of Adam Under Unbounded Gradients and Affine Variance Noise. (arXiv:2311.02000v1 [math.OC])</title>
<link>http://arxiv.org/abs/2311.02000</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the convergence of the Adaptive Moment Estimation
(Adam) algorithm under unconstrained non-convex smooth stochastic
optimizations. Despite the widespread usage in machine learning areas, its
theoretical properties remain limited. Prior researches primarily investigated
Adam&apos;s convergence from an expectation view, often necessitating strong
assumptions like uniformly stochastic bounded gradients or problem-dependent
knowledge in prior. As a result, the applicability of these findings in
practical real-world scenarios has been constrained. To overcome these
limitations, we provide a deep analysis and show that Adam could converge to
the stationary point in high probability with a rate of $\mathcal{O}\left({\rm
poly}(\log T)/\sqrt{T}\right)$ under coordinate-wise &quot;affine&quot; variance noise,
not requiring any bounded gradient assumption and any problem-dependent
knowledge in prior to tune hyper-parameters. Additionally, it is revealed that
Adam confines its gradients&apos; magnitudes within an order of
$\mathcal{O}\left({\rm poly}(\log T)\right)$. Finally, we also investigate a
simplified version of Adam without one of the corrective terms and obtain a
convergence rate that is adaptive to the noise level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Yusu Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Junhong Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02002">
<title>A Variational Perspective on High-Resolution ODEs. (arXiv:2311.02002v1 [math.OC])</title>
<link>http://arxiv.org/abs/2311.02002</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider unconstrained minimization of smooth convex functions. We propose
a novel variational perspective using forced Euler-Lagrange equation that
allows for studying high-resolution ODEs. Through this, we obtain a faster
convergence rate for gradient norm minimization using Nesterov&apos;s accelerated
gradient method. Additionally, we show that Nesterov&apos;s method can be
interpreted as a rate-matching discretization of an appropriately chosen
high-resolution ODE. Finally, using the results from the new variational
perspective, we propose a stochastic method for noisy gradients. Several
numerical experiments compare and illustrate our stochastic algorithm with
state of the art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Maskan_H/0/1/0/all/0/1&quot;&gt;Hoomaan Maskan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zygalakis_K/0/1/0/all/0/1&quot;&gt;Konstantinos C. Zygalakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yurtsever_A/0/1/0/all/0/1&quot;&gt;Alp Yurtsever&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02013">
<title>Score Models for Offline Goal-Conditioned Reinforcement Learning. (arXiv:2311.02013v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.02013</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with
learning to achieve multiple goals in an environment purely from offline
datasets using sparse reward functions. Offline GCRL is pivotal for developing
generalist agents capable of leveraging pre-existing datasets to learn diverse
and reusable skills without hand-engineering reward functions. However,
contemporary approaches to GCRL based on supervised learning and contrastive
learning are often suboptimal in the offline setting. An alternative
perspective on GCRL optimizes for occupancy matching, but necessitates learning
a discriminator, which subsequently serves as a pseudo-reward for downstream
RL. Inaccuracies in the learned discriminator can cascade, negatively
influencing the resulting policy. We present a novel approach to GCRL under a
new lens of mixture-distribution matching, leading to our discriminator-free
method: SMORe. The key insight is combining the occupancy matching perspective
of GCRL with a convex dual formulation to derive a learning objective that can
better leverage suboptimal offline data. SMORe learns scores or unnormalized
densities representing the importance of taking an action at a state for
reaching a particular goal. SMORe is principled and our extensive experiments
on the fully offline GCRL benchmark composed of robot manipulation and
locomotion tasks, including high-dimensional observations, show that SMORe can
outperform state-of-the-art baselines by a significant margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sikchi_H/0/1/0/all/0/1&quot;&gt;Harshit Sikchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chitnis_R/0/1/0/all/0/1&quot;&gt;Rohan Chitnis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Touati_A/0/1/0/all/0/1&quot;&gt;Ahmed Touati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geramifard_A/0/1/0/all/0/1&quot;&gt;Alborz Geramifard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Amy Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1&quot;&gt;Scott Niekum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02017">
<title>DeliverAI: Reinforcement Learning Based Distributed Path-Sharing Network for Food Deliveries. (arXiv:2311.02017v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.02017</link>
<description rdf:parseType="Literal">&lt;p&gt;Delivery of items from the producer to the consumer has experienced
significant growth over the past decade and has been greatly fueled by the
recent pandemic. Amazon Fresh, Shopify, UberEats, InstaCart, and DoorDash are
rapidly growing and are sharing the same business model of consumer items or
food delivery. Existing food delivery methods are sub-optimal because each
delivery is individually optimized to go directly from the producer to the
consumer via the shortest time path. We observe a significant scope for
reducing the costs associated with completing deliveries under the current
model. We model our food delivery problem as a multi-objective optimization,
where consumer satisfaction and delivery costs, both, need to be optimized.
Taking inspiration from the success of ride-sharing in the taxi industry, we
propose DeliverAI - a reinforcement learning-based path-sharing algorithm.
Unlike previous attempts for path-sharing, DeliverAI can provide real-time,
time-efficient decision-making using a Reinforcement learning-enabled agent
system. Our novel agent interaction scheme leverages path-sharing among
deliveries to reduce the total distance traveled while keeping the delivery
completion time under check. We generate and test our methodology vigorously on
a simulation setup using real data from the city of Chicago. Our results show
that DeliverAI can reduce the delivery fleet size by 12\%, the distance
traveled by 13%, and achieve 50% higher fleet utilization compared to the
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1&quot;&gt;Ashman Mehra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1&quot;&gt;Snehanshu Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raychoudhury_V/0/1/0/all/0/1&quot;&gt;Vaskar Raychoudhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathur_A/0/1/0/all/0/1&quot;&gt;Archana Mathur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02019">
<title>Reproducible Parameter Inference Using Bagged Posteriors. (arXiv:2311.02019v1 [stat.ME])</title>
<link>http://arxiv.org/abs/2311.02019</link>
<description rdf:parseType="Literal">&lt;p&gt;Under model misspecification, it is known that Bayesian posteriors often do
not properly quantify uncertainty about true or pseudo-true parameters. Even
more fundamentally, misspecification leads to a lack of reproducibility in the
sense that the same model will yield contradictory posteriors on independent
data sets from the true distribution. To define a criterion for reproducible
uncertainty quantification under misspecification, we consider the probability
that two confidence sets constructed from independent data sets have nonempty
overlap, and we establish a lower bound on this overlap probability that holds
for any valid confidence sets. We prove that credible sets from the standard
posterior can strongly violate this bound, particularly in high-dimensional
settings (i.e., with dimension increasing with sample size), indicating that it
is not internally coherent under misspecification. To improve reproducibility
in an easy-to-use and widely applicable way, we propose to apply bagging to the
Bayesian posterior (&quot;BayesBag&quot;&apos;); that is, to use the average of posterior
distributions conditioned on bootstrapped datasets. We motivate BayesBag from
first principles based on Jeffrey conditionalization and show that the bagged
posterior typically satisfies the overlap lower bound. Further, we prove a
Bernstein--Von Mises theorem for the bagged posterior, establishing its
asymptotic normal distribution. We demonstrate the benefits of BayesBag via
simulation experiments and an application to crime rate prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huggins_J/0/1/0/all/0/1&quot;&gt;Jonathan H. Huggins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miller_J/0/1/0/all/0/1&quot;&gt;Jeffrey W. Miller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02041">
<title>Quantum circuit synthesis with diffusion models. (arXiv:2311.02041v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2311.02041</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum computing has recently emerged as a transformative technology. Yet,
its promised advantages rely on efficiently translating quantum operations into
viable physical realizations. In this work, we use generative machine learning
models, specifically denoising diffusion models (DMs), to facilitate this
transformation. Leveraging text-conditioning, we steer the model to produce
desired quantum operations within gate-based quantum circuits. Notably, DMs
allow to sidestep during training the exponential overhead inherent in the
classical simulation of quantum dynamics -- a consistent bottleneck in
preceding ML techniques. We demonstrate the model&apos;s capabilities across two
tasks: entanglement generation and unitary compilation. The model excels at
generating new circuits and supports typical DM extensions such as masking and
editing to, for instance, align the circuit generation to the constraints of
the targeted quantum device. Given their flexibility and generalization
abilities, we envision DMs as pivotal in quantum circuit synthesis, enhancing
both practical applications but also insights into theoretical quantum
computation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Furrutter_F/0/1/0/all/0/1&quot;&gt;Florian F&amp;#xfc;rrutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Munoz_Gil_G/0/1/0/all/0/1&quot;&gt;Gorka Mu&amp;#xf1;oz-Gil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Briegel_H/0/1/0/all/0/1&quot;&gt;Hans J. Briegel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02058">
<title>LOTUS: Continual Imitation Learning for Robot Manipulation Through Unsupervised Skill Discovery. (arXiv:2311.02058v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.02058</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce LOTUS, a continual imitation learning algorithm that empowers a
physical robot to continuously and efficiently learn to solve new manipulation
tasks throughout its lifespan. The core idea behind LOTUS is constructing an
ever-growing skill library from a sequence of new tasks with a small number of
human demonstrations. LOTUS starts with a continual skill discovery process
using an open-vocabulary vision model, which extracts skills as recurring
patterns presented in unsegmented demonstrations. Continual skill discovery
updates existing skills to avoid catastrophic forgetting of previous tasks and
adds new skills to solve novel tasks. LOTUS trains a meta-controller that
flexibly composes various skills to tackle vision-based manipulation tasks in
the lifelong learning process. Our comprehensive experiments show that LOTUS
outperforms state-of-the-art baselines by over 11% in success rate, showing its
superior knowledge transfer ability compared to prior methods. More results and
videos can be found on the project website:
https://ut-austin-rpl.github.io/Lotus/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1&quot;&gt;Weikang Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yifeng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1&quot;&gt;Rutav Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yuke Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02061">
<title>Active Learning-Based Species Range Estimation. (arXiv:2311.02061v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.02061</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new active learning approach for efficiently estimating the
geographic range of a species from a limited number of on the ground
observations. We model the range of an unmapped species of interest as the
weighted combination of estimated ranges obtained from a set of different
species. We show that it is possible to generate this candidate set of ranges
by using models that have been trained on large weakly supervised community
collected observation data. From this, we develop a new active querying
approach that sequentially selects geographic locations to visit that best
reduce our uncertainty over an unmapped species&apos; range. We conduct a detailed
evaluation of our approach and compare it to existing active learning methods
using an evaluation dataset containing expert-derived ranges for one thousand
species. Our results demonstrate that our method outperforms alternative active
learning methods and approaches the performance of end-to-end trained models,
even when only using a fraction of the data. This highlights the utility of
active learning via transfer learned spatial representations for species range
estimation. It also emphasizes the value of leveraging emerging large-scale
crowdsourced datasets, not only for modeling a species&apos; range, but also for
actively discovering them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lange_C/0/1/0/all/0/1&quot;&gt;Christian Lange&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cole_E/0/1/0/all/0/1&quot;&gt;Elijah Cole&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horn_G/0/1/0/all/0/1&quot;&gt;Grant Van Horn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1&quot;&gt;Oisin Mac Aodha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02076">
<title>Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos. (arXiv:2311.02076v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.02076</link>
<description rdf:parseType="Literal">&lt;p&gt;In gradient descent dynamics of neural networks, the top eigenvalue of the
Hessian of the loss (sharpness) displays a variety of robust phenomena
throughout training. This includes early time regimes where the sharpness may
decrease during early periods of training (sharpness reduction), and later time
behavior such as progressive sharpening and edge of stability. We demonstrate
that a simple $2$-layer linear network (UV model) trained on a single training
example exhibits all of the essential sharpness phenomenology observed in
real-world scenarios. By analyzing the structure of dynamical fixed points in
function space and the vector field of function updates, we uncover the
underlying mechanisms behind these sharpness trends. Our analysis reveals (i)
the mechanism behind early sharpness reduction and progressive sharpening, (ii)
the required conditions for edge of stability, and (iii) a period-doubling
route to chaos on the edge of stability manifold as learning rate is increased.
Finally, we demonstrate that various predictions from this simplified model
generalize to real-world scenarios and discuss its limitations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalra_D/0/1/0/all/0/1&quot;&gt;Dayal Singh Kalra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1&quot;&gt;Tianyu He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barkeshli_M/0/1/0/all/0/1&quot;&gt;Maissam Barkeshli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2007.04750">
<title>Recurrent Neural-Linear Posterior Sampling for Nonstationary Contextual Bandits. (arXiv:2007.04750v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2007.04750</link>
<description rdf:parseType="Literal">&lt;p&gt;An agent in a nonstationary contextual bandit problem should balance between
exploration and the exploitation of (periodic or structured) patterns present
in its previous experiences. Handcrafting an appropriate historical context is
an attractive alternative to transform a nonstationary problem into a
stationary problem that can be solved efficiently. However, even a carefully
designed historical context may introduce spurious relationships or lack a
convenient representation of crucial information. In order to address these
issues, we propose an approach that learns to represent the relevant context
for a decision based solely on the raw history of interactions between the
agent and the environment. This approach relies on a combination of features
extracted by recurrent neural networks with a contextual linear bandit
algorithm based on posterior sampling. Our experiments on a diverse selection
of contextual and noncontextual nonstationary problems show that our recurrent
approach consistently outperforms its feedforward counterpart, which requires
handcrafted historical contexts, while being more widely applicable than
conventional nonstationary bandit algorithms. Although it is very difficult to
provide theoretical performance guarantees for our new approach, we also prove
a novel regret bound for linear posterior sampling with measurement error that
may serve as a foundation for future theoretical work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramesh_A/0/1/0/all/0/1&quot;&gt;Aditya Ramesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rauber_P/0/1/0/all/0/1&quot;&gt;Paulo Rauber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conserva_M/0/1/0/all/0/1&quot;&gt;Michelangelo Conserva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1&quot;&gt;J&amp;#xfc;rgen Schmidhuber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.08627">
<title>Minimax Quasi-Bayesian estimation in sparse canonical correlation analysis via a Rayleigh quotient function. (arXiv:2010.08627v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2010.08627</link>
<description rdf:parseType="Literal">&lt;p&gt;Canonical correlation analysis (CCA) is a popular statistical technique for
exploring relationships between datasets. In recent years, the estimation of
sparse canonical vectors has emerged as an important but challenging variant of
the CCA problem, with widespread applications. Unfortunately, existing
rate-optimal estimators for sparse canonical vectors have high computational
cost. We propose a quasi-Bayesian estimation procedure that not only achieves
the minimax estimation rate, but also is easy to compute by Markov Chain Monte
Carlo (MCMC). The method builds on Tan et al. (2018) and uses a re-scaled
Rayleigh quotient function as the quasi-log-likelihood. However, unlike Tan et
al. (2018), we adopt a Bayesian framework that combines this
quasi-log-likelihood with a spike-and-slab prior to regularize the inference
and promote sparsity. We investigate the empirical behavior of the proposed
method on both continuous and truncated data, and we demonstrate that it
outperforms several state-of-the-art methods. As an application, we use the
proposed methodology to maximally correlate clinical variables and proteomic
data for better understanding the Covid-19 disease.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_Q/0/1/0/all/0/1&quot;&gt;Qiuyun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Atchade_Y/0/1/0/all/0/1&quot;&gt;Yves Atchade&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.12915">
<title>Numerical influence of ReLU&apos;(0) on backpropagation. (arXiv:2106.12915v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.12915</link>
<description rdf:parseType="Literal">&lt;p&gt;In theory, the choice of ReLU(0) in [0, 1] for a neural network has a
negligible influence both on backpropagation and training. Yet, in the real
world, 32 bits default precision combined with the size of deep learning
problems makes it a hyperparameter of training methods. We investigate the
importance of the value of ReLU&apos;(0) for several precision levels (16, 32, 64
bits), on various networks (fully connected, VGG, ResNet) and datasets (MNIST,
CIFAR10, SVHN, ImageNet). We observe considerable variations of backpropagation
outputs which occur around half of the time in 32 bits precision. The effect
disappears with double precision, while it is systematic at 16 bits. For
vanilla SGD training, the choice ReLU&apos;(0) = 0 seems to be the most efficient.
For our experiments on ImageNet the gain in test accuracy over ReLU&apos;(0) = 1 was
more than 10 points (two runs). We also evidence that reconditioning approaches
as batch-norm or ADAM tend to buffer the influence of ReLU&apos;(0)&apos;s value.
Overall, the message we convey is that algorithmic differentiation of nonsmooth
problems potentially hides parameters that could be tuned advantageously.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertoin_D/0/1/0/all/0/1&quot;&gt;David Bertoin&lt;/a&gt; (ISAE-SUPAERO), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bolte_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe9;r&amp;#xf4;me Bolte&lt;/a&gt; (TSE-R), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerchinovitz_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Gerchinovitz&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pauwels_E/0/1/0/all/0/1&quot;&gt;Edouard Pauwels&lt;/a&gt; (IRIT-ADRIA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.08452">
<title>On minimizers and convolutional filters: theoretical connections and applications to genome analysis. (arXiv:2111.08452v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.08452</link>
<description rdf:parseType="Literal">&lt;p&gt;Minimizers and convolutional neural networks (CNNs) are two quite distinct
popular techniques that have both been employed to analyze categorical
biological sequences. At face value, the methods seem entirely dissimilar.
Minimizers use min-wise hashing on a rolling window to extract a single
important k-mer feature per window. CNNs start with a wide array of randomly
initialized convolutional filters, paired with a pooling operation, and then
multiple additional neural layers to learn both the filters themselves and how
they can be used to classify the sequence.
&lt;/p&gt;
&lt;p&gt;Here, our main result is a careful mathematical analysis of hash function
properties showing that for sequences over a categorical alphabet, random
Gaussian initialization of convolutional filters with max-pooling is equivalent
to choosing a minimizer ordering such that selected k-mers are (in Hamming
distance) far from the k-mers within the sequence but close to other
minimizers. In empirical experiments, we find that this property manifests as
decreased density in repetitive regions, both in simulation and on real human
telomeres. We additionally train from scratch a CNN embedding of synthetic
short-reads from the SARS-CoV-2 genome into 3D Euclidean space that locally
recapitulates the linear sequence distance of the read origins, a modest step
towards building a deep learning assembler, though it is at present too slow to
be practical. In total, this manuscript provides a partial explanation for the
effectiveness of CNNs in categorical sequence analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yun William Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.03626">
<title>Phase transitions in nonparametric regressions. (arXiv:2112.03626v7 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/2112.03626</link>
<description rdf:parseType="Literal">&lt;p&gt;When the unknown regression function of a single variable is known to have
derivatives up to the $(\gamma+1)$th order bounded in absolute values by a
common constant everywhere or a.e. (i.e., $(\gamma+1)$th degree of smoothness),
the minimax optimal rate of the mean integrated squared error (MISE) is stated
as $\left(\frac{1}{n}\right)^{\frac{2\gamma+2}{2\gamma+3}}$ in the literature.
This paper shows that: (i) if $n\leq\left(\gamma+1\right)^{2\gamma+3}$, the
minimax optimal MISE rate is $\frac{\log n}{n\log(\log n)}$ and the optimal
degree of smoothness to exploit is roughly $\max\left\{ \left\lfloor \frac{\log
n}{2\log\left(\log n\right)}\right\rfloor ,\,1\right\} $; (ii) if
$n&amp;gt;\left(\gamma+1\right)^{2\gamma+3}$, the minimax optimal MISE rate is
$\left(\frac{1}{n}\right)^{\frac{2\gamma+2}{2\gamma+3}}$ and the optimal degree
of smoothness to exploit is $\gamma+1$. The fundamental contribution of this
paper is a set of metric entropy bounds we develop for smooth function classes.
Some of our bounds are original, and some of them improve and/or generalize the
ones in the literature (e.g., Kolmogorov and Tikhomirov, 1959). Our metric
entropy bounds allow us to show phase transitions in the minimax optimal MISE
rates associated with some commonly seen smoothness classes as well as
non-standard smoothness classes, and can also be of independent interest
outside the nonparametric regression problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Ying Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.08369">
<title>Feature-Attending Recurrent Modules for Generalization in Reinforcement Learning. (arXiv:2112.08369v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2112.08369</link>
<description rdf:parseType="Literal">&lt;p&gt;Many important tasks are defined in terms of object. To generalize across
these tasks, a reinforcement learning (RL) agent needs to exploit the structure
that the objects induce. Prior work has either hard-coded object-centric
features, used complex object-centric generative models, or updated state using
local spatial features. However, these approaches have had limited success in
enabling general RL agents. Motivated by this, we introduce &quot;Feature-Attending
Recurrent Modules&quot; (FARM), an architecture for learning state representations
that relies on simple, broadly applicable inductive biases for capturing
spatial and temporal regularities. FARM learns a state representation that is
distributed across multiple modules that each attend to spatiotemporal features
with an expressive feature attention mechanism. We show that this improves an
RL agent&apos;s ability to generalize across object-centric tasks. We study task
suites in both 2D and 3D environments and find that FARM better generalizes
compared to competing architectures that leverage attention or multiple
modules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_W/0/1/0/all/0/1&quot;&gt;Wilka Carvalho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lampinen_A/0/1/0/all/0/1&quot;&gt;Andrew Lampinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikiforou_K/0/1/0/all/0/1&quot;&gt;Kyriacos Nikiforou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1&quot;&gt;Felix Hill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1&quot;&gt;Murray Shanahan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.09698">
<title>Graph Neural Diffusion Networks for Semi-supervised Learning. (arXiv:2201.09698v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2201.09698</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Convolutional Networks (GCN) is a pioneering model for graph-based
semi-supervised learning. However, GCN does not perform well on
sparsely-labeled graphs. Its two-layer version cannot effectively propagate the
label information to the whole graph structure (i.e., the under-smoothing
problem) while its deep version over-smoothens and is hard to train (i.e., the
over-smoothing problem). To solve these two issues, we propose a new graph
neural network called GND-Nets (for Graph Neural Diffusion Networks) that
exploits the local and global neighborhood information of a vertex in a single
layer. Exploiting the shallow network mitigates the over-smoothing problem
while exploiting the local and global neighborhood information mitigates the
under-smoothing problem. The utilization of the local and global neighborhood
information of a vertex is achieved by a new graph diffusion method called
neural diffusions, which integrate neural networks into the conventional linear
and nonlinear graph diffusions. The adoption of neural networks makes neural
diffusions adaptable to different datasets. Extensive experiments on various
sparsely-labeled graphs verify the effectiveness and efficiency of GND-Nets
compared to state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1&quot;&gt;Wei Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zexi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Yunqi Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Ambuj Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.01466">
<title>Recognition of Unseen Bird Species by Learning from Field Guides. (arXiv:2206.01466v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2206.01466</link>
<description rdf:parseType="Literal">&lt;p&gt;We exploit field guides to learn bird species recognition, in particular
zero-shot recognition of unseen species. Illustrations contained in field
guides deliberately focus on discriminative properties of each species, and can
serve as side information to transfer knowledge from seen to unseen bird
species. We study two approaches: (1) a contrastive encoding of illustrations,
which can be fed into standard zero-shot learning schemes; and (2) a novel
method that leverages the fact that illustrations are also images and as such
structurally more similar to photographs than other kinds of side information.
Our results show that illustrations from field guides, which are readily
available for a wide range of species, are indeed a competitive source of side
information for zero-shot learning. On a subset of the iNaturalist2021 dataset
with 749 seen and 739 unseen species, we obtain a classification accuracy of
unseen bird species of $12\%$ @top-1 and $38\%$ @top-10, which shows the
potential of field guides for challenging real-world scenarios with many
species. Our code is available at https://github.com/ac-rodriguez/zsl_billow
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s C. Rodr&amp;#xed;guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DAronco_S/0/1/0/all/0/1&quot;&gt;Stefano D&amp;#x27;Aronco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daudt_R/0/1/0/all/0/1&quot;&gt;Rodrigo Caye Daudt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1&quot;&gt;Jan D. Wegner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1&quot;&gt;Konrad Schindler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.03028">
<title>Bayesian learning of feature spaces for multitasks problems. (arXiv:2209.03028v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2209.03028</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a novel approach for multi-task regression that
connects Kernel Machines (KMs) and Extreme Learning Machines (ELMs) through the
exploitation of the Random Fourier Features (RFFs) approximation of the RBF
kernel. In this sense, one of the contributions of this paper shows that for
the proposed models, the KM and the ELM formulations can be regarded as two
sides of the same coin. These proposed models, termed RFF-BLR, stand on a
Bayesian framework that simultaneously addresses two main design goals. On the
one hand, it fits multitask regressors based on KMs endowed with RBF kernels.
On the other hand, it enables the introduction of a common-across-tasks prior
that promotes multioutput sparsity in the ELM view. This Bayesian approach
facilitates the simultaneous consideration of both the KM and ELM perspectives
enabling (i) the optimisation of the RBF kernel parameter $\gamma$ within a
probabilistic framework, (ii) the optimisation of the model complexity, and
(iii) an efficient transfer of knowledge across tasks. The experimental results
show that this framework can lead to significant performance improvements
compared to the state-of-the-art methods in multitask nonlinear regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sevilla_Salcedo_C/0/1/0/all/0/1&quot;&gt;Carlos Sevilla-Salcedo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gallardo_Antolin_A/0/1/0/all/0/1&quot;&gt;Ascensi&amp;#xf3;n Gallardo-Antol&amp;#xed;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gomez_Verdejo_V/0/1/0/all/0/1&quot;&gt;Vanessa G&amp;#xf3;mez-Verdejo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Parrado_Hernandez_E/0/1/0/all/0/1&quot;&gt;Emilio Parrado-Hern&amp;#xe1;ndez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.06177">
<title>Characterizing Graph Datasets for Node Classification: Homophily-Heterophily Dichotomy and Beyond. (arXiv:2209.06177v3 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2209.06177</link>
<description rdf:parseType="Literal">&lt;p&gt;Homophily is a graph property describing the tendency of edges to connect
similar nodes; the opposite is called heterophily. It is often believed that
heterophilous graphs are challenging for standard message-passing graph neural
networks (GNNs), and much effort has been put into developing efficient methods
for this setting. However, there is no universally agreed-upon measure of
homophily in the literature. In this work, we show that commonly used homophily
measures have critical drawbacks preventing the comparison of homophily levels
across different datasets. For this, we formalize desirable properties for a
proper homophily measure and verify which measures satisfy which properties. In
particular, we show that a measure that we call adjusted homophily satisfies
more desirable properties than other popular homophily measures while being
rarely used in graph machine learning literature. Then, we go beyond the
homophily-heterophily dichotomy and propose a new characteristic that allows
one to further distinguish different sorts of heterophily. The proposed label
informativeness (LI) characterizes how much information a neighbor&apos;s label
provides about a node&apos;s label. We prove that this measure satisfies important
desirable properties. We also observe empirically that LI better agrees with
GNN performance compared to homophily measures, which confirms that it is a
useful characteristic of the graph structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Platonov_O/0/1/0/all/0/1&quot;&gt;Oleg Platonov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuznedelev_D/0/1/0/all/0/1&quot;&gt;Denis Kuznedelev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1&quot;&gt;Artem Babenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1&quot;&gt;Liudmila Prokhorenkova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.17514">
<title>Cost-aware Generalized $\alpha$-investing for Multiple Hypothesis Testing. (arXiv:2210.17514v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.17514</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of sequential multiple hypothesis testing with
nontrivial data collection costs. This problem appears, for example, when
conducting biological experiments to identify differentially expressed genes of
a disease process. This work builds on the generalized $\alpha$-investing
framework which enables control of the false discovery rate in a sequential
testing setting. We make a theoretical analysis of the long term asymptotic
behavior of $\alpha$-wealth which motivates a consideration of sample size in
the $\alpha$-investing decision rule. Posing the testing process as a game with
nature, we construct a decision rule that optimizes the expected
$\alpha$-wealth reward (ERO) and provides an optimal sample size for each test.
Empirical results show that a cost-aware ERO decision rule correctly rejects
more false null hypotheses than other methods for $n=1$ where $n$ is the sample
size. When the sample size is not fixed cost-aware ERO uses a prior on the null
hypothesis to adaptively allocate of the sample budget to each test. We extend
cost-aware ERO investing to finite-horizon testing which enables the decision
rule to allocate samples in a non-myopic manner. Finally, empirical tests on
real data sets from biological experiments show that cost-aware ERO balances
the allocation of samples to an individual test against the allocation of
samples across multiple tests.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cook_T/0/1/0/all/0/1&quot;&gt;Thomas Cook&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_H/0/1/0/all/0/1&quot;&gt;Harsh Vardhan Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Ji Ah Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1&quot;&gt;Guangyu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tingting Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flaherty_P/0/1/0/all/0/1&quot;&gt;Patrick Flaherty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.07596">
<title>Towards Abstractive Timeline Summarisation using Preference-based Reinforcement Learning. (arXiv:2211.07596v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.07596</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a novel pipeline for summarising timelines of events
reported by multiple news sources. Transformer-based models for abstractive
summarisation generate coherent and concise summaries of long documents but can
fail to outperform established extractive methods on specialised tasks such as
timeline summarisation (TLS). While extractive summaries are more faithful to
their sources, they may be less readable and contain redundant or unnecessary
information. This paper proposes a preference-based reinforcement learning
(PBRL) method for adapting pretrained abstractive summarisers to TLS, which can
overcome the drawbacks of extractive timeline summaries. We define a compound
reward function that learns from keywords of interest and pairwise preference
labels, which we use to fine-tune a pretrained abstractive summariser via
offline reinforcement learning. We carry out both automated and human
evaluation on three datasets, finding that our method outperforms a comparable
extractive TLS method on two of the three benchmark datasets, and participants
prefer our method&apos;s summaries to those of both the extractive TLS method and
the pretrained abstractive model. The method does not require expensive
reference summaries and needs only a small number of preferences to align the
generated summaries with human preferences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yuxuan Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simpson_E/0/1/0/all/0/1&quot;&gt;Edwin Simpson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.08761">
<title>Separable PINN: Mitigating the Curse of Dimensionality in Physics-Informed Neural Networks. (arXiv:2211.08761v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.08761</link>
<description rdf:parseType="Literal">&lt;p&gt;Physics-informed neural networks (PINNs) have emerged as new data-driven PDE
solvers for both forward and inverse problems. While promising, the expensive
computational costs to obtain solutions often restrict their broader
applicability. We demonstrate that the computations in automatic
differentiation (AD) can be significantly reduced by leveraging forward-mode AD
when training PINN. However, a naive application of forward-mode AD to
conventional PINNs results in higher computation, losing its practical benefit.
Therefore, we propose a network architecture, called separable PINN (SPINN),
which can facilitate forward-mode AD for more efficient computation. SPINN
operates on a per-axis basis instead of point-wise processing in conventional
PINNs, decreasing the number of network forward passes. Besides, while the
computation and memory costs of standard PINNs grow exponentially along with
the grid resolution, that of our model is remarkably less susceptible,
mitigating the curse of dimensionality. We demonstrate the effectiveness of our
model in various PDE systems by significantly reducing the training run-time
while achieving comparable accuracy. Project page:
https://jwcho5576.github.io/spinn/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1&quot;&gt;Junwoo Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Seungtae Nam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hyunmo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1&quot;&gt;Seok-Bae Yun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Youngjoon Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1&quot;&gt;Eunbyung Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.07738">
<title>A large-scale and PCR-referenced vocal audio dataset for COVID-19. (arXiv:2212.07738v4 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2212.07738</link>
<description rdf:parseType="Literal">&lt;p&gt;The UK COVID-19 Vocal Audio Dataset is designed for the training and
evaluation of machine learning models that classify SARS-CoV-2 infection status
or associated respiratory symptoms using vocal audio. The UK Health Security
Agency recruited voluntary participants through the national Test and Trace
programme and the REACT-1 survey in England from March 2021 to March 2022,
during dominant transmission of the Alpha and Delta SARS-CoV-2 variants and
some Omicron variant sublineages. Audio recordings of volitional coughs,
exhalations, and speech were collected in the &apos;Speak up to help beat
coronavirus&apos; digital survey alongside demographic, self-reported symptom and
respiratory condition data, and linked to SARS-CoV-2 test results. The UK
COVID-19 Vocal Audio Dataset represents the largest collection of SARS-CoV-2
PCR-referenced audio recordings to date. PCR results were linked to 70,794 of
72,999 participants and 24,155 of 25,776 positive cases. Respiratory symptoms
were reported by 45.62% of participants. This dataset has additional potential
uses for bioacoustics research, with 11.30% participants reporting asthma, and
27.20% with linked influenza PCR test results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budd_J/0/1/0/all/0/1&quot;&gt;Jobie Budd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baker_K/0/1/0/all/0/1&quot;&gt;Kieran Baker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karoune_E/0/1/0/all/0/1&quot;&gt;Emma Karoune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coppock_H/0/1/0/all/0/1&quot;&gt;Harry Coppock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1&quot;&gt;Selina Patel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Canadas_A/0/1/0/all/0/1&quot;&gt;Ana Tendero Ca&amp;#xf1;adas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Titcomb_A/0/1/0/all/0/1&quot;&gt;Alexander Titcomb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Payne_R/0/1/0/all/0/1&quot;&gt;Richard Payne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hurley_D/0/1/0/all/0/1&quot;&gt;David Hurley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Egglestone_S/0/1/0/all/0/1&quot;&gt;Sabrina Egglestone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Butler_L/0/1/0/all/0/1&quot;&gt;Lorraine Butler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mellor_J/0/1/0/all/0/1&quot;&gt;Jonathon Mellor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicholson_G/0/1/0/all/0/1&quot;&gt;George Nicholson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiskin_I/0/1/0/all/0/1&quot;&gt;Ivan Kiskin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koutra_V/0/1/0/all/0/1&quot;&gt;Vasiliki Koutra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jersakova_R/0/1/0/all/0/1&quot;&gt;Radka Jersakova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McKendry_R/0/1/0/all/0/1&quot;&gt;Rachel A. McKendry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diggle_P/0/1/0/all/0/1&quot;&gt;Peter Diggle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richardson_S/0/1/0/all/0/1&quot;&gt;Sylvia Richardson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn W. Schuller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilmour_S/0/1/0/all/0/1&quot;&gt;Steven Gilmour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pigoli_D/0/1/0/all/0/1&quot;&gt;Davide Pigoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1&quot;&gt;Stephen Roberts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Packham_J/0/1/0/all/0/1&quot;&gt;Josef Packham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thornley_T/0/1/0/all/0/1&quot;&gt;Tracey Thornley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holmes_C/0/1/0/all/0/1&quot;&gt;Chris Holmes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.05062">
<title>Tracr: Compiled Transformers as a Laboratory for Interpretability. (arXiv:2301.05062v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.05062</link>
<description rdf:parseType="Literal">&lt;p&gt;We show how to &quot;compile&quot; human-readable programs into standard decoder-only
transformer models. Our compiler, Tracr, generates models with known structure.
This structure can be used to design experiments. For example, we use it to
study &quot;superposition&quot; in transformers that execute multi-step algorithms.
Additionally, the known structure of Tracr-compiled models can serve as
ground-truth for evaluating interpretability methods. Commonly, because the
&quot;programs&quot; learned by transformers are unknown it is unclear whether an
interpretation succeeded. We demonstrate our approach by implementing and
examining programs including computing token frequencies, sorting, and
parenthesis checking. We provide an open-source implementation of Tracr at
https://github.com/google-deepmind/tracr.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindner_D/0/1/0/all/0/1&quot;&gt;David Lindner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramar_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe1;nos Kram&amp;#xe1;r&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1&quot;&gt;Sebastian Farquhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahtz_M/0/1/0/all/0/1&quot;&gt;Matthew Rahtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGrath_T/0/1/0/all/0/1&quot;&gt;Thomas McGrath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikulik_V/0/1/0/all/0/1&quot;&gt;Vladimir Mikulik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.12247">
<title>SEGA: Instructing Text-to-Image Models using Semantic Guidance. (arXiv:2301.12247v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2301.12247</link>
<description rdf:parseType="Literal">&lt;p&gt;Text-to-image diffusion models have recently received a lot of interest for
their astonishing ability to produce high-fidelity images from text only.
However, achieving one-shot generation that aligns with the user&apos;s intent is
nearly impossible, yet small changes to the input prompt often result in very
different images. This leaves the user with little semantic control. To put the
user in control, we show how to interact with the diffusion process to flexibly
steer it along semantic directions. This semantic guidance (SEGA) generalizes
to any generative architecture using classifier-free guidance. More
importantly, it allows for subtle and extensive edits, changes in composition
and style, as well as optimizing the overall artistic conception. We
demonstrate SEGA&apos;s effectiveness on both latent and pixel-based diffusion
models such as Stable Diffusion, Paella, and DeepFloyd-IF using a variety of
tasks, thus providing strong evidence for its versatility, flexibility, and
improvements over existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brack_M/0/1/0/all/0/1&quot;&gt;Manuel Brack&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friedrich_F/0/1/0/all/0/1&quot;&gt;Felix Friedrich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1&quot;&gt;Dominik Hintersdorf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1&quot;&gt;Lukas Struppek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schramowski_P/0/1/0/all/0/1&quot;&gt;Patrick Schramowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1&quot;&gt;Kristian Kersting&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.07317">
<title>Algorithm Selection for Deep Active Learning with Imbalanced Datasets. (arXiv:2302.07317v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.07317</link>
<description rdf:parseType="Literal">&lt;p&gt;Label efficiency has become an increasingly important objective in deep
learning applications. Active learning aims to reduce the number of labeled
examples needed to train deep networks, but the empirical performance of active
learning algorithms can vary dramatically across datasets and applications. It
is difficult to know in advance which active learning strategy will perform
well or best in a given application. To address this, we propose the first
adaptive algorithm selection strategy for deep active learning. For any
unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning
algORithm selection) iteratively and adaptively chooses among a set of
candidate active learning algorithms. TAILOR uses novel reward functions aimed
at gathering class-balanced examples. Extensive experiments in multi-class and
multi-label applications demonstrate TAILOR&apos;s effectiveness in achieving
accuracy comparable or better than that of the best of the candidate
algorithms. Our implementation of TAILOR is open-sourced at
https://github.com/jifanz/TAILOR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jifan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1&quot;&gt;Shuai Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1&quot;&gt;Saurabh Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nowak_R/0/1/0/all/0/1&quot;&gt;Robert Nowak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.14082">
<title>Detecting and Mitigating Mode-Collapse for Flow-based Sampling of Lattice Field Theories. (arXiv:2302.14082v2 [hep-lat] UPDATED)</title>
<link>http://arxiv.org/abs/2302.14082</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the consequences of mode-collapse of normalizing flows in the
context of lattice field theory. Normalizing flows allow for independent
sampling. For this reason, it is hoped that they can avoid the tunneling
problem of local-update MCMC algorithms for multi-modal distributions. In this
work, we first point out that the tunneling problem is also present for
normalizing flows but is shifted from the sampling to the training phase of the
algorithm. Specifically, normalizing flows often suffer from mode-collapse for
which the training process assigns vanishingly low probability mass to relevant
modes of the physical distribution. This may result in a significant bias when
the flow is used as a sampler in a Markov-Chain or with Importance Sampling. We
propose a metric to quantify the degree of mode-collapse and derive a bound on
the resulting bias. Furthermore, we propose various mitigation strategies in
particular in the context of estimating thermodynamic observables, such as the
free energy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Nicoli_K/0/1/0/all/0/1&quot;&gt;Kim A. Nicoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Anders_C/0/1/0/all/0/1&quot;&gt;Christopher J. Anders&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Hartung_T/0/1/0/all/0/1&quot;&gt;Tobias Hartung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Jansen_K/0/1/0/all/0/1&quot;&gt;Karl Jansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Kessel_P/0/1/0/all/0/1&quot;&gt;Pan Kessel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Nakajima_S/0/1/0/all/0/1&quot;&gt;Shinichi Nakajima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.03374">
<title>To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning. (arXiv:2303.03374v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.03374</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning and ensembling are two popular techniques for improving the
performance and robustness of neural networks. Due to the high cost of
pre-training, ensembles of models fine-tuned from a single pre-trained
checkpoint are often used in practice. Such models end up in the same basin of
the loss landscape, which we call the pre-train basin, and thus have limited
diversity. In this work, we show that ensembles trained from a single
pre-trained checkpoint may be improved by better exploring the pre-train basin,
however, leaving the basin results in losing the benefits of transfer learning
and in degradation of the ensemble quality. Based on the analysis of existing
exploration methods, we propose a more effective modification of the Snapshot
Ensembles (SSE) for transfer learning setup, StarSSE, which results in stronger
ensembles and uniform model soups.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadrtdinov_I/0/1/0/all/0/1&quot;&gt;Ildus Sadrtdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pozdeev_D/0/1/0/all/0/1&quot;&gt;Dmitrii Pozdeev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1&quot;&gt;Dmitry Vetrov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lobacheva_E/0/1/0/all/0/1&quot;&gt;Ekaterina Lobacheva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.10834">
<title>Object-Centric Slot Diffusion. (arXiv:2303.10834v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.10834</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent success of transformer-based image generative models in
object-centric learning highlights the importance of powerful image generators
for handling complex scenes. However, despite the high expressiveness of
diffusion models in image generation, their integration into object-centric
learning remains largely unexplored in this domain. In this paper, we explore
the feasibility and potential of integrating diffusion models into
object-centric learning and investigate the pros and cons of this approach. We
introduce Latent Slot Diffusion (LSD), a novel model that serves dual purposes:
it is the first object-centric learning model to replace conventional slot
decoders with a latent diffusion model conditioned on object slots, and it is
also the first unsupervised compositional conditional diffusion model that
operates without the need for supervised annotations like text. Through
experiments on various object-centric tasks, including the first application of
the FFHQ dataset in this field, we demonstrate that LSD significantly
outperforms state-of-the-art transformer-based decoders, particularly in more
complex scenes, and exhibits superior unsupervised compositional generation
quality. In addition, we conduct a preliminary investigation into the
integration of pre-trained diffusion models in LSD and demonstrate its
effectiveness in real-world image segmentation and generation. Project page is
available at https://latentslotdiffusion.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jindong Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_F/0/1/0/all/0/1&quot;&gt;Fei Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1&quot;&gt;Gautam Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1&quot;&gt;Sungjin Ahn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.11143">
<title>Adversarial Attacks against Binary Similarity Systems. (arXiv:2303.11143v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2303.11143</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, binary analysis gained traction as a fundamental approach to
inspect software and guarantee its security. Due to the exponential increase of
devices running software, much research is now moving towards new autonomous
solutions based on deep learning models, as they have been showing
state-of-the-art performances in solving binary analysis problems. One of the
hot topics in this context is binary similarity, which consists in determining
if two functions in assembly code are compiled from the same source code.
However, it is unclear how deep learning models for binary similarity behave in
an adversarial context. In this paper, we study the resilience of binary
similarity models against adversarial examples, showing that they are
susceptible to both targeted and untargeted attacks (w.r.t. similarity goals)
performed by black-box and white-box attackers. In more detail, we extensively
test three current state-of-the-art solutions for binary similarity against two
black-box greedy attacks, including a new technique that we call Spatial
Greedy, and one white-box attack in which we repurpose a gradient-guided
strategy used in attacks to image classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Capozzi_G/0/1/0/all/0/1&quot;&gt;Gianluca Capozzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DElia_D/0/1/0/all/0/1&quot;&gt;Daniele Cono D&amp;#x27;Elia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luna_G/0/1/0/all/0/1&quot;&gt;Giuseppe Antonio Di Luna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Querzoni_L/0/1/0/all/0/1&quot;&gt;Leonardo Querzoni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.03843">
<title>Why think step by step? Reasoning emerges from the locality of experience. (arXiv:2304.03843v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2304.03843</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans have a powerful and mysterious capacity to reason. Working through a
set of mental steps enables us to make inferences we would not be capable of
making directly even though we get no additional data from the world.
Similarly, when large language models generate intermediate steps (a chain of
thought) before answering a question, they often produce better answers than
they would directly. We investigate why and how chain-of-thought reasoning is
useful in language models, testing the hypothesis that reasoning is effective
when training data consists of overlapping local clusters of variables that
influence each other strongly. These training conditions enable the chaining of
accurate local inferences to estimate relationships between variables that were
not seen together in training. We prove that there will exist a &quot;reasoning
gap&quot;, where reasoning through intermediate variables reduces bias, for the
simple case of an autoregressive density estimator trained on local samples
from a chain-structured probabilistic model. We then test our hypothesis
experimentally in more complex models, training an autoregressive language
model on samples from Bayes nets but only including a subset of variables in
each sample. We test language models&apos; ability to match conditional
probabilities with and without intermediate reasoning steps, finding that
intermediate steps are only helpful when the training data is locally
structured with respect to dependencies between variables. The combination of
locally structured observations and reasoning is much more data-efficient than
training on all variables. Our results illustrate how the effectiveness of
reasoning step by step is rooted in the local statistical structure of the
training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prystawski_B/0/1/0/all/0/1&quot;&gt;Ben Prystawski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Michael Y. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1&quot;&gt;Noah D. Goodman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.04370">
<title>OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v6 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2304.04370</link>
<description rdf:parseType="Literal">&lt;p&gt;Human Intelligence (HI) excels at combining basic skills to solve complex
tasks. This capability is vital for Artificial Intelligence (AI) and should be
embedded in comprehensive AI Agents, enabling them to harness expert models for
complex task-solving towards Artificial General Intelligence (AGI). Large
Language Models (LLMs) show promising learning and reasoning abilities, and can
effectively use external models, tools, plugins, or APIs to tackle complex
problems. In this work, we introduce OpenAGI, an open-source AGI research and
development platform designed for solving multi-step, real-world tasks.
Specifically, OpenAGI uses a dual strategy, integrating standard benchmark
tasks for benchmarking and evaluation, and open-ended tasks including more
expandable models, tools, plugins, or APIs for creative problem-solving. Tasks
are presented as natural language queries to the LLM, which then selects and
executes appropriate models. We also propose a Reinforcement Learning from Task
Feedback (RLTF) mechanism that uses task results to improve the LLM&apos;s
task-solving ability, which creates a self-improving AI feedback loop. While we
acknowledge that AGI is a broad and multifaceted research challenge with no
singularly defined solution path, the integration of LLMs with domain-specific
expert models, inspired by mirroring the blend of general and specialized
intelligence in humans, offers a promising approach towards AGI. We are
open-sourcing the OpenAGI project&apos;s code, dataset, benchmarks, evaluation
methods, and the UI demo to foster community involvement in AGI advancement:
https://github.com/agiresearch/OpenAGI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1&quot;&gt;Yingqiang Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1&quot;&gt;Wenyue Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mei_K/0/1/0/all/0/1&quot;&gt;Kai Mei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1&quot;&gt;Jianchao Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1&quot;&gt;Juntao Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shuyuan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zelong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yongfeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.03515">
<title>GradTree: Learning Axis-Aligned Decision Trees with Gradient Descent. (arXiv:2305.03515v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.03515</link>
<description rdf:parseType="Literal">&lt;p&gt;Decision Trees (DTs) are commonly used for many machine learning tasks due to
their high degree of interpretability. However, learning a DT from data is a
difficult optimization problem, as it is non-convex and non-differentiable.
Therefore, common approaches learn DTs using a greedy growth algorithm that
minimizes the impurity locally at each internal node. Unfortunately, this
greedy procedure can lead to inaccurate trees. In this paper, we present a
novel approach for learning hard, axis-aligned DTs with gradient descent. The
proposed method uses backpropagation with a straight-through operator on a
dense DT representation, to jointly optimize all tree parameters. Our approach
outperforms existing methods on binary classification benchmarks and achieves
competitive results for multi-class tasks. The method is available under:
https://github.com/s-marton/GradTree
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marton_S/0/1/0/all/0/1&quot;&gt;Sascha Marton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ludtke_S/0/1/0/all/0/1&quot;&gt;Stefan L&amp;#xfc;dtke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartelt_C/0/1/0/all/0/1&quot;&gt;Christian Bartelt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stuckenschmidt_H/0/1/0/all/0/1&quot;&gt;Heiner Stuckenschmidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.03609">
<title>Differentially Private Topological Data Analysis. (arXiv:2305.03609v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2305.03609</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is the first to attempt differentially private (DP) topological
data analysis (TDA), producing near-optimal private persistence diagrams. We
analyze the sensitivity of persistence diagrams in terms of the bottleneck
distance, and we show that the commonly used \v{C}ech complex has sensitivity
that does not decrease as the sample size $n$ increases. This makes it
challenging for the persistence diagrams of \v{C}ech complexes to be
privatized. As an alternative, we show that the persistence diagram obtained by
the $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on the
sensitivity analysis, we propose using the exponential mechanism whose utility
function is defined in terms of the bottleneck distance of the $L^1$-DTM
persistence diagrams. We also derive upper and lower bounds of the accuracy of
our privacy mechanism; the obtained bounds indicate that the privacy error of
our mechanism is near-optimal. We demonstrate the performance of our privatized
persistence diagrams through simulations as well as on a real dataset tracking
human movement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kang_T/0/1/0/all/0/1&quot;&gt;Taegyu Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sehwan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sohn_J/0/1/0/all/0/1&quot;&gt;Jinwon Sohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Awan_J/0/1/0/all/0/1&quot;&gt;Jordan Awan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.11092">
<title>Universal Domain Adaptation from Foundation Models: A Baseline Study. (arXiv:2305.11092v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.11092</link>
<description rdf:parseType="Literal">&lt;p&gt;Foundation models (e.g., CLIP or DINOv2) have shown their impressive learning
and transfer capabilities in a wide range of visual tasks, by training on a
large corpus of data and adapting to specific downstream tasks. It is, however,
interesting that foundation models have not been fully explored for universal
domain adaptation (UniDA), which is to learn models using labeled data in a
source domain and unlabeled data in a target one, such that the learned models
can successfully adapt to the target data. In this paper, we make comprehensive
empirical studies of state-of-the-art UniDA methods using foundation models. We
first observe that, unlike fine-tuning from ImageNet pre-trained models, as
previous methods do, fine-tuning from foundation models yields significantly
poorer results, sometimes even worse than training from scratch. While freezing
the backbones, we demonstrate that although the foundation models greatly
improve the performance of the baseline method that trains the models on the
source data alone, existing UniDA methods generally fail to improve over the
baseline. This suggests that new research efforts are very necessary for UniDA
using foundation models. Based on these findings, we introduce \textit{CLIP
distillation}, a parameter-free method specifically designed to distill target
knowledge from CLIP models. The core of our \textit{CLIP distillation} lies in
a self-calibration technique for automatic temperature scaling, a feature that
significantly enhances the baseline&apos;s out-class detection capability. Although
simple, our method outperforms previous approaches in most benchmark tasks,
excelling in evaluation metrics including H-score/H$^3$-score and the newly
proposed universal classification rate (UCR) metric. We hope that our
investigation and the proposed simple framework can serve as a strong baseline
to facilitate future studies in this field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1&quot;&gt;Bin Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1&quot;&gt;Kui Jia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13484">
<title>Flover: A Temporal Fusion Framework for Efficient Autoregressive Model Parallel Inference. (arXiv:2305.13484v3 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13484</link>
<description rdf:parseType="Literal">&lt;p&gt;Autoregressive models, despite their commendable performance in a myriad of
generative tasks, face challenges stemming from their inherently sequential
structure. Inference on these models, by design, harnesses a temporal
dependency, where the current token&apos;s probability distribution is conditioned
on preceding tokens. This inherent characteristic severely impedes
computational efficiency during inference as a typical inference request can
require more than thousands of tokens, where generating each token requires a
load of entire model weights, making the inference more memory-bound. The large
overhead becomes profound in real deployment where requests arrive randomly,
necessitating various generation lengths. Existing solutions, such as dynamic
batching and concurrent instances, introduce significant response delays and
bandwidth contention, falling short of achieving optimal latency and
throughput. To address these shortcomings, we propose Flover -- a temporal
fusion framework for efficiently inferring multiple requests in parallel. We
deconstruct the general generation pipeline into pre-processing and token
generation, and equip the framework with a dedicated work scheduler for fusing
the generation process temporally across all requests. By orchestrating the
token-level parallelism, Flover exhibits optimal hardware efficiency and
significantly spares the system resources. By further employing a fast buffer
reordering algorithm that allows memory eviction of finished tasks, it brings
over 11x inference speedup on GPT and 16x on LLAMA compared to the cutting-edge
solutions provided by NVIDIA FasterTransformer. Crucially, by leveraging the
advanced tensor parallel technique, Flover proves efficacious across diverse
computational landscapes, from single-GPU setups to distributed scenarios,
thereby offering robust performance optimization that adapts to variable use
cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jinghan Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alnaasan_N/0/1/0/all/0/1&quot;&gt;Nawras Alnaasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafi_A/0/1/0/all/0/1&quot;&gt;Aamir Shafi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramoni_H/0/1/0/all/0/1&quot;&gt;Hari Subramoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+K%2E_D/0/1/0/all/0/1&quot;&gt;Dhabaleswar K.&lt;/a&gt; (DK) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panda/0/1/0/all/0/1&quot;&gt;Panda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14637">
<title>Learning UI-to-Code Reverse Generator Using Visual Critic Without Rendering. (arXiv:2305.14637v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14637</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated reverse engineering of HTML/CSS code from UI screenshots is an
important yet challenging problem with broad applications in website
development and design. In this paper, we propose a novel vision-code
transformer (ViCT) composed of a vision encoder processing the screenshots and
a language decoder to generate the code. They are initialized by pre-trained
models such as ViT/DiT and GPT-2/LLaMA but aligning the two modalities requires
end-to-end finetuning, which aims to minimize the visual discrepancy between
the code-rendered webpage and the original screenshot. However, the rendering
is non-differentiable and causes costly overhead. We address this problem by
actor-critic fine-tuning where a visual critic without rendering (ViCR) is
developed to predict visual discrepancy given the original and generated code.
To train and evaluate our models, we created two synthetic datasets of varying
complexity, with over 75,000 unique (code, screenshot) pairs. We evaluate the
UI-to-Code performance using a combination of automated metrics such as MSE,
BLEU, IoU, and a novel htmlBLEU score. ViCT outperforms a strong baseline model
DiT-GPT2, improving IoU from 0.64 to 0.79 and lowering MSE from 12.25 to 9.02.
With much lower computational cost, it can achieve comparable performance as
when using a larger decoder such as LLaMA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soselia_D/0/1/0/all/0/1&quot;&gt;Davit Soselia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saifullah_K/0/1/0/all/0/1&quot;&gt;Khalid Saifullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.16671">
<title>A Unified Approach for Maximizing Continuous DR-submodular Functions. (arXiv:2305.16671v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.16671</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a unified approach for maximizing continuous
DR-submodular functions that encompasses a range of settings and oracle access
types. Our approach includes a Frank-Wolfe type offline algorithm for both
monotone and non-monotone functions, with different restrictions on the general
convex set. We consider settings where the oracle provides access to either the
gradient of the function or only the function value, and where the oracle
access is either deterministic or stochastic. We determine the number of
required oracle accesses in all cases. Our approach gives new/improved results
for nine out of the sixteen considered cases, avoids computationally expensive
projections in two cases, with the proposed framework matching performance of
state-of-the-art approaches in the remaining five cases. Notably, our approach
for the stochastic function value-based oracle enables the first regret bounds
with bandit feedback for stochastic DR-submodular functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedramfar_M/0/1/0/all/0/1&quot;&gt;Mohammad Pedramfar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1&quot;&gt;Christopher John Quinn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1&quot;&gt;Vaneet Aggarwal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.17560">
<title>Scalable Transformer for PDE Surrogate Modeling. (arXiv:2305.17560v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.17560</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer has shown state-of-the-art performance on various applications
and has recently emerged as a promising tool for surrogate modeling of partial
differential equations (PDEs). Despite the introduction of linear-complexity
attention, applying Transformer to problems with a large number of grid points
can be numerically unstable and computationally expensive. In this work, we
propose Factorized Transformer (FactFormer), which is based on an axial
factorized kernel integral. Concretely, we introduce a learnable projection
operator that decomposes the input function into multiple sub-functions with
one-dimensional domain. These sub-functions are then evaluated and used to
compute the instance-based kernel with an axial factorized scheme. We showcase
that the proposed model is able to simulate 2D Kolmogorov flow on a $256\times
256$ grid and 3D smoke buoyancy on a $64\times64\times64$ grid with good
accuracy and efficiency. The proposed factorized scheme can serve as a
computationally efficient low-rank surrogate for the full attention scheme when
dealing with multi-dimensional problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zijie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_D/0/1/0/all/0/1&quot;&gt;Dule Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1&quot;&gt;Amir Barati Farimani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18381">
<title>Distill Gold from Massive Ores: Efficient Dataset Distillation via Critical Samples Selection. (arXiv:2305.18381v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18381</link>
<description rdf:parseType="Literal">&lt;p&gt;Data-efficient learning has drawn significant attention, especially given the
current trend of large multi-modal models, where dataset distillation can be an
effective solution. However, the dataset distillation process itself is still
very inefficient. In this work, we model the distillation problem with
reference to information transport. Observing that severe data redundancy
exists in dataset distillation, we argue to put more emphasis on the utility of
the training samples. We propose a family of methods to exploit the most
valuable samples, which is validated by our comprehensive analysis of the
optimal data selection. The new strategy significantly reduces the training
cost and extends a variety of existing distillation algorithms to larger and
more diversified datasets, e.g., in some cases only 0.04% training data is
sufficient for comparable distillation performance. Moreover, our strategy
consistently enhances the performance, which may open up new analyses on the
dynamics of distillation and networks. Our method is able to extend the
distillation algorithms to much larger-scale datasets and more heterogeneous
datasets, e.g., ImageNet-1K and Kinetics-400. Our code is available on
https://github.com/silicx/GoldFromOres.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yue Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yong-Lu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1&quot;&gt;Kaitong Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Cewu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1&quot;&gt;Yu-Wing Tai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1&quot;&gt;Chi-Keung Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.00265">
<title>Doubly Robust Self-Training. (arXiv:2306.00265v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.00265</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-training is an important technique for solving semi-supervised learning
problems. It leverages unlabeled data by generating pseudo-labels and combining
them with a limited labeled dataset for training. The effectiveness of
self-training heavily relies on the accuracy of these pseudo-labels. In this
paper, we introduce doubly robust self-training, a novel semi-supervised
algorithm that provably balances between two extremes. When the pseudo-labels
are entirely incorrect, our method reduces to a training process solely using
labeled data. Conversely, when the pseudo-labels are completely accurate, our
method transforms into a training process utilizing all pseudo-labeled data and
labeled data, thus increasing the effective sample size. Through empirical
evaluations on both the ImageNet dataset for image classification and the
nuScenes autonomous driving dataset for 3D object detection, we demonstrate the
superiority of the doubly robust loss over the standard self-training baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1&quot;&gt;Banghua Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Mingyu Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobson_P/0/1/0/all/0/1&quot;&gt;Philip Jacobson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Ming Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1&quot;&gt;Wei Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jiantao Jiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.01264">
<title>Convex and Non-convex Optimization Under Generalized Smoothness. (arXiv:2306.01264v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2306.01264</link>
<description rdf:parseType="Literal">&lt;p&gt;Classical analysis of convex and non-convex optimization methods often
requires the Lipshitzness of the gradient, which limits the analysis to
functions bounded by quadratics. Recent work relaxed this requirement to a
non-uniform smoothness condition with the Hessian norm bounded by an affine
function of the gradient norm, and proved convergence in the non-convex setting
via gradient clipping, assuming bounded noise. In this paper, we further
generalize this non-uniform smoothness condition and develop a simple, yet
powerful analysis technique that bounds the gradients along the trajectory,
thereby leading to stronger results for both convex and non-convex optimization
problems. In particular, we obtain the classical convergence rates for
(stochastic) gradient descent and Nesterov&apos;s accelerated gradient method in the
convex and/or non-convex setting under this general smoothness condition. The
new analysis approach does not require gradient clipping and allows
heavy-tailed noise with bounded variance in the stochastic setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haochuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Qian_J/0/1/0/all/0/1&quot;&gt;Jian Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yi Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Rakhlin_A/0/1/0/all/0/1&quot;&gt;Alexander Rakhlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jadbabaie_A/0/1/0/all/0/1&quot;&gt;Ali Jadbabaie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.02231">
<title>Fine-Tuning Language Models with Advantage-Induced Policy Alignment. (arXiv:2306.02231v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.02231</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning from human feedback (RLHF) has emerged as a reliable
approach to aligning large language models (LLMs) to human preferences. Among
the plethora of RLHF techniques, proximal policy optimization (PPO) is of the
most widely used methods. Despite its popularity, however, PPO may suffer from
mode collapse, instability, and poor sample efficiency. We show that these
issues can be alleviated by a novel algorithm that we refer to as
Advantage-Induced Policy Alignment (APA), which leverages a squared error loss
function based on the estimated advantages. We demonstrate empirically that APA
consistently outperforms PPO in language tasks by a large margin, when a
separate reward model is employed as the evaluator. In addition, compared with
PPO, APA offers a more stable form of control over the deviation from the
model&apos;s initial policy, ensuring that the model improves its performance
without collapsing to deterministic output. In addition to empirical results,
we also provide a theoretical justification supporting the design of our loss
function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1&quot;&gt;Banghua Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_H/0/1/0/all/0/1&quot;&gt;Hiteshi Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frujeri_F/0/1/0/all/0/1&quot;&gt;Felipe Vieira Frujeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1&quot;&gt;Shi Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Chenguang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jiantao Jiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.02899">
<title>Learning nonparametric latent causal graphs with unknown interventions. (arXiv:2306.02899v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.02899</link>
<description rdf:parseType="Literal">&lt;p&gt;We establish conditions under which latent causal graphs are
nonparametrically identifiable and can be reconstructed from unknown
interventions in the latent space. Our primary focus is the identification of
the latent structure in measurement models without parametric assumptions such
as linearity or Gaussianity. Moreover, we do not assume the number of hidden
variables is known, and we show that at most one unknown intervention per
hidden variable is needed. This extends a recent line of work on learning
causal representations from observations and interventions. The proofs are
constructive and introduce two new graphical concepts -- imaginary subsets and
isolated edges -- that may be useful in their own right. As a matter of
independent interest, the proofs also involve a novel characterization of the
limits of edge orientations within the equivalence class of DAGs induced by
unknown interventions. These are the first results to characterize the
conditions under which causal representations are identifiable without making
any parametric assumptions in a general setting with unknown interventions and
without faithfulness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yibo Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aragam_B/0/1/0/all/0/1&quot;&gt;Bryon Aragam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.09136">
<title>Finite-Time Logarithmic Bayes Regret Upper Bounds. (arXiv:2306.09136v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.09136</link>
<description rdf:parseType="Literal">&lt;p&gt;We derive the first finite-time logarithmic Bayes regret upper bounds for
Bayesian bandits. In Gaussian bandits, we obtain $O(c_\Delta \log n)$ and
$O(c_h \log^2 n)$ bounds for an upper confidence bound algorithm, where $c_h$
and $c_\Delta$ are constants depending on the prior distribution and the gaps
of random bandit instances sampled from it, respectively. The latter bound
asymptotically matches the lower bound of Lai (1987). Our proofs are a major
technical departure from prior works, while being simple and general. To show
the generality of our techniques, we apply them to linear bandits. Our results
provide insights on the value of prior in the Bayesian setting, both in the
objective and as a side information given to the learner. They significantly
improve upon existing $\tilde{O}(\sqrt{n})$ bounds, which have become standard
in the literature despite the existing lower bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atsidakou_A/0/1/0/all/0/1&quot;&gt;Alexia Atsidakou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katariya_S/0/1/0/all/0/1&quot;&gt;Sumeet Katariya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caramanis_C/0/1/0/all/0/1&quot;&gt;Constantine Caramanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanghavi_S/0/1/0/all/0/1&quot;&gt;Sujay Sanghavi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.10763">
<title>Guiding Language Models of Code with Global Context using Monitors. (arXiv:2306.10763v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.10763</link>
<description rdf:parseType="Literal">&lt;p&gt;Language models of code (LMs) work well when the surrounding code provides
sufficient context. This is not true when it becomes necessary to use types,
functionality or APIs defined elsewhere in the repository or a linked library,
especially those not seen during training. LMs suffer from limited awareness of
such global context and end up hallucinating.
&lt;/p&gt;
&lt;p&gt;Integrated development environments (IDEs) assist developers in understanding
repository context using static analysis. We extend this assistance, enjoyed by
developers, to LMs. We propose monitor-guided decoding (MGD) where a monitor
uses static analysis to guide the decoding. We construct a repository-level
dataset PragmaticCode for method-completion in Java and evaluate MGD on it. On
models of varying parameter scale, by monitoring for type-consistent object
dereferences, MGD consistently improves compilation rates and agreement with
ground truth. Further, LMs with fewer parameters, when augmented with MGD, can
outperform larger LMs. With MGD, SantaCoder-1.1B achieves better compilation
rate and next-identifier match than the much larger text-davinci-003 model.
&lt;/p&gt;
&lt;p&gt;We also conduct a generalizability study to evaluate the ability of MGD to
generalize to multiple programming languages (Java, C# and Rust), coding
scenarios (e.g., correct number of arguments to method calls), and to enforce
richer semantic constraints (e.g., stateful API protocols). Our data and
implementation are available at https://github.com/microsoft/monitors4codegen .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_L/0/1/0/all/0/1&quot;&gt;Lakshya A Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanade_A/0/1/0/all/0/1&quot;&gt;Aditya Kanade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1&quot;&gt;Navin Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lahiri_S/0/1/0/all/0/1&quot;&gt;Shuvendu K. Lahiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajamani_S/0/1/0/all/0/1&quot;&gt;Sriram K. Rajamani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.16578">
<title>Allocating Divisible Resources on Arms with Unknown and Random Rewards. (arXiv:2306.16578v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.16578</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a decision maker allocating one unit of renewable and divisible
resource in each period on a number of arms. The arms have unknown and random
rewards whose means are proportional to the allocated resource and whose
variances are proportional to an order $b$ of the allocated resource. In
particular, if the decision maker allocates resource $A_i$ to arm $i$ in a
period, then the reward $Y_i$ is$Y_i(A_i)=A_i \mu_i+A_i^b \xi_{i}$, where
$\mu_i$ is the unknown mean and the noise $\xi_{i}$ is independent and
sub-Gaussian. When the order $b$ ranges from 0 to 1, the framework smoothly
bridges the standard stochastic multi-armed bandit and online learning with
full feedback. We design two algorithms that attain the optimal gap-dependent
and gap-independent regret bounds for $b\in [0,1]$, and demonstrate a phase
transition at $b=1/2$. The theoretical results hinge on a novel concentration
inequality we have developed that bounds a linear combination of sub-Gaussian
random variables whose weights are fractional, adapted to the filtration, and
monotonic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1&quot;&gt;Ningyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenhao Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00424">
<title>Adaptive Algorithms for Relaxed Pareto Set Identification. (arXiv:2307.00424v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2307.00424</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we revisit the fixed-confidence identification of the Pareto
optimal set in a multi-objective multi-armed bandit model. As the sample
complexity to identify the exact Pareto set can be very large, a relaxation
allowing to output some additional near-optimal arms has been studied. In this
work we also tackle alternative relaxations that allow instead to identify a
relevant subset of the Pareto set. Notably, we propose a single sampling
strategy, called Adaptive Pareto Exploration, that can be used in conjunction
with different stopping rules to take into account different relaxations of the
Pareto Set Identification problem. We analyze the sample complexity of these
different combinations, quantifying in particular the reduction in sample
complexity that occurs when one seeks to identify at most $k$ Pareto optimal
arms. We showcase the good practical performance of Adaptive Pareto Exploration
on a real-world scenario, in which we adaptively explore several vaccination
strategies against Covid-19 in order to find the optimal ones when multiple
immunogenicity criteria are taken into account.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kone_C/0/1/0/all/0/1&quot;&gt;Cyrille Kone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kaufmann_E/0/1/0/all/0/1&quot;&gt;Emilie Kaufmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Richert_L/0/1/0/all/0/1&quot;&gt;Laura Richert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.01050">
<title>Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\&quot;odinger Bridges. (arXiv:2307.01050v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2307.01050</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the connections between optimal transport and variational
inference, with a focus on forward and reverse time stochastic differential
equations and Girsanov transformations.We present a principled and systematic
framework for sampling and generative modelling centred around divergences on
path space. Our work culminates in the development of a novel score-based
annealed flow technique (with connections to Jarzynski and Crooks identities
from statistical physics) and a regularised iterative proportional fitting
(IPF)-type objective, departing from the sequential nature of standard IPF.
Through a series of generative modelling examples and a double-well-based rare
event task, we showcase the potential of the proposed methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1&quot;&gt;Francisco Vargas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nusken_N/0/1/0/all/0/1&quot;&gt;Nikolas N&amp;#xfc;sken&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.01827">
<title>Deconstructing Data Reconstruction: Multiclass, Weight Decay and General Losses. (arXiv:2307.01827v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.01827</link>
<description rdf:parseType="Literal">&lt;p&gt;Memorization of training data is an active research area, yet our
understanding of the inner workings of neural networks is still in its infancy.
Recently, Haim et al. (2022) proposed a scheme to reconstruct training samples
from multilayer perceptron binary classifiers, effectively demonstrating that a
large portion of training samples are encoded in the parameters of such
networks. In this work, we extend their findings in several directions,
including reconstruction from multiclass and convolutional neural networks. We
derive a more general reconstruction scheme which is applicable to a wider
range of loss functions such as regression losses. Moreover, we study the
various factors that contribute to networks&apos; susceptibility to such
reconstruction schemes. Intriguingly, we observe that using weight decay during
training increases reconstructability both in terms of quantity and quality.
Additionally, we examine the influence of the number of neurons relative to the
number of training samples on the reconstructability. Code:
https://github.com/gonbuzaglo/decoreco
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buzaglo_G/0/1/0/all/0/1&quot;&gt;Gon Buzaglo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haim_N/0/1/0/all/0/1&quot;&gt;Niv Haim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yehudai_G/0/1/0/all/0/1&quot;&gt;Gilad Yehudai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1&quot;&gt;Gal Vardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oz_Y/0/1/0/all/0/1&quot;&gt;Yakir Oz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikankin_Y/0/1/0/all/0/1&quot;&gt;Yaniv Nikankin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Irani_M/0/1/0/all/0/1&quot;&gt;Michal Irani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02108">
<title>Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02108</link>
<description rdf:parseType="Literal">&lt;p&gt;In many applications, e.g. in healthcare and e-commerce, the goal of a
contextual bandit may be to learn an optimal treatment assignment policy at the
end of the experiment. That is, to minimize simple regret. However, this
objective remains understudied. We propose a new family of computationally
efficient bandit algorithms for the stochastic contextual bandit setting, where
a tuning parameter determines the weight placed on cumulative regret
minimization (where we establish near-optimal minimax guarantees) versus simple
regret minimization (where we establish state-of-the-art guarantees). Our
algorithms work with any function class, are robust to model misspecification,
and can be used in continuous arm settings. This flexibility comes from
constructing and relying on &quot;conformal arm sets&quot; (CASs). CASs provide a set of
arms for every context, encompassing the context-specific optimal arm with a
certain probability across the context distribution. Our positive results on
simple and cumulative regret guarantees are contrasted with a negative result,
which shows that no algorithm can achieve instance-dependent simple regret
guarantees while simultaneously achieving minimax optimal cumulative regret
guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1&quot;&gt;Sanath Kumar Krishnamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_R/0/1/0/all/0/1&quot;&gt;Ruohan Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1&quot;&gt;Susan Athey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02345">
<title>LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning. (arXiv:2307.02345v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02345</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern reinforcement learning (RL) can be categorized into online and offline
variants. As a pivotal aspect of both online and offline RL, current research
on the Bellman equation revolves primarily around optimization techniques and
performance enhancement rather than exploring the inherent structural
properties of the Bellman error, such as its distribution characteristics. This
study investigates the distribution of the Bellman approximation error in both
online and offline settings through iterative exploration of the Bellman
equation. We observed that both in online RL and offline RL, the Bellman error
conforms to a Logistic distribution. Building upon this discovery, this study
employed the Logistics maximum likelihood function (LLoss) as an alternative to
the commonly used MSE Loss, assuming that Bellman errors adhere to a normal
distribution. We validated our hypotheses through extensive numerical
experiments across diverse online and offline environments. In particular, we
applied corrections to the loss function across various baseline algorithms and
consistently observed that the loss function with Logistic corrections
outperformed the MSE counterpart significantly. Additionally, we conducted
Kolmogorov-Smirnov tests to confirm the reliability of the Logistic
distribution. This study&apos;s theoretical and empirical insights provide valuable
groundwork for future investigations and enhancements centered on the
distribution of Bellman errors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_O/0/1/0/all/0/1&quot;&gt;Outongyi Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Bingxin Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.03864">
<title>When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment. (arXiv:2307.03864v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.03864</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) algorithms face two distinct challenges: learning
effective representations of past and present observations, and determining how
actions influence future returns. Both challenges involve modeling long-term
dependencies. The Transformer architecture has been very successful to solve
problems that involve long-term dependencies, including in the RL domain.
However, the underlying reason for the strong performance of Transformer-based
RL methods remains unclear: is it because they learn effective memory, or
because they perform effective credit assignment? After introducing formal
definitions of memory length and credit assignment length, we design simple
configurable tasks to measure these distinct quantities. Our empirical results
reveal that Transformers can enhance the memory capability of RL algorithms,
scaling up to tasks that require memorizing observations $1500$ steps ago.
However, Transformers do not improve long-term credit assignment. In summary,
our results provide an explanation for the success of Transformers in RL, while
also highlighting an important area for future research and benchmark design.
Our code is open-sourced at https://github.com/twni2016/Memory-RL
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_T/0/1/0/all/0/1&quot;&gt;Tianwei Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1&quot;&gt;Michel Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1&quot;&gt;Benjamin Eysenbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacon_P/0/1/0/all/0/1&quot;&gt;Pierre-Luc Bacon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.05374">
<title>Multi-Task Learning to Enhance Generalizability of Neural Network Equalizers in Coherent Optical Systems. (arXiv:2307.05374v3 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2307.05374</link>
<description rdf:parseType="Literal">&lt;p&gt;For the first time, multi-task learning is proposed to improve the
flexibility of NN-based equalizers in coherent systems. A &quot;single&quot; NN-based
equalizer improves Q-factor by up to 4 dB compared to CDC, without re-training,
even with variations in launch power, symbol rate, or transmission distance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Srivallapanondh_S/0/1/0/all/0/1&quot;&gt;Sasipim Srivallapanondh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Freire_P/0/1/0/all/0/1&quot;&gt;Pedro J. Freire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Alam_A/0/1/0/all/0/1&quot;&gt;Ashraful Alam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Costa_N/0/1/0/all/0/1&quot;&gt;Nelson Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Spinnler_B/0/1/0/all/0/1&quot;&gt;Bernhard Spinnler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Napoli_A/0/1/0/all/0/1&quot;&gt;Antonio Napoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sedov_E/0/1/0/all/0/1&quot;&gt;Egor Sedov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Turitsyn_S/0/1/0/all/0/1&quot;&gt;Sergei K. Turitsyn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Prilepsky_J/0/1/0/all/0/1&quot;&gt;Jaroslaw E. Prilepsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08873">
<title>An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient. (arXiv:2307.08873v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08873</link>
<description rdf:parseType="Literal">&lt;p&gt;Restricting the variance of a policy&apos;s return is a popular choice in
risk-averse Reinforcement Learning (RL) due to its clear mathematical
definition and easy interpretability. Traditional methods directly restrict the
total return variance. Recent methods restrict the per-step reward variance as
a proxy. We thoroughly examine the limitations of these variance-based methods,
such as sensitivity to numerical scale and hindering of policy learning, and
propose to use an alternative risk measure, Gini deviation, as a substitute. We
study various properties of this new risk measure and derive a policy gradient
algorithm to minimize it. Empirical evaluation in domains where risk-aversion
can be clearly defined, shows that our algorithm can mitigate the limitations
of variance-based risk measures and achieves high return with low risk in terms
of variance and Gini deviation when others fail to learn a reasonable policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yudong Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guiliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1&quot;&gt;Pascal Poupart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yangchen Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08964">
<title>Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information. (arXiv:2307.08964v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08964</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent works in learning-integrated optimization have shown promise in
settings where the optimization problem is only partially observed or where
general-purpose optimizers perform poorly without expert tuning. By learning an
optimizer $\mathbf{g}$ to tackle these challenging problems with $f$ as the
objective, the optimization process can be substantially accelerated by
leveraging past experience. The optimizer can be trained with supervision from
known optimal solutions or implicitly by optimizing the compound function
$f\circ \mathbf{g}$. The implicit approach may not require optimal solutions as
labels and is capable of handling problem uncertainty; however, it is slow to
train and deploy due to frequent calls to optimizer $\mathbf{g}$ during both
training and testing. The training is further challenged by sparse gradients of
$\mathbf{g}$, especially for combinatorial solvers. To address these
challenges, we propose using a smooth and learnable Landscape Surrogate $M$ as
a replacement for $f\circ \mathbf{g}$. This surrogate, learnable by neural
networks, can be computed faster than the solver $\mathbf{g}$, provides dense
and smooth gradients during training, can generalize to unseen optimization
problems, and is efficiently learned via alternating optimization. We test our
approach on both synthetic problems, including shortest path and
multidimensional knapsack, and real-world problems such as portfolio
optimization, achieving comparable or superior objective values compared to
state-of-the-art baselines while reducing the number of calls to $\mathbf{g}$.
Notably, our approach outperforms existing methods for computationally
expensive high-dimensional problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zharmagambetov_A/0/1/0/all/0/1&quot;&gt;Arman Zharmagambetov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1&quot;&gt;Brandon Amos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1&quot;&gt;Aaron Ferber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Taoan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1&quot;&gt;Bistra Dilkina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yuandong Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.10683">
<title>Fractional Denoising for 3D Molecular Pre-training. (arXiv:2307.10683v2 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2307.10683</link>
<description rdf:parseType="Literal">&lt;p&gt;Coordinate denoising is a promising 3D molecular pre-training method, which
has achieved remarkable performance in various downstream drug discovery tasks.
Theoretically, the objective is equivalent to learning the force field, which
is revealed helpful for downstream tasks. Nevertheless, there are two
challenges for coordinate denoising to learn an effective force field, i.e. low
coverage samples and isotropic force field. The underlying reason is that
molecular distributions assumed by existing denoising methods fail to capture
the anisotropic characteristic of molecules. To tackle these challenges, we
propose a novel hybrid noise strategy, including noises on both dihedral angel
and coordinate. However, denoising such hybrid noise in a traditional way is no
more equivalent to learning the force field. Through theoretical deductions, we
find that the problem is caused by the dependency of the input conformation for
covariance. To this end, we propose to decouple the two types of noise and
design a novel fractional denoising method (Frad), which only denoises the
latter coordinate part. In this way, Frad enjoys both the merits of sampling
more low-energy structures and the force field equivalence. Extensive
experiments show the effectiveness of Frad in molecular representation, with a
new state-of-the-art on 9 out of 12 tasks of QM9 and on 7 out of 8 targets of
MD17.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Shikun Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ni_Y/0/1/0/all/0/1&quot;&gt;Yuyan Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lan_Y/0/1/0/all/0/1&quot;&gt;Yanyan Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zhi-Ming Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ma_W/0/1/0/all/0/1&quot;&gt;Wei-Ying Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.11957">
<title>High-performance real-world optical computing trained by in situ model-free optimization. (arXiv:2307.11957v3 [physics.optics] UPDATED)</title>
<link>http://arxiv.org/abs/2307.11957</link>
<description rdf:parseType="Literal">&lt;p&gt;Optical computing systems can provide high-speed and low-energy data
processing but face deficiencies in computationally demanding training and
simulation-to-reality gap. We propose a model-free solution for lightweight in
situ optimization of optical computing systems based on the score gradient
estimation algorithm. This approach treats the system as a black box and
back-propagates loss directly to the optical weights&apos; probabilistic
distributions, hence circumventing the need for computation-heavy and biased
system simulation. We demonstrate a superior classification accuracy on the
MNIST and FMNIST datasets through experiments on a single-layer diffractive
optical computing system. Furthermore, we show its potential for image-free and
high-speed cell analysis. The inherent simplicity of our proposed method,
combined with its low demand for computational resources, expedites the
transition of optical computing from laboratory demonstrations to real-world
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhao_G/0/1/0/all/0/1&quot;&gt;Guangyuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Shu_X/0/1/0/all/0/1&quot;&gt;Xin Shu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.14283">
<title>General Purpose Artificial Intelligence Systems (GPAIS): Properties, Definition, Taxonomy, Societal Implications and Responsible Governance. (arXiv:2307.14283v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2307.14283</link>
<description rdf:parseType="Literal">&lt;p&gt;Most applications of Artificial Intelligence (AI) are designed for a confined
and specific task. However, there are many scenarios that call for a more
general AI, capable of solving a wide array of tasks without being specifically
designed for them. The term General-Purpose Artificial Intelligence Systems
(GPAIS) has been defined to refer to these AI systems. To date, the possibility
of an Artificial General Intelligence, powerful enough to perform any
intellectual task as if it were human, or even improve it, has remained an
aspiration, fiction, and considered a risk for our society. Whilst we might
still be far from achieving that, GPAIS is a reality and sitting at the
forefront of AI research. This work discusses existing definitions for GPAIS
and proposes a new definition that allows for a gradual differentiation among
types of GPAIS according to their properties and limitations. We distinguish
between closed-world and open-world GPAIS, characterising their degree of
autonomy and ability based on several factors such as adaptation to new tasks,
competence in domains not intentionally trained for, ability to learn from few
data, or proactive acknowledgment of their own limitations. We propose a
taxonomy of approaches to realise GPAIS, describing research trends such as the
use of AI techniques to improve another AI (AI-powered AI) or (single)
foundation models. As a prime example, we delve into GenAI, aligning them with
the concepts presented in the taxonomy. We explore multi-modality, which
involves fusing various types of data sources to expand the capabilities of
GPAIS. Through the proposed definition and taxonomy, our aim is to facilitate
research collaboration across different areas that are tackling general purpose
tasks, as they share many common aspects. Finally, we discuss the state of
GPAIS, prospects, societal implications, and the need for regulation and
governance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Triguero_I/0/1/0/all/0/1&quot;&gt;Isaac Triguero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molina_D/0/1/0/all/0/1&quot;&gt;Daniel Molina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poyatos_J/0/1/0/all/0/1&quot;&gt;Javier Poyatos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ser_J/0/1/0/all/0/1&quot;&gt;Javier Del Ser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herrera_F/0/1/0/all/0/1&quot;&gt;Francisco Herrera&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.00180">
<title>General Anomaly Detection of Underwater Gliders Validated by Large-scale Deployment Datasets. (arXiv:2308.00180v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2308.00180</link>
<description rdf:parseType="Literal">&lt;p&gt;Underwater gliders have been widely used in oceanography for a range of
applications. However, unpredictable events like shark strikes or remora
attachments can lead to abnormal glider behavior or even loss of the
instrument. This paper employs an anomaly detection algorithm to assess
operational conditions of underwater gliders in the real-world ocean
environment. Prompt alerts are provided to glider pilots upon detecting any
anomaly, so that they can take control of the glider to prevent further harm.
The detection algorithm is applied to multiple datasets collected in real
glider deployments led by the University of Georgia&apos;s Skidaway Institute of
Oceanography (SkIO) and the University of South Florida (USF). In order to
demonstrate the algorithm generality, the experimental evaluation is applied to
four glider deployment datasets, each highlighting various anomalies happening
in different scenes. Specifically, we utilize high resolution datasets only
available post-recovery to perform detailed analysis of the anomaly and compare
it with pilot logs. Additionally, we simulate the online detection based on the
real-time subsets of data transmitted from the glider at the surfacing events.
While the real-time data may not contain as much rich information as the
post-recovery one, the online detection is of great importance as it allows
glider pilots to monitor potential abnormal conditions in real time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Ruochu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lembke_C/0/1/0/all/0/1&quot;&gt;Chad Lembke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fumin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_C/0/1/0/all/0/1&quot;&gt;Catherine Edwards&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01923">
<title>Fairness Improvement with Multiple Protected Attributes: How Far Are We?. (arXiv:2308.01923v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.01923</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing research mostly improves the fairness of Machine Learning (ML)
software regarding a single protected attribute at a time, but this is
unrealistic given that many users have multiple protected attributes. This
paper conducts an extensive study of fairness improvement regarding multiple
protected attributes, covering 11 state-of-the-art fairness improvement
methods. We analyze the effectiveness of these methods with different datasets,
metrics, and ML models when considering multiple protected attributes. The
results reveal that improving fairness for a single protected attribute can
largely decrease fairness regarding unconsidered protected attributes. This
decrease is observed in up to 88.3% of scenarios (57.5% on average). More
surprisingly, we find little difference in accuracy loss when considering
single and multiple protected attributes, indicating that accuracy can be
maintained in the multiple-attribute paradigm. However, the effect on precision
and recall when handling multiple protected attributes is about 5 times and 8
times that of a single attribute. This has important implications for future
fairness research: reporting only accuracy as the ML performance metric, which
is currently common in the literature, is inadequate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhenpeng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jie M. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarro_F/0/1/0/all/0/1&quot;&gt;Federica Sarro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harman_M/0/1/0/all/0/1&quot;&gt;Mark Harman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02618">
<title>ChatGPT for GTFS: Benchmarking LLMs on GTFS Understanding and Retrieval. (arXiv:2308.02618v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2308.02618</link>
<description rdf:parseType="Literal">&lt;p&gt;The General Transit Feed Specification (GTFS) standard for publishing transit
data is ubiquitous. GTFS being tabular data, with information spread across
different files, necessitates specialized tools or packages to retrieve
information. Concurrently, the use of Large Language Models(LLMs) for text and
information retrieval is growing. The idea of this research is to see if the
current widely adopted LLMs (ChatGPT) are able to understand GTFS and retrieve
information from GTFS using natural language instructions without explicitly
providing information. In this research, we benchmark OpenAI&apos;s GPT-3.5-Turbo
and GPT-4 LLMs which are the backbone of ChatGPT. ChatGPT demonstrates a
reasonable understanding of GTFS by answering 59.7% (GPT-3.5-Turbo) and 73.3%
(GPT-4) of our multiple-choice questions (MCQ) correctly. Furthermore, we
evaluated the LLMs on information extraction tasks using a filtered GTFS feed
containing four routes. We found that program synthesis techniques outperformed
zero-shot approaches, achieving up to 93% (90%) accuracy for simple queries and
61% (41%) for complex ones using GPT-4 (GPT-3.5-Turbo).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devunuri_S/0/1/0/all/0/1&quot;&gt;Saipraneeth Devunuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiam_S/0/1/0/all/0/1&quot;&gt;Shirin Qiam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehe_L/0/1/0/all/0/1&quot;&gt;Lewis Lehe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.15457">
<title>From SMOTE to Mixup for Deep Imbalanced Classification. (arXiv:2308.15457v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.15457</link>
<description rdf:parseType="Literal">&lt;p&gt;Given imbalanced data, it is hard to train a good classifier using deep
learning because of the poor generalization of minority classes. Traditionally,
the well-known synthetic minority oversampling technique (SMOTE) for data
augmentation, a data mining approach for imbalanced learning, has been used to
improve this generalization. However, it is unclear whether SMOTE also benefits
deep learning. In this work, we study why the original SMOTE is insufficient
for deep learning, and enhance SMOTE using soft labels. Connecting the
resulting soft SMOTE with Mixup, a modern data augmentation technique, leads to
a unified framework that puts traditional and modern data augmentation
techniques under the same umbrella. A careful study within this framework shows
that Mixup improves generalization by implicitly achieving uneven margins
between majority and minority classes. We then propose a novel margin-aware
Mixup technique that more explicitly achieves uneven margins. Extensive
experimental results demonstrate that our proposed technique yields
state-of-the-art performance on deep imbalanced classification while achieving
superior performance on extremely imbalanced data. The code is open-sourced in
our developed package https://github.com/ntucllab/imbalanced-DL to foster
future research in this direction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1&quot;&gt;Wei-Chao Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1&quot;&gt;Tan-Ha Mai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hsuan-Tien Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.16150">
<title>Modality Cycles with Masked Conditional Diffusion for Unsupervised Anomaly Segmentation in MRI. (arXiv:2308.16150v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.16150</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised anomaly segmentation aims to detect patterns that are distinct
from any patterns processed during training, commonly called abnormal or
out-of-distribution patterns, without providing any associated manual
segmentations. Since anomalies during deployment can lead to model failure,
detecting the anomaly can enhance the reliability of models, which is valuable
in high-risk domains like medical imaging. This paper introduces Masked
Modality Cycles with Conditional Diffusion (MMCCD), a method that enables
segmentation of anomalies across diverse patterns in multimodal MRI. The method
is based on two fundamental ideas. First, we propose the use of cyclic modality
translation as a mechanism for enabling abnormality detection.
Image-translation models learn tissue-specific modality mappings, which are
characteristic of tissue physiology. Thus, these learned mappings fail to
translate tissues or image patterns that have never been encountered during
training, and the error enables their segmentation. Furthermore, we combine
image translation with a masked conditional diffusion model, which attempts to
`imagine&apos; what tissue exists under a masked area, further exposing unknown
patterns as the generative model fails to recreate them. We evaluate our method
on a proxy task by training on healthy-looking slices of BraTS2021
multi-modality MRIs and testing on slices with tumors. We show that our method
compares favorably to previous unsupervised approaches based on image
reconstruction and denoising with autoencoders and diffusion models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liang_Z/0/1/0/all/0/1&quot;&gt;Ziyun Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Anthony_H/0/1/0/all/0/1&quot;&gt;Harry Anthony&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wagner_F/0/1/0/all/0/1&quot;&gt;Felix Wagner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kamnitsas_K/0/1/0/all/0/1&quot;&gt;Konstantinos Kamnitsas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.08473">
<title>On some limitations of data-driven weather forecasting models. (arXiv:2309.08473v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2309.08473</link>
<description rdf:parseType="Literal">&lt;p&gt;As in many other areas of engineering and applied science, Machine Learning
(ML) is having a profound impact in the domain of Weather and Climate
Prediction. A very recent development in this area has been the emergence of
fully data-driven ML prediction models which routinely claim superior
performance to that of traditional physics-based models. In this work, we
examine some aspects of the forecasts produced by an exemplar of the current
generation of ML models, Pangu-Weather, with a focus on the fidelity and
physical consistency of those forecasts and how these characteristics relate to
perceived forecast performance. The main conclusion is that Pangu-Weather
forecasts, and possibly those of similar ML models, do not have the fidelity
and physical consistency of physics-based models and their advantage in
accuracy on traditional deterministic metrics of forecast skill can be at least
partly attributed to these peculiarities. Balancing forecast skill and physical
consistency of ML-driven predictions will be an important consideration for
future ML models. However, and similarly to other modern post-processing
technologies, the current ML models appear to be already able to add value to
standard NWP output for specific forecast applications and combined with their
extremely low computational cost during deployment, are set to provide an
additional, useful source of forecast information. .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bonavita_M/0/1/0/all/0/1&quot;&gt;Massimo Bonavita&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.09599">
<title>MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential Deep Learning. (arXiv:2309.09599v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.09599</link>
<description rdf:parseType="Literal">&lt;p&gt;Advancements in deep learning-based 3D object detection necessitate the
availability of large-scale datasets. However, this requirement introduces the
challenge of manual annotation, which is often both burdensome and
time-consuming. To tackle this issue, the literature has seen the emergence of
several weakly supervised frameworks for 3D object detection which can
automatically generate pseudo labels for unlabeled data. Nevertheless, these
generated pseudo labels contain noise and are not as accurate as those labeled
by humans. In this paper, we present the first approach that addresses the
inherent ambiguities present in pseudo labels by introducing an Evidential Deep
Learning (EDL) based uncertainty estimation framework. Specifically, we propose
MEDL-U, an EDL framework based on MTrans, which not only generates pseudo
labels but also quantifies the associated uncertainties. However, applying EDL
to 3D object detection presents three primary challenges: (1) relatively lower
pseudolabel quality in comparison to other autolabelers; (2) excessively high
evidential uncertainty estimates; and (3) lack of clear interpretability and
effective utilization of uncertainties for downstream tasks. We tackle these
issues through the introduction of an uncertainty-aware IoU-based loss, an
evidence-aware multi-task loss function, and the implementation of a
post-processing stage for uncertainty refinement. Our experimental results
demonstrate that probabilistic detectors trained using the outputs of MEDL-U
surpass deterministic detectors trained using outputs from previous 3D
annotators on the KITTI val set for all difficulty levels. Moreover, MEDL-U
achieves state-of-the-art results on the KITTI official test set compared to
existing 3D automatic annotators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paat_H/0/1/0/all/0/1&quot;&gt;Helbert Paat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lian_Q/0/1/0/all/0/1&quot;&gt;Qing Lian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1&quot;&gt;Weilong Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.17130">
<title>GRANDE: Gradient-Based Decision Tree Ensembles. (arXiv:2309.17130v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.17130</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the success of deep learning for text and image data, tree-based
ensemble models are still state-of-the-art for machine learning with
heterogeneous tabular data. However, there is a significant need for
tabular-specific gradient-based methods due to their high flexibility. In this
paper, we propose $\text{GRANDE}$, $\text{GRA}$die$\text{N}$t-Based
$\text{D}$ecision Tree $\text{E}$nsembles, a novel approach for learning hard,
axis-aligned decision tree ensembles using end-to-end gradient descent. GRANDE
is based on a dense representation of tree ensembles, which affords to use
backpropagation with a straight-through operator to jointly optimize all model
parameters. Our method combines axis-aligned splits, which is a useful
inductive bias for tabular data, with the flexibility of gradient-based
optimization. Furthermore, we introduce an advanced instance-wise weighting
that facilitates learning representations for both, simple and complex
relations, within a single model. We conducted an extensive evaluation on a
predefined benchmark with 19 classification datasets and demonstrate that our
method outperforms existing gradient-boosting and deep learning frameworks on
most datasets. The method is available under:
https://github.com/s-marton/GRANDE
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marton_S/0/1/0/all/0/1&quot;&gt;Sascha Marton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ludtke_S/0/1/0/all/0/1&quot;&gt;Stefan L&amp;#xfc;dtke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartelt_C/0/1/0/all/0/1&quot;&gt;Christian Bartelt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stuckenschmidt_H/0/1/0/all/0/1&quot;&gt;Heiner Stuckenschmidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.05812">
<title>Provably Convergent Data-Driven Convex-Nonconvex Regularization. (arXiv:2310.05812v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.05812</link>
<description rdf:parseType="Literal">&lt;p&gt;An emerging new paradigm for solving inverse problems is via the use of deep
learning to learn a regularizer from data. This leads to high-quality results,
but often at the cost of provable guarantees. In this work, we show how
well-posedness and convergent regularization arises within the convex-nonconvex
(CNC) framework for inverse problems. We introduce a novel input weakly convex
neural network (IWCNN) construction to adapt the method of learned adversarial
regularization to the CNC framework. Empirically we show that our method
overcomes numerical issues of previous adversarial methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shumaylov_Z/0/1/0/all/0/1&quot;&gt;Zakhar Shumaylov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budd_J/0/1/0/all/0/1&quot;&gt;Jeremy Budd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1&quot;&gt;Subhadip Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1&quot;&gt;Carola-Bibiane Sch&amp;#xf6;nlieb&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.07223">
<title>Deep Learning for blind spectral unmixing of LULC classes with MODIS multispectral time series and ancillary data. (arXiv:2310.07223v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.07223</link>
<description rdf:parseType="Literal">&lt;p&gt;Remotely sensed data are dominated by mixed Land Use and Land Cover (LULC)
types. Spectral unmixing is a technique to extract information from mixed
pixels into their constituent LULC types and corresponding abundance fractions.
Traditionally, solving this task has relied on either classical methods that
require prior knowledge of endmembers or machine learning methods that avoid
explicit endmembers calculation, also known as blind spectral unmixing (BSU).
Most BSU studies based on Deep Learning (DL) focus on one time-step
hyperspectral or multispectral data. To our knowledge, here we provide the
first study on BSU of LULC classes using MODIS multispectral time series, in
presence of missing data, with end-to-end DL models. We further boost the
performance of a Long-Short Term Memory (LSTM)-based model by incorporating
geographic plus topographic (geo-topographic) and climatic ancillary
information. Our experiments show that combining spectral-temporal input data
together with geo-topographic and climatic information substantially improves
the abundance estimation of LULC classes in mixed pixels. To carry out this
study, we built a new labeled dataset of the region of Andalusia (Spain) with
monthly multispectral time series of pixels for the year 2013 from MODIS at
460m resolution, for two hierarchical levels of LULC classes, named Andalusia
MultiSpectral MultiTemporal Unmixing (Andalusia-MSMTU). This dataset provides,
at the pixel level, a multispectral time series plus ancillary information
annotated with the abundance of each LULC class inside each pixel. The dataset
(https://zenodo.org/record/7752348##.ZBmkkezMLdo) and code
(https://github.com/jrodriguezortega/MSMTU) are available to the public.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_Ortega_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Rodr&amp;#xed;guez-Ortega&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khaldi_R/0/1/0/all/0/1&quot;&gt;Rohaifa Khaldi&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alcaraz_Segura_D/0/1/0/all/0/1&quot;&gt;Domingo Alcaraz-Segura&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabik_S/0/1/0/all/0/1&quot;&gt;Siham Tabik&lt;/a&gt; (1) ((1) Department of Computer Science and Artificial Intelligence, DaSCI, University of Granada, Granada, Spain, (2) LifeWatch-ERIC ICT Core, Seville, Spain, (3) Department of Botany, Faculty of Science, University of Granada, Granada, Spain)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.07736">
<title>Observatory: Characterizing Embeddings of Relational Tables. (arXiv:2310.07736v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/2310.07736</link>
<description rdf:parseType="Literal">&lt;p&gt;Language models and specialized table embedding models have recently
demonstrated strong performance on many tasks over tabular data. Researchers
and practitioners are keen to leverage these models in many new application
contexts; but limited understanding of the strengths and weaknesses of these
models, and the table representations they generate, makes the process of
finding a suitable model for a given task reliant on trial and error. There is
an urgent need to gain a comprehensive understanding of these models to
minimize inefficiency and failures in downstream usage.
&lt;/p&gt;
&lt;p&gt;To address this need, we propose Observatory, a formal framework to
systematically analyze embedding representations of relational tables.
Motivated both by invariants of the relational data model and by statistical
considerations regarding data distributions, we define eight primitive
properties, and corresponding measures to quantitatively characterize table
embeddings for these properties. Based on these properties, we define an
extensible framework to evaluate language and table embedding models. We
collect and synthesize a suite of datasets and use Observatory to analyze nine
such models. Our analysis provides insights into the strengths and weaknesses
of learned representations over tables. We find, for example, that some models
are sensitive to table structure such as column order, that functional
dependencies are rarely reflected in embeddings, and that specialized table
embedding models have relatively lower sample fidelity. Such insights help
researchers and practitioners better anticipate model behaviors and select
appropriate models for their downstream tasks, while guiding researchers in the
development of new models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cong_T/0/1/0/all/0/1&quot;&gt;Tianji Cong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hulsebos_M/0/1/0/all/0/1&quot;&gt;Madelon Hulsebos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zhenjie Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Groth_P/0/1/0/all/0/1&quot;&gt;Paul Groth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jagadish_H/0/1/0/all/0/1&quot;&gt;H. V. Jagadish&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.08571">
<title>Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders. (arXiv:2310.08571v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.08571</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning as a Service (MLaaS) APIs provide ready-to-use and
high-utility encoders that generate vector representations for given inputs.
Since these encoders are very costly to train, they become lucrative targets
for model stealing attacks during which an adversary leverages query access to
the API to replicate the encoder locally at a fraction of the original training
costs. We propose Bucks for Buckets (B4B), the first active defense that
prevents stealing while the attack is happening without degrading
representation quality for legitimate API users. Our defense relies on the
observation that the representations returned to adversaries who try to steal
the encoder&apos;s functionality cover a significantly larger fraction of the
embedding space than representations of legitimate users who utilize the
encoder to solve a particular downstream task.vB4B leverages this to adaptively
adjust the utility of the returned representations according to a user&apos;s
coverage of the embedding space. To prevent adaptive adversaries from eluding
our defense by simply creating multiple user accounts (sybils), B4B also
individually transforms each user&apos;s representations. This prevents the
adversary from directly aggregating representations over multiple accounts to
create their stolen encoder copy. Our active defense opens a new path towards
securely sharing and democratizing encoders over public APIs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubinski_J/0/1/0/all/0/1&quot;&gt;Jan Dubi&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawlak_S/0/1/0/all/0/1&quot;&gt;Stanis&amp;#x142;aw Pawlak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boenisch_F/0/1/0/all/0/1&quot;&gt;Franziska Boenisch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1&quot;&gt;Tomasz Trzci&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dziedzic_A/0/1/0/all/0/1&quot;&gt;Adam Dziedzic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.08854">
<title>Rank-DETR for High Quality Object Detection. (arXiv:2310.08854v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.08854</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern detection transformers (DETRs) use a set of object queries to predict
a list of bounding boxes, sort them by their classification confidence scores,
and select the top-ranked predictions as the final detection results for the
given input image. A highly performant object detector requires accurate
ranking for the bounding box predictions. For DETR-based detectors, the
top-ranked bounding boxes suffer from less accurate localization quality due to
the misalignment between classification scores and localization accuracy, thus
impeding the construction of high-quality detectors. In this work, we introduce
a simple and highly performant DETR-based object detector by proposing a series
of rank-oriented designs, combinedly called Rank-DETR. Our key contributions
include: (i) a rank-oriented architecture design that can prompt positive
predictions and suppress the negative ones to ensure lower false positive
rates, as well as (ii) a rank-oriented loss function and matching cost design
that prioritizes predictions of more accurate localization accuracy during
ranking to boost the AP under high IoU thresholds. We apply our method to
improve the recent SOTA methods (e.g., H-DETR and DINO-DETR) and report strong
COCO object detection results when using different backbones such as
ResNet-$50$, Swin-T, and Swin-L, demonstrating the effectiveness of our
approach. Code is available at \url{https://github.com/LeapLabTHU/Rank-DETR}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yifan Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1&quot;&gt;Weicong Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1&quot;&gt;Yiduo Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1&quot;&gt;Yuhui Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yukang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Han Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1&quot;&gt;Gao Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.12560">
<title>Fast Model Debias with Machine Unlearning. (arXiv:2310.12560v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.12560</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent discoveries have revealed that deep neural networks might behave in a
biased manner in many real-world scenarios. For instance, deep networks trained
on a large-scale face recognition dataset CelebA tend to predict blonde hair
for females and black hair for males. Such biases not only jeopardize the
robustness of models but also perpetuate and amplify social biases, which is
especially concerning for automated decision-making processes in healthcare,
recruitment, etc., as they could exacerbate unfair economic and social
inequalities among different groups. Existing debiasing methods suffer from
high costs in bias labeling or model re-training, while also exhibiting a
deficiency in terms of elucidating the origins of biases within the model. To
this respect, we propose a fast model debiasing framework (FMD) which offers an
efficient approach to identify, evaluate and remove biases inherent in trained
models. The FMD identifies biased attributes through an explicit counterfactual
concept and quantifies the influence of data samples with influence functions.
Moreover, we design a machine unlearning-based strategy to efficiently and
effectively remove the bias in a trained model with a small counterfactual
dataset. Experiments on the Colored MNIST, CelebA, and Adult Income datasets
along with experiments with large language models demonstrate that our method
achieves superior or competing accuracies compared with state-of-the-art
methods while attaining significantly fewer biases and requiring much less
debiasing cost. Notably, our method requires only a small external dataset and
updating a minimal amount of model parameters, without the requirement of
access to training data that may be too large or unavailable in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Ruizhe Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianfei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Huimin Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1&quot;&gt;Jianhong Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1&quot;&gt;Tianxiang Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1&quot;&gt;Jin Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Joey Tianyi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zuozhu Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.12612">
<title>How a student becomes a teacher: learning and forgetting through Spectral methods. (arXiv:2310.12612v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.12612</link>
<description rdf:parseType="Literal">&lt;p&gt;In theoretical ML, the teacher-student paradigm is often employed as an
effective metaphor for real-life tuition. The above scheme proves particularly
relevant when the student network is overparameterized as compared to the
teacher network. Under these operating conditions, it is tempting to speculate
that the student ability to handle the given task could be eventually stored in
a sub-portion of the whole network. This latter should be to some extent
reminiscent of the frozen teacher structure, according to suitable metrics,
while being approximately invariant across different architectures of the
student candidate network. Unfortunately, state-of-the-art conventional
learning techniques could not help in identifying the existence of such an
invariant subnetwork, due to the inherent degree of non-convexity that
characterizes the examined problem. In this work, we take a leap forward by
proposing a radically different optimization scheme which builds on a spectral
representation of the linear transfer of information between layers. The
gradient is hence calculated with respect to both eigenvalues and eigenvectors
with negligible increase in terms of computational and complexity load, as
compared to standard training algorithms. Working in this framework, we could
isolate a stable student substructure, that mirrors the true complexity of the
teacher in terms of computing neurons, path distribution and topological
attributes. When pruning unimportant nodes of the trained student, as follows a
ranking that reflects the optimized eigenvalues, no degradation in the recorded
performance is seen above a threshold that corresponds to the effective teacher
size. The observed behavior can be pictured as a genuine second-order phase
transition that bears universality traits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giambagli_L/0/1/0/all/0/1&quot;&gt;Lorenzo Giambagli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buffoni_L/0/1/0/all/0/1&quot;&gt;Lorenzo Buffoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chicchi_L/0/1/0/all/0/1&quot;&gt;Lorenzo Chicchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fanelli_D/0/1/0/all/0/1&quot;&gt;Duccio Fanelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13139">
<title>Graph Neural Networks with polynomial activations have limited expressivity. (arXiv:2310.13139v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13139</link>
<description rdf:parseType="Literal">&lt;p&gt;The expressivity of Graph Neural Networks (GNNs) can be entirely
characterized by appropriate fragments of the first-order logic. Namely, any
query of the two variable fragment of graded modal logic (GC2) interpreted over
labeled graphs can be expressed using a GNN whose size depends only on the
depth of the query. As pointed out by [Barcelo &amp;amp; Al., 2020, Grohe, 2021], this
description holds for a family of activation functions, leaving the possibility
for a hierarchy of logics expressible by GNNs depending on the chosen
activation function. In this article, we show that such hierarchy indeed exists
by proving that GC2 queries cannot be expressed by GNNs with polynomial
activation functions. This implies a separation between polynomial and popular
non-polynomial activations (such as ReLUs, sigmoid and hyperbolic tan and
others) and answers an open question formulated by [Grohe, 2021].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalife_S/0/1/0/all/0/1&quot;&gt;Sammy Khalife&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.14201">
<title>Prompt Engineering Through the Lens of Optimal Control. (arXiv:2310.14201v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.14201</link>
<description rdf:parseType="Literal">&lt;p&gt;Prompt Engineering (PE) has emerged as a critical technique for guiding Large
Language Models (LLMs) in solving intricate tasks. Its importance is
highlighted by its potential to significantly enhance the efficiency and
effectiveness of human-machine interaction. As tasks grow increasingly complex,
recent advanced PE methods have extended beyond the limitations of single-round
interactions to embrace multi-round interactions, which allows for a deeper and
more nuanced engagement with LLMs. In this paper, we propose an optimal control
framework tailored for multi-round interactions with LLMs. This framework
provides a unified mathematical structure that not only systematizes the
existing PE methods but also sets the stage for rigorous analytical
improvements. Furthermore, we extend this framework to include PE via ensemble
methods and multi-agent collaboration, thereby enlarging the scope of
applicability. By adopting an optimal control perspective, we offer fresh
insights into existing PE methods and highlight theoretical challenges that
warrant future research. Besides, our work lays a foundation for the
development of more effective and interpretable PE methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yifan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yiming Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Chengfeng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhennan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1&quot;&gt;Bin Dong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.16789">
<title>Detecting Pretraining Data from Large Language Models. (arXiv:2310.16789v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.16789</link>
<description rdf:parseType="Literal">&lt;p&gt;Although large language models (LLMs) are widely deployed, the data used to
train them is rarely disclosed. Given the incredible scale of this data, up to
trillions of tokens, it is all but certain that it includes potentially
problematic text such as copyrighted materials, personally identifiable
information, and test data for widely reported reference benchmarks. However,
we currently have no way to know which data of these types is included or in
what proportions. In this paper, we study the pretraining data detection
problem: given a piece of text and black-box access to an LLM without knowing
the pretraining data, can we determine if the model was trained on the provided
text? To facilitate this study, we introduce a dynamic benchmark WIKIMIA that
uses data created before and after model training to support gold truth
detection. We also introduce a new detection method Min-K% Prob based on a
simple hypothesis: an unseen example is likely to contain a few outlier words
with low probabilities under the LLM, while a seen example is less likely to
have words with such low probabilities. Min-K% Prob can be applied without any
knowledge about the pretraining corpus or any additional training, departing
from previous detection methods that require training a reference model on data
that is similar to the pretraining data. Moreover, our experiments demonstrate
that Min-K% Prob achieves a 7.4% improvement on WIKIMIA over these previous
methods. We apply Min-K% Prob to three real-world scenarios, copyrighted book
detection, contaminated downstream example detection and privacy auditing of
machine unlearning, and find it a consistently effective solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1&quot;&gt;Weijia Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ajith_A/0/1/0/all/0/1&quot;&gt;Anirudh Ajith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1&quot;&gt;Mengzhou Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yangsibo Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Daogao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blevins_T/0/1/0/all/0/1&quot;&gt;Terra Blevins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Danqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1&quot;&gt;Luke Zettlemoyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.16804">
<title>Learning COVID-19 Regional Transmission Using Universal Differential Equations in a SIR model. (arXiv:2310.16804v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.16804</link>
<description rdf:parseType="Literal">&lt;p&gt;Highly-interconnected societies difficult to model the spread of infectious
diseases such as COVID-19. Single-region SIR models fail to account for
incoming forces of infection and expanding them to a large number of
interacting regions involves many assumptions that do not hold in the real
world. We propose using Universal Differential Equations (UDEs) to capture the
influence of neighboring regions and improve the model&apos;s predictions in a
combined SIR+UDE model. UDEs are differential equations totally or partially
defined by a deep neural network (DNN). We include an additive term to the SIR
equations composed by a DNN that learns the incoming force of infection from
the other regions. The learning is performed using automatic differentiation
and gradient descent to approach the change in the target system caused by the
state of the neighboring regions. We compared the proposed model using a
simulated COVID-19 outbreak against a single-region SIR and a fully data-driven
model composed only of a DNN. The proposed UDE+SIR model generates predictions
that capture the outbreak dynamic more accurately, but a decay in performance
is observed at the last stages of the outbreak. The single-area SIR and the
fully data-driven approach do not capture the proper dynamics accurately. Once
the predictions were obtained, we employed the SINDy algorithm to substitute
the DNN with a regression, removing the black box element of the model with no
considerable increase in the error levels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rojas_Campos_A/0/1/0/all/0/1&quot;&gt;Adrian Rojas-Campos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stelz_L/0/1/0/all/0/1&quot;&gt;Lukas Stelz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nieters_P/0/1/0/all/0/1&quot;&gt;Pascal Nieters&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.16945">
<title>Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2310.16945</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate estimation of conditional average treatment effects (CATE) is at the
core of personalized decision making. While there is a plethora of models for
CATE estimation, model selection is a nontrivial task, due to the fundamental
problem of causal inference. Recent empirical work provides evidence in favor
of proxy loss metrics with double robust properties and in favor of model
ensembling. However, theoretical understanding is lacking. Direct application
of prior theoretical work leads to suboptimal oracle model selection rates due
to the non-convexity of the model selection problem. We provide regret rates
for the major existing CATE ensembling approaches and propose a new CATE model
ensembling approach based on Q-aggregation using the doubly robust loss. Our
main result shows that causal Q-aggregation achieves statistically optimal
oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and
$n$ samples), with the addition of higher-order estimation error terms related
to products of errors in the nuisance functions. Crucially, our regret rate
does not require that any of the candidate CATE models be close to the truth.
We validate our new method on many semi-synthetic datasets and also provide
extensions of our work to CATE model selection with instrumental variables and
unobserved confounding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lan_H/0/1/0/all/0/1&quot;&gt;Hui Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.17584">
<title>A minimax optimal control approach for robust neural ODEs. (arXiv:2310.17584v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2310.17584</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we address the adversarial training of neural ODEs from a
robust control perspective. This is an alternative to the classical training
via empirical risk minimization, and it is widely used to enforce reliable
outcomes for input perturbations. Neural ODEs allow the interpretation of deep
neural networks as discretizations of control systems, unlocking powerful tools
from control theory for the development and the understanding of machine
learning. In this specific case, we formulate the adversarial training with
perturbed data as a minimax optimal control problem, for which we derive first
order optimality conditions in the form of Pontryagin&apos;s Maximum Principle. We
provide a novel interpretation of robust training leading to an alternative
weighted technique, which we test on a low-dimensional classification task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cipriani_C/0/1/0/all/0/1&quot;&gt;Cristina Cipriani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Scagliotti_A/0/1/0/all/0/1&quot;&gt;Alessandro Scagliotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wohrer_T/0/1/0/all/0/1&quot;&gt;Tobias W&amp;#xf6;hrer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.17785">
<title>Learning Extrinsic Dexterity with Parameterized Manipulation Primitives. (arXiv:2310.17785v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2310.17785</link>
<description rdf:parseType="Literal">&lt;p&gt;Many practically relevant robot grasping problems feature a target object for
which all grasps are occluded, e.g., by the environment. Single-shot grasp
planning invariably fails in such scenarios. Instead, it is necessary to first
manipulate the object into a configuration that affords a grasp. We solve this
problem by learning a sequence of actions that utilize the environment to
change the object&apos;s pose. Concretely, we employ hierarchical reinforcement
learning to combine a sequence of learned parameterized manipulation
primitives. By learning the low-level manipulation policies, our approach can
control the object&apos;s state through exploiting interactions between the object,
the gripper, and the environment. Designing such a complex behavior
analytically would be infeasible under uncontrolled conditions, as an analytic
approach requires accurate physical modeling of the interaction and contact
dynamics. In contrast, we learn a hierarchical policy model that operates
directly on depth perception data, without the need for object detection, pose
estimation, or manual design of controllers. We evaluate our approach on
picking box-shaped objects of various weight, shape, and friction properties
from a constrained table-top workspace. Our method transfers to a real robot
and is able to successfully complete the object picking task in 98\% of
experimental trials.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Shih-Min Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magnusson_M/0/1/0/all/0/1&quot;&gt;Martin Magnusson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stork_J/0/1/0/all/0/1&quot;&gt;Johannes A. Stork&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoyanov_T/0/1/0/all/0/1&quot;&gt;Todor Stoyanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.18144">
<title>Improving Intrinsic Exploration by Creating Stationary Objectives. (arXiv:2310.18144v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.18144</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploration bonuses in reinforcement learning guide long-horizon exploration
by defining custom intrinsic objectives. Count-based methods use the frequency
of state visits to derive an exploration bonus. In this paper, we identify that
any intrinsic reward function derived from count-based methods is
non-stationary and hence induces a difficult objective to optimize for the
agent. The key contribution of our work lies in transforming the original
non-stationary rewards into stationary rewards through an augmented state
representation. For this purpose, we introduce the Stationary Objectives For
Exploration (SOFE) framework. SOFE requires identifying sufficient statistics
for different exploration bonuses and finding an efficient encoding of these
statistics to use as input to a deep network. SOFE is based on proposing state
augmentations that expand the state space but hold the promise of simplifying
the optimization of the agent&apos;s objective. Our experiments show that SOFE
improves the agents&apos; performance in challenging exploration problems, including
sparse-reward tasks, pixel-based observations, 3D navigation, and procedurally
generated environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castanyer_R/0/1/0/all/0/1&quot;&gt;Roger Creus Castanyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romoff_J/0/1/0/all/0/1&quot;&gt;Joshua Romoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berseth_G/0/1/0/all/0/1&quot;&gt;Glen Berseth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.18860">
<title>Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization. (arXiv:2310.18860v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2310.18860</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel method for tuning the regularization hyper-parameter,
$\lambda$, of a ridge regression that is faster to compute than leave-one-out
cross-validation (LOOCV) while yielding estimates of the regression parameters
of equal, or particularly in the setting of sparse covariates, superior quality
to those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from
multiple and bad local minima for finite $n$ and thus requires the
specification of a set of candidate $\lambda$, which can fail to provide good
solutions. In contrast, we show that the proposed method is guaranteed to find
a unique optimal solution for large enough $n$, under relatively mild
conditions, without requiring the specification of any difficult to determine
hyper-parameters. This is based on a Bayesian formulation of ridge regression
that we prove to have a unimodal posterior for large enough $n$, allowing for
both the optimal $\lambda$ and the regression coefficients to be jointly
learned within an iterative expectation maximization (EM) procedure.
Importantly, we show that by utilizing an appropriate preprocessing step, a
single iteration of the main EM loop can be implemented in $O(\min(n, p))$
operations, for input data with $n$ rows and $p$ columns. In contrast,
evaluating a single value of $\lambda$ using fast LOOCV costs $O(n \min(n, p))$
operations when using the same preprocessing. This advantage amounts to an
asymptotic improvement of a factor of $l$ for $l$ candidate values for
$\lambda$ (in the regime $q, p \in O(\sqrt{n})$ where $q$ is the number of
regression targets).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tew_S/0/1/0/all/0/1&quot;&gt;Shu Yu Tew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boley_M/0/1/0/all/0/1&quot;&gt;Mario Boley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schmidt_D/0/1/0/all/0/1&quot;&gt;Daniel F. Schmidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.19589">
<title>Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message Passing. (arXiv:2310.19589v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.19589</link>
<description rdf:parseType="Literal">&lt;p&gt;Data over non-Euclidean manifolds, often discretized as surface meshes,
naturally arise in computer graphics and biological and physical systems. In
particular, solutions to partial differential equations (PDEs) over manifolds
depend critically on the underlying geometry. While graph neural networks have
been successfully applied to PDEs, they do not incorporate surface geometry and
do not consider local gauge symmetries of the manifold. Alternatively, recent
works on gauge equivariant convolutional and attentional architectures on
meshes leverage the underlying geometry but underperform in modeling surface
PDEs with complex nonlinear dynamics. To address these issues, we introduce a
new gauge equivariant architecture using nonlinear message passing. Our novel
architecture achieves higher performance than either convolutional or
attentional networks on domains with highly complex and nonlinear dynamics.
However, similar to the non-mesh case, design trade-offs favor convolutional,
attentional, or message passing networks for different tasks; we investigate in
which circumstances our message passing method provides the most benefit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jung Yeon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1&quot;&gt;Lawson L.S. Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1&quot;&gt;Robin Walters&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.20258">
<title>Advancing Bayesian Optimization via Learning Correlated Latent Space. (arXiv:2310.20258v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.20258</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian optimization is a powerful method for optimizing black-box functions
with limited function evaluations. Recent works have shown that optimization in
a latent space through deep generative models such as variational autoencoders
leads to effective and efficient Bayesian optimization for structured or
discrete data. However, as the optimization does not take place in the input
space, it leads to an inherent gap that results in potentially suboptimal
solutions. To alleviate the discrepancy, we propose Correlated latent space
Bayesian Optimization (CoBO), which focuses on learning correlated latent
spaces characterized by a strong correlation between the distances in the
latent space and the distances within the objective function. Specifically, our
method introduces Lipschitz regularization, loss weighting, and trust region
recoordination to minimize the inherent gap around the promising areas. We
demonstrate the effectiveness of our approach on several optimization tasks in
discrete data, such as molecule design and arithmetic expression fitting, and
achieve high performance within a small budget.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seunghun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_J/0/1/0/all/0/1&quot;&gt;Jaewon Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sihyeon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1&quot;&gt;Juyeon Ko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyunwoo J. Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.20380">
<title>Dropout Strategy in Reinforcement Learning: Limiting the Surrogate Objective Variance in Policy Optimization Methods. (arXiv:2310.20380v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.20380</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy-based reinforcement learning algorithms are widely used in various
fields. Among them, mainstream policy optimization algorithms such as TRPO and
PPO introduce importance sampling into policy iteration, which allows the reuse
of historical data. However, this can also lead to a high variance of the
surrogate objective and indirectly affects the stability and convergence of the
algorithm. In this paper, we first derived an upper bound of the surrogate
objective variance, which can grow quadratically with the increase of the
surrogate objective. Next, we proposed the dropout technique to avoid the
excessive increase of the surrogate objective variance caused by importance
sampling. Then, we introduced a general reinforcement learning framework
applicable to mainstream policy optimization methods, and applied the dropout
technique to the PPO algorithm to obtain the D-PPO variant. Finally, we conduct
comparative experiments between D-PPO and PPO algorithms in the Atari 2600
environment, and the results show that D-PPO achieved significant performance
improvements compared to PPO, and effectively limited the excessive increase of
the surrogate objective variance during training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1&quot;&gt;Zhengpeng Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Changdong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_W/0/1/0/all/0/1&quot;&gt;Weizheng Qiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.20550">
<title>CapsFusion: Rethinking Image-Text Data at Scale. (arXiv:2310.20550v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.20550</link>
<description rdf:parseType="Literal">&lt;p&gt;Large multimodal models demonstrate remarkable generalist ability to perform
diverse multimodal tasks in a zero-shot manner. Large-scale web-based
image-text pairs contribute fundamentally to this success, but suffer from
excessive noise. Recent studies use alternative captions synthesized by
captioning models and have achieved notable benchmark performance. However, our
experiments reveal significant Scalability Deficiency and World Knowledge Loss
issues in models trained with synthetic captions, which have been largely
obscured by their initial benchmark success. Upon closer examination, we
identify the root cause as the overly-simplified language structure and lack of
knowledge details in existing synthetic captions. To provide higher-quality and
more scalable multimodal pretraining data, we propose CapsFusion, an advanced
framework that leverages large language models to consolidate and refine
information from both web-based image-text pairs and synthetic captions.
Extensive experiments show that CapsFusion captions exhibit remarkable
all-round superiority over existing captions in terms of model performance
(e.g., 18.8 and 18.3 improvements in CIDEr score on COCO and NoCaps), sample
efficiency (requiring 11-16 times less computation than baselines), world
knowledge depth, and scalability. These effectiveness, efficiency and
scalability advantages position CapsFusion as a promising candidate for future
scaling of LMM training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1&quot;&gt;Qiying Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Quan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaosong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1&quot;&gt;Yufeng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yue Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinlong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingjing Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00060">
<title>Ensemble models outperform single model uncertainties and predictions for operator-learning of hypersonic flows. (arXiv:2311.00060v2 [physics.flu-dyn] UPDATED)</title>
<link>http://arxiv.org/abs/2311.00060</link>
<description rdf:parseType="Literal">&lt;p&gt;High-fidelity computational simulations and physical experiments of
hypersonic flows are resource intensive. Training scientific machine learning
(SciML) models on limited high-fidelity data offers one approach to rapidly
predict behaviors for situations that have not been seen before. However,
high-fidelity data is itself in limited quantity to validate all outputs of the
SciML model in unexplored input space. As such, an uncertainty-aware SciML
model is desired. The SciML model&apos;s output uncertainties could then be used to
assess the reliability and confidence of the model&apos;s predictions. In this
study, we extend a DeepONet using three different uncertainty quantification
mechanisms: mean-variance estimation, evidential uncertainty, and ensembling.
The uncertainty aware DeepONet models are trained and evaluated on the
hypersonic flow around a blunt cone object with data generated via
computational fluid dynamics over a wide range of Mach numbers and altitudes.
We find that ensembling outperforms the other two uncertainty models in terms
of minimizing error and calibrating uncertainty in both interpolative and
extrapolative regimes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Leon_V/0/1/0/all/0/1&quot;&gt;Victor J. Leon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ford_N/0/1/0/all/0/1&quot;&gt;Noah Ford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mrema_H/0/1/0/all/0/1&quot;&gt;Honest Mrema&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gilbert_J/0/1/0/all/0/1&quot;&gt;Jeffrey Gilbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+New_A/0/1/0/all/0/1&quot;&gt;Alexander New&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00687">
<title>Improving Interpersonal Communication by Simulating Audiences with Language Models. (arXiv:2311.00687v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2311.00687</link>
<description rdf:parseType="Literal">&lt;p&gt;How do we communicate with others to achieve our goals? We use our prior
experience or advice from others, or construct a candidate utterance by
predicting how it will be received. However, our experiences are limited and
biased, and reasoning about potential outcomes can be difficult and cognitively
challenging. In this paper, we explore how we can leverage Large Language Model
(LLM) simulations to help us communicate better. We propose the
Explore-Generate-Simulate (EGS) framework, which takes as input any scenario
where an individual is communicating to an audience with a goal they want to
achieve. EGS (1) explores the solution space by producing a diverse set of
advice relevant to the scenario, (2) generates communication candidates
conditioned on subsets of the advice, and (3) simulates the reactions from
various audiences to determine both the best candidate and advice to use. We
evaluate the framework on eight scenarios spanning the ten fundamental
processes of interpersonal communication. For each scenario, we collect a
dataset of human evaluations across candidates and baselines, and showcase that
our framework&apos;s chosen candidate is preferred over popular generation
mechanisms including Chain-of-Thought. We also find that audience simulations
achieve reasonably high agreement with human raters across 5 of the 8
scenarios. Finally, we demonstrate the generality of our framework by applying
it to real-world scenarios described by users on web forums. Through
evaluations and demonstrations, we show that EGS enhances the effectiveness and
outcomes of goal-oriented communication across a variety of situations, thus
opening up new possibilities for the application of large language models in
revolutionizing communication and decision-making processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Ryan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yen_H/0/1/0/all/0/1&quot;&gt;Howard Yen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marjieh_R/0/1/0/all/0/1&quot;&gt;Raja Marjieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1&quot;&gt;Thomas L. Griffiths&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1&quot;&gt;Ranjay Krishna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01282">
<title>FlashDecoding++: Faster Large Language Model Inference on GPUs. (arXiv:2311.01282v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.01282</link>
<description rdf:parseType="Literal">&lt;p&gt;As the Large Language Model (LLM) becomes increasingly important in various
domains. However, the following challenges still remain unsolved in
accelerating LLM inference: (1) Synchronized partial softmax update. The
softmax operation requires a synchronized update operation among each partial
softmax result, leading to ~20% overheads for the attention computation in
LLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices
performing GEMM in LLM inference is flat, leading to under-utilized computation
and &amp;gt;50% performance loss after padding zeros in previous designs. (3)
Performance loss due to static dataflow. Kernel performance in LLM depends on
varied input data features, hardware configurations, etc. A single and static
dataflow may lead to a 50.25% performance loss for GEMMs of different shapes in
LLM inference.
&lt;/p&gt;
&lt;p&gt;We present FlashDecoding++, a fast LLM inference engine supporting mainstream
LLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++
creatively proposes: (1) Asynchronized softmax with unified max value.
FlashDecoding++ introduces a unified max value technique for different partial
softmax computations to avoid synchronization. (2) Flat GEMM optimization with
double buffering. FlashDecoding++ points out that flat GEMMs with different
shapes face varied bottlenecks. Then, techniques like double buffering are
introduced. (3) Heuristic dataflow with hardware resource adaptation.
FlashDecoding++ heuristically optimizes dataflow using different hardware
resource considering input dynamics. Due to the versatility of optimizations in
FlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on
both NVIDIA and AMD GPUs compared to Hugging Face implementations.
FlashDecoding++ also achieves an average speedup of 1.37x compared to
state-of-the-art LLM inference engines on mainstream LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1&quot;&gt;Ke Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_G/0/1/0/all/0/1&quot;&gt;Guohao Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiaming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1&quot;&gt;Qiuli Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiuhong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kangdi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1&quot;&gt;Hanyu Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04532">
<title>Long Sequence Hopfield Memory. (arXiv:2306.04532v2 [cs.NE] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2306.04532</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequence memory is an essential attribute of natural and artificial
intelligence that enables agents to encode, store, and retrieve complex
sequences of stimuli and actions. Computational models of sequence memory have
been proposed where recurrent Hopfield-like neural networks are trained with
temporally asymmetric Hebbian rules. However, these networks suffer from
limited sequence capacity (maximal length of the stored sequence) due to
interference between the memories. Inspired by recent work on Dense Associative
Memories, we expand the sequence capacity of these models by introducing a
nonlinear interaction term, enhancing separation between the patterns. We
derive novel scaling laws for sequence capacity with respect to network size,
significantly outperforming existing scaling laws for models based on
traditional Hopfield networks, and verify these theoretical results with
numerical simulation. Moreover, we introduce a generalized pseudoinverse rule
to recall sequences of highly correlated patterns. Finally, we extend this
model to store sequences with variable timing between states&apos; transitions and
describe a biologically-plausible implementation, with connections to motor
neuroscience.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhry_H/0/1/0/all/0/1&quot;&gt;Hamza Tahir Chaudhry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zavatone_Veth_J/0/1/0/all/0/1&quot;&gt;Jacob A. Zavatone-Veth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krotov_D/0/1/0/all/0/1&quot;&gt;Dmitry Krotov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pehlevan_C/0/1/0/all/0/1&quot;&gt;Cengiz Pehlevan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.17688">
<title>Managing AI Risks in an Era of Rapid Progress. (arXiv:2310.17688v1 [cs.CY] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2310.17688</link>
<description rdf:parseType="Literal">&lt;p&gt;In this short consensus paper, we outline risks from upcoming, advanced AI
systems. We examine large-scale social harms and malicious uses, as well as an
irreversible loss of human control over autonomous AI systems. In light of
rapid and continuing AI progress, we propose priorities for AI R&amp;amp;D and
governance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hinton_G/0/1/0/all/0/1&quot;&gt;Geoffrey Hinton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1&quot;&gt;Andrew Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dawn Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harari_Y/0/1/0/all/0/1&quot;&gt;Yuval Noah Harari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Ya-Qin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1&quot;&gt;Lan Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shalev_Shwartz_S/0/1/0/all/0/1&quot;&gt;Shai Shalev-Shwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadfield_G/0/1/0/all/0/1&quot;&gt;Gillian Hadfield&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1&quot;&gt;Jeff Clune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maharaj_T/0/1/0/all/0/1&quot;&gt;Tegan Maharaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baydin_A/0/1/0/all/0/1&quot;&gt;At&amp;#x131;l&amp;#x131;m G&amp;#xfc;ne&amp;#x15f; Baydin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McIlraith_S/0/1/0/all/0/1&quot;&gt;Sheila McIlraith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1&quot;&gt;Qiqi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1&quot;&gt;Ashwin Acharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krueger_D/0/1/0/all/0/1&quot;&gt;David Krueger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip Torr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1&quot;&gt;Stuart Russell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahneman_D/0/1/0/all/0/1&quot;&gt;Daniel Kahneman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1&quot;&gt;Jan Brauner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf6;ren Mindermann&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>