<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-07-03T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00004" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00009" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00012" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00014" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00024" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00032" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00033" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00035" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00036" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00039" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00066" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00067" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00079" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00080" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00088" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00104" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00106" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00108" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00117" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00123" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00125" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00126" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00131" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00134" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00141" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00142" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00144" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00149" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00154" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00157" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00161" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00162" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00168" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00169" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00171" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00175" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00185" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00213" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00215" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00222" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00227" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00228" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00231" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00233" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00238" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00246" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00247" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00252" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00268" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00274" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00280" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00285" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00290" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00293" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00296" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00305" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00309" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00310" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00316" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1911.10322" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2002.04258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2009.07888" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2012.04597" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.12021" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.14639" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.03907" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.14015" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.02378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.04470" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.10258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.02271" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.05674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.03892" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.09982" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.11660" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.14900" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2202.13975" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2203.06527" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2204.02937" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.01138" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.10947" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.00667" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.00820" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.03792" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.03851" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.03922" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.10540" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.10553" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.00208" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.00884" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.06146" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.06648" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.12227" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.13713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.03475" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.13578" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.13678" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.15635" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.01910" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.02410" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.04165" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.05723" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.07661" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.10737" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.13507" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.16424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.17283" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.01738" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.03216" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.03803" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.05039" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.11736" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.12044" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.13289" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.15875" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.10478" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.10511" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.13679" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.03147" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.10813" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.10908" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.12579" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.01470" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.02119" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.02399" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.03122" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.05686" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.06279" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.06354" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.06600" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.07294" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.07517" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.09543" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.10258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.10289" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.10681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.10894" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.11012" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.11628" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.11700" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.12432" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.12559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.14260" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.02063" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.04356" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.09335" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.11338" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.14244" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.14464" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.15485" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.01117" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.06502" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.07702" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.08158" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.09914" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.11436" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.12944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.13230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.14248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.14343" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.01666" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.03774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.05392" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06174" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06569" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06989" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.10210" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13093" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15889" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.16380" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18438" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18624" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18777" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.20002" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.00488" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.00942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.01589" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.02561" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.03828" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04376" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04527" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04634" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04940" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.06674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.07024" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.07743" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.07812" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.07874" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.07961" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.08984" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.09548" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.10234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.10640" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.10946" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11667" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11768" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12594" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12640" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12729" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.13800" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.14288" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.14759" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.14891" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.15156" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.15538" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.15656" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.15868" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.15969" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.16817" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.17323" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.17624" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.00068" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2307.00004">
<title>PV Fleet Modeling via Smooth Periodic Gaussian Copula. (arXiv:2307.00004v1 [stat.AP])</title>
<link>http://arxiv.org/abs/2307.00004</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for jointly modeling power generation from a fleet of
photovoltaic (PV) systems. We propose a white-box method that finds a function
that invertibly maps vector time-series data to independent and identically
distributed standard normal variables. The proposed method, based on a novel
approach for fitting a smooth, periodic copula transform to data, captures many
aspects of the data such as diurnal variation in the distribution of power
output, dependencies among different PV systems, and dependencies across time.
It consists of interpretable steps and is scalable to many systems. The
resulting joint probability model of PV fleet output across systems and time
can be used to generate synthetic data, impute missing data, perform anomaly
detection, and make forecasts. In this paper, we explain the method and
demonstrate these applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ogut_M/0/1/0/all/0/1&quot;&gt;Mehmet G. Ogut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meyers_B/0/1/0/all/0/1&quot;&gt;Bennet Meyers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boyd_S/0/1/0/all/0/1&quot;&gt;Stephen P. Boyd&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00009">
<title>Automated Assignment and Classification of Software Issues. (arXiv:2307.00009v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.00009</link>
<description rdf:parseType="Literal">&lt;p&gt;Software issues contain units of work to fix, improve or create new threads
during the development and facilitate communication among the team members.
Assigning an issue to the most relevant team member and determining a category
of an issue is a tedious and challenging task. Wrong classifications cause
delays and rework in the project and trouble among the team members. This
thesis proposes a set of carefully curated linguistic features for shallow
machine learning methods and compares the performance of shallow and ensemble
methods with deep language models. Unlike the state-of-the-art, we assign
issues to four roles (designer, developer, tester, and leader) rather than to
specific individuals or teams to contribute to the generality of our solution.
We also consider the level of experience of the developers to reflect the
industrial practices in our solution formulation. We employ a classification
approach to categorize issues into distinct classes, namely bug, new feature,
improvement, and other. Additionally, we endeavor to further classify bugs
based on the specific type of modification required. We collect and annotate
five industrial data sets from one of the top three global television producers
to evaluate our proposal and compare it with deep language models. Our data
sets contain 5324 issues in total. We show that an ensemble classifier of
shallow techniques achieves 0.92 for issue assignment and 0.90 for issue
classification in accuracy which is statistically comparable to the
state-of-the-art deep language models. The contributions include the public
sharing of five annotated industrial issue data sets, the development of a
clear and comprehensive feature set, the introduction of a novel label set and
the validation of the efficacy of an ensemble classifier of shallow machine
learning techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabak_B/0/1/0/all/0/1&quot;&gt;B&amp;#xfc;&amp;#x15f;ra Tabak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00012">
<title>Black-Box Prediction of Flaky Test Fix Categories Using Language Models. (arXiv:2307.00012v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2307.00012</link>
<description rdf:parseType="Literal">&lt;p&gt;Flaky tests are problematic because they non-deterministically pass or fail
for the same software version under test, causing confusion and wasting
developer time. While machine learning models have been used to predict
flakiness and its root causes, there is less work on providing support to fix
the problem. To address this gap, we propose a framework that automatically
generates labeled datasets for 13 fix categories and train models to predict
the fix category of a flaky test by analyzing the test code only. Though it is
unrealistic at this stage to accurately predict the fix itself, the categories
provide precise guidance about what part of the test code to look at. Our
approach is based on language models, namely CodeBERT and UniXcoder, whose
output is fine-tuned with a Feed Forward Neural Network (FNN) or a Siamese
Network-based Few Shot Learning (FSL). Our experimental results show that
UniXcoder outperforms CodeBERT, in correctly predicting most of the categories
of fixes a developer should apply. Furthermore, FSL does not appear to have any
significant effect. Given the high accuracy obtained for most fix categories,
our proposed framework has the potential to help developers to fix flaky tests
quickly and accurately.To aid future research, we make our automated labeling
tool, dataset, prediction models, and experimental infrastructure publicly
available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fatima_S/0/1/0/all/0/1&quot;&gt;Sakina Fatima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemmati_H/0/1/0/all/0/1&quot;&gt;Hadi Hemmati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Briand_L/0/1/0/all/0/1&quot;&gt;Lionel Briand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00014">
<title>Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions. (arXiv:2307.00014v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2307.00014</link>
<description rdf:parseType="Literal">&lt;p&gt;Inertial sensing is used in many applications and platforms, ranging from
day-to-day devices such as smartphones to very complex ones such as autonomous
vehicles. In recent years, the development of machine learning and deep
learning techniques has increased significantly in the field of inertial
sensing. This is due to the development of efficient computing hardware and the
accessibility of publicly available sensor data. These data-driven approaches
are used to empower model-based navigation and sensor fusion algorithms. This
paper provides an in-depth review of those deep learning methods. We examine
separately, each vehicle operation domain including land, air, and sea. Each
domain is divided into pure inertial advances and improvements based on filter
parameters learning. In addition, we review deep learning approaches for
calibrating and denoising inertial sensors. Throughout the paper, we discuss
these trends and future directions. We also provide statistics on the commonly
used approaches to illustrate their efficiency and stimulate further research
in deep learning embedded in inertial navigation and fusion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1&quot;&gt;Nadav Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klein_I/0/1/0/all/0/1&quot;&gt;Itzik Klein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00024">
<title>EmoSpeech: Guiding FastSpeech2 Towards Emotional Text to Speech. (arXiv:2307.00024v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2307.00024</link>
<description rdf:parseType="Literal">&lt;p&gt;State-of-the-art speech synthesis models try to get as close as possible to
the human voice. Hence, modelling emotions is an essential part of
Text-To-Speech (TTS) research. In our work, we selected FastSpeech2 as the
starting point and proposed a series of modifications for synthesizing
emotional speech. According to automatic and human evaluation, our model,
EmoSpeech, surpasses existing models regarding both MOS score and emotion
recognition accuracy in generated speech. We provided a detailed ablation study
for every extension to FastSpeech2 architecture that forms EmoSpeech. The
uneven distribution of emotions in the text is crucial for better, synthesized
speech and intonation perception. Our model includes a conditioning mechanism
that effectively handles this issue by allowing emotions to contribute to each
phone with varying intensity levels. The human assessment indicates that
proposed modifications generate audio with higher MOS and emotional
expressiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Diatlova_D/0/1/0/all/0/1&quot;&gt;Daria Diatlova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shutov_V/0/1/0/all/0/1&quot;&gt;Vitaly Shutov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00028">
<title>Seeing in Words: Learning to Classify through Language Bottlenecks. (arXiv:2307.00028v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00028</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks for computer vision extract uninterpretable features despite
achieving high accuracy on benchmarks. In contrast, humans can explain their
predictions using succinct and intuitive descriptions. To incorporate
explainability into neural networks, we train a vision model whose feature
representations are text. We show that such a model can effectively classify
ImageNet images, and we discuss the challenges we encountered when training it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saifullah_K/0/1/0/all/0/1&quot;&gt;Khalid Saifullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1&quot;&gt;Jonas Geiping&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1&quot;&gt;Micah Goldblum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1&quot;&gt;Tom Goldstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00032">
<title>Uncertainty Informed Optimal Resource Allocation with Gaussian Process based Bayesian Inference. (arXiv:2307.00032v1 [math.OC])</title>
<link>http://arxiv.org/abs/2307.00032</link>
<description rdf:parseType="Literal">&lt;p&gt;We focus on the problem of uncertainty informed allocation of medical
resources (vaccines) to heterogeneous populations for managing epidemic spread.
We tackle two related questions: (1) For a compartmental ordinary differential
equation (ODE) model of epidemic spread, how can we estimate and integrate
parameter uncertainty into resource allocation decisions? (2) How can we
computationally handle both nonlinear ODE constraints and parameter
uncertainties for a generic stochastic optimization problem for resource
allocation? To the best of our knowledge current literature does not fully
resolve these questions. Here, we develop a data-driven approach to represent
parameter uncertainty accurately and tractably in a novel stochastic
optimization problem formulation. We first generate a tractable scenario set by
estimating the distribution on ODE model parameters using Bayesian inference
with Gaussian processes. Next, we develop a parallelized solution algorithm
that accounts for scenario-dependent nonlinear ODE constraints. Our
scenario-set generation procedure and solution approach are flexible in that
they can handle any compartmental epidemiological ODE model. Our computational
experiments on two different non-linear ODE models (SEIR and SEPIHR) indicate
that accounting for uncertainty in key epidemiological parameters can improve
the efficacy of time-critical allocation decisions by 4-8%. This improvement
can be attributed to data-driven and optimal (strategic) nature of vaccine
allocations, especially in the early stages of the epidemic when the allocation
strategy can crucially impact the long-term trajectory of the disease.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Samarth Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Amin_S/0/1/0/all/0/1&quot;&gt;Saurabh Amin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00033">
<title>Application of data engineering approaches to address challenges in microbiome data for optimal medical decision-making. (arXiv:2307.00033v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/2307.00033</link>
<description rdf:parseType="Literal">&lt;p&gt;The human gut microbiota is known to contribute to numerous physiological
functions of the body through their interplay with multiple organs and also
implicated in a myriad of pathological conditions. Prolific research work in
the past few decades have yielded valuable information regarding the relative
taxonomic distribution of the gut microbiota that could enable personalized
medicine. Unfortunately, the microbiome data suffers from class imbalance and
high dimensionality issues that must be addressed. In this study, we have
implemented data engineering algorithms to address the above-mentioned issues
inherent to microbiome data. Four standard machine learning classifiers
(logistic regression (LR), support vector machines (SVM), random forests (RF),
and extreme gradient boosting (XGB) decision trees) were implemented on a
previously published dataset of infants with cystic fibrosis exhibiting normal
vs abnormal growth patterns. The issue of class imbalance and high
dimensionality of the data was addressed through synthetic minority
oversampling technique (SMOTE) and principal component analysis (PCA).
Classification of host phenotype was performed at multiple levels of taxonomic
hierarchy. Our results indicate that ensemble classifiers (RF and XGB decision
trees) exhibit superior classification accuracy in predicting the host
phenotype. The application of PCA significantly reduced the testing time while
maintaining high classification accuracy. The highest classification accuracy
was obtained at the levels of species for most classifiers. The prototype
employed in the study addresses the issues inherent to microbiome datasets and
could be highly beneficial for providing personalized medicine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Thombre_I/0/1/0/all/0/1&quot;&gt;Isha Thombre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Perepu_P/0/1/0/all/0/1&quot;&gt;Pavan Kumar Perepu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sudhakar_S/0/1/0/all/0/1&quot;&gt;Shyam Kumar Sudhakar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00035">
<title>Parameter Identification for Partial Differential Equations with Spatiotemporal Varying Coefficients. (arXiv:2307.00035v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00035</link>
<description rdf:parseType="Literal">&lt;p&gt;To comprehend complex systems with multiple states, it is imperative to
reveal the identity of these states by system outputs. Nevertheless, the
mathematical models describing these systems often exhibit nonlinearity so that
render the resolution of the parameter inverse problem from the observed
spatiotemporal data a challenging endeavor. Starting from the observed data
obtained from such systems, we propose a novel framework that facilitates the
investigation of parameter identification for multi-state systems governed by
spatiotemporal varying parametric partial differential equations. Our framework
consists of two integral components: a constrained self-adaptive
physics-informed neural network, encompassing a sub-network, as our methodology
for parameter identification, and a finite mixture model approach to detect
regions of probable parameter variations. Through our scheme, we can precisely
ascertain the unknown varying parameters of the complex multi-state system,
thereby accomplishing the inversion of the varying parameters. Furthermore, we
have showcased the efficacy of our framework on two numerical cases: the 1D
Burgers&apos; equation with time-varying parameters and the 2D wave equation with a
space-varying parameter.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Guangtao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1&quot;&gt;Yiting Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_G/0/1/0/all/0/1&quot;&gt;Guanyu Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Qijing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Huiyu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhikun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00036">
<title>Machine learning for potion development at Hogwarts. (arXiv:2307.00036v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00036</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: To determine whether machine learning methods can generate useful
potion recipes for research and teaching at Hogwarts School of Witchcraft and
Wizardry. Design: Using deep neural networks to classify generated recipes into
a standard drug classification system. Setting: Hogwarts School of Witchcraft
and Wizardry. Data sources: 72 potion recipes from the Hogwarts curriculum,
extracted from the Harry Potter Wiki. Results: Most generated recipes fall into
the categories of psychoanaleptics and dermatologicals. The number of recipes
predicted for each category reflected the number of training recipes. Predicted
probabilities were often above 90% but some recipes were classified into 2 or
more categories with similar probabilities which complicates anticipating the
predicted effects. Conclusions: Machine learning powered methods are able to
generate potentially useful potion recipes for teaching and research at
Hogwarts. This corresponds to similar efforts in the non-magical world where
such methods have been applied to identify potentially effective drug
combinations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurz_C/0/1/0/all/0/1&quot;&gt;Christoph F. Kurz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konig_A/0/1/0/all/0/1&quot;&gt;Adriana N. K&amp;#xf6;nig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00039">
<title>Towards Brain Inspired Design for Addressing the Shortcomings of ANNs. (arXiv:2307.00039v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2307.00039</link>
<description rdf:parseType="Literal">&lt;p&gt;As our understanding of the mechanisms of brain function is enhanced, the
value of insights gained from neuroscience to the development of AI algorithms
deserves further consideration. Here, we draw parallels with an existing
tree-based ANN architecture and a recent neuroscience study[27] arguing that
the error-based organization of neurons in the cerebellum that share a
preference for a personalized view of the entire error space, may account for
several desirable features of behavior and learning. We then analyze the
learning behavior and characteristics of the model under varying scenarios to
gauge the potential benefits of a similar mechanism in ANN. Our empirical
results suggest that having separate populations of neurons with personalized
error views can enable efficient learning under class imbalance and limited
data, and reduce the susceptibility to unintended shortcut strategies, leading
to improved generalization. This work highlights the potential of translating
the learning machinery of the brain into the design of a new generation of ANNs
and provides further credence to the argument that biologically inspired AI may
hold the key to overcoming the shortcomings of ANNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarfraz_F/0/1/0/all/0/1&quot;&gt;Fahad Sarfraz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1&quot;&gt;Elahe Arani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1&quot;&gt;Bahram Zonooz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00066">
<title>Improving the Transferability of Time Series Forecasting with Decomposition Adaptation. (arXiv:2307.00066v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00066</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to effective pattern mining and feature representation, neural
forecasting models based on deep learning have achieved great progress. The
premise of effective learning is to collect sufficient data. However, in time
series forecasting, it is difficult to obtain enough data, which limits the
performance of neural forecasting models. To alleviate the data scarcity
limitation, we design Sequence Decomposition Adaptation Network (SeDAN) which
is a novel transfer architecture to improve forecasting performance on the
target domain by aligning transferable knowledge from cross-domain datasets.
Rethinking the transferability of features in time series data, we propose
Implicit Contrastive Decomposition to decompose the original features into
components including seasonal and trend features, which are easier to transfer.
Then we design the corresponding adaptation methods for decomposed features in
different domains. Specifically, for seasonal features, we perform joint
distribution adaptation and for trend features, we design an Optimal Local
Adaptation. We conduct extensive experiments on five benchmark datasets for
multivariate time series forecasting. The results demonstrate the effectiveness
of our SeDAN. It can provide more efficient and stable knowledge transfer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yan Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qiang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00067">
<title>Transformers in Healthcare: A Survey. (arXiv:2307.00067v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.00067</link>
<description rdf:parseType="Literal">&lt;p&gt;With Artificial Intelligence (AI) increasingly permeating various aspects of
society, including healthcare, the adoption of the Transformers neural network
architecture is rapidly changing many applications. Transformer is a type of
deep learning architecture initially developed to solve general-purpose Natural
Language Processing (NLP) tasks and has subsequently been adapted in many
fields, including healthcare. In this survey paper, we provide an overview of
how this architecture has been adopted to analyze various forms of data,
including medical imaging, structured and unstructured Electronic Health
Records (EHR), social media, physiological signals, and biomolecular sequences.
Those models could help in clinical diagnosis, report generation, data
reconstruction, and drug/protein synthesis. We identified relevant studies
using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses
(PRISMA) guidelines. We also discuss the benefits and limitations of using
transformers in healthcare and examine issues such as computational cost, model
interpretability, fairness, alignment with human values, ethical implications,
and environmental impact.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nerella_S/0/1/0/all/0/1&quot;&gt;Subhash Nerella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bandyopadhyay_S/0/1/0/all/0/1&quot;&gt;Sabyasachi Bandyopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiaqing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Contreras_M/0/1/0/all/0/1&quot;&gt;Miguel Contreras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siegel_S/0/1/0/all/0/1&quot;&gt;Scott Siegel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bumin_A/0/1/0/all/0/1&quot;&gt;Aysegul Bumin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_B/0/1/0/all/0/1&quot;&gt;Brandon Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sena_J/0/1/0/all/0/1&quot;&gt;Jessica Sena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shickel_B/0/1/0/all/0/1&quot;&gt;Benjamin Shickel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bihorac_A/0/1/0/all/0/1&quot;&gt;Azra Bihorac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khezeli_K/0/1/0/all/0/1&quot;&gt;Kia Khezeli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashidi_P/0/1/0/all/0/1&quot;&gt;Parisa Rashidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00079">
<title>Dataset balancing can hurt model performance. (arXiv:2307.00079v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00079</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning from training data with a skewed distribution of examples
per class can lead to models that favor performance on common classes at the
expense of performance on rare ones. AudioSet has a very wide range of priors
over its 527 sound event classes. Classification performance on AudioSet is
usually evaluated by a simple average over per-class metrics, meaning that
performance on rare classes is equal in importance to the performance on common
ones. Several recent papers have used dataset balancing techniques to improve
performance on AudioSet. We find, however, that while balancing improves
performance on the public AudioSet evaluation data it simultaneously hurts
performance on an unpublished evaluation set collected under the same
conditions. By varying the degree of balancing, we show that its benefits are
fragile and depend on the evaluation set. We also do not find evidence
indicating that balancing improves rare class performance relative to common
classes. We therefore caution against blind application of balancing, as well
as against paying too much attention to small improvements on a public
evaluation set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_R/0/1/0/all/0/1&quot;&gt;R. Channing Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ellis_D/0/1/0/all/0/1&quot;&gt;Daniel P. W. Ellis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonseca_E/0/1/0/all/0/1&quot;&gt;Eduardo Fonseca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hershey_S/0/1/0/all/0/1&quot;&gt;Shawn Hershey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jansen_A/0/1/0/all/0/1&quot;&gt;Aren Jansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plakal_M/0/1/0/all/0/1&quot;&gt;Manoj Plakal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00080">
<title>Inter-case Predictive Process Monitoring: A candidate for Quantum Machine Learning?. (arXiv:2307.00080v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00080</link>
<description rdf:parseType="Literal">&lt;p&gt;Regardless of the domain, forecasting the future behaviour of a running
process instance is a question of interest for decision makers, especially when
multiple instances interact. Fostered by the recent advances in machine
learning research, several methods have been proposed to predict the next
activity, outcome or remaining time of a process automatically. Still, building
a model with high predictive power requires both - intrinsic knowledge of how
to extract meaningful features from the event log data and a model that
captures complex patterns in data. This work builds upon the recent progress in
inter-case Predictive Process Monitoring (PPM) and comprehensively benchmarks
the impact of inter-case features on prediction accuracy. Moreover, it includes
quantum machine learning models, which are expected to provide an advantage
over classical models with a scaling amount of feature dimensions. The
evaluation on real-world training data from the BPI challenge shows that the
inter-case features provide a significant boost by more than four percent in
accuracy and quantum algorithms are indeed competitive in a handful of feature
configurations. Yet, as quantum hardware is still in its early stages of
development, this paper critically discusses these findings in the light of
runtime, noise and the risk to overfit on the training data. Finally, the
implementation of an open-source plugin demonstrates the technical feasibility
to connect a state-of-the-art workflow engine such as Camunda to an IBM quantum
computing cloud service.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hill_S/0/1/0/all/0/1&quot;&gt;Stefan Hill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fitzek_D/0/1/0/all/0/1&quot;&gt;David Fitzek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delfmann_P/0/1/0/all/0/1&quot;&gt;Patrick Delfmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corea_C/0/1/0/all/0/1&quot;&gt;Carl Corea&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00088">
<title>Redeeming Data Science by Decision Modelling. (arXiv:2307.00088v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00088</link>
<description rdf:parseType="Literal">&lt;p&gt;With the explosion of applications of Data Science, the field is has come
loose from its foundations. This article argues for a new program of applied
research in areas familiar to researchers in Bayesian methods in AI that are
needed to ground the practice of Data Science by borrowing from AI techniques
for model formulation that we term ``Decision Modelling.&apos;&apos; This article briefly
reviews the formulation process as building a causal graphical model, then
discusses the process in terms of six principles that comprise \emph{Decision
Quality}, a framework from the popular business literature. We claim that any
successful applied ML modelling effort must include these six principles.
&lt;/p&gt;
&lt;p&gt;We explain how Decision Modelling combines a conventional machine learning
model with an explicit value model. To give a specific example we show how this
is done by integrating a model&apos;s ROC curve with a utility model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agosta_J/0/1/0/all/0/1&quot;&gt;John Mark Agosta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horton_R/0/1/0/all/0/1&quot;&gt;Robert Horton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00104">
<title>Obscured Wildfire Flame Detection By Temporal Analysis of Smoke Patterns Captured by Unmanned Aerial Systems. (arXiv:2307.00104v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00104</link>
<description rdf:parseType="Literal">&lt;p&gt;This research paper addresses the challenge of detecting obscured wildfires
(when the fire flames are covered by trees, smoke, clouds, and other natural
barriers) in real-time using drones equipped only with RGB cameras. We propose
a novel methodology that employs semantic segmentation based on the temporal
analysis of smoke patterns in video sequences. Our approach utilizes an
encoder-decoder architecture based on deep convolutional neural network
architecture with a pre-trained CNN encoder and 3D convolutions for decoding
while using sequential stacking of features to exploit temporal variations. The
predicted fire locations can assist drones in effectively combating forest
fires and pinpoint fire retardant chemical drop on exact flame locations. We
applied our method to a curated dataset derived from the FLAME2 dataset that
includes RGB video along with IR video to determine the ground truth. Our
proposed method has a unique property of detecting obscured fire and achieves a
Dice score of 85.88%, while achieving a high precision of 92.47% and
classification accuracy of 90.67% on test data showing promising results when
inspected visually. Indeed, our method outperforms other methods by a
significant margin in terms of video-level fire classification as we obtained
about 100% accuracy using MobileNet+CBAM as the encoder backbone.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meleti_U/0/1/0/all/0/1&quot;&gt;Uma Meleti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razi_A/0/1/0/all/0/1&quot;&gt;Abolfazl Razi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00106">
<title>Distance Functions and Normalization Under Stream Scenarios. (arXiv:2307.00106v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00106</link>
<description rdf:parseType="Literal">&lt;p&gt;Data normalization is an essential task when modeling a classification
system. When dealing with data streams, data normalization becomes especially
challenging since we may not know in advance the properties of the features,
such as their minimum/maximum values, and these properties may change over
time. We compare the accuracies generated by eight well-known distance
functions in data streams without normalization, normalized considering the
statistics of the first batch of data received, and considering the previous
batch received. We argue that experimental protocols for streams that consider
the full stream as normalized are unrealistic and can lead to biased and poor
results. Our results indicate that using the original data stream without
applying normalization, and the Canberra distance, can be a good combination
when no information about the data stream is known beforehand.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barboza_E/0/1/0/all/0/1&quot;&gt;Eduardo V. L. Barboza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Almeida_P/0/1/0/all/0/1&quot;&gt;Paulo R. Lisboa de Almeida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Britto_A/0/1/0/all/0/1&quot;&gt;Alceu de Souza Britto Jr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cruz_R/0/1/0/all/0/1&quot;&gt;Rafael M. O. Cruz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00108">
<title>Ticket-BERT: Labeling Incident Management Tickets with Language Models. (arXiv:2307.00108v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.00108</link>
<description rdf:parseType="Literal">&lt;p&gt;An essential aspect of prioritizing incident tickets for resolution is
efficiently labeling tickets with fine-grained categories. However, ticket data
is often complex and poses several unique challenges for modern machine
learning methods: (1) tickets are created and updated either by machines with
pre-defined algorithms or by engineers with domain expertise that share
different protocols, (2) tickets receive frequent revisions that update ticket
status by modifying all or parts of ticket descriptions, and (3) ticket
labeling is time-sensitive and requires knowledge updates and new labels per
the rapid software and hardware improvement lifecycle. To handle these issues,
we introduce Ticket- BERT which trains a simple yet robust language model for
labeling tickets using our proposed ticket datasets. Experiments demonstrate
the superiority of Ticket-BERT over baselines and state-of-the-art text
classifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT
with an active learning cycle and deploy it on the Microsoft IcM system, which
enables the model to quickly finetune on newly-collected tickets with a few
annotations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhexiong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benge_C/0/1/0/all/0/1&quot;&gt;Cris Benge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Siduo Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00117">
<title>Goal Representations for Instruction Following: A Semi-Supervised Language Interface to Control. (arXiv:2307.00117v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2307.00117</link>
<description rdf:parseType="Literal">&lt;p&gt;Our goal is for robots to follow natural language instructions like &quot;put the
towel next to the microwave.&quot; But getting large amounts of labeled data, i.e.
data that contains demonstrations of tasks labeled with the language
instruction, is prohibitive. In contrast, obtaining policies that respond to
image goals is much easier, because any autonomous trial or demonstration can
be labeled in hindsight with its final state as the goal. In this work, we
contribute a method that taps into joint image- and goal- conditioned policies
with language using only a small amount of language data. Prior work has made
progress on this using vision-language models or by jointly training
language-goal-conditioned policies, but so far neither method has scaled
effectively to real-world robot tasks without significant human annotation. Our
method achieves robust performance in the real world by learning an embedding
from the labeled data that aligns language not to the goal image, but rather to
the desired change between the start and goal images that the instruction
corresponds to. We then train a policy on this embedding: the policy benefits
from all the unlabeled data, but the aligned embedding provides an interface
for language to steer the policy. We show instruction following across a
variety of manipulation tasks in different scenes, with generalization to
language instructions outside of the labeled data. Videos and code for our
approach can be found on our website: &lt;a href=&quot;http://tiny.cc/grif&quot;&gt;this http URL&lt;/a&gt; .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Myers_V/0/1/0/all/0/1&quot;&gt;Vivek Myers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_A/0/1/0/all/0/1&quot;&gt;Andre He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_K/0/1/0/all/0/1&quot;&gt;Kuan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walke_H/0/1/0/all/0/1&quot;&gt;Homer Walke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hansen_Estruch_P/0/1/0/all/0/1&quot;&gt;Philippe Hansen-Estruch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Ching-An Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jalobeanu_M/0/1/0/all/0/1&quot;&gt;Mihai Jalobeanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1&quot;&gt;Andrey Kolobov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00123">
<title>How Do Human Users Teach a Continual Learning Robot in Repeated Interactions?. (arXiv:2307.00123v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2307.00123</link>
<description rdf:parseType="Literal">&lt;p&gt;Continual learning (CL) has emerged as an important avenue of research in
recent years, at the intersection of Machine Learning (ML) and Human-Robot
Interaction (HRI), to allow robots to continually learn in their environments
over long-term interactions with humans. Most research in continual learning,
however, has been robot-centered to develop continual learning algorithms that
can quickly learn new information on static datasets. In this paper, we take a
human-centered approach to continual learning, to understand how humans teach
continual learning robots over the long term and if there are variations in
their teaching styles. We conducted an in-person study with 40 participants
that interacted with a continual learning robot in 200 sessions. In this
between-participant study, we used two different CL models deployed on a Fetch
mobile manipulator robot. An extensive qualitative and quantitative analysis of
the data collected in the study shows that there is significant variation among
the teaching styles of individual users indicating the need for personalized
adaptation to their distinct teaching styles. The results also show that
although there is a difference in the teaching styles between expert and
non-expert users, the style does not have an effect on the performance of the
continual learning robot. Finally, our analysis shows that the constrained
experimental setups that have been widely used to test most continual learning
techniques are not adequate, as real users interact with and teach continual
learning robots in a variety of ways. Our code is available at
https://github.com/aliayub7/cl_hri.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ayub_A/0/1/0/all/0/1&quot;&gt;Ali Ayub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_J/0/1/0/all/0/1&quot;&gt;Jainish Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Francesco_Z/0/1/0/all/0/1&quot;&gt;Zachary De Francesco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holthaus_P/0/1/0/all/0/1&quot;&gt;Patrick Holthaus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dautenhahn_K/0/1/0/all/0/1&quot;&gt;Kerstin Dautenhahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nehaniv_C/0/1/0/all/0/1&quot;&gt;Chrystopher L. Nehaniv&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00125">
<title>RObotic MAnipulation Network (ROMAN) -- Hybrid Hierarchical Learning for Solving Complex Sequential Tasks. (arXiv:2307.00125v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2307.00125</link>
<description rdf:parseType="Literal">&lt;p&gt;Solving long sequential tasks poses a significant challenge in embodied
artificial intelligence. Enabling a robotic system to perform diverse
sequential tasks with a broad range of manipulation skills is an active area of
research. In this work, we present a Hybrid Hierarchical Learning framework,
the Robotic Manipulation Network (ROMAN), to address the challenge of solving
multiple complex tasks over long time horizons in robotic manipulation. ROMAN
achieves task versatility and robust failure recovery by integrating
behavioural cloning, imitation learning, and reinforcement learning. It
consists of a central manipulation network that coordinates an ensemble of
various neural networks, each specialising in distinct re-combinable sub-tasks
to generate their correct in-sequence actions for solving complex long-horizon
manipulation tasks. Experimental results show that by orchestrating and
activating these specialised manipulation experts, ROMAN generates correct
sequential activations for accomplishing long sequences of sophisticated
manipulation tasks and achieving adaptive behaviours beyond demonstrations,
while exhibiting robustness to various sensory noises. These results
demonstrate the significance and versatility of ROMAN&apos;s dynamic adaptability
featuring autonomous failure recovery capabilities, and highlight its potential
for various autonomous manipulation tasks that demand adaptive motor skills.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Triantafyllidis_E/0/1/0/all/0/1&quot;&gt;Eleftherios Triantafyllidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acero_F/0/1/0/all/0/1&quot;&gt;Fernando Acero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhaocheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhibin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00126">
<title>Accelerating Inexact HyperGradient Descent for Bilevel Optimization. (arXiv:2307.00126v1 [math.OC])</title>
<link>http://arxiv.org/abs/2307.00126</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for solving general nonconvex-strongly-convex bilevel
optimization problems. Our method -- the \emph{Restarted Accelerated
HyperGradient Descent} (\texttt{RAHGD}) method -- finds an
$\epsilon$-first-order stationary point of the objective with
$\tilde{\mathcal{O}}(\kappa^{3.25}\epsilon^{-1.75})$ oracle complexity, where
$\kappa$ is the condition number of the lower-level objective and $\epsilon$ is
the desired accuracy. We also propose a perturbed variant of \texttt{RAHGD} for
finding an
$\big(\epsilon,\mathcal{O}(\kappa^{2.5}\sqrt{\epsilon}\,)\big)$-second-order
stationary point within the same order of oracle complexity. Our results
achieve the best-known theoretical guarantees for finding stationary points in
bilevel optimization and also improve upon the existing upper complexity bound
for finding second-order stationary points in nonconvex-strongly-concave
minimax optimization problems, setting a new state-of-the-art benchmark.
Empirical studies are conducted to validate the theoretical results in this
paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haikuo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Luo_L/0/1/0/all/0/1&quot;&gt;Luo Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chris Junchi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00131">
<title>Machine learning for advancing low-temperature plasma modeling and simulation. (arXiv:2307.00131v1 [physics.plasm-ph])</title>
<link>http://arxiv.org/abs/2307.00131</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning has had an enormous impact in many scientific disciplines.
Also in the field of low-temperature plasma modeling and simulation it has
attracted significant interest within the past years. Whereas its application
should be carefully assessed in general, many aspects of plasma modeling and
simulation have benefited substantially from recent developments within the
field of machine learning and data-driven modeling. In this survey, we approach
two main objectives: (a) We review the state-of-the-art focusing on approaches
to low-temperature plasma modeling and simulation. By dividing our survey into
plasma physics, plasma chemistry, plasma-surface interactions, and plasma
process control, we aim to extensively discuss relevant examples from
literature. (b) We provide a perspective of potential advances to plasma
science and technology. We specifically elaborate on advances possibly enabled
by adaptation from other scientific disciplines. We argue that not only the
known unknowns, but also unknown unknowns may be discovered due to an inherent
propensity to spotlight hidden patterns in data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Trieschmann_J/0/1/0/all/0/1&quot;&gt;Jan Trieschmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Vialetto_L/0/1/0/all/0/1&quot;&gt;Luca Vialetto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gergs_T/0/1/0/all/0/1&quot;&gt;Tobias Gergs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00134">
<title>Generalization Limits of Graph Neural Networks in Identity Effects Learning. (arXiv:2307.00134v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00134</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) have emerged as a powerful tool for data-driven
learning on various graph domains. They are usually based on a message-passing
mechanism and have gained increasing popularity for their intuitive
formulation, which is closely linked to the Weisfeiler-Lehman (WL) test for
graph isomorphism to which they have been proven equivalent in terms of
expressive power. In this work, we establish new generalization properties and
fundamental limits of GNNs in the context of learning so-called identity
effects, i.e., the task of determining whether an object is composed of two
identical components or not. Our study is motivated by the need to understand
the capabilities of GNNs when performing simple cognitive tasks, with potential
applications in computational linguistics and chemistry. We analyze two case
studies: (i) two-letters words, for which we show that GNNs trained via
stochastic gradient descent are unable to generalize to unseen letters when
utilizing orthogonal encodings like one-hot representations; (ii) dicyclic
graphs, i.e., graphs composed of two cycles, for which we present positive
existence results leveraging the connection between GNNs and the WL test. Our
theoretical analysis is supported by an extensive numerical study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DInverno_G/0/1/0/all/0/1&quot;&gt;Giuseppe Alessio D&amp;#x27;Inverno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brugiapaglia_S/0/1/0/all/0/1&quot;&gt;Simone Brugiapaglia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravanelli_M/0/1/0/all/0/1&quot;&gt;Mirco Ravanelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00141">
<title>Risk-sensitive Actor-free Policy via Convex Optimization. (arXiv:2307.00141v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00141</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional reinforcement learning methods optimize agents without
considering safety, potentially resulting in unintended consequences. In this
paper, we propose an optimal actor-free policy that optimizes a risk-sensitive
criterion based on the conditional value at risk. The risk-sensitive objective
function is modeled using an input-convex neural network ensuring convexity
with respect to the actions and enabling the identification of globally optimal
actions through simple gradient-following methods. Experimental results
demonstrate the efficacy of our approach in maintaining effective risk control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruoqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sjolund_J/0/1/0/all/0/1&quot;&gt;Jens Sj&amp;#xf6;lund&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00142">
<title>BuildingsBench: A Large-Scale Dataset of 900K Buildings and Benchmark for Short-Term Load Forecasting. (arXiv:2307.00142v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00142</link>
<description rdf:parseType="Literal">&lt;p&gt;Short-term forecasting of residential and commercial building energy
consumption is widely used in power systems and continues to grow in
importance. Data-driven short-term load forecasting (STLF), although promising,
has suffered from a lack of open, large-scale datasets with high building
diversity. This has hindered exploring the pretrain-then-finetune paradigm for
STLF. To help address this, we present BuildingsBench, which consists of 1)
Buildings-900K, a large-scale dataset of 900K simulated buildings representing
the U.S. building stock, and 2) an evaluation platform with over 1,900 real
residential and commercial buildings from 7 open datasets. BuildingsBench
benchmarks two under-explored tasks: zero-shot STLF, where a pretrained model
is evaluated on unseen buildings without fine-tuning, and transfer learning,
where a pretrained model is fine-tuned on a target building. The main finding
of our benchmark analysis is that synthetically pretrained models generalize
surprisingly well to real commercial buildings. An exploration of the effect of
increasing dataset size and diversity on zero-shot commercial building
performance reveals a power-law with diminishing returns. We also show that
fine-tuning pretrained models on real commercial and residential buildings
improves performance for a majority of target buildings. We hope that
BuildingsBench encourages and facilitates future research on generalizable
STLF. All datasets and code can be accessed from
\url{https://github.com/NREL/BuildingsBench}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emami_P/0/1/0/all/0/1&quot;&gt;Patrick Emami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahu_A/0/1/0/all/0/1&quot;&gt;Abhijeet Sahu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graf_P/0/1/0/all/0/1&quot;&gt;Peter Graf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00144">
<title>Abide by the Law and Follow the Flow: Conservation Laws for Gradient Flows. (arXiv:2307.00144v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00144</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the geometric properties of gradient descent dynamics is a key
ingredient in deciphering the recent success of very large machine learning
models. A striking observation is that trained over-parameterized models retain
some properties of the optimization initialization. This &quot;implicit bias&quot; is
believed to be responsible for some favorable properties of the trained models
and could explain their good generalization properties. The purpose of this
article is threefold. First, we rigorously expose the definition and basic
properties of &quot;conservation laws&quot;, which are maximal sets of independent
quantities conserved during gradient flows of a given model (e.g. of a ReLU
network with a given architecture) with any training data and any loss. Then we
explain how to find the exact number of these quantities by performing
finite-dimensional algebraic manipulations on the Lie algebra generated by the
Jacobian of the model. Finally, we provide algorithms (implemented in SageMath)
to: a) compute a family of polynomial laws; b) compute the number of (not
necessarily polynomial) conservation laws. We provide showcase examples that we
fully work out theoretically. Besides, applying the two algorithms confirms for
a number of ReLU network architectures that all known laws are recovered by the
algorithm, and that there are no other laws. Such computational tools pave the
way to understanding desirable properties of optimization initialization in
large machine learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marcotte_S/0/1/0/all/0/1&quot;&gt;Sibylle Marcotte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gribonval_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Gribonval&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peyre_G/0/1/0/all/0/1&quot;&gt;Gabriel Peyr&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00149">
<title>Hierarchical Neural Coding for Controllable CAD Model Generation. (arXiv:2307.00149v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00149</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel generative model for Computer Aided Design (CAD)
that 1) represents high-level design concepts of a CAD model as a three-level
hierarchical tree of neural codes, from global part arrangement down to local
curve geometry; and 2) controls the generation or completion of CAD models by
specifying the target design using a code tree. Concretely, a novel variant of
a vector quantized VAE with &quot;masked skip connection&quot; extracts design variations
as neural codebooks at three levels. Two-stage cascaded auto-regressive
transformers learn to generate code trees from incomplete CAD models and then
complete CAD models following the intended design. Extensive experiments
demonstrate superior performance on conventional tasks such as random
generation while enabling novel interaction capabilities on conditional
generation tasks. The code is available at
https://github.com/samxuxiang/hnc-cad.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Xiang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jayaraman_P/0/1/0/all/0/1&quot;&gt;Pradeep Kumar Jayaraman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lambourne_J/0/1/0/all/0/1&quot;&gt;Joseph G. Lambourne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Willis_K/0/1/0/all/0/1&quot;&gt;Karl D.D. Willis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Furukawa_Y/0/1/0/all/0/1&quot;&gt;Yasutaka Furukawa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00154">
<title>Stitched ViTs are Flexible Vision Backbones. (arXiv:2307.00154v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00154</link>
<description rdf:parseType="Literal">&lt;p&gt;Large pretrained plain vision Transformers (ViTs) have been the workhorse for
many downstream tasks. However, existing works utilizing off-the-shelf ViTs are
inefficient in terms of training and deployment, because adopting ViTs with
individual sizes requires separate training and is restricted by fixed
performance-efficiency trade-offs. In this paper, we are inspired by stitchable
neural networks, which is a new framework that cheaply produces a single model
that covers rich subnetworks by stitching pretrained model families, supporting
diverse performance-efficiency trade-offs at runtime. Building upon this
foundation, we introduce SN-Netv2, a systematically improved model stitching
framework to facilitate downstream task adaptation. Specifically, we first
propose a Two-way stitching scheme to enlarge the stitching space. We then
design a resource-constrained sampling strategy that takes into account the
underlying FLOPs distributions in the space for improved sampling. Finally, we
observe that learning stitching layers is a low-rank update, which plays an
essential role on downstream tasks to stabilize training and ensure a good
Pareto frontier. With extensive experiments on ImageNet-1K, ADE20K,
COCO-Stuff-10K, NYUv2 and COCO-2017, SN-Netv2 demonstrates strong ability to
serve as a flexible vision backbone, achieving great advantages in both
training efficiency and adaptation. Code will be released at
https://github.com/ziplab/SN-Netv2.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1&quot;&gt;Zizheng Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1&quot;&gt;Haoyu He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1&quot;&gt;Jianfei Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1&quot;&gt;Bohan Zhuang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00157">
<title>The Effect of Balancing Methods on Model Behavior in Imbalanced Classification Problems. (arXiv:2307.00157v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00157</link>
<description rdf:parseType="Literal">&lt;p&gt;Imbalanced data poses a significant challenge in classification as model
performance is affected by insufficient learning from minority classes.
Balancing methods are often used to address this problem. However, such
techniques can lead to problems such as overfitting or loss of information.
This study addresses a more challenging aspect of balancing methods - their
impact on model behavior. To capture these changes, Explainable Artificial
Intelligence tools are used to compare models trained on datasets before and
after balancing. In addition to the variable importance method, this study uses
the partial dependence profile and accumulated local effects techniques. Real
and simulated datasets are tested, and an open-source Python package edgaro is
developed to facilitate this analysis. The results obtained show significant
changes in model behavior due to balancing methods, which can lead to biased
models toward a balanced distribution. These findings confirm that balancing
analysis should go beyond model performance comparisons to achieve higher
reliability of machine learning models. Therefore, we propose a new method
performance gain plot for informed data balancing strategy to make an optimal
selection of balancing method by analyzing the measure of change in model
behavior versus performance gain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stando_A/0/1/0/all/0/1&quot;&gt;Adrian Stando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cavus_M/0/1/0/all/0/1&quot;&gt;Mustafa Cavus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biecek_P/0/1/0/all/0/1&quot;&gt;Przemys&amp;#x142;aw Biecek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00161">
<title>FFPDG: Fast, Fair and Private Data Generation. (arXiv:2307.00161v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00161</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative modeling has been used frequently in synthetic data generation.
Fairness and privacy are two big concerns for synthetic data. Although Recent
GAN [\cite{goodfellow2014generative}] based methods show good results in
preserving privacy, the generated data may be more biased. At the same time,
these methods require high computation resources. In this work, we design a
fast, fair, flexible and private data generation method. We show the
effectiveness of our method theoretically and empirically. We show that models
trained on data generated by the proposed method can perform well (in inference
stage) on real application scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Weijie Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jinjin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iannacci_F/0/1/0/all/0/1&quot;&gt;Francis Iannacci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bo Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00162">
<title>What do self-supervised speech models know about words?. (arXiv:2307.00162v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.00162</link>
<description rdf:parseType="Literal">&lt;p&gt;Many self-supervised speech models (S3Ms) have been introduced over the last
few years, producing performance and data efficiency improvements for a variety
of speech tasks. Evidence is emerging that different S3Ms encode linguistic
information in different layers, and also that some S3Ms appear to learn
phone-like sub-word units. However, the extent to which these models capture
larger linguistic units, such as words, and where word-related information is
encoded, remains unclear. In this study, we conduct several analyses of word
segment representations extracted from different layers of three S3Ms:
wav2vec2, HuBERT, and WavLM. We employ canonical correlation analysis (CCA), a
lightweight analysis tool, to measure the similarity between these
representations and word-level linguistic properties. We find that the maximal
word-level linguistic content tends to be found in intermediate model layers,
while some lower-level information like pronunciation is also retained in
higher layers of HuBERT and WavLM. Syntactic and semantic word attributes have
similar layer-wise behavior. We also find that, for all of the models tested,
word identity information is concentrated near the center of each word segment.
We then test the layer-wise performance of the same models, when used directly
with no additional learned parameters, on several tasks: acoustic word
discrimination, word segmentation, and semantic sentence similarity. We find
similar layer-wise trends in performance, and furthermore, find that when using
the best-performing layer of HuBERT or WavLM, it is possible to achieve
performance on word segmentation and sentence similarity that rivals more
complex existing approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasad_A/0/1/0/all/0/1&quot;&gt;Ankita Pasad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chien_C/0/1/0/all/0/1&quot;&gt;Chung-Ming Chien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Settle_S/0/1/0/all/0/1&quot;&gt;Shane Settle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livescu_K/0/1/0/all/0/1&quot;&gt;Karen Livescu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00168">
<title>U-Calibration: Forecasting for an Unknown Agent. (arXiv:2307.00168v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00168</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of evaluating forecasts of binary events whose
predictions are consumed by rational agents who take an action in response to a
prediction, but whose utility is unknown to the forecaster. We show that
optimizing forecasts for a single scoring rule (e.g., the Brier score) cannot
guarantee low regret for all possible agents. In contrast, forecasts that are
well-calibrated guarantee that all agents incur sublinear regret. However,
calibration is not a necessary criterion here (it is possible for miscalibrated
forecasts to provide good regret guarantees for all possible agents), and
calibrated forecasting procedures have provably worse convergence rates than
forecasting procedures targeting a single scoring rule.
&lt;/p&gt;
&lt;p&gt;Motivated by this, we present a new metric for evaluating forecasts that we
call U-calibration, equal to the maximal regret of the sequence of forecasts
when evaluated under any bounded scoring rule. We show that sublinear
U-calibration error is a necessary and sufficient condition for all agents to
achieve sublinear regret guarantees. We additionally demonstrate how to compute
the U-calibration error efficiently and provide an online algorithm that
achieves $O(\sqrt{T})$ U-calibration error (on par with optimal rates for
optimizing for a single scoring rule, and bypassing lower bounds for the
traditionally calibrated learning procedures). Finally, we discuss
generalizations to the multiclass prediction setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_R/0/1/0/all/0/1&quot;&gt;Robert Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leme_R/0/1/0/all/0/1&quot;&gt;Renato Paes Leme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1&quot;&gt;Jon Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1&quot;&gt;Yifeng Teng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00169">
<title>VoxWatch: An open-set speaker recognition benchmark on VoxCeleb. (arXiv:2307.00169v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2307.00169</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite its broad practical applications such as in fraud prevention,
open-set speaker identification (OSI) has received less attention in the
speaker recognition community compared to speaker verification (SV). OSI deals
with determining if a test speech sample belongs to a speaker from a set of
pre-enrolled individuals (in-set) or if it is from an out-of-set speaker. In
addition to the typical challenges associated with speech variability, OSI is
prone to the &quot;false-alarm problem&quot;; as the size of the in-set speaker
population (a.k.a watchlist) grows, the out-of-set scores become larger,
leading to increased false alarm rates. This is in particular challenging for
applications in financial institutions and border security where the watchlist
size is typically of the order of several thousand speakers. Therefore, it is
important to systematically quantify the false-alarm problem, and develop
techniques that alleviate the impact of watchlist size on detection
performance. Prior studies on this problem are sparse, and lack a common
benchmark for systematic evaluations. In this paper, we present the first
public benchmark for OSI, developed using the VoxCeleb dataset. We quantify the
effect of the watchlist size and speech duration on the watchlist-based speaker
detection task using three strong neural network based systems. In contrast to
the findings from prior research, we show that the commonly adopted adaptive
score normalization is not guaranteed to improve the performance for this task.
On the other hand, we show that score calibration and score fusion, two other
commonly used techniques in SV, result in significant improvements in OSI
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Peri_R/0/1/0/all/0/1&quot;&gt;Raghuveer Peri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sadjadi_S/0/1/0/all/0/1&quot;&gt;Seyed Omid Sadjadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Garcia_Romero_D/0/1/0/all/0/1&quot;&gt;Daniel Garcia-Romero&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00171">
<title>The Integer Linear Programming Inference Cookbook. (arXiv:2307.00171v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.00171</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the years, integer linear programs have been employed to model inference
in many natural language processing problems. This survey is meant to guide the
reader through the process of framing a new inference problem as an instance of
an integer linear program and is structured as a collection of recipes. At the
end, we will see two worked examples to illustrate the use of these recipes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1&quot;&gt;Vivek Srikumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1&quot;&gt;Dan Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00175">
<title>Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks. (arXiv:2307.00175v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.00175</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the questions of whether or not large language models (LLMs) have
beliefs, and, if they do, how we might measure them. First, we evaluate two
existing approaches, one due to Azaria and Mitchell (2023) and the other to
Burns et al. (2022). We provide empirical results that show that these methods
fail to generalize in very basic ways. We then argue that, even if LLMs have
beliefs, these methods are unlikely to be successful for conceptual reasons.
Thus, there is still no lie-detector for LLMs. After describing our empirical
results we take a step back and consider whether or not we should expect LLMs
to have something like beliefs in the first place. We consider some recent
arguments aiming to show that LLMs cannot have beliefs. We show that these
arguments are misguided. We provide a more productive framing of questions
surrounding the status of beliefs in LLMs, and highlight the empirical nature
of the problem. We conclude by suggesting some concrete paths for future work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levinstein_B/0/1/0/all/0/1&quot;&gt;B.A. Levinstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herrmann_D/0/1/0/all/0/1&quot;&gt;Daniel A. Herrmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00185">
<title>An Interpretable Constructive Algorithm for Incremental Random Weight Neural Networks and Its Application. (arXiv:2307.00185v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00185</link>
<description rdf:parseType="Literal">&lt;p&gt;Incremental random weight neural networks (IRWNNs) have gained attention in
view of its easy implementation and fast learning. However, a significant
drawback of IRWNNs is that the elationship between the hidden parameters
(node)and the residual error (model performance) is difficult to be
interpreted. To address the above issue, this article proposes an interpretable
constructive algorithm (ICA) with geometric information constraint. First,
based on the geometric relationship between the hidden parameters and the
residual error, an interpretable geometric information constraint is proposed
to randomly assign the hidden parameters. Meanwhile, a node pool strategy is
employed to obtain hidden parameters that is more conducive to convergence from
hidden parameters satisfying the proposed constraint. Furthermore, the
universal approximation property of the ICA is proved. Finally, a lightweight
version of ICA is presented for large-scale data modeling tasks. Experimental
results on six benchmark datasets and a numerical simulation dataset
demonstrate that the ICA outperforms other constructive algorithms in terms of
modeling speed, model accuracy, and model network structure. Besides, two
practical industrial application case are used to validate the effectiveness of
ICA in practical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nan_J/0/1/0/all/0/1&quot;&gt;Jing Nan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1&quot;&gt;Wei Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1&quot;&gt;Guan Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1&quot;&gt;Ping Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00213">
<title>More for Less: Compact Convolutional Transformers Enable Robust Medical Image Classification with Limited Data. (arXiv:2307.00213v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00213</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformers are very powerful tools for a variety of tasks across domains,
from text generation to image captioning. However, transformers require
substantial amounts of training data, which is often a challenge in biomedical
settings, where high quality labeled data can be challenging or expensive to
obtain. This study investigates the efficacy of Compact Convolutional
Transformers (CCT) for robust medical image classification with limited data,
addressing a key issue faced by conventional Vision Transformers - their
requirement for large datasets. A hybrid of transformers and convolutional
layers, CCTs demonstrate high accuracy on modestly sized datasets. We employed
a benchmark dataset of peripheral blood cell images of eight distinct cell
types, each represented by approximately 2,000 low-resolution (28x28x3 pixel)
samples. Despite the dataset size being smaller than those typically used with
Vision Transformers, we achieved a commendable classification accuracy of
92.49% and a micro-average ROC AUC of 0.9935. The CCT also learned quickly,
exceeding 80% validation accuracy after five epochs. Analysis of per-class
precision, recall, F1, and ROC showed that performance was strong across cell
types. Our findings underscore the robustness of CCTs, indicating their
potential as a solution to data scarcity issues prevalent in biomedical
imaging. We substantiate the applicability of CCTs in data-constrained areas
and encourage further work on CCTs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_A/0/1/0/all/0/1&quot;&gt;Andrew Kean Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00215">
<title>A Constructive Approach to Function Realization by Neural Stochastic Differential Equations. (arXiv:2307.00215v1 [math.OC])</title>
<link>http://arxiv.org/abs/2307.00215</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of function approximation by neural dynamical systems has
typically been approached in a top-down manner: Any continuous function can be
approximated to an arbitrary accuracy by a sufficiently complex model with a
given architecture. This can lead to high-complexity controls which are
impractical in applications. In this paper, we take the opposite, constructive
approach: We impose various structural restrictions on system dynamics and
consequently characterize the class of functions that can be realized by such a
system. The systems are implemented as a cascade interconnection of a neural
stochastic differential equation (Neural SDE), a deterministic dynamical
system, and a readout map. Both probabilistic and geometric (Lie-theoretic)
methods are used to characterize the classes of functions realized by such
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Veeravalli_T/0/1/0/all/0/1&quot;&gt;Tanya Veeravalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Raginsky_M/0/1/0/all/0/1&quot;&gt;Maxim Raginsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00222">
<title>Re-Think and Re-Design Graph Neural Networks in Spaces of Continuous Graph Diffusion Functionals. (arXiv:2307.00222v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00222</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks (GNNs) are widely used in domains like social networks
and biological systems. However, the locality assumption of GNNs, which limits
information exchange to neighboring nodes, hampers their ability to capture
long-range dependencies and global patterns in graphs. To address this, we
propose a new inductive bias based on variational analysis, drawing inspiration
from the Brachistochrone problem. Our framework establishes a mapping between
discrete GNN models and continuous diffusion functionals. This enables the
design of application-specific objective functions in the continuous domain and
the construction of discrete deep models with mathematical guarantees. To
tackle over-smoothing in GNNs, we analyze the existing layer-by-layer graph
embedding models and identify that they are equivalent to l2-norm integral
functionals of graph gradients, which cause over-smoothing. Similar to
edge-preserving filters in image denoising, we introduce total variation (TV)
to align the graph diffusion pattern with global community topologies.
Additionally, we devise a selective mechanism to address the trade-off between
model depth and over-smoothing, which can be easily integrated into existing
GNNs. Furthermore, we propose a novel generative adversarial network (GAN) that
predicts spreading flows in graphs through a neural transport equation. To
mitigate vanishing flows, we customize the objective function to minimize
transportation within each community while maximizing inter-community flows.
Our GNN models achieve state-of-the-art (SOTA) performance on popular graph
learning benchmarks such as Cora, Citeseer, and Pubmed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dan_T/0/1/0/all/0/1&quot;&gt;Tingting Dan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1&quot;&gt;Jiaqi Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1&quot;&gt;Ziquan Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kovalsky_S/0/1/0/all/0/1&quot;&gt;Shahar Z Kovalsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Minjeong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1&quot;&gt;Won Hwa Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1&quot;&gt;Guorong Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00226">
<title>S-Omninet: Structured Data Enhanced Universal Multimodal Learning Architecture. (arXiv:2307.00226v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00226</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal multitask learning has attracted an increasing interest in recent
years. Singlemodal models have been advancing rapidly and have achieved
astonishing results on various tasks across multiple domains. Multimodal
learning offers opportunities for further improvements by integrating data from
multiple modalities. Many methods are proposed to learn on a specific type of
multimodal data, such as vision and language data. A few of them are designed
to handle several modalities and tasks at a time. In this work, we extend and
improve Omninet, an architecture that is capable of handling multiple
modalities and tasks at a time, by introducing cross-cache attention,
integrating patch embeddings for vision inputs, and supporting structured data.
The proposed Structured-data-enhanced Omninet (S-Omninet) is a universal model
that is capable of learning from structured data of various dimensions
effectively with unstructured data through cross-cache attention, which enables
interactions among spatial, temporal, and structured features. We also enhance
spatial representations in a spatial cache with patch embeddings. We evaluate
the proposed model on several multimodal datasets and demonstrate a significant
improvement over the baseline, Omninet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1&quot;&gt;Ye Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1&quot;&gt;Diego Klabjan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Utke_J/0/1/0/all/0/1&quot;&gt;Jean Utke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00227">
<title>Causal Structure Learning by Using Intersection of Markov Blankets. (arXiv:2307.00227v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2307.00227</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a novel causal structure learning algorithm
called Endogenous and Exogenous Markov Blankets Intersection (EEMBI), which
combines the properties of Bayesian networks and Structural Causal Models
(SCM). Furthermore, we propose an extended version of EEMBI, namely EEMBI-PC,
which integrates the last step of the PC algorithm into EEMBI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yiran Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_C/0/1/0/all/0/1&quot;&gt;Chuanhou Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00228">
<title>InferTurbo: A Scalable System for Boosting Full-graph Inference of Graph Neural Network over Huge Graphs. (arXiv:2307.00228v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00228</link>
<description rdf:parseType="Literal">&lt;p&gt;GNN inference is a non-trivial task, especially in industrial scenarios with
giant graphs, given three main challenges, i.e., scalability tailored for
full-graph inference on huge graphs, inconsistency caused by stochastic
acceleration strategies (e.g., sampling), and the serious redundant computation
issue. To address the above challenges, we propose a scalable system named
InferTurbo to boost the GNN inference tasks in industrial scenarios. Inspired
by the philosophy of ``think-like-a-vertex&quot;, a GAS-like (Gather-Apply-Scatter)
schema is proposed to describe the computation paradigm and data flow of GNN
inference. The computation of GNNs is expressed in an iteration manner, in
which a vertex would gather messages via in-edges and update its state
information by forwarding an associated layer of GNNs with those messages and
then send the updated information to other vertexes via out-edges. Following
the schema, the proposed InferTurbo can be built with alternative backends
(e.g., batch processing system or graph computing system). Moreover, InferTurbo
introduces several strategies like shadow-nodes and partial-gather to handle
nodes with large degrees for better load balancing. With InferTurbo, GNN
inference can be hierarchically conducted over the full graph without sampling
and redundant computation. Experimental results demonstrate that our system is
robust and efficient for inference tasks over graphs containing some hub nodes
with many adjacent edges. Meanwhile, the system gains a remarkable performance
compared with the traditional inference pipeline, and it can finish a GNN
inference task over a graph with tens of billions of nodes and hundreds of
billions of edges within 2 hours.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dalong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1&quot;&gt;Xianzheng Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zhiyang Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1&quot;&gt;Miao Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1&quot;&gt;Binbin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jun Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00231">
<title>Forward-Forward Algorithm for Hyperspectral Image Classification: A Preliminary Study. (arXiv:2307.00231v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00231</link>
<description rdf:parseType="Literal">&lt;p&gt;The back-propagation algorithm has long been the de-facto standard in
optimizing weights and biases in neural networks, particularly in cutting-edge
deep learning models. Its widespread adoption in fields like natural language
processing, computer vision, and remote sensing has revolutionized automation
in various tasks. The popularity of back-propagation stems from its ability to
achieve outstanding performance in tasks such as classification, detection, and
segmentation. Nevertheless, back-propagation is not without its limitations,
encompassing sensitivity to initial conditions, vanishing gradients,
overfitting, and computational complexity. The recent introduction of a
forward-forward algorithm (FFA), which computes local goodness functions to
optimize network parameters, alleviates the dependence on substantial
computational resources and the constant need for architectural scaling. This
study investigates the application of FFA for hyperspectral image
classification. Experimental results and comparative analysis are provided with
the use of the traditional back-propagation algorithm. Preliminary results show
the potential behind FFA and its promises.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paheding_S/0/1/0/all/0/1&quot;&gt;Sidike Paheding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reyes_Angulo_A/0/1/0/all/0/1&quot;&gt;Abel A. Reyes-Angulo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00233">
<title>Hierarchical Federated Learning Incentivization for Gas Usage Estimation. (arXiv:2307.00233v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00233</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurately estimating gas usage is essential for the efficient functioning of
gas distribution networks and saving operational costs. Traditional methods
rely on centralized data processing, which poses privacy risks. Federated
learning (FL) offers a solution to this problem by enabling local data
processing on each participant, such as gas companies and heating stations.
However, local training and communication overhead may discourage gas companies
and heating stations from actively participating in the FL training process. To
address this challenge, we propose a Hierarchical FL Incentive Mechanism for
Gas Usage Estimation (HI-GAS), which has been testbedded in the ENN Group, one
of the leading players in the natural gas and green energy industry. It is
designed to support horizontal FL among gas companies, and vertical FL among
each gas company and heating station within a hierarchical FL ecosystem,
rewarding participants based on their contributions to FL. In addition, a
hierarchical FL model aggregation approach is also proposed to improve the gas
usage estimation performance by aggregating models at different levels of the
hierarchy. The incentive scheme employs a multi-dimensional contribution-aware
reward distribution function that combines the evaluation of data quality and
model contribution to incentivize both gas companies and heating stations
within their jurisdiction while maintaining fairness. Results of extensive
experiments validate the effectiveness of the proposed mechanism.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Has Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1&quot;&gt;Xiaoli Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chengyi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhenpeng Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiuli Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_Q/0/1/0/all/0/1&quot;&gt;Qijie Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zengxiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Han Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00238">
<title>Unified Transfer Learning Models for High-Dimensional Linear Regression. (arXiv:2307.00238v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2307.00238</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning plays a key role in modern data analysis when: (1) the
target data are scarce but the source data are sufficient; (2) the
distributions of the source and target data are heterogeneous. This paper
develops an interpretable unified transfer learning model, termed as UTrans,
which can detect both transferable variables and source data. More
specifically, we establish the estimation error bounds and prove that our
bounds are lower than those with target data only. Besides, we propose a source
detection algorithm based on hypothesis testing to exclude the nontransferable
data. We evaluate and compare UTrans to the existing algorithms in multiple
experiments. It is shown that UTrans attains much lower estimation and
prediction errors than the existing methods, while preserving interpretability.
We finally apply it to the US intergenerational mobility data and compare our
proposed algorithms to the classical machine learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shuo Shuo Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00246">
<title>On a Relation Between the Rate-Distortion Function and Optimal Transport. (arXiv:2307.00246v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2307.00246</link>
<description rdf:parseType="Literal">&lt;p&gt;We discuss a relationship between rate-distortion and optimal transport (OT)
theory, even though they seem to be unrelated at first glance. In particular,
we show that a function defined via an extremal entropic OT distance is
equivalent to the rate-distortion function. We numerically verify this result
as well as previous results that connect the Monge and Kantorovich problems to
optimal scalar quantization. Thus, we unify solving scalar quantization and
rate-distortion functions in an alternative fashion by using their respective
optimal transport solvers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_E/0/1/0/all/0/1&quot;&gt;Eric Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1&quot;&gt;Hamed Hassani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bidokhti_S/0/1/0/all/0/1&quot;&gt;Shirin Saeedi Bidokhti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00247">
<title>Safe Screening for Unbalanced Optimal Transport. (arXiv:2307.00247v1 [math.OC])</title>
<link>http://arxiv.org/abs/2307.00247</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a framework that utilizes the Safe Screening technique
to accelerate the optimization process of the Unbalanced Optimal Transport
(UOT) problem by proactively identifying and eliminating zero elements in the
sparse solutions. We demonstrate the feasibility of applying Safe Screening to
the UOT problem with $\ell_2$-penalty and KL-penalty by conducting an analysis
of the solution&apos;s bounds and considering the local strong convexity of the dual
problem. Considering the specific structural characteristics of the UOT in
comparison to general Lasso problems on the index matrix, we specifically
propose a novel approximate projection, an elliptical safe region construction,
and a two-hyperplane relaxation method. These enhancements significantly
improve the screening efficiency for the UOT&apos;s without altering the algorithm&apos;s
complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Su_X/0/1/0/all/0/1&quot;&gt;Xun Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Fang_Z/0/1/0/all/0/1&quot;&gt;Zhongxi Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kasai_H/0/1/0/all/0/1&quot;&gt;Hiroyuki Kasai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00252">
<title>An ML approach to resolution of singularities. (arXiv:2307.00252v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00252</link>
<description rdf:parseType="Literal">&lt;p&gt;The solution set of a system of polynomial equations typically contains
ill-behaved, singular points. Resolution is a fundamental process in geometry
in which we replace singular points with smooth points, while keeping the rest
of the solution set unchanged. Resolutions are not unique: the usual way to
describe them involves repeatedly performing a fundamental operation known as
&quot;blowing-up&quot;, and the complexity of the resolution highly depends on certain
choices. The process can be translated into various versions of a 2-player
game, the so-called Hironaka game, and a winning strategy for the first player
provides a solution to the resolution problem. In this paper we introduce a new
approach to the Hironaka game that uses reinforcement learning agents to find
optimal resolutions of singularities. In certain domains, the trained model
outperforms state-of-the-art selection heuristics in total number of polynomial
additions performed, which provides a proof-of-concept that recent developments
in machine learning have the potential to improve performance of algorithms in
symbolic computation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berczi_G/0/1/0/all/0/1&quot;&gt;Gergely B&amp;#xe9;rczi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1&quot;&gt;Honglu Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1&quot;&gt;Mingcong Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00268">
<title>Hiding in Plain Sight: Differential Privacy Noise Exploitation for Evasion-resilient Localized Poisoning Attacks in Multiagent Reinforcement Learning. (arXiv:2307.00268v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00268</link>
<description rdf:parseType="Literal">&lt;p&gt;Lately, differential privacy (DP) has been introduced in cooperative
multiagent reinforcement learning (CMARL) to safeguard the agents&apos; privacy
against adversarial inference during knowledge sharing. Nevertheless, we argue
that the noise introduced by DP mechanisms may inadvertently give rise to a
novel poisoning threat, specifically in the context of private knowledge
sharing during CMARL, which remains unexplored in the literature. To address
this shortcoming, we present an adaptive, privacy-exploiting, and
evasion-resilient localized poisoning attack (PeLPA) that capitalizes on the
inherent DP-noise to circumvent anomaly detection systems and hinder the
optimal convergence of the CMARL model. We rigorously evaluate our proposed
PeLPA attack in diverse environments, encompassing both non-adversarial and
multiple-adversarial contexts. Our findings reveal that, in a medium-scale
environment, the PeLPA attack with attacker ratios of 20% and 40% can lead to
an increase in average steps to goal by 50.69% and 64.41%, respectively.
Furthermore, under similar conditions, PeLPA can result in a 1.4x and 1.6x
computational time increase in optimal reward attainment and a 1.18x and 1.38x
slower convergence for attacker ratios of 20% and 40%, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1&quot;&gt;Md Tamjid Hossain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+La_H/0/1/0/all/0/1&quot;&gt;Hung La&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00274">
<title>Common Knowledge Learning for Generating Transferable Adversarial Examples. (arXiv:2307.00274v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00274</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper focuses on an important type of black-box attacks, i.e.,
transfer-based adversarial attacks, where the adversary generates adversarial
examples by a substitute (source) model and utilize them to attack an unseen
target model, without knowing its information. Existing methods tend to give
unsatisfactory adversarial transferability when the source and target models
are from different types of DNN architectures (e.g. ResNet-18 and Swin
Transformer). In this paper, we observe that the above phenomenon is induced by
the output inconsistency problem. To alleviate this problem while effectively
utilizing the existing DNN models, we propose a common knowledge learning (CKL)
framework to learn better network weights to generate adversarial examples with
better transferability, under fixed network architectures. Specifically, to
reduce the model-specific features and obtain better output distributions, we
construct a multi-teacher framework, where the knowledge is distilled from
different teacher architectures into one student network. By considering that
the gradient of input is usually utilized to generated adversarial examples, we
impose constraints on the gradients between the student and teacher models, to
further alleviate the output inconsistency problem and enhance the adversarial
transferability. Extensive experiments demonstrate that our proposed work can
significantly improve the adversarial transferability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Ruijie Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yuanfang Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junfu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiantao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yunhong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00280">
<title>SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency. (arXiv:2307.00280v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00280</link>
<description rdf:parseType="Literal">&lt;p&gt;Extensive studies have shown that deep learning models are vulnerable to
adversarial and natural noises, yet little is known about model robustness on
noises caused by different system implementations. In this paper, we for the
first time introduce SysNoise, a frequently occurred but often overlooked noise
in the deep learning training-deployment cycle. In particular, SysNoise happens
when the source training system switches to a disparate target system in
deployments, where various tiny system mismatch adds up to a non-negligible
difference. We first identify and classify SysNoise into three categories based
on the inference stage; we then build a holistic benchmark to quantitatively
measure the impact of SysNoise on 20+ models, comprehending image
classification, object detection, instance segmentation and natural language
processing tasks. Our extensive experiments revealed that SysNoise could bring
certain impacts on model robustness across different tasks and common
mitigations like data augmentation and adversarial training show limited
effects on it. Together, our findings open a new research topic and we hope
this work will raise research attention to deep learning deployment systems
accounting for model performance. We have open-sourced the benchmark and
framework at https://modeltc.github.io/systemnoise_web.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuhang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1&quot;&gt;Ruihao Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1&quot;&gt;Aishan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanfei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jian Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yongqiang Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yunchen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1&quot;&gt;Tianzi Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Fengwei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xianglong Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00285">
<title>Assembled-OpenML: Creating Efficient Benchmarks for Ensembles in AutoML with OpenML. (arXiv:2307.00285v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00285</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated Machine Learning (AutoML) frameworks regularly use ensembles.
Developers need to compare different ensemble techniques to select appropriate
techniques for an AutoML framework from the many potential techniques. So far,
the comparison of ensemble techniques is often computationally expensive,
because many base models must be trained and evaluated one or multiple times.
Therefore, we present Assembled-OpenML. Assembled-OpenML is a Python tool,
which builds meta-datasets for ensembles using OpenML. A meta-dataset, called
Metatask, consists of the data of an OpenML task, the task&apos;s dataset, and
prediction data from model evaluations for the task. We can make the comparison
of ensemble techniques computationally cheaper by using the predictions stored
in a metatask instead of training and evaluating base models. To introduce
Assembled-OpenML, we describe the first version of our tool. Moreover, we
present an example of using Assembled-OpenML to compare a set of ensemble
techniques. For this example comparison, we built a benchmark using
Assembled-OpenML and implemented ensemble techniques expecting predictions
instead of base models as input. In our example comparison, we gathered the
prediction data of $1523$ base models for $31$ datasets. Obtaining the
prediction data for all base models using Assembled-OpenML took ${\sim} 1$ hour
in total. In comparison, obtaining the prediction data by training and
evaluating just one base model on the most computationally expensive dataset
took ${\sim} 37$ minutes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purucker_L/0/1/0/all/0/1&quot;&gt;Lennart Purucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beel_J/0/1/0/all/0/1&quot;&gt;Joeran Beel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00286">
<title>CMA-ES for Post Hoc Ensembling in AutoML: A Great Success and Salvageable Failure. (arXiv:2307.00286v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00286</link>
<description rdf:parseType="Literal">&lt;p&gt;Many state-of-the-art automated machine learning (AutoML) systems use greedy
ensemble selection (GES) by Caruana et al. (2004) to ensemble models found
during model selection post hoc. Thereby, boosting predictive performance and
likely following Auto-Sklearn 1&apos;s insight that alternatives, like stacking or
gradient-free numerical optimization, overfit. Overfitting in Auto-Sklearn 1 is
much more likely than in other AutoML systems because it uses only low-quality
validation data for post hoc ensembling. Therefore, we were motivated to
analyze whether Auto-Sklearn 1&apos;s insight holds true for systems with
higher-quality validation data. Consequently, we compared the performance of
covariance matrix adaptation evolution strategy (CMA-ES), state-of-the-art
gradient-free numerical optimization, to GES on the 71 classification datasets
from the AutoML benchmark for AutoGluon. We found that Auto-Sklearn&apos;s insight
depends on the chosen metric. For the metric ROC AUC, CMA-ES overfits
drastically and is outperformed by GES -- statistically significantly for
multi-class classification. For the metric balanced accuracy, CMA-ES does not
overfit and outperforms GES significantly. Motivated by the successful
application of CMA-ES for balanced accuracy, we explored methods to stop CMA-ES
from overfitting for ROC AUC. We propose a method to normalize the weights
produced by CMA-ES, inspired by GES, that avoids overfitting for CMA-ES and
makes CMA-ES perform better than or similar to GES for ROC AUC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purucker_L/0/1/0/all/0/1&quot;&gt;Lennart Purucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beel_J/0/1/0/all/0/1&quot;&gt;Joeran Beel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00290">
<title>All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with Prompt-based Finetuning. (arXiv:2307.00290v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00290</link>
<description rdf:parseType="Literal">&lt;p&gt;The Segment Anything Model (SAM) is a recently proposed prompt-based
segmentation model in a generic zero-shot segmentation approach. With the
zero-shot segmentation capacity, SAM achieved impressive flexibility and
precision on various segmentation tasks. However, the current pipeline requires
manual prompts during the inference stage, which is still resource intensive
for biomedical image segmentation. In this paper, instead of using prompts
during the inference stage, we introduce a pipeline that utilizes the SAM,
called all-in-SAM, through the entire AI development workflow (from annotation
generation to model finetuning) without requiring manual prompts during the
inference stage. Specifically, SAM is first employed to generate pixel-level
annotations from weak prompts (e.g., points, bounding box). Then, the
pixel-level annotations are used to finetune the SAM segmentation model rather
than training from scratch. Our experimental results reveal two key findings:
1) the proposed pipeline surpasses the state-of-the-art (SOTA) methods in a
nuclei segmentation task on the public Monuseg dataset, and 2) the utilization
of weak and few annotations for SAM finetuning achieves competitive performance
compared to using strong pixel-wise annotated data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1&quot;&gt;Can Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_R/0/1/0/all/0/1&quot;&gt;Ruining Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Quan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1&quot;&gt;Tianyuan Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_S/0/1/0/all/0/1&quot;&gt;Shunxing Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Remedios_L/0/1/0/all/0/1&quot;&gt;Lucas W. Remedios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yucheng Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1&quot;&gt;Yuankai Huo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00293">
<title>AutoST: Training-free Neural Architecture Search for Spiking Transformers. (arXiv:2307.00293v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2307.00293</link>
<description rdf:parseType="Literal">&lt;p&gt;Spiking Transformers have gained considerable attention because they achieve
both the energy efficiency of Spiking Neural Networks (SNNs) and the high
capacity of Transformers. However, the existing Spiking Transformer
architectures, derived from ANNs, exhibit a notable architectural gap,
resulting in suboptimal performance compared to their ANN counterparts.
Traditional approaches to discovering optimal architectures primarily rely on
either manual procedures, which are time-consuming, or Neural Architecture
Search (NAS) methods, which are usually expensive in terms of memory footprints
and computation time. To address these limitations, we introduce AutoST, a
training-free NAS method for Spiking Transformers, to rapidly identify
high-performance and energy-efficient Spiking Transformer architectures. Unlike
existing training-free NAS methods, which struggle with the
non-differentiability and high sparsity inherent in SNNs, we propose to utilize
Floating-Point Operations (FLOPs) as a performance metric, which is independent
of model computations and training dynamics, leading to a stronger correlation
with performance. Moreover, to enable the search for energy-efficient
architectures, we leverage activation patterns during initialization to
estimate the energy consumption of Spiking Transformers. Our extensive
experiments show that AutoST models outperform state-of-the-art manually or
automatically designed SNN architectures on static and neuromorphic datasets,
while significantly reducing energy consumption.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziqing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qidong Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1&quot;&gt;Jinku Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1&quot;&gt;Dongkuan Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00296">
<title>Accelerated primal-dual methods with enlarged step sizes and operator learning for nonsmooth optimal control problems. (arXiv:2307.00296v1 [math.OC])</title>
<link>http://arxiv.org/abs/2307.00296</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a general class of nonsmooth optimal control problems with
partial differential equation (PDE) constraints, which are very challenging due
to its nonsmooth objective functionals and the resulting high-dimensional and
ill-conditioned systems after discretization. We focus on the application of a
primal-dual method, with which different types of variables can be treated
individually and thus its main computation at each iteration only requires
solving two PDEs. Our target is to accelerate the primal-dual method with
either larger step sizes or operator learning techniques. For the accelerated
primal-dual method with larger step sizes, its convergence can be still proved
rigorously while it numerically accelerates the original primal-dual method in
a simple and universal way. For the operator learning acceleration, we
construct deep neural network surrogate models for the involved PDEs. Once a
neural operator is learned, solving a PDE requires only a forward pass of the
neural network, and the computational cost is thus substantially reduced. The
accelerated primal-dual method with operator learning is mesh-free, numerically
efficient, and scalable to different types of PDEs. The acceleration
effectiveness of these two techniques is promisingly validated by some
preliminary numerical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yongcun Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xiaoming Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yue_H/0/1/0/all/0/1&quot;&gt;Hangrui Yue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00305">
<title>Applied Bayesian Structural Health Monitoring: inclinometer data anomaly detection and forecasting. (arXiv:2307.00305v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00305</link>
<description rdf:parseType="Literal">&lt;p&gt;Inclinometer probes are devices that can be used to measure deformations
within earthwork slopes. This paper demonstrates a novel application of
Bayesian techniques to real-world inclinometer data, providing both anomaly
detection and forecasting. Specifically, this paper details an analysis of data
collected from inclinometer data across the entire UK rail network.
&lt;/p&gt;
&lt;p&gt;Practitioners have effectively two goals when processing monitoring data. The
first is to identify any anomalous or dangerous movements, and the second is to
predict potential future adverse scenarios by forecasting. In this paper we
apply Uncertainty Quantification (UQ) techniques by implementing a Bayesian
approach to anomaly detection and forecasting for inclinometer data.
Subsequently, both costs and risks may be minimised by quantifying and
evaluating the appropriate uncertainties. This framework may then act as an
enabler for enhanced decision making and risk analysis.
&lt;/p&gt;
&lt;p&gt;We show that inclinometer data can be described by a latent autocorrelated
Markov process derived from measurements. This can be used as the transition
model of a non-linear Bayesian filter. This allows for the prediction of system
states. This learnt latent model also allows for the detection of anomalies:
observations that are far from their expected value may be considered to have
`high surprisal&apos;, that is they have a high information content relative to the
model encoding represented by the learnt latent model.
&lt;/p&gt;
&lt;p&gt;We successfully apply the forecasting and anomaly detection techniques to a
large real-world data set in a computationally efficient manner. Although this
paper studies inclinometers in particular, the techniques are broadly
applicable to all areas of engineering UQ and Structural Health Monitoring
(SHM).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Green_D/0/1/0/all/0/1&quot;&gt;David K. E. Green&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaspan_A/0/1/0/all/0/1&quot;&gt;Adam Jaspan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00306">
<title>SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D Object Pose Estimation. (arXiv:2307.00306v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00306</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting objects and estimating their 6D poses is essential for automated
systems to interact safely with the environment. Most 6D pose estimators,
however, rely on a single camera frame and suffer from occlusions and
ambiguities due to object symmetries. We overcome this issue by presenting a
novel symmetry-aware multi-view 6D pose estimator called SyMFM6D. Our approach
efficiently fuses the RGB-D frames from multiple perspectives in a deep
multi-directional fusion network and predicts predefined keypoints for all
objects in the scene simultaneously. Based on the keypoints and an instance
semantic segmentation, we efficiently compute the 6D poses by least-squares
fitting. To address the ambiguity issues for symmetric objects, we propose a
novel training procedure for symmetry-aware keypoint detection including a new
objective function. Our SyMFM6D network significantly outperforms the
state-of-the-art in both single-view and multi-view 6D pose estimation. We
furthermore show the effectiveness of our symmetry-aware training procedure and
demonstrate that our approach is robust towards inaccurate camera calibration
and dynamic camera setups.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duffhauss_F/0/1/0/all/0/1&quot;&gt;Fabian Duffhauss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koch_S/0/1/0/all/0/1&quot;&gt;Sebastian Koch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1&quot;&gt;Hanna Ziesche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1&quot;&gt;Ngo Anh Vien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1&quot;&gt;Gerhard Neumann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00309">
<title>Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey. (arXiv:2307.00309v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.00309</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has successfully solved a wide range of tasks in 2D vision as a
dominant AI technique. Recently, deep learning on 3D point clouds is becoming
increasingly popular for addressing various tasks in this field. Despite
remarkable achievements, deep learning algorithms are vulnerable to adversarial
attacks. These attacks are imperceptible to the human eye but can easily fool
deep neural networks in the testing and deployment stage. To encourage future
research, this survey summarizes the current progress on adversarial attack and
defense techniques on point cloud classification. This paper first introduces
the principles and characteristics of adversarial attacks and summarizes and
analyzes the adversarial example generation methods in recent years. Besides,
it classifies defense strategies as input transformation, data optimization,
and deep model modification. Finally, it presents several challenging issues
and future research directions in this domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naderi_H/0/1/0/all/0/1&quot;&gt;Hanieh Naderi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajic_I/0/1/0/all/0/1&quot;&gt;Ivan V. Baji&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00310">
<title>Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD. (arXiv:2307.00310v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00310</link>
<description rdf:parseType="Literal">&lt;p&gt;Differentially private stochastic gradient descent (DP-SGD) is the canonical
algorithm for private deep learning. While it is known that its privacy
analysis is tight in the worst-case, several empirical results suggest that
when training on common benchmark datasets, the models obtained leak
significantly less privacy for many datapoints. In this paper, we develop a new
analysis for DP-SGD that captures the intuition that points with similar
neighbors in the dataset enjoy better privacy than outliers. Formally, this is
done by modifying the per-step privacy analysis of DP-SGD to introduce a
dependence on the distribution of model updates computed from a training
dataset. We further develop a new composition theorem to effectively use this
new per-step analysis to reason about an entire training run. Put all together,
our evaluation shows that this novel DP-SGD analysis allows us to now formally
show that DP-SGD leaks significantly less privacy for many datapoints. In
particular, we observe that correctly classified points obtain better privacy
guarantees than misclassified points.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thudi_A/0/1/0/all/0/1&quot;&gt;Anvith Thudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1&quot;&gt;Hengrui Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meehan_C/0/1/0/all/0/1&quot;&gt;Casey Meehan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1&quot;&gt;Ilia Shumailov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1&quot;&gt;Nicolas Papernot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00316">
<title>SHARCS: Shared Concept Space for Explainable Multimodal Learning. (arXiv:2307.00316v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.00316</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal learning is an essential paradigm for addressing complex
real-world problems, where individual data modalities are typically
insufficient to accurately solve a given modelling task. While various deep
learning approaches have successfully addressed these challenges, their
reasoning process is often opaque; limiting the capabilities for a principled
explainable cross-modal analysis and any domain-expert intervention. In this
paper, we introduce SHARCS (SHARed Concept Space) -- a novel concept-based
approach for explainable multimodal learning. SHARCS learns and maps
interpretable concepts from different heterogeneous modalities into a single
unified concept-manifold, which leads to an intuitive projection of
semantically similar cross-modal concepts. We demonstrate that such an approach
can lead to inherently explainable task predictions while also improving
downstream predictive performance. Moreover, we show that SHARCS can operate
and significantly outperform other approaches in practically significant
scenarios, such as retrieval of missing modalities and cross-modal
explanations. Our approach is model-agnostic and easily applicable to different
types (and number) of modalities, thus advancing the development of effective,
interpretable, and trustworthy multimodal approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dominici_G/0/1/0/all/0/1&quot;&gt;Gabriele Dominici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbiero_P/0/1/0/all/0/1&quot;&gt;Pietro Barbiero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magister_L/0/1/0/all/0/1&quot;&gt;Lucie Charlotte Magister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1&quot;&gt;Pietro Li&amp;#xf2;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simidjievski_N/0/1/0/all/0/1&quot;&gt;Nikola Simidjievski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1911.10322">
<title>Meta Adaptation using Importance Weighted Demonstrations. (arXiv:1911.10322v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1911.10322</link>
<description rdf:parseType="Literal">&lt;p&gt;Imitation learning has gained immense popularity because of its high
sample-efficiency. However, in real-world scenarios, where the trajectory
distribution of most of the tasks dynamically shifts, model fitting on
continuously aggregated data alone would be futile. In some cases, the
distribution shifts, so much, that it is difficult for an agent to infer the
new task. We propose a novel algorithm to generalize on any related task by
leveraging prior knowledge on a set of specific tasks, which involves assigning
importance weights to each past demonstration. We show experiments where the
robot is trained from a diversity of environmental tasks and is also able to
adapt to an unseen environment, using few-shot learning. We also developed a
prototype robot system to test our approach on the task of visual navigation,
and experimental results obtained were able to confirm these suppositions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lekkala_K/0/1/0/all/0/1&quot;&gt;Kiran Lekkala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abu_El_Haija_S/0/1/0/all/0/1&quot;&gt;Sami Abu-El-Haija&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Itti_L/0/1/0/all/0/1&quot;&gt;Laurent Itti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2002.04258">
<title>Learning to Switch Among Agents in a Team via 2-Layer Markov Decision Processes. (arXiv:2002.04258v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2002.04258</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning agents have been mostly developed and evaluated under
the assumption that they will operate in a fully autonomous manner -- they will
take all actions. In this work, our goal is to develop algorithms that, by
learning to switch control between agents, allow existing reinforcement
learning agents to operate under different automation levels. To this end, we
first formally define the problem of learning to switch control among agents in
a team via a 2-layer Markov decision process. Then, we develop an online
learning algorithm that uses upper confidence bounds on the agents&apos; policies
and the environment&apos;s transition probabilities to find a sequence of switching
policies. The total regret of our algorithm with respect to the optimal
switching policy is sublinear in the number of learning steps and, whenever
multiple teams of agents operate in a similar environment, our algorithm
greatly benefits from maintaining shared confidence bounds for the
environments&apos; transition probabilities and it enjoys a better regret bound than
problem-agnostic algorithms. Simulation experiments in an obstacle avoidance
task illustrate our theoretical findings and demonstrate that, by exploiting
the specific structure of the problem, our proposed algorithm is superior to
problem-agnostic algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balazadeh_V/0/1/0/all/0/1&quot;&gt;Vahid Balazadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1&quot;&gt;Abir De&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1&quot;&gt;Adish Singla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_M/0/1/0/all/0/1&quot;&gt;Manuel Gomez-Rodriguez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2009.07888">
<title>Transfer Learning in Deep Reinforcement Learning: A Survey. (arXiv:2009.07888v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2009.07888</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning is a learning paradigm for solving sequential
decision-making problems. Recent years have witnessed remarkable progress in
reinforcement learning upon the fast development of deep neural networks. Along
with the promising prospects of reinforcement learning in numerous domains such
as robotics and game-playing, transfer learning has arisen to tackle various
challenges faced by reinforcement learning, by transferring knowledge from
external expertise to facilitate the efficiency and effectiveness of the
learning process. In this survey, we systematically investigate the recent
progress of transfer learning approaches in the context of deep reinforcement
learning. Specifically, we provide a framework for categorizing the
state-of-the-art transfer learning approaches, under which we analyze their
goals, methodologies, compatible reinforcement learning backbones, and
practical applications. We also draw connections between transfer learning and
other relevant topics from the reinforcement learning perspective and explore
their potential challenges that await future research progress.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhuangdi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1&quot;&gt;Kaixiang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1&quot;&gt;Anil K. Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiayu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2012.04597">
<title>Generalized iterated-sums signatures. (arXiv:2012.04597v3 [math.RA] UPDATED)</title>
<link>http://arxiv.org/abs/2012.04597</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the algebraic properties of a generalized version of the
iterated-sums signature, inspired by previous work of F.~Kir\&apos;aly and
H.~Oberhauser. In particular, we show how to recover the character property of
the associated linear map over the tensor algebra by considering a deformed
quasi-shuffle product of words on the latter. We introduce three non-linear
transformations on iterated-sums signatures, close in spirit to Machine
Learning applications, and show some of their properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Diehl_J/0/1/0/all/0/1&quot;&gt;Joscha Diehl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ebrahimi_Fard_K/0/1/0/all/0/1&quot;&gt;Kurusch Ebrahimi-Fard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tapia_N/0/1/0/all/0/1&quot;&gt;Nikolas Tapia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.12021">
<title>Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism. (arXiv:2103.12021v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2103.12021</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline (or batch) reinforcement learning (RL) algorithms seek to learn an
optimal policy from a fixed dataset without active data collection. Based on
the composition of the offline dataset, two main categories of methods are
used: imitation learning which is suitable for expert datasets and vanilla
offline RL which often requires uniform coverage datasets. From a practical
standpoint, datasets often deviate from these two extremes and the exact data
composition is usually unknown a priori. To bridge this gap, we present a new
offline RL framework that smoothly interpolates between the two extremes of
data composition, hence unifying imitation learning and vanilla offline RL. The
new framework is centered around a weak version of the concentrability
coefficient that measures the deviation from the behavior policy to the expert
policy alone.
&lt;/p&gt;
&lt;p&gt;Under this new framework, we further investigate the question on algorithm
design: can one develop an algorithm that achieves a minimax optimal rate and
also adapts to unknown data composition? To address this question, we consider
a lower confidence bound (LCB) algorithm developed based on pessimism in the
face of uncertainty in offline RL. We study finite-sample properties of LCB as
well as information-theoretic limits in multi-armed bandits, contextual
bandits, and Markov decision processes (MDPs). Our analysis reveals surprising
facts about optimality rates. In particular, in all three settings, LCB
achieves a faster rate of $1/N$ for nearly-expert datasets compared to the
usual rate of $1/\sqrt{N}$ in offline RL, where $N$ is the number of samples in
the batch dataset. In the case of contextual bandits with at least two
contexts, we prove that LCB is adaptively optimal for the entire data
composition range, achieving a smooth transition from imitation learning to
offline RL. We further show that LCB is almost adaptively optimal in MDPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashidinejad_P/0/1/0/all/0/1&quot;&gt;Paria Rashidinejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1&quot;&gt;Banghua Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Cong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jiantao Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1&quot;&gt;Stuart Russell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.14639">
<title>Shaped Policy Search for Evolutionary Strategies using Waypoints. (arXiv:2105.14639v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2105.14639</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we try to improve exploration in Blackbox methods,
particularly Evolution strategies (ES), when applied to Reinforcement Learning
(RL) problems where intermediate waypoints/subgoals are available. Since
Evolutionary strategies are highly parallelizable, instead of extracting just a
scalar cumulative reward, we use the state-action pairs from the trajectories
obtained during rollouts/evaluations, to learn the dynamics of the agent. The
learnt dynamics are then used in the optimization procedure to speed-up
training. Lastly, we show how our proposed approach is universally applicable
by presenting results from experiments conducted on Carla driving and UR5
robotic arm simulators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lekkala_K/0/1/0/all/0/1&quot;&gt;Kiran Lekkala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Itti_L/0/1/0/all/0/1&quot;&gt;Laurent Itti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.03907">
<title>Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation. (arXiv:2106.03907v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.03907</link>
<description rdf:parseType="Literal">&lt;p&gt;Proxy causal learning (PCL) is a method for estimating the causal effect of
treatments on outcomes in the presence of unobserved confounding, using proxies
(structured side information) for the confounder. This is achieved via
two-stage regression: in the first stage, we model relations among the
treatment and proxies; in the second stage, we use this model to learn the
effect of treatment on the outcome, given the context provided by the proxies.
PCL guarantees recovery of the true causal effect, subject to identifiability
conditions. We propose a novel method for PCL, the deep feature proxy variable
method (DFPV), to address the case where the proxies, treatments, and outcomes
are high-dimensional and have nonlinear complex relationships, as represented
by deep neural network features. We show that DFPV outperforms recent
state-of-the-art PCL methods on challenging synthetic benchmarks, including
settings involving high dimensional image data. Furthermore, we show that PCL
can be applied to off-policy evaluation for the confounded bandit problem, in
which DFPV also exhibits competitive performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1&quot;&gt;Liyuan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanagawa_H/0/1/0/all/0/1&quot;&gt;Heishiro Kanagawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gretton_A/0/1/0/all/0/1&quot;&gt;Arthur Gretton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.14015">
<title>Contextual Inverse Optimization: Offline and Online Learning. (arXiv:2106.14015v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.14015</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problems of offline and online contextual optimization with
feedback information, where instead of observing the loss, we observe,
after-the-fact, the optimal action an oracle with full knowledge of the
objective function would have taken. We aim to minimize regret, which is
defined as the difference between our losses and the ones incurred by an
all-knowing oracle. In the offline setting, the decision-maker has information
available from past periods and needs to make one decision, while in the online
setting, the decision-maker optimizes decisions dynamically over time based a
new set of feasible actions and contextual functions in each period. For the
offline setting, we characterize the optimal minimax policy, establishing the
performance that can be achieved as a function of the underlying geometry of
the information induced by the data. In the online setting, we leverage this
geometric characterization to optimize the cumulative regret. We develop an
algorithm that yields the first regret bound for this problem that is
logarithmic in the time horizon. Finally, we show via simulation that our
proposed algorithms outperform previous methods from the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Besbes_O/0/1/0/all/0/1&quot;&gt;Omar Besbes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonseca_Y/0/1/0/all/0/1&quot;&gt;Yuri Fonseca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lobel_I/0/1/0/all/0/1&quot;&gt;Ilan Lobel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.02378">
<title>Learning an Explicit Hyperparameter Prediction Function Conditioned on Tasks. (arXiv:2107.02378v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2107.02378</link>
<description rdf:parseType="Literal">&lt;p&gt;Meta learning has attracted much attention recently in machine learning
community. Contrary to conventional machine learning aiming to learn inherent
prediction rules to predict labels for new query data, meta learning aims to
learn the learning methodology for machine learning from observed tasks, so as
to generalize to new query tasks by leveraging the meta-learned learning
methodology. In this study, we interpret such learning methodology as learning
an explicit hyper-parameter prediction function shared by all training tasks.
Specifically, this function is represented as a parameterized function called
meta-learner, mapping from a training/test task to its suitable hyper-parameter
setting, extracted from a pre-specified function set called meta learning
machine. Such setting guarantees that the meta-learned learning methodology is
able to flexibly fit diverse query tasks, instead of only obtaining fixed
hyper-parameters by many current meta learning methods, with less adaptability
to query task&apos;s variations. Such understanding of meta learning also makes it
easily succeed from traditional learning theory for analyzing its
generalization bounds with general losses/tasks/models. The theory naturally
leads to some feasible controlling strategies for ameliorating the quality of
the extracted meta-learner, verified to be able to finely ameliorate its
generalization capability in some typical meta learning applications, including
few-shot regression, few-shot classification and domain generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_J/0/1/0/all/0/1&quot;&gt;Jun Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1&quot;&gt;Deyu Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zongben Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.04470">
<title>Truth Discovery in Sequence Labels from Crowds. (arXiv:2109.04470v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/2109.04470</link>
<description rdf:parseType="Literal">&lt;p&gt;Annotation quality and quantity positively affect the learning performance of
sequence labeling, a vital task in Natural Language Processing. Hiring domain
experts to annotate a corpus is very costly in terms of money and time.
Crowdsourcing platforms, such as Amazon Mechanical Turk (AMT), have been
deployed to assist in this purpose. However, the annotations collected this way
are prone to human errors due to the lack of expertise of the crowd workers.
Existing literature in annotation aggregation assumes that annotations are
independent and thus faces challenges when handling the sequential label
aggregation tasks with complex dependencies. To conquer the challenges, we
propose an optimization-based method that infers the ground truth labels using
annotations provided by workers for sequential labeling tasks. The proposed
Aggregation method for Sequential Labels from Crowds ($AggSLC$) jointly
considers the characteristics of sequential labeling tasks, workers&apos;
reliabilities, and advanced machine learning techniques. Theoretical analysis
on the algorithm&apos;s convergence further demonstrates that the proposed $AggSLC$
halts after a finite number of iterations. We evaluate $AggSLC$ on different
crowdsourced datasets for Named Entity Recognition (NER) tasks and Information
Extraction tasks in biomedical (PICO), as well as a simulated dataset. Our
results show that the proposed method outperforms the state-of-the-art
aggregation methods. To achieve insights into the framework, we study the
effectiveness of $AggSLC$&apos;s components through ablation studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabetpour_N/0/1/0/all/0/1&quot;&gt;Nasim Sabetpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1&quot;&gt;Adithya Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1&quot;&gt;Sihong Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qi Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.10258">
<title>Arterial blood pressure waveform in liver transplant surgery possesses variability of morphology reflecting recipients&apos; acuity and predicting short term outcomes. (arXiv:2109.10258v2 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2109.10258</link>
<description rdf:parseType="Literal">&lt;p&gt;Background: We investigated clinical information underneath the beat-to-beat
fluctuation of the arterial blood pressure (ABP) waveform morphology. We
proposed the Dynamical Diffusion Map algorithm (DDMap) to quantify the
variability of morphology. The underlying physiology could be the compensatory
mechanisms involving complex interactions between various physiological
mechanisms to regulate the cardiovascular system. As a liver transplant surgery
contains distinct periods, we investigated its clinical behavior in different
surgical steps. Methods: Our study used DDmap algorithm, based on unsupervised
manifold learning, to obtain a quantitative index for the beat-to-beat
variability of morphology. We examined the correlation between the variability
of ABP morphology and disease acuity as indicated by Model for End-Stage Liver
Disease (MELD) scores, the postoperative laboratory data, and 4 early allograft
failure (EAF) scores. Results: Among the 85 enrolled patients, the variability
of morphology obtained during the presurgical phase was best correlated with
MELD-Na scores. The neohepatic phase variability of morphology was associated
with EAF scores as well as postoperative bilirubin levels, international
normalized ratio, aspartate aminotransferase levels, and platelet count.
Furthermore, variability of morphology presents more associations with the
above clinical conditions than the common BP measures and their BP variability
indices. Conclusions: The variability of morphology obtained during the
presurgical phase is indicative of patient acuity, whereas those during the
neohepatic phase are indicative of short-term surgical outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shen-Chih Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ting_C/0/1/0/all/0/1&quot;&gt;Chien-Kun Ting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Cheng-Yen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chin-Su Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lin_N/0/1/0/all/0/1&quot;&gt;Niang-Cheng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Loon_C/0/1/0/all/0/1&quot;&gt;Che-Chuan Loon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hau-Tieng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yu-Ting Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.02271">
<title>Networked Time Series Prediction with Incomplete Data. (arXiv:2110.02271v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.02271</link>
<description rdf:parseType="Literal">&lt;p&gt;A networked time series (NETS) is a family of time series on a given graph,
one for each node. It has found a wide range of applications from intelligent
transportation, environment monitoring to mobile network management. An
important task in such applications is to predict the future values of a NETS
based on its historical values and the underlying graph. Most existing methods
require complete data for training. However, in real-world scenarios, it is not
uncommon to have missing data due to sensor malfunction, incomplete sensing
coverage, etc. In this paper, we study the problem of NETS prediction with
incomplete data. We propose NETS-ImpGAN, a novel deep learning framework that
can be trained on incomplete data with missing values in both history and
future. Furthermore, we propose novel Graph Temporal Attention Networks by
incorporating the attention mechanism to capture both inter-time series
correlations and temporal correlations. We conduct extensive experiments on
three real-world datasets under different missing patterns and missing rates.
The experimental results show that NETS-ImpGAN outperforms existing methods
except when data exhibit very low variance, in which case NETS-ImpGAN still
achieves competitive performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yichen Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mengtian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1&quot;&gt;Bo Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Haiming Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jianqiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinbing Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.05674">
<title>Deviance Matrix Factorization. (arXiv:2110.05674v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2110.05674</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate a general matrix factorization for deviance-based data losses,
extending the ubiquitous singular value decomposition beyond squared error
loss. While similar approaches have been explored before, our method leverages
classical statistical methodology from generalized linear models (GLMs) and
provides an efficient algorithm that is flexible enough to allow for structural
zeros via entry weights. Moreover, by adapting results from GLM theory, we
provide support for these decompositions by (i) showing strong consistency
under the GLM setup, (ii) checking the adequacy of a chosen exponential family
via a generalized Hosmer-Lemeshow test, and (iii) determining the rank of the
decomposition via a maximum eigenvalue gap method. To further support our
findings, we conduct simulation studies to assess robustness to decomposition
assumptions and extensive case studies using benchmark datasets from image face
recognition, natural language processing, network analysis, and biomedical
studies. Our theoretical and empirical results indicate that the proposed
decomposition is more flexible, general, and robust, and can thus provide
improved performance when compared to similar methods. To facilitate
applications, an R package with efficient model fitting and family and rank
determination is also provided.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carvalho_L/0/1/0/all/0/1&quot;&gt;Luis Carvalho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.03892">
<title>TND-NAS: Towards Non-differentiable Objectives in Progressive Differentiable NAS Framework. (arXiv:2111.03892v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.03892</link>
<description rdf:parseType="Literal">&lt;p&gt;Differentiable architecture search has gradually become the mainstream
research topic in the field of Neural Architecture Search (NAS) for its high
efficiency compared with the early NAS methods. Recent differentiable NAS also
aims at further improving the search performance and reducing the GPU-memory
consumption. However, these methods are no longer naturally capable of tackling
the non-differentiable objectives, e.g., energy, resource-constrained
efficiency, and other metrics, let alone the multi-objective search demands.
Researches in the multi-objective NAS field target this but requires vast
computational resources cause of the sole optimization of each candidate
architecture. In light of this discrepancy, we propose the TND-NAS, which is
with the merits of the high efficiency in differentiable NAS framework and the
compatibility among non-differentiable metrics in Multi-objective NAS. Under
the differentiable NAS framework, with the continuous relaxation of the search
space, TND-NAS has the architecture parameters been optimized in discrete
space, while resorting to the progressive search space shrinking by
architecture parameters. Our representative experiment takes two objectives
(Parameters, Accuracy) as an example, we achieve a series of high-performance
compact architectures on CIFAR10 (1.09M/3.3%, 2.4M/2.95%, 9.57M/2.54%) and
CIFAR100 (2.46M/18.3%, 5.46/16.73%, 12.88/15.20%) datasets. Favorably, compared
with other multi-objective NAS methods, TND-NAS is less time-consuming (1.3
GPU-days on NVIDIA 1080Ti, 1/6 of that in NSGA-Net), and can be conveniently
adapted to real-world NAS scenarios (resource-constrained,
platform-specialized).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_B/0/1/0/all/0/1&quot;&gt;Bo Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1&quot;&gt;Shiping Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.09982">
<title>Second-Order Mirror Descent: Convergence in Games Beyond Averaging and Discounting. (arXiv:2111.09982v4 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2111.09982</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a second-order extension of the continuous-time
game-theoretic mirror descent (MD) dynamics, referred to as MD2, which provably
converges to mere (but not necessarily strict) variationally stable states
(VSS) without using common auxiliary techniques such as time-averaging or
discounting. We show that MD2 enjoys no-regret as well as an exponential rate
of convergence towards strong VSS upon a slight modification. MD2 can also be
used to derive many novel continuous-time primal-space dynamics. We then use
stochastic approximation techniques to provide a convergence guarantee of
discrete-time MD2 with noisy observations towards interior mere VSS. Selected
simulations are provided to illustrate our results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gao_B/0/1/0/all/0/1&quot;&gt;Bolin Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pavel_L/0/1/0/all/0/1&quot;&gt;Lacra Pavel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.11660">
<title>A Black-box NLP Classifier Attacker. (arXiv:2112.11660v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2112.11660</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have a wide range of applications in solving various
real-world tasks and have achieved satisfactory results, in domains such as
computer vision, image classification, and natural language processing.
Meanwhile, the security and robustness of neural networks have become
imperative, as diverse researches have shown the vulnerable aspects of neural
networks. Case in point, in Natural language processing tasks, the neural
network may be fooled by an attentively modified text, which has a high
similarity to the original one. As per previous research, most of the studies
are focused on the image domain; Different from image adversarial attacks, the
text is represented in a discrete sequence, traditional image attack methods
are not applicable in the NLP field. In this paper, we propose a word-level NLP
sentiment classifier attack model, which includes a self-attention
mechanism-based word selection method and a greedy search algorithm for word
substitution. We experiment with our attack model by attacking GRU and 1D-CNN
victim models on IMDB datasets. Experimental results demonstrate that our model
achieves a higher attack success rate and more efficient than previous methods
due to the efficient word selection algorithms are employed and minimized the
word substitute number. Also, our model is transferable, which can be used in
the image domain with several modifications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yueyang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hunmin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Cai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.14900">
<title>Motif Graph Neural Network. (arXiv:2112.14900v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2112.14900</link>
<description rdf:parseType="Literal">&lt;p&gt;Graphs can model complicated interactions between entities, which naturally
emerge in many important applications. These applications can often be cast
into standard graph learning tasks, in which a crucial step is to learn
low-dimensional graph representations. Graph neural networks (GNNs) are
currently the most popular model in graph embedding approaches. However,
standard GNNs in the neighborhood aggregation paradigm suffer from limited
discriminative power in distinguishing \emph{high-order} graph structures as
opposed to \emph{low-order} structures. To capture high-order structures,
researchers have resorted to motifs and developed motif-based GNNs. However,
existing motif-based GNNs still often suffer from less discriminative power on
high-order structures. To overcome the above limitations, we propose Motif
Graph Neural Network (MGNN), a novel framework to better capture high-order
structures, hinging on our proposed motif redundancy minimization operator and
injective motif combination. First, MGNN produces a set of node representations
w.r.t. each motif. The next phase is our proposed redundancy minimization among
motifs which compares the motifs with each other and distills the features
unique to each motif. Finally, MGNN performs the updating of node
representations by combining multiple representations from different motifs. In
particular, to enhance the discriminative power, MGNN utilizes an injective
function to combine the representations w.r.t. different motifs. We further
show that our proposed architecture increases the expressive power of GNNs with
a theoretical analysis. We demonstrate that MGNN outperforms state-of-the-art
methods on seven public benchmarks on both node classification and graph
classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xuexin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1&quot;&gt;Ruichu Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1&quot;&gt;Yuan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Min Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zijian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Hao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2202.13975">
<title>A Proximal Algorithm for Sampling. (arXiv:2202.13975v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2202.13975</link>
<description rdf:parseType="Literal">&lt;p&gt;We study sampling problems associated with potentials that lack smoothness.
The potentials can be either convex or non-convex. Departing from the standard
smooth setting, the potentials are only assumed to be weakly smooth or
non-smooth, or the summation of multiple such functions. We develop a sampling
algorithm that resembles proximal algorithms in optimization for this
challenging sampling task. Our algorithm is based on a special case of Gibbs
sampling known as the alternating sampling framework (ASF). The key
contribution of this work is a practical realization of the ASF based on
rejection sampling for both non-convex and convex potentials that are not
necessarily smooth. In almost all the cases of sampling considered in this
work, our proximal sampling algorithm achieves better complexity than all
existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jiaming Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yongxin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2203.06527">
<title>Learning Hidden Markov Models When the Locations of Missing Observations are Unknown. (arXiv:2203.06527v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2203.06527</link>
<description rdf:parseType="Literal">&lt;p&gt;The Hidden Markov Model (HMM) is one of the most widely used statistical
models for sequential data analysis. One of the key reasons for this
versatility is the ability of HMM to deal with missing data. However, standard
HMM learning algorithms rely crucially on the assumption that the positions of
the missing observations \emph{within the observation sequence} are known. In
the natural sciences, where this assumption is often violated, special variants
of HMM, commonly known as Silent-state HMMs (SHMMs), are used. Despite their
widespread use, these algorithms strongly rely on specific structural
assumptions of the underlying chain, such as acyclicity, thus limiting the
applicability of these methods. Moreover, even in the acyclic case, it has been
shown that these methods can lead to poor reconstruction. In this paper we
consider the general problem of learning an HMM from data with unknown missing
observation locations. We provide reconstruction algorithms that do not require
any assumptions about the structure of the underlying chain, and can also be
used with limited prior knowledge, unlike SHMM. We evaluate and compare the
algorithms in a variety of scenarios, measuring their reconstruction precision,
and robustness under model miss-specification. Notably, we show that under
proper specifications one can reconstruct the process dynamics as well as if
the missing observations positions were known.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perets_B/0/1/0/all/0/1&quot;&gt;Binyamin Perets&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kozdoba_M/0/1/0/all/0/1&quot;&gt;Mark Kozdoba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2204.02937">
<title>Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations. (arXiv:2204.02937v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2204.02937</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network classifiers can largely rely on simple spurious features, such
as backgrounds, to make predictions. However, even in these cases, we show that
they still often learn core features associated with the desired attributes of
the data, contrary to recent findings. Inspired by this insight, we demonstrate
that simple last layer retraining can match or outperform state-of-the-art
approaches on spurious correlation benchmarks, but with profoundly lower
complexity and computational expenses. Moreover, we show that last layer
retraining on large ImageNet-trained models can also significantly reduce
reliance on background and texture information, improving robustness to
covariate shift, after only minutes of training on a single GPU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirichenko_P/0/1/0/all/0/1&quot;&gt;Polina Kirichenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izmailov_P/0/1/0/all/0/1&quot;&gt;Pavel Izmailov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.01138">
<title>Transformers in Time-series Analysis: A Tutorial. (arXiv:2205.01138v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.01138</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer architecture has widespread applications, particularly in Natural
Language Processing and computer vision. Recently Transformers have been
employed in various aspects of time-series analysis. This tutorial provides an
overview of the Transformer architecture, its applications, and a collection of
examples from recent research papers in time-series analysis. We delve into an
explanation of the core components of the Transformer, including the
self-attention mechanism, positional encoding, multi-head, and encoder/decoder.
Several enhancements to the initial, Transformer architecture are highlighted
to tackle time-series tasks. The tutorial also provides best practices and
techniques to overcome the challenge of effectively training Transformers for
time-series analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1&quot;&gt;Sabeen Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nielsen_I/0/1/0/all/0/1&quot;&gt;Ian E. Nielsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathi_A/0/1/0/all/0/1&quot;&gt;Aakash Tripathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siddiqui_S/0/1/0/all/0/1&quot;&gt;Shamoon Siddiqui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasool_G/0/1/0/all/0/1&quot;&gt;Ghulam Rasool&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramachandran_R/0/1/0/all/0/1&quot;&gt;Ravi P. Ramachandran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.10947">
<title>Deep Direct Discriminative Decoders for High-dimensional Time-series Data Analysis. (arXiv:2205.10947v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.10947</link>
<description rdf:parseType="Literal">&lt;p&gt;The state-space models (SSMs) are widely utilized in the analysis of
time-series data. SSMs rely on an explicit definition of the state and
observation processes. Characterizing these processes is not always easy and
becomes a modeling challenge when the dimension of observed data grows or the
observed data distribution deviates from the normal distribution. Here, we
propose a new formulation of SSM for high-dimensional observation processes. We
call this solution the deep direct discriminative decoder (D4). The D4 brings
deep neural networks&apos; expressiveness and scalability to the SSM formulation
letting us build a novel solution that efficiently estimates the underlying
state processes through high-dimensional observation signal. We demonstrate the
D4 solutions in simulated and real data such as Lorenz attractors, Langevin
dynamics, random walk dynamics, and rat hippocampus spiking neural data and
show that the D4 performs better than traditional SSMs and RNNs. The D4 can be
applied to a broader class of time-series data where the connection between
high-dimensional observation and the underlying latent process is hard to
characterize.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezaei_M/0/1/0/all/0/1&quot;&gt;Mohammad R. Rezaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popovic_M/0/1/0/all/0/1&quot;&gt;Milos R. Popovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lankarany_M/0/1/0/all/0/1&quot;&gt;Milad Lankarany&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yousefi_A/0/1/0/all/0/1&quot;&gt;Ali Yousefi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.00667">
<title>How Biased are Your Features?: Computing Fairness Influence Functions with Global Sensitivity Analysis. (arXiv:2206.00667v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.00667</link>
<description rdf:parseType="Literal">&lt;p&gt;Fairness in machine learning has attained significant focus due to the
widespread application in high-stake decision-making tasks. Unregulated machine
learning classifiers can exhibit bias towards certain demographic groups in
data, thus the quantification and mitigation of classifier bias is a central
concern in fairness in machine learning. In this paper, we aim to quantify the
influence of different features in a dataset on the bias of a classifier. To do
this, we introduce the Fairness Influence Function (FIF). This function breaks
down bias into its components among individual features and the intersection of
multiple features. The key idea is to represent existing group fairness metrics
as the difference of the scaled conditional variances in the classifier&apos;s
prediction and apply a decomposition of variance according to global
sensitivity analysis. To estimate FIFs, we instantiate an algorithm
FairXplainer that applies variance decomposition of classifier&apos;s prediction
following local regression. Experiments demonstrate that FairXplainer captures
FIFs of individual feature and intersectional features, provides a better
approximation of bias based on FIFs, demonstrates higher correlation of FIFs
with fairness interventions, and detects changes in bias due to fairness
affirmative/punitive actions in the classifier.
&lt;/p&gt;
&lt;p&gt;The code is available at https://github.com/ReAILe/bias-explainer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_B/0/1/0/all/0/1&quot;&gt;Bishwamittra Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1&quot;&gt;Debabrota Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meel_K/0/1/0/all/0/1&quot;&gt;Kuldeep S. Meel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.00820">
<title>NIPQ: Noise proxy-based Integrated Pseudo-Quantization. (arXiv:2206.00820v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.00820</link>
<description rdf:parseType="Literal">&lt;p&gt;Straight-through estimator (STE), which enables the gradient flow over the
non-differentiable function via approximation, has been favored in studies
related to quantization-aware training (QAT). However, STE incurs unstable
convergence during QAT, resulting in notable quality degradation in low
precision. Recently, pseudoquantization training has been proposed as an
alternative approach to updating the learnable parameters using the
pseudo-quantization noise instead of STE. In this study, we propose a novel
noise proxy-based integrated pseudoquantization (NIPQ) that enables unified
support of pseudoquantization for both activation and weight by integrating the
idea of truncation on the pseudo-quantization framework. NIPQ updates all of
the quantization parameters (e.g., bit-width and truncation boundary) as well
as the network parameters via gradient descent without STE instability.
According to our extensive experiments, NIPQ outperforms existing quantization
algorithms in various vision and language applications by a large margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Juncheol Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+So_J/0/1/0/all/0/1&quot;&gt;Junhyuk So&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sein Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1&quot;&gt;Seungyeop Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1&quot;&gt;Sungjoo Yoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1&quot;&gt;Eunhyeok Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.03792">
<title>Utilising the CLT Structure in Stochastic Gradient based Sampling : Improved Analysis and Faster Algorithms. (arXiv:2206.03792v5 [math.PR] UPDATED)</title>
<link>http://arxiv.org/abs/2206.03792</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider stochastic approximations of sampling algorithms, such as
Stochastic Gradient Langevin Dynamics (SGLD) and the Random Batch Method (RBM)
for Interacting Particle Dynamcs (IPD). We observe that the noise introduced by
the stochastic approximation is nearly Gaussian due to the Central Limit
Theorem (CLT) while the driving Brownian motion is exactly Gaussian. We harness
this structure to absorb the stochastic approximation error inside the
diffusion process, and obtain improved convergence guarantees for these
algorithms. For SGLD, we prove the first stable convergence rate in KL
divergence without requiring uniform warm start, assuming the target density
satisfies a Log-Sobolev Inequality. Our result implies superior first-order
oracle complexity compared to prior works, under significantly milder
assumptions. We also prove the first guarantees for SGLD under even weaker
conditions such as H\&quot;{o}lder smoothness and Poincare Inequality, thus bridging
the gap between the state-of-the-art guarantees for LMC and SGLD. Our analysis
motivates a new algorithm called covariance correction, which corrects for the
additional noise introduced by the stochastic approximation by rescaling the
strength of the diffusion. Finally, we apply our techniques to analyze RBM, and
significantly improve upon the guarantees in prior works (such as removing
exponential dependence on horizon), under minimal assumptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Aniket Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nagaraj_D/0/1/0/all/0/1&quot;&gt;Dheeraj Nagaraj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Raj_A/0/1/0/all/0/1&quot;&gt;Anant Raj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.03851">
<title>Reconsidering Learning Objectives in Unbiased Recommendation: A Distribution Shift Perspective. (arXiv:2206.03851v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2206.03851</link>
<description rdf:parseType="Literal">&lt;p&gt;This work studies the problem of learning unbiased algorithms from biased
feedback for recommendation. We address this problem from a novel distribution
shift perspective. Recent works in unbiased recommendation have advanced the
state-of-the-art with various techniques such as re-weighting, multi-task
learning, and meta-learning. Despite their empirical successes, most of them
lack theoretical guarantees, forming non-negligible gaps between theories and
recent algorithms. In this paper, we propose a theoretical understanding of why
existing unbiased learning objectives work for unbiased recommendation. We
establish a close connection between unbiased recommendation and distribution
shift, which shows that existing unbiased learning objectives implicitly align
biased training and unbiased test distributions. Built upon this connection, we
develop two generalization bounds for existing unbiased learning methods and
analyze their learning behavior. Besides, as a result of the distribution
shift, we further propose a principled framework, Adversarial Self-Training
(AST), for unbiased recommendation. Extensive experiments on real-world and
semi-synthetic datasets demonstrate the effectiveness of AST.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1&quot;&gt;Teng Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhengyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Suhang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.03922">
<title>A unified stochastic approximation framework for learning in games. (arXiv:2206.03922v2 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/2206.03922</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a flexible stochastic approximation framework for analyzing the
long-run behavior of learning in games (both continuous and finite). The
proposed analysis template incorporates a wide array of popular learning
algorithms, including gradient-based methods, the exponential/multiplicative
weights algorithm for learning in finite games, optimistic and bandit variants
of the above, etc. In addition to providing an integrated view of these
algorithms, our framework further allows us to obtain several new convergence
results, both asymptotic and in finite time, in both continuous and finite
games. Specifically, we provide a range of criteria for identifying classes of
Nash equilibria and sets of action profiles that are attracting with high
probability, and we also introduce the notion of coherence, a game-theoretic
property that includes strict and sharp equilibria, and which leads to
convergence in finite time. Importantly, our analysis applies to both
oracle-based and bandit, payoff-based methods - that is, when players only
observe their realized payoffs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mertikopoulos_P/0/1/0/all/0/1&quot;&gt;Panayotis Mertikopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_Y/0/1/0/all/0/1&quot;&gt;Ya-Ping Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cevher_V/0/1/0/all/0/1&quot;&gt;Volkan Cevher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.10540">
<title>Rethinking Symbolic Regression Datasets and Benchmarks for Scientific Discovery. (arXiv:2206.10540v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.10540</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper revisits datasets and evaluation criteria for Symbolic Regression
(SR), specifically focused on its potential for scientific discovery. Focused
on a set of formulas used in the existing datasets based on Feynman Lectures on
Physics, we recreate 120 datasets to discuss the performance of symbolic
regression for scientific discovery (SRSD). For each of the 120 SRSD datasets,
we carefully review the properties of the formula and its variables to design
reasonably realistic sampling ranges of values so that our new SRSD datasets
can be used for evaluating the potential of SRSD such as whether or not an SR
method can (re)discover physical laws from such datasets. We also create
another 120 datasets that contain dummy variables to examine whether SR methods
can choose necessary variables only. Besides, we propose to use normalized edit
distances (NED) between a predicted equation and the true equation trees for
addressing a critical issue that existing SR metrics are either binary or
errors between the target values and an SR model&apos;s predicted values for a given
input. We conduct experiments on our new SRSD datasets using six SR methods.
The experimental results show that we provide a more realistic performance
evaluation, and our user study shows that the NED correlates with human judges
significantly more than an existing SR metric.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsubara_Y/0/1/0/all/0/1&quot;&gt;Yoshitomo Matsubara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiba_N/0/1/0/all/0/1&quot;&gt;Naoya Chiba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Igarashi_R/0/1/0/all/0/1&quot;&gt;Ryo Igarashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1&quot;&gt;Yoshitaka Ushiku&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.10553">
<title>MABe22: A Multi-Species Multi-Task Benchmark for Learned Representations of Behavior. (arXiv:2207.10553v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2207.10553</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce MABe22, a large-scale, multi-agent video and trajectory
benchmark to assess the quality of learned behavior representations. This
dataset is collected from a variety of biology experiments, and includes
triplets of interacting mice (4.7 million frames video+pose tracking data, 10
million frames pose only), symbiotic beetle-ant interactions (10 million frames
video data), and groups of interacting flies (4.4 million frames of pose
tracking data). Accompanying these data, we introduce a panel of real-life
downstream analysis tasks to assess the quality of learned representations by
evaluating how well they preserve information about the experimental conditions
(e.g. strain, time of day, optogenetic stimulation) and animal behavior. We
test multiple state-of-the-art self-supervised video and trajectory
representation learning methods to demonstrate the use of our benchmark,
revealing that methods developed using human action datasets do not fully
translate to animal datasets. We hope that our benchmark and dataset encourage
a broader exploration of behavior representation learning methods across
species and settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jennifer J. Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marks_M/0/1/0/all/0/1&quot;&gt;Markus Marks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ulmer_A/0/1/0/all/0/1&quot;&gt;Andrew Ulmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1&quot;&gt;Dipam Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geuther_B/0/1/0/all/0/1&quot;&gt;Brian Geuther&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayes_E/0/1/0/all/0/1&quot;&gt;Edward Hayes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1&quot;&gt;Heng Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vivek Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oleszko_S/0/1/0/all/0/1&quot;&gt;Sebastian Oleszko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Partridge_Z/0/1/0/all/0/1&quot;&gt;Zachary Partridge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peelman_M/0/1/0/all/0/1&quot;&gt;Milan Peelman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robie_A/0/1/0/all/0/1&quot;&gt;Alice Robie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schretter_C/0/1/0/all/0/1&quot;&gt;Catherine E. Schretter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheppard_K/0/1/0/all/0/1&quot;&gt;Keith Sheppard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1&quot;&gt;Chao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uttarwar_P/0/1/0/all/0/1&quot;&gt;Param Uttarwar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wagner_J/0/1/0/all/0/1&quot;&gt;Julian M. Wagner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Werner_E/0/1/0/all/0/1&quot;&gt;Eric Werner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parker_J/0/1/0/all/0/1&quot;&gt;Joseph Parker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1&quot;&gt;Pietro Perona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yisong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Branson_K/0/1/0/all/0/1&quot;&gt;Kristin Branson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1&quot;&gt;Ann Kennedy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.00208">
<title>DRSOM: A Dimension Reduced Second-Order Method. (arXiv:2208.00208v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2208.00208</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a Dimension-Reduced Second-Order Method (DRSOM) for
convex and nonconvex (unconstrained) optimization. Under a trust-region-like
framework, our method preserves the convergence of the second-order method
while using only curvature information in a few directions. Consequently, the
computational overhead of our method remains comparable to the first-order such
as the gradient descent method. Theoretically, we show that the method has a
local quadratic convergence and a global convergence rate of
$O(\epsilon^{-3/2})$ to satisfy the first-order and second-order conditions if
the subspace satisfies a commonly adopted approximated Hessian assumption. We
further show that this assumption can be removed if we perform a corrector step
using a Krylov-like method periodically at the end stage of the algorithm. The
applicability and performance of DRSOM are exhibited by various computational
experiments, including $L_2 - L_p$ minimization, CUTEst problems, and sensor
network localization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chuwen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ge_D/0/1/0/all/0/1&quot;&gt;Dongdong Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+He_C/0/1/0/all/0/1&quot;&gt;Chang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jiang_B/0/1/0/all/0/1&quot;&gt;Bo Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yuntian Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yinyu Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.00884">
<title>Infant movement classification through pressure distribution analysis. (arXiv:2208.00884v3 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2208.00884</link>
<description rdf:parseType="Literal">&lt;p&gt;Aiming at objective early detection of neuromotor disorders such as cerebral
palsy, we proposed an innovative non-intrusive approach using a pressure
sensing device to classify infant general movements (GMs). Here, we tested the
feasibility of using pressure data to differentiate typical GM patterns of the
&apos;&apos;fidgety period&apos;&apos; (i.e., fidgety movements) vs. the &apos;&apos;pre-fidgety period&apos;&apos;
(i.e., writhing movements). Participants (N = 45) were sampled from a
typically-developing infant cohort. Multi-modal sensor data, including pressure
data from a 32x32-grid pressure sensing mat with 1024 sensors, were
prospectively recorded for each infant in seven succeeding laboratory sessions
in biweekly intervals from 4-16 weeks of post-term age. For proof-of-concept,
1776 pressure data snippets, each 5s long, from the two targeted age periods
were taken for movement classification. Each snippet was pre-annotated based on
corresponding synchronised video data by human assessors as either fidgety
present (FM+) or absent (FM-). Multiple neural network architectures were
tested to distinguish the FM+ vs. FM- classes, including support vector
machines (SVM), feed-forward networks (FFNs), convolutional neural networks
(CNNs), and long short-term memory (LSTM) networks. The CNN achieved the
highest average classification accuracy (81.4%) for classes FM+ vs. FM-.
Comparing the pros and cons of other methods aiming at automated GMA to the
pressure sensing approach, we concluded that the pressure sensing approach has
great potential for efficient large-scale motion data acquisition and sharing.
This will in return enable improvement of the approach that may prove scalable
for daily clinical application for evaluating infant neuromotor functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kulvicius_T/0/1/0/all/0/1&quot;&gt;Tomas Kulvicius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dajie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nielsen_Saines_K/0/1/0/all/0/1&quot;&gt;Karin Nielsen-Saines&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bolte_S/0/1/0/all/0/1&quot;&gt;Sven B&amp;#xf6;lte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kraft_M/0/1/0/all/0/1&quot;&gt;Marc Kraft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Einspieler_C/0/1/0/all/0/1&quot;&gt;Christa Einspieler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Poustka_L/0/1/0/all/0/1&quot;&gt;Luise Poustka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Worgotter_F/0/1/0/all/0/1&quot;&gt;Florentin W&amp;#xf6;rg&amp;#xf6;tter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Marschik_P/0/1/0/all/0/1&quot;&gt;Peter B Marschik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.06146">
<title>Feature-Based Time-Series Analysis in R using the theft Package. (arXiv:2208.06146v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2208.06146</link>
<description rdf:parseType="Literal">&lt;p&gt;Time series are measured and analyzed across the sciences. One method of
quantifying the structure of time series is by calculating a set of summary
statistics or `features&apos;, and then representing a time series in terms of its
properties as a feature vector. The resulting feature space is interpretable
and informative, and enables conventional statistical learning approaches,
including clustering, regression, and classification, to be applied to
time-series datasets. Many open-source software packages for computing sets of
time-series features exist across multiple programming languages, including
catch22 (22 features: Matlab, R, Python, Julia), feasts (42 features: R),
tsfeatures (63 features: R), Kats (40 features: Python), tsfresh (779 features:
Python), and TSFEL (390 features: Python). However, there are several issues:
(i) a singular access point to these packages is not currently available; (ii)
to access all feature sets, users must be fluent in multiple languages; and
(iii) these feature-extraction packages lack extensive accompanying
methodological pipelines for performing feature-based time-series analysis,
such as applications to time-series classification. Here we introduce a
solution to these issues in an R software package called theft: Tools for
Handling Extraction of Features from Time series. theft is a unified and
extendable framework for computing features from the six open-source
time-series feature sets listed above. It also includes a suite of functions
for processing and interpreting the performance of extracted features,
including extensive data-visualization templates, low-dimensional projections,
and time-series classification operations. With an increasing volume and
complexity of time-series datasets in the sciences and industry, theft provides
a standardized framework for comprehensively quantifying and interpreting
informative structure in time series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Henderson_T/0/1/0/all/0/1&quot;&gt;Trent Henderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fulcher_B/0/1/0/all/0/1&quot;&gt;Ben D. Fulcher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.06648">
<title>Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness. (arXiv:2208.06648v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2208.06648</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning risks reinforcing biases present in data, and, as we argue
in this work, in what is absent from data. In healthcare, biases have marked
medical history, leading to unequal care affecting marginalised groups.
Patterns in missing data often reflect these group discrepancies, but the
algorithmic fairness implications of group-specific missingness are not well
understood. Despite its potential impact, imputation is often an overlooked
preprocessing step, with attention placed on the reduction of reconstruction
error and overall performance, ignoring how imputation can affect groups
differently. Our work studies how imputation choices affect reconstruction
errors across groups and algorithmic fairness properties of downstream
predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeanselme_V/0/1/0/all/0/1&quot;&gt;Vincent Jeanselme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+De_Arteaga_M/0/1/0/all/0/1&quot;&gt;Maria De-Arteaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barrett_J/0/1/0/all/0/1&quot;&gt;Jessica Barrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tom_B/0/1/0/all/0/1&quot;&gt;Brian Tom&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.12227">
<title>Community Detection in the Hypergraph SBM: Optimal Recovery Given the Similarity Matrix. (arXiv:2208.12227v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2208.12227</link>
<description rdf:parseType="Literal">&lt;p&gt;Community detection is a fundamental problem in network science. In this
paper, we consider community detection in hypergraphs drawn from the
$hypergraph$ $stochastic$ $block$ $model$ (HSBM), with a focus on exact
community recovery. We study the performance of polynomial-time algorithms
which operate on the $similarity$ $matrix$ $W$, where $W_{ij}$ reports the
number of hyperedges containing both $i$ and $j$. Under this information model,
Kim, Bandeira, and Goemans determined the information-theoretic threshold for
exact recovery in the logarithmic degree regime, and proposed a semidefinite
programming relaxation which they conjectured to be optimal. In this paper, we
confirm this conjecture. We also design a simple and highly efficient spectral
algorithm with nearly linear runtime and show that it achieves the
information-theoretic threshold. Moreover, the spectral algorithm also succeeds
in denser regimes and is considerably more efficient than previous approaches,
establishing it as the method of choice. Our analysis of the spectral algorithm
crucially relies on strong $entrywise$ bounds on the eigenvectors of $W$. Our
bounds are inspired by the work of Abbe, Fan, Wang, and Zhong, who developed
entrywise bounds for eigenvectors of symmetric matrices with independent
entries. Despite the complex dependency structure in similarity matrices, we
prove similar entrywise guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaudio_J/0/1/0/all/0/1&quot;&gt;Julia Gaudio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1&quot;&gt;Nirmit Joshi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.13713">
<title>Online Bidding Algorithms for Return-on-Spend Constrained Advertisers. (arXiv:2208.13713v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2208.13713</link>
<description rdf:parseType="Literal">&lt;p&gt;Online advertising has recently grown into a highly competitive and complex
multi-billion-dollar industry, with advertisers bidding for ad slots at large
scales and high frequencies. This has resulted in a growing need for efficient
&quot;auto-bidding&quot; algorithms that determine the bids for incoming queries to
maximize advertisers&apos; targets subject to their specified constraints. This work
explores efficient online algorithms for a single value-maximizing advertiser
under an increasingly popular constraint: Return-on-Spend (RoS). We quantify
efficiency in terms of regret relative to the optimal algorithm, which knows
all queries a priori.
&lt;/p&gt;
&lt;p&gt;We contribute a simple online algorithm that achieves near-optimal regret in
expectation while always respecting the specified RoS constraint when the input
sequence of queries are i.i.d. samples from some distribution. We also
integrate our results with the previous work of Balseiro, Lu, and Mirrokni
[BLM20] to achieve near-optimal regret while respecting both RoS and fixed
budget constraints.
&lt;/p&gt;
&lt;p&gt;Our algorithm follows the primal-dual framework and uses online mirror
descent (OMD) for the dual updates. However, we need to use a non-canonical
setup of OMD, and therefore the classic low-regret guarantee of OMD, which is
for the adversarial setting in online learning, no longer holds. Nonetheless,
in our case and more generally where low-regret dynamics are applied in
algorithm design, the gradients encountered by OMD can be far from adversarial
but influenced by our algorithmic choices. We exploit this key insight to show
our OMD setup achieves low regret in the realm of our algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zhe Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Padmanabhan_S/0/1/0/all/0/1&quot;&gt;Swati Padmanabhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Di Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.03475">
<title>Convolutional Neural Network (CNN) to reduce construction loss in JPEG compression caused by Discrete Fourier Transform (DFT). (arXiv:2209.03475v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2209.03475</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent decades, digital image processing has gained enormous popularity.
Consequently, a number of data compression strategies have been put forth, with
the goal of minimizing the amount of information required to represent images.
Among them, JPEG compression is one of the most popular methods that has been
widely applied in multimedia and digital applications. The periodic nature of
DFT makes it impossible to meet the periodic condition of an image&apos;s opposing
edges without producing severe artifacts, which lowers the image&apos;s perceptual
visual quality. On the other hand, deep learning has recently achieved
outstanding results for applications like speech recognition, image reduction,
and natural language processing. Convolutional Neural Networks (CNN) have
received more attention than most other types of deep neural networks. The use
of convolution in feature extraction results in a less redundant feature map
and a smaller dataset, both of which are crucial for image compression. In this
work, an effective image compression method is purposed using autoencoders. The
study&apos;s findings revealed a number of important trends that suggested better
reconstruction along with good compression can be achieved using autoencoders.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kunwar_S/0/1/0/all/0/1&quot;&gt;Suman Kunwar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.13578">
<title>Learning When to Advise Human Decision Makers. (arXiv:2209.13578v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2209.13578</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial intelligence (AI) systems are increasingly used for providing
advice to facilitate human decision making in a wide range of domains, such as
healthcare, criminal justice, and finance. Motivated by limitations of the
current practice where algorithmic advice is provided to human users as a
constant element in the decision-making pipeline, in this paper we raise the
question of when should algorithms provide advice? We propose a novel design of
AI systems in which the algorithm interacts with the human user in a two-sided
manner and aims to provide advice only when it is likely to be beneficial for
the user in making their decision. The results of a large-scale experiment show
that our advising approach manages to provide advice at times of need and to
significantly improve human decision making compared to fixed, non-interactive,
advising approaches. This approach has additional advantages in facilitating
human learning, preserving complementary strengths of human decision makers,
and leading to more positive responsiveness to the advice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Noti_G/0/1/0/all/0/1&quot;&gt;Gali Noti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiling Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.13678">
<title>FAIR-FATE: Fair Federated Learning with Momentum. (arXiv:2209.13678v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.13678</link>
<description rdf:parseType="Literal">&lt;p&gt;While fairness-aware machine learning algorithms have been receiving
increasing attention, the focus has been on centralized machine learning,
leaving decentralized methods underexplored. Federated Learning is a
decentralized form of machine learning where clients train local models with a
server aggregating them to obtain a shared global model. Data heterogeneity
amongst clients is a common characteristic of Federated Learning, which may
induce or exacerbate discrimination of unprivileged groups defined by sensitive
attributes such as race or gender. In this work we propose FAIR-FATE: a novel
FAIR FederATEd Learning algorithm that aims to achieve group fairness while
maintaining high utility via a fairness-aware aggregation method that computes
the global model by taking into account the fairness of the clients. To achieve
that, the global model update is computed by estimating a fair model update
using a Momentum term that helps to overcome the oscillations of non-fair
gradients. To the best of our knowledge, this is the first approach in machine
learning that aims to achieve fairness using a fair Momentum estimate.
Experimental results on real-world datasets demonstrate that FAIR-FATE
outperforms state-of-the-art fair Federated Learning algorithms under different
levels of data heterogeneity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salazar_T/0/1/0/all/0/1&quot;&gt;Teresa Salazar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandes_M/0/1/0/all/0/1&quot;&gt;Miguel Fernandes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Araujo_H/0/1/0/all/0/1&quot;&gt;Helder Araujo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abreu_P/0/1/0/all/0/1&quot;&gt;Pedro Henriques Abreu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.15635">
<title>Vertical Semi-Federated Learning for Efficient Online Advertising. (arXiv:2209.15635v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.15635</link>
<description rdf:parseType="Literal">&lt;p&gt;The traditional vertical federated learning schema suffers from two main
issues: 1) restricted applicable scope to overlapped samples and 2) high system
challenge of real-time federated serving, which limits its application to
advertising systems. To this end, we advocate a new learning setting Semi-VFL
(Vertical Semi-Federated Learning) to tackle these challenge. Semi-VFL is
proposed to achieve a practical industry application fashion for VFL, by
learning a federation-aware local model which performs better than single-party
models and meanwhile maintain the convenience of local-serving. For this
purpose, we propose the carefully designed Joint Privileged Learning framework
(JPL) to i) alleviate the absence of the passive party&apos;s feature and ii) adapt
to the whole sample space. Specifically, we build an inference-efficient
single-party student model applicable to the whole sample space and meanwhile
maintain the advantage of the federated feature extension. New representation
distillation methods are designed to extract cross-party feature correlations
for both the overlapped and non-overlapped data. We conducted extensive
experiments on real-world advertising datasets. The results show that our
method achieves the best performance over baseline methods and validate its
superiority in the Semi-VFL setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenjie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Q/0/1/0/all/0/1&quot;&gt;Qiaolin Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1&quot;&gt;Hao Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_K/0/1/0/all/0/1&quot;&gt;Kouyin Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1&quot;&gt;Shu-Tao Xia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.01910">
<title>Learning Signal Temporal Logic through Neural Network for Interpretable Classification. (arXiv:2210.01910v2 [cs.FL] UPDATED)</title>
<link>http://arxiv.org/abs/2210.01910</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning techniques using neural networks have achieved promising
success for time-series data classification. However, the models that they
produce are challenging to verify and interpret. In this paper, we propose an
explainable neural-symbolic framework for the classification of time-series
behaviors. In particular, we use an expressive formal language, namely Signal
Temporal Logic (STL), to constrain the search of the computation graph for a
neural network. We design a novel time function and sparse softmax function to
improve the soundness and precision of the neural-STL framework. As a result,
we can efficiently learn a compact STL formula for the classification of
time-series data through off-the-shelf gradient-based tools. We demonstrate the
computational efficiency, compactness, and interpretability of the proposed
method through driving scenarios and naval surveillance case studies, compared
with state-of-the-art baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Danyang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1&quot;&gt;Mingyu Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasile_C/0/1/0/all/0/1&quot;&gt;Cristian-Ioan Vasile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tron_R/0/1/0/all/0/1&quot;&gt;Roberto Tron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.02410">
<title>The Vendi Score: A Diversity Evaluation Metric for Machine Learning. (arXiv:2210.02410v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.02410</link>
<description rdf:parseType="Literal">&lt;p&gt;Diversity is an important criterion for many areas of machine learning (ML),
including generative modeling and dataset curation. However, existing metrics
for measuring diversity are often domain-specific and limited in flexibility.
In this paper, we address the diversity evaluation problem by proposing the
Vendi Score, which connects and extends ideas from ecology and quantum
statistical mechanics to ML. The Vendi Score is defined as the exponential of
the Shannon entropy of the eigenvalues of a similarity matrix. This matrix is
induced by a user-defined similarity function applied to the sample to be
evaluated for diversity. In taking a similarity function as input, the Vendi
Score enables its user to specify any desired form of diversity. Importantly,
unlike many existing metrics in ML, the Vendi Score does not require a
reference dataset or distribution over samples or labels, it is therefore
general and applicable to any generative model, decoding algorithm, and dataset
from any domain where similarity can be defined. We showcase the Vendi Score on
molecular generative modeling where we found it addresses shortcomings of the
current diversity metric of choice in that domain. We also applied the Vendi
Score to generative models of images and decoding algorithms of text where we
found it confirms known results about diversity in those domains. Furthermore,
we used the Vendi Score to measure mode collapse, a known shortcoming of
generative adversarial networks (GANs). In particular, the Vendi Score revealed
that even GANs that capture all the modes of a labeled dataset can be less
diverse than the original dataset. Finally, the interpretability of the Vendi
Score allowed us to diagnose several benchmark ML datasets for diversity,
opening the door for diversity-informed data augmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friedman_D/0/1/0/all/0/1&quot;&gt;Dan Friedman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dieng_A/0/1/0/all/0/1&quot;&gt;Adji Bousso Dieng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.04165">
<title>Neural Extended Kalman Filters for Learning and Predicting Dynamics of Structural Systems. (arXiv:2210.04165v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.04165</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate structural response prediction forms a main driver for structural
health monitoring and control applications. This often requires the proposed
model to adequately capture the underlying dynamics of complex structural
systems. In this work, we utilize a learnable Extended Kalman Filter (EKF),
named the Neural Extended Kalman Filter (Neural EKF) throughout this paper, for
learning the latent evolution dynamics of complex physical systems. The Neural
EKF is a generalized version of the conventional EKF, where the modeling of
process dynamics and sensory observations can be parameterized by neural
networks, therefore learned by end-to-end training. The method is implemented
under the variational inference framework with the EKF conducting inference
from sensing measurements. Typically, conventional variational inference models
are parameterized by neural networks independent of the latent dynamics models.
This characteristic makes the inference and reconstruction accuracy weakly
based on the dynamics models and renders the associated training inadequate. In
this work, we show that the structure imposed by the Neural EKF is beneficial
to the learning process. We demonstrate the efficacy of the framework on both
simulated and real-world structural monitoring datasets, with the results
indicating significant predictive capabilities of the proposed scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1&quot;&gt;Zhilu Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacsa_K/0/1/0/all/0/1&quot;&gt;Kiran Bacsa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzi_E/0/1/0/all/0/1&quot;&gt;Eleni Chatzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.05723">
<title>Embeddings as Epistemic States: Limitations on the Use of Pooling Operators for Accumulating Knowledge. (arXiv:2210.05723v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2210.05723</link>
<description rdf:parseType="Literal">&lt;p&gt;Various neural network architectures rely on pooling operators to aggregate
information coming from different sources. It is often implicitly assumed in
such contexts that vectors encode epistemic states, i.e. that vectors capture
the evidence that has been obtained about some properties of interest, and that
pooling these vectors yields a vector that combines this evidence. We study,
for a number of standard pooling operators, under what conditions they are
compatible with this idea, which we call the epistemic pooling principle. While
we find that all the considered pooling operators can satisfy the epistemic
pooling principle, this only holds when embeddings are sufficiently
high-dimensional and, for most pooling operators, when the embeddings satisfy
particular constraints (e.g. having non-negative coordinates). We furthermore
show that these constraints have important implications on how the embeddings
can be used in practice. In particular, we find that when the epistemic pooling
principle is satisfied, in most cases it is impossible to verify the
satisfaction of propositional formulas using linear scoring functions, with two
exceptions: (i) max-pooling with embeddings that are upper-bounded and (ii)
Hadamard pooling with non-negative embeddings. This finding helps to clarify,
among others, why Graph Neural Networks sometimes under-perform in reasoning
tasks. Finally, we also study an extension of the epistemic pooling principle
to weighted epistemic states, which are important in the context of
non-monotonic reasoning, where max-pooling emerges as the most suitable
operator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schockaert_S/0/1/0/all/0/1&quot;&gt;Steven Schockaert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.07661">
<title>CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling. (arXiv:2210.07661v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.07661</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer has achieved remarkable success in language, image, and speech
processing. Recently, various efficient attention architectures have been
proposed to improve transformer&apos;s efficiency while largely preserving its
efficacy, especially in modeling long sequences. A widely-used benchmark to
test these efficient methods&apos; capability on long-range modeling is Long Range
Arena (LRA). However, LRA only focuses on the standard bidirectional (or
noncausal) self attention, and completely ignores cross attentions and
unidirectional (or causal) attentions, which are equally important to
downstream applications. In this paper, we propose Comprehensive Attention
Benchmark (CAB) under a fine-grained attention taxonomy with four
distinguishable attention patterns, namely, noncausal self, causal self,
noncausal cross, and causal cross attentions. CAB collects seven real-world
tasks from different research areas to evaluate efficient attentions under the
four attention patterns. Among these tasks, CAB validates efficient attentions
in eight backbone networks to show their generalization across neural
architectures. We conduct exhaustive experiments to benchmark the performances
of nine widely-used efficient attention architectures designed with different
philosophies on CAB. Extensive experimental results also shed light on the
fundamental problems of efficient attentions, such as efficiency length against
vanilla attention, performance consistency across attention patterns, the
benefit of attention mechanisms, and interpolation/extrapolation on
long-context language modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shuyang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jiangtao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Lin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1&quot;&gt;Lingpeng Kong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.10737">
<title>RSC: Accelerating Graph Neural Networks Training via Randomized Sparse Computations. (arXiv:2210.10737v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.10737</link>
<description rdf:parseType="Literal">&lt;p&gt;The training of graph neural networks (GNNs) is extremely time consuming
because sparse graph-based operations are hard to be accelerated by hardware.
Prior art explores trading off the computational precision to reduce the time
complexity via sampling-based approximation. Based on the idea, previous works
successfully accelerate the dense matrix based operations (e.g., convolution
and linear) with negligible accuracy drop. However, unlike dense matrices,
sparse matrices are stored in the irregular data format such that each
row/column may have different number of non-zero entries. Thus, compared to the
dense counterpart, approximating sparse operations has two unique challenges
(1) we cannot directly control the efficiency of approximated sparse operation
since the computation is only executed on non-zero entries; (2) sub-sampling
sparse matrices is much more inefficient due to the irregular data format. To
address the issues, our key idea is to control the accuracy-efficiency trade
off by optimizing computation resource allocation layer-wisely and
epoch-wisely. Specifically, for the first challenge, we customize the
computation resource to different sparse operations, while limit the total used
resource below a certain budget. For the second challenge, we cache previous
sampled sparse matrices to reduce the epoch-wise sampling overhead. Finally, we
propose a switching mechanisms to improve the generalization of GNNs trained
with approximated operations. To this end, we propose Randomized Sparse
Computation, which for the first time demonstrate the potential of training
GNNs with approximated operations. In practice, rsc can achieve up to
$11.6\times$ speedup for a single sparse operation and a $1.6\times$ end-to-end
wall-clock time speedup with negligible accuracy drop.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zirui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shengyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1&quot;&gt;Kaixiong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1&quot;&gt;Daochen Zha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xiao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.13507">
<title>Causal Explanation for Reinforcement Learning: Quantifying State and Temporal Importance. (arXiv:2210.13507v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2210.13507</link>
<description rdf:parseType="Literal">&lt;p&gt;Explainability plays an increasingly important role in machine learning.
Furthermore, humans view the world through a causal lens and thus prefer causal
explanations over associational ones. Therefore, in this paper, we develop a
causal explanation mechanism that quantifies the causal importance of states on
actions and such importance over time. We also demonstrate the advantages of
our mechanism over state-of-the-art associational methods in terms of RL policy
explanation through a series of simulation studies, including crop irrigation,
Blackjack, collision avoidance, and lunar lander.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaoxiao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1&quot;&gt;Fanyu Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_Z/0/1/0/all/0/1&quot;&gt;Zhaodan Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.16424">
<title>Machine Unlearning of Federated Clusters. (arXiv:2210.16424v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.16424</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated clustering (FC) is an unsupervised learning problem that arises in
a number of practical applications, including personalized recommender and
healthcare systems. With the adoption of recent laws ensuring the &quot;right to be
forgotten&quot;, the problem of machine unlearning for FC methods has become of
significant importance. We introduce, for the first time, the problem of
machine unlearning for FC, and propose an efficient unlearning mechanism for a
customized secure FC framework. Our FC framework utilizes special
initialization procedures that we show are well-suited for unlearning. To
protect client data privacy, we develop the secure compressed multiset
aggregation (SCMA) framework that addresses sparse secure federated learning
(FL) problems encountered during clustering as well as more general problems.
To simultaneously facilitate low communication complexity and secret sharing
protocols, we integrate Reed-Solomon encoding with special evaluation points
into our SCMA pipeline, and prove that the client communication cost is
logarithmic in the vector dimension. Additionally, to demonstrate the benefits
of our unlearning mechanism over complete retraining, we provide a theoretical
analysis for the unlearning performance of our approach. Simulation results
show that the new FC framework exhibits superior clustering performance
compared to previously reported FC baselines when the cluster sizes are highly
imbalanced. Compared to completely retraining K-means++ locally and globally
for each removal request, our unlearning procedure offers an average speed-up
of roughly 84x across seven datasets. Our implementation for the proposed
method is available at https://github.com/thupchnsky/mufc.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1&quot;&gt;Chao Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sima_J/0/1/0/all/0/1&quot;&gt;Jin Sima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prakash_S/0/1/0/all/0/1&quot;&gt;Saurav Prakash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rana_V/0/1/0/all/0/1&quot;&gt;Vishal Rana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1&quot;&gt;Olgica Milenkovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.17283">
<title>CausalBench: A Large-scale Benchmark for Network Inference from Single-cell Perturbation Data. (arXiv:2210.17283v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.17283</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference is a vital aspect of multiple scientific disciplines and is
routinely applied to high-impact applications such as medicine. However,
evaluating the performance of causal inference methods in real-world
environments is challenging due to the need for observations under both
interventional and control conditions. Traditional evaluations conducted on
synthetic datasets do not reflect the performance in real-world systems. To
address this, we introduce CausalBench, a benchmark suite for evaluating
network inference methods on real-world interventional data from large-scale
single-cell perturbation experiments. CausalBench incorporates
biologically-motivated performance metrics, including new distribution-based
interventional metrics. A systematic evaluation of state-of-the-art causal
inference methods using our CausalBench suite highlights how poor scalability
of current methods limits performance. Moreover, methods that use
interventional information do not outperform those that only use observational
data, contrary to what is observed on synthetic benchmarks. Thus, CausalBench
opens new avenues in causal network inference research and provides a
principled and reliable way to track progress in leveraging real-world
interventional data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chevalley_M/0/1/0/all/0/1&quot;&gt;Mathieu Chevalley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roohani_Y/0/1/0/all/0/1&quot;&gt;Yusuf Roohani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehrjou_A/0/1/0/all/0/1&quot;&gt;Arash Mehrjou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwab_P/0/1/0/all/0/1&quot;&gt;Patrick Schwab&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.01738">
<title>Analysis of a Deep Learning Model for 12-Lead ECG Classification Reveals Learned Features Similar to Diagnostic Criteria. (arXiv:2211.01738v2 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2211.01738</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their remarkable performance, deep neural networks remain unadopted
in clinical practice, which is considered to be partially due to their lack in
explainability. In this work, we apply attribution methods to a pre-trained
deep neural network (DNN) for 12-lead electrocardiography classification to
open this &quot;black box&quot; and understand the relationship between model prediction
and learned features. We classify data from a public data set and the
attribution methods assign a &quot;relevance score&quot; to each sample of the classified
signals. This allows analyzing what the network learned during training, for
which we propose quantitative methods: average relevance scores over a)
classes, b) leads, and c) average beats. The analyses of relevance scores for
atrial fibrillation (AF) and left bundle branch block (LBBB) compared to
healthy controls show that their mean values a) increase with higher
classification probability and correspond to false classifications when around
zero, and b) correspond to clinical recommendations regarding which lead to
consider. Furthermore, c) visible P-waves and concordant T-waves result in
clearly negative relevance scores in AF and LBBB classification, respectively.
In summary, our analysis suggests that the DNN learned features similar to
cardiology textbook knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bender_T/0/1/0/all/0/1&quot;&gt;Theresa Bender&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Beinecke_J/0/1/0/all/0/1&quot;&gt;Jacqueline Michelle Beinecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Krefting_D/0/1/0/all/0/1&quot;&gt;Dagmar Krefting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Muller_C/0/1/0/all/0/1&quot;&gt;Carolin M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dathe_H/0/1/0/all/0/1&quot;&gt;Henning Dathe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Seidler_T/0/1/0/all/0/1&quot;&gt;Tim Seidler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Spicher_N/0/1/0/all/0/1&quot;&gt;Nicolai Spicher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hauschild_A/0/1/0/all/0/1&quot;&gt;Anne-Christin Hauschild&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.03216">
<title>Unlearning Graph Classifiers with Limited Data Resources. (arXiv:2211.03216v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.03216</link>
<description rdf:parseType="Literal">&lt;p&gt;As the demand for user privacy grows, controlled data removal (machine
unlearning) is becoming an important feature of machine learning models for
data-sensitive Web applications such as social networks and recommender
systems. Nevertheless, at this point it is still largely unknown how to perform
efficient machine unlearning of graph neural networks (GNNs); this is
especially the case when the number of training samples is small, in which case
unlearning can seriously compromise the performance of the model. To address
this issue, we initiate the study of unlearning the Graph Scattering Transform
(GST), a mathematical framework that is efficient, provably stable under
feature or graph topology perturbations, and offers graph classification
performance comparable to that of GNNs. Our main contribution is the first
known nonlinear approximate graph unlearning method based on GSTs. Our second
contribution is a theoretical analysis of the computational complexity of the
proposed unlearning mechanism, which is hard to replicate for deep neural
networks. Our third contribution are extensive simulation results which show
that, compared to complete retraining of GNNs after each removal request, the
new GST-based approach offers, on average, a 10.38x speed-up and leads to a
2.6% increase in test accuracy during unlearning of 90 out of 100 training
graphs from the IMDB dataset (10% training ratio). Our implementation is
available online at https://doi.org/10.5281/zenodo.7613150.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1&quot;&gt;Chao Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1&quot;&gt;Eli Chien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1&quot;&gt;Olgica Milenkovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.03803">
<title>Quantum-probabilistic Hamiltonian learning for generative modelling &amp; anomaly detection. (arXiv:2211.03803v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2211.03803</link>
<description rdf:parseType="Literal">&lt;p&gt;The Hamiltonian of an isolated quantum mechanical system determines its
dynamics and physical behaviour. This study investigates the possibility of
learning and utilising a system&apos;s Hamiltonian and its variational thermal state
estimation for data analysis techniques. For this purpose, we employ the method
of Quantum Hamiltonian-Based Models for the generative modelling of simulated
Large Hadron Collider data and demonstrate the representability of such data as
a mixed state. In a further step, we use the learned Hamiltonian for anomaly
detection, showing that different sample types can form distinct dynamical
behaviours once treated as a quantum many-body system. We exploit these
characteristics to quantify the difference between sample types. Our findings
show that the methodologies designed for field theory computations can be
utilised in machine learning applications to employ theoretical approaches in
data analysis techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Araz_J/0/1/0/all/0/1&quot;&gt;Jack Y. Araz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Spannowsky_M/0/1/0/all/0/1&quot;&gt;Michael Spannowsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.05039">
<title>Active Acquisition for Multimodal Temporal Data: A Challenging Decision-Making Task. (arXiv:2211.05039v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.05039</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a challenging decision-making task that we call active
acquisition for multimodal temporal data (A2MT). In many real-world scenarios,
input features are not readily available at test time and must instead be
acquired at significant cost. With A2MT, we aim to learn agents that actively
select which modalities of an input to acquire, trading off acquisition cost
and predictive performance. A2MT extends a previous task called active feature
acquisition to temporal decision making about high-dimensional inputs. We
propose a method based on the Perceiver IO architecture to address A2MT in
practice. Our agents are able to solve a novel synthetic scenario requiring
practically relevant cross-modal reasoning skills. On two large-scale,
real-world datasets, Kinetics-700 and AudioSet, our agents successfully learn
cost-reactive acquisition behavior. However, an ablation reveals they are
unable to learn adaptive acquisition strategies, emphasizing the difficulty of
the task even for state-of-the-art models. Applications of A2MT may be
impactful in domains like medicine, robotics, or finance, where modalities
differ in acquisition cost and informativeness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kossen_J/0/1/0/all/0/1&quot;&gt;Jannik Kossen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cangea_C/0/1/0/all/0/1&quot;&gt;C&amp;#x103;t&amp;#x103;lina Cangea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vertes_E/0/1/0/all/0/1&quot;&gt;Eszter V&amp;#xe9;rtes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaegle_A/0/1/0/all/0/1&quot;&gt;Andrew Jaegle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patraucean_V/0/1/0/all/0/1&quot;&gt;Viorica Patraucean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ktena_I/0/1/0/all/0/1&quot;&gt;Ira Ktena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomasev_N/0/1/0/all/0/1&quot;&gt;Nenad Tomasev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belgrave_D/0/1/0/all/0/1&quot;&gt;Danielle Belgrave&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.11736">
<title>Robotic Skill Acquisition via Instruction Augmentation with Vision-Language Models. (arXiv:2211.11736v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2211.11736</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, much progress has been made in learning robotic manipulation
policies that follow natural language instructions. Such methods typically
learn from corpora of robot-language data that was either collected with
specific tasks in mind or expensively re-labelled by humans with rich language
descriptions in hindsight. Recently, large-scale pretrained vision-language
models (VLMs) like CLIP or ViLD have been applied to robotics for learning
representations and scene descriptors. Can these pretrained models serve as
automatic labelers for robot data, effectively importing Internet-scale
knowledge into existing datasets to make them useful even for tasks that are
not reflected in their ground truth annotations? To accomplish this, we
introduce Data-driven Instruction Augmentation for Language-conditioned control
(DIAL): we utilize semi-supervised language labels leveraging the semantic
understanding of CLIP to propagate knowledge onto large datasets of unlabelled
demonstration data and then train language-conditioned policies on the
augmented datasets. This method enables cheaper acquisition of useful language
descriptions compared to expensive human labels, allowing for more efficient
label coverage of large-scale datasets. We apply DIAL to a challenging
real-world robotic manipulation domain where 96.5% of the 80,000 demonstrations
do not contain crowd-sourced language annotations. DIAL enables imitation
learning policies to acquire new capabilities and generalize to 60 novel
instructions unseen in the original dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1&quot;&gt;Ted Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1&quot;&gt;Harris Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sermanet_P/0/1/0/all/0/1&quot;&gt;Pierre Sermanet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wahid_A/0/1/0/all/0/1&quot;&gt;Ayzaan Wahid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brohan_A/0/1/0/all/0/1&quot;&gt;Anthony Brohan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1&quot;&gt;Karol Hausman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tompson_J/0/1/0/all/0/1&quot;&gt;Jonathan Tompson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.12044">
<title>Backdoor Cleansing with Unlabeled Data. (arXiv:2211.12044v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.12044</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the increasing computational demand of Deep Neural Networks (DNNs),
companies and organizations have begun to outsource the training process.
However, the externally trained DNNs can potentially be backdoor attacked. It
is crucial to defend against such attacks, i.e., to postprocess a suspicious
model so that its backdoor behavior is mitigated while its normal prediction
power on clean inputs remain uncompromised. To remove the abnormal backdoor
behavior, existing methods mostly rely on additional labeled clean samples.
However, such requirement may be unrealistic as the training data are often
unavailable to end users. In this paper, we investigate the possibility of
circumventing such barrier. We propose a novel defense method that does not
require training labels. Through a carefully designed layer-wise weight
re-initialization and knowledge distillation, our method can effectively
cleanse backdoor behaviors of a suspicious network with negligible compromise
in its normal behavior. In experiments, we show that our method, trained
without labels, is on-par with state-of-the-art defense methods trained using
labels. We also observe promising defense results even on out-of-distribution
data. This makes our method very practical. Code is available at:
https://github.com/luluppang/BCU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1&quot;&gt;Lu Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1&quot;&gt;Haibin Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chao Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.13289">
<title>Shapley Curves: A Smoothing Perspective. (arXiv:2211.13289v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2211.13289</link>
<description rdf:parseType="Literal">&lt;p&gt;Originating from cooperative game theory, Shapley values have become one of
the most widely used measures for variable importance in applied Machine
Learning. However, the statistical understanding of Shapley values is still
limited. In this paper, we take a nonparametric (or smoothing) perspective by
introducing Shapley curves as a local measure of variable importance. We
propose two estimation strategies and derive the consistency and asymptotic
normality both under independence and dependence among the features. This
allows us to construct confidence intervals and conduct inference on the
estimated Shapley curves. We propose a novel version of the wild bootstrap
procedure, specifically adjusted to give good finite sample coverage of the
Shapley curves. The asymptotic results are validated in extensive experiments.
In an empirical application, we analyze which attributes drive the prices of
vehicles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miftachov_R/0/1/0/all/0/1&quot;&gt;Ratmir Miftachov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Keilbar_G/0/1/0/all/0/1&quot;&gt;Georg Keilbar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hardle_W/0/1/0/all/0/1&quot;&gt;Wolfgang Karl H&amp;#xe4;rdle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.15875">
<title>Data Poisoning Attack Aiming the Vulnerability of Continual Learning. (arXiv:2211.15875v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.15875</link>
<description rdf:parseType="Literal">&lt;p&gt;Generally, regularization-based continual learning models limit access to the
previous task data to imitate the real-world constraints related to memory and
privacy. However, this introduces a problem in these models by not being able
to track the performance on each task. In essence, current continual learning
methods are susceptible to attacks on previous tasks. We demonstrate the
vulnerability of regularization-based continual learning methods by presenting
a simple task-specific data poisoning attack that can be used in the learning
process of a new task. Training data generated by the proposed attack causes
performance degradation on a specific task targeted by the attacker. We
experiment with the attack on the two representative regularization-based
continual learning methods, Elastic Weight Consolidation (EWC) and Synaptic
Intelligence (SI), trained with variants of MNIST dataset. The experiment
results justify the vulnerability proposed in this paper and demonstrate the
importance of developing continual learning models that are robust to
adversarial attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_G/0/1/0/all/0/1&quot;&gt;Gyojin Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jaehyun Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1&quot;&gt;Hyeong Gwon Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junmo Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.10478">
<title>Machine Learning and Polymer Self-Consistent Field Theory in Two Spatial Dimensions. (arXiv:2212.10478v2 [cond-mat.mtrl-sci] UPDATED)</title>
<link>http://arxiv.org/abs/2212.10478</link>
<description rdf:parseType="Literal">&lt;p&gt;A computational framework that leverages data from self-consistent field
theory simulations with deep learning to accelerate the exploration of
parameter space for block copolymers is presented. This is a substantial
two-dimensional extension of the framework introduced in [1]. Several
innovations and improvements are proposed. (1) A Sobolev space-trained,
convolutional neural network (CNN) is employed to handle the exponential
dimension increase of the discretized, local average monomer density fields and
to strongly enforce both spatial translation and rotation invariance of the
predicted, field-theoretic intensive Hamiltonian. (2) A generative adversarial
network (GAN) is introduced to efficiently and accurately predict saddle point,
local average monomer density fields without resorting to gradient descent
methods that employ the training set. This GAN approach yields important
savings of both memory and computational cost. (3) The proposed machine
learning framework is successfully applied to 2D cell size optimization as a
clear illustration of its broad potential to accelerate the exploration of
parameter space for discovering polymer nanostructures. Extensions to
three-dimensional phase discovery appear to be feasible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Xuan_Y/0/1/0/all/0/1&quot;&gt;Yao Xuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Delaney_K/0/1/0/all/0/1&quot;&gt;Kris T. Delaney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Ceniceros_H/0/1/0/all/0/1&quot;&gt;Hector D. Ceniceros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Fredrickson_G/0/1/0/all/0/1&quot;&gt;Glenn H. Fredrickson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.10511">
<title>When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories. (arXiv:2212.10511v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2212.10511</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their impressive performance on diverse tasks, large language models
(LMs) still struggle with tasks requiring rich world knowledge, implying the
limitations of relying solely on their parameters to encode a wealth of world
knowledge. This paper aims to understand LMs&apos; strengths and limitations in
memorizing factual knowledge, by conducting large-scale knowledge probing
experiments of 10 models and 4 augmentation methods on PopQA, our new
open-domain QA dataset with 14k questions. We find that LMs struggle with less
popular factual knowledge, and that scaling fails to appreciably improve
memorization of factual knowledge in the long tail. We then show that
retrieval-augmented LMs largely outperform orders of magnitude larger LMs,
while unassisted LMs remain competitive in questions about high-popularity
entities. Based on those findings, we devise a simple, yet effective, method
for powerful and efficient retrieval-augmented LMs, which retrieves
non-parametric memories only when necessary. Experimental results show that
this significantly improves models&apos; performance while reducing the inference
costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mallen_A/0/1/0/all/0/1&quot;&gt;Alex Mallen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1&quot;&gt;Akari Asai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1&quot;&gt;Victor Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1&quot;&gt;Rajarshi Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1&quot;&gt;Daniel Khashabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1&quot;&gt;Hannaneh Hajishirzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.13679">
<title>CC-FedAvg: Computationally Customized Federated Averaging. (arXiv:2212.13679v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.13679</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is an emerging paradigm to train model with
distributed data from numerous Internet of Things (IoT) devices. It inherently
assumes a uniform capacity among participants. However, due to different
conditions such as differing energy budgets or executing parallel unrelated
tasks, participants have diverse computational resources in practice.
Participants with insufficient computation budgets must plan for the use of
restricted computational resources appropriately, otherwise they would be
unable to complete the entire training procedure, resulting in model
performance decline. To address this issue, we propose a strategy for
estimating local models without computationally intensive iterations. Based on
it, we propose Computationally Customized Federated Averaging (CC-FedAvg),
which allows participants to determine whether to perform traditional local
training or model estimation in each round based on their current computational
budgets. Both theoretical analysis and exhaustive experiments indicate that
CC-FedAvg has the same convergence rate and comparable performance as FedAvg
without resource constraints. Furthermore, CC-FedAvg can be viewed as a
computation-efficient version of FedAvg that retains model performance while
considerably lowering computation overhead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tingting Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Siyao Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jie Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.03147">
<title>Finding Lookalike Customers for E-Commerce Marketing. (arXiv:2301.03147v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.03147</link>
<description rdf:parseType="Literal">&lt;p&gt;Customer-centric marketing campaigns generate a large portion of e-commerce
website traffic for Walmart. As the scale of customer data grows larger,
expanding the marketing audience to reach more customers is becoming more
critical for e-commerce companies to drive business growth and bring more value
to customers. In this paper, we present a scalable and efficient system to
expand targeted audience of marketing campaigns, which can handle hundreds of
millions of customers. We use a deep learning based embedding model to
represent customers and an approximate nearest neighbor search method to
quickly find lookalike customers of interest. The model can deal with various
business interests by constructing interpretable and meaningful customer
similarity metrics. We conduct extensive experiments to demonstrate the great
performance of our system and customer embedding model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1&quot;&gt;Yang Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Changzheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1&quot;&gt;Wei Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.10813">
<title>Increasing Fairness via Combination with Learning Guarantees. (arXiv:2301.10813v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.10813</link>
<description rdf:parseType="Literal">&lt;p&gt;The concern about underlying discrimination hidden in ML models is
increasing, as ML systems have been widely applied in more and more real-world
scenarios and any discrimination hidden in them will directly affect human
life. Many techniques have been developed to enhance fairness including
commonly-used group fairness measures and several fairness-aware methods
combining ensemble learning. However, existing fairness measures can only focus
on one aspect -- either group or individual fairness, and the hard
compatibility among them indicates a possibility of remaining biases even if
one of them is satisfied. Moreover, existing mechanisms to boost fairness
usually present empirical results to show validity, yet few of them discuss
whether fairness can be boosted with certain theoretical guarantees. To address
these issues, we propose a fairness quality measure named discriminative risk
in this paper to reflect both individual and group fairness aspects.
Furthermore, we investigate the properties of the proposed measure and propose
first- and second-order oracle bounds to show that fairness can be boosted via
ensemble combination with theoretical learning guarantees. Note that the
analysis is suitable for both binary and multi-class classification. A pruning
method is also proposed to utilise our proposed measure and comprehensive
experiments are conducted to evaluate the effectiveness of the proposed methods
in this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_Y/0/1/0/all/0/1&quot;&gt;Yijun Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_A/0/1/0/all/0/1&quot;&gt;Anqi Qiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.10908">
<title>Distilling Cognitive Backdoor Patterns within an Image: A SOTA Method for Backdoor Sample Detection. (arXiv:2301.10908v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.10908</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a simple method to distill and detect backdoor patterns
within an image: \emph{Cognitive Distillation} (CD). The idea is to extract the
&quot;minimal essence&quot; from an input image responsible for the model&apos;s prediction.
CD optimizes an input mask to extract a small pattern from the input image that
can lead to the same model output (i.e., logits or deep features). The
extracted pattern can help understand the cognitive mechanism of a model on
clean vs. backdoor images and is thus called a \emph{Cognitive Pattern} (CP).
Using CD and the distilled CPs, we uncover an interesting phenomenon of
backdoor attacks: despite the various forms and sizes of trigger patterns used
by different attacks, the CPs of backdoor samples are all surprisingly and
suspiciously small. One thus can leverage the learned mask to detect and remove
backdoor examples from poisoned training datasets. We conduct extensive
experiments to show that CD can robustly detect a wide range of advanced
backdoor attacks. We also show that CD can potentially be applied to help
detect potential biases from face datasets. Code is available at
\url{https://github.com/HanxunH/CognitiveDistillation}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Hanxun Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xingjun Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erfani_S/0/1/0/all/0/1&quot;&gt;Sarah Erfani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bailey_J/0/1/0/all/0/1&quot;&gt;James Bailey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.12579">
<title>Sample Efficient Deep Reinforcement Learning via Local Planning. (arXiv:2301.12579v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.12579</link>
<description rdf:parseType="Literal">&lt;p&gt;The focus of this work is sample-efficient deep reinforcement learning (RL)
with a simulator. One useful property of simulators is that it is typically
easy to reset the environment to a previously observed state. We propose an
algorithmic framework, named uncertainty-first local planning (UFLP), that
takes advantage of this property. Concretely, in each data collection
iteration, with some probability, our meta-algorithm resets the environment to
an observed state which has high uncertainty, instead of sampling according to
the initial-state distribution. The agent-environment interaction then proceeds
as in the standard online RL setting. We demonstrate that this simple procedure
can dramatically improve the sample cost of several baseline RL algorithms on
difficult exploration tasks. Notably, with our framework, we can achieve
super-human performance on the notoriously hard Atari game, Montezuma&apos;s
Revenge, with a simple (distributional) double DQN. Our work can be seen as an
efficient approximate implementation of an existing algorithm with theoretical
guarantees, which offers an interpretation of the positive empirical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1&quot;&gt;Dong Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiagarajan_S/0/1/0/all/0/1&quot;&gt;Sridhar Thiagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazic_N/0/1/0/all/0/1&quot;&gt;Nevena Lazic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajaraman_N/0/1/0/all/0/1&quot;&gt;Nived Rajaraman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_B/0/1/0/all/0/1&quot;&gt;Botao Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1&quot;&gt;Csaba Szepesvari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.01470">
<title>Learning to Optimize for Reinforcement Learning. (arXiv:2302.01470v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.01470</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, by leveraging more data, computation, and diverse tasks,
learned optimizers have achieved remarkable success in supervised learning,
outperforming classical hand-designed optimizers. Reinforcement learning (RL)
is essentially different from supervised learning and in practice these learned
optimizers do not work well even in simple RL tasks. We investigate this
phenomenon and identity three issues. First, the gradients of an RL agent vary
across a wide range in logarithms while their absolute values are in a small
range, making neural networks hard to obtain accurate parameter updates.
Second, the agent-gradient distribution is non-independent and identically
distributed, leading to inefficient meta-training. Finally, due to highly
stochastic agent-environment interactions, the agent-gradients have high bias
and variance, which increase the difficulty of learning an optimizer for RL. We
propose gradient processing, pipeline training, and a novel optimizer structure
with good inductive bias to address these issues. By applying these techniques,
for the first time, we show that learning an optimizer for RL from scratch is
possible. Although only trained in toy tasks, our learned optimizer can
generalize to unseen complex tasks in Brax.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_Q/0/1/0/all/0/1&quot;&gt;Qingfeng Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1&quot;&gt;A. Rupam Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1&quot;&gt;Shuicheng Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhongwen Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.02119">
<title>Diversity Induced Environment Design via Self-Play. (arXiv:2302.02119v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2302.02119</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work on designing an appropriate distribution of environments has
shown promise for training effective generally capable agents. Its success is
partly because of a form of adaptive curriculum learning that generates
environment instances (or levels) at the frontier of the agent&apos;s capabilities.
However, such an environment design framework often struggles to find effective
levels in challenging design spaces and requires costly interactions with the
environment. In this paper, we aim to introduce diversity in the Unsupervised
Environment Design (UED) framework. Specifically, we propose a task-agnostic
method to identify observed/hidden states that are representative of a given
level. The outcome of this method is then utilized to characterize the
diversity between two levels, which as we show can be crucial to effective
performance. In addition, to improve sampling efficiency, we incorporate the
self-play technique that allows the environment generator to automatically
generate environments that are of great benefit to the training agent.
Quantitatively, our approach, Diversity-induced Environment Design via
Self-Play (DivSP), shows compelling performance over existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Dexun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenjun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varakantham_P/0/1/0/all/0/1&quot;&gt;Pradeep Varakantham&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.02399">
<title>Enhancing Exploration in Latent Space Bayesian Optimization. (arXiv:2302.02399v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.02399</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent Space Bayesian Optimization (LSBO) combines generative models,
typically Variational Autoencoders (VAE), with Bayesian Optimization (BO) to
generate de novo objects of interest. However, LSBO faces challenges due to the
mismatch between the objectives of BO and VAE, resulting in poor extrapolation
capabilities. In this paper, we propose novel contributions to enhance LSBO
efficiency and overcome this challenge. We first introduce the concept of
latent consistency/inconsistency as a crucial problem in LSBO, arising from the
BO-VAE mismatch. To address this, we propose the Latent Consistent
Aware-Acquisition Function (LCA-AF) that leverages consistent regions in LSBO.
Additionally, we present LCA-VAE, a novel VAE method that generates a latent
space with increased consistent points, improving BO&apos;s extrapolation
capabilities. Combining LCA-VAE and LCA-AF, we develop LCA-LSBO. Experimental
evaluations validate the improved performance of LCA-LSBO in image generation
and de-novo chemical design tasks, showcasing its enhanced extrapolation
capabilities in LSBO. Our approach achieves high sample-efficiency and
effective exploration, emphasizing the significance of addressing latent
consistency and leveraging LCA-VAE in LSBO.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boyar_O/0/1/0/all/0/1&quot;&gt;Onur Boyar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takeuchi_I/0/1/0/all/0/1&quot;&gt;Ichiro Takeuchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.03122">
<title>State-wise Safe Reinforcement Learning: A Survey. (arXiv:2302.03122v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.03122</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the tremendous success of Reinforcement Learning (RL) algorithms in
simulation environments, applying RL to real-world applications still faces
many challenges. A major concern is safety, in another word, constraint
satisfaction. State-wise constraints are one of the most common constraints in
real-world applications and one of the most challenging constraints in Safe RL.
Enforcing state-wise constraints is necessary and essential to many challenging
tasks such as autonomous driving, robot manipulation. This paper provides a
comprehensive review of existing approaches that address state-wise constraints
in RL. Under the framework of State-wise Constrained Markov Decision Process
(SCMDP), we will discuss the connections, differences, and trade-offs of
existing approaches in terms of (i) safety guarantee and scalability, (ii)
safety and reward performance, and (iii) safety after convergence and during
training. We also summarize limitations of current methods and discuss
potential future directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Weiye Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1&quot;&gt;Tairan He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Rui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1&quot;&gt;Tianhao Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Changliu Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.05686">
<title>A High-dimensional Convergence Theorem for U-statistics with Applications to Kernel-based Testing. (arXiv:2302.05686v3 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/2302.05686</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove a convergence theorem for U-statistics of degree two, where the data
dimension $d$ is allowed to scale with sample size $n$. We find that the
limiting distribution of a U-statistic undergoes a phase transition from the
non-degenerate Gaussian limit to the degenerate limit, regardless of its
degeneracy and depending only on a moment ratio. A surprising consequence is
that a non-degenerate U-statistic in high dimensions can have a non-Gaussian
limit with a larger variance and asymmetric distribution. Our bounds are valid
for any finite $n$ and $d$, independent of individual eigenvalues of the
underlying function, and dimension-independent under a mild assumption. As an
application, we apply our theory to two popular kernel-based distribution
tests, MMD and KSD, whose high-dimensional performance has been challenging to
study. In a simple empirical setting, our results correctly predict how the
test power at a fixed threshold scales with $d$ and the bandwidth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kevin H. Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Duncan_A/0/1/0/all/0/1&quot;&gt;Andrew B. Duncan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gandy_A/0/1/0/all/0/1&quot;&gt;Axel Gandy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.06279">
<title>Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data. (arXiv:2302.06279v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2302.06279</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have demonstrated remarkable performance across
various tasks, including image and speech recognition. However, maximizing the
effectiveness of DNNs requires meticulous optimization of numerous
hyperparameters and network parameters through training. Moreover,
high-performance DNNs entail many parameters, which consume significant energy
during training. In order to overcome these challenges, researchers have turned
to spiking neural networks (SNNs), which offer enhanced energy efficiency and
biologically plausible data processing capabilities, rendering them highly
suitable for sensory data tasks, particularly in neuromorphic data. Despite
their advantages, SNNs, like DNNs, are susceptible to various threats,
including adversarial examples and backdoor attacks. Yet, the field of SNNs
still needs to be explored in terms of understanding and countering these
attacks.
&lt;/p&gt;
&lt;p&gt;This paper delves into backdoor attacks in SNNs using neuromorphic datasets
and diverse triggers. Specifically, we explore backdoor triggers within
neuromorphic data that can manipulate their position and color, providing a
broader scope of possibilities than conventional triggers in domains like
images. We present various attack strategies, achieving an attack success rate
of up to 100\% while maintaining a negligible impact on clean accuracy.
Furthermore, we assess these attacks&apos; stealthiness, revealing that our most
potent attacks possess significant stealth capabilities. Lastly, we adapt
several state-of-the-art defenses from the image domain, evaluating their
efficacy on neuromorphic data and uncovering instances where they fall short,
leading to compromised performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abad_G/0/1/0/all/0/1&quot;&gt;Gorka Abad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ersoy_O/0/1/0/all/0/1&quot;&gt;Oguzhan Ersoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Picek_S/0/1/0/all/0/1&quot;&gt;Stjepan Picek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urbieta_A/0/1/0/all/0/1&quot;&gt;Aitor Urbieta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.06354">
<title>Less is More: Selective Layer Finetuning with SubTuning. (arXiv:2302.06354v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.06354</link>
<description rdf:parseType="Literal">&lt;p&gt;Finetuning a pretrained model has become a standard approach for training
neural networks on novel tasks, resulting in fast convergence and improved
performance. In this work, we study an alternative finetuning method, where
instead of finetuning all the weights of the network, we only train a carefully
chosen subset of layers, keeping the rest of the weights frozen at their
initial (pretrained) values. We demonstrate that \emph{subset finetuning} (or
SubTuning) often achieves accuracy comparable to full finetuning of the model,
and even surpasses the performance of full finetuning when training data is
scarce. Therefore, SubTuning allows deploying new tasks at minimal
computational cost, while enjoying the benefits of finetuning the entire model.
This yields a simple and effective method for multi-task learning, where
different tasks do not interfere with one another, and yet share most of the
resources at inference time. We demonstrate the efficiency of SubTuning across
multiple tasks, using different network architectures and pretraining methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaplun_G/0/1/0/all/0/1&quot;&gt;Gal Kaplun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurevich_A/0/1/0/all/0/1&quot;&gt;Andrey Gurevich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swisa_T/0/1/0/all/0/1&quot;&gt;Tal Swisa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+David_M/0/1/0/all/0/1&quot;&gt;Mazor David&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shalev_Shwartz_S/0/1/0/all/0/1&quot;&gt;Shai Shalev-Shwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malach_E/0/1/0/all/0/1&quot;&gt;Eran Malach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.06600">
<title>Task-Specific Skill Localization in Fine-tuned Language Models. (arXiv:2302.06600v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2302.06600</link>
<description rdf:parseType="Literal">&lt;p&gt;Pre-trained language models can be fine-tuned to solve diverse NLP tasks,
including in few-shot settings. Thus fine-tuning allows the model to quickly
pick up task-specific ``skills,&apos;&apos; but there has been limited study of where
these newly-learnt skills reside inside the massive model. This paper
introduces the term skill localization for this problem and proposes a
solution. Given the downstream task and a model fine-tuned on that task, a
simple optimization is used to identify a very small subset of parameters
($\sim0.01$% of model parameters) responsible for ($&amp;gt;95$%) of the model&apos;s
performance, in the sense that grafting the fine-tuned values for just this
tiny subset onto the pre-trained model gives performance almost as well as the
fine-tuned model. While reminiscent of recent works on parameter-efficient
fine-tuning, the novel aspects here are that: (i) No further re-training is
needed on the subset (unlike, say, with lottery tickets). (ii) Notable
improvements are seen over vanilla fine-tuning with respect to calibration of
predictions in-distribution ($40$-$90$% error reduction) as well as the quality
of predictions out-of-distribution (OOD). In models trained on multiple tasks,
a stronger notion of skill localization is observed, where the sparse regions
corresponding to different tasks are almost disjoint, and their overlap (when
it happens) is a proxy for task similarity. Experiments suggest that
localization via grafting can assist certain forms of continual learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panigrahi_A/0/1/0/all/0/1&quot;&gt;Abhishek Panigrahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saunshi_N/0/1/0/all/0/1&quot;&gt;Nikunj Saunshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Haoyu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1&quot;&gt;Sanjeev Arora&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.07294">
<title>Derandomized Novelty Detection with FDR Control via Conformal E-values. (arXiv:2302.07294v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.07294</link>
<description rdf:parseType="Literal">&lt;p&gt;Conformal inference provides a general distribution-free method to rigorously
calibrate the output of any machine learning algorithm for novelty detection.
While this approach has many strengths, it has the limitation of being
randomized, in the sense that it may lead to different results when analyzing
twice the same data, and this can hinder the interpretation of any findings. We
propose to make conformal inferences more stable by leveraging suitable
conformal e-values instead of p-values to quantify statistical significance.
This solution allows the evidence gathered from multiple analyses of the same
data to be aggregated effectively while provably controlling the false
discovery rate. Further, we show that the proposed method can reduce randomness
without much loss of power compared to standard conformal inference, partly
thanks to an innovative way of weighting conformal e-values based on additional
side information carefully extracted from the same data. Simulations with
synthetic and real data confirm this solution can be effective at eliminating
random noise in the inferences obtained with state-of-the-art alternative
techniques, sometimes also leading to higher power.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bashari_M/0/1/0/all/0/1&quot;&gt;Meshi Bashari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Epstein_A/0/1/0/all/0/1&quot;&gt;Amir Epstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romano_Y/0/1/0/all/0/1&quot;&gt;Yaniv Romano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sesia_M/0/1/0/all/0/1&quot;&gt;Matteo Sesia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.07517">
<title>Extensible Motion-based Identification of XR Users using Non-Specific Motion Data. (arXiv:2302.07517v4 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/2302.07517</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we combine the strengths of distance-based and
classification-based approaches for the task of identifying extended reality
users by their movements. For this we explore an embedding-based model that
leverages deep metric learning. We train the model on a dataset of users
playing the VR game ``Half-Life: Alyx&apos;&apos; and conduct multiple experiments and
analyses using a state of the art classification-based model as baseline. The
results show that the embedding-based method 1) is able to identify new users
from non-specific movements using only a few minutes of enrollment data, 2) can
enroll new users within seconds, while retraining the baseline approach takes
almost a day, 3) is more reliable than the baseline approach when only little
enrollment data is available, 4) can be used to identify new users from another
dataset recorded with different VR devices.
&lt;/p&gt;
&lt;p&gt;Altogether, our solution is a foundation for easily extensible XR user
identification systems, applicable to a wide range of user motions. It also
paves the way for production-ready models that could be used by XR
practitioners without the requirements of expertise, hardware, or data for
training deep learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rack_C/0/1/0/all/0/1&quot;&gt;Christian Rack&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kobs_K/0/1/0/all/0/1&quot;&gt;Konstantin Kobs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernando_T/0/1/0/all/0/1&quot;&gt;Tamara Fernando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hotho_A/0/1/0/all/0/1&quot;&gt;Andreas Hotho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Latoschik_M/0/1/0/all/0/1&quot;&gt;Marc Erich Latoschik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.09543">
<title>Topological Feature Selection. (arXiv:2302.09543v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.09543</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a novel unsupervised, graph-based filter feature
selection technique which exploits the power of topologically constrained
network representations. We model dependency structures among features using a
family of chordal graphs (the Triangulated Maximally Filtered Graph), and we
maximise the likelihood of features&apos; relevance by studying their relative
position inside the network. Such an approach presents three aspects that are
particularly satisfactory compared to its alternatives: (i) it is highly
tunable and easily adaptable to the nature of input data; (ii) it is fully
explainable, maintaining, at the same time, a remarkable level of simplicity;
(iii) it is computationally cheaper compared to its alternatives. We test our
algorithm on 16 benchmark datasets from different applicative domains showing
that it outperforms or matches the current state-of-the-art under heterogeneous
evaluation conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Briola_A/0/1/0/all/0/1&quot;&gt;Antonio Briola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aste_T/0/1/0/all/0/1&quot;&gt;Tomaso Aste&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.10258">
<title>Neural Algorithmic Reasoning with Causal Regularisation. (arXiv:2302.10258v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.10258</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work on neural algorithmic reasoning has investigated the reasoning
capabilities of neural networks, effectively demonstrating they can learn to
execute classical algorithms on unseen data coming from the train distribution.
However, the performance of existing neural reasoners significantly degrades on
out-of-distribution (OOD) test data, where inputs have larger sizes. In this
work, we make an important observation: there are many different inputs for
which an algorithm will perform certain intermediate computations identically.
This insight allows us to develop data augmentation procedures that, given an
algorithm&apos;s intermediate trajectory, produce inputs for which the target
algorithm would have exactly the same next trajectory step. We ensure
invariance in the next-step prediction across such inputs, by employing a
self-supervised objective derived by our observation, formalised in a causal
graph. We prove that the resulting method, which we call Hint-ReLIC, improves
the OOD generalisation capabilities of the reasoner. We evaluate our method on
the CLRS algorithmic reasoning benchmark, where we show up to 3$\times$
improvements on the OOD test data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1&quot;&gt;Beatrice Bevilacqua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikiforou_K/0/1/0/all/0/1&quot;&gt;Kyriacos Nikiforou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibarz_B/0/1/0/all/0/1&quot;&gt;Borja Ibarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bica_I/0/1/0/all/0/1&quot;&gt;Ioana Bica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paganini_M/0/1/0/all/0/1&quot;&gt;Michela Paganini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blundell_C/0/1/0/all/0/1&quot;&gt;Charles Blundell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitrovic_J/0/1/0/all/0/1&quot;&gt;Jovana Mitrovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1&quot;&gt;Petar Veli&amp;#x10d;kovi&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.10289">
<title>Tackling Shortcut Learning in Deep Neural Networks: An Iterative Approach with Interpretable Models. (arXiv:2302.10289v8 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.10289</link>
<description rdf:parseType="Literal">&lt;p&gt;We use concept-based interpretable models to mitigate shortcut learning.
Existing methods lack interpretability. Beginning with a Blackbox, we
iteratively carve out a mixture of interpretable experts (MoIE) and a residual
network. Each expert explains a subset of data using First Order Logic (FOL).
While explaining a sample, the FOL from biased BB-derived MoIE detects the
shortcut effectively. Finetuning the BB with Metadata Normalization (MDN)
eliminates the shortcut. The FOLs from the finetuned-BB-derived MoIE verify the
elimination of the shortcut. Our experiments show that MoIE does not hurt the
accuracy of the original BB and eliminates shortcuts effectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Shantanu Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1&quot;&gt;Ke Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arabshahi_F/0/1/0/all/0/1&quot;&gt;Forough Arabshahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batmanghelich_K/0/1/0/all/0/1&quot;&gt;Kayhan Batmanghelich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.10681">
<title>FrankenSplit: Efficient Neural Feature Compression with Shallow Variational Bottleneck Injection for Mobile Edge Computing. (arXiv:2302.10681v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2302.10681</link>
<description rdf:parseType="Literal">&lt;p&gt;The rise of mobile AI accelerators allows latency-sensitive applications to
execute lightweight Deep Neural Networks (DNNs) on the client side. However,
critical applications require powerful models that edge devices cannot host and
must therefore offload requests, where the high-dimensional data will compete
for limited bandwidth. This work proposes shifting away from focusing on
executing shallow layers of partitioned DNNs. Instead, it advocates
concentrating the local resources on variational compression optimized for
machine interpretability. We introduce a novel framework for resource-conscious
compression models and extensively evaluate our method in an environment
reflecting the asymmetric resource distribution between edge devices and
servers. Our method achieves 60% lower bitrate than a state-of-the-art SC
method without decreasing accuracy and is up to 16x faster than offloading with
existing codec standards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Furutanpey_A/0/1/0/all/0/1&quot;&gt;Alireza Furutanpey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Raith_P/0/1/0/all/0/1&quot;&gt;Philipp Raith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dustdar_S/0/1/0/all/0/1&quot;&gt;Schahram Dustdar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.10894">
<title>Red Teaming Deep Neural Networks with Feature Synthesis Tools. (arXiv:2302.10894v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.10894</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretable AI tools are often motivated by the goal of understanding model
behavior in out-of-distribution (OOD) contexts. Despite the attention this area
of study receives, there are comparatively few cases where these tools have
identified novel, previously unknown, bugs in models. We argue that this is
due, in part, to a common feature of many interpretability methods: they
analyze and explain the behavior of a model using a particular dataset. While
this is useful, such tools can only analyze behaviors induced by features that
the user can sample or identify in advance. To address this, a growing body of
research involves interpreting models using feature synthesis methods which do
not depend on a dataset.
&lt;/p&gt;
&lt;p&gt;In this paper, our primary contribution is a benchmark to evaluate
interpretability tools. Our key insight is that we can train models that
respond to specific triggers (e.g., a specific patch inserted into an image)
with specific outputs (i.e. a label) and then evaluate interpretability tools
based on whether they help humans identify these triggers. We make four
contributions. (1) We propose trojan discovery as an evaluation task for
interpretability tools and introduce a trojan-discovery benchmark with 12
trojans of 3 different types. (2) We demonstrate the difficulty of this
benchmark with a preliminary evaluation of 16 feature attribution/saliency
tools. Even with access to data with a trojan&apos;s trigger, these methods
regularly fail to identify bugs. (3) We evaluate 7 feature-synthesis methods on
our benchmark. (4) We introduce and evaluate 2 variants of the best-performing
method from the previous evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casper_S/0/1/0/all/0/1&quot;&gt;Stephen Casper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuxiao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiawei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bu_T/0/1/0/all/0/1&quot;&gt;Tong Bu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kevin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hariharan_K/0/1/0/all/0/1&quot;&gt;Kaivalya Hariharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1&quot;&gt;Dylan Hadfield-Menell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.11012">
<title>Likelihood Annealing: Fast Calibrated Uncertainty for Regression. (arXiv:2302.11012v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.11012</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in deep learning have shown that uncertainty estimation is
becoming increasingly important in applications such as medical imaging,
natural language processing, and autonomous systems. However, accurately
quantifying uncertainty remains a challenging problem, especially in regression
tasks where the output space is continuous. Deep learning approaches that allow
uncertainty estimation for regression problems often converge slowly and yield
poorly calibrated uncertainty estimates that can not be effectively used for
quantification. Recently proposed post hoc calibration techniques are seldom
applicable to regression problems and often add overhead to an already slow
model training phase. This work presents a fast calibrated uncertainty
estimation method for regression tasks called Likelihood Annealing, that
consistently improves the convergence of deep regression models and yields
calibrated uncertainty without any post hoc calibration phase. Unlike previous
methods for calibrated uncertainty in regression that focus only on
low-dimensional regression problems, our method works well on a broad spectrum
of regression problems, including high-dimensional regression.Our empirical
analysis shows that our approach is generalizable to various network
architectures, including multilayer perceptrons, 1D/2D convolutional networks,
and graph neural networks, on five vastly diverse tasks, i.e., chaotic particle
trajectory denoising, physical property prediction of molecules using 3D
atomistic representation, natural image super-resolution, and medical image
translation using MRI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Upadhyay_U/0/1/0/all/0/1&quot;&gt;Uddeshya Upadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jae Myung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_C/0/1/0/all/0/1&quot;&gt;Cordelia Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1&quot;&gt;Zeynep Akata&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.11628">
<title>Feature Partition Aggregation: A Fast Certified Defense Against a Union of $\ell_0$ Attacks. (arXiv:2302.11628v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.11628</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse or $\ell_0$ adversarial attacks arbitrarily perturb an unknown subset
of the features. $\ell_0$ robustness analysis is particularly well-suited for
heterogeneous (tabular) data where features have different types or scales.
State-of-the-art $\ell_0$ certified defenses are based on randomized smoothing
and apply to evasion attacks only. This paper proposes feature partition
aggregation (FPA) -- a certified defense against the union of $\ell_0$ evasion,
backdoor, and poisoning attacks. FPA generates its stronger robustness
guarantees via an ensemble whose submodels are trained on disjoint feature
sets. Compared to state-of-the-art $\ell_0$ defenses, FPA is up to
3,000${\times}$ faster and provides larger median robustness guarantees (e.g.,
median certificates of 13 pixels over 10 for CIFAR10, 12 pixels over 10 for
MNIST, 4 features over 1 for Weather, and 3 features over 1 for Ames), meaning
FPA provides the additional dimensions of robustness essentially for free.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hammoudeh_Z/0/1/0/all/0/1&quot;&gt;Zayd Hammoudeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lowd_D/0/1/0/all/0/1&quot;&gt;Daniel Lowd&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.11700">
<title>Learning Revenue Maximizing Menus of Lotteries and Two-Part Tariffs. (arXiv:2302.11700v2 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/2302.11700</link>
<description rdf:parseType="Literal">&lt;p&gt;We advance a recently flourishing line of work at the intersection of
learning theory and computational economics by studying the learnability of two
classes of mechanisms prominent in economics, namely menus of lotteries and
two-part tariffs. The former is a family of randomized mechanisms designed for
selling multiple items, known to achieve revenue beyond deterministic
mechanisms, while the latter is designed for selling multiple units (copies) of
a single item with applications in real-world scenarios such as car or
bike-sharing services. We focus on learning high-revenue mechanisms of this
form from buyer valuation data in both distributional settings, where we have
access to buyers&apos; valuation samples up-front, and the more challenging and
less-studied online settings, where buyers arrive one-at-a-time and no
distributional assumption is made about their values.
&lt;/p&gt;
&lt;p&gt;Our main contribution is proposing the first online learning algorithms for
menus of lotteries and two-part tariffs with strong regret-bound guarantees. In
the general case, we provide a reduction to a finite number of experts, and in
the limited buyer type case, we show a reduction to online linear optimization,
which allows us to obtain no-regret guarantees by presenting buyers with menus
that correspond to a barycentric spanner. In addition, we provide algorithms
with improved running times over prior work for the distributional settings.
The key difficulty when deriving learning algorithms for these settings is that
the relevant revenue functions have sharp transition boundaries. In stark
contrast with the recent literature on learning such unstructured functions, we
show that simple discretization-based techniques are sufficient for learning in
these settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1&quot;&gt;Maria-Florina Balcan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beyhaghi_H/0/1/0/all/0/1&quot;&gt;Hedyeh Beyhaghi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.12432">
<title>Graph Neural Networks with Learnable and Optimal Polynomial Bases. (arXiv:2302.12432v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.12432</link>
<description rdf:parseType="Literal">&lt;p&gt;Polynomial filters, a kind of Graph Neural Networks, typically use a
predetermined polynomial basis and learn the coefficients from the training
data. It has been observed that the effectiveness of the model is highly
dependent on the property of the polynomial basis. Consequently, two natural
and fundamental questions arise: Can we learn a suitable polynomial basis from
the training data? Can we determine the optimal polynomial basis for a given
graph and node features?
&lt;/p&gt;
&lt;p&gt;In this paper, we propose two spectral GNN models that provide positive
answers to the questions posed above. First, inspired by Favard&apos;s Theorem, we
propose the FavardGNN model, which learns a polynomial basis from the space of
all possible orthonormal bases. Second, we examine the supposedly unsolvable
definition of optimal polynomial basis from Wang &amp;amp; Zhang (2022) and propose a
simple model, OptBasisGNN, which computes the optimal basis for a given graph
structure and graph signal. Extensive experiments are conducted to demonstrate
the effectiveness of our proposed models. Our code is available at
https://github.com/yuziGuo/FarOptBasis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yuhe Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1&quot;&gt;Zhewei Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.12559">
<title>From Noisy Fixed-Point Iterations to Private ADMM for Centralized and Federated Learning. (arXiv:2302.12559v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.12559</link>
<description rdf:parseType="Literal">&lt;p&gt;We study differentially private (DP) machine learning algorithms as instances
of noisy fixed-point iterations, in order to derive privacy and utility results
from this well-studied framework. We show that this new perspective recovers
popular private gradient-based methods like DP-SGD and provides a principled
way to design and analyze new private optimization algorithms in a flexible
manner. Focusing on the widely-used Alternating Directions Method of
Multipliers (ADMM) method, we use our general framework to derive novel private
ADMM algorithms for centralized, federated and fully decentralized learning.
For these three algorithms, we establish strong privacy guarantees leveraging
privacy amplification by iteration and by subsampling. Finally, we provide
utility guarantees using a unified analysis that exploits a recent linear
convergence result for noisy fixed-point iterations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cyffers_E/0/1/0/all/0/1&quot;&gt;Edwige Cyffers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellet_A/0/1/0/all/0/1&quot;&gt;Aur&amp;#xe9;lien Bellet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1&quot;&gt;Debabrota Basu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.14260">
<title>A Closer Look at the Intervention Procedure of Concept Bottleneck Models. (arXiv:2302.14260v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.14260</link>
<description rdf:parseType="Literal">&lt;p&gt;Concept bottleneck models (CBMs) are a class of interpretable neural network
models that predict the target response of a given input based on its
high-level concepts. Unlike the standard end-to-end models, CBMs enable domain
experts to intervene on the predicted concepts and rectify any mistakes at test
time, so that more accurate task predictions can be made at the end. While such
intervenability provides a powerful avenue of control, many aspects of the
intervention procedure remain rather unexplored. In this work, we develop
various ways of selecting intervening concepts to improve the intervention
effectiveness and conduct an array of in-depth analyses as to how they evolve
under different circumstances. Specifically, we find that an informed
intervention strategy can reduce the task error more than ten times compared to
the current baseline under the same amount of intervention counts in realistic
settings, and yet, this can vary quite significantly when taking into account
different intervention granularity. We verify our findings through
comprehensive evaluations, not only on the standard real datasets, but also on
synthetic datasets that we generate based on a set of different causal graphs.
We further discover some major pitfalls of the current practices which, without
a proper addressing, raise concerns on reliability and fairness of the
intervention procedure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1&quot;&gt;Sungbin Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_Y/0/1/0/all/0/1&quot;&gt;Yohan Jo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1&quot;&gt;Sungsoo Ahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1&quot;&gt;Namhoon Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.02063">
<title>Physics-Informed Deep Learning For Traffic State Estimation: A Survey and the Outlook. (arXiv:2303.02063v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.02063</link>
<description rdf:parseType="Literal">&lt;p&gt;For its robust predictive power (compared to pure physics-based models) and
sample-efficient training (compared to pure deep learning models),
physics-informed deep learning (PIDL), a paradigm hybridizing physics-based
models and deep neural networks (DNN), has been booming in science and
engineering fields. One key challenge of applying PIDL to various domains and
problems lies in the design of a computational graph that integrates physics
and DNNs. In other words, how physics are encoded into DNNs and how the physics
and data components are represented. In this paper, we provide a variety of
architecture designs of PIDL computational graphs and how these structures are
customized to traffic state estimation (TSE), a central problem in
transportation engineering. When observation data, problem type, and goal vary,
we demonstrate potential architectures of PIDL computational graphs and compare
these variants using the same real-world dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Di_X/0/1/0/all/0/1&quot;&gt;Xuan Di&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1&quot;&gt;Rongye Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mo_Z/0/1/0/all/0/1&quot;&gt;Zhaobin Mo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yongjie Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.04356">
<title>Soft Actor-Critic Algorithm with Truly-satisfied Inequality Constraint. (arXiv:2303.04356v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.04356</link>
<description rdf:parseType="Literal">&lt;p&gt;Soft actor-critic (SAC) in reinforcement learning is expected to be one of
the next-generation robot control schemes. Its ability to maximize policy
entropy would make a robotic controller robust to noise and perturbation, which
is useful for real-world robot applications. However, the priority of
maximizing the policy entropy is automatically tuned in the current
implementation, the rule of which can be interpreted as one for equality
constraint, binding the policy entropy into its specified lower bound. The
current SAC is therefore no longer maximize the policy entropy, contrary to our
expectation. To resolve this issue in SAC, this paper improves its
implementation with a learnable state-dependent slack variable for
appropriately handling the inequality constraint to maximize the policy entropy
by reformulating it as the corresponding equality constraint. The introduced
slack variable is optimized by a switching-type loss function that takes into
account the dual objectives of satisfying the equality constraint and checking
the lower bound. In Mujoco and Pybullet simulators, the modified SAC
statistically achieved the higher robustness for adversarial attacks than
before while regularizing the norm of action. A real-robot variable impedance
task was demonstrated for showing the applicability of the modified SAC to
real-world robot control. In particular, the modified SAC maintained adaptive
behaviors for physical human-robot interaction, which had no experience at all
during training. https://youtu.be/EH3xVtlVaJw
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kobayashi_T/0/1/0/all/0/1&quot;&gt;Taisuke Kobayashi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.09335">
<title>ExoplANNET: A deep learning algorithm to detect and identify planetary signals in radial velocity data. (arXiv:2303.09335v2 [astro-ph.EP] UPDATED)</title>
<link>http://arxiv.org/abs/2303.09335</link>
<description rdf:parseType="Literal">&lt;p&gt;The detection of exoplanets with the radial velocity method consists in
detecting variations of the stellar velocity caused by an unseen sub-stellar
companion. Instrumental errors, irregular time sampling, and different noise
sources originating in the intrinsic variability of the star can hinder the
interpretation of the data, and even lead to spurious detections. In recent
times, work began to emerge in the field of extrasolar planets that use Machine
Learning algorithms, some with results that exceed those obtained with the
traditional techniques in the field. We seek to explore the scope of the neural
networks in the radial velocity method, in particular for exoplanet detection
in the presence of correlated noise of stellar origin. In this work, a neural
network is proposed to replace the computation of the significance of the
signal detected with the radial velocity method and to classify it as of
planetary origin or not. The algorithm is trained using synthetic data of
systems with and without planetary companions. We injected realistic correlated
noise in the simulations, based on previous studies of the behaviour of stellar
activity. The performance of the network is compared to the traditional method
based on null hypothesis significance testing. The network achieves 28 % fewer
false positives. The improvement is observed mainly in the detection of
small-amplitude signals associated with low-mass planets. In addition, its
execution time is five orders of magnitude faster than the traditional method.
The superior performance exhibited by the algorithm has only been tested on
simulated radial velocity data so far. Although in principle it should be
straightforward to adapt it for use in real time series, its performance has to
be tested thoroughly. Future work should permit evaluating its potential for
adoption as a valuable tool for exoplanet detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Nieto_L/0/1/0/all/0/1&quot;&gt;L. A. Nieto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Diaz_R/0/1/0/all/0/1&quot;&gt;R. F. D&amp;#xed;az&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.11338">
<title>Towards Domain Generalization for ECG and EEG Classification: Algorithms and Benchmarks. (arXiv:2303.11338v3 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2303.11338</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their immense success in numerous fields, machine and deep learning
systems have not yet been able to firmly establish themselves in
mission-critical applications in healthcare. One of the main reasons lies in
the fact that when models are presented with previously unseen,
Out-of-Distribution samples, their performance deteriorates significantly. This
is known as the Domain Generalization (DG) problem. Our objective in this work
is to propose a benchmark for evaluating DG algorithms, in addition to
introducing a novel architecture for tackling DG in biosignal classification.
In this paper, we describe the Domain Generalization problem for biosignals,
focusing on electrocardiograms (ECG) and electroencephalograms (EEG) and
propose and implement an open-source biosignal DG evaluation benchmark.
Furthermore, we adapt state-of-the-art DG algorithms from computer vision to
the problem of 1D biosignal classification and evaluate their effectiveness.
Finally, we also introduce a novel neural network architecture that leverages
multi-layer representations for improved model generalizability. By
implementing the above DG setup we are able to experimentally demonstrate the
presence of the DG problem in ECG and EEG datasets. In addition, our proposed
model demonstrates improved effectiveness compared to the baseline algorithms,
exceeding the state-of-the-art in both datasets. Recognizing the significance
of the distribution shift present in biosignal datasets, the presented
benchmark aims at urging further research into the field of biomedical DG by
simplifying the evaluation process of proposed algorithms. To our knowledge,
this is the first attempt at developing an open-source framework for evaluating
ECG and EEG DG algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ballas_A/0/1/0/all/0/1&quot;&gt;Aristotelis Ballas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Diou_C/0/1/0/all/0/1&quot;&gt;Christos Diou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.14244">
<title>Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing. (arXiv:2303.14244v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.14244</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, there has been significant progress in understanding the
convergence and generalization properties of gradient-based methods for
training overparameterized learning models. However, many aspects including the
role of small random initialization and how the various parameters of the model
are coupled during gradient-based updates to facilitate good generalization
remain largely mysterious. A series of recent papers have begun to study this
role for non-convex formulations of symmetric Positive Semi-Definite (PSD)
matrix sensing problems which involve reconstructing a low-rank PSD matrix from
a few linear measurements. The underlying symmetry/PSDness is crucial to
existing convergence and generalization guarantees for this problem. In this
paper, we study a general overparameterized low-rank matrix sensing problem
where one wishes to reconstruct an asymmetric rectangular low-rank matrix from
a few linear measurements. We prove that an overparameterized model trained via
factorized gradient descent converges to the low-rank matrix generating the
measurements. We show that in this setting, factorized gradient descent enjoys
two implicit properties: (1) coupling of the trajectory of gradient descent
where the factors are coupled in various ways throughout the gradient update
trajectory and (2) an algorithmic regularization property where the iterates
show a propensity towards low-rank models despite the overparameterized nature
of the factorized model. These two implicit properties in turn allow us to show
that the gradient descent trajectory from small random initialization moves
towards solutions that are both globally optimal and generalize well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1&quot;&gt;Mahdi Soltanolkotabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoger_D/0/1/0/all/0/1&quot;&gt;Dominik St&amp;#xf6;ger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Changzhi Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.14464">
<title>Verifying Properties of Tsetlin Machines. (arXiv:2303.14464v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.14464</link>
<description rdf:parseType="Literal">&lt;p&gt;Tsetlin Machines (TsMs) are a promising and interpretable machine learning
method which can be applied for various classification tasks. We present an
exact encoding of TsMs into propositional logic and formally verify properties
of TsMs using a SAT solver. In particular, we introduce in this work a notion
of similarity of machine learning models and apply our notion to check for
similarity of TsMs. We also consider notions of robustness and equivalence from
the literature and adapt them for TsMs. Then, we show the correctness of our
encoding and provide results for the properties: adversarial robustness,
equivalence, and similarity of TsMs. In our experiments, we employ the MNIST
and IMDB datasets for (respectively) image and sentiment classification. We
discuss the results for verifying robustness obtained with TsMs with those in
the literature obtained with Binarized Neural Networks on MNIST.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Przybysz_E/0/1/0/all/0/1&quot;&gt;Emilia Przybysz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattarai_B/0/1/0/all/0/1&quot;&gt;Bimal Bhattarai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Persia_C/0/1/0/all/0/1&quot;&gt;Cosimo Persia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozaki_A/0/1/0/all/0/1&quot;&gt;Ana Ozaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1&quot;&gt;Ole-Christoffer Granmo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_J/0/1/0/all/0/1&quot;&gt;Jivitesh Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.15485">
<title>Transfer-Once-For-All: AI Model Optimization for Edge. (arXiv:2303.15485v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.15485</link>
<description rdf:parseType="Literal">&lt;p&gt;Weight-sharing neural architecture search aims to optimize a configurable
neural network model (supernet) for a variety of deployment scenarios across
many devices with different resource constraints. Existing approaches use
evolutionary search to extract models of different sizes from a supernet
trained on a very large data set, and then fine-tune the extracted models on
the typically small, real-world data set of interest. The computational cost of
training thus grows linearly with the number of different model deployment
scenarios. Hence, we propose Transfer-Once-For-All (TOFA) for supernet-style
training on small data sets with constant computational training cost over any
number of edge deployment scenarios. Given a task, TOFA obtains custom neural
networks, both the topology and the weights, optimized for any number of edge
deployment scenarios. To overcome the challenges arising from small data, TOFA
utilizes a unified semi-supervised training loss to simultaneously train all
subnets within the supernet, coupled with on-the-fly architecture selection at
deployment time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kundu_A/0/1/0/all/0/1&quot;&gt;Achintya Kundu&lt;/a&gt; (IBM Research), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wynter_L/0/1/0/all/0/1&quot;&gt;Laura Wynter&lt;/a&gt; (IBM Research), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1&quot;&gt;Rhui Dih Lee&lt;/a&gt; (IBM Research), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bathen_L/0/1/0/all/0/1&quot;&gt;Luis Angel Bathen&lt;/a&gt; (IBM Research)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.01117">
<title>Interpretable Symbolic Regression for Data Science: Analysis of the 2022 Competition. (arXiv:2304.01117v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.01117</link>
<description rdf:parseType="Literal">&lt;p&gt;Symbolic regression searches for analytic expressions that accurately
describe studied phenomena. The main attraction of this approach is that it
returns an interpretable model that can be insightful to users. Historically,
the majority of algorithms for symbolic regression have been based on
evolutionary algorithms. However, there has been a recent surge of new
proposals that instead utilize approaches such as enumeration algorithms, mixed
linear integer programming, neural networks, and Bayesian optimization. In
order to assess how well these new approaches behave on a set of common
challenges often faced in real-world data, we hosted a competition at the 2022
Genetic and Evolutionary Computation Conference consisting of different
synthetic and real-world datasets which were blind to entrants. For the
real-world track, we assessed interpretability in a realistic way by using a
domain expert to judge the trustworthiness of candidate models.We present an
in-depth analysis of the results obtained in this competition, discuss current
challenges of symbolic regression algorithms and highlight possible
improvements for future competitions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franca_F/0/1/0/all/0/1&quot;&gt;F. O. de Franca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Virgolin_M/0/1/0/all/0/1&quot;&gt;M. Virgolin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kommenda_M/0/1/0/all/0/1&quot;&gt;M. Kommenda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumder_M/0/1/0/all/0/1&quot;&gt;M. S. Majumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cranmer_M/0/1/0/all/0/1&quot;&gt;M. Cranmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Espada_G/0/1/0/all/0/1&quot;&gt;G. Espada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ingelse_L/0/1/0/all/0/1&quot;&gt;L. Ingelse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonseca_A/0/1/0/all/0/1&quot;&gt;A. Fonseca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Landajuela_M/0/1/0/all/0/1&quot;&gt;M. Landajuela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petersen_B/0/1/0/all/0/1&quot;&gt;B. Petersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glatt_R/0/1/0/all/0/1&quot;&gt;R. Glatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mundhenk_N/0/1/0/all/0/1&quot;&gt;N. Mundhenk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;C. S. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hochhalter_J/0/1/0/all/0/1&quot;&gt;J. D. Hochhalter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Randall_D/0/1/0/all/0/1&quot;&gt;D. L. Randall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamienny_P/0/1/0/all/0/1&quot;&gt;P. Kamienny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;H. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dick_G/0/1/0/all/0/1&quot;&gt;G. Dick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simon_A/0/1/0/all/0/1&quot;&gt;A. Simon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burlacu_B/0/1/0/all/0/1&quot;&gt;B. Burlacu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasak_J/0/1/0/all/0/1&quot;&gt;Jaan Kasak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Machado_M/0/1/0/all/0/1&quot;&gt;Meera Machado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilstrup_C/0/1/0/all/0/1&quot;&gt;Casper Wilstrup&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cava_W/0/1/0/all/0/1&quot;&gt;W. G. La Cava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.06502">
<title>Variations of Squeeze and Excitation networks. (arXiv:2304.06502v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.06502</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks learns spatial features and are heavily
interlinked within kernels. The SE module have broken the traditional route of
neural networks passing the entire result to next layer. Instead SE only passes
important features to be learned with its squeeze and excitation (SE) module.
We propose variations of the SE module which improvises the process of squeeze
and excitation and enhances the performance. The proposed squeezing or exciting
the layer makes it possible for having a smooth transition of layer weights.
These proposed variations also retain the characteristics of SE module. The
experimented results are carried out on residual networks and the results are
tabulated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+NV_M/0/1/0/all/0/1&quot;&gt;Mahendran NV&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.07702">
<title>Towards Better Evaluation of GNN Expressiveness with BREC Dataset. (arXiv:2304.07702v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.07702</link>
<description rdf:parseType="Literal">&lt;p&gt;Research on the theoretical expressiveness of Graph Neural Networks (GNNs)
has developed rapidly, and many methods have been proposed to enhance the
expressiveness. However, most methods do not have a uniform expressiveness
measure except for a few that strictly follow the $k$-dimensional
Weisfeiler-Lehman ($k$-WL) test hierarchy. Their theoretical analyses are often
limited to distinguishing certain families of non-isomorphic graphs, leading to
difficulties in quantitatively comparing their expressiveness. In contrast to
theoretical analysis, another way to measure expressiveness is by evaluating
model performance on certain datasets containing 1-WL-indistinguishable graphs.
Previous datasets specifically designed for this purpose, however, face
problems with difficulty (any model surpassing 1-WL has nearly 100% accuracy),
granularity (models tend to be either 100% correct or near random guess), and
scale (only a few essentially different graphs in each dataset). To address
these limitations, we propose a new expressiveness dataset, $\textbf{BREC}$,
which includes 400 pairs of non-isomorphic graphs carefully selected from four
primary categories (Basic, Regular, Extension, and CFI). These graphs have
higher difficulty (up to 4-WL-indistinguishable), finer granularity (able to
compare models between 1-WL and 3-WL), and a larger scale (400 pairs). Further,
we synthetically test 23 models with higher-than-1-WL expressiveness on our
BREC dataset. Our experiment gives the first thorough comparison of the
expressiveness of those state-of-the-art beyond-1-WL GNN models. We expect this
dataset to serve as a benchmark for testing the expressiveness of future GNNs.
Our dataset and evaluation code are released at:
https://github.com/GraphPKU/BREC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanbo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Muhan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.08158">
<title>Attention Mixtures for Time-Aware Sequential Recommendation. (arXiv:2304.08158v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2304.08158</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformers emerged as powerful methods for sequential recommendation.
However, existing architectures often overlook the complex dependencies between
user preferences and the temporal context. In this short paper, we introduce
MOJITO, an improved Transformer sequential recommender system that addresses
this limitation. MOJITO leverages Gaussian mixtures of attention-based temporal
context and item embedding representations for sequential modeling. Such an
approach permits to accurately predict which items should be recommended next
to users depending on past actions and the temporal context. We demonstrate the
relevance of our approach, by empirically outperforming existing Transformers
for sequential recommendation on several real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1&quot;&gt;Viet-Anh Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salha_Galvan_G/0/1/0/all/0/1&quot;&gt;Guillaume Salha-Galvan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sguerra_B/0/1/0/all/0/1&quot;&gt;Bruno Sguerra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hennequin_R/0/1/0/all/0/1&quot;&gt;Romain Hennequin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.09914">
<title>The Face of Populism: Examining Differences in Facial Emotional Expressions of Political Leaders Using Machine Learning. (arXiv:2304.09914v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/2304.09914</link>
<description rdf:parseType="Literal">&lt;p&gt;Online media has revolutionized the way political information is disseminated
and consumed on a global scale, and this shift has compelled political figures
to adopt new strategies of capturing and retaining voter attention. These
strategies often rely on emotional persuasion and appeal, and as visual content
becomes increasingly prevalent in virtual space, much of political
communication too has come to be marked by evocative video content and imagery.
The present paper offers a novel approach to analyzing material of this kind.
We apply a deep-learning-based computer-vision algorithm to a sample of 220
YouTube videos depicting political leaders from 15 different countries, which
is based on an existing trained convolutional neural network architecture
provided by the Python library fer. The algorithm returns emotion scores
representing the relative presence of 6 emotional states (anger, disgust, fear,
happiness, sadness, and surprise) and a neutral expression for each frame of
the processed YouTube video. We observe statistically significant differences
in the average score of expressed negative emotions between groups of leaders
with varying degrees of populist rhetoric as defined by the Global Party Survey
(GPS), indicating that populist leaders tend to express negative emotions to a
greater extent during their public performance than their non-populist
counterparts. Overall, our contribution provides insight into the
characteristics of visual self-representation among political leaders, as well
as an open-source workflow for further computational studies of their
non-verbal communication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Major_S/0/1/0/all/0/1&quot;&gt;Sara Major&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomasevic_A/0/1/0/all/0/1&quot;&gt;Aleksandar Toma&amp;#x161;evi&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.11436">
<title>Breaching FedMD: Image Recovery via Paired-Logits Inversion Attack. (arXiv:2304.11436v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2304.11436</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning with Model Distillation (FedMD) is a nascent collaborative
learning paradigm, where only output logits of public datasets are transmitted
as distilled knowledge, instead of passing on private model parameters that are
susceptible to gradient inversion attacks, a known privacy risk in federated
learning. In this paper, we found that even though sharing output logits of
public datasets is safer than directly sharing gradients, there still exists a
substantial risk of data exposure caused by carefully designed malicious
attacks. Our study shows that a malicious server can inject a PLI
(Paired-Logits Inversion) attack against FedMD and its variants by training an
inversion neural network that exploits the confidence gap between the server
and client models. Experiments on multiple facial recognition datasets validate
that under FedMD-like schemes, by using paired server-client logits of public
datasets only, the malicious server is able to reconstruct private images on
all tested benchmarks with a high success rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takahashi_H/0/1/0/all/0/1&quot;&gt;Hideaki Takahashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingjing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.12944">
<title>Latent Traversals in Generative Models as Potential Flows. (arXiv:2304.12944v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.12944</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the significant recent progress in deep generative models, the
underlying structure of their latent spaces is still poorly understood, thereby
making the task of performing semantically meaningful latent traversals an open
research challenge. Most prior work has aimed to solve this challenge by
modeling latent structures linearly, and finding corresponding linear
directions which result in `disentangled&apos; generations. In this work, we instead
propose to model latent structures with a learned dynamic potential landscape,
thereby performing latent traversals as the flow of samples down the
landscape&apos;s gradient. Inspired by physics, optimal transport, and neuroscience,
these potential landscapes are learned as physically realistic partial
differential equations, thereby allowing them to flexibly vary over both space
and time. To achieve disentanglement, multiple potentials are learned
simultaneously, and are constrained by a classifier to be distinct and
semantically self-consistent. Experimentally, we demonstrate that our method
achieves both more qualitatively and quantitatively disentangled trajectories
than state-of-the-art baselines. Further, we demonstrate that our method can be
integrated as a regularization term during training, thereby acting as an
inductive bias towards the learning of structured representations, ultimately
improving model likelihood on similarly structured data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yue Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keller_T/0/1/0/all/0/1&quot;&gt;T. Anderson Keller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1&quot;&gt;Nicu Sebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.13230">
<title>UNADON: Transformer-based model to predict genome-wide chromosome spatial position. (arXiv:2304.13230v2 [q-bio.GN] UPDATED)</title>
<link>http://arxiv.org/abs/2304.13230</link>
<description rdf:parseType="Literal">&lt;p&gt;The spatial positioning of chromosomes relative to functional nuclear bodies
is intertwined with genome functions such as transcription. However, the
sequence patterns and epigenomic features that collectively influence chromatin
spatial positioning in a genome-wide manner are not well understood. Here, we
develop a new transformer-based deep learning model called UNADON, which
predicts the genome-wide cytological distance to a specific type of nuclear
body, as measured by TSA-seq, using both sequence features and epigenomic
signals. Evaluations of UNADON in four cell lines (K562, H1, HFFc6, HCT116)
show high accuracy in predicting chromatin spatial positioning to nuclear
bodies when trained on a single cell line. UNADON also performed well in an
unseen cell type. Importantly, we reveal potential sequence and epigenomic
factors that affect large-scale chromatin compartmentalization to nuclear
bodies. Together, UNADON provides new insights into the principles between
sequence features and large-scale chromatin spatial localization, which has
important implications for understanding nuclear structure and function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Muyu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jian Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.14248">
<title>On Manifold Learning in Plato&apos;s Cave: Remarks on Manifold Learning and Physical Phenomena. (arXiv:2304.14248v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2304.14248</link>
<description rdf:parseType="Literal">&lt;p&gt;Many techniques in machine learning attempt explicitly or implicitly to infer
a low-dimensional manifold structure of an underlying physical phenomenon from
measurements without an explicit model of the phenomenon or the measurement
apparatus. This paper presents a cautionary tale regarding the discrepancy
between the geometry of measurements and the geometry of the underlying
phenomenon in a benign setting. The deformation in the metric illustrated in
this paper is mathematically straightforward and unavoidable in the general
case, and it is only one of several similar effects. While this is not always
problematic, we provide an example of an arguably standard and harmless data
processing procedure where this effect leads to an incorrect answer to a
seemingly simple question. Although we focus on manifold learning, these issues
apply broadly to dimensionality reduction and unsupervised learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lederman_R/0/1/0/all/0/1&quot;&gt;Roy R. Lederman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Toader_B/0/1/0/all/0/1&quot;&gt;Bogdan Toader&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.14343">
<title>Towards Efficient and Comprehensive Urban Spatial-Temporal Prediction: A Unified Library and Performance Benchmark. (arXiv:2304.14343v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.14343</link>
<description rdf:parseType="Literal">&lt;p&gt;As deep learning technology advances and more urban spatial-temporal data
accumulates, an increasing number of deep learning models are being proposed to
solve urban spatial-temporal prediction problems. However, there are
limitations in the existing field, including open-source data being in various
formats and difficult to use, few papers making their code and data openly
available, and open-source models often using different frameworks and
platforms, making comparisons challenging. A standardized framework is urgently
needed to implement and evaluate these methods. To address these issues, we
provide a comprehensive review of urban spatial-temporal prediction and propose
a unified storage format for spatial-temporal data called atomic files. We also
propose LibCity, an open-source library that offers researchers a credible
experimental tool and a convenient development framework. In this library, we
have reproduced 65 spatial-temporal prediction models and collected 55
spatial-temporal datasets, allowing researchers to conduct comprehensive
experiments conveniently. Using LibCity, we conducted a series of experiments
to validate the effectiveness of different models and components, and we
summarized promising future technology developments and research directions for
spatial-temporal prediction. By enabling fair model comparisons, designing a
unified data storage format, and simplifying the process of developing new
models, LibCity is poised to make significant contributions to the
spatial-temporal prediction field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jiawei Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1&quot;&gt;Chengkai Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1&quot;&gt;Wenjun Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wayne Xin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jingyuan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.01666">
<title>BrainNPT: Pre-training of Transformer networks for brain network classification. (arXiv:2305.01666v3 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/2305.01666</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning methods have advanced quickly in brain imaging analysis over
the past few years, but they are usually restricted by the limited labeled
data. Pre-trained model on unlabeled data has presented promising improvement
in feature learning in many domains, including natural language processing and
computer vision. However, this technique is under-explored in brain network
analysis. In this paper, we focused on pre-training methods with Transformer
networks to leverage existing unlabeled data for brain functional network
classification. First, we proposed a Transformer-based neural network, named as
BrainNPT, for brain functional network classification. The proposed method
leveraged &amp;lt;cls&amp;gt; token as a classification embedding vector for the Transformer
model to effectively capture the representation of brain network. Second, we
proposed a pre-training framework for BrainNPT model to leverage unlabeled
brain network data to learn the structure information of brain networks. The
results of classification experiments demonstrated the BrainNPT model without
pre-training achieved the best performance with the state-of-the-art models,
and the BrainNPT model with pre-training strongly outperformed the
state-of-the-art models. The pre-training BrainNPT model improved 8.75% of
accuracy compared with the model without pre-training. We further compared the
pre-training strategies, analyzed the influence of the parameters of the model,
and interpreted the trained model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jinlong Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yangmin Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_N/0/1/0/all/0/1&quot;&gt;Nan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Dong_S/0/1/0/all/0/1&quot;&gt;Shoubin Dong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.03774">
<title>Physics-Informed Localized Learning for Advection-Diffusion-Reaction Systems. (arXiv:2305.03774v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.03774</link>
<description rdf:parseType="Literal">&lt;p&gt;The global push to advance Carbon Capture and Sequestration initiatives and
green energy solutions, such as geothermal, have thrust new demands upon the
current state-of-the-art subsurface fluid simulators. The requirement to be
able to simulate a large order of reservoir states simultaneously, in a short
period of time, has opened the door of opportunity for the application of
machine learning techniques for surrogate modelling. We propose a novel
physics-informed and boundary condition-aware Localized Learning method which
extends the Embed-to-Control (E2C) and Embed-to-Control and Observe (E2CO)
models to learn local representations of global state variables in an
Advection-Diffusion Reaction system. Trained on reservoir simulation data, we
show that our model is able to predict future states of the system, for a given
set of controls, to a great deal of accuracy with only a fraction of the
available information. It hence reduces training times significantly compared
to the original E2C and E2CO models, lending to its benefit in application to
optimal control problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sathujoda_S/0/1/0/all/0/1&quot;&gt;Surya T. Sathujoda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheth_S/0/1/0/all/0/1&quot;&gt;Soham M. Sheth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.05392">
<title>Sharpness-Aware Minimization Alone can Improve Adversarial Robustness. (arXiv:2305.05392v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.05392</link>
<description rdf:parseType="Literal">&lt;p&gt;Sharpness-Aware Minimization (SAM) is an effective method for improving
generalization ability by regularizing loss sharpness. In this paper, we
explore SAM in the context of adversarial robustness. We find that using only
SAM can achieve superior adversarial robustness without sacrificing clean
accuracy compared to standard training, which is an unexpected benefit. We also
discuss the relation between SAM and adversarial training (AT), a popular
method for improving the adversarial robustness of DNNs. In particular, we show
that SAM and AT differ in terms of perturbation strength, leading to different
accuracy and robustness trade-offs. We provide theoretical evidence for these
claims in a simplified model. Finally, while AT suffers from decreased clean
accuracy and computational overhead, we suggest that SAM can be regarded as a
lightweight substitute for AT under certain requirements. Code is available at
https://github.com/weizeming/SAM_AT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1&quot;&gt;Zeming Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jingyu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yihao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06174">
<title>Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging. (arXiv:2305.06174v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06174</link>
<description rdf:parseType="Literal">&lt;p&gt;Climate change is the defining issue of our time, and we are at a defining
moment. Various interest groups, social movement organizations, and individuals
engage in collective action on this issue on social media. In addition, issue
advocacy campaigns on social media often arise in response to ongoing societal
concerns, especially those faced by energy industries. Our goal in this paper
is to analyze how those industries, their advocacy group, and climate advocacy
group use social media to influence the narrative on climate change. In this
work, we propose a minimally supervised model soup [57] approach combined with
messaging themes to identify the stances of climate ads on Facebook. Finally,
we release our stance dataset, model, and set of themes related to climate
campaigns for future work on opinion mining and the automatic detection of
climate change stances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1&quot;&gt;Tunazzina Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldwasser_D/0/1/0/all/0/1&quot;&gt;Dan Goldwasser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06569">
<title>How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v3 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06569</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommendation foundation model utilizes large language models (LLM) for
recommendation by converting recommendation tasks into natural language tasks.
It enables generative recommendation which directly generates the item(s) to
recommend rather than calculating a ranking score for each and every candidate
item in traditional recommendation models, simplifying the recommendation
pipeline from multi-stage filtering to single-stage filtering. To avoid
generating excessively long text when deciding which item(s) to recommend,
creating LLM-compatible item IDs is essential for recommendation foundation
models. In this study, we systematically examine the item indexing problem for
recommendation foundation models, using P5 as the representative backbone model
and replicating its results with various indexing methods. To emphasize the
importance of item indexing, we first discuss the issues of several trivial
item indexing methods, such as independent indexing, title indexing, and random
indexing. We then propose four simple yet effective solutions, including
sequential indexing, collaborative indexing, semantic (content-based) indexing,
and hybrid indexing. Our reproducibility study of P5 highlights the significant
influence of item indexing methods on the model performance, and our results on
real-world datasets validate the effectiveness of our proposed solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1&quot;&gt;Wenyue Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shuyuan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1&quot;&gt;Yingqiang Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yongfeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06989">
<title>Neural Wave Functions for Superfluids. (arXiv:2305.06989v2 [cond-mat.quant-gas] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06989</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding superfluidity remains a major goal of condensed matter physics.
Here we tackle this challenge utilizing the recently developed Fermionic neural
network (FermiNet) wave function Ansatz for variational Monte Carlo
calculations. We study the unitary Fermi gas, a system with strong,
short-range, two-body interactions known to possess a superfluid ground state
but difficult to describe quantitatively. We demonstrate key limitations of the
FermiNet Ansatz in studying the unitary Fermi gas and propose a simple
modification that outperforms the original FermiNet significantly, giving
highly accurate results. We prove mathematically that the new Ansatz, which
only differs from the original Ansatz by the method of antisymmetrization, is a
strict generalization of the original FermiNet architecture, despite the use of
fewer parameters. Our approach shares several advantages with the FermiNet: the
use of a neural network removes the need for an underlying basis set; and the
flexibility of the network yields extremely accurate results within a
variational quantum Monte Carlo framework that provides access to unbiased
estimates of arbitrary ground-state expectation values. We discuss how the
method can be extended to study other superfluids.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Lou_W/0/1/0/all/0/1&quot;&gt;Wan Tong Lou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Sutterud_H/0/1/0/all/0/1&quot;&gt;Halvard Sutterud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Cassella_G/0/1/0/all/0/1&quot;&gt;Gino Cassella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Foulkes_W/0/1/0/all/0/1&quot;&gt;W.M.C. Foulkes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Knolle_J/0/1/0/all/0/1&quot;&gt;Johannes Knolle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Pfau_D/0/1/0/all/0/1&quot;&gt;David Pfau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Spencer_J/0/1/0/all/0/1&quot;&gt;James S. Spencer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.10210">
<title>Object Re-Identification from Point Clouds. (arXiv:2305.10210v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.10210</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we study the problem of object re-identification (ReID) in a 3D
multi-object tracking (MOT) context, by learning to match pairs of objects from
cropped (e.g., using their predicted 3D bounding boxes) point cloud
observations. We are not concerned with SOTA performance for 3D MOT, however.
Instead, we seek to answer the following question: In a realistic tracking
by-detection context, how does object ReID from point clouds perform relative
to ReID from images? To enable such a study, we propose a lightweight matching
head that can be concatenated to any set or sequence processing backbone (e.g.,
PointNet or ViT), creating a family of comparable object ReID networks for both
modalities. Run in siamese style, our proposed point-cloud ReID networks can
make thousands of pairwise comparisons in real-time (10 hz). Our findings
demonstrate that their performance increases with higher sensor resolution and
approaches that of image ReID when observations are sufficiently dense.
Additionally, we investigate our network&apos;s ability to enhance 3D multi-object
tracking (MOT), showing that our point-cloud ReID networks can successfully
re-identify objects which led a strong motion-based tracker into error. To our
knowledge, we are the first to study real-time object re-identification from
point clouds in a 3D multi-object tracking context.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Therien_B/0/1/0/all/0/1&quot;&gt;Benjamin Th&amp;#xe9;rien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chengjie Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chow_A/0/1/0/all/0/1&quot;&gt;Adrian Chow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czarnecki_K/0/1/0/all/0/1&quot;&gt;Krzysztof Czarnecki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13093">
<title>Restore Anything Pipeline: Segment Anything Meets Image Restoration. (arXiv:2305.13093v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13093</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent image restoration methods have produced significant advancements using
deep learning. However, existing methods tend to treat the whole image as a
single entity, failing to account for the distinct objects in the image that
exhibit individual texture properties. Existing methods also typically generate
a single result, which may not suit the preferences of different users. In this
paper, we introduce the Restore Anything Pipeline (RAP), a novel interactive
and per-object level image restoration approach that incorporates a
controllable model to generate different results that users may choose from.
RAP incorporates image segmentation through the recent Segment Anything Model
(SAM) into a controllable image restoration model to create a user-friendly
pipeline for several image restoration tasks. We demonstrate the versatility of
RAP by applying it to three common image restoration tasks: image deblurring,
image denoising, and JPEG artifact removal. Our experiments show that RAP
produces superior visual results compared to state-of-the-art methods. RAP
represents a promising direction for image restoration, providing users with
greater control, and enabling image restoration at an object level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jiaxi Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holz_C/0/1/0/all/0/1&quot;&gt;Christian Holz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13681">
<title>GUARD: A Safe Reinforcement Learning Benchmark. (arXiv:2305.13681v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13681</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the trial-and-error nature, it is typically challenging to apply RL
algorithms to safety-critical real-world applications, such as autonomous
driving, human-robot interaction, robot manipulation, etc, where such errors
are not tolerable. Recently, safe RL (i.e. constrained RL) has emerged rapidly
in the literature, in which the agents explore the environment while satisfying
constraints. Due to the diversity of algorithms and tasks, it remains difficult
to compare existing safe RL algorithms. To fill that gap, we introduce GUARD, a
Generalized Unified SAfe Reinforcement Learning Development Benchmark. GUARD
has several advantages compared to existing benchmarks. First, GUARD is a
generalized benchmark with a wide variety of RL agents, tasks, and safety
constraint specifications. Second, GUARD comprehensively covers
state-of-the-art safe RL algorithms with self-contained implementations. Third,
GUARD is highly customizable in tasks and algorithms. We present a comparison
of state-of-the-art safe RL algorithms in various task settings using GUARD and
establish baselines that future work can build on.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Weiye Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Rui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yifan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Ruixuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1&quot;&gt;Tianhao Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Changliu Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15889">
<title>Quantifying and Exploring Heterogeneity in Domain Generalization through Contrastive Analysis. (arXiv:2305.15889v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15889</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain generalization (DG) is a commonly encountered issue in real-world
applications. Its objective is to train models that can generalize well to
unseen target domains by utilizing multiple source domains. In most DG
algorithms, domain labels, which indicate the domain from which each data point
is sampled, are treated as a form of supervision to enhance generalization
performance. However, using the original domain labels as the supervision
signal may not be optimal due to a lack of diversity among domains, known as
heterogeneity. This lack of heterogeneity can lead to the original labels being
noisy and disrupting the generalization learning process. Some methods attempt
to address this by re-dividing the domains and applying a new dividing pattern.
However, the chosen pattern may not capture the maximum heterogeneity since
there is no metric available to quantify it accurately. In this paper, we
propose that domain heterogeneity primarily lies in variant features within the
invariant learning framework. We introduce a novel approach which utilizes
contrastive learning to guide the metric for domain heterogeneity. By promoting
the learning of variant features, we develop a metric that captures models&apos;
learning potential for data heterogeneity. We also emphasize the distinction
between seeking variance-based heterogeneity and training an invariance-based
generalizable model. In the first stage, we generate the most heterogeneous
dividing pattern using our contrastive metric. In the second stage, we employ
contrastive learning focused on invariance by constructing pairs based on the
stable relationships indicated by domains and classes. This approach
effectively utilizes the generated domain labels for generalization. Extensive
experiments demonstrate that our method successfully uncovers heterogeneity and
achieves remarkable generalization performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1&quot;&gt;Yunze Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1&quot;&gt;Junkun Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Min Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1&quot;&gt;Didi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Keli Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1&quot;&gt;Kun Kuang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.16380">
<title>Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer. (arXiv:2305.16380v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.16380</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer architecture has shown impressive performance in multiple
research domains and has become the backbone of many neural network models.
However, there is limited understanding on how it works. In particular, with a
simple predictive loss, how the representation emerges from the gradient
\emph{training dynamics} remains a mystery. In this paper, for 1-layer
transformer with one self-attention layer plus one decoder layer, we analyze
its SGD training dynamics for the task of next token prediction in a
mathematically rigorous manner. We open the black box of the dynamic process of
how the self-attention layer combines input tokens, and reveal the nature of
underlying inductive bias. More specifically, with the assumption (a) no
positional encoding, (b) long input sequence, and (c) the decoder layer learns
faster than the self-attention layer, we prove that self-attention acts as a
\emph{discriminative scanning algorithm}: starting from uniform attention, it
gradually attends more to distinct key tokens for a specific next token to be
predicted, and pays less attention to common key tokens that occur across
different next tokens. Among distinct tokens, it progressively drops attention
weights, following the order of low to high co-occurrence between the key and
the query token in the training set. Interestingly, this procedure does not
lead to winner-takes-all, but decelerates due to a \emph{phase transition} that
is controllable by the learning rates of the two layers, leaving (almost) fixed
token combination. We verify this \textbf{\emph{scan and snap}} dynamics on
synthetic and real-world data (WikiText).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yuandong Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yiping Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Beidi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon Du&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18438">
<title>Reinforcement Learning with Human Feedback: Learning Dynamic Choices via Pessimism. (arXiv:2305.18438v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18438</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study offline Reinforcement Learning with Human Feedback
(RLHF) where we aim to learn the human&apos;s underlying reward and the MDP&apos;s
optimal policy from a set of trajectories induced by human choices. RLHF is
challenging for multiple reasons: large state space but limited human feedback,
the bounded rationality of human decisions, and the off-policy distribution
shift. In this paper, we focus on the Dynamic Discrete Choice (DDC) model for
modeling and understanding human choices. DCC, rooted in econometrics and
decision theory, is widely used to model a human decision-making process with
forward-looking and bounded rationality. We propose a
\underline{D}ynamic-\underline{C}hoice-\underline{P}essimistic-\underline{P}olicy-\underline{O}ptimization
(DCPPO) method. \ The method involves a three-stage process: The first step is
to estimate the human behavior policy and the state-action value function via
maximum likelihood estimation (MLE); the second step recovers the human reward
function via minimizing Bellman mean squared error using the learned value
functions; the third step is to plug in the learned reward and invoke
pessimistic value iteration for finding a near-optimal policy. With only
single-policy coverage (i.e., optimal policy) of the dataset, we prove that the
suboptimality of DCPPO almost matches the classical pessimistic offline RL
algorithm in terms of suboptimality&apos;s dependency on distribution shift and
dimension. To the best of our knowledge, this paper presents the first
theoretical guarantees for off-policy offline RLHF with dynamic discrete choice
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zihao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mengdi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18624">
<title>W-procer: Weighted Prototypical Contrastive Learning for Medical Few-Shot Named Entity Recognition. (arXiv:2305.18624v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18624</link>
<description rdf:parseType="Literal">&lt;p&gt;Contrastive learning has become a popular solution for few-shot Name Entity
Recognization (NER). The conventional configuration strives to reduce the
distance between tokens with the same labels and increase the distance between
tokens with different labels. The effect of this setup may, however, in the
medical domain, there are a lot of entities annotated as OUTSIDE (O), and they
are undesirably pushed apart to other entities that are not labeled as OUTSIDE
(O) by the current contrastive learning method end up with a noisy prototype
for the semantic representation of the label, though there are many OUTSIDE (O)
labeled entities are relevant to the labeled entities. To address this
challenge, we propose a novel method named Weighted Prototypical Contrastive
Learning for Medical Few Shot Named Entity Recognization (W-PROCER). Our
approach primarily revolves around constructing the prototype-based contractive
loss and weighting network. These components play a crucial role in assisting
the model in differentiating the negative samples from OUTSIDE (O) tokens and
enhancing the discrimination ability of contrastive learning. Experimental
results show that our proposed W-PROCER framework significantly outperforms the
strong baselines on the three medical benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mingchen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yang Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1&quot;&gt;Jeremy Yeung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Huixue Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1&quot;&gt;Huaiyuan Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Rui Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18777">
<title>Adaptive Conditional Quantile Neural Processes. (arXiv:2305.18777v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18777</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural processes are a family of probabilistic models that inherit the
flexibility of neural networks to parameterize stochastic processes. Despite
providing well-calibrated predictions, especially in regression problems, and
quick adaptation to new tasks, the Gaussian assumption that is commonly used to
represent the predictive likelihood fails to capture more complicated
distributions such as multimodal ones. To overcome this limitation, we propose
Conditional Quantile Neural Processes (CQNPs), a new member of the neural
processes family, which exploits the attractive properties of quantile
regression in modeling the distributions irrespective of their form. By
introducing an extension of quantile regression where the model learns to focus
on estimating informative quantiles, we show that the sampling efficiency and
prediction accuracy can be further enhanced. Our experiments with real and
synthetic datasets demonstrate substantial improvements in predictive
performance compared to the baselines, and better modeling of heterogeneous
distributions&apos; characteristics such as multimodality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohseni_P/0/1/0/all/0/1&quot;&gt;Peiman Mohseni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duffield_N/0/1/0/all/0/1&quot;&gt;Nick Duffield&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mallick_B/0/1/0/all/0/1&quot;&gt;Bani Mallick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasanzadeh_A/0/1/0/all/0/1&quot;&gt;Arman Hasanzadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.20002">
<title>Representer Point Selection for Explaining Regularized High-dimensional Models. (arXiv:2305.20002v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.20002</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel class of sample-based explanations we term
high-dimensional representers, that can be used to explain the predictions of a
regularized high-dimensional model in terms of importance weights for each of
the training samples. Our workhorse is a novel representer theorem for general
regularized high-dimensional models, which decomposes the model prediction in
terms of contributions from each of the training samples: with positive
(negative) values corresponding to positive (negative) impact training samples
to the model&apos;s prediction. We derive consequences for the canonical instances
of $\ell_1$ regularized sparse models, and nuclear norm regularized low-rank
models. As a case study, we further investigate the application of low-rank
models in the context of collaborative filtering, where we instantiate
high-dimensional representers for specific popular classes of models. Finally,
we study the empirical performance of our proposed methods on three real-world
binary classification datasets and two recommender system datasets. We also
showcase the utility of high-dimensional representers in explaining model
recommendations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsai_C/0/1/0/all/0/1&quot;&gt;Che-Ping Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1&quot;&gt;Eli Chien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hsiang-Fu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.00488">
<title>Reconstructing Graph Diffusion History from a Single Snapshot. (arXiv:2306.00488v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.00488</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion on graphs is ubiquitous with numerous high-impact applications. In
these applications, complete diffusion histories play an essential role in
terms of identifying dynamical patterns, reflecting on precaution actions, and
forecasting intervention effects. Despite their importance, complete diffusion
histories are rarely available and are highly challenging to reconstruct due to
ill-posedness, explosive search space, and scarcity of training data. To date,
few methods exist for diffusion history reconstruction. They are exclusively
based on the maximum likelihood estimation (MLE) formulation and require to
know true diffusion parameters. In this paper, we study an even harder problem,
namely reconstructing Diffusion history from A single SnapsHot} (DASH), where
we seek to reconstruct the history from only the final snapshot without knowing
true diffusion parameters. We start with theoretical analyses that reveal a
fundamental limitation of the MLE formulation. We prove: (a) estimation error
of diffusion parameters is unavoidable due to NP-hardness of diffusion
parameter estimation, and (b) the MLE formulation is sensitive to estimation
error of diffusion parameters. To overcome the inherent limitation of the MLE
formulation, we propose a novel barycenter formulation: finding the barycenter
of the posterior distribution of histories, which is provably stable against
the estimation error of diffusion parameters. We further develop an effective
solver named DIffusion hiTting Times with Optimal proposal (DITTO) by reducing
the problem to estimating posterior expected hitting times via the
Metropolis--Hastings Markov chain Monte Carlo method (M--H MCMC) and employing
an unsupervised graph neural network to learn an optimal proposal to accelerate
the convergence of M--H MCMC. We conduct extensive experiments to demonstrate
the efficacy of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1&quot;&gt;Ruizhong Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dingsu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1&quot;&gt;Lei Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1&quot;&gt;H. Vincent Poor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yifang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1&quot;&gt;Hanghang Tong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.00942">
<title>Train Offline, Test Online: A Real Robot Learning Benchmark. (arXiv:2306.00942v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2306.00942</link>
<description rdf:parseType="Literal">&lt;p&gt;Three challenges limit the progress of robot learning research: robots are
expensive (few labs can participate), everyone uses different robots (findings
do not generalize across labs), and we lack internet-scale robotics data. We
take on these challenges via a new benchmark: Train Offline, Test Online
(TOTO). TOTO provides remote users with access to shared robotic hardware for
evaluating methods on common tasks and an open-source dataset of these tasks
for offline training. Its manipulation task suite requires challenging
generalization to unseen objects, positions, and lighting. We present initial
results on TOTO comparing five pretrained visual representations and four
offline policy learning baselines, remotely contributed by five institutions.
The real promise of TOTO, however, lies in the future: we release the benchmark
for additional submissions from any user, enabling easy, direct comparison to
several methods without the need to obtain hardware or collect data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1&quot;&gt;Gaoyue Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dean_V/0/1/0/all/0/1&quot;&gt;Victoria Dean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srirama_M/0/1/0/all/0/1&quot;&gt;Mohan Kumar Srirama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajeswaran_A/0/1/0/all/0/1&quot;&gt;Aravind Rajeswaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pari_J/0/1/0/all/0/1&quot;&gt;Jyothish Pari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hatch_K/0/1/0/all/0/1&quot;&gt;Kyle Hatch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1&quot;&gt;Aryan Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1&quot;&gt;Tianhe Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinto_L/0/1/0/all/0/1&quot;&gt;Lerrel Pinto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhinav Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.01589">
<title>Transfer learning for atomistic simulations using GNNs and kernel mean embeddings. (arXiv:2306.01589v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.01589</link>
<description rdf:parseType="Literal">&lt;p&gt;Interatomic potentials learned using machine learning methods have been
successfully applied to atomistic simulations. However, deep learning pipelines
are notoriously data-hungry, while generating reference calculations is
computationally demanding. To overcome this difficulty, we propose a transfer
learning algorithm that leverages the ability of graph neural networks (GNNs)
in describing chemical environments, together with kernel mean embeddings. We
extract a feature map from GNNs pre-trained on the OC20 dataset and use it to
learn the potential energy surface from system-specific datasets of catalytic
processes. Our method is further enhanced by a flexible kernel function that
incorporates chemical species information, resulting in improved performance
and interpretability. We test our approach on a series of realistic datasets of
increasing complexity, showing excellent generalization and transferability
performance, and improving on methods that rely on GNNs or ridge regression
alone, as well as similar fine-tuning approaches. We make the code available to
the community at https://github.com/IsakFalk/atomistic_transfer_mekrr.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Falk_J/0/1/0/all/0/1&quot;&gt;John Falk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonati_L/0/1/0/all/0/1&quot;&gt;Luigi Bonati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Novelli_P/0/1/0/all/0/1&quot;&gt;Pietro Novelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parrinello_M/0/1/0/all/0/1&quot;&gt;Michele Parrinello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pontil_M/0/1/0/all/0/1&quot;&gt;Massimiliano Pontil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.02561">
<title>LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion. (arXiv:2306.02561v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.02561</link>
<description rdf:parseType="Literal">&lt;p&gt;We present LLM-Blender, an ensembling framework designed to attain
consistently superior performance by leveraging the diverse strengths of
multiple open-source large language models (LLMs). Our framework consists of
two modules: PairRanker and GenFuser, addressing the observation that optimal
LLMs for different examples can significantly vary. PairRanker employs a
specialized pairwise comparison method to distinguish subtle differences
between candidate outputs. It jointly encodes the input text and a pair of
candidates, using cross-attention encoders to determine the superior one. Our
results demonstrate that PairRanker exhibits the highest correlation with
ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates,
generating an improved output by capitalizing on their strengths and mitigating
their weaknesses. To facilitate large-scale evaluation, we introduce a
benchmark dataset, MixInstruct, which is a mixture of multiple instruction
datasets featuring oracle pairwise comparisons. Our LLM-Blender significantly
outperform individual LLMs and baseline methods across various metrics,
establishing a substantial performance gap.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1&quot;&gt;Dongfu Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1&quot;&gt;Xiang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Bill Yuchen Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.03828">
<title>Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How. (arXiv:2306.03828v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.03828</link>
<description rdf:parseType="Literal">&lt;p&gt;With the ever-increasing number of pretrained models, machine learning
practitioners are continuously faced with which pretrained model to use, and
how to finetune it for a new dataset. In this paper, we propose a methodology
that jointly searches for the optimal pretrained model and the hyperparameters
for finetuning it. Our method transfers knowledge about the performance of many
pretrained models with multiple hyperparameter configurations on a series of
datasets. To this aim, we evaluated over 20k hyperparameter configurations for
finetuning 24 pretrained image classification models on 87 datasets to generate
a large-scale meta-dataset. We meta-learn a multi-fidelity performance
predictor on the learning curves of this meta-dataset and use it for fast
hyperparameter optimization on new datasets. We empirically demonstrate that
our resulting approach can quickly select an accurate pretrained model for a
new dataset together with its optimal hyperparameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arango_S/0/1/0/all/0/1&quot;&gt;Sebastian Pineda Arango&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreira_F/0/1/0/all/0/1&quot;&gt;Fabio Ferreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadra_A/0/1/0/all/0/1&quot;&gt;Arlind Kadra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grabocka_J/0/1/0/all/0/1&quot;&gt;Josif Grabocka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04376">
<title>Label Shift Quantification with Robustness Guarantees via Distribution Feature Matching. (arXiv:2306.04376v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.04376</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantification learning deals with the task of estimating the target label
distribution under label shift. In this paper, we first present a unifying
framework, distribution feature matching (DFM), that recovers as particular
instances various estimators introduced in previous literature. We derive a
general performance bound for DFM procedures, improving in several key aspects
upon previous bounds derived in particular cases. We then extend this analysis
to study robustness of DFM procedures in the misspecified setting under
departure from the exact label shift hypothesis, in particular in the case of
contamination of the target by an unknown distribution. These theoretical
findings are confirmed by a detailed numerical study on simulated and
real-world datasets. We also introduce an efficient, scalable and robust
version of kernel-based DFM using the Random Fourier Feature principle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dussap_B/0/1/0/all/0/1&quot;&gt;Bastien Dussap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blanchard_G/0/1/0/all/0/1&quot;&gt;Gilles Blanchard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cherief_Abdellatif_B/0/1/0/all/0/1&quot;&gt;Badr-Eddine Ch&amp;#xe9;rief-Abdellatif&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04527">
<title>ContriMix: Unsupervised disentanglement of content and attribute for domain generalization in microscopy image analysis. (arXiv:2306.04527v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.04527</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain generalization is critical for real-world applications of machine
learning models to microscopy images, including histopathology and fluorescence
imaging. Artifacts in histopathology arise through a complex combination of
factors relating to tissue collection and laboratory processing, as well as
factors intrinsic to patient samples. In fluorescence imaging, these artifacts
stem from variations across experimental batches. The complexity and subtlety
of these artifacts make the enumeration of data domains intractable. Therefore,
augmentation-based methods of domain generalization that require domain
identifiers and manual fine-tuning are inadequate in this setting. To overcome
this challenge, we introduce ContriMix, a domain generalization technique that
learns to generate synthetic images by disentangling and permuting the
biological content (&quot;content&quot;) and technical variations (&quot;attributes&quot;) in
microscopy images. ContriMix does not rely on domain identifiers or handcrafted
augmentations and makes no assumptions about the input characteristics of
images. We assess the performance of ContriMix on two pathology datasets
(Camelyon17-WILDS and a prostate cell classification dataset) and one
fluorescence microscopy dataset (RxRx1-WILDS). ContriMix outperforms current
state-of-the-art methods in all datasets, motivating its usage for microscopy
image analysis in real-world settings where domain information is hard to come
by.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Tan H. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Juyal_D/0/1/0/all/0/1&quot;&gt;Dinkar Juyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Prakash_A/0/1/0/all/0/1&quot;&gt;Aaditya Prakash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nofallah_S/0/1/0/all/0/1&quot;&gt;Shima Nofallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shah_C/0/1/0/all/0/1&quot;&gt;Chintan Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gullapally_S/0/1/0/all/0/1&quot;&gt;Sai Chowdary Gullapally&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Griffin_M/0/1/0/all/0/1&quot;&gt;Michael Griffin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sampat_A/0/1/0/all/0/1&quot;&gt;Anand Sampat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Abel_J/0/1/0/all/0/1&quot;&gt;John Abel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Justin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Taylor_Weiner_A/0/1/0/all/0/1&quot;&gt;Amaro Taylor-Weiner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04634">
<title>On the Reliability of Watermarks for Large Language Models. (arXiv:2306.04634v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.04634</link>
<description rdf:parseType="Literal">&lt;p&gt;As LLMs become commonplace, machine-generated text has the potential to flood
the internet with spam, social media bots, and valueless content. Watermarking
is a simple and effective strategy for mitigating such harms by enabling the
detection and documentation of LLM-generated text. Yet a crucial question
remains: How reliable is watermarking in realistic settings in the wild? There,
watermarked text may be modified to suit a user&apos;s needs, or entirely rewritten
to avoid detection.
&lt;/p&gt;
&lt;p&gt;We study the robustness of watermarked text after it is re-written by humans,
paraphrased by a non-watermarked LLM, or mixed into a longer hand-written
document. We find that watermarks remain detectable even after human and
machine paraphrasing. While these attacks dilute the strength of the watermark,
paraphrases are statistically likely to leak n-grams or even longer fragments
of the original text, resulting in high-confidence detections when enough
tokens are observed. For example, after strong human paraphrasing the watermark
is detectable after observing 800 tokens on average, when setting a 1e-5 false
positive rate. We also consider a range of new detection schemes that are
sensitive to short spans of watermarked text embedded inside a large document,
and we compare the robustness of watermarking to other kinds of detectors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirchenbauer_J/0/1/0/all/0/1&quot;&gt;John Kirchenbauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1&quot;&gt;Jonas Geiping&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_M/0/1/0/all/0/1&quot;&gt;Manli Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saifullah_K/0/1/0/all/0/1&quot;&gt;Khalid Saifullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_K/0/1/0/all/0/1&quot;&gt;Kezhi Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernando_K/0/1/0/all/0/1&quot;&gt;Kasun Fernando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1&quot;&gt;Aniruddha Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1&quot;&gt;Micah Goldblum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1&quot;&gt;Tom Goldstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04940">
<title>Layer-level activation mechanism. (arXiv:2306.04940v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.04940</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a novel activation mechanism aimed at establishing
layer-level activation (LayerAct) functions. These functions are designed to be
more noise-robust compared to traditional element-level activation functions by
reducing the layer-level fluctuation of the activation outputs due to shift in
inputs. Moreover, the LayerAct functions achieve a zero-like mean activation
output without restricting the activation output space. We present an analysis
and experiments demonstrating that LayerAct functions exhibit superior
noise-robustness compared to element-level activation functions, and
empirically show that these functions have a zero-like mean activation.
Experimental results on three benchmark image classification tasks show that
LayerAct functions excel in handling noisy image datasets, outperforming
element-level activation functions, while the performance on clean datasets is
also superior in most cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1&quot;&gt;Kihyuk Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_C/0/1/0/all/0/1&quot;&gt;Chiehyeon Lim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.06674">
<title>Self-supervised Equality Embedded Deep Lagrange Dual for Approximate Constrained Optimization. (arXiv:2306.06674v4 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2306.06674</link>
<description rdf:parseType="Literal">&lt;p&gt;Conventional solvers are often computationally expensive for constrained
optimization, particularly in large-scale and time-critical problems. While
this leads to a growing interest in using neural networks (NNs) as fast optimal
solution approximators, incorporating the constraints with NNs is challenging.
In this regard, we propose deep Lagrange dual with equality embedding
(DeepLDE), a framework that learns to find an optimal solution without using
labels. To ensure feasible solutions, we embed equality constraints into the
NNs and train the NNs using the primal-dual method to impose inequality
constraints. Furthermore, we prove the convergence of DeepLDE and show that the
primal-dual learning method alone cannot ensure equality constraints without
the help of equality embedding. Simulation results on convex, non-convex, and
AC optimal power flow (AC-OPF) problems show that the proposed DeepLDE achieves
the smallest optimality gap among all the NN-based approaches while always
ensuring feasible solutions. Furthermore, the computation time of the proposed
method is about 5 to 250 times faster than DC3 and the conventional solvers in
solving constrained convex, non-convex optimization, and/or AC-OPF.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Minsoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hongseok Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.07024">
<title>DRCFS: Doubly Robust Causal Feature Selection. (arXiv:2306.07024v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.07024</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowing the features of a complex system that are highly relevant to a
particular target variable is of fundamental interest in many areas of science.
Existing approaches are often limited to linear settings, sometimes lack
guarantees, and in most cases, do not scale to the problem at hand, in
particular to images. We propose DRCFS, a doubly robust feature selection
method for identifying the causal features even in nonlinear and high
dimensional settings. We provide theoretical guarantees, illustrate necessary
conditions for our assumptions, and perform extensive experiments across a wide
range of simulated and semi-synthetic datasets. DRCFS significantly outperforms
existing state-of-the-art methods, selecting robust features even in
challenging highly non-linear and high-dimensional problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quinzan_F/0/1/0/all/0/1&quot;&gt;Francesco Quinzan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soleymani_A/0/1/0/all/0/1&quot;&gt;Ashkan Soleymani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1&quot;&gt;Patrik Jaillet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rojas_C/0/1/0/all/0/1&quot;&gt;Cristian R. Rojas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1&quot;&gt;Stefan Bauer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.07743">
<title>V-LoL: A Diagnostic Dataset for Visual Logical Learning. (arXiv:2306.07743v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2306.07743</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the successes of recent developments in visual AI, different
shortcomings still exist; from missing exact logical reasoning, to abstract
generalization abilities, to understanding complex and noisy scenes.
Unfortunately, existing benchmarks, were not designed to capture more than a
few of these aspects. Whereas deep learning datasets focus on visually complex
data but simple visual reasoning tasks, inductive logic datasets involve
complex logical learning tasks, however, lack the visual component. To address
this, we propose the visual logical learning dataset, V-LoL, that seamlessly
combines visual and logical challenges. Notably, we introduce the first
instantiation of V-LoL, V-LoL-Trains, -- a visual rendition of a classic
benchmark in symbolic AI, the Michalski train problem. By incorporating
intricate visual scenes and flexible logical reasoning tasks within a versatile
framework, V-LoL-Trains provides a platform for investigating a wide range of
visual logical learning challenges. We evaluate a variety of AI systems
including traditional symbolic AI, neural AI, as well as neuro-symbolic AI. Our
evaluations demonstrate that even state-of-the-art AI faces difficulties in
dealing with visual logical learning challenges, highlighting unique advantages
and limitations specific to each methodology. Overall, V-LoL opens up new
avenues for understanding and enhancing current abilities in visual logical
learning for AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helff_L/0/1/0/all/0/1&quot;&gt;Lukas Helff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stammer_W/0/1/0/all/0/1&quot;&gt;Wolfgang Stammer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shindo_H/0/1/0/all/0/1&quot;&gt;Hikaru Shindo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhami_D/0/1/0/all/0/1&quot;&gt;Devendra Singh Dhami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1&quot;&gt;Kristian Kersting&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.07812">
<title>Automated 3D Pre-Training for Molecular Property Prediction. (arXiv:2306.07812v2 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2306.07812</link>
<description rdf:parseType="Literal">&lt;p&gt;Molecular property prediction is an important problem in drug discovery and
materials science. As geometric structures have been demonstrated necessary for
molecular property prediction, 3D information has been combined with various
graph learning methods to boost prediction performance. However, obtaining the
geometric structure of molecules is not feasible in many real-world
applications due to the high computational cost. In this work, we propose a
novel 3D pre-training framework (dubbed 3D PGT), which pre-trains a model on 3D
molecular graphs, and then fine-tunes it on molecular graphs without 3D
structures. Based on fact that bond length, bond angle, and dihedral angle are
three basic geometric descriptors corresponding to a complete molecular 3D
conformer, we first develop a multi-task generative pre-train framework based
on these three attributes. Next, to automatically fuse these three generative
tasks, we design a surrogate metric using the \textit{total energy} to search
for weight distribution of the three pretext task since total energy
corresponding to the quality of 3D conformer.Extensive experiments on 2D
molecular graphs are conducted to demonstrate the accuracy, efficiency and
generalization ability of the proposed 3D PGT compared to various pre-training
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Huan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tu_W/0/1/0/all/0/1&quot;&gt;Weiwei Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yao_Q/0/1/0/all/0/1&quot;&gt;Quanming Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.07874">
<title>Taxonomy-Structured Domain Adaptation. (arXiv:2306.07874v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.07874</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain adaptation aims to mitigate distribution shifts among different
domains. However, traditional formulations are mostly limited to categorical
domains, greatly simplifying nuanced domain relationships in the real world. In
this work, we tackle a generalization with taxonomy-structured domains, which
formalizes domains with nested, hierarchical similarity structures such as
animal species and product catalogs. We build on the classic adversarial
framework and introduce a novel taxonomist, which competes with the adversarial
discriminator to preserve the taxonomy information. The equilibrium recovers
the classic adversarial domain adaptation&apos;s solution if given a non-informative
domain taxonomy (e.g., a flat taxonomy where all leaf nodes connect to the root
node) while yielding non-trivial results with other taxonomies. Empirically,
our method achieves state-of-the-art performance on both synthetic and
real-world datasets with successful adaptation. Code is available at
https://github.com/Wang-ML-Lab/TSDA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tianyi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zihao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1&quot;&gt;Hao He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_G/0/1/0/all/0/1&quot;&gt;Guang-Yuan Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1&quot;&gt;Guang-He Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hao Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.07961">
<title>Differentiating Metropolis-Hastings to Optimize Intractable Densities. (arXiv:2306.07961v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.07961</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop an algorithm for automatic differentiation of Metropolis-Hastings
samplers, allowing us to differentiate through probabilistic inference, even if
the model has discrete components within it. Our approach fuses recent advances
in stochastic automatic differentiation with traditional Markov chain coupling
schemes, providing an unbiased and low-variance gradient estimator. This allows
us to apply gradient-based optimization to objectives expressed as expectations
over intractable target densities. We demonstrate our approach by finding an
ambiguous observation in a Gaussian mixture model and by maximizing the
specific heat in an Ising model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arya_G/0/1/0/all/0/1&quot;&gt;Gaurav Arya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Seyer_R/0/1/0/all/0/1&quot;&gt;Ruben Seyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schafer_F/0/1/0/all/0/1&quot;&gt;Frank Sch&amp;#xe4;fer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chandra_K/0/1/0/all/0/1&quot;&gt;Kartik Chandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lew_A/0/1/0/all/0/1&quot;&gt;Alexander K. Lew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huot_M/0/1/0/all/0/1&quot;&gt;Mathieu Huot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mansinghka_V/0/1/0/all/0/1&quot;&gt;Vikash K. Mansinghka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ragan_Kelley_J/0/1/0/all/0/1&quot;&gt;Jonathan Ragan-Kelley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rackauckas_C/0/1/0/all/0/1&quot;&gt;Christopher Rackauckas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schauer_M/0/1/0/all/0/1&quot;&gt;Moritz Schauer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.08984">
<title>Tree Variational Autoencoders. (arXiv:2306.08984v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.08984</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new generative hierarchical clustering model that learns a
flexible tree-based posterior distribution over latent variables. The proposed
Tree Variational Autoencoder (TreeVAE) hierarchically divides samples according
to their intrinsic characteristics, shedding light on hidden structure in the
data. It adapts its architecture to discover the optimal tree for encoding
dependencies between latent variables. The proposed tree-based generative
architecture permits lightweight conditional inference and improves generative
performance by utilizing specialized leaf decoders. We show that TreeVAE
uncovers underlying clusters in the data and finds meaningful hierarchical
relations between the different groups on a variety of datasets, including
real-world imaging data. We present empirically that TreeVAE provides a more
competitive log-likelihood lower bound than the sequential counterparts.
Finally, due to its generative nature, TreeVAE is able to generate new samples
from the discovered clusters via conditional sampling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manduchi_L/0/1/0/all/0/1&quot;&gt;Laura Manduchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vandenhirtz_M/0/1/0/all/0/1&quot;&gt;Moritz Vandenhirtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryser_A/0/1/0/all/0/1&quot;&gt;Alain Ryser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1&quot;&gt;Julia Vogt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.09548">
<title>Online Heavy-tailed Change-point detection. (arXiv:2306.09548v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.09548</link>
<description rdf:parseType="Literal">&lt;p&gt;We study algorithms for online change-point detection (OCPD), where samples
that are potentially heavy-tailed, are presented one at a time and a change in
the underlying mean must be detected as early as possible. We present an
algorithm based on clipped Stochastic Gradient Descent (SGD), that works even
if we only assume that the second moment of the data generating process is
bounded. We derive guarantees on worst-case, finite-sample false-positive rate
(FPR) over the family of all distributions with bounded second moment. Thus,
our method is the first OCPD algorithm that guarantees finite-sample FPR, even
if the data is high dimensional and the underlying distributions are
heavy-tailed. The technical contribution of our paper is to show that
clipped-SGD can estimate the mean of a random vector and simultaneously provide
confidence bounds at all confidence values. We combine this robust estimate
with a union bound argument and construct a sequential change-point algorithm
with finite-sample FPR guarantees. We show empirically that our algorithm works
well in a variety of situations, whether the underlying data are heavy-tailed,
light-tailed, high dimensional or discrete. No other algorithm achieves bounded
FPR theoretically or empirically, over all settings we study simultaneously.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sankararaman_A/0/1/0/all/0/1&quot;&gt;Abishek Sankararaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balakrishnan/0/1/0/all/0/1&quot;&gt;Balakrishnan&lt;/a&gt; (Murali) &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Narayanaswamy/0/1/0/all/0/1&quot;&gt;Narayanaswamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.10234">
<title>Federated Few-shot Learning. (arXiv:2306.10234v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.10234</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) enables multiple clients to collaboratively learn a
machine learning model without exchanging their own local data. In this way,
the server can exploit the computational power of all clients and train the
model on a larger set of data samples among all clients. Although such a
mechanism is proven to be effective in various fields, existing works generally
assume that each client preserves sufficient data for training. In practice,
however, certain clients may only contain a limited number of samples (i.e.,
few-shot samples). For example, the available photo data taken by a specific
user with a new mobile device is relatively rare. In this scenario, existing FL
efforts typically encounter a significant performance drop on these clients.
Therefore, it is urgent to develop a few-shot model that can generalize to
clients with limited data under the FL scenario. In this paper, we refer to
this novel problem as federated few-shot learning. Nevertheless, the problem
remains challenging due to two major reasons: the global data variance among
clients (i.e., the difference in data distributions among clients) and the
local data insufficiency in each client (i.e., the lack of adequate local data
for training). To overcome these two challenges, we propose a novel federated
few-shot learning framework with two separately updated models and dedicated
training strategies to reduce the adverse impact of global data variance and
local data insufficiency. Extensive experiments on four prevalent datasets that
cover news articles and images validate the effectiveness of our framework
compared with the state-of-the-art baselines. Our code is provided at
https://github.com/SongW-SW/F2L.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Song Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1&quot;&gt;Xingbo Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1&quot;&gt;Kaize Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huiyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jundong Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.10640">
<title>Evolving Strategies for Competitive Multi-Agent Search. (arXiv:2306.10640v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/2306.10640</link>
<description rdf:parseType="Literal">&lt;p&gt;While evolutionary computation is well suited for automatic discovery in
engineering, it can also be used to gain insight into how humans and
organizations could perform more effectively. Using a real-world problem of
innovation search in organizations as the motivating example, this article
first formalizes human creative problem solving as competitive multi-agent
search (CMAS). CMAS is different from existing single-agent and team search
problems in that the agents interact through knowledge of other agents&apos;
searches and through the dynamic changes in the search landscape that result
from these searches. The main hypothesis is that evolutionary computation can
be used to discover effective strategies for CMAS; this hypothesis is verified
in a series of experiments on the NK model, i.e.\ partially correlated and
tunably rugged fitness landscapes. Different specialized strategies are evolved
for each different competitive environment, and also general strategies that
perform well across environments. These strategies are more effective and more
complex than hand-designed strategies and a strategy based on traditional tree
search. Using a novel spherical visualization of such landscapes, insight is
gained about how successful strategies work, e.g.\ by tracking positive changes
in the landscape. The article thus provides a possible framework for studying
various human creative activities as competitive multi-agent search in the
future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bahceci_E/0/1/0/all/0/1&quot;&gt;Erkin Bahceci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katila_R/0/1/0/all/0/1&quot;&gt;Riitta Katila&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1&quot;&gt;Risto Miikkulainen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.10946">
<title>Att-KGCN: Tourist Attractions Recommendation System by using Attention mechanism and Knowledge Graph Convolution Network. (arXiv:2306.10946v4 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2306.10946</link>
<description rdf:parseType="Literal">&lt;p&gt;The recommendation algorithm based on knowledge graphs is at a relatively
mature stage. However, there are still some problems in the recommendation of
specific areas. For example, in the tourism field, selecting suitable tourist
attraction attributes process is complicated as the recommendation basis for
tourist attractions. In this paper, we propose the improved Attention Knowledge
Graph Convolution Network model, named ($Att-KGCN$), which automatically
discovers the neighboring entities of the target scenic spot semantically. The
attention layer aggregates relatively similar locations and represents them
with an adjacent vector. Then, according to the tourist&apos;s preferred choices,
the model predicts the probability of similar spots as a recommendation system.
A knowledge graph dataset of tourist attractions used based on tourism data on
Socotra Island-Yemen. Through experiments, it is verified that the Attention
Knowledge Graph Convolution Network has a good effect on the recommendation of
tourist attractions and can make more recommendations for tourists&apos; choices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mubarak_A/0/1/0/all/0/1&quot;&gt;Ahmad A. Mubarak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;JingJing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1&quot;&gt;Han Cao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11667">
<title>G-NM: A Group of Numerical Time Series Prediction Models. (arXiv:2306.11667v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11667</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we focus on the development and implementation of a
comprehensive ensemble of numerical time series forecasting models,
collectively referred to as the Group of Numerical Time Series Prediction Model
(G-NM). This inclusive set comprises traditional models such as Autoregressive
Integrated Moving Average (ARIMA), Holt-Winters&apos; method, and Support Vector
Regression (SVR), in addition to modern neural network models including
Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). G-NM is
explicitly constructed to augment our predictive capabilities related to
patterns and trends inherent in complex natural phenomena. By utilizing time
series data relevant to these events, G-NM facilitates the prediction of such
phenomena over extended periods. The primary objective of this research is to
both advance our understanding of such occurrences and to significantly enhance
the accuracy of our forecasts. G-NM encapsulates both linear and non-linear
dependencies, seasonalities, and trends present in time series data. Each of
these models contributes distinct strengths, from ARIMA&apos;s resilience in
handling linear trends and seasonality, SVR&apos;s proficiency in capturing
non-linear patterns, to LSTM&apos;s adaptability in modeling various components of
time series data. Through the exploitation of the G-NM potential, we strive to
advance the state-of-the-art in large-scale time series forecasting models. We
anticipate that this research will represent a significant stepping stone in
our ongoing endeavor to comprehend and forecast the complex events that
constitute the natural world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_J/0/1/0/all/0/1&quot;&gt;Juyoung Yun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11768">
<title>A Systematic Survey in Geometric Deep Learning for Structure-based Drug Design. (arXiv:2306.11768v3 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11768</link>
<description rdf:parseType="Literal">&lt;p&gt;Structure-based drug design (SBDD), which utilizes the three-dimensional
geometry of proteins to identify potential drug candidates, is becoming
increasingly vital in drug discovery. However, traditional methods based on
physiochemical modeling and experts&apos; domain knowledge are time-consuming and
laborious. The recent advancements in geometric deep learning, which integrates
and processes 3D geometric data, coupled with the availability of accurate
protein 3D structure predictions from tools like AlphaFold, have significantly
propelled progress in structure-based drug design. In this paper, we
systematically review the recent progress of geometric deep learning for
structure-based drug design. We start with a brief discussion of the mainstream
tasks in structure-based drug design, commonly used 3D protein representations
and representative predictive/generative models. Then we delve into detailed
reviews for each task (binding site prediction, binding pose generation,
\emph{de novo} molecule generation, linker design, and binding affinity
prediction), including the problem setup, representative methods, datasets, and
evaluation metrics. Finally, we conclude this survey with the current
challenges and highlight potential opportunities of geometric deep learning for
structure-based drug design.We curate a GitHub repo containing the related
papers \url{https://github.com/zaixizhang/Awesome-SBDD}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zaixi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Jiaxian Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chen_E/0/1/0/all/0/1&quot;&gt;Enhong Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12594">
<title>State-wise Constrained Policy Optimization. (arXiv:2306.12594v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12594</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement Learning (RL) algorithms have shown tremendous success in
simulation environments, but their application to real-world problems faces
significant challenges, with safety being a major concern. In particular,
enforcing state-wise constraints is essential for many challenging tasks such
as autonomous driving and robot manipulation. However, existing safe RL
algorithms under the framework of Constrained Markov Decision Process (CMDP) do
not consider state-wise constraints. To address this gap, we propose State-wise
Constrained Policy Optimization (SCPO), the first general-purpose policy search
algorithm for state-wise constrained reinforcement learning. SCPO provides
guarantees for state-wise constraint satisfaction in expectation. In
particular, we introduce the framework of Maximum Markov Decision Process, and
prove that the worst-case safety violation is bounded under SCPO. We
demonstrate the effectiveness of our approach on training neural network
policies for extensive robot locomotion tasks, where the agent must satisfy a
variety of state-wise safety constraints. Our results show that SCPO
significantly outperforms existing methods and can handle state-wise
constraints in high-dimensional robotics tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Weiye Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Rui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yifan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1&quot;&gt;Tianhao Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Changliu Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12640">
<title>On Addressing the Limitations of Graph Neural Networks. (arXiv:2306.12640v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12640</link>
<description rdf:parseType="Literal">&lt;p&gt;This report gives a summary of two problems about graph convolutional
networks (GCNs): over-smoothing and heterophily challenges, and outlines future
directions to explore.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luan_S/0/1/0/all/0/1&quot;&gt;Sitao Luan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12729">
<title>MP3: Movement Primitive-Based (Re-)Planning Policy. (arXiv:2306.12729v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12729</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel deep reinforcement learning (RL) approach called
Movement Primitive-based Planning Policy (MP3). By integrating movement
primitives (MPs) into the deep RL framework, MP3 enables the generation of
smooth trajectories throughout the whole learning process while effectively
learning from sparse and non-Markovian rewards. Additionally, MP3 maintains the
capability to adapt to changes in the environment during execution. Although
many early successes in robot RL have been achieved by combining RL with MPs,
these approaches are often limited to learning single stroke-based motions,
lacking the ability to adapt to task variations or adjust motions during
execution. Building upon our previous work, which introduced an episode-based
RL method for the non-linear adaptation of MP parameters to different task
variations, this paper extends the approach to incorporating replanning
strategies. This allows adaptation of the MP parameters throughout motion
execution, addressing the lack of online motion adaptation in stochastic
domains requiring feedback. We compared our approach against state-of-the-art
deep RL and RL with MPs methods. The results demonstrated improved performance
in sophisticated, sparse reward settings and in domains requiring replanning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Otto_F/0/1/0/all/0/1&quot;&gt;Fabian Otto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hongyi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celik_O/0/1/0/all/0/1&quot;&gt;Onur Celik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Ge Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lioutikov_R/0/1/0/all/0/1&quot;&gt;Rudolf Lioutikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1&quot;&gt;Gerhard Neumann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.13800">
<title>A First Order Meta Stackelberg Method for Robust Federated Learning. (arXiv:2306.13800v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.13800</link>
<description rdf:parseType="Literal">&lt;p&gt;Previous research has shown that federated learning (FL) systems are exposed
to an array of security risks. Despite the proposal of several defensive
strategies, they tend to be non-adaptive and specific to certain types of
attacks, rendering them ineffective against unpredictable or adaptive threats.
This work models adversarial federated learning as a Bayesian Stackelberg
Markov game (BSMG) to capture the defender&apos;s incomplete information of various
attack types. We propose meta-Stackelberg learning (meta-SL), a provably
efficient meta-learning algorithm, to solve the equilibrium strategy in BSMG,
leading to an adaptable FL defense. We demonstrate that meta-SL converges to
the first-order $\varepsilon$-equilibrium point in $O(\varepsilon^{-2})$
gradient iterations, with $O(\varepsilon^{-4})$ samples needed per iteration,
matching the state of the art. Empirical evidence indicates that our
meta-Stackelberg framework performs exceptionally well against potent model
poisoning and backdoor attacks of an uncertain nature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yunian Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Henger Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1&quot;&gt;Tianyi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zizhan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1&quot;&gt;Quanyan Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.14288">
<title>Near Optimal Heteroscedastic Regression with Symbiotic Learning. (arXiv:2306.14288v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.14288</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of heteroscedastic linear regression, where, given
$n$ samples $(\mathbf{x}_i, y_i)$ from $y_i = \langle \mathbf{w}^{*},
\mathbf{x}_i \rangle + \epsilon_i \cdot \langle \mathbf{f}^{*}, \mathbf{x}_i
\rangle$ with $\mathbf{x}_i \sim N(0,\mathbf{I})$, $\epsilon_i \sim N(0,1)$, we
aim to estimate $\mathbf{w}^{*}$. Beyond classical applications of such models
in statistics, econometrics, time series analysis etc., it is also particularly
relevant in machine learning when data is collected from multiple sources of
varying but apriori unknown quality. Our work shows that we can estimate
$\mathbf{w}^{*}$ in squared norm up to an error of
$\tilde{O}\left(\|\mathbf{f}^{*}\|^2 \cdot \left(\frac{1}{n} +
\left(\frac{d}{n}\right)^2\right)\right)$ and prove a matching lower bound
(upto log factors). This represents a substantial improvement upon the previous
best known upper bound of $\tilde{O}\left(\|\mathbf{f}^{*}\|^2\cdot
\frac{d}{n}\right)$. Our algorithm is an alternating minimization procedure
with two key subroutines 1. An adaptation of the classical weighted least
squares heuristic to estimate $\mathbf{w}^{*}$, for which we provide the first
non-asymptotic guarantee. 2. A nonconvex pseudogradient descent procedure for
estimating $\mathbf{f}^{*}$ inspired by phase retrieval. As corollaries, we
obtain fast non-asymptotic rates for two important problems, linear regression
with multiplicative noise and phase retrieval with multiplicative noise, both
of which are of independent interest. Beyond this, the proof of our lower
bound, which involves a novel adaptation of LeCam&apos;s method for handling
infinite mutual information quantities (thereby preventing a direct application
of standard techniques like Fano&apos;s method), could also be of broader interest
for establishing lower bounds for other heteroscedastic or heavy-tailed
statistical problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baby_D/0/1/0/all/0/1&quot;&gt;Dheeraj Baby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Aniket Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nagaraj_D/0/1/0/all/0/1&quot;&gt;Dheeraj Nagaraj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Netrapalli_P/0/1/0/all/0/1&quot;&gt;Praneeth Netrapalli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.14759">
<title>PMaF: Deep Declarative Layers for Principal Matrix Features. (arXiv:2306.14759v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.14759</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore two differentiable deep declarative layers, namely least squares
on sphere (LESS) and implicit eigen decomposition (IED), for learning the
principal matrix features (PMaF). It can be used to represent data features
with a low-dimensional vector containing dominant information from a
high-dimensional matrix. We first solve the problems with iterative
optimization in the forward pass and then backpropagate the solution for
implicit gradients under a bi-level optimization framework. Particularly,
adaptive descent steps with the backtracking line search method and descent
decay in the tangent space are studied to improve the forward pass efficiency
of LESS. Meanwhile, exploited data structures are used to greatly reduce the
computational complexity in the backward pass of LESS and IED. Empirically, we
demonstrate the superiority of our layers over the off-the-shelf baselines by
comparing the solution optimality and computational requirements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yanbin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1&quot;&gt;Stephen Gould&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.14891">
<title>Fuzzy-Conditioned Diffusion and Diffusion Projection Attention Applied to Facial Image Correction. (arXiv:2306.14891v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.14891</link>
<description rdf:parseType="Literal">&lt;p&gt;Image diffusion has recently shown remarkable performance in image synthesis
and implicitly as an image prior. Such a prior has been used with conditioning
to solve the inpainting problem, but only supporting binary user-based
conditioning. We derive a fuzzy-conditioned diffusion, where implicit diffusion
priors can be exploited with controllable strength. Our fuzzy conditioning can
be applied pixel-wise, enabling the modification of different image components
to varying degrees. Additionally, we propose an application to facial image
correction, where we combine our fuzzy-conditioned diffusion with
diffusion-derived attention maps. Our map estimates the degree of anomaly, and
we obtain it by projecting on the diffusion space. We show how our approach
also leads to interpretable and autonomous facial image correction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helou_M/0/1/0/all/0/1&quot;&gt;Majed El Helou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.15156">
<title>Learning non-Markovian Decision-Making from State-only Sequences. (arXiv:2306.15156v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.15156</link>
<description rdf:parseType="Literal">&lt;p&gt;Conventional imitation learning assumes access to the actions of
demonstrators, but these motor signals are often non-observable in naturalistic
settings. Additionally, sequential decision-making behaviors in these settings
can deviate from the assumptions of a standard Markov Decision Process (MDP).
To address these challenges, we explore deep generative modeling of state-only
sequences with non-Markov Decision Process (nMDP), where the policy is an
energy-based prior in the latent space of the state transition generator. We
develop maximum likelihood estimation to achieve model-based imitation, which
involves short-run MCMC sampling from the prior and importance sampling for the
posterior. The learned model enables \textit{decision-making as inference}:
model-free policy execution is equivalent to prior sampling, model-based
planning is posterior sampling initialized from the policy. We demonstrate the
efficacy of the proposed method in a prototypical path planning task with
non-Markovian constraints and show that the learned model exhibits strong
performances in challenging domains from the MuJoCo suite.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_A/0/1/0/all/0/1&quot;&gt;Aoyang Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1&quot;&gt;Feng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1&quot;&gt;Sirui Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.15538">
<title>DataCI: A Platform for Data-Centric AI on Streaming Data. (arXiv:2306.15538v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2306.15538</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce DataCI, a comprehensive open-source platform designed
specifically for data-centric AI in dynamic streaming data settings. DataCI
provides 1) an infrastructure with rich APIs for seamless streaming dataset
management, data-centric pipeline development and evaluation on streaming
scenarios, 2) an carefully designed versioning control function to track the
pipeline lineage, and 3) an intuitive graphical interface for a better
interactive user experience. Preliminary studies and demonstrations attest to
the easy-to-use and effectiveness of DataCI, highlighting its potential to
revolutionize the practice of data-centric AI in streaming data contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huaizheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yizheng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanming Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.15656">
<title>SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate via Compiler Co-design. (arXiv:2306.15656v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.15656</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces SparseOptimizer, a novel deep learning optimizer that
exploits Moreau-Yosida regularization to naturally induce sparsity in large
language models such as BERT, ALBERT and GPT. Key to the design of
SparseOptimizer is an embedded shrinkage operator, which imparts sparsity
directly within the optimization process. This operator, backed by a sound
theoretical framework, includes an analytical solution, thereby reinforcing the
optimizer&apos;s robustness and efficacy. Crucially, SparseOptimizer&apos;s plug-and-play
functionality eradicates the need for code modifications, making it a
universally adaptable tool for a wide array of large language models. Empirical
evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2
confirm that SparseBERT and SparseALBERT, when sparsified using
SparseOptimizer, achieve performance comparable to their dense counterparts,
BERT and ALBERT, while significantly reducing their parameter count. Further,
this work proposes an innovative optimizer-compiler co-design strategy,
demonstrating the potential of inference acceleration (\textbf{3.37x},
\textbf{6.30x}, and \textbf{7.15x} in comparison with Pytorch, TensorFlow, and
LLVM generic compile, respectively) in SparseBERT when paired with an
appropriately designed compiler. This study represents a significant step
forward in the evolution of efficient, scalable, and high-performing large
language models, setting a precedent for future exploration and optimization in
this domain. The SparseOptimizer code and SparseALBERT model will be publicly
available upon paper acceptance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1&quot;&gt;Fu-Ming Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.15868">
<title>GraSS: Contrastive Learning with Gradient Guided Sampling Strategy for Remote Sensing Image Semantic Segmentation. (arXiv:2306.15868v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.15868</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised contrastive learning (SSCL) has achieved significant
milestones in remote sensing image (RSI) understanding. Its essence lies in
designing an unsupervised instance discrimination pretext task to extract image
features from a large number of unlabeled images that are beneficial for
downstream tasks. However, existing instance discrimination based SSCL suffer
from two limitations when applied to the RSI semantic segmentation task: 1)
Positive sample confounding issue; 2) Feature adaptation bias. It introduces a
feature adaptation bias when applied to semantic segmentation tasks that
require pixel-level or object-level features. In this study, We observed that
the discrimination information can be mapped to specific regions in RSI through
the gradient of unsupervised contrastive loss, these specific regions tend to
contain singular ground objects. Based on this, we propose contrastive learning
with Gradient guided Sampling Strategy (GraSS) for RSI semantic segmentation.
GraSS consists of two stages: Instance Discrimination warm-up (ID warm-up) and
Gradient guided Sampling contrastive training (GS training). The ID warm-up
aims to provide initial discrimination information to the contrastive loss
gradients. The GS training stage aims to utilize the discrimination information
contained in the contrastive loss gradients and adaptively select regions in
RSI patches that contain more singular ground objects, in order to construct
new positive and negative samples. Experimental results on three open datasets
demonstrate that GraSS effectively enhances the performance of SSCL in
high-resolution RSI semantic segmentation. Compared to seven baseline methods
from five different types of SSCL, GraSS achieves an average improvement of
1.57\% and a maximum improvement of 3.58\% in terms of mean intersection over
the union. The source code is available at https://github.com/GeoX-Lab/GraSS
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhaoyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zhen Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1&quot;&gt;Chao Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yunsheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1&quot;&gt;Chengli Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haifeng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.15969">
<title>Separable Physics-Informed Neural Networks. (arXiv:2306.15969v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.15969</link>
<description rdf:parseType="Literal">&lt;p&gt;Physics-informed neural networks (PINNs) have recently emerged as promising
data-driven PDE solvers showing encouraging results on various PDEs. However,
there is a fundamental limitation of training PINNs to solve multi-dimensional
PDEs and approximate highly complex solution functions. The number of training
points (collocation points) required on these challenging PDEs grows
substantially, but it is severely limited due to the expensive computational
costs and heavy memory overhead. To overcome this issue, we propose a network
architecture and training algorithm for PINNs. The proposed method, separable
PINN (SPINN), operates on a per-axis basis to significantly reduce the number
of network propagations in multi-dimensional PDEs unlike point-wise processing
in conventional PINNs. We also propose using forward-mode automatic
differentiation to reduce the computational cost of computing PDE residuals,
enabling a large number of collocation points (&amp;gt;10^7) on a single commodity
GPU. The experimental results show drastically reduced computational costs (62x
in wall-clock time, 1,394x in FLOPs given the same number of collocation
points) in multi-dimensional PDEs while achieving better accuracy. Furthermore,
we present that SPINN can solve a chaotic (2+1)-d Navier-Stokes equation
significantly faster than the best-performing prior method (9 minutes vs 10
hours in a single GPU), maintaining accuracy. Finally, we showcase that SPINN
can accurately obtain the solution of a highly nonlinear and multi-dimensional
PDE, a (3+1)-d Navier-Stokes equation. For visualized results and code, please
see https://jwcho5576.github.io/spinn.github.io/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1&quot;&gt;Junwoo Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Seungtae Nam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hyunmo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1&quot;&gt;Seok-Bae Yun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Youngjoon Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1&quot;&gt;Eunbyung Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.16817">
<title>Improving Online Continual Learning Performance and Stability with Temporal Ensembles. (arXiv:2306.16817v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.16817</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are very effective when trained on large datasets for a large
number of iterations. However, when they are trained on non-stationary streams
of data and in an online fashion, their performance is reduced (1) by the
online setup, which limits the availability of data, (2) due to catastrophic
forgetting because of the non-stationary nature of the data. Furthermore,
several recent works (Caccia et al., 2022; Lange et al., 2023) &lt;a href=&quot;/abs/2205.13452&quot;&gt;arXiv:2205.13452&lt;/a&gt;
showed that replay methods used in continual learning suffer from the stability
gap, encountered when evaluating the model continually (rather than only on
task boundaries). In this article, we study the effect of model ensembling as a
way to improve performance and stability in online continual learning. We
notice that naively ensembling models coming from a variety of training tasks
increases the performance in online continual learning considerably. Starting
from this observation, and drawing inspirations from semi-supervised learning
ensembling methods, we use a lightweight temporal ensemble that computes the
exponential moving average of the weights (EMA) at test time, and show that it
can drastically increase the performance and stability when used in combination
with several methods from the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soutif__Cormerais_A/0/1/0/all/0/1&quot;&gt;Albin Soutif--Cormerais&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carta_A/0/1/0/all/0/1&quot;&gt;Antonio Carta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weijer_J/0/1/0/all/0/1&quot;&gt;Joost Van de Weijer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.17323">
<title>Scaling Model Checking for DNN Analysis via State-Space Reduction and Input Segmentation (Extended Version). (arXiv:2306.17323v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.17323</link>
<description rdf:parseType="Literal">&lt;p&gt;Owing to their remarkable learning capabilities and performance in real-world
applications, the use of machine learning systems based on Neural Networks
(NNs) has been continuously increasing. However, various case studies and
empirical findings in the literature suggest that slight variations to NN
inputs can lead to erroneous and undesirable NN behavior. This has led to
considerable interest in their formal analysis, aiming to provide guarantees
regarding a given NN&apos;s behavior. Existing frameworks provide robustness and/or
safety guarantees for the trained NNs, using satisfiability solving and linear
programming. We proposed FANNet, the first model checking-based framework for
analyzing a broader range of NN properties. However, the state-space explosion
associated with model checking entails a scalability problem, making the FANNet
applicable only to small NNs. This work develops state-space reduction and
input segmentation approaches, to improve the scalability and timing efficiency
of formal NN analysis. Compared to the state-of-the-art FANNet, this enables
our new model checking-based framework to reduce the verification&apos;s timing
overhead by a factor of up to 8000, making the framework applicable to NNs even
with approximately $80$ times more network parameters. This in turn allows the
analysis of NN safety properties using the new framework, in addition to all
the NN properties already included with FANNet. The framework is shown to be
efficiently able to analyze properties of NNs trained on healthcare datasets as
well as the well--acknowledged ACAS Xu NNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1&quot;&gt;Mahum Naseer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasan_O/0/1/0/all/0/1&quot;&gt;Osman Hasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1&quot;&gt;Muhammad Shafique&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.17624">
<title>Sphere2Vec: A General-Purpose Location Representation Learning over a Spherical Surface for Large-Scale Geospatial Predictions. (arXiv:2306.17624v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.17624</link>
<description rdf:parseType="Literal">&lt;p&gt;Generating learning-friendly representations for points in space is a
fundamental and long-standing problem in ML. Recently, multi-scale encoding
schemes (such as Space2Vec and NeRF) were proposed to directly encode any point
in 2D/3D Euclidean space as a high-dimensional vector, and has been
successfully applied to various geospatial prediction and generative tasks.
However, all current 2D and 3D location encoders are designed to model point
distances in Euclidean space. So when applied to large-scale real-world GPS
coordinate datasets, which require distance metric learning on the spherical
surface, both types of models can fail due to the map projection distortion
problem (2D) and the spherical-to-Euclidean distance approximation error (3D).
To solve these problems, we propose a multi-scale location encoder called
Sphere2Vec which can preserve spherical distances when encoding point
coordinates on a spherical surface. We developed a unified view of
distance-reserving encoding on spheres based on the DFS. We also provide
theoretical proof that the Sphere2Vec preserves the spherical surface distance
between any two points, while existing encoding schemes do not. Experiments on
20 synthetic datasets show that Sphere2Vec can outperform all baseline models
on all these datasets with up to 30.8% error rate reduction. We then apply
Sphere2Vec to three geo-aware image classification tasks - fine-grained species
recognition, Flickr image recognition, and remote sensing image classification.
Results on 7 real-world datasets show the superiority of Sphere2Vec over
multiple location encoders on all three tasks. Further analysis shows that
Sphere2Vec outperforms other location encoder models, especially in the polar
regions and data-sparse areas because of its nature for spherical surface
distance preservation. Code and data are available at
https://gengchenmai.github.io/sphere2vec-website/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mai_G/0/1/0/all/0/1&quot;&gt;Gengchen Mai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xuan_Y/0/1/0/all/0/1&quot;&gt;Yao Xuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1&quot;&gt;Wenyun Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yutong He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jiaming Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janowicz_K/0/1/0/all/0/1&quot;&gt;Krzysztof Janowicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lao_N/0/1/0/all/0/1&quot;&gt;Ni Lao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.00068">
<title>Wearing face mask detection using deep learning through COVID-19 pandemic. (arXiv:2305.00068v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2305.00068</link>
<description rdf:parseType="Literal">&lt;p&gt;During the COVID-19 pandemic, wearing a face mask has been known to be an
effective way to prevent the spread of COVID-19. In lots of monitoring tasks,
humans have been replaced with computers thanks to the outstanding performance
of the deep learning models. Monitoring the wearing of a face mask is another
task that can be done by deep learning models with acceptable accuracy. The
main challenge of this task is the limited amount of data because of the
quarantine. In this paper, we did an investigation on the capability of three
state-of-the-art object detection neural networks on face mask detection for
real-time applications. As mentioned, here are three models used, Single Shot
Detector (SSD), two versions of You Only Look Once (YOLO) i.e., YOLOv4-tiny,
and YOLOv4-tiny-3l from which the best was selected. In the proposed method,
according to the performance of different models, the best model that can be
suitable for use in real-world and mobile device applications in comparison to
other recent studies was the YOLOv4-tiny model, with 85.31% and 50.66 for mean
Average Precision (mAP) and Frames Per Second (FPS), respectively. These
acceptable values were achieved using two datasets with only 1531 images in
three separate classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoramdel_J/0/1/0/all/0/1&quot;&gt;Javad Khoramdel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hatami_S/0/1/0/all/0/1&quot;&gt;Soheila Hatami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadedel_M/0/1/0/all/0/1&quot;&gt;Majid Sadedel&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>