<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-11-02T21:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00724" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00727" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00731" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00732" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00735" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00737" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00739" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00749" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00750" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00754" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00768" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00775" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00787" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00797" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00801" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00802" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00807" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00808" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00811" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00840" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00844" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00855" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00858" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00859" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00860" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00862" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00863" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00865" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00866" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00871" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00873" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00875" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00880" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00886" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00902" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00906" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00919" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00923" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00927" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00931" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00936" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00938" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00941" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00959" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00964" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00966" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00971" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00973" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00975" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00983" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00993" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01002" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01007" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01010" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01011" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01017" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01024" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01033" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01038" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01046" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01047" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01050" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01052" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01059" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01061" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01064" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01075" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01106" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01111" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01118" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01130" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01135" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01138" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01139" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01154" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01191" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01195" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01196" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01198" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01200" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01205" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01252" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01256" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01276" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01282" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01295" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01301" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01305" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01310" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01323" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01327" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01329" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01331" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01344" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01349" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01352" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01356" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01367" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01375" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01388" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01394" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01404" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01406" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01409" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01410" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01412" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01420" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01425" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01428" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01434" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01435" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01441" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01442" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01446" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01447" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2002.07897" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2005.05163" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.05147" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2104.04926" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.10381" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.00839" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.10284" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.08907" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.03152" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.13398" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.11104" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.12358" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.14724" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.08879" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.06950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.12835" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.04366" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.13441" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.09721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.15092" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.15856" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.10649" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.14319" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.07210" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.12874" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.04040" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.04391" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.10180" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.10725" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.12783" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.17760" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.10832" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.13410" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.14274" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.00586" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.01638" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.02305" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.07828" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.09253" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13009" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14690" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15208" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15572" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.17020" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18333" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18497" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18666" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19913" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.03698" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.05225" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.07962" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.08153" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.09750" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12658" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02598" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.03486" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.05973" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.07050" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.07439" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.06534" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.07843" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.10068" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.00733" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.01267" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.01632" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.04037" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.05183" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.13425" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00806" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01853" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02090" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03047" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03103" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04015" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.06157" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.09259" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.10030" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.10702" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.12560" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13018" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.16917" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.17341" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.17403" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.18230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.18348" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.18477" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.19385" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.19793" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.20280" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00489" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2311.00721">
<title>Empathy Detection Using Machine Learning on Text, Audiovisual, Audio or Physiological Signals. (arXiv:2311.00721v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2311.00721</link>
<description rdf:parseType="Literal">&lt;p&gt;Empathy is a social skill that indicates an individual&apos;s ability to
understand others. Over the past few years, empathy has drawn attention from
various disciplines, including but not limited to Affective Computing,
Cognitive Science and Psychology. Empathy is a context-dependent term; thus,
detecting or recognising empathy has potential applications in society,
healthcare and education. Despite being a broad and overlapping topic, the
avenue of empathy detection studies leveraging Machine Learning remains
underexplored from a holistic literature perspective. To this end, we
systematically collect and screen 801 papers from 10 well-known databases and
analyse the selected 54 papers. We group the papers based on input modalities
of empathy detection systems, i.e., text, audiovisual, audio and physiological
signals. We examine modality-specific pre-processing and network architecture
design protocols, popular dataset descriptions and availability details, and
evaluation protocols. We further discuss the potential applications, deployment
challenges and research gaps in the Affective Computing-based empathy domain,
which can facilitate new avenues of exploration. We believe that our work is a
stepping stone to developing a privacy-preserving and unbiased empathic system
inclusive of culture, diversity and multilingualism that can be deployed in
practice to enhance the overall well-being of human life.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1&quot;&gt;Md Rakibul Hasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1&quot;&gt;Md Zakir Hossain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Shreya Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soon_S/0/1/0/all/0/1&quot;&gt;Susannah Soon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1&quot;&gt;Tom Gedeon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00724">
<title>Fraud Analytics Using Machine-learning &amp; Engineering on Big Data (FAME) for Telecom. (arXiv:2311.00724v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00724</link>
<description rdf:parseType="Literal">&lt;p&gt;Telecom industries lose globally 46.3 Billion USD due to fraud. Data mining
and machine learning techniques (apart from rules oriented approach) have been
used in past, but efficiency has been low as fraud pattern changes very
rapidly. This paper presents an industrialized solution approach with self
adaptive data mining technique and application of big data technologies to
detect fraud and discover novel fraud patterns in accurate, efficient and cost
effective manner. Solution has been successfully demonstrated to detect
International Revenue Share Fraud with &amp;lt;5% false positive. More than 1 Terra
Bytes of Call Detail Record from a reputed wholesale carrier and overseas
telecom transit carrier has been used to conduct this study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pratihar_S/0/1/0/all/0/1&quot;&gt;Sudarson Roy Pratihar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1&quot;&gt;Subhadip Paul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dash_P/0/1/0/all/0/1&quot;&gt;Pranab Kumar Dash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Amartya Kumar Das&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00727">
<title>Investigating Relative Performance of Transfer and Meta Learning. (arXiv:2311.00727v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00727</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past decade, the field of machine learning has experienced
remarkable advancements. While image recognition systems have achieved
impressive levels of accuracy, they continue to rely on extensive training
datasets. Additionally, a significant challenge has emerged in the form of poor
out-of-distribution performance, which necessitates retraining neural networks
when they encounter conditions that deviate from their training data. This
limitation has notably contributed to the slow progress in self-driving car
technology. These pressing issues have sparked considerable interest in methods
that enable neural networks to learn effectively from limited data. This paper
presents the outcomes of an extensive investigation designed to compare two
distinct approaches, transfer learning and meta learning, as potential
solutions to this problem. The overarching objective was to establish a robust
criterion for selecting the most suitable method in diverse machine learning
scenarios. Building upon prior research, I expanded the comparative analysis by
introducing a new meta learning method into the investigation. Subsequently, I
assessed whether the findings remained consistent under varying conditions.
Finally, I delved into the impact of altering the size of the training dataset
on the relative performance of these methods. This comprehensive exploration
has yielded insights into the conditions favoring each approach, thereby
facilitating the development of a criterion for selecting the most appropriate
method in any given situation
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alwis_B/0/1/0/all/0/1&quot;&gt;Benji Alwis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00731">
<title>Enhancing Clustering Representations with Positive Proximity and Cluster Dispersion Learning. (arXiv:2311.00731v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00731</link>
<description rdf:parseType="Literal">&lt;p&gt;Contemporary deep clustering approaches often rely on either contrastive or
non-contrastive techniques to acquire effective representations for clustering
tasks. Contrastive methods leverage negative pairs to achieve homogenous
representations but can introduce class collision issues, potentially
compromising clustering performance. On the contrary, non-contrastive
techniques prevent class collisions but may produce non-uniform representations
that lead to clustering collapse. In this work, we propose a novel end-to-end
deep clustering approach named PIPCDR, designed to harness the strengths of
both approaches while mitigating their limitations. PIPCDR incorporates a
positive instance proximity loss and a cluster dispersion regularizer. The
positive instance proximity loss ensures alignment between augmented views of
instances and their sampled neighbors, enhancing within-cluster compactness by
selecting genuinely positive pairs within the embedding space. Meanwhile, the
cluster dispersion regularizer maximizes inter-cluster distances while
minimizing within-cluster compactness, promoting uniformity in the learned
representations. PIPCDR excels in producing well-separated clusters, generating
uniform representations, avoiding class collision issues, and enhancing
within-cluster compactness. We extensively validate the effectiveness of PIPCDR
within an end-to-end Majorize-Minimization framework, demonstrating its
competitive performance on moderate-scale clustering benchmark datasets and
establishing new state-of-the-art results on large-scale datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Abhishek Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Dong-Gyu Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00732">
<title>tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for Detecting Tweets Self-reporting a COVID-19 Diagnosis. (arXiv:2311.00732v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.00732</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper describes a system developed for Task 1 at SMM4H 2023. The goal of
the task is to automatically distinguish tweets that self-report a COVID-19
diagnosis (for example, a positive test, clinical diagnosis, or
hospitalization) from those that do not. We investigate the use of different
techniques for preprocessing tweets using four transformer-based models. The
ensemble of fine-tuned language models obtained an F1-score of 84.5%, which is
4.1% higher than the average value.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glazkova_A/0/1/0/all/0/1&quot;&gt;Anna Glazkova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00735">
<title>PET Tracer Conversion among Brain PET via Variable Augmented Invertible Network. (arXiv:2311.00735v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00735</link>
<description rdf:parseType="Literal">&lt;p&gt;Positron emission tomography (PET), as an imaging technique with high
biochemical sensitivity, has been widely used in diagnosis of encephalopathy
and brain science research used in brain disease diagnosis and brain science
research. Since different tracers present different effects on the same focal
area, the choice of tracers is getting more significant for PET imaging.
Nowadays, with the wide application of PET imaging in neuropsychiatric
treatment, 6-18F-fluoro-3, 4-dihydroxy-L-phenylalanine (DOPA) has been found to
be more effective than 18F-labeled fluorine-2-deoxyglucose (FDG) in this field.
However, due to the complexity of its preparation and other limitations, DOPA
is far less widely used than FDG. To address this issue, a tracer conversion
invertible neural network (TC-INN) for image projection is developed to map FDG
images to DOPA images through deep learning. More diagnostic information is
obtained by generating PET images from FDG to DOPA. Specifically, the proposed
TC-INN consists of two separate phases, one for training the traceable data,
the other for re-building the new data. The reference DOPA PET image is used as
the learning target for the corresponding network during the training process
of tracer conversion. Mean-while, the invertible network iteratively estimates
the resultant DOPA PET data and compares it to the reference DOPA PET data.
Notably, the reversible model employed variable enhancement techniques to
achieve better power generation. Moreover, image registration needs to be
performed before training due to the angular deviation of the acquired FDG and
DOPA data information. Experimental results show generative ability in mapping
be-tween FDG images and DOPA images. It demonstrates great potential for PET
image conversion in the case of limited tracer applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1&quot;&gt;Bohui Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xubiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Pengfei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shirui Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1&quot;&gt;Xinchong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiangsong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weirui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bingxuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiegen Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00737">
<title>Real-Time Magnetic Tracking and Diagnosis of COVID-19 via Machine Learning. (arXiv:2311.00737v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00737</link>
<description rdf:parseType="Literal">&lt;p&gt;The COVID-19 pandemic underscored the importance of reliable, noninvasive
diagnostic tools for robust public health interventions. In this work, we fused
magnetic respiratory sensing technology (MRST) with machine learning (ML) to
create a diagnostic platform for real-time tracking and diagnosis of COVID-19
and other respiratory diseases. The MRST precisely captures breathing patterns
through three specific breath testing protocols: normal breath, holding breath,
and deep breath. We collected breath data from both COVID-19 patients and
healthy subjects in Vietnam using this platform, which then served to train and
validate ML models. Our evaluation encompassed multiple ML algorithms,
including support vector machines and deep learning models, assessing their
ability to diagnose COVID-19. Our multi-model validation methodology ensures a
thorough comparison and grants the adaptability to select the most optimal
model, striking a balance between diagnostic precision with model
interpretability. The findings highlight the exceptional potential of our
diagnostic tool in pinpointing respiratory anomalies, achieving over 90%
accuracy. This innovative sensor technology can be seamlessly integrated into
healthcare settings for patient monitoring, marking a significant enhancement
for the healthcare infrastructure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Dang Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huynh_P/0/1/0/all/0/1&quot;&gt;Phat K. Huynh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bui_V/0/1/0/all/0/1&quot;&gt;Vinh Duc An Bui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_K/0/1/0/all/0/1&quot;&gt;Kee Young Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1&quot;&gt;Nityanand Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1&quot;&gt;Chau Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minh_L/0/1/0/all/0/1&quot;&gt;Le Huu Nhat Minh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Truong_L/0/1/0/all/0/1&quot;&gt;Le Van Truong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_X/0/1/0/all/0/1&quot;&gt;Xuan Thanh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Dinh Hoang Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dung_L/0/1/0/all/0/1&quot;&gt;Le Tien Dung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Trung Q. Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_M/0/1/0/all/0/1&quot;&gt;Manh-Huong Phan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00739">
<title>Can Large Language Models Design Accurate Label Functions?. (arXiv:2311.00739v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.00739</link>
<description rdf:parseType="Literal">&lt;p&gt;Programmatic weak supervision methodologies facilitate the expedited labeling
of extensive datasets through the use of label functions (LFs) that encapsulate
heuristic data sources. Nonetheless, the creation of precise LFs necessitates
domain expertise and substantial endeavors. Recent advances in pre-trained
language models (PLMs) have exhibited substantial potential across diverse
tasks. However, the capacity of PLMs to autonomously formulate accurate LFs
remains an underexplored domain. In this research, we address this gap by
introducing DataSculpt, an interactive framework that harnesses PLMs for the
automated generation of LFs. Within DataSculpt, we incorporate an array of
prompting techniques, instance selection strategies, and LF filtration methods
to explore the expansive design landscape. Ultimately, we conduct a thorough
assessment of DataSculpt&apos;s performance on 12 real-world datasets, encompassing
a range of tasks. This evaluation unveils both the strengths and limitations of
contemporary PLMs in LF design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_N/0/1/0/all/0/1&quot;&gt;Naiqing Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kaiwen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koudas_N/0/1/0/all/0/1&quot;&gt;Nick Koudas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00749">
<title>Sorting with Predictions. (arXiv:2311.00749v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2311.00749</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the fundamental problem of sorting through the lens of
learning-augmented algorithms, where algorithms can leverage possibly erroneous
predictions to improve their efficiency. We consider two different settings: In
the first setting, each item is provided a prediction of its position in the
sorted list. In the second setting, we assume there is a &quot;quick-and-dirty&quot; way
of comparing items, in addition to slow-and-exact comparisons. For both
settings, we design new and simple algorithms using only $O(\sum_i \log
\eta_i)$ exact comparisons, where $\eta_i$ is a suitably defined prediction
error for the $i$th element. In particular, as the quality of predictions
deteriorates, the number of comparisons degrades smoothly from $O(n)$ to
$O(n\log n)$. We prove that the comparison complexity is theoretically optimal
with respect to the examined error measures. An experimental evaluation against
existing adaptive and non-adaptive sorting algorithms demonstrates the
potential of applying learning-augmented algorithms in sorting tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1&quot;&gt;Xingjian Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coester_C/0/1/0/all/0/1&quot;&gt;Christian Coester&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00750">
<title>Are These the Same Apple? Comparing Images Based on Object Intrinsics. (arXiv:2311.00750v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.00750</link>
<description rdf:parseType="Literal">&lt;p&gt;The human visual system can effortlessly recognize an object under different
extrinsic factors such as lighting, object poses, and background, yet current
computer vision systems often struggle with these variations. An important step
to understanding and improving artificial vision systems is to measure image
similarity purely based on intrinsic object properties that define object
identity. This problem has been studied in the computer vision literature as
re-identification, though mostly restricted to specific object categories such
as people and cars. We propose to extend it to general object categories,
exploring an image similarity metric based on object intrinsics. To benchmark
such measurements, we collect the Common paired objects Under differenT
Extrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different
extrinsic factors such as lighting, poses, and imaging conditions. While
existing methods such as LPIPS and CLIP scores do not measure object intrinsics
well, we find that combining deep features learned from contrastive
self-supervised learning with foreground filtering is a simple yet effective
approach to approximating the similarity. We conduct an extensive survey of
pre-trained features and foreground extraction methods to arrive at a strong
baseline that best measures intrinsic object-centric image similarity among
current methods. Finally, we demonstrate that our approach can aid in
downstream applications such as acting as an analog for human subjects and
improving generalizable re-identification. Please see our project website at
https://s-tian.github.io/projects/cute/ for visualizations of the data and
demos of our metric.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kotar_K/0/1/0/all/0/1&quot;&gt;Klemen Kotar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1&quot;&gt;Stephen Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hong-Xing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1&quot;&gt;Daniel L.K. Yamins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00754">
<title>Learning to Design and Use Tools for Robotic Manipulation. (arXiv:2311.00754v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.00754</link>
<description rdf:parseType="Literal">&lt;p&gt;When limited by their own morphologies, humans and some species of animals
have the remarkable ability to use objects from the environment toward
accomplishing otherwise impossible tasks. Robots might similarly unlock a range
of additional capabilities through tool use. Recent techniques for jointly
optimizing morphology and control via deep learning are effective at designing
locomotion agents. But while outputting a single morphology makes sense for
locomotion, manipulation involves a variety of strategies depending on the task
goals at hand. A manipulation agent must be capable of rapidly prototyping
specialized tools for different goals. Therefore, we propose learning a
designer policy, rather than a single design. A designer policy is conditioned
on task information and outputs a tool design that helps solve the task. A
design-conditioned controller policy can then perform manipulation using these
tools. In this work, we take a step towards this goal by introducing a
reinforcement learning framework for jointly learning these policies. Through
simulated manipulation tasks, we show that this framework is more sample
efficient than prior methods in multi-goal or multi-variant settings, can
perform zero-shot interpolation or fine-tuning to tackle previously unseen
goals, and allows tradeoffs between the complexity of design and control
policies under practical constraints. Finally, we deploy our learned policies
onto a real robot. Please see our supplementary video and website at
https://robotic-tool-design.github.io/ for visualizations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Ziang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1&quot;&gt;Stephen Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1&quot;&gt;Michelle Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;C. Karen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00768">
<title>Language Model Training Paradigms for Clinical Feature Embeddings. (arXiv:2311.00768v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00768</link>
<description rdf:parseType="Literal">&lt;p&gt;In research areas with scarce data, representation learning plays a
significant role. This work aims to enhance representation learning for
clinical time series by deriving universal embeddings for clinical features,
such as heart rate and blood pressure. We use self-supervised training
paradigms for language models to learn high-quality clinical feature
embeddings, achieving a finer granularity than existing time-step and
patient-level representation learning. We visualize the learnt embeddings via
unsupervised dimension reduction techniques and observe a high degree of
consistency with prior clinical knowledge. We also evaluate the model
performance on the MIMIC-III benchmark and demonstrate the effectiveness of
using clinical feature embeddings. We publish our code online for replication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yurong Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burger_M/0/1/0/all/0/1&quot;&gt;Manuel Burger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1&quot;&gt;Gunnar R&amp;#xe4;tsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuznetsova_R/0/1/0/all/0/1&quot;&gt;Rita Kuznetsova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00774">
<title>Conformalized Deep Splines for Optimal and Efficient Prediction Sets. (arXiv:2311.00774v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00774</link>
<description rdf:parseType="Literal">&lt;p&gt;Uncertainty estimation is critical in high-stakes machine learning
applications. One effective way to estimate uncertainty is conformal
prediction, which can provide predictive inference with statistical coverage
guarantees. We present a new conformal regression method, Spline Prediction
Intervals via Conformal Estimation (SPICE), that estimates the conditional
density using neural-network-parameterized splines. We prove universal
approximation and optimality results for SPICE, which are empirically validated
by our experiments. SPICE is compatible with two different efficient-to-compute
conformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the
other asymptotically optimal for conditional coverage (SPICE-HPD). Results on
benchmark datasets demonstrate SPICE-ND models achieve the smallest average
prediction set sizes, including average size reductions of nearly 50% for some
datasets compared to the next best baseline. SPICE-HPD models achieve the best
conditional coverage compared to baselines. The SPICE implementation is made
available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diamant_N/0/1/0/all/0/1&quot;&gt;Nathaniel Diamant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajiramezanali_E/0/1/0/all/0/1&quot;&gt;Ehsan Hajiramezanali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biancalani_T/0/1/0/all/0/1&quot;&gt;Tommaso Biancalani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scalia_G/0/1/0/all/0/1&quot;&gt;Gabriele Scalia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00775">
<title>Harnessing machine learning for accurate treatment of overlapping opacity species in GCMs. (arXiv:2311.00775v1 [astro-ph.EP])</title>
<link>http://arxiv.org/abs/2311.00775</link>
<description rdf:parseType="Literal">&lt;p&gt;To understand high precision observations of exoplanets and brown dwarfs, we
need detailed and complex general circulation models (GCMs) that incorporate
hydrodynamics, chemistry, and radiation. In this study, we specifically examine
the coupling between chemistry and radiation in GCMs and compare different
methods for mixing opacities of different chemical species in the correlated-k
assumption, when equilibrium chemistry cannot be assumed. We propose a fast
machine learning method based on DeepSets (DS), which effectively combines
individual correlated-k opacities (k-tables). We evaluate the DS method
alongside other published methods like adaptive equivalent extinction (AEE) and
random overlap with rebinning and resorting (RORR). We integrate these mixing
methods into our GCM (expeRT/MITgcm) and assess their accuracy and performance
for the example of the hot Jupiter HD~209458 b. Our findings indicate that the
DS method is both accurate and efficient for GCM usage, whereas RORR is too
slow. Additionally, we observe that the accuracy of AEE depends on its specific
implementation and may introduce numerical issues in achieving radiative
transfer solution convergence. We then apply the DS mixing method in a
simplified chemical disequilibrium situation, where we model the rainout of TiO
and VO, and confirm that the rainout of TiO and VO would hinder the formation
of a stratosphere. To further expedite the development of consistent
disequilibrium chemistry calculations in GCMs, we provide documentation and
code for coupling the DS mixing method with correlated-k radiative transfer
solvers. The DS method has been extensively tested to be accurate enough for
GCMs, however, other methods might be needed for accelerating atmospheric
retrievals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Schneider_A/0/1/0/all/0/1&quot;&gt;Aaron David Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Molliere_P/0/1/0/all/0/1&quot;&gt;Paul Molli&amp;#xe8;re&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Louppe_G/0/1/0/all/0/1&quot;&gt;Gilles Louppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Carone_L/0/1/0/all/0/1&quot;&gt;Ludmila Carone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Jorgensen_U/0/1/0/all/0/1&quot;&gt;Uffe Gr&amp;#xe5;e J&amp;#xf8;rgensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Decin_L/0/1/0/all/0/1&quot;&gt;Leen Decin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Helling_C/0/1/0/all/0/1&quot;&gt;Christiane Helling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00787">
<title>Accelerating Electronic Stopping Power Predictions by 10 Million Times with a Combination of Time-Dependent Density Functional Theory and Machine Learning. (arXiv:2311.00787v1 [cond-mat.mtrl-sci])</title>
<link>http://arxiv.org/abs/2311.00787</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowing the rate at which particle radiation releases energy in a material,
the stopping power, is key to designing nuclear reactors, medical treatments,
semiconductor and quantum materials, and many other technologies. While the
nuclear contribution to stopping power, i.e., elastic scattering between atoms,
is well understood in the literature, the route for gathering data on the
electronic contribution has for decades remained costly and reliant on many
simplifying assumptions, including that materials are isotropic. We establish a
method that combines time-dependent density functional theory (TDDFT) and
machine learning to reduce the time to assess new materials to mere hours on a
supercomputer and provides valuable data on how atomic details influence
electronic stopping. Our approach uses TDDFT to compute the electronic stopping
contributions to stopping power from first principles in several directions and
then machine learning to interpolate to other directions at rates 10 million
times higher. We demonstrate the combined approach in a study of proton
irradiation in aluminum and employ it to predict how the depth of maximum
energy deposition, the &quot;Bragg Peak,&quot; varies depending on incident angle -- a
quantity otherwise inaccessible to modelers. The lack of any experimental
information requirement makes our method applicable to most materials, and its
speed makes it a prime candidate for enabling quantum-to-continuum models of
radiation damage. The prospect of reusing valuable TDDFT data for training the
model make our approach appealing for applications in the age of materials data
science.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Ward_L/0/1/0/all/0/1&quot;&gt;Logan Ward&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Blaiszik_B/0/1/0/all/0/1&quot;&gt;Ben Blaiszik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Cheng-Wei Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Martin_T/0/1/0/all/0/1&quot;&gt;Troy Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Foster_I/0/1/0/all/0/1&quot;&gt;Ian Foster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Schleife_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Schleife&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00797">
<title>Tipping Points of Evolving Epidemiological Networks: Machine Learning-Assisted, Data-Driven Effective Modeling. (arXiv:2311.00797v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00797</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the tipping point collective dynamics of an adaptive
susceptible-infected-susceptible (SIS) epidemiological network in a
data-driven, machine learning-assisted manner. We identify a
parameter-dependent effective stochastic differential equation (eSDE) in terms
of physically meaningful coarse mean-field variables through a deep-learning
ResNet architecture inspired by numerical stochastic integrators. We construct
an approximate effective bifurcation diagram based on the identified drift term
of the eSDE and contrast it with the mean-field SIS model bifurcation diagram.
We observe a subcritical Hopf bifurcation in the evolving network&apos;s effective
SIS dynamics, that causes the tipping point behavior; this takes the form of
large amplitude collective oscillations that spontaneously -- yet rarely --
arise from the neighborhood of a (noisy) stationary state. We study the
statistics of these rare events both through repeated brute force simulations
and by using established mathematical/computational tools exploiting the
right-hand-side of the identified SDE. We demonstrate that such a collective
SDE can also be identified (and the rare events computations also performed) in
terms of data-driven coarse observables, obtained here via manifold learning
techniques, in particular Diffusion Maps. The workflow of our study is
straightforwardly applicable to other complex dynamics problems exhibiting
tipping point dynamics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evangelou_N/0/1/0/all/0/1&quot;&gt;Nikolaos Evangelou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_T/0/1/0/all/0/1&quot;&gt;Tianqi Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bello_Rivas_J/0/1/0/all/0/1&quot;&gt;Juan M. Bello-Rivas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makeev_A/0/1/0/all/0/1&quot;&gt;Alexei Makeev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kevrekidis_I/0/1/0/all/0/1&quot;&gt;Ioannis G. Kevrekidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00801">
<title>GIST: Generated Inputs Sets Transferability in Deep Learning. (arXiv:2311.00801v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00801</link>
<description rdf:parseType="Literal">&lt;p&gt;As the demand for verifiability and testability of neural networks continues
to rise, an increasing number of methods for generating test sets are being
developed. However, each of these techniques tends to emphasize specific
testing aspects and can be quite time-consuming. A straightforward solution to
mitigate this issue is to transfer test sets between some benchmarked models
and a new model under test, based on a desirable property one wishes to
transfer. This paper introduces GIST (Generated Inputs Sets Transferability), a
novel approach for the efficient transfer of test sets among Deep Learning
models. Given a property of interest that a user wishes to transfer (e.g.,
coverage criterion), GIST enables the selection of good test sets from the
point of view of this property among available ones from a benchmark. We
empirically evaluate GIST on fault types coverage property with two modalities
and different test set generation procedures to demonstrate the approach&apos;s
feasibility. Experimental results show that GIST can select an effective test
set for the given property to transfer it to the model under test. Our results
suggest that GIST could be applied to transfer other properties and could
generalize to different test sets&apos; generation procedures and modalities
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tambon_F/0/1/0/all/0/1&quot;&gt;Florian Tambon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1&quot;&gt;Foutse Khomh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antoniol_G/0/1/0/all/0/1&quot;&gt;Giuliano Antoniol&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00802">
<title>Neural Field Dynamics Model for Granular Object Piles Manipulation. (arXiv:2311.00802v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.00802</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a learning-based dynamics model for granular material
manipulation. Inspired by the Eulerian approach commonly used in fluid
dynamics, our method adopts a fully convolutional neural network that operates
on a density field-based representation of object piles and pushers, allowing
it to exploit the spatial locality of inter-object interactions as well as the
translation equivariance through convolution operations. Furthermore, our
differentiable action rendering module makes the model fully differentiable and
can be directly integrated with a gradient-based trajectory optimization
algorithm. We evaluate our model with a wide array of piles manipulation tasks
both in simulation and real-world experiments and demonstrate that it
significantly exceeds existing latent or particle-based methods in both
accuracy and computation efficiency, and exhibits zero-shot generalization
capabilities across various environments and tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1&quot;&gt;Shangjie Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Shuo Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kachana_P/0/1/0/all/0/1&quot;&gt;Pujith Kachana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1&quot;&gt;Danfei Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00807">
<title>VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization. (arXiv:2311.00807v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.00807</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual question answering (VQA) models are designed to demonstrate
visual-textual reasoning capabilities. However, their real-world applicability
is hindered by a lack of comprehensive benchmark datasets. Existing domain
generalization datasets for VQA exhibit a unilateral focus on textual shifts
while VQA being a multi-modal task contains shifts across both visual and
textual domains. We propose VQA-GEN, the first ever multi-modal benchmark
dataset for distribution shift generated through a shift induced pipeline.
Experiments demonstrate VQA-GEN dataset exposes the vulnerability of existing
methods to joint multi-modal distribution shifts. validating that comprehensive
multi-modal shifts are critical for robust VQA generalization. Models trained
on VQA-GEN exhibit improved cross-domain and in-domain performance, confirming
the value of VQA-GEN. Further, we analyze the importance of each shift
technique of our pipeline contributing to the generalization of the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Unni_S/0/1/0/all/0/1&quot;&gt;Suraj Jyothi Unni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moraffah_R/0/1/0/all/0/1&quot;&gt;Raha Moraffah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Huan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00808">
<title>Mahalanobis-Aware Training for Out-of-Distribution Detection. (arXiv:2311.00808v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00808</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep learning models have seen widespread success in controlled
environments, there are still barriers to their adoption in open-world
settings. One critical task for safe deployment is the detection of anomalous
or out-of-distribution samples that may require human intervention. In this
work, we present a novel loss function and recipe for training networks with
improved density-based out-of-distribution sensitivity. We demonstrate the
effectiveness of our method on CIFAR-10, notably reducing the false-positive
rate of the relative Mahalanobis distance method on far-OOD tasks by over 50%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mclaughlin_C/0/1/0/all/0/1&quot;&gt;Connor Mclaughlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matterer_J/0/1/0/all/0/1&quot;&gt;Jason Matterer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yee_M/0/1/0/all/0/1&quot;&gt;Michael Yee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00811">
<title>A quantum-classical performance separation in nonconvex optimization. (arXiv:2311.00811v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2311.00811</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we identify a family of nonconvex continuous optimization
instances, each $d$-dimensional instance with $2^d$ local minima, to
demonstrate a quantum-classical performance separation. Specifically, we prove
that the recently proposed Quantum Hamiltonian Descent (QHD) algorithm [Leng et
al., &lt;a href=&quot;/abs/2303.01471&quot;&gt;arXiv:2303.01471&lt;/a&gt;] is able to solve any $d$-dimensional instance from this
family using $\widetilde{\mathcal{O}}(d^3)$ quantum queries to the function
value and $\widetilde{\mathcal{O}}(d^4)$ additional 1-qubit and 2-qubit
elementary quantum gates. On the other side, a comprehensive empirical study
suggests that representative state-of-the-art classical optimization
algorithms/solvers (including Gurobi) would require a super-polynomial time to
solve such optimization instances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Leng_J/0/1/0/all/0/1&quot;&gt;Jiaqi Leng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yufan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaodi Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00840">
<title>Sharp Noisy Binary Search with Monotonic Probabilities. (arXiv:2311.00840v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2311.00840</link>
<description rdf:parseType="Literal">&lt;p&gt;We revisit the noisy binary search model of Karp and Kleinberg, in which we
have $n$ coins with unknown probabilities $p_i$ that we can flip. The coins are
sorted by increasing $p_i$, and we would like to find where the probability
crosses (to within $\varepsilon$) of a target value $\tau$. This generalized
the fixed-noise model of Burnashev and Zigangirov , in which $p_i = \frac{1}{2}
\pm \varepsilon$, to a setting where coins near the target may be
indistinguishable from it. Karp and Kleinberg showed that
$\Theta(\frac{1}{\varepsilon^2} \log n)$ samples are necessary and sufficient
for this task.
&lt;/p&gt;
&lt;p&gt;We produce a practical algorithm by solving two theoretical challenges:
high-probability behavior and sharp constants. We give an algorithm that
succeeds with probability $1-\delta$ from
&lt;/p&gt;
&lt;p&gt;\[
&lt;/p&gt;
&lt;p&gt;\frac{1}{C_{\tau, \varepsilon}} \cdot \left(\lg n + O(\log^{2/3} n \log^{1/3}
\frac{1}{\delta} + \log \frac{1}{\delta})\right)
&lt;/p&gt;
&lt;p&gt;\]
&lt;/p&gt;
&lt;p&gt;samples, where $C_{\tau, \varepsilon}$ is the optimal such constant
achievable. For $\delta &amp;gt; n^{-o(1)}$ this is within $1 + o(1)$ of optimal, and
for $\delta \ll 1$ it is the first bound within constant factors of optimal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gretta_L/0/1/0/all/0/1&quot;&gt;Lucas Gretta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Price_E/0/1/0/all/0/1&quot;&gt;Eric Price&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00844">
<title>Electronic excited states from physically-constrained machine learning. (arXiv:2311.00844v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2311.00844</link>
<description rdf:parseType="Literal">&lt;p&gt;Data-driven techniques are increasingly used to replace electronic-structure
calculations of matter. In this context, a relevant question is whether machine
learning (ML) should be applied directly to predict the desired properties or
be combined explicitly with physically-grounded operations. We present an
example of an integrated modeling approach, in which a symmetry-adapted ML
model of an effective Hamiltonian is trained to reproduce electronic
excitations from a quantum-mechanical calculation. The resulting model can make
predictions for molecules that are much larger and more complex than those that
it is trained on, and allows for dramatic computational savings by indirectly
targeting the outputs of well-converged calculations while using a
parameterization corresponding to a minimal atom-centered basis. These results
emphasize the merits of intertwining data-driven techniques with physical
approximations, improving the transferability and interpretability of ML models
without affecting their accuracy and computational efficiency, and providing a
blueprint for developing ML-augmented electronic-structure methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Cignoni_E/0/1/0/all/0/1&quot;&gt;Edoardo Cignoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Suman_D/0/1/0/all/0/1&quot;&gt;Divya Suman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Nigam_J/0/1/0/all/0/1&quot;&gt;Jigyasa Nigam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Cupellini_L/0/1/0/all/0/1&quot;&gt;Lorenzo Cupellini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mennucci_B/0/1/0/all/0/1&quot;&gt;Benedetta Mennucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ceriotti_M/0/1/0/all/0/1&quot;&gt;Michele Ceriotti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00855">
<title>A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S. Ending the HIV Epidemic Plan. (arXiv:2311.00855v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2311.00855</link>
<description rdf:parseType="Literal">&lt;p&gt;Human immunodeficiency virus (HIV) is a major public health concern in the
United States, with about 1.2 million people living with HIV and 35,000 newly
infected each year. There are considerable geographical disparities in HIV
burden and care access across the U.S. The 2019 Ending the HIV Epidemic (EHE)
initiative aims to reduce new infections by 90% by 2030, by improving coverage
of diagnoses, treatment, and prevention interventions and prioritizing
jurisdictions with high HIV prevalence. Identifying optimal scale-up of
intervention combinations will help inform resource allocation. Existing HIV
decision analytic models either evaluate specific cities or the overall
national population, thus overlooking jurisdictional interactions or
differences. In this paper, we propose a multi-agent reinforcement learning
(MARL) model, that enables jurisdiction-specific decision analyses but in an
environment with cross-jurisdictional epidemiological interactions. In
experimental analyses, conducted on jurisdictions within California and
Florida, optimal policies from MARL were significantly different than those
generated from single-agent RL, highlighting the influence of jurisdictional
variations and interactions. By using comprehensive modeling of HIV and
formulations of state space, action space, and reward functions, this work
helps demonstrate the strengths and applicability of MARL for informing public
health policies, and provides a framework for expanding to the national-level
to inform the EHE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1&quot;&gt;Dinesh Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1&quot;&gt;Ankit Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalappa_C/0/1/0/all/0/1&quot;&gt;Chaitra Gopalappa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00858">
<title>SmoothHess: ReLU Network Feature Interactions via Stein&apos;s Lemma. (arXiv:2311.00858v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00858</link>
<description rdf:parseType="Literal">&lt;p&gt;Several recent methods for interpretability model feature interactions by
looking at the Hessian of a neural network. This poses a challenge for ReLU
networks, which are piecewise-linear and thus have a zero Hessian almost
everywhere. We propose SmoothHess, a method of estimating second-order
interactions through Stein&apos;s Lemma. In particular, we estimate the Hessian of
the network convolved with a Gaussian through an efficient sampling algorithm,
requiring only network gradient calls. SmoothHess is applied post-hoc, requires
no modifications to the ReLU network architecture, and the extent of smoothing
can be controlled explicitly. We provide a non-asymptotic bound on the sample
complexity of our estimation procedure. We validate the superior ability of
SmoothHess to capture interactions on benchmark datasets and a real-world
medical spirometry dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torop_M/0/1/0/all/0/1&quot;&gt;Max Torop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masoomi_A/0/1/0/all/0/1&quot;&gt;Aria Masoomi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hill_D/0/1/0/all/0/1&quot;&gt;Davin Hill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kose_K/0/1/0/all/0/1&quot;&gt;Kivanc Kose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ioannidis_S/0/1/0/all/0/1&quot;&gt;Stratis Ioannidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dy_J/0/1/0/all/0/1&quot;&gt;Jennifer Dy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00859">
<title>Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems. (arXiv:2311.00859v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00859</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding optimal adversarial attack strategies is an important topic in
reinforcement learning and the Markov decision process. Previous studies
usually assume one all-knowing coordinator (attacker) for whom attacking
different recipient (victim) agents incurs uniform costs. However, in reality,
instead of using one limitless central attacker, the attacks often need to be
performed by distributed attack agents. We formulate the problem of performing
optimal adversarial agent-to-agent attacks using distributed attack agents, in
which we impose distinct cost constraints on each different attacker-victim
pair. We propose an optimal method integrating within-step static constrained
attack-resource allocation optimization and between-step dynamic programming to
achieve the optimal adversarial attack in a multi-agent system. Our numerical
results show that the proposed attacks can significantly reduce the rewards
received by the attacked agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Ziqing Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guanlin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1&quot;&gt;Lifeng Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Weiyu Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00860">
<title>Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning. (arXiv:2311.00860v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00860</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic differentiation (AD) is a critical step in physics-informed machine
learning, required for computing the high-order derivatives of network output
w.r.t. coordinates. In this paper, we present a novel and lightweight algorithm
to conduct such AD for physics-informed operator learning, as we call the trick
of Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates leaf
variables, ZCS introduces only one scalar-valued leaf variable for each spatial
or temporal dimension, leading to a game-changing performance leap by
simplifying the wanted derivatives from &quot;many-roots-many-leaves&quot; to
&quot;one-root-many-leaves&quot;. ZCS is easy to implement with current deep learning
libraries; our own implementation is by extending the DeepXDE package. We carry
out a comprehensive benchmark analysis and several case studies, training
physics-informed DeepONets to solve partial differential equations (PDEs)
without data. The results show that ZCS has persistently brought down GPU
memory consumption and wall time for training by an order of magnitude, with
the savings increasing with problem scale (i.e., number of functions, number of
points and order of PDE). As a low-level optimisation, ZCS entails no
restrictions on data, physics (PDEs) or network architecture and does not
compromise training results from any aspect.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leng_K/0/1/0/all/0/1&quot;&gt;Kuangdai Leng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shankar_M/0/1/0/all/0/1&quot;&gt;Mallikarjun Shankar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiyagalingam_J/0/1/0/all/0/1&quot;&gt;Jeyan Thiyagalingam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00862">
<title>Role of Structural and Conformational Diversity for Machine Learning Potentials. (arXiv:2311.00862v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2311.00862</link>
<description rdf:parseType="Literal">&lt;p&gt;In the field of Machine Learning Interatomic Potentials (MLIPs),
understanding the intricate relationship between data biases, specifically
conformational and structural diversity, and model generalization is critical
in improving the quality of Quantum Mechanics (QM) data generation efforts. We
investigate these dynamics through two distinct experiments: a fixed budget
one, where the dataset size remains constant, and a fixed molecular set one,
which focuses on fixed structural diversity while varying conformational
diversity. Our results reveal nuanced patterns in generalization metrics.
Notably, for optimal structural and conformational generalization, a careful
balance between structural and conformational diversity is required, but
existing QM datasets do not meet that trade-off. Additionally, our results
highlight the limitation of the MLIP models at generalizing beyond their
training distribution, emphasizing the importance of defining applicability
domain during model deployment. These findings provide valuable insights and
guidelines for QM data generation efforts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Shenoy_N/0/1/0/all/0/1&quot;&gt;Nikhil Shenoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Tossou_P/0/1/0/all/0/1&quot;&gt;Prudencio Tossou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Noutahi_E/0/1/0/all/0/1&quot;&gt;Emmanuel Noutahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mary_H/0/1/0/all/0/1&quot;&gt;Hadrien Mary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Beaini_D/0/1/0/all/0/1&quot;&gt;Dominique Beaini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ding_J/0/1/0/all/0/1&quot;&gt;Jiarui Ding&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00863">
<title>Training Dynamics of Contextual N-Grams in Language Models. (arXiv:2311.00863v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00863</link>
<description rdf:parseType="Literal">&lt;p&gt;Prior work has shown the existence of contextual neurons in language models,
including a neuron that activates on German text. We show that this neuron
exists within a broader contextual n-gram circuit: we find late layer neurons
which recognize and continue n-grams common in German text, but which only
activate if the German neuron is active. We investigate the formation of this
circuit throughout training and find that it is an example of what we call a
second-order circuit. In particular, both the constituent n-gram circuits and
the German detection circuit which culminates in the German neuron form with
independent functions early in training - the German detection circuit
partially through modeling German unigram statistics, and the n-grams by
boosting appropriate completions. Only after both circuits have already formed
do they fit together into a second-order circuit. Contrary to the hypotheses
presented in prior work, we find that the contextual n-gram circuit forms
gradually rather than in a sudden phase transition. We further present a range
of anomalous observations such as a simultaneous phase transition in many tasks
coinciding with the learning rate warm-up, and evidence that many context
neurons form simultaneously early in training but are later unlearned.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quirke_L/0/1/0/all/0/1&quot;&gt;Lucia Quirke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heindrich_L/0/1/0/all/0/1&quot;&gt;Lovis Heindrich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurnee_W/0/1/0/all/0/1&quot;&gt;Wes Gurnee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nanda_N/0/1/0/all/0/1&quot;&gt;Neel Nanda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00865">
<title>Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning. (arXiv:2311.00865v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00865</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized
Experience Relay, in which agents share with other agents a limited number of
transitions they observe during training. The intuition behind this is that
even a small number of relevant experiences from other agents could help each
agent learn. Unlike many other multi-agent RL algorithms, this approach allows
for largely decentralized training, requiring only a limited communication
channel between agents. We show that our approach outperforms baseline
no-sharing decentralized training and state-of-the art multi-agent RL
algorithms. Further, sharing only a small number of highly relevant experiences
outperforms sharing all experiences between agents, and the performance uplift
from selective experience sharing is robust across a range of hyperparameters
and DQN variants. A reference implementation of our algorithm is available at
https://github.com/mgerstgrasser/super.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerstgrasser_M/0/1/0/all/0/1&quot;&gt;Matthias Gerstgrasser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Danino_T/0/1/0/all/0/1&quot;&gt;Tom Danino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keren_S/0/1/0/all/0/1&quot;&gt;Sarah Keren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00866">
<title>Generalizing Nonlinear ICA Beyond Structural Sparsity. (arXiv:2311.00866v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00866</link>
<description rdf:parseType="Literal">&lt;p&gt;Nonlinear independent component analysis (ICA) aims to uncover the true
latent sources from their observable nonlinear mixtures. Despite its
significance, the identifiability of nonlinear ICA is known to be impossible
without additional assumptions. Recent advances have proposed conditions on the
connective structure from sources to observed variables, known as Structural
Sparsity, to achieve identifiability in an unsupervised manner. However, the
sparsity constraint may not hold universally for all sources in practice.
Furthermore, the assumptions of bijectivity of the mixing process and
independence among all sources, which arise from the setting of ICA, may also
be violated in many real-world scenarios. To address these limitations and
generalize nonlinear ICA, we propose a set of new identifiability results in
the general settings of undercompleteness, partial sparsity and source
dependence, and flexible grouping structures. Specifically, we prove
identifiability when there are more observed variables than sources
(undercomplete), and when certain sparsity and/or source independence
assumptions are not met for some changing sources. Moreover, we show that even
in cases with flexible grouping structures (e.g., part of the sources can be
divided into irreducible independent groups with various sizes), appropriate
identifiability results can also be established. Theoretical claims are
supported empirically on both synthetic and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yujia Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00871">
<title>Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models. (arXiv:2311.00871v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00871</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer models, notably large language models (LLMs), have the remarkable
ability to perform in-context learning (ICL) -- to perform new tasks when
prompted with unseen input-output examples without any explicit model training.
In this work, we study how effectively transformers can bridge between their
pretraining data mixture, comprised of multiple distinct task families, to
identify and learn new tasks in-context which are both inside and outside the
pretraining distribution. Building on previous work, we investigate this
question in a controlled setting, where we study transformer models trained on
sequences of $(x, f(x))$ pairs rather than natural language. Our empirical
results show transformers demonstrate near-optimal unsupervised model selection
capabilities, in their ability to first in-context identify different task
families and in-context learn within them when the task families are
well-represented in their pretraining data. However when presented with tasks
or functions which are out-of-domain of their pretraining data, we demonstrate
various failure modes of transformers and degradation of their generalization
for even simple extrapolation tasks. Together our results highlight that the
impressive ICL abilities of high-capacity sequence models may be more closely
tied to the coverage of their pretraining data mixtures than inductive biases
that create fundamental generalization capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadlowsky_S/0/1/0/all/0/1&quot;&gt;Steve Yadlowsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doshi_L/0/1/0/all/0/1&quot;&gt;Lyric Doshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripuraneni_N/0/1/0/all/0/1&quot;&gt;Nilesh Tripuraneni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00873">
<title>Low-latency Real-time Voice Conversion on CPU. (arXiv:2311.00873v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2311.00873</link>
<description rdf:parseType="Literal">&lt;p&gt;We adapt the architectures of previous audio manipulation and generation
neural networks to the task of real-time any-to-one voice conversion. Our
resulting model, LLVC ($\textbf{L}$ow-latency $\textbf{L}$ow-resource
$\textbf{V}$oice $\textbf{C}$onversion), has a latency of under 20ms at a
bitrate of 16kHz and runs nearly 2.8x faster than real-time on a consumer CPU.
LLVC uses both a generative adversarial architecture as well as knowledge
distillation in order to attain this performance. To our knowledge LLVC
achieves both the lowest resource usage as well as the lowest latency of any
open-source voice conversion model. We provide open-source samples, code, and
pretrained model weights at https://github.com/KoeAI/LLVC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadov_K/0/1/0/all/0/1&quot;&gt;Konstantine Sadov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1&quot;&gt;Matthew Hutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Near_A/0/1/0/all/0/1&quot;&gt;Asara Near&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00875">
<title>Learning Collective Behaviors from Observation. (arXiv:2311.00875v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00875</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a review of a series of learning methods used to identify the
structure of dynamical systems, aiming to understand emergent behaviors in
complex systems of interacting agents. These methods not only offer theoretical
guarantees of convergence but also demonstrate computational efficiency in
handling high-dimensional observational data. They can manage observation data
from both first- and second-order dynamical systems, accounting for
observation/stochastic noise, complex interaction rules, missing interaction
features, and real-world observations of interacting agent systems. The essence
of developing such a series of learning methods lies in designing appropriate
loss functions using the variational inverse problem approach, which inherently
provides dimension reduction capabilities to our learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jinchao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1&quot;&gt;Ming Zhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00880">
<title>SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization. (arXiv:2311.00880v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00880</link>
<description rdf:parseType="Literal">&lt;p&gt;Incorporating safety is an essential prerequisite for broadening the
practical applications of reinforcement learning in real-world scenarios. To
tackle this challenge, Constrained Markov Decision Processes (CMDPs) are
leveraged, which introduce a distinct cost function representing safety
violations. In CMDPs&apos; settings, Lagrangian relaxation technique has been
employed in previous algorithms to convert constrained optimization problems
into unconstrained dual problems. However, these algorithms may inaccurately
predict unsafe behavior, resulting in instability while learning the Lagrange
multiplier. This study introduces a novel safe reinforcement learning
algorithm, Safety Critic Policy Optimization (SCPO). In this study, we define
the safety critic, a mechanism that nullifies rewards obtained through
violating safety constraints. Furthermore, our theoretical analysis indicates
that the proposed algorithm can automatically balance the trade-off between
adhering to safety constraints and maximizing rewards. The effectiveness of the
SCPO algorithm is empirically validated by benchmarking it against strong
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mhamed_J/0/1/0/all/0/1&quot;&gt;Jaafar Mhamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1&quot;&gt;Shangding Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00886">
<title>COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised Learning. (arXiv:2311.00886v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00886</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimation of temporal counterfactual outcomes from observed history is
crucial for decision-making in many domains such as healthcare and e-commerce,
particularly when randomized controlled trials (RCTs) suffer from high cost or
impracticality. For real-world datasets, modeling time-dependent confounders is
challenging due to complex dynamics, long-range dependencies and both past
treatments and covariates affecting the future outcomes. In this paper, we
introduce COunterfactual Self-supervised TrAnsformeR (COSTAR), a novel approach
that integrates self-supervised learning for improved historical
representations. The proposed framework combines temporal and feature-wise
attention with a component-wise contrastive loss tailored for temporal
treatment outcome observations, yielding superior performance in estimation
accuracy and generalization to out-of-distribution data compared to existing
models, as validated by empirical results on both synthetic and real-world
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1&quot;&gt;Chuizheng Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yihe Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1&quot;&gt;Sercan &amp;#xd6;. Ar&amp;#x131;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1&quot;&gt;Tomas Pfister&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00902">
<title>Data-Driven Model Selections of Second-Order Particle Dynamics via Integrating Gaussian Processes with Low-Dimensional Interacting Structures. (arXiv:2311.00902v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.00902</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we focus on the data-driven discovery of a general
second-order particle-based model that contains many state-of-the-art models
for modeling the aggregation and collective behavior of interacting agents of
similar size and body type. This model takes the form of a high-dimensional
system of ordinary differential equations parameterized by two interaction
kernels that appraise the alignment of positions and velocities. We propose a
Gaussian Process-based approach to this problem, where the unknown model
parameters are marginalized by using two independent Gaussian Process (GP)
priors on latent interaction kernels constrained to dynamics and observational
data. This results in a nonparametric model for interacting dynamical systems
that accounts for uncertainty quantification. We also develop acceleration
techniques to improve scalability. Moreover, we perform a theoretical analysis
to interpret the methodology and investigate the conditions under which the
kernels can be recovered. We demonstrate the effectiveness of the proposed
approach on various prototype systems, including the selection of the order of
the systems and the types of interactions. In particular, we present
applications to modeling two real-world fish motion datasets that display
flocking and milling patterns up to 248 dimensions. Despite the use of small
data sets, the GP-based approach learns an effective representation of the
nonlinear dynamics in these spaces and outperforms competitor methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jinchao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kulick_C/0/1/0/all/0/1&quot;&gt;Charles Kulick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Sui Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00906">
<title>Re-weighting Tokens: A Simple and Effective Active Learning Strategy for Named Entity Recognition. (arXiv:2311.00906v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.00906</link>
<description rdf:parseType="Literal">&lt;p&gt;Active learning, a widely adopted technique for enhancing machine learning
models in text and image classification tasks with limited annotation
resources, has received relatively little attention in the domain of Named
Entity Recognition (NER). The challenge of data imbalance in NER has hindered
the effectiveness of active learning, as sequence labellers lack sufficient
learning signals. To address these challenges, this paper presents a novel
reweighting-based active learning strategy that assigns dynamic smoothed
weights to individual tokens. This adaptable strategy is compatible with
various token-level acquisition functions and contributes to the development of
robust active learners. Experimental results on multiple corpora demonstrate
the substantial performance improvement achieved by incorporating our
re-weighting strategy into existing acquisition functions, validating its
practical efficacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Haocheng Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1&quot;&gt;Wei Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Ngoc Dang Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1&quot;&gt;Lan Du&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00919">
<title>MIST: Defending Against Membership Inference Attacks Through Membership-Invariant Subspace Training. (arXiv:2311.00919v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2311.00919</link>
<description rdf:parseType="Literal">&lt;p&gt;In Member Inference (MI) attacks, the adversary try to determine whether an
instance is used to train a machine learning (ML) model. MI attacks are a major
privacy concern when using private data to train ML models. Most MI attacks in
the literature take advantage of the fact that ML models are trained to fit the
training data well, and thus have very low loss on training instances. Most
defenses against MI attacks therefore try to make the model fit the training
data less well. Doing so, however, generally results in lower accuracy. We
observe that training instances have different degrees of vulnerability to MI
attacks. Most instances will have low loss even when not included in training.
For these instances, the model can fit them well without concerns of MI
attacks. An effective defense only needs to (possibly implicitly) identify
instances that are vulnerable to MI attacks and avoids overfitting them. A
major challenge is how to achieve such an effect in an efficient training
process. Leveraging two distinct recent advancements in representation
learning: counterfactually-invariant representations and subspace learning
methods, we introduce a novel Membership-Invariant Subspace Training (MIST)
method to defend against MI attacks. MIST avoids overfitting the vulnerable
instances without significant impact on other instances. We have conducted
extensive experimental studies, comparing MIST with various other
state-of-the-art (SOTA) MI defenses against several SOTA MI attacks. We find
that MIST outperforms other defenses while resulting in minimal reduction in
testing accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiacheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1&quot;&gt;Ninghui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1&quot;&gt;Bruno Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00923">
<title>A Review and Roadmap of Deep Causal Model from Different Causal Structures and Representations. (arXiv:2311.00923v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00923</link>
<description rdf:parseType="Literal">&lt;p&gt;The fusion of causal models with deep learning introducing increasingly
intricate data sets, such as the causal associations within images or between
textual components, has surfaced as a focal research area. Nonetheless, the
broadening of original causal concepts and theories to such complex,
non-statistical data has been met with serious challenges. In response, our
study proposes redefinitions of causal data into three distinct categories from
the standpoint of causal structure and representation: definite data,
semi-definite data, and indefinite data. Definite data chiefly pertains to
statistical data used in conventional causal scenarios, while semi-definite
data refers to a spectrum of data formats germane to deep learning, including
time-series, images, text, and others. Indefinite data is an emergent research
sphere inferred from the progression of data forms by us. To comprehensively
present these three data paradigms, we elaborate on their formal definitions,
differences manifested in datasets, resolution pathways, and development of
research. We summarize key tasks and achievements pertaining to definite and
semi-definite data from myriad research undertakings, present a roadmap for
indefinite data, beginning with its current research conundrums. Lastly, we
classify and scrutinize the key datasets presently utilized within these three
paradigms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_K/0/1/0/all/0/1&quot;&gt;Keqing Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chenguang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xinyu Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00927">
<title>Scalable Counterfactual Distribution Estimation in Multivariate Causal Models. (arXiv:2311.00927v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.00927</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of estimating the counterfactual joint distribution
of multiple quantities of interests (e.g., outcomes) in a multivariate causal
model extended from the classical difference-in-difference design. Existing
methods for this task either ignore the correlation structures among dimensions
of the multivariate outcome by considering univariate causal models on each
dimension separately and hence produce incorrect counterfactual distributions,
or poorly scale even for moderate-size datasets when directly dealing with such
multivariate causal model. We propose a method that alleviates both issues
simultaneously by leveraging a robust latent one-dimensional subspace of the
original high-dimension space and exploiting the efficient estimation from the
univariate causal model on such space. Since the construction of the
one-dimensional subspace uses information from all the dimensions, our method
can capture the correlation structures and produce good estimates of the
counterfactual distribution. We demonstrate the advantages of our approach over
existing methods on both synthetic and real-world data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pham_T/0/1/0/all/0/1&quot;&gt;Thong Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shimizu_S/0/1/0/all/0/1&quot;&gt;Shohei Shimizu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hino_H/0/1/0/all/0/1&quot;&gt;Hideitsu Hino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Tam Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00931">
<title>Learning Defect Prediction from Unrealistic Data. (arXiv:2311.00931v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00931</link>
<description rdf:parseType="Literal">&lt;p&gt;Pretrained models of code, such as CodeBERT and CodeT5, have become popular
choices for code understanding and generation tasks. Such models tend to be
large and require commensurate volumes of training data, which are rarely
available for downstream tasks. Instead, it has become popular to train models
with far larger but less realistic datasets, such as functions with
artificially injected bugs. Models trained on such data, however, tend to only
perform well on similar data, while underperforming on real world programs. In
this paper, we conjecture that this discrepancy stems from the presence of
distracting samples that steer the model away from the real-world task
distribution. To investigate this conjecture, we propose an approach for
identifying the subsets of these large yet unrealistic datasets that are most
similar to examples in real-world datasets based on their learned
representations. Our approach extracts high-dimensional embeddings of both
real-world and artificial programs using a neural model and scores artificial
samples based on their distance to the nearest real-world sample. We show that
training on only the nearest, representationally most similar samples while
discarding samples that are not at all similar in representations yields
consistent improvements across two popular pretrained models of code on two
code understanding tasks. Our results are promising, in that they show that
training models on a representative subset of an unrealistic dataset can help
us harness the power of large-scale synthetic data generation while preserving
downstream task performance. Finally, we highlight the limitations of applying
AI models for predicting vulnerabilities and bugs in real-world applications
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alrashedy_K/0/1/0/all/0/1&quot;&gt;Kamel Alrashedy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hellendoorn_V/0/1/0/all/0/1&quot;&gt;Vincent J. Hellendoorn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orso_A/0/1/0/all/0/1&quot;&gt;Alessandro Orso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00936">
<title>SatBird: Bird Species Distribution Modeling with Remote Sensing and Citizen Science Data. (arXiv:2311.00936v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00936</link>
<description rdf:parseType="Literal">&lt;p&gt;Biodiversity is declining at an unprecedented rate, impacting ecosystem
services necessary to ensure food, water, and human health and well-being.
Understanding the distribution of species and their habitats is crucial for
conservation policy planning. However, traditional methods in ecology for
species distribution models (SDMs) generally focus either on narrow sets of
species or narrow geographical areas and there remain significant knowledge
gaps about the distribution of species. A major reason for this is the limited
availability of data traditionally used, due to the prohibitive amount of
effort and expertise required for traditional field monitoring. The wide
availability of remote sensing data and the growing adoption of citizen science
tools to collect species observations data at low cost offer an opportunity for
improving biodiversity monitoring and enabling the modelling of complex
ecosystems. We introduce a novel task for mapping bird species to their
habitats by predicting species encounter rates from satellite images, and
present SatBird, a satellite dataset of locations in the USA with labels
derived from presence-absence observation data from the citizen science
database eBird, considering summer (breeding) and winter seasons. We also
provide a dataset in Kenya representing low-data regimes. We additionally
provide environmental data and species range maps for each location. We
benchmark a set of baselines on our dataset, including SOTA models for remote
sensing tasks. SatBird opens up possibilities for scalably modelling properties
of ecosystems worldwide.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teng_M/0/1/0/all/0/1&quot;&gt;M&amp;#xe9;lisande Teng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elmustafa_A/0/1/0/all/0/1&quot;&gt;Amna Elmustafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akera_B/0/1/0/all/0/1&quot;&gt;Benjamin Akera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdelwahed_H/0/1/0/all/0/1&quot;&gt;Hager Radi Abdelwahed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1&quot;&gt;Hugo Larochelle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rolnick_D/0/1/0/all/0/1&quot;&gt;David Rolnick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00938">
<title>Bridging the Gap: Addressing Discrepancies in Diffusion Model Training for Classifier-Free Guidance. (arXiv:2311.00938v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00938</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models have emerged as a pivotal advancement in generative models,
setting new standards to the quality of the generated instances. In the current
paper we aim to underscore a discrepancy between conventional training methods
and the desired conditional sampling behavior of these models. While the
prevalent classifier-free guidance technique works well, it&apos;s not without
flaws. At higher values for the guidance scale parameter $w$, we often get out
of distribution samples and mode collapse, whereas at lower values for $w$ we
may not get the desired specificity. To address these challenges, we introduce
an updated loss function that better aligns training objectives with sampling
behaviors. Experimental validation with FID scores on CIFAR-10 elucidates our
method&apos;s ability to produce higher quality samples with fewer sampling
timesteps, and be more robust to the choice of guidance scale $w$. We also
experiment with fine-tuning Stable Diffusion on the proposed loss, to provide
early evidence that large diffusion models may also benefit from this refined
loss function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_N/0/1/0/all/0/1&quot;&gt;Niket Patel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salamanca_L/0/1/0/all/0/1&quot;&gt;Luis Salamanca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barba_L/0/1/0/all/0/1&quot;&gt;Luis Barba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00941">
<title>Gaussian Mixture Solvers for Diffusion Models. (arXiv:2311.00941v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00941</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, diffusion models have achieved great success in generative tasks.
Sampling from diffusion models is equivalent to solving the reverse diffusion
stochastic differential equations (SDEs) or the corresponding probability flow
ordinary differential equations (ODEs). In comparison, SDE-based solvers can
generate samples of higher quality and are suited for image translation tasks
like stroke-based synthesis. During inference, however, existing SDE-based
solvers are severely constrained by the efficiency-effectiveness dilemma. Our
investigation suggests that this is because the Gaussian assumption in the
reverse transition kernel is frequently violated (even in the case of simple
mixture data) given a limited number of discretization steps. To overcome this
limitation, we introduce a novel class of SDE-based solvers called
\emph{Gaussian Mixture Solvers (GMS)} for diffusion models. Our solver
estimates the first three-order moments and optimizes the parameters of a
Gaussian mixture transition kernel using generalized methods of moments in each
step during sampling. Empirically, our solver outperforms numerous SDE-based
solvers in terms of sample quality in image generation and stroke-based
synthesis in various diffusion models, which validates the motivation and
effectiveness of GMS. Our code is available at
https://github.com/Guohanzhong/GMS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Hanzhong Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Cheng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_F/0/1/0/all/0/1&quot;&gt;Fan Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1&quot;&gt;Tianyu Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1&quot;&gt;Shuicheng Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1&quot;&gt;Chao Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chongxuan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00944">
<title>Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization. (arXiv:2311.00944v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.00944</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, federated minimax optimization has attracted growing
interest due to its extensive applications in various machine learning tasks.
While Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved
its success in centralized nonconvex minimax optimization, how and whether
smoothing technique could be helpful in federated setting remains unexplored.
In this paper, we propose a new algorithm termed Federated Stochastic Smoothed
Gradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for
federated minimax optimization. We prove that FESS-GDA can be uniformly used to
solve several classes of federated minimax problems and prove new or better
analytical convergence results for these settings. We showcase the practical
efficiency of FESS-GDA in practical federated learning tasks of training
generative adversarial networks (GANs) and fair classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_W/0/1/0/all/0/1&quot;&gt;Wei Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_M/0/1/0/all/0/1&quot;&gt;Minhui Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Cong Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00945">
<title>E3 TTS: Easy End-to-End Diffusion-based Text to Speech. (arXiv:2311.00945v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2311.00945</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Easy End-to-End Diffusion-based Text to Speech, a simple and
efficient end-to-end text-to-speech model based on diffusion. E3 TTS directly
takes plain text as input and generates an audio waveform through an iterative
refinement process. Unlike many prior work, E3 TTS does not rely on any
intermediate representations like spectrogram features or alignment
information. Instead, E3 TTS models the temporal structure of the waveform
through the diffusion process. Without relying on additional conditioning
information, E3 TTS could support flexible latent structure within the given
audio. This enables E3 TTS to be easily adapted for zero-shot tasks such as
editing without any additional training. Experiments show that E3 TTS can
generate high-fidelity audio, approaching the performance of a state-of-the-art
neural TTS system. Audio samples are available at https://e3tts.github.io.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yuan Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morioka_N/0/1/0/all/0/1&quot;&gt;Nobuyuki Morioka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1&quot;&gt;Nanxin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00959">
<title>Dynamic Fair Federated Learning Based on Reinforcement Learning. (arXiv:2311.00959v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00959</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning enables a collaborative training and optimization of
global models among a group of devices without sharing local data samples.
However, the heterogeneity of data in federated learning can lead to unfair
representation of the global model across different devices. To address the
fairness issue in federated learning, we propose a dynamic q fairness federated
learning algorithm with reinforcement learning, called DQFFL. DQFFL aims to
mitigate the discrepancies in device aggregation and enhance the fairness of
treatment for all groups involved in federated learning. To quantify fairness,
DQFFL leverages the performance of the global federated model on each device
and incorporates {\alpha}-fairness to transform the preservation of fairness
during federated aggregation into the distribution of client weights in the
aggregation process. Considering the sensitivity of parameters in measuring
fairness, we propose to utilize reinforcement learning for dynamic parameters
during aggregation. Experimental results demonstrate that our DQFFL outperforms
the state-of-the-art methods in terms of overall performance, fairness and
convergence speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Weikang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1&quot;&gt;Junping Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1&quot;&gt;Yingxia Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jia Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yangxi Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00964">
<title>On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications. (arXiv:2311.00964v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00964</link>
<description rdf:parseType="Literal">&lt;p&gt;Rules are widely used in Fintech institutions to make fraud prevention
decisions, since rules are highly interpretable thanks to their intuitive
if-then structure. In practice, a two-stage framework of fraud prevention
decision rule set mining is usually employed in large Fintech institutions.
This paper is concerned with finding high-quality rule subsets in a
bi-objective space (such as precision and recall) from an initial pool of
rules. To this end, we adopt the concept of Pareto optimality and aim to find a
set of non-dominated rule subsets, which constitutes a Pareto front. We propose
a heuristic-based framework called PORS and we identify that the core of PORS
is the problem of solution selection on the front (SSF). We provide a
systematic categorization of the SSF problem and a thorough empirical
evaluation of various SSF methods on both public and proprietary datasets. We
also introduce a novel variant of sequential covering algorithm called
SpectralRules to encourage the diversity of the initial rule set and we
empirically find that SpectralRules further improves the quality of the found
Pareto front. On two real application scenarios within Alipay, we demonstrate
the advantages of our proposed methodology compared to existing work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1&quot;&gt;Chengyao Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1&quot;&gt;Yin Lou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00966">
<title>Invariant-Feature Subspace Recovery: A New Class of Provable Domain Generalization Algorithms. (arXiv:2311.00966v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00966</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain generalization asks for models trained over a set of training
environments to generalize well in unseen test environments. Recently, a series
of algorithms such as Invariant Risk Minimization (IRM) have been proposed for
domain generalization. However, Rosenfeld et al. (2021) shows that in a simple
linear data model, even if non-convexity issues are ignored, IRM and its
extensions cannot generalize to unseen environments with less than $d_s+1$
training environments, where $d_s$ is the dimension of the spurious-feature
subspace. In this work, we propose Invariant-feature Subspace Recovery (ISR): a
new class of algorithms to achieve provable domain generalization across the
settings of classification and regression problems. First, in the binary
classification setup of Rosenfeld et al. (2021), we show that our first
algorithm, ISR-Mean, can identify the subspace spanned by invariant features
from the first-order moments of the class-conditional distributions, and
achieve provable domain generalization with $d_s+1$ training environments. Our
second algorithm, ISR-Cov, further reduces the required number of training
environments to $O(1)$ using the information of second-order moments. Notably,
unlike IRM, our algorithms bypass non-convexity issues and enjoy global
convergence guarantees. Next, we extend ISR-Mean to the more general setting of
multi-class classification and propose ISR-Multiclass, which leverages class
information and provably recovers the invariant-feature subspace with $\lceil
d_s/k\rceil+1$ training environments for $k$-class classification. Finally, for
regression problems, we propose ISR-Regression that can identify the
invariant-feature subspace with $d_s+1$ training environments. Empirically, we
demonstrate the superior performance of our ISRs on synthetic benchmarks.
Further, ISR can be used as post-processing methods for feature extractors such
as neural nets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haoxiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balasubramaniam_G/0/1/0/all/0/1&quot;&gt;Gargi Balasubramaniam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Si_H/0/1/0/all/0/1&quot;&gt;Haozhe Si&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Han Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00971">
<title>An Integrated Framework Integrating Monte Carlo Tree Search and Supervised Learning for Train Timetabling Problem. (arXiv:2311.00971v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00971</link>
<description rdf:parseType="Literal">&lt;p&gt;The single-track railway train timetabling problem (TTP) is an important and
complex problem. This article proposes an integrated Monte Carlo Tree Search
(MCTS) computing framework that combines heuristic methods, unsupervised
learning methods, and supervised learning methods for solving TTP in discrete
action spaces. This article first describes the mathematical model and
simulation system dynamics of TTP, analyzes the characteristics of the solution
from the perspective of MCTS, and proposes some heuristic methods to improve
MCTS. This article considers these methods as planners in the proposed
framework. Secondly, this article utilizes deep convolutional neural networks
to approximate the value of nodes and further applies them to the MCTS search
process, referred to as learners. The experiment shows that the proposed
heuristic MCTS method is beneficial for solving TTP; The algorithm framework
that integrates planners and learners can improve the data efficiency of
solving TTP; The proposed method provides a new paradigm for solving TTP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Feiyu Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00973">
<title>Federated Linear Bandits with Finite Adversarial Actions. (arXiv:2311.00973v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00973</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a federated linear bandits model, where $M$ clients communicate with
a central server to solve a linear contextual bandits problem with finite
adversarial action sets that may be different across clients. To address the
unique challenges of adversarial finite action sets, we propose the
FedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL
algorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a
total regret of $\tilde{O}(\sqrt{d T})$, where $T$ is the total number of arm
pulls from all clients, and $d$ is the ambient dimension of the linear model.
This matches the minimax lower bound and thus is order-optimal (up to polylog
terms). We study both asynchronous and synchronous cases and show that the
communication cost can be controlled as $O(d M^2 \log(d)\log(T))$ and
$O(\sqrt{d^3 M^3} \log(d))$, respectively. The FedSupLinUCB design is further
extended to two scenarios: (1) variance-adaptive, where a total regret of
$\tilde{O} (\sqrt{d \sum \nolimits_{t=1}^{T} \sigma_t^2})$ can be achieved with
$\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial
corruption, where a total regret of $\tilde{O}(\sqrt{dT} + d C_p)$ can be
achieved with $C_p$ being the total corruption budget. Experiment results
corroborate the theoretical analysis and demonstrate the effectiveness of
FedSupLinUCB on both synthetic and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Li Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1&quot;&gt;Ruida Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1&quot;&gt;Chao Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Cong Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00975">
<title>Autonomous Learning of Generative Models with Chemical Reaction Network Ensembles. (arXiv:2311.00975v1 [q-bio.MN])</title>
<link>http://arxiv.org/abs/2311.00975</link>
<description rdf:parseType="Literal">&lt;p&gt;Can a micron sized sack of interacting molecules autonomously learn an
internal model of a complex and fluctuating environment? We draw insights from
control theory, machine learning theory, chemical reaction network theory, and
statistical physics to develop a general architecture whereby a broad class of
chemical systems can autonomously learn complex distributions. Our construction
takes the form of a chemical implementation of machine learning&apos;s optimization
workhorse: gradient descent on the relative entropy cost function. We show how
this method can be applied to optimize any detailed balanced chemical reaction
network and that the construction is capable of using hidden units to learn
complex distributions. This result is then recast as a form of integral
feedback control. Finally, due to our use of an explicit physical model of
learning, we are able to derive thermodynamic costs and trade-offs associated
to this process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Poole_W/0/1/0/all/0/1&quot;&gt;William Poole&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ouldridge_T/0/1/0/all/0/1&quot;&gt;Thomas E. Ouldridge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gopalkrishnan_M/0/1/0/all/0/1&quot;&gt;Manoj Gopalkrishnan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00983">
<title>Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks. (arXiv:2311.00983v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00983</link>
<description rdf:parseType="Literal">&lt;p&gt;Inventory Routing Problem (IRP) is a crucial challenge in supply chain
management as it involves optimizing efficient route selection while
considering the uncertainty of inventory demand planning. To solve IRPs,
usually a two-stage approach is employed, where demand is predicted using
machine learning techniques first, and then an optimization algorithm is used
to minimize routing costs. Our experiment shows machine learning models fall
short of achieving perfect accuracy because inventory levels are influenced by
the dynamic business environment, which, in turn, affects the optimization
problem in the next stage, resulting in sub-optimal decisions. In this paper,
we formulate and propose a decision-focused learning-based approach to solving
real-world IRPs. This approach directly integrates inventory prediction and
routing optimization within an end-to-end system potentially ensuring a robust
supply chain strategy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1&quot;&gt;MD Shafikul Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wasi_A/0/1/0/all/0/1&quot;&gt;Azmine Toushik Wasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00993">
<title>Scalable Probabilistic Forecasting in Retail with Gradient Boosted Trees: A Practitioner&apos;s Approach. (arXiv:2311.00993v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.00993</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent M5 competition has advanced the state-of-the-art in retail
forecasting. However, we notice important differences between the competition
challenge and the challenges we face in a large e-commerce company. The
datasets in our scenario are larger (hundreds of thousands of time series), and
e-commerce can afford to have a larger assortment than brick-and-mortar
retailers, leading to more intermittent data. To scale to larger dataset sizes
with feasible computational effort, firstly, we investigate a two-layer
hierarchy and propose a top-down approach to forecasting at an aggregated level
with less amount of series and intermittency, and then disaggregating to obtain
the decision-level forecasts. Probabilistic forecasts are generated under
distributional assumptions. Secondly, direct training at the lower level with
subsamples can also be an alternative way of scaling. Performance of modelling
with subsets is evaluated with the main dataset. Apart from a proprietary
dataset, the proposed scalable methods are evaluated using the Favorita dataset
and the M5 dataset. We are able to show the differences in characteristics of
the e-commerce and brick-and-mortar retail datasets. Notably, our top-down
forecasting framework enters the top 50 of the original M5 competition, even
with models trained at a higher level under a much simpler setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_X/0/1/0/all/0/1&quot;&gt;Xueying Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bui_Q/0/1/0/all/0/1&quot;&gt;Quang Bui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oktavian_G/0/1/0/all/0/1&quot;&gt;Grady Oktavian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_D/0/1/0/all/0/1&quot;&gt;Daniel F. Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1&quot;&gt;Christoph Bergmeir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godahewa_R/0/1/0/all/0/1&quot;&gt;Rakshitha Godahewa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seong Per Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1&quot;&gt;Kaifeng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Condylis_P/0/1/0/all/0/1&quot;&gt;Paul Condylis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01002">
<title>Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy. (arXiv:2311.01002v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01002</link>
<description rdf:parseType="Literal">&lt;p&gt;Data pruning, which aims to downsize a large training set into a small
informative subset, is crucial for reducing the enormous computational costs of
modern deep learning. Though large-scale data collections invariably contain
annotation noise and numerous robust learning methods have been developed, data
pruning for the noise-robust learning scenario has received little attention.
With state-of-the-art Re-labeling methods that self-correct erroneous labels
while training, it is challenging to identify which subset induces the most
accurate re-labeling of erroneous labels in the entire training set. In this
paper, we formalize the problem of data pruning with re-labeling. We first show
that the likelihood of a training example being correctly re-labeled is
proportional to the prediction confidence of its neighborhood in the subset.
Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a
subset maximizing the total neighborhood confidence of all training examples,
thereby maximizing the re-labeling accuracy and generalization performance.
Extensive experiments on four real and one synthetic noisy datasets show that
\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as
well as those with a standard model by up to 21.6%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1&quot;&gt;Dongmin Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Seola Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Doyoung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1&quot;&gt;Hwanjun Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jae-Gil Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01007">
<title>Effective Human-AI Teams via Learned Natural Language Rules and Onboarding. (arXiv:2311.01007v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01007</link>
<description rdf:parseType="Literal">&lt;p&gt;People are relying on AI agents to assist them with various tasks. The human
must know when to rely on the agent, collaborate with the agent, or ignore its
suggestions. In this work, we propose to learn rules grounded in data regions
and described in natural language that illustrate how the human should
collaborate with the AI. Our novel region discovery algorithm finds local
regions in the data as neighborhoods in an embedding space that corrects the
human prior. Each region is then described using an iterative and contrastive
procedure where a large language model describes the region. We then teach
these rules to the human via an onboarding stage. Through user studies on
object detection and question-answering tasks, we show that our method can lead
to more accurate human-AI teams. We also evaluate our region discovery and
description algorithms separately.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozannar_H/0/1/0/all/0/1&quot;&gt;Hussein Mozannar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jimin J Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1&quot;&gt;Dennis Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1&quot;&gt;Prasanna Sattigeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1&quot;&gt;Subhro Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1&quot;&gt;David Sontag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01010">
<title>Exploring Unified Perspective For Fast Shapley Value Estimation. (arXiv:2311.01010v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01010</link>
<description rdf:parseType="Literal">&lt;p&gt;Shapley values have emerged as a widely accepted and trustworthy tool,
grounded in theoretical axioms, for addressing challenges posed by black-box
models like deep neural networks. However, computing Shapley values encounters
exponential complexity in the number of features. Various approaches, including
ApproSemivalue, KernelSHAP, and FastSHAP, have been explored to expedite the
computation. We analyze the consistency of existing works and conclude that
stochastic estimators can be unified as the linear transformation of importance
sampling of feature subsets. Based on this, we investigate the possibility of
designing simple amortized estimators and propose a straightforward and
efficient one, SimSHAP, by eliminating redundant techniques. Extensive
experiments conducted on tabular and image datasets validate the effectiveness
of our SimSHAP, which significantly accelerates the computation of accurate
Shapley values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Borui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_B/0/1/0/all/0/1&quot;&gt;Baotong Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1&quot;&gt;Wenzhao Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jie Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiwen Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01011">
<title>Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game. (arXiv:2311.01011v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01011</link>
<description rdf:parseType="Literal">&lt;p&gt;While Large Language Models (LLMs) are increasingly being used in real-world
applications, they remain vulnerable to prompt injection attacks: malicious
third party prompts that subvert the intent of the system designer. To help
researchers study this problem, we present a dataset of over 126,000 prompt
injection attacks and 46,000 prompt-based &quot;defenses&quot; against prompt injection,
all created by players of an online game called Tensor Trust. To the best of
our knowledge, this is currently the largest dataset of human-generated
adversarial examples for instruction-following LLMs. The attacks in our dataset
have a lot of easily interpretable stucture, and shed light on the weaknesses
of LLMs. We also use the dataset to create a benchmark for resistance to two
types of prompt injection, which we refer to as prompt extraction and prompt
hijacking. Our benchmark results show that many models are vulnerable to the
attack strategies in the Tensor Trust dataset. Furthermore, we show that some
attack strategies from the dataset generalize to deployed LLM-based
applications, even though they have a very different set of constraints to the
game. We release all data and source code at https://tensortrust.ai/paper
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toyer_S/0/1/0/all/0/1&quot;&gt;Sam Toyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1&quot;&gt;Olivia Watkins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendes_E/0/1/0/all/0/1&quot;&gt;Ethan Adrian Mendes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svegliato_J/0/1/0/all/0/1&quot;&gt;Justin Svegliato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bailey_L/0/1/0/all/0/1&quot;&gt;Luke Bailey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tiffany Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ong_I/0/1/0/all/0/1&quot;&gt;Isaac Ong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elmaaroufi_K/0/1/0/all/0/1&quot;&gt;Karim Elmaaroufi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1&quot;&gt;Trevor Darrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1&quot;&gt;Alan Ritter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1&quot;&gt;Stuart Russell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01017">
<title>Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion. (arXiv:2311.01017v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01017</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning world models can teach an agent how the world works in an
unsupervised manner. Even though it can be viewed as a special case of sequence
modeling, progress for scaling world models on robotic applications such as
autonomous driving has been somewhat less rapid than scaling language models
with Generative Pre-trained Transformers (GPT). We identify two reasons as
major bottlenecks: dealing with complex and unstructured observation space, and
having a scalable generative model. Consequently, we propose a novel world
modeling approach that first tokenizes sensor observations with VQVAE, then
predicts the future via discrete diffusion. To efficiently decode and denoise
tokens in parallel, we recast Masked Generative Image Transformer into the
discrete diffusion framework with a few simple changes, resulting in notable
improvement. When applied to learning world models on point cloud observations,
our model reduces prior SOTA Chamfer distance by more than 65% for 1s
prediction, and more than 50% for 3s prediction, across NuScenes, KITTI
Odometry, and Argoverse2 datasets. Our results demonstrate that discrete
diffusion on tokenized agent experience can unlock the power of GPT-like
unsupervised learning for robotic agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lunjun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1&quot;&gt;Yuwen Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Ze Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casas_S/0/1/0/all/0/1&quot;&gt;Sergio Casas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1&quot;&gt;Rui Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1&quot;&gt;Raquel Urtasun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01024">
<title>Distance-Based Propagation for Efficient Knowledge Graph Reasoning. (arXiv:2311.01024v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01024</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graph completion (KGC) aims to predict unseen edges in knowledge
graphs (KGs), resulting in the discovery of new facts. A new class of methods
have been proposed to tackle this problem by aggregating path information.
These methods have shown tremendous ability in the task of KGC. However they
are plagued by efficiency issues. Though there are a few recent attempts to
address this through learnable path pruning, they often sacrifice the
performance to gain efficiency. In this work, we identify two intrinsic
limitations of these methods that affect the efficiency and representation
quality. To address the limitations, we introduce a new method, TAGNet, which
is able to efficiently propagate information. This is achieved by only
aggregating paths in a fixed window for each source-target pair. We demonstrate
that the complexity of TAGNet is independent of the number of layers. Extensive
experiments demonstrate that TAGNet can cut down on the number of propagated
messages by as much as 90% while achieving competitive performance on multiple
KG datasets. The code is available at https://github.com/HarryShomer/TAGNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shomer_H/0/1/0/all/0/1&quot;&gt;Harry Shomer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yao Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Juanhui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1&quot;&gt;Bo Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1&quot;&gt;Charu C. Aggarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jiliang Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01033">
<title>Non-Autoregressive Diffusion-based Temporal Point Processes for Continuous-Time Long-Term Event Prediction. (arXiv:2311.01033v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01033</link>
<description rdf:parseType="Literal">&lt;p&gt;Continuous-time long-term event prediction plays an important role in many
application scenarios. Most existing works rely on autoregressive frameworks to
predict event sequences, which suffer from error accumulation, thus
compromising prediction quality. Inspired by the success of denoising diffusion
probabilistic models, we propose a diffusion-based non-autoregressive temporal
point process model for long-term event prediction in continuous time. Instead
of generating events one at a time in an autoregressive way, our model predicts
the future event sequence entirely as a whole. In order to perform diffusion
processes on event sequences, we develop a bidirectional map between target
event sequences and the Euclidean vector space. Furthermore, we design a novel
denoising network to capture both sequential and contextual features for better
sample quality. Extensive experiments are conducted to prove the superiority of
our proposed model over state-of-the-art methods on long-term event prediction
in continuous time. To the best of our knowledge, this is the first work to
apply diffusion methods to long-term event prediction problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wang-Tao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1&quot;&gt;Zhao Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1&quot;&gt;Ling Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01038">
<title>Better with Less: A Data-Active Perspective on Pre-Training Graph Neural Networks. (arXiv:2311.01038v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01038</link>
<description rdf:parseType="Literal">&lt;p&gt;Pre-training on graph neural networks (GNNs) aims to learn transferable
knowledge for downstream tasks with unlabeled data, and it has recently become
an active research area. The success of graph pre-training models is often
attributed to the massive amount of input data. In this paper, however, we
identify the curse of big data phenomenon in graph pre-training: more training
data do not necessarily lead to better downstream performance. Motivated by
this observation, we propose a better-with-less framework for graph
pre-training: fewer, but carefully chosen data are fed into a GNN model to
enhance pre-training. The proposed pre-training pipeline is called the
data-active graph pre-training (APT) framework, and is composed of a graph
selector and a pre-training model. The graph selector chooses the most
representative and instructive data points based on the inherent properties of
graphs as well as predictive uncertainty. The proposed predictive uncertainty,
as feedback from the pre-training model, measures the confidence level of the
model in the data. When fed with the chosen data, on the other hand, the
pre-training model grasps an initial understanding of the new, unseen data, and
at the same time attempts to remember the knowledge learned from previous data.
Therefore, the integration and interaction between these two components form a
unified framework (APT), in which graph pre-training is performed in a
progressive and iterative way. Experiment results show that the proposed APT is
able to obtain an efficient pre-training model with fewer training data and
better downstream performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiarong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1&quot;&gt;Renhong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1&quot;&gt;Xin Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yuxuan Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Carl Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chunping Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01046">
<title>Time-Independent Information-Theoretic Generalization Bounds for SGLD. (arXiv:2311.01046v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01046</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide novel information-theoretic generalization bounds for stochastic
gradient Langevin dynamics (SGLD) under the assumptions of smoothness and
dissipativity, which are widely used in sampling and non-convex optimization
studies. Our bounds are time-independent and decay to zero as the sample size
increases, regardless of the number of iterations and whether the step size is
fixed. Unlike previous studies, we derive the generalization error bounds by
focusing on the time evolution of the Kullback--Leibler divergence, which is
related to the stability of datasets and is the upper bound of the mutual
information between output parameters and an input dataset. Additionally, we
establish the first information-theoretic generalization bound when the
training and test loss are the same by showing that a loss function of SGLD is
sub-exponential. This bound is also time-independent and removes the
problematic step size dependence in existing work, leading to an improved
excess risk bound by combining our analysis with the existing non-convex
optimization error bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Futami_F/0/1/0/all/0/1&quot;&gt;Futoshi Futami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujisawa_M/0/1/0/all/0/1&quot;&gt;Masahiro Fujisawa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01047">
<title>Improving Robustness via Tilted Exponential Layer: A Communication-Theoretic Perspective. (arXiv:2311.01047v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01047</link>
<description rdf:parseType="Literal">&lt;p&gt;State-of-the-art techniques for enhancing robustness of deep networks mostly
rely on empirical risk minimization with suitable data augmentation. In this
paper, we propose a complementary approach motivated by communication theory,
aimed at enhancing the signal-to-noise ratio at the output of a neural network
layer via neural competition during learning and inference. In addition to
minimization of a standard end-to-end cost, neurons compete to sparsely
represent layer inputs by maximization of a tilted exponential (TEXP) objective
function for the layer. TEXP learning can be interpreted as maximum likelihood
estimation of matched filters under a Gaussian model for data noise. Inference
in a TEXP layer is accomplished by replacing batch norm by a tilted softmax,
which can be interpreted as computation of posterior probabilities for the
competing signaling hypotheses represented by each neuron. After providing
insights via simplified models, we show, by experimentation on standard image
datasets, that TEXP learning and inference enhances robustness against noise
and other common corruptions, without requiring data augmentation. Further
cumulative gains in robustness against this array of distortions can be
obtained by appropriately combining TEXP with data augmentation techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puranik_B/0/1/0/all/0/1&quot;&gt;Bhagyashree Puranik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1&quot;&gt;Ahmad Beirami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1&quot;&gt;Yao Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madhow_U/0/1/0/all/0/1&quot;&gt;Upamanyu Madhow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01050">
<title>Application and Energy-Aware Data Aggregation using Vector Synchronization in Distributed Battery-less IoT Networks. (arXiv:2311.01050v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2311.01050</link>
<description rdf:parseType="Literal">&lt;p&gt;The battery-less Internet of Things (IoT) devices are a key element in the
sustainable green initiative for the next-generation wireless networks. These
battery-free devices use the ambient energy, harvested from the environment.
The energy harvesting environment is dynamic and causes intermittent task
execution. The harvested energy is stored in small capacitors and it is
challenging to assure the application task execution. The main goal is to
provide a mechanism to aggregate the sensor data and provide a sustainable
application support in the distributed battery-less IoT network. We model the
distributed IoT network system consisting of many battery-free IoT sensor
hardware modules and heterogeneous IoT applications that are being supported in
the device-edge-cloud continuum. The applications require sensor data from a
distributed set of battery-less hardware modules and there is provision of
joint control over the module actuators. We propose an application-aware task
and energy manager (ATEM) for the IoT devices and a vector-synchronization
based data aggregator (VSDA). The ATEM is supported by device-level federated
energy harvesting and system-level energy-aware heterogeneous application
management. In our proposed framework the data aggregator forecasts the
available power from the ambient energy harvester using long-short-term-memory
(LSTM) model and sets the device profile as well as the application task rates
accordingly. Our proposed scheme meets the heterogeneous application
requirements with negligible overhead; reduces the data loss and packet delay;
increases the hardware component availability; and makes the components
available sooner as compared to the state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhal_C/0/1/0/all/0/1&quot;&gt;Chetna Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barick_S/0/1/0/all/0/1&quot;&gt;Subhrajit Barick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonkar_R/0/1/0/all/0/1&quot;&gt;Rishabh Sonkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01052">
<title>Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis. (arXiv:2311.01052v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01052</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Resilient Multiple Choice Learning (rMCL), an extension of the
MCL approach for conditional distribution estimation in regression settings
where multiple targets may be sampled for each training input. Multiple Choice
Learning is a simple framework to tackle multimodal density estimation, using
the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression
settings, the existing MCL variants focus on merging the hypotheses, thereby
eventually sacrificing the diversity of the predictions. In contrast, our
method relies on a novel learned scoring scheme underpinned by a mathematical
framework based on Voronoi tessellations of the output space, from which we can
derive a probabilistic interpretation. After empirically validating rMCL with
experiments on synthetic data, we further assess its merits on the sound source
localization problem, demonstrating its practical usefulness and the relevance
of its interpretation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Letzelter_V/0/1/0/all/0/1&quot;&gt;Victor Letzelter&lt;/a&gt; (S2A, IDS), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fontaine_M/0/1/0/all/0/1&quot;&gt;Mathieu Fontaine&lt;/a&gt; (S2A, IDS), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Micka&amp;#xeb;l Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perez_P/0/1/0/all/0/1&quot;&gt;Patrick P&amp;#xe9;rez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Richard_G/0/1/0/all/0/1&quot;&gt;Gael Richard&lt;/a&gt; (S2A, IDS), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Essid_S/0/1/0/all/0/1&quot;&gt;Slim Essid&lt;/a&gt; (IDS, S2A)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01059">
<title>Adapt On-the-Go: Behavior Modulation for Single-Life Robot Deployment. (arXiv:2311.01059v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.01059</link>
<description rdf:parseType="Literal">&lt;p&gt;To succeed in the real world, robots must cope with situations that differ
from those seen during training. We study the problem of adapting on-the-fly to
such novel scenarios during deployment, by drawing upon a diverse repertoire of
previously learned behaviors. Our approach, RObust Autonomous Modulation
(ROAM), introduces a mechanism based on the perceived value of pre-trained
behaviors to select and adapt pre-trained behaviors to the situation at hand.
Crucially, this adaptation process all happens within a single episode at test
time, without any human supervision. We provide theoretical analysis of our
selection mechanism and demonstrate that ROAM enables a robot to adapt rapidly
to changes in dynamics both in simulation and on a real Go1 quadruped, even
successfully moving forward with roller skates on its feet. Our approach adapts
over 2x as efficiently compared to existing methods when facing a variety of
out-of-distribution situations during deployment by effectively choosing and
adapting relevant behaviors on-the-fly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1&quot;&gt;Annie S. Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chada_G/0/1/0/all/0/1&quot;&gt;Govind Chada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1&quot;&gt;Laura Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Archit Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1&quot;&gt;Zipeng Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01061">
<title>Deep Learning for real-time neural decoding of grasp. (arXiv:2311.01061v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01061</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural decoding involves correlating signals acquired from the brain to
variables in the physical world like limb movement or robot control in Brain
Machine Interfaces. In this context, this work starts from a specific
pre-existing dataset of neural recordings from monkey motor cortex and presents
a Deep Learning-based approach to the decoding of neural signals for grasp type
classification. Specifically, we propose here an approach that exploits LSTM
networks to classify time series containing neural data (i.e., spike trains)
into classes representing the object being grasped. The main goal of the
presented approach is to improve over state-of-the-art decoding accuracy
without relying on any prior neuroscience knowledge, and leveraging only the
capability of deep learning models to extract correlations from data. The paper
presents the results achieved for the considered dataset and compares them with
previous works on the same dataset, showing a significant improvement in
classification accuracy, even if considering simulated real-time decoding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viviani_P/0/1/0/all/0/1&quot;&gt;Paolo Viviani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gesmundo_I/0/1/0/all/0/1&quot;&gt;Ilaria Gesmundo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghinato_E/0/1/0/all/0/1&quot;&gt;Elios Ghinato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agudelo_Toro_A/0/1/0/all/0/1&quot;&gt;Andres Agudelo-Toro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vercellino_C/0/1/0/all/0/1&quot;&gt;Chiara Vercellino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vitali_G/0/1/0/all/0/1&quot;&gt;Giacomo Vitali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergamasco_L/0/1/0/all/0/1&quot;&gt;Letizia Bergamasco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scionti_A/0/1/0/all/0/1&quot;&gt;Alberto Scionti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghislieri_M/0/1/0/all/0/1&quot;&gt;Marco Ghislieri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agostini_V/0/1/0/all/0/1&quot;&gt;Valentina Agostini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Terzo_O/0/1/0/all/0/1&quot;&gt;Olivier Terzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scherberger_H/0/1/0/all/0/1&quot;&gt;Hansj&amp;#xf6;rg Scherberger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01064">
<title>Multimodal Foundation Models for Zero-shot Animal Species Recognition in Camera Trap Images. (arXiv:2311.01064v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01064</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to deteriorating environmental conditions and increasing human activity,
conservation efforts directed towards wildlife is crucial. Motion-activated
camera traps constitute an efficient tool for tracking and monitoring wildlife
populations across the globe. Supervised learning techniques have been
successfully deployed to analyze such imagery, however training such techniques
requires annotations from experts. Reducing the reliance on costly labelled
data therefore has immense potential in developing large-scale wildlife
tracking solutions with markedly less human labor. In this work we propose
WildMatch, a novel zero-shot species classification framework that leverages
multimodal foundation models. In particular, we instruction tune
vision-language models to generate detailed visual descriptions of camera trap
images using similar terminology to experts. Then, we match the generated
caption to an external knowledge base of descriptions in order to determine the
species in a zero-shot manner. We investigate techniques to build instruction
tuning datasets for detailed animal description generation and propose a novel
knowledge augmentation technique to enhance caption quality. We demonstrate the
performance of WildMatch on a new camera trap dataset collected in the
Magdalena Medio region of Colombia.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fabian_Z/0/1/0/all/0/1&quot;&gt;Zalan Fabian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miao_Z/0/1/0/all/0/1&quot;&gt;Zhongqi Miao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chunyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuanhan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Ziwei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Hern&amp;#xe1;ndez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montes_Rojas_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Montes-Rojas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escucha_R/0/1/0/all/0/1&quot;&gt;Rafael Escucha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siabatto_L/0/1/0/all/0/1&quot;&gt;Laura Siabatto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Link_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Link&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1&quot;&gt;Pablo Arbel&amp;#xe1;ez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1&quot;&gt;Rahul Dodhia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1&quot;&gt;Juan Lavista Ferres&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01075">
<title>Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning. (arXiv:2311.01075v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01075</link>
<description rdf:parseType="Literal">&lt;p&gt;In the field of multi-task reinforcement learning, the modular principle,
which involves specializing functionalities into different modules and
combining them appropriately, has been widely adopted as a promising approach
to prevent the negative transfer problem that performance degradation due to
conflicts between tasks. However, most of the existing multi-task RL methods
only combine shared modules at the task level, ignoring that there may be
conflicts within the task. In addition, these methods do not take into account
that without constraints, some modules may learn similar functions, resulting
in restricting the model&apos;s expressiveness and generalization capability of
modular methods. In this paper, we propose the Contrastive Modules with
Temporal Attention(CMTA) method to address these limitations. CMTA constrains
the modules to be different from each other by contrastive learning and
combining shared modules at a finer granularity than the task level with
temporal attention, alleviating the negative transfer within the task and
improving the generalization ability and the performance for multi-task RL. We
conducted the experiment on Meta-World, a multi-task RL benchmark containing
various robotics manipulation tasks. Experimental results show that CMTA
outperforms learning each task individually for the first time and achieves
substantial performance improvements over the baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1&quot;&gt;Siming Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Rui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1&quot;&gt;Qi Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jiaming Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1&quot;&gt;Shaohui Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yunkai Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Ruizhi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1&quot;&gt;Zidong Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xing Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xishan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Ling Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yunji Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01106">
<title>In Defense of Softmax Parametrization for Calibrated and Consistent Learning to Defer. (arXiv:2311.01106v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01106</link>
<description rdf:parseType="Literal">&lt;p&gt;Enabling machine learning classifiers to defer their decision to a downstream
expert when the expert is more accurate will ensure improved safety and
performance. This objective can be achieved with the learning-to-defer
framework which aims to jointly learn how to classify and how to defer to the
expert. In recent studies, it has been theoretically shown that popular
estimators for learning to defer parameterized with softmax provide unbounded
estimates for the likelihood of deferring which makes them uncalibrated.
However, it remains unknown whether this is due to the widely used softmax
parameterization and if we can find a softmax-based estimator that is both
statistically consistent and possesses a valid probability estimator. In this
work, we first show that the cause of the miscalibrated and unbounded estimator
in prior literature is due to the symmetric nature of the surrogate losses used
and not due to softmax. We then propose a novel statistically consistent
asymmetric softmax-based surrogate loss that can produce valid estimates
without the issue of unboundedness. We further analyze the non-asymptotic
properties of our method and empirically validate its performance and
calibration on benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yuzhou Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozannar_H/0/1/0/all/0/1&quot;&gt;Hussein Mozannar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1&quot;&gt;Lei Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1&quot;&gt;Hongxin Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1&quot;&gt;Bo An&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01111">
<title>H-NeXt: The next step towards roto-translation invariant networks. (arXiv:2311.01111v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01111</link>
<description rdf:parseType="Literal">&lt;p&gt;The widespread popularity of equivariant networks underscores the
significance of parameter efficient models and effective use of training data.
At a time when robustness to unseen deformations is becoming increasingly
important, we present H-NeXt, which bridges the gap between equivariance and
invariance. H-NeXt is a parameter-efficient roto-translation invariant network
that is trained without a single augmented image in the training set. Our
network comprises three components: an equivariant backbone for learning
roto-translation independent features, an invariant pooling layer for
discarding roto-translation information, and a classification layer. H-NeXt
outperforms the state of the art in classification on unaugmented training sets
and augmented test sets of MNIST and CIFAR-10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karella_T/0/1/0/all/0/1&quot;&gt;Tomas Karella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sroubek_F/0/1/0/all/0/1&quot;&gt;Filip Sroubek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flusser_J/0/1/0/all/0/1&quot;&gt;Jan Flusser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blazek_J/0/1/0/all/0/1&quot;&gt;Jan Blazek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kosik_V/0/1/0/all/0/1&quot;&gt;Vasek Kosik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01118">
<title>AI for Interpretable Chemistry: Predicting Radical Mechanistic Pathways via Contrastive Learning. (arXiv:2311.01118v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01118</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning-based reaction predictors have undergone significant
architectural evolution. However, their reliance on reactions from the US
Patent Office results in a lack of interpretable predictions and limited
generalization capability to other chemistry domains, such as radical and
atmospheric chemistry. To address these challenges, we introduce a new reaction
predictor system, RMechRP, that leverages contrastive learning in conjunction
with mechanistic pathways, the most interpretable representation of chemical
reactions. Specifically designed for radical reactions, RMechRP provides
different levels of interpretation of chemical reactions. We develop and train
multiple deep-learning models using RMechDB, a public database of radical
reactions, to establish the first benchmark for predicting radical reactions.
Our results demonstrate the effectiveness of RMechRP in providing accurate and
interpretable predictions of radical reactions, and its potential for various
applications in atmospheric chemistry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tavakoli_M/0/1/0/all/0/1&quot;&gt;Mohammadamin Tavakoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiu_Y/0/1/0/all/0/1&quot;&gt;Yin Ting T.Chiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shmakov_A/0/1/0/all/0/1&quot;&gt;Alexander Shmakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlton_A/0/1/0/all/0/1&quot;&gt;Ann Marie Carlton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vranken_D/0/1/0/all/0/1&quot;&gt;David Van Vranken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baldi_P/0/1/0/all/0/1&quot;&gt;Pierre Baldi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01130">
<title>A deep learning experiment for semantic segmentation of overlapping characters in palimpsests. (arXiv:2311.01130v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01130</link>
<description rdf:parseType="Literal">&lt;p&gt;Palimpsests refer to historical manuscripts where erased writings have been
partially covered by the superimposition of a second writing. By employing
imaging techniques, e.g., multispectral imaging, it becomes possible to
identify features that are imperceptible to the naked eye, including faded and
erased inks. When dealing with overlapping inks, Artificial Intelligence
techniques can be utilized to disentangle complex nodes of overlapping letters.
In this work, we propose deep learning-based semantic segmentation as a method
for identifying and segmenting individual letters in overlapping characters.
The experiment was conceived as a proof of concept, focusing on the palimpsests
of the Ars Grammatica by Prisciano as a case study. Furthermore, caveats and
prospects of our approach combined with multispectral imaging are also
discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perino_M/0/1/0/all/0/1&quot;&gt;Michela Perino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ginolfi_M/0/1/0/all/0/1&quot;&gt;Michele Ginolfi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Felici_A/0/1/0/all/0/1&quot;&gt;Anna Candida Felici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosellini_M/0/1/0/all/0/1&quot;&gt;Michela Rosellini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01135">
<title>Generating QM1B with PySCF$_{\text{IPU}}$. (arXiv:2311.01135v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01135</link>
<description rdf:parseType="Literal">&lt;p&gt;The emergence of foundation models in Computer Vision and Natural Language
Processing have resulted in immense progress on downstream tasks. This progress
was enabled by datasets with billions of training examples. Similar benefits
are yet to be unlocked for quantum chemistry, where the potential of deep
learning is constrained by comparatively small datasets with 100k to 20M
training examples. These datasets are limited in size because the labels are
computed using the accurate (but computationally demanding) predictions of
Density Functional Theory (DFT). Notably, prior DFT datasets were created using
CPU supercomputers without leveraging hardware acceleration. In this paper, we
take a first step towards utilising hardware accelerators by introducing the
data generator PySCF$_{\text{IPU}}$ using Intelligence Processing Units (IPUs).
This allowed us to create the dataset QM1B with one billion training examples
containing 9-11 heavy atoms. We demonstrate that a simple baseline neural
network (SchNet 9M) improves its performance by simply increasing the amount of
training data without additional inductive biases. To encourage future
researchers to use QM1B responsibly, we highlight several limitations of QM1B
and emphasise the low-resolution of our DFT options, which also serves as
motivation for even larger, more accurate datasets. Code and dataset are
available on Github: &lt;a href=&quot;http://github.com/graphcore-research/pyscf-ipu&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathiasen_A/0/1/0/all/0/1&quot;&gt;Alexander Mathiasen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helal_H/0/1/0/all/0/1&quot;&gt;Hatem Helal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klaser_K/0/1/0/all/0/1&quot;&gt;Kerstin Klaser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balanca_P/0/1/0/all/0/1&quot;&gt;Paul Balanca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dean_J/0/1/0/all/0/1&quot;&gt;Josef Dean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1&quot;&gt;Carlo Luschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beaini_D/0/1/0/all/0/1&quot;&gt;Dominique Beaini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fitzgibbon_A/0/1/0/all/0/1&quot;&gt;Andrew Fitzgibbon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1&quot;&gt;Dominic Masters&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01138">
<title>AeroPath: An airway segmentation benchmark dataset with challenging pathology. (arXiv:2311.01138v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01138</link>
<description rdf:parseType="Literal">&lt;p&gt;To improve the prognosis of patients suffering from pulmonary diseases, such
as lung cancer, early diagnosis and treatment are crucial. The analysis of CT
images is invaluable for diagnosis, whereas high quality segmentation of the
airway tree are required for intervention planning and live guidance during
bronchoscopy. Recently, the Multi-domain Airway Tree Modeling (ATM&apos;22)
challenge released a large dataset, both enabling training of deep-learning
based models and bringing substantial improvement of the state-of-the-art for
the airway segmentation task. However, the ATM&apos;22 dataset includes few patients
with severe pathologies affecting the airway tree anatomy. In this study, we
introduce a new public benchmark dataset (AeroPath), consisting of 27 CT images
from patients with pathologies ranging from emphysema to large tumors, with
corresponding trachea and bronchi annotations. Second, we present a multiscale
fusion design for automatic airway segmentation. Models were trained on the
ATM&apos;22 dataset, tested on the AeroPath dataset, and further evaluated against
competitive open-source methods. The same performance metrics as used in the
ATM&apos;22 challenge were used to benchmark the different considered approaches.
Lastly, an open web application is developed, to easily test the proposed model
on new data. The results demonstrated that our proposed architecture predicted
topologically correct segmentations for all the patients included in the
AeroPath dataset. The proposed method is robust and able to handle various
anomalies, down to at least the fifth airway generation. In addition, the
AeroPath dataset, featuring patients with challenging pathologies, will
contribute to development of new state-of-the-art methods. The AeroPath dataset
and the web application are made openly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoverud_K/0/1/0/all/0/1&quot;&gt;Karen-Helene St&amp;#xf8;verud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouget_D/0/1/0/all/0/1&quot;&gt;David Bouget&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedersen_A/0/1/0/all/0/1&quot;&gt;Andre Pedersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leira_H/0/1/0/all/0/1&quot;&gt;H&amp;#xe5;kon Olav Leira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lango_T/0/1/0/all/0/1&quot;&gt;Thomas Lang&amp;#xf8;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofstad_E/0/1/0/all/0/1&quot;&gt;Erlend Fagertun Hofstad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01139">
<title>Add and Thin: Diffusion for Temporal Point Processes. (arXiv:2311.01139v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01139</link>
<description rdf:parseType="Literal">&lt;p&gt;Autoregressive neural networks within the temporal point process (TPP)
framework have become the standard for modeling continuous-time event data.
Even though these models can expressively capture event sequences in a
one-step-ahead fashion, they are inherently limited for long-term forecasting
applications due to the accumulation of errors caused by their sequential
nature. To overcome these limitations, we derive ADD-THIN, a principled
probabilistic denoising diffusion model for TPPs that operates on entire event
sequences. Unlike existing diffusion approaches, ADD-THIN naturally handles
data with discrete and continuous components. In experiments on synthetic and
real-world datasets, our model matches the state-of-the-art TPP models in
density estimation and strongly outperforms them in forecasting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ludke_D/0/1/0/all/0/1&quot;&gt;David L&amp;#xfc;dke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilos_M/0/1/0/all/0/1&quot;&gt;Marin Bilo&amp;#x161;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shchur_O/0/1/0/all/0/1&quot;&gt;Oleksandr Shchur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lienen_M/0/1/0/all/0/1&quot;&gt;Marten Lienen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01154">
<title>A Review of Digital Twins and their Application in Cybersecurity based on Artificial Intelligence. (arXiv:2311.01154v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2311.01154</link>
<description rdf:parseType="Literal">&lt;p&gt;The potential of digital twin technology is yet to be fully realized due to
its diversity and untapped potential. Digital twins enable systems&apos; analysis,
design, optimization, and evolution to be performed digitally or in conjunction
with a cyber-physical approach to improve speed, accuracy, and efficiency over
traditional engineering methods. Industry 4.0, factories of the future, and
digital twins continue to benefit from the technology and provide enhanced
efficiency within existing systems. Due to the lack of information and security
standards associated with the transition to cyber digitization, cybercriminals
have been able to take advantage of the situation. Access to a digital twin of
a product or service is equivalent to threatening the entire collection. There
is a robust interaction between digital twins and artificial intelligence
tools, which leads to strong interaction between these technologies, so it can
be used to improve the cybersecurity of these digital platforms based on their
integration with these technologies. This study aims to investigate the role of
artificial intelligence in providing cybersecurity for digital twin versions of
various industries, as well as the risks associated with these versions. In
addition, this research serves as a road map for researchers and others
interested in cybersecurity and digital security.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Homaei_M/0/1/0/all/0/1&quot;&gt;MohammadHossein Homaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutierrez_O/0/1/0/all/0/1&quot;&gt;Oscar Mogollon Gutierrez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nunez_J/0/1/0/all/0/1&quot;&gt;Jose Carlos Sancho Nunez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vegas_M/0/1/0/all/0/1&quot;&gt;Mar Avila Vegas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindo_A/0/1/0/all/0/1&quot;&gt;Andres Caro Lindo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01191">
<title>VIGraph: Self-supervised Learning for Class-Imbalanced Node Classification. (arXiv:2311.01191v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01191</link>
<description rdf:parseType="Literal">&lt;p&gt;Class imbalance in graph data poses significant challenges for node
classification. Existing methods, represented by SMOTE-based approaches,
partially alleviate this issue but still exhibit limitations during imbalanced
scenario construction. Self-supervised learning (SSL) offers a promising
solution by synthesizing minority nodes from the data itself, yet its potential
remains unexplored. In this paper, we analyze the limitations of SMOTE-based
approaches and introduce VIGraph, a novel SSL model based on the
self-supervised Variational Graph Auto-Encoder (VGAE) that leverages
Variational Inference (VI) to generate minority nodes. Specifically, VIGraph
strictly adheres to the concept of imbalance when constructing imbalanced
graphs and utilizes the generative VGAE to generate minority nodes. Moreover,
VIGraph introduces a novel Siamese contrastive strategy at the decoding phase
to improve the overall quality of generated nodes. VIGraph can generate
high-quality nodes without reintegrating them into the original graph,
eliminating the &quot;Generating, Reintegrating, and Retraining&quot; process found in
SMOTE-based methods. Experiments on multiple real-world datasets demonstrate
that VIGraph achieves promising results for class-imbalanced node
classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yulan Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1&quot;&gt;Sheng Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhirui Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yong Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01195">
<title>Batch Bayesian Optimization for Replicable Experimental Design. (arXiv:2311.01195v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01195</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world experimental design problems (a) evaluate multiple
experimental conditions in parallel and (b) replicate each condition multiple
times due to large and heteroscedastic observation noise. Given a fixed total
budget, this naturally induces a trade-off between evaluating more unique
conditions while replicating each of them fewer times vs. evaluating fewer
unique conditions and replicating each more times. Moreover, in these problems,
practitioners may be risk-averse and hence prefer an input with both good
average performance and small variability. To tackle both challenges, we
propose the Batch Thompson Sampling for Replicable Experimental Design
(BTS-RED) framework, which encompasses three algorithms. Our BTS-RED-Known and
BTS-RED-Unknown algorithms, for, respectively, known and unknown noise
variance, choose the number of replications adaptively rather than
deterministically such that an input with a larger noise variance is replicated
more times. As a result, despite the noise heteroscedasticity, both algorithms
enjoy a theoretical guarantee and are asymptotically no-regret. Our
Mean-Var-BTS-RED algorithm aims at risk-averse optimization and is also
asymptotically no-regret. We also show the effectiveness of our algorithms in
two practical real-world applications: precision agriculture and AutoML.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1&quot;&gt;Zhongxiang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1&quot;&gt;Quoc Phong Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_S/0/1/0/all/0/1&quot;&gt;Sebastian Shenghong Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urano_D/0/1/0/all/0/1&quot;&gt;Daisuke Urano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leong_R/0/1/0/all/0/1&quot;&gt;Richalynn Leong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Low_B/0/1/0/all/0/1&quot;&gt;Bryan Kian Hsiang Low&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1&quot;&gt;Patrick Jaillet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01196">
<title>Combating Bilateral Edge Noise for Robust Link Prediction. (arXiv:2311.01196v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01196</link>
<description rdf:parseType="Literal">&lt;p&gt;Although link prediction on graphs has achieved great success with the
development of graph neural networks (GNNs), the potential robustness under the
edge noise is still less investigated. To close this gap, we first conduct an
empirical study to disclose that the edge noise bilaterally perturbs both input
topology and target label, yielding severe performance degradation and
representation collapse. To address this dilemma, we propose an
information-theory-guided principle, Robust Graph Information Bottleneck
(RGIB), to extract reliable supervision signals and avoid representation
collapse. Different from the basic information bottleneck, RGIB further
decouples and balances the mutual dependence among graph topology, target
labels, and representation, building new learning objectives for robust
representation against the bilateral noise. Two instantiations, RGIB-SSL and
RGIB-REP, are explored to leverage the merits of different methodologies, i.e.,
self-supervised learning and data reparameterization, for implicit and explicit
data denoising, respectively. Extensive experiments on six datasets and three
GNNs with diverse noisy scenarios verify the effectiveness of our RGIB
instantiations. The code is publicly available at:
https://github.com/tmlr-group/RGIB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhanke Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jiangchao Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiaxu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xiawei Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1&quot;&gt;Quanming Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Li He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1&quot;&gt;Bo Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bo Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01198">
<title>Gaussian Processes on Cellular Complexes. (arXiv:2311.01198v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01198</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, there has been considerable interest in developing machine
learning models on graphs in order to account for topological inductive biases.
In particular, recent attention was given to Gaussian processes on such
structures since they can additionally account for uncertainty. However, graphs
are limited to modelling relations between two vertices. In this paper, we go
beyond this dyadic setting and consider polyadic relations that include
interactions between vertices, edges and one of their generalisations, known as
cells. Specifically, we propose Gaussian processes on cellular complexes, a
generalisation of graphs that captures interactions between these higher-order
cells. One of our key contributions is the derivation of two novel kernels, one
that generalises the graph Mat\&apos;ern kernel and one that additionally mixes
information of different cell types.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alain_M/0/1/0/all/0/1&quot;&gt;Mathieu Alain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takao_S/0/1/0/all/0/1&quot;&gt;So Takao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paige_B/0/1/0/all/0/1&quot;&gt;Brooks Paige&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deisenroth_M/0/1/0/all/0/1&quot;&gt;Marc Peter Deisenroth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01200">
<title>A Study of Continual Learning Under Language Shift. (arXiv:2311.01200v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01200</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent increase in data and model scale for language model pre-training
has led to huge training costs. In scenarios where new data become available
over time, updating a model instead of fully retraining it would therefore
provide significant gains. In this paper, we study the benefits and downsides
of updating a language model when new data comes from new languages - the case
of continual learning under language shift. Starting from a monolingual English
language model, we incrementally add data from Norwegian and Icelandic to
investigate how forward and backward transfer effects depend on the
pre-training order and characteristics of languages, for different model sizes
and learning rate schedulers. Our results show that, while forward transfer is
largely positive and independent of language order, backward transfer can be
either positive or negative depending on the order and characteristics of new
languages. To explain these patterns we explore several language similarity
metrics and find that syntactic similarity appears to have the best correlation
with our results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gogoulou_E/0/1/0/all/0/1&quot;&gt;Evangelia Gogoulou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1&quot;&gt;Timoth&amp;#xe9;e Lesort&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boman_M/0/1/0/all/0/1&quot;&gt;Magnus Boman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nivre_J/0/1/0/all/0/1&quot;&gt;Joakim Nivre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01201">
<title>Federated Learning on Edge Sensing Devices: A Review. (arXiv:2311.01201v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01201</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to monitor ambient characteristics, interact with them, and
derive information about the surroundings has been made possible by the rapid
proliferation of edge sensing devices like IoT, mobile, and wearable devices
and their measuring capabilities with integrated sensors. Even though these
devices are small and have less capacity for data storage and processing, they
produce vast amounts of data. Some example application areas where sensor data
is collected and processed include healthcare, environmental (including air
quality and pollution levels), automotive, industrial, aerospace, and
agricultural applications. These enormous volumes of sensing data collected
from the edge devices are analyzed using a variety of Machine Learning (ML) and
Deep Learning (DL) approaches. However, analyzing them on the cloud or a server
presents challenges related to privacy, hardware, and connectivity limitations.
Federated Learning (FL) is emerging as a solution to these problems while
preserving privacy by jointly training a model without sharing raw data. In
this paper, we review the FL strategies from the perspective of edge sensing
devices to get over the limitations of conventional machine learning
techniques. We focus on the key FL principles, software frameworks, and
testbeds. We also explore the current sensor technologies, properties of the
sensing devices and sensing applications where FL is utilized. We conclude with
a discussion on open issues and future research directions on FL for further
studies
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saylam_B/0/1/0/all/0/1&quot;&gt;Berrenur Saylam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Incel_O/0/1/0/all/0/1&quot;&gt;&amp;#xd6;zlem Durmaz &amp;#x130;ncel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01205">
<title>Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent. (arXiv:2311.01205v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01205</link>
<description rdf:parseType="Literal">&lt;p&gt;Prior attacks on graph neural networks have mostly focused on graph poisoning
and evasion, neglecting the network&apos;s weights and biases. Traditional
weight-based fault injection attacks, such as bit flip attacks used for
convolutional neural networks, do not consider the unique properties of graph
neural networks. We propose the Injectivity Bit Flip Attack, the first bit flip
attack designed specifically for graph neural networks. Our attack targets the
learnable neighborhood aggregation functions in quantized message passing
neural networks, degrading their ability to distinguish graph structures and
losing the expressivity of the Weisfeiler-Lehman test. Our findings suggest
that exploiting mathematical properties specific to certain graph neural
network architectures can significantly increase their vulnerability to bit
flip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive
Graph Isomorphism Networks trained on various graph property prediction
datasets to random output by flipping only a small fraction of the network&apos;s
bits, demonstrating its higher destructive power compared to a bit flip attack
transferred from convolutional neural networks. Our attack is transparent and
motivated by theoretical insights which are confirmed by extensive empirical
results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kummer_L/0/1/0/all/0/1&quot;&gt;Lorenz Kummer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moustafa_S/0/1/0/all/0/1&quot;&gt;Samir Moustafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kriege_N/0/1/0/all/0/1&quot;&gt;Nils N. Kriege&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gansterer_W/0/1/0/all/0/1&quot;&gt;Wilfried N. Gansterer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01223">
<title>Diffusion Models for Reinforcement Learning: A Survey. (arXiv:2311.01223v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01223</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models have emerged as a prominent class of generative models,
surpassing previous methods regarding sample quality and training stability.
Recent works have shown the advantages of diffusion models in improving
reinforcement learning (RL) solutions, including as trajectory planners,
expressive policy classes, data synthesizers, etc. This survey aims to provide
an overview of the advancements in this emerging field and hopes to inspire new
avenues of research. First, we examine several challenges encountered by
current RL algorithms. Then, we present a taxonomy of existing methods based on
the roles played by diffusion models in RL and explore how the existing
challenges are addressed. We further outline successful applications of
diffusion models in various RL-related tasks while discussing the limitations
of current approaches. Finally, we conclude the survey and offer insights into
future research directions, focusing on enhancing model performance and
applying diffusion models to broader tasks. We are actively maintaining a
GitHub repository for papers and other related resources in applying diffusion
models in RL: https://github.com/apexrl/Diff4RLSurvey .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhengbang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Hanye Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1&quot;&gt;Haoran He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1&quot;&gt;Yichao Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shenyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01230">
<title>Multi-Operational Mathematical Derivations in Latent Space. (arXiv:2311.01230v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01230</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates the possibility of approximating multiple
mathematical operations in latent space for expression derivation. To this end,
we introduce different multi-operational representation paradigms, modelling
mathematical operations as explicit geometric transformations. By leveraging a
symbolic engine, we construct a large-scale dataset comprising 1.7M derivation
steps stemming from 61K premises and 6 operators, analysing the properties of
each paradigm when instantiated with state-of-the-art neural encoders.
Specifically, we investigate how different encoding mechanisms can approximate
equational reasoning in latent space, exploring the trade-off between learning
different operators and specialising within single operations, as well as the
ability to support multi-step derivations and out-of-distribution
generalisation. Our empirical analysis reveals that the multi-operational
paradigm is crucial for disentangling different operators, while discriminating
the conclusions for a single operation is achievable in the original expression
encoder. Moreover, we show that architectural choices can heavily affect the
training dynamics, structural organisation, and generalisation of the latent
space, resulting in significant variations across paradigms and classes of
encoders.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1&quot;&gt;Marco Valentino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meadows_J/0/1/0/all/0/1&quot;&gt;Jordan Meadows&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Freitas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01248">
<title>Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching. (arXiv:2311.01248v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.01248</link>
<description rdf:parseType="Literal">&lt;p&gt;Optical tactile sensors have emerged as an effective means to acquire dense
contact information during robotic manipulation. A recently-introduced
`see-through-your-skin&apos; (STS) variant of this type of sensor has both visual
and tactile modes, enabled by leveraging a semi-transparent surface and
controllable lighting. In this work, we investigate the benefits of pairing
visuotactile sensing with imitation learning for contact-rich manipulation
tasks. First, we use tactile force measurements and a novel algorithm during
kinesthetic teaching to yield a force profile that better matches that of the
human demonstrator. Second, we add visual/tactile STS mode switching as a
control policy output, simplifying the application of the sensor. Finally, we
study multiple observation configurations to compare and contrast the value of
visual/tactile data (both with and without mode switching) with visual data
from a wrist-mounted eye-in-hand camera. We perform an extensive series of
experiments on a real robotic manipulator with door-opening and closing tasks,
including over 3,000 real test episodes. Our results highlight the importance
of tactile sensing for imitation learning, both for data collection to allow
force matching, and for policy execution to allow accurate task feedback.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ablett_T/0/1/0/all/0/1&quot;&gt;Trevor Ablett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Limoyo_O/0/1/0/all/0/1&quot;&gt;Oliver Limoyo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sigal_A/0/1/0/all/0/1&quot;&gt;Adam Sigal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jilani_A/0/1/0/all/0/1&quot;&gt;Affan Jilani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1&quot;&gt;Jonathan Kelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siddiqi_K/0/1/0/all/0/1&quot;&gt;Kaleem Siddiqi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hogan_F/0/1/0/all/0/1&quot;&gt;Francois Hogan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1&quot;&gt;Gregory Dudek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01252">
<title>Sanitized Clustering against Confounding Bias. (arXiv:2311.01252v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01252</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-world datasets inevitably contain biases that arise from different
sources or conditions during data collection. Consequently, such inconsistency
itself acts as a confounding factor that disturbs the cluster analysis.
Existing methods eliminate the biases by projecting data onto the orthogonal
complement of the subspace expanded by the confounding factor before
clustering. Therein, the interested clustering factor and the confounding
factor are coarsely considered in the raw feature space, where the correlation
between the data and the confounding factor is ideally assumed to be linear for
convenient solutions. These approaches are thus limited in scope as the data in
real applications is usually complex and non-linearly correlated with the
confounding factor. This paper presents a new clustering framework named
Sanitized Clustering Against confounding Bias (SCAB), which removes the
confounding factor in the semantic latent space of complex data through a
non-linear dependence measure. To be specific, we eliminate the bias
information in the latent space by minimizing the mutual information between
the confounding factor and the latent representation delivered by Variational
Auto-Encoder (VAE). Meanwhile, a clustering module is introduced to cluster
over the purified latent representations. Extensive experiments on complex
datasets demonstrate that our SCAB achieves a significant gain in clustering
performance by removing the confounding bias. The code is available at
\url{https://github.com/EvaFlower/SCAB}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yinghua Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yuangang Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1&quot;&gt;Ivor W. Tsang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1&quot;&gt;Xin Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01256">
<title>An energy-based comparative analysis of common approaches to text classification in the Legal domain. (arXiv:2311.01256v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.01256</link>
<description rdf:parseType="Literal">&lt;p&gt;Most Machine Learning research evaluates the best solutions in terms of
performance. However, in the race for the best performing model, many important
aspects are often overlooked when, on the contrary, they should be carefully
considered. In fact, sometimes the gaps in performance between different
approaches are neglectable, whereas factors such as production costs, energy
consumption, and carbon footprint must take into consideration. Large Language
Models (LLMs) are extensively adopted to address NLP problems in academia and
industry. In this work, we present a detailed quantitative comparison of LLM
and traditional approaches (e.g. SVM) on the LexGLUE benchmark, which takes
into account both performance (standard indices) and alternative metrics such
as timing, power consumption and cost, in a word: the carbon-footprint. In our
analysis, we considered the prototyping phase (model selection by
training-validation-test iterations) and in-production phases separately, since
they follow different implementation procedures and also require different
resources. The results indicate that very often, the simplest algorithms
achieve performance very close to that of large LLMs but with very low power
consumption and lower resource demands. The results obtained could suggest
companies to include additional evaluations in the choice of Machine Learning
(ML) solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gultekin_S/0/1/0/all/0/1&quot;&gt;Sinan Gultekin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Globo_A/0/1/0/all/0/1&quot;&gt;Achille Globo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zugarini_A/0/1/0/all/0/1&quot;&gt;Andrea Zugarini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ernandes_M/0/1/0/all/0/1&quot;&gt;Marco Ernandes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigutini_L/0/1/0/all/0/1&quot;&gt;Leonardo Rigutini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01276">
<title>Long-Range Neural Atom Learning for Molecular Graphs. (arXiv:2311.01276v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01276</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) have been widely adopted for drug discovery with
molecular graphs. Nevertheless, current GNNs are mainly good at leveraging
short-range interactions (SRI) but struggle to capture long-range interactions
(LRI), both of which are crucial for determining molecular properties. To
tackle this issue, we propose a method that implicitly projects all original
atoms into a few Neural Atoms, which abstracts the collective information of
atomic groups within a molecule. Specifically, we explicitly exchange the
information among neural atoms and project them back to the atoms&apos;
representations as an enhancement. With this mechanism, neural atoms establish
the communication channels among distant nodes, effectively reducing the
interaction scope of arbitrary node pairs into a single hop. To provide an
inspection of our method from a physical perspective, we reveal its connection
with the traditional LRI calculation method, Ewald Summation. We conduct
extensive experiments on three long-range graph benchmarks, covering both
graph-level and link-level tasks on molecular graphs. We empirically justify
that our method can be equipped with an arbitrary GNN and help to capture LRI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhanke Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jiangchao Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1&quot;&gt;Yu Rong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bo Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01282">
<title>FlashDecoding++: Faster Large Language Model Inference on GPUs. (arXiv:2311.01282v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01282</link>
<description rdf:parseType="Literal">&lt;p&gt;As the Large Language Model (LLM) becomes increasingly important in various
domains. However, the following challenges still remain unsolved in
accelerating LLM inference: (1) Synchronized partial softmax update. The
softmax operation requires a synchronized update operation among each partial
softmax result, leading to ~20% overheads for the attention computation in
LLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices
performing GEMM in LLM inference is flat, leading to under-utilized computation
and &amp;gt;50% performance loss after padding zeros in previous designs. (3)
Performance loss due to static dataflow. Kernel performance in LLM depends on
varied input data features, hardware configurations, etc. A single and static
dataflow may lead to a 50.25% performance loss for GEMMs of different shapes in
LLM inference.
&lt;/p&gt;
&lt;p&gt;We present FlashDecoding++, a fast LLM inference engine supporting mainstream
LLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++
creatively proposes: (1) Asynchronized softmax with unified max value.
FlashDecoding++ introduces a unified max value technique for different partial
softmax computations to avoid synchronization. (2) Flat GEMM optimization with
double buffering. FlashDecoding++ points out that flat GEMMs with different
shapes face varied bottlenecks. Then, techniques like double buffering are
introduced. (3) Heuristic dataflow with hardware resource adaptation.
FlashDecoding++ heuristically optimizes dataflow using different hardware
resource considering input dynamics. Due to the versatility of optimizations in
FlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on
both NVIDIA and AMD GPUs compared to Hugging Face implementations.
FlashDecoding++ also achieves an average speedup of 1.37x compared to
state-of-the-art LLM inference engines on mainstream LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1&quot;&gt;Ke Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_G/0/1/0/all/0/1&quot;&gt;Guohao Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiaming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1&quot;&gt;Qiuli Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiuhong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kangdi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1&quot;&gt;Hanyu Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01295">
<title>DP-Mix: Mixup-based Data Augmentation for Differentially Private Learning. (arXiv:2311.01295v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01295</link>
<description rdf:parseType="Literal">&lt;p&gt;Data augmentation techniques, such as simple image transformations and
combinations, are highly effective at improving the generalization of computer
vision models, especially when training data is limited. However, such
techniques are fundamentally incompatible with differentially private learning
approaches, due to the latter&apos;s built-in assumption that each training image&apos;s
contribution to the learned model is bounded. In this paper, we investigate why
naive applications of multi-sample data augmentation techniques, such as mixup,
fail to achieve good performance and propose two novel data augmentation
techniques specifically designed for the constraints of differentially private
learning. Our first technique, DP-Mix_Self, achieves SoTA classification
performance across a range of datasets and settings by performing mixup on
self-augmented data. Our second technique, DP-Mix_Diff, further improves
performance by incorporating synthetic data from a pre-trained diffusion model
into the mixup process. We open-source the code at
https://github.com/wenxuan-Bao/DP-Mix.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1&quot;&gt;Wenxuan Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pittaluga_F/0/1/0/all/0/1&quot;&gt;Francesco Pittaluga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+G_V/0/1/0/all/0/1&quot;&gt;Vijay Kumar B G&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bindschaedler_V/0/1/0/all/0/1&quot;&gt;Vincent Bindschaedler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01301">
<title>TRIALSCOPE A Unifying Causal Framework for Scaling Real-World Evidence Generation with Biomedical Language Models. (arXiv:2311.01301v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01301</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid digitization of real-world data offers an unprecedented opportunity
for optimizing healthcare delivery and accelerating biomedical discovery. In
practice, however, such data is most abundantly available in unstructured
forms, such as clinical notes in electronic medical records (EMRs), and it is
generally plagued by confounders. In this paper, we present TRIALSCOPE, a
unifying framework for distilling real-world evidence from population-level
observational data. TRIALSCOPE leverages biomedical language models to
structure clinical text at scale, employs advanced probabilistic modeling for
denoising and imputation, and incorporates state-of-the-art causal inference
techniques to combat common confounders. Using clinical trial specification as
generic representation, TRIALSCOPE provides a turn-key solution to generate and
reason with clinical hypotheses using observational data. In extensive
experiments and analyses on a large-scale real-world dataset with over one
million cancer patients from a large US healthcare network, we show that
TRIALSCOPE can produce high-quality structuring of real-world data and
generates comparable results to marquee cancer trials. In addition to
facilitating in-silicon clinical trial design and optimization, TRIALSCOPE may
be used to empower synthetic controls, pragmatic trials, post-market
surveillance, as well as support fine-grained patient-like-me reasoning in
precision diagnosis and treatment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Javier Gonz&amp;#xe1;lez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1&quot;&gt;Cliff Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gero_Z/0/1/0/all/0/1&quot;&gt;Zelalem Gero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagga_J/0/1/0/all/0/1&quot;&gt;Jass Bagga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ueno_R/0/1/0/all/0/1&quot;&gt;Risa Ueno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chien_I/0/1/0/all/0/1&quot;&gt;Isabel Chien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orakvin_E/0/1/0/all/0/1&quot;&gt;Eduard Orakvin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiciman_E/0/1/0/all/0/1&quot;&gt;Emre Kiciman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nori_A/0/1/0/all/0/1&quot;&gt;Aditya Nori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weerasinghe_R/0/1/0/all/0/1&quot;&gt;Roshanthi Weerasinghe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leidner_R/0/1/0/all/0/1&quot;&gt;Rom S. Leidner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piening_B/0/1/0/all/0/1&quot;&gt;Brian Piening&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1&quot;&gt;Tristan Naumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bifulco_C/0/1/0/all/0/1&quot;&gt;Carlo Bifulco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1&quot;&gt;Hoifung Poon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01305">
<title>AWEQ: Post-Training Quantization with Activation-Weight Equalization for Large Language Models. (arXiv:2311.01305v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01305</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models(LLMs) exhibit excellent performance across a variety of
tasks, but they come with significant computational and storage costs.
Quantizing these models is an effective way to alleviate this issue. However,
existing methods struggle to strike a balance between model accuracy and
hardware efficiency. This is where we introduce AWEQ, a post-training method
that requires no additional training overhead. AWEQ excels in both
ultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization.
There is an observation that weight quantization is less challenging than
activation quantization. AWEQ transfers the difficulty of activation
quantization to weights using channel equalization, achieving a balance between
the quantization difficulties of both, and thereby maximizing performance. We
have further refined the equalization method to mitigate quantization bias
error, ensuring the robustness of the model. Extensive experiments on popular
models such as LLaMA and OPT demonstrate that AWEQ outperforms all existing
post-training quantization methods for large models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Baisong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xingwang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Haixiao Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01310">
<title>Scattering Vision Transformer: Spectral Mixing Matters. (arXiv:2311.01310v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01310</link>
<description rdf:parseType="Literal">&lt;p&gt;Vision transformers have gained significant attention and achieved
state-of-the-art performance in various computer vision tasks, including image
classification, instance segmentation, and object detection. However,
challenges remain in addressing attention complexity and effectively capturing
fine-grained information within images. Existing solutions often resort to
down-sampling operations, such as pooling, to reduce computational cost.
Unfortunately, such operations are non-invertible and can result in information
loss. In this paper, we present a novel approach called Scattering Vision
Transformer (SVT) to tackle these challenges. SVT incorporates a spectrally
scattering network that enables the capture of intricate image details. SVT
overcomes the invertibility issue associated with down-sampling operations by
separating low-frequency and high-frequency components. Furthermore, SVT
introduces a unique spectral gating network utilizing Einstein multiplication
for token and channel mixing, effectively reducing complexity. We show that SVT
achieves state-of-the-art performance on the ImageNet dataset with a
significant reduction in a number of parameters and FLOPS. SVT shows 2\%
improvement over LiTv2 and iFormer. SVT-H-S reaches 84.2\% top-1 accuracy,
while SVT-H-B reaches 85.2\% (state-of-art for base versions) and SVT-H-L
reaches 85.7\% (again state-of-art for large versions). SVT also shows
comparable results in other vision tasks such as instance segmentation. SVT
also outperforms other transformers in transfer learning on standard datasets
such as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The
project page is available on this
webpage.\url{https://badripatro.github.io/svt/}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patro_B/0/1/0/all/0/1&quot;&gt;Badri N. Patro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agneeswaran_V/0/1/0/all/0/1&quot;&gt;Vijay Srinivas Agneeswaran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01323">
<title>Towards Evaluating Transfer-based Attacks Systematically, Practically, and Fairly. (arXiv:2311.01323v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01323</link>
<description rdf:parseType="Literal">&lt;p&gt;The adversarial vulnerability of deep neural networks (DNNs) has drawn great
attention due to the security risk of applying these models in real-world
applications. Based on transferability of adversarial examples, an increasing
number of transfer-based methods have been developed to fool black-box DNN
models whose architecture and parameters are inaccessible. Although tremendous
effort has been exerted, there still lacks a standardized benchmark that could
be taken advantage of to compare these methods systematically, fairly, and
practically. Our investigation shows that the evaluation of some methods needs
to be more reasonable and more thorough to verify their effectiveness, to
avoid, for example, unfair comparison and insufficient consideration of
possible substitute/victim models. Therefore, we establish a transfer-based
attack benchmark (TA-Bench) which implements 30+ methods. In this paper, we
evaluate and compare them comprehensively on 25 popular substitute/victim
models on ImageNet. New insights about the effectiveness of these methods are
gained and guidelines for future evaluations are provided. Code at:
https://github.com/qizhangli/TA-Bench.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qizhang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yiwen Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1&quot;&gt;Wangmeng Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01327">
<title>High-dimensional Linear Bandits with Knapsacks. (arXiv:2311.01327v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01327</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the contextual bandits with knapsack (CBwK) problem under the
high-dimensional setting where the dimension of the feature is large. The
reward of pulling each arm equals the multiplication of a sparse
high-dimensional weight vector and the feature of the current arrival, with
additional random noise. In this paper, we investigate how to exploit this
sparsity structure to achieve improved regret for the CBwK problem. To this
end, we first develop an online variant of the hard thresholding algorithm that
performs the sparse estimation in an online manner. We further combine our
online estimator with a primal-dual framework, where we assign a dual variable
to each knapsack constraint and utilize an online learning algorithm to update
the dual variable, thereby controlling the consumption of the knapsack
capacity. We show that this integrated approach allows us to achieve a
sublinear regret that depends logarithmically on the feature dimension, thus
improving the polynomial dependency established in the previous literature. We
also apply our framework to the high-dimension contextual bandit problem
without the knapsack constraint and achieve optimal regret in both the
data-poor regime and the data-rich regime. We finally conduct numerical
experiments to show the efficient empirical performance of our algorithms under
the high dimensional setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1&quot;&gt;Wanteng Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_D/0/1/0/all/0/1&quot;&gt;Dong Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jiashuo Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01329">
<title>A Simple Solution for Offline Imitation from Observations and Examples with Possibly Incomplete Trajectories. (arXiv:2311.01329v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01329</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline imitation from observations aims to solve MDPs where only
task-specific expert states and task-agnostic non-expert state-action pairs are
available. Offline imitation is useful in real-world scenarios where arbitrary
interactions are costly and expert actions are unavailable. The
state-of-the-art &quot;DIstribution Correction Estimation&quot; (DICE) methods minimize
divergence of state occupancy between expert and learner policies and retrieve
a policy with weighted behavior cloning; however, their results are unstable
when learning from incomplete trajectories, due to a non-robust optimization in
the dual domain. To address the issue, in this paper, we propose
Trajectory-Aware Imitation Learning from Observations (TAILO). TAILO uses a
discounted sum along the future trajectory as the weight for weighted behavior
cloning. The terms for the sum are scaled by the output of a discriminator,
which aims to identify expert states. Despite simplicity, TAILO works well if
there exist trajectories or segments of expert behavior in the task-agnostic
data, a common assumption in prior work. In experiments across multiple
testbeds, we find TAILO to be more robust and effective, particularly with
incomplete trajectories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1&quot;&gt;Kai Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1&quot;&gt;Alexander G. Schwing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01331">
<title>Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching. (arXiv:2311.01331v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01331</link>
<description rdf:parseType="Literal">&lt;p&gt;In real-world scenarios, arbitrary interactions with the environment can
often be costly, and actions of expert demonstrations are not always available.
To reduce the need for both, Offline Learning from Observations (LfO) is
extensively studied, where the agent learns to solve a task with only expert
states and \textit{task-agnostic} non-expert state-action pairs. The
state-of-the-art DIstribution Correction Estimation (DICE) methods minimize the
state occupancy divergence between the learner and expert policies. However,
they are limited to either $f$-divergences (KL and $\chi^2$) or Wasserstein
distance with Rubinstein duality, the latter of which constrains the underlying
distance metric crucial to the performance of Wasserstein-based solutions. To
address this problem, we propose Primal Wasserstein DICE (PW-DICE), which
minimizes the primal Wasserstein distance between the expert and learner state
occupancies with a pessimistic regularizer and leverages a contrastively
learned distance as the underlying metric for the Wasserstein distance.
Theoretically, we prove that our framework is a generalization of the
state-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein
minimization. Empirically, we find that PW-DICE improves upon several
state-of-the-art methods on multiple testbeds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1&quot;&gt;Kai Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1&quot;&gt;Alexander G. Schwing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-xiong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01344">
<title>Like an Open Book? Read Neural Network Architecture with Simple Power Analysis on 32-bit Microcontrollers. (arXiv:2311.01344v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2311.01344</link>
<description rdf:parseType="Literal">&lt;p&gt;Model extraction is a growing concern for the security of AI systems. For
deep neural network models, the architecture is the most important information
an adversary aims to recover. Being a sequence of repeated computation blocks,
neural network models deployed on edge-devices will generate distinctive
side-channel leakages. The latter can be exploited to extract critical
information when targeted platforms are physically accessible. By combining
theoretical knowledge about deep learning practices and analysis of a
widespread implementation library (ARM CMSIS-NN), our purpose is to answer this
critical question: how far can we extract architecture information by simply
examining an EM side-channel trace? For the first time, we propose an
extraction methodology for traditional MLP and CNN models running on a high-end
32-bit microcontroller (Cortex-M7) that relies only on simple pattern
recognition analysis. Despite few challenging cases, we claim that, contrary to
parameters extraction, the complexity of the attack is relatively low and we
highlight the urgent need for practicable protections that could fit the strong
memory and latency requirements of such platforms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joud_R/0/1/0/all/0/1&quot;&gt;Raphael Joud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moellic_P/0/1/0/all/0/1&quot;&gt;Pierre-Alain Moellic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pontie_S/0/1/0/all/0/1&quot;&gt;Simon Pontie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigaud_J/0/1/0/all/0/1&quot;&gt;Jean-Baptiste Rigaud&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01349">
<title>Unreading Race: Purging Protected Features from Chest X-ray Embeddings. (arXiv:2311.01349v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01349</link>
<description rdf:parseType="Literal">&lt;p&gt;Purpose: To analyze and remove protected feature effects in chest radiograph
embeddings of deep learning models.
&lt;/p&gt;
&lt;p&gt;Materials and Methods: An orthogonalization is utilized to remove the
influence of protected features (e.g., age, sex, race) in chest radiograph
embeddings, ensuring feature-independent results. To validate the efficacy of
the approach, we retrospectively study the MIMIC and CheXpert datasets using
three pre-trained models, namely a supervised contrastive, a self-supervised
contrastive, and a baseline classifier model. Our statistical analysis involves
comparing the original versus the orthogonalized embeddings by estimating
protected feature influences and evaluating the ability to predict race, age,
or sex using the two types of embeddings.
&lt;/p&gt;
&lt;p&gt;Results: Our experiments reveal a significant influence of protected features
on predictions of pathologies. Applying orthogonalization removes these feature
effects. Apart from removing any influence on pathology classification, while
maintaining competitive predictive performance, orthogonalized embeddings
further make it infeasible to directly predict protected attributes and
mitigate subgroup disparities.
&lt;/p&gt;
&lt;p&gt;Conclusion: The presented work demonstrates the successful application and
evaluation of the orthogonalization technique in the domain of chest X-ray
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_T/0/1/0/all/0/1&quot;&gt;Tobias Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ingrisch_M/0/1/0/all/0/1&quot;&gt;Michael Ingrisch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1&quot;&gt;Bernd Bischl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1&quot;&gt;David R&amp;#xfc;gamer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01352">
<title>Deep learning based Image Compression for Microscopy Images: An Empirical Study. (arXiv:2311.01352v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.01352</link>
<description rdf:parseType="Literal">&lt;p&gt;With the fast development of modern microscopes and bioimaging techniques, an
unprecedentedly large amount of imaging data are being generated, stored,
analyzed, and even shared through networks. The size of the data poses great
challenges for current data infrastructure. One common way to reduce the data
size is by image compression. This present study analyzes classic and deep
learning based image compression methods, and their impact on deep learning
based image processing models. Deep learning based label-free prediction models
(i.e., predicting fluorescent images from bright field images) are used as an
example application for comparison and analysis. Effective image compression
methods could help reduce the data size significantly without losing necessary
information, and therefore reduce the burden on data management infrastructure
and permit fast transmission through the network for data sharing or cloud
computing. To compress images in such a wanted way, multiple classical lossy
image compression techniques are compared to several AI-based compression
models provided by and trained with the CompressAI toolbox using python. These
different compression techniques are compared in compression ratio, multiple
image similarity measures and, most importantly, the prediction accuracy from
label-free models on compressed images. We found that AI-based compression
techniques largely outperform the classic ones and will minimally affect the
downstream label-free task in 2D cases. In the end, we hope the present study
could shed light on the potential of deep learning based image compression and
the impact of image compression on downstream deep learning based image
analysis models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sollman_J/0/1/0/all/0/1&quot;&gt;Jan Sollman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jianxu Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01356">
<title>On the Lipschitz constant of random neural networks. (arXiv:2311.01356v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01356</link>
<description rdf:parseType="Literal">&lt;p&gt;Empirical studies have widely demonstrated that neural networks are highly
sensitive to small, adversarial perturbations of the input. The worst-case
robustness against these so-called adversarial examples can be quantified by
the Lipschitz constant of the neural network. However, only few theoretical
results regarding this quantity exist in the literature. In this paper, we
initiate the study of the Lipschitz constant of random ReLU neural networks,
i.e., neural networks whose weights are chosen at random and which employ the
ReLU activation function. For shallow neural networks, we characterize the
Lipschitz constant up to an absolute numerical constant. Moreover, we extend
our analysis to deep neural networks of sufficiently large width where we prove
upper and lower bounds for the Lipschitz constant. These bounds match up to a
logarithmic factor that depends on the depth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Geuchen_P/0/1/0/all/0/1&quot;&gt;Paul Geuchen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heindl_T/0/1/0/all/0/1&quot;&gt;Thomas Heindl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stoger_D/0/1/0/all/0/1&quot;&gt;Dominik St&amp;#xf6;ger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Voigtlaender_F/0/1/0/all/0/1&quot;&gt;Felix Voigtlaender&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01367">
<title>Respiratory Anomaly Detection using Reflected Infrared Light-wave Signals. (arXiv:2311.01367v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2311.01367</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we present a non-contact respiratory anomaly detection method
using incoherent light-wave signals reflected from the chest of a mechanical
robot that can breathe like human beings. In comparison to existing radar and
camera-based sensing systems for vitals monitoring, this technology uses only a
low-cost ubiquitous light source (e.g., infrared light emitting diode) and
sensor (e.g., photodetector). This light-wave sensing (LWS) system recognizes
different breathing anomalies from the variations of light intensity reflected
from the chest of the robot within a 0.5m-1.5m range. The anomaly detection
model demonstrates up to 96.6% average accuracy in classifying 7 different
types of breathing data using machine learning. The model can also detect
faulty data collected by the system that does not contain breathing
information. The developed system can be utilized at home or healthcare
facilities as a smart, non-contact and discreet respiration monitoring method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Islam_M/0/1/0/all/0/1&quot;&gt;Md Zobaer Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Martin_B/0/1/0/all/0/1&quot;&gt;Brenden Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gotcher_C/0/1/0/all/0/1&quot;&gt;Carly Gotcher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Martinez_T/0/1/0/all/0/1&quot;&gt;Tyler Martinez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+OHara_J/0/1/0/all/0/1&quot;&gt;John F. O&amp;#x27;Hara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ekin_S/0/1/0/all/0/1&quot;&gt;Sabit Ekin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01375">
<title>Monotone Generative Modeling via a Gromov-Monge Embedding. (arXiv:2311.01375v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01375</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) are powerful tools for creating new
content, but they face challenges such as sensitivity to starting conditions
and mode collapse. To address these issues, we propose a deep generative model
that utilizes the Gromov-Monge embedding (GME). It helps identify the
low-dimensional structure of the underlying measure of the data and then maps
it, while preserving its geometry, into a measure in a low-dimensional latent
space, which is then optimally transported to the reference measure. We
guarantee the preservation of the underlying geometry by the GME and
$c$-cyclical monotonicity of the generative map, where $c$ is an intrinsic
embedding cost employed by the GME. The latter property is a first step in
guaranteeing better robustness to initialization of parameters and mode
collapse. Numerical experiments demonstrate the effectiveness of our approach
in generating high-quality images, avoiding mode collapse, and exhibiting
robustness to different starting conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1&quot;&gt;Wonjun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yifei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1&quot;&gt;Dongmian Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerman_G/0/1/0/all/0/1&quot;&gt;Gilad Lerman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01378">
<title>Vision-Language Foundation Models as Effective Robot Imitators. (arXiv:2311.01378v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.01378</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress in vision language foundation models has shown their ability
to understand multimodal data and resolve complicated vision language tasks,
including robotics manipulation. We seek a straightforward way of making use of
existing vision-language models (VLMs) with simple fine-tuning on robotics
data. To this end, we derive a simple and novel vision-language manipulation
framework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo.
Unlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step
vision-language comprehension, models sequential history information with an
explicit policy head, and is slightly fine-tuned by imitation learning only on
language-conditioned manipulation datasets. Such a decomposition provides
RoboFlamingo the flexibility for open-loop control and deployment on
low-performance platforms. By exceeding the state-of-the-art performance with a
large margin on the tested benchmark, we show RoboFlamingo can be an effective
and competitive alternative to adapt VLMs to robot control. Our extensive
experimental results also reveal several interesting conclusions regarding the
behavior of different pre-trained VLMs on manipulation tasks. We believe
RoboFlamingo has the potential to be a cost-effective and easy-to-use solution
for robotics manipulation, empowering everyone with the ability to fine-tune
their own robotics policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xinghang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Minghuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hanbo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Cunjun Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jie Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hongtao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheang_C/0/1/0/all/0/1&quot;&gt;Chilam Cheang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jing_Y/0/1/0/all/0/1&quot;&gt;Ya Jing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Huaping Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_T/0/1/0/all/0/1&quot;&gt;Tao Kong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01388">
<title>Time-series Generation by Contrastive Imitation. (arXiv:2311.01388v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.01388</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider learning a generative model for time-series data. The sequential
setting poses a unique challenge: Not only should the generator capture the
conditional dynamics of (stepwise) transitions, but its open-loop rollouts
should also preserve the joint distribution of (multi-step) trajectories. On
one hand, autoregressive models trained by MLE allow learning and computing
explicit transition distributions, but suffer from compounding error during
rollouts. On the other hand, adversarial models based on GAN training alleviate
such exposure bias, but transitions are implicit and hard to assess. In this
work, we study a generative framework that seeks to combine the strengths of
both: Motivated by a moment-matching objective to mitigate compounding error,
we optimize a local (but forward-looking) transition policy, where the
reinforcement signal is provided by a global (but stepwise-decomposable) energy
model trained by contrastive estimation. At training, the two components are
learned cooperatively, avoiding the instabilities typical of adversarial
objectives. At inference, the learned policy serves as the generator for
iterative sampling, and the learned energy serves as a trajectory-level measure
for evaluating sample quality. By expressly training a policy to imitate
sequential behavior of time-series features in a dataset, this approach
embodies &quot;generation by imitation&quot;. Theoretically, we illustrate the
correctness of this formulation and the consistency of the algorithm.
Empirically, we evaluate its ability to generate predictively useful samples
from real-world datasets, verifying that it performs at the standard of
existing benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jarrett_D/0/1/0/all/0/1&quot;&gt;Daniel Jarrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bica_I/0/1/0/all/0/1&quot;&gt;Ioana Bica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela van der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01394">
<title>Learning Realistic Traffic Agents in Closed-loop. (arXiv:2311.01394v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.01394</link>
<description rdf:parseType="Literal">&lt;p&gt;Realistic traffic simulation is crucial for developing self-driving software
in a safe and scalable manner prior to real-world deployment. Typically,
imitation learning (IL) is used to learn human-like traffic agents directly
from real-world observations collected offline, but without explicit
specification of traffic rules, agents trained from IL alone frequently display
unrealistic infractions like collisions and driving off the road. This problem
is exacerbated in out-of-distribution and long-tail scenarios. On the other
hand, reinforcement learning (RL) can train traffic agents to avoid
infractions, but using RL alone results in unhuman-like driving behaviors. We
propose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning
objective to match expert demonstrations under a traffic compliance constraint,
which naturally gives rise to a joint IL + RL approach, obtaining the best of
both worlds. Our method learns in closed-loop simulations of both nominal
scenarios from real-world datasets as well as procedurally generated long-tail
scenarios. Our experiments show that RTR learns more realistic and
generalizable traffic simulation policies, achieving significantly better
tradeoffs between human-like driving and traffic compliance in both nominal and
long-tail scenarios. Moreover, when used as a data generation tool for training
prediction models, our learned traffic policy leads to considerably improved
downstream prediction metrics compared to baseline traffic agents. For more
information, visit the project website: https://waabi.ai/rtr
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chris Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1&quot;&gt;James Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lunjun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1&quot;&gt;Kelvin Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suo_S/0/1/0/all/0/1&quot;&gt;Simon Suo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1&quot;&gt;Raquel Urtasun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01404">
<title>Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs. (arXiv:2311.01404v1 [math.OC])</title>
<link>http://arxiv.org/abs/2311.01404</link>
<description rdf:parseType="Literal">&lt;p&gt;The term &quot;Normalizing Flows&quot; is related to the task of constructing
invertible transport maps between probability measures by means of deep neural
networks. In this paper, we consider the problem of recovering the
$W_2$-optimal transport map $T$ between absolutely continuous measures
$\mu,\nu\in\mathcal{P}(\mathbb{R}^n)$ as the flow of a linear-control neural
ODE. We first show that, under suitable assumptions on $\mu,\nu$ and on the
controlled vector fields, the optimal transport map is contained in the
$C^0_c$-closure of the flows generated by the system. Assuming that discrete
approximations $\mu_N,\nu_N$ of the original measures $\mu,\nu$ are available,
we use a discrete optimal coupling $\gamma_N$ to define an optimal control
problem. With a $\Gamma$-convergence argument, we prove that its solutions
correspond to flows that approximate the optimal transport map $T$. Finally,
taking advantage of the Pontryagin Maximum Principle, we propose an iterative
numerical scheme for the resolution of the optimal control problem, resulting
in an algorithm for the practical computation of the approximated optimal
transport map.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Scagliotti_A/0/1/0/all/0/1&quot;&gt;Alessandro Scagliotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Farinelli_S/0/1/0/all/0/1&quot;&gt;Sara Farinelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01405">
<title>Learning to See Physical Properties with Active Sensing Motor Policies. (arXiv:2311.01405v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.01405</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge of terrain&apos;s physical properties inferred from color images can aid
in making efficient robotic locomotion plans. However, unlike image
classification, it is unintuitive for humans to label image patches with
physical properties. Without labeled data, building a vision system that takes
as input the observed terrain and predicts physical properties remains
challenging. We present a method that overcomes this challenge by
self-supervised labeling of images captured by robots during real-world
traversal with physical property estimators trained in simulation. To ensure
accurate labeling, we introduce Active Sensing Motor Policies (ASMP), which are
trained to explore locomotion behaviors that increase the accuracy of
estimating physical parameters. For instance, the quadruped robot learns to
swipe its foot against the ground to estimate the friction coefficient
accurately. We show that the visual system trained with a small amount of
real-world traversal data accurately predicts physical parameters. The trained
system is robust and works even with overhead images captured by a drone
despite being trained on data collected by cameras attached to a quadruped
robot walking on the ground.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Margolis_G/0/1/0/all/0/1&quot;&gt;Gabriel B. Margolis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1&quot;&gt;Xiang Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1&quot;&gt;Yandong Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1&quot;&gt;Pulkit Agrawal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01406">
<title>Analysis of Information Propagation in Ethereum Network Using Combined Graph Attention Network and Reinforcement Learning to Optimize Network Efficiency and Scalability. (arXiv:2311.01406v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01406</link>
<description rdf:parseType="Literal">&lt;p&gt;Blockchain technology has revolutionized the way information is propagated in
decentralized networks. Ethereum plays a pivotal role in facilitating smart
contracts and decentralized applications. Understanding information propagation
dynamics in Ethereum is crucial for ensuring network efficiency, security, and
scalability. In this study, we propose an innovative approach that utilizes
Graph Convolutional Networks (GCNs) to analyze the information propagation
patterns in the Ethereum network. The first phase of our research involves data
collection from the Ethereum blockchain, consisting of blocks, transactions,
and node degrees. We construct a transaction graph representation using
adjacency matrices to capture the node embeddings; while our major contribution
is to develop a combined Graph Attention Network (GAT) and Reinforcement
Learning (RL) model to optimize the network efficiency and scalability. It
learns the best actions to take in various network states, ultimately leading
to improved network efficiency, throughput, and optimize gas limits for block
processing. In the experimental evaluation, we analyze the performance of our
model on a large-scale Ethereum dataset. We investigate effectively aggregating
information from neighboring nodes capturing graph structure and updating node
embeddings using GCN with the objective of transaction pattern prediction,
accounting for varying network loads and number of blocks. Not only we design a
gas limit optimization model and provide the algorithm, but also to address
scalability, we demonstrate the use and implementation of sparse matrices in
GraphConv, GraphSAGE, and GAT. The results indicate that our designed GAT-RL
model achieves superior results compared to other GCN models in terms of
performance. It effectively propagates information across the network,
optimizing gas limits for block processing and improving network efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behfar_S/0/1/0/all/0/1&quot;&gt;Stefan Kambiz Behfar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crowcroft_J/0/1/0/all/0/1&quot;&gt;Jon Crowcroft&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01409">
<title>A Coreset-based, Tempered Variational Posterior for Accurate and Scalable Stochastic Gaussian Process Inference. (arXiv:2311.01409v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01409</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel stochastic variational Gaussian process ($\mathcal{GP}$)
inference method, based on a posterior over a learnable set of weighted pseudo
input-output points (coresets). Instead of a free-form variational family, the
proposed coreset-based, variational tempered family for $\mathcal{GP}$s (CVTGP)
is defined in terms of the $\mathcal{GP}$ prior and the data-likelihood; hence,
accommodating the modeling inductive biases. We derive CVTGP&apos;s lower bound for
the log-marginal likelihood via marginalization of the proposed posterior over
latent $\mathcal{GP}$ coreset variables, and show it is amenable to stochastic
optimization. CVTGP reduces the learnable parameter size to $\mathcal{O}(M)$,
enjoys numerical stability, and maintains $\mathcal{O}(M^3)$ time- and
$\mathcal{O}(M^2)$ space-complexity, by leveraging a coreset-based tempered
posterior that, in turn, provides sparse and explainable representations of the
data. Results on simulated and real-world regression problems with Gaussian
observation noise validate that CVTGP provides better evidence lower-bound
estimates and predictive root mean squared error than alternative stochastic
$\mathcal{GP}$ inference methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ketenci_M/0/1/0/all/0/1&quot;&gt;Mert Ketenci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perotte_A/0/1/0/all/0/1&quot;&gt;Adler Perotte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elhadad_N/0/1/0/all/0/1&quot;&gt;No&amp;#xe9;mie Elhadad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urteaga_I/0/1/0/all/0/1&quot;&gt;I&amp;#xf1;igo Urteaga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01410">
<title>The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing. (arXiv:2311.01410v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01410</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a unified probabilistic formulation for diffusion-based image
editing, where a latent variable is edited in a task-specific manner and
generally deviates from the corresponding marginal distribution induced by the
original stochastic or ordinary differential equation (SDE or ODE). Instead, it
defines a corresponding SDE or ODE for editing. In the formulation, we prove
that the Kullback-Leibler divergence between the marginal distributions of the
two SDEs gradually decreases while that for the ODEs remains as the time
approaches zero, which shows the promise of SDE in image editing. Inspired by
it, we provide the SDE counterparts for widely used ODE baselines in various
tasks including inpainting and image-to-image translation, where SDE shows a
consistent and substantial improvement. Moreover, we propose SDE-Drag -- a
simple yet effective method built upon the SDE formulation for point-based
content dragging. We build a challenging benchmark (termed DragBench) with
open-set natural, art, and AI-generated images for evaluation. A user study on
DragBench indicates that SDE-Drag significantly outperforms our ODE baseline,
existing diffusion-based methods, and the renowned DragGAN. Our results
demonstrate the superiority and versatility of SDE in image editing and push
the boundary of diffusion-based editing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1&quot;&gt;Shen Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Hanzhong Allan Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Cheng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuhao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Chenyu Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chongxuan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01412">
<title>Castor: Causal Temporal Regime Structure Learning. (arXiv:2311.01412v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01412</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of uncovering causal relationships among multivariate time series
data stands as an essential and challenging objective that cuts across a broad
array of disciplines ranging from climate science to healthcare. Such data
entails linear or non-linear relationships, and usually follow multiple a
priori unknown regimes. Existing causal discovery methods can infer summary
causal graphs from heterogeneous data with known regimes, but they fall short
in comprehensively learning both regimes and the corresponding causal graph. In
this paper, we introduce CASTOR, a novel framework designed to learn causal
relationships in heterogeneous time series data composed of various regimes,
each governed by a distinct causal graph. Through the maximization of a score
function via the EM algorithm, CASTOR infers the number of regimes and learns
linear or non-linear causal relationships in each regime. We demonstrate the
robust convergence properties of CASTOR, specifically highlighting its
proficiency in accurately identifying unique regimes. Empirical evidence,
garnered from exhaustive synthetic experiments and two real-world benchmarks,
confirm CASTOR&apos;s superior performance in causal discovery compared to baseline
methods. By learning a full temporal causal graph for each regime, CASTOR
establishes itself as a distinctly interpretable method for causal discovery in
heterogeneous time series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahmani_A/0/1/0/all/0/1&quot;&gt;Abdellah Rahmani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1&quot;&gt;Pascal Frossard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01420">
<title>Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial Target Data. (arXiv:2311.01420v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01420</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a learning problem involving adapting a pre-trained source model
to the target domain for classifying all classes that appeared in the source
data, using target data that covers only a partial label space. This problem is
practical, as it is unrealistic for the target end-users to collect data for
all classes prior to adaptation. However, it has received limited attention in
the literature. To shed light on this issue, we construct benchmark datasets
and conduct extensive experiments to uncover the inherent challenges. We found
a dilemma -- on the one hand, adapting to the new target domain is important to
claim better performance; on the other hand, we observe that preserving the
classification accuracy of classes missing in the target adaptation data is
highly challenging, let alone improving them. To tackle this, we identify two
key directions: 1) disentangling domain gradients from classification
gradients, and 2) preserving class relationships. We present several effective
solutions that maintain the accuracy of the missing classes and enhance the
overall performance, establishing solid baselines for holistic transfer of
pre-trained models with partial target data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_C/0/1/0/all/0/1&quot;&gt;Cheng-Hao Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hong-You Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mai_Z/0/1/0/all/0/1&quot;&gt;Zheda Mai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_J/0/1/0/all/0/1&quot;&gt;Jike Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1&quot;&gt;Vardaan Pahuja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berger_Wolf_T/0/1/0/all/0/1&quot;&gt;Tanya Berger-Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Song Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stewart_C/0/1/0/all/0/1&quot;&gt;Charles Stewart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yu Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1&quot;&gt;Wei-Lun Chao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01425">
<title>Exploring Deep Learning Techniques for Glaucoma Detection: A Comprehensive Review. (arXiv:2311.01425v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.01425</link>
<description rdf:parseType="Literal">&lt;p&gt;Glaucoma is one of the primary causes of vision loss around the world,
necessitating accurate and efficient detection methods. Traditional manual
detection approaches have limitations in terms of cost, time, and subjectivity.
Recent developments in deep learning approaches demonstrate potential in
automating glaucoma detection by detecting relevant features from retinal
fundus images. This article provides a comprehensive overview of cutting-edge
deep learning methods used for the segmentation, classification, and detection
of glaucoma. By analyzing recent studies, the effectiveness and limitations of
these techniques are evaluated, key findings are highlighted, and potential
areas for further research are identified. The use of deep learning algorithms
may significantly improve the efficacy, usefulness, and accuracy of glaucoma
detection. The findings from this research contribute to the ongoing
advancements in automated glaucoma detection and have implications for
improving patient outcomes and reducing the global burden of glaucoma.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Soofi_A/0/1/0/all/0/1&quot;&gt;Aized Amin Soofi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fazal-e-Amin/0/1/0/all/0/1&quot;&gt;Fazal-e-Amin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01428">
<title>Identifying Alzheimer Disease Dementia Levels Using Machine Learning Methods. (arXiv:2311.01428v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01428</link>
<description rdf:parseType="Literal">&lt;p&gt;Dementia, a prevalent neurodegenerative condition, is a major manifestation
of Alzheimer&apos;s disease (AD). As the condition progresses from mild to severe,
it significantly impairs the individual&apos;s ability to perform daily tasks
independently, necessitating the need for timely and accurate AD
classification. Machine learning or deep learning models have emerged as
effective tools for this purpose. In this study, we suggested an approach for
classifying the four stages of dementia using RF, SVM, and CNN algorithms,
augmented with watershed segmentation for feature extraction from MRI images.
Our results reveal that SVM with watershed features achieves an impressive
accuracy of 96.25%, surpassing other classification methods. The ADNI dataset
is utilized to evaluate the effectiveness of our method, and we observed that
the inclusion of watershed segmentation contributes to the enhanced performance
of the models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hussain_M/0/1/0/all/0/1&quot;&gt;Md Gulzar Hussain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shiren_Y/0/1/0/all/0/1&quot;&gt;Ye Shiren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01434">
<title>Tailoring Mixup to Data using Kernel Warping functions. (arXiv:2311.01434v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01434</link>
<description rdf:parseType="Literal">&lt;p&gt;Data augmentation is an essential building block for learning efficient deep
learning models. Among all augmentation techniques proposed so far, linear
interpolation of training data points, also called mixup, has found to be
effective for a large panel of applications. While the majority of works have
focused on selecting the right points to mix, or applying complex non-linear
interpolation, we are interested in mixing similar points more frequently and
strongly than less similar ones. To this end, we propose to dynamically change
the underlying distribution of interpolation coefficients through warping
functions, depending on the similarity between data points to combine. We
define an efficient and flexible framework to do so without losing in
diversity. We provide extensive experiments for classification and regression
tasks, showing that our proposed method improves both performance and
calibration of models. Code available in
https://github.com/ENSTA-U2IS/torch-uncertainty
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouniot_Q/0/1/0/all/0/1&quot;&gt;Quentin Bouniot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozharovskyi_P/0/1/0/all/0/1&quot;&gt;Pavlo Mozharovskyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1&quot;&gt;Florence d&amp;#x27;Alch&amp;#xe9;-Buc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01435">
<title>Contrastive Moments: Unsupervised Halfspace Learning in Polynomial Time. (arXiv:2311.01435v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01435</link>
<description rdf:parseType="Literal">&lt;p&gt;We give a polynomial-time algorithm for learning high-dimensional halfspaces
with margins in $d$-dimensional space to within desired TV distance when the
ambient distribution is an unknown affine transformation of the $d$-fold
product of an (unknown) symmetric one-dimensional logconcave distribution, and
the halfspace is introduced by deleting at least an $\epsilon$ fraction of the
data in one of the component distributions. Notably, our algorithm does not
need labels and establishes the unique (and efficient) identifiability of the
hidden halfspace under this distributional assumption. The sample and time
complexity of the algorithm are polynomial in the dimension and $1/\epsilon$.
The algorithm uses only the first two moments of suitable re-weightings of the
empirical distribution, which we call contrastive moments; its analysis uses
classical facts about generalized Dirichlet polynomials and relies crucially on
a new monotonicity property of the moment ratio of truncations of logconcave
distributions. Such algorithms, based only on first and second moments were
suggested in earlier work, but hitherto eluded rigorous guarantees.
&lt;/p&gt;
&lt;p&gt;Prior work addressed the special case when the underlying distribution is
Gaussian via Non-Gaussian Component Analysis. We improve on this by providing
polytime guarantees based on Total Variation (TV) distance, in place of
existing moment-bound guarantees that can be super-polynomial. Our work is also
the first to go beyond Gaussians in this setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1&quot;&gt;Xinyuan Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1&quot;&gt;Santosh S. Vempala&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01441">
<title>Distilling Out-of-Distribution Robustness from Vision-Language Foundation Models. (arXiv:2311.01441v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01441</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a conceptually simple and lightweight framework for improving the
robustness of vision models through the combination of knowledge distillation
and data augmentation. We address the conjecture that larger models do not make
for better teachers by showing strong gains in out-of-distribution robustness
when distilling from pretrained foundation models. Following this finding, we
propose Discrete Adversarial Distillation (DAD), which leverages a robust
teacher to generate adversarial examples and a VQGAN to discretize them,
creating more informative samples than standard data augmentation techniques.
We provide a theoretical framework for the use of a robust teacher in the
knowledge distillation with data augmentation setting and demonstrate strong
gains in out-of-distribution robustness and clean accuracy across different
student architectures. Notably, our method adds minor computational overhead
compared to similar techniques and can be easily combined with other data
augmentations for further improvements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Andy Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haohan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01442">
<title>Deep Double Descent for Time Series Forecasting: Avoiding Undertrained Models. (arXiv:2311.01442v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.01442</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models, particularly Transformers, have achieved impressive
results in various domains, including time series forecasting. While existing
time series literature primarily focuses on model architecture modifications
and data augmentation techniques, this paper explores the training schema of
deep learning models for time series; how models are trained regardless of
their architecture. We perform extensive experiments to investigate the
occurrence of deep double descent in several Transformer models trained on
public time series data sets. We demonstrate epoch-wise deep double descent and
that overfitting can be reverted using more epochs. Leveraging these findings,
we achieve state-of-the-art results for long sequence time series forecasting
in nearly 70% of the 72 benchmarks tested. This suggests that many models in
the literature may possess untapped potential. Additionally, we introduce a
taxonomy for classifying training schema modifications, covering data
augmentation, model inputs, model targets, time series per model, and
computational budget.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assandri_V/0/1/0/all/0/1&quot;&gt;Valentino Assandri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heshmati_S/0/1/0/all/0/1&quot;&gt;Sam Heshmati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yaman_B/0/1/0/all/0/1&quot;&gt;Burhaneddin Yaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iakovlev_A/0/1/0/all/0/1&quot;&gt;Anton Iakovlev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Repetur_A/0/1/0/all/0/1&quot;&gt;Ariel Emiliano Repetur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01446">
<title>Adv3D: Generating Safety-Critical 3D Objects through Closed-Loop Simulation. (arXiv:2311.01446v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.01446</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-driving vehicles (SDVs) must be rigorously tested on a wide range of
scenarios to ensure safe deployment. The industry typically relies on
closed-loop simulation to evaluate how the SDV interacts on a corpus of
synthetic and real scenarios and verify it performs properly. However, they
primarily only test the system&apos;s motion planning module, and only consider
behavior variations. It is key to evaluate the full autonomy system in
closed-loop, and to understand how variations in sensor data based on scene
appearance, such as the shape of actors, affect system performance. In this
paper, we propose a framework, Adv3D, that takes real world scenarios and
performs closed-loop sensor simulation to evaluate autonomy performance, and
finds vehicle shapes that make the scenario more challenging, resulting in
autonomy failures and uncomfortable SDV maneuvers. Unlike prior works that add
contrived adversarial shapes to vehicle roof-tops or roadside to harm
perception only, we optimize a low-dimensional shape representation to modify
the vehicle shape itself in a realistic manner to degrade autonomy performance
(e.g., perception, prediction, and motion planning). Moreover, we find that the
shape variations found with Adv3D optimized in closed-loop are much more
effective than those in open-loop, demonstrating the importance of finding
scene appearance variations that affect autonomy in the interactive setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarva_J/0/1/0/all/0/1&quot;&gt;Jay Sarva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jingkang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1&quot;&gt;James Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1&quot;&gt;Yuwen Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manivasagam_S/0/1/0/all/0/1&quot;&gt;Sivabalan Manivasagam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1&quot;&gt;Raquel Urtasun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01447">
<title>CADSim: Robust and Scalable in-the-wild 3D Reconstruction for Controllable Sensor Simulation. (arXiv:2311.01447v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.01447</link>
<description rdf:parseType="Literal">&lt;p&gt;Realistic simulation is key to enabling safe and scalable development of %
self-driving vehicles. A core component is simulating the sensors so that the
entire autonomy system can be tested in simulation. Sensor simulation involves
modeling traffic participants, such as vehicles, with high quality appearance
and articulated geometry, and rendering them in real time. The self-driving
industry has typically employed artists to build these assets. However, this is
expensive, slow, and may not reflect reality. Instead, reconstructing assets
automatically from sensor data collected in the wild would provide a better
path to generating a diverse and large set with good real-world coverage.
Nevertheless, current reconstruction approaches struggle on in-the-wild sensor
data, due to its sparsity and noise. To tackle these issues, we present CADSim,
which combines part-aware object-class priors via a small set of CAD models
with differentiable rendering to automatically reconstruct vehicle geometry,
including articulated wheels, with high-quality appearance. Our experiments
show our method recovers more accurate shapes from sparse data compared to
existing approaches. Importantly, it also trains and renders efficiently. We
demonstrate our reconstructed vehicles in several applications, including
accurate testing of autonomy perception systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jingkang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manivasagam_S/0/1/0/all/0/1&quot;&gt;Sivabalan Manivasagam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Ze Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barsan_I/0/1/0/all/0/1&quot;&gt;Ioan Andrei B&amp;#xe2;rsan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1&quot;&gt;Anqi Joyce Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1&quot;&gt;Wei-Chiu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1&quot;&gt;Raquel Urtasun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2002.07897">
<title>LocoGAN -- Locally Convolutional GAN. (arXiv:2002.07897v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2002.07897</link>
<description rdf:parseType="Literal">&lt;p&gt;In the paper we construct a fully convolutional GAN model: LocoGAN, which
latent space is given by noise-like images of possibly different resolutions.
The learning is local, i.e. we process not the whole noise-like image, but the
sub-images of a fixed size. As a consequence LocoGAN can produce images of
arbitrary dimensions e.g. LSUN bedroom data set. Another advantage of our
approach comes from the fact that we use the position channels, which allows
the generation of fully periodic (e.g. cylindrical panoramic images) or almost
periodic ,,infinitely long&quot; images (e.g. wall-papers).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Struski_L/0/1/0/all/0/1&quot;&gt;&amp;#x141;ukasz Struski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Knop_S/0/1/0/all/0/1&quot;&gt;Szymon Knop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tabor_J/0/1/0/all/0/1&quot;&gt;Jacek Tabor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Daniec_W/0/1/0/all/0/1&quot;&gt;Wiktor Daniec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Spurek_P/0/1/0/all/0/1&quot;&gt;Przemys&amp;#x142;aw Spurek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2005.05163">
<title>Computable Phenotypes of Patient Acuity in the Intensive Care Unit. (arXiv:2005.05163v2 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2005.05163</link>
<description rdf:parseType="Literal">&lt;p&gt;Continuous monitoring and patient acuity assessments are key aspects of
Intensive Care Unit (ICU) practice, but both are limited by time constraints
imposed on healthcare providers. Moreover, anticipating clinical trajectories
remains imprecise. The objectives of this study are to (1) develop an
electronic phenotype of acuity using automated variable retrieval within the
electronic health records and (2) describe transitions between acuity states
that illustrate the clinical trajectories of ICU patients. We gathered two
single-center, longitudinal electronic health record datasets for 51,372 adult
ICU patients admitted to the University of Florida Health (UFH) Gainesville
(GNV) and Jacksonville (JAX). We developed algorithms to quantify acuity status
at four-hour intervals for each ICU admission and identify acuity phenotypes
using continuous acuity status and k-means clustering approach. 51,073
admissions for 38,749 patients in the UFH GNV dataset and 22,219 admissions for
12,623 patients in the UFH JAX dataset had at least one ICU stay lasting more
than four hours. There were three phenotypes: persistently stable, persistently
unstable, and transitioning from unstable to stable. For stable patients,
approximately 0.7%-1.7% would transition to unstable, 0.02%-0.1% would expire,
1.2%-3.4% would be discharged, and the remaining 96%-97% would remain stable in
the ICU every four hours. For unstable patients, approximately 6%-10% would
transition to stable, 0.4%-0.5% would expire, and the remaining 89%-93% would
remain unstable in the ICU in the next four hours. We developed phenotyping
algorithms for patient acuity status every four hours while admitted to the
ICU. This approach may be useful in developing prognostic and clinical
decision-support tools to aid patients, caregivers, and providers in shared
decision-making processes regarding escalation of care and patient values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ren_Y/0/1/0/all/0/1&quot;&gt;Yuanfang Ren&lt;/a&gt; (1) (2), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Balch_J/0/1/0/all/0/1&quot;&gt;Jeremy Balch&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Abbott_K/0/1/0/all/0/1&quot;&gt;Kenneth L. Abbott&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Loftus_T/0/1/0/all/0/1&quot;&gt;Tyler J. Loftus&lt;/a&gt; (1) (3), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Shickel_B/0/1/0/all/0/1&quot;&gt;Benjamin Shickel&lt;/a&gt; (1) (2), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Rashidi_P/0/1/0/all/0/1&quot;&gt;Parisa Rashidi&lt;/a&gt; (1) (4), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Bihorac_A/0/1/0/all/0/1&quot;&gt;Azra Bihorac&lt;/a&gt; (1) (2), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ozrazgat_Baslanti_T/0/1/0/all/0/1&quot;&gt;Tezcan Ozrazgat-Baslanti&lt;/a&gt; (1) (2) ((1) Intelligent Clinical Care Center (IC3), University of Florida, Gainesville, FL, USA, (2) Department of Medicine, College of Medicine, University of Florida, Gainesville, FL, USA, (3) Department of Surgery, College of Medicine, University of Florida, Gainesville, FL, USA, (4) J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.05147">
<title>Model-free Policy Learning with Reward Gradients. (arXiv:2103.05147v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2103.05147</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the increasing popularity of policy gradient methods, they are yet to
be widely utilized in sample-scarce applications, such as robotics. The sample
efficiency could be improved by making best usage of available information. As
a key component in reinforcement learning, the reward function is usually
devised carefully to guide the agent. Hence, the reward function is usually
known, allowing access to not only scalar reward signals but also reward
gradients. To benefit from reward gradients, previous works require the
knowledge of environment dynamics, which are hard to obtain. In this work, we
develop the \textit{Reward Policy Gradient} estimator, a novel approach that
integrates reward gradients without learning a model. Bypassing the model
dynamics allows our estimator to achieve a better bias-variance trade-off,
which results in a higher sample efficiency, as shown in the empirical
analysis. Our method also boosts the performance of Proximal Policy
Optimization on different MuJoCo control tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_Q/0/1/0/all/0/1&quot;&gt;Qingfeng Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tosatto_S/0/1/0/all/0/1&quot;&gt;Samuele Tosatto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farrahi_H/0/1/0/all/0/1&quot;&gt;Homayoon Farrahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1&quot;&gt;A. Rupam Mahmood&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2104.04926">
<title>Deep learning-based Edge-aware pre and post-processing methods for JPEG compressed images. (arXiv:2104.04926v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2104.04926</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a learning-based compression scheme that envelopes a standard
codec between pre and post-processing deep CNNs. Specifically, we demonstrate
improvements over prior approaches utilizing a compression-decompression
network by introducing: (a) an edge-aware loss function to prevent blurring
that is commonly occurred in prior works &amp;amp; (b) a super-resolution convolutional
neural network (CNN) for post-processing along with a corresponding
pre-processing network for improved rate-distortion performance in the low rate
regime. The algorithm is assessed on a variety of datasets varying from low to
high resolution namely Set 5, Set 7, Classic 5, Set 14, Live 1, Kodak, General
100, CLIC 2019. When compared to JPEG, JPEG2000, BPG, and recent CNN approach,
the proposed algorithm contributes significant improvement in PSNR with an
approximate gain of 20.75%, 8.47%, 3.22%, 3.23% and 24.59%, 14.46%, 10.14%,
8.57% at low and high bit-rates respectively. Similarly, this improvement in
MS-SSIM is approximately 71.43%, 50%, 36.36%, 23.08%, 64.70% and 64.47%,
61.29%, 47.06%, 51.52%, 16.28% at low and high bit-rates respectively. With
CLIC 2019 dataset, PSNR is found to be superior with approximately 16.67%,
10.53%, 6.78%, and 24.62%, 17.39%, 14.08% at low and high bit-rates
respectively, over JPEG2000, BPG, and recent CNN approach. Similarly, the
MS-SSIM is found to be superior with approximately 72%, 45.45%, 39.13%, 18.52%,
and 71.43%, 50%, 41.18%, 17.07% at low and high bit-rates respectively,
compared to the same approaches. A similar type of improvement is achieved with
other datasets also.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mishra_D/0/1/0/all/0/1&quot;&gt;Dipti Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Satish Kumar Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Rajat Kumar Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.10381">
<title>Entropy-based Discovery of Summary Causal Graphs in Time Series. (arXiv:2105.10381v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2105.10381</link>
<description rdf:parseType="Literal">&lt;p&gt;This study addresses the problem of learning a summary causal graph on time
series with potentially different sampling rates. To do so, we first propose a
new causal temporal mutual information measure for time series. We then show
how this measure relates to an entropy reduction principle that can be seen as
a special case of the probability raising principle. We finally combine these
two ingredients in PC-like and FCI-like algorithms to construct the summary
causal graph. There algorithm are evaluated on several datasets, which shows
both their efficacy and efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assaad_C/0/1/0/all/0/1&quot;&gt;Charles K. Assaad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devijver_E/0/1/0/all/0/1&quot;&gt;Emilie Devijver&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaussier_E/0/1/0/all/0/1&quot;&gt;Eric Gaussier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.00839">
<title>Exploration noise for learning linear-quadratic mean field games. (arXiv:2107.00839v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2107.00839</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of this paper is to demonstrate that common noise may serve as an
exploration noise for learning the solution of a mean field game. This concept
is here exemplified through a toy linear-quadratic model, for which a suitable
form of common noise has already been proven to restore existence and
uniqueness. We here go one step further and prove that the same form of common
noise may force the convergence of the learning algorithm called `fictitious
play&apos;, and this without any further potential or monotone structure. Several
numerical examples are provided in order to support our theoretical analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Delarue_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Delarue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Vasileiadis_A/0/1/0/all/0/1&quot;&gt;Athanasios Vasileiadis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.10284">
<title>Exclusive Group Lasso for Structured Variable Selection. (arXiv:2108.10284v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2108.10284</link>
<description rdf:parseType="Literal">&lt;p&gt;A structured variable selection problem is considered in which the
covariates, divided into predefined groups, activate according to sparse
patterns with few nonzero entries per group. Capitalizing on the concept of
atomic norm, a composite norm can be properly designed to promote such
exclusive group sparsity patterns. The resulting norm lends itself to efficient
and flexible regularized optimization algorithms for support recovery, like the
proximal algorithm. Moreover, an active set algorithm is proposed that builds
the solution by successively including structure atoms into the estimated
support. It is also shown that such an algorithm can be tailored to match more
rigid structures than plain exclusive group sparsity. Asymptotic consistency
analysis (with both the number of parameters as well as the number of groups
growing with the observation size) establishes the effectiveness of the
proposed solution in terms of signed support recovery under conventional
assumptions. Finally, a set of numerical simulations further corroborates the
results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gregoratti_D/0/1/0/all/0/1&quot;&gt;David Gregoratti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mestre_X/0/1/0/all/0/1&quot;&gt;Xavier Mestre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buelga_C/0/1/0/all/0/1&quot;&gt;Carlos Buelga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.08907">
<title>Releasing Graph Neural Networks with Differential Privacy Guarantees. (arXiv:2109.08907v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2109.08907</link>
<description rdf:parseType="Literal">&lt;p&gt;With the increasing popularity of graph neural networks (GNNs) in several
sensitive applications like healthcare and medicine, concerns have been raised
over the privacy aspects of trained GNNs. More notably, GNNs are vulnerable to
privacy attacks, such as membership inference attacks, even if only black-box
access to the trained model is granted. We propose PrivGNN, a
privacy-preserving framework for releasing GNN models in a centralized setting.
Assuming an access to a public unlabeled graph, PrivGNN provides a framework to
release GNN models trained explicitly on public data along with knowledge
obtained from the private data in a privacy preserving manner. PrivGNN combines
the knowledge-distillation framework with the two noise mechanisms, random
subsampling, and noisy labeling, to ensure rigorous privacy guarantees. We
theoretically analyze our approach in the Renyi differential privacy framework.
Besides, we show the solid experimental performance of our method compared to
several baselines adapted for graph-structured data. Our code is available at
https://github.com/iyempissy/privGnn.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olatunji_I/0/1/0/all/0/1&quot;&gt;Iyiola E. Olatunji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Funke_T/0/1/0/all/0/1&quot;&gt;Thorben Funke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khosla_M/0/1/0/all/0/1&quot;&gt;Megha Khosla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.03152">
<title>Bounding Wasserstein distance with couplings. (arXiv:2112.03152v3 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/2112.03152</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov chain Monte Carlo (MCMC) provides asymptotically consistent estimates
of intractable posterior expectations as the number of iterations tends to
infinity. However, in large data applications, MCMC can be computationally
expensive per iteration. This has catalyzed interest in approximating MCMC in a
manner that improves computational speed per iteration but does not produce
asymptotically consistent estimates. In this article, we propose estimators
based on couplings of Markov chains to assess the quality of such
asymptotically biased sampling methods. The estimators give empirical upper
bounds of the Wasserstein distance between the limiting distribution of the
asymptotically biased sampling method and the original target distribution of
interest. We establish theoretical guarantees for our upper bounds and show
that our estimators can remain effective in high dimensions. We apply our
quality measures to stochastic gradient MCMC, variational Bayes, and Laplace
approximations for tall data and to approximate MCMC for Bayesian logistic
regression in 4500 dimensions and Bayesian linear regression in 50000
dimensions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Biswas_N/0/1/0/all/0/1&quot;&gt;Niloy Biswas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1&quot;&gt;Lester Mackey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.13398">
<title>Long Story Short: Omitted Variable Bias in Causal Machine Learning. (arXiv:2112.13398v4 [econ.EM] UPDATED)</title>
<link>http://arxiv.org/abs/2112.13398</link>
<description rdf:parseType="Literal">&lt;p&gt;We derive general, yet simple, sharp bounds on the size of the omitted
variable bias for a broad class of causal parameters that can be identified as
linear functionals of the conditional expectation function of the outcome. Such
functionals encompass many of the traditional targets of investigation in
causal inference studies, such as, for example, (weighted) average of potential
outcomes, average treatment effects (including subgroup effects, such as the
effect on the treated), (weighted) average derivatives, and policy effects from
shifts in covariate distribution -- all for general, nonparametric causal
models. Our construction relies on the Riesz-Frechet representation of the
target functional. Specifically, we show how the bound on the bias depends only
on the additional variation that the latent variables create both in the
outcome and in the Riesz representer for the parameter of interest. Moreover,
in many important cases (e.g, average treatment effects and avearage
derivatives) the bound is shown to depend on easily interpretable quantities
that measure the explanatory power of the omitted variables. Therefore, simple
plausibility judgments on the maximum explanatory power of omitted variables
(in explaining treatment and outcome variation) are sufficient to place overall
bounds on the size of the bias. Furthermore, we use debiased machine learning
to provide flexible and efficient statistical inference on learnable components
of the bounds. Finally, empirical examples demonstrate the usefulness of the
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Cinelli_C/0/1/0/all/0/1&quot;&gt;Carlos Cinelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Newey_W/0/1/0/all/0/1&quot;&gt;Whitney Newey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Amit Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.11104">
<title>Combining Optimal Path Search With Task-Dependent Learning in a Neural Network. (arXiv:2201.11104v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2201.11104</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding optimal paths in connected graphs requires determining the smallest
total cost for traveling along the graph&apos;s edges. This problem can be solved by
several classical algorithms where, usually, costs are predefined for all
edges. Conventional planning methods can, thus, normally not be used when
wanting to change costs in an adaptive way following the requirements of some
task. Here we show that one can define a neural network representation of path
finding problems by transforming cost values into synaptic weights, which
allows for online weight adaptation using network learning mechanisms. When
starting with an initial activity value of one, activity propagation in this
network will lead to solutions, which are identical to those found by the
Bellman-Ford algorithm. The neural network has the same algorithmic complexity
as Bellman-Ford and, in addition, we can show that network learning mechanisms
(such as Hebbian learning) can adapt the weights in the network augmenting the
resulting paths according to some task at hand. We demonstrate this by learning
to navigate in an environment with obstacles as well as by learning to follow
certain sequences of path nodes. Hence, the here-presented novel algorithm may
open up a different regime of applications where path-augmentation (by
learning) is directly coupled with path finding in a natural way.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulvicius_T/0/1/0/all/0/1&quot;&gt;Tomas Kulvicius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tamosiunaite_M/0/1/0/all/0/1&quot;&gt;Minija Tamosiunaite&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Worgotter_F/0/1/0/all/0/1&quot;&gt;Florentin W&amp;#xf6;rg&amp;#xf6;tter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.12358">
<title>EVBattery: A Large-Scale Electric Vehicle Dataset for Battery Health and Capacity Estimation. (arXiv:2201.12358v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2201.12358</link>
<description rdf:parseType="Literal">&lt;p&gt;Electric vehicles (EVs) play an important role in reducing carbon emissions.
As EV adoption accelerates, safety issues caused by EV batteries have become an
important research topic. In order to benchmark and develop data-driven methods
for this task, we introduce a large and comprehensive dataset of EV batteries.
Our dataset includes charging records collected from hundreds of EVs from three
manufacturers over several years. Our dataset is the first large-scale public
dataset on real-world battery data, as existing data either include only
several vehicles or is collected in the lab environment. Meanwhile, our dataset
features two types of labels, corresponding to two key tasks - battery health
estimation and battery capacity estimation. In addition to demonstrating how
existing deep learning algorithms can be applied to this task, we further
develop an algorithm that exploits the data structure of battery systems. Our
algorithm achieves better results and shows that a customized method can
improve model performances. We hope that this public dataset provides valuable
resources for researchers, policymakers, and industry professionals to better
understand the dynamics of EV battery aging and support the transition toward a
sustainable transportation system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1&quot;&gt;Haowei He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingzhao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1&quot;&gt;Benben Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shaobo Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_G/0/1/0/all/0/1&quot;&gt;Gengang Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1&quot;&gt;Xuebing Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1&quot;&gt;Dongxu Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_G/0/1/0/all/0/1&quot;&gt;Guannan He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_M/0/1/0/all/0/1&quot;&gt;Minggao Ouyang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.14724">
<title>Private Graph Extraction via Feature Explanations. (arXiv:2206.14724v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.14724</link>
<description rdf:parseType="Literal">&lt;p&gt;Privacy and interpretability are two important ingredients for achieving
trustworthy machine learning. We study the interplay of these two aspects in
graph machine learning through graph reconstruction attacks. The goal of the
adversary here is to reconstruct the graph structure of the training data given
access to model explanations. Based on the different kinds of auxiliary
information available to the adversary, we propose several graph reconstruction
attacks. We show that additional knowledge of post-hoc feature explanations
substantially increases the success rate of these attacks. Further, we
investigate in detail the differences between attack performance with respect
to three different classes of explanation methods for graph neural networks:
gradient-based, perturbation-based, and surrogate model-based methods. While
gradient-based explanations reveal the most in terms of the graph structure, we
find that these explanations do not always score high in utility. For the other
two classes of explanations, privacy leakage increases with an increase in
explanation utility. Finally, we propose a defense based on a randomized
response mechanism for releasing the explanations, which substantially reduces
the attack success rate. Our code is available at
https://github.com/iyempissy/graph-stealing-attacks-with-explanation
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olatunji_I/0/1/0/all/0/1&quot;&gt;Iyiola E. Olatunji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rathee_M/0/1/0/all/0/1&quot;&gt;Mandeep Rathee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Funke_T/0/1/0/all/0/1&quot;&gt;Thorben Funke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khosla_M/0/1/0/all/0/1&quot;&gt;Megha Khosla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.08879">
<title>SensorSCAN: Self-Supervised Learning and Deep Clustering for Fault Diagnosis in Chemical Processes. (arXiv:2208.08879v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2208.08879</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern industrial facilities generate large volumes of raw sensor data during
the production process. This data is used to monitor and control the processes
and can be analyzed to detect and predict process abnormalities. Typically, the
data has to be annotated by experts in order to be used in predictive modeling.
However, manual annotation of large amounts of data can be difficult in
industrial settings.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose SensorSCAN, a novel method for unsupervised fault
detection and diagnosis, designed for industrial chemical process monitoring.
We demonstrate our model&apos;s performance on two publicly available datasets of
the Tennessee Eastman Process with various faults. The results show that our
method significantly outperforms existing approaches (+0.2-0.3 TPR for a fixed
FPR) and effectively detects most of the process faults without expert
annotation. Moreover, we show that the model fine-tuned on a small fraction of
labeled data nearly reaches the performance of a SOTA model trained on the full
dataset. We also demonstrate that our method is suitable for real-world
applications where the number of faults is not known in advance. The code is
available at https://github.com/AIRI-Institute/sensorscan.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golyadkin_M/0/1/0/all/0/1&quot;&gt;Maksim Golyadkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pozdnyakov_V/0/1/0/all/0/1&quot;&gt;Vitaliy Pozdnyakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhukov_L/0/1/0/all/0/1&quot;&gt;Leonid Zhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makarov_I/0/1/0/all/0/1&quot;&gt;Ilya Makarov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.06950">
<title>Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v6 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2209.06950</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper outlines an end-to-end optimized lossy image compression framework
using diffusion generative models. The approach relies on the transform coding
paradigm, where an image is mapped into a latent space for entropy coding and,
from there, mapped back to the data space for reconstruction. In contrast to
VAE-based neural compression, where the (mean) decoder is a deterministic
neural network, our decoder is a conditional diffusion model. Our approach thus
introduces an additional &quot;content&quot; latent variable on which the reverse
diffusion process is conditioned and uses this variable to store information
about the image. The remaining &quot;texture&quot; variables characterizing the diffusion
process are synthesized at decoding time. We show that the model&apos;s performance
can be tuned toward perceptual metrics of interest. Our extensive experiments
involving multiple datasets and image quality assessment metrics show that our
approach yields stronger reported FID scores than the GAN-based model, while
also yielding competitive performance with VAE-based models in several
distortion metrics. Furthermore, training the diffusion with X-parameterization
enables high-quality reconstructions in only a handful of decoding steps,
greatly affecting the model&apos;s practicality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Ruihan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mandt_S/0/1/0/all/0/1&quot;&gt;Stephan Mandt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.12835">
<title>Targeted Separation and Convergence with Kernel Discrepancies. (arXiv:2209.12835v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2209.12835</link>
<description rdf:parseType="Literal">&lt;p&gt;Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD)
have grown central to a wide range of applications, including hypothesis
testing, sampler selection, distribution approximation, and variational
inference. In each setting, these kernel-based discrepancy measures are
required to (i) separate a target P from other probability measures or even
(ii) control weak convergence to P. In this article we derive new sufficient
and necessary conditions to ensure (i) and (ii). For MMDs on separable metric
spaces, we characterize those kernels that separate Bochner embeddable measures
and introduce simple conditions for separating all measures with unbounded
kernels and for controlling convergence with bounded kernels. We use these
results on $\mathbb{R}^d$ to substantially broaden the known conditions for KSD
separation and convergence control and to develop the first KSDs known to
exactly metrize weak convergence to P. Along the way, we highlight the
implications of our results for hypothesis testing, measuring and improving
sample quality, and sampling with Stein variational gradient descent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barp_A/0/1/0/all/0/1&quot;&gt;Alessandro Barp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simon_Gabriel_C/0/1/0/all/0/1&quot;&gt;Carl-Johann Simon-Gabriel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1&quot;&gt;Mark Girolami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1&quot;&gt;Lester Mackey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.04366">
<title>KP-RNN: A Deep Learning Pipeline for Human Motion Prediction and Synthesis of Performance Art. (arXiv:2210.04366v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2210.04366</link>
<description rdf:parseType="Literal">&lt;p&gt;Digitally synthesizing human motion is an inherently complex process, which
can create obstacles in application areas such as virtual reality. We offer a
new approach for predicting human motion, KP-RNN, a neural network which can
integrate easily with existing image processing and generation pipelines. We
utilize a new human motion dataset of performance art, Take The Lead, as well
as the motion generation pipeline, the Everybody Dance Now system, to
demonstrate the effectiveness of KP-RNN&apos;s motion predictions. We have found
that our neural network can predict human dance movements effectively, which
serves as a baseline result for future works using the Take The Lead dataset.
Since KP-RNN can work alongside a system such as Everybody Dance Now, we argue
that our approach could inspire new methods for rendering human avatar
animation. This work also serves to benefit the visualization of performance
art in digital platforms by utilizing accessible neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perrine_P/0/1/0/all/0/1&quot;&gt;Patrick Perrine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirkby_T/0/1/0/all/0/1&quot;&gt;Trevor Kirkby&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.13441">
<title>Bridging Machine Learning and Sciences: Opportunities and Challenges. (arXiv:2210.13441v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2210.13441</link>
<description rdf:parseType="Literal">&lt;p&gt;The application of machine learning in sciences has seen exciting advances in
recent years. As a widely applicable technique, anomaly detection has been long
studied in the machine learning community. Especially, deep neural nets-based
out-of-distribution detection has made great progress for high-dimensional
data. Recently, these techniques have been showing their potential in
scientific disciplines. We take a critical look at their applicative prospects
including data universality, experimental protocols, model robustness, etc. We
discuss examples that display transferable practices and domain-specific
challenges simultaneously, providing a starting point for establishing a novel
interdisciplinary research paradigm in the near future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_T/0/1/0/all/0/1&quot;&gt;Taoli Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.09721">
<title>A Finite-Particle Convergence Rate for Stein Variational Gradient Descent. (arXiv:2211.09721v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.09721</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide the first finite-particle convergence rate for Stein variational
gradient descent (SVGD), a popular algorithm for approximating a probability
distribution with a collection of particles. Specifically, whenever the target
distribution is sub-Gaussian with a Lipschitz score, SVGD with n particles and
an appropriate step size sequence drives the kernel Stein discrepancy to zero
at an order 1/sqrt(log log n) rate. We suspect that the dependence on n can be
improved, and we hope that our explicit, non-asymptotic proof strategy will
serve as a template for future refinements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jiaxin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1&quot;&gt;Lester Mackey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.15092">
<title>Hierarchical Proxy Modeling for Improved HPO in Time Series Forecasting. (arXiv:2211.15092v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.15092</link>
<description rdf:parseType="Literal">&lt;p&gt;Selecting the right set of hyperparameters is crucial in time series
forecasting. The classical temporal cross-validation framework for
hyperparameter optimization (HPO) often leads to poor test performance because
of a possible mismatch between validation and test periods. To address this
test-validation mismatch, we propose a novel technique, H-Pro to drive HPO via
test proxies by exploiting data hierarchies often associated with time series
datasets. Since higher-level aggregated time series often show less
irregularity and better predictability as compared to the lowest-level time
series which can be sparse and intermittent, we optimize the hyperparameters of
the lowest-level base-forecaster by leveraging the proxy forecasts for the test
period generated from the forecasters at higher levels. H-Pro can be applied on
any off-the-shelf machine learning model to perform HPO. We validate the
efficacy of our technique with extensive empirical evaluation on five publicly
available hierarchical forecasting datasets. Our approach outperforms existing
state-of-the-art methods in Tourism, Wiki, and Traffic datasets, and achieves
competitive result in Tourism-L dataset, without any model-specific
enhancements. Moreover, our method outperforms the winning method of the M5
forecast accuracy competition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jati_A/0/1/0/all/0/1&quot;&gt;Arindam Jati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ekambaram_V/0/1/0/all/0/1&quot;&gt;Vijay Ekambaram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1&quot;&gt;Shaonli Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quanz_B/0/1/0/all/0/1&quot;&gt;Brian Quanz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gifford_W/0/1/0/all/0/1&quot;&gt;Wesley M. Gifford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harsha_P/0/1/0/all/0/1&quot;&gt;Pavithra Harsha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siegel_S/0/1/0/all/0/1&quot;&gt;Stuart Siegel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1&quot;&gt;Sumanta Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayanaswami_C/0/1/0/all/0/1&quot;&gt;Chandra Narayanaswami&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.15856">
<title>Beyond Ensemble Averages: Leveraging Climate Model Ensembles for Subseasonal Forecasting. (arXiv:2211.15856v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.15856</link>
<description rdf:parseType="Literal">&lt;p&gt;Producing high-quality forecasts of key climate variables such as temperature
and precipitation on subseasonal time scales has long been a gap in operational
forecasting. Recent studies have shown promising results using machine learning
(ML) models to advance subseasonal forecasting (SSF), but several open
questions remain. First, several past approaches use the average of an ensemble
of physics-based forecasts as an input feature of these models. However,
ensemble forecasts contain information that can aid prediction beyond only the
ensemble mean. Second, past methods have focused on average performance,
whereas forecasts of extreme events are far more important for planning and
mitigation purposes. Third, climate forecasts correspond to a spatially-varying
collection of forecasts, and different methods account for spatial variability
in the response differently. Trade-offs between different approaches may be
mitigated with model stacking. This paper describes the application of a
variety of ML methods used to predict monthly average precipitation and two
meter temperature using physics-based predictions (ensemble forecasts) and
observational data such as relative humidity, pressure at sea level, or
geopotential height, two weeks in advance for the whole continental United
States. Regression, quantile regression, and tercile classification tasks using
linear models, random forests, convolutional neural networks, and stacked
models are considered. The proposed models outperform common baselines such as
historical averages (or quantiles) and ensemble averages (or quantiles). This
paper further includes an investigation of feature importance, trade-offs
between using the full ensemble or only the ensemble average, and different
modes of accounting for spatial variability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orlova_E/0/1/0/all/0/1&quot;&gt;Elena Orlova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haokun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossellini_R/0/1/0/all/0/1&quot;&gt;Raphael Rossellini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cash_B/0/1/0/all/0/1&quot;&gt;Benjamin Cash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Willett_R/0/1/0/all/0/1&quot;&gt;Rebecca Willett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.10649">
<title>Inversion of Bayesian Networks. (arXiv:2212.10649v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.10649</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational autoencoders and Helmholtz machines use a recognition network
(encoder) to approximate the posterior distribution of a generative model
(decoder). In this paper we study the necessary and sufficient properties of a
recognition network so that it can model the true posterior distribution
exactly. These results are derived in the general context of probabilistic
graphical modelling / Bayesian networks, for which the network represents a set
of conditional independence statements. We derive both global conditions, in
terms of d-separation, and local conditions for the recognition network to have
the desired qualities. It turns out that for the local conditions the property
perfectness (for every node, all parents are joined) plays an important role.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oostrum_J/0/1/0/all/0/1&quot;&gt;Jesse van Oostrum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hintum_P/0/1/0/all/0/1&quot;&gt;Peter van Hintum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ay_N/0/1/0/all/0/1&quot;&gt;Nihat Ay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.14319">
<title>Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients. (arXiv:2212.14319v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2212.14319</link>
<description rdf:parseType="Literal">&lt;p&gt;Partial differential equations (PDEs) are important tools to model physical
systems and including them into machine learning models is an important way of
incorporating physical knowledge. Given any system of linear PDEs with constant
coefficients, we propose a family of Gaussian process (GP) priors, which we
call EPGP, such that all realizations are exact solutions of this system. We
apply the Ehrenpreis-Palamodov fundamental principle, which works as a
non-linear Fourier transform, to construct GP kernels mirroring standard
spectral methods for GPs. Our approach can infer probable solutions of linear
PDE systems from any data such as noisy measurements, or pointwise defined
initial and boundary conditions. Constructing EPGP-priors is algorithmic,
generally applicable, and comes with a sparse version (S-EPGP) that learns the
relevant spectral frequencies and works better for big data sets. We
demonstrate our approach on three families of systems of PDEs, the heat
equation, wave equation, and Maxwell&apos;s equations, where we improve upon the
state of the art in computation time and precision, in some experiments by
several orders of magnitude.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Harkonen_M/0/1/0/all/0/1&quot;&gt;Marc H&amp;#xe4;rk&amp;#xf6;nen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lange_Hegermann_M/0/1/0/all/0/1&quot;&gt;Markus Lange-Hegermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raita_B/0/1/0/all/0/1&quot;&gt;Bogdan Rai&amp;#x163;&amp;#x103;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.07210">
<title>Causal Falsification of Digital Twins. (arXiv:2301.07210v4 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/2301.07210</link>
<description rdf:parseType="Literal">&lt;p&gt;Digital twins are virtual systems designed to predict how a real-world
process will evolve in response to interventions. This modelling paradigm holds
substantial promise in many applications, but rigorous procedures for assessing
their accuracy are essential for safety-critical settings. We consider how to
assess the accuracy of a digital twin using real-world data. We formulate this
as causal inference problem, which leads to a precise definition of what it
means for a twin to be &quot;correct&quot; appropriate for many applications.
Unfortunately, fundamental results from causal inference mean observational
data cannot be used to certify that a twin is correct in this sense unless
potentially tenuous assumptions are made, such as that the data are
unconfounded. To avoid these assumptions, we propose instead to find situations
in which the twin is not correct, and present a general-purpose statistical
procedure for doing so. Our approach yields reliable and actionable information
about the twin under only the assumption of an i.i.d. dataset of observational
trajectories, and remains sound even if the data are confounded. We apply our
methodology to a large-scale, real-world case study involving sepsis modelling
within the Pulse Physiology Engine, which we assess using the MIMIC-III dataset
of ICU patients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cornish_R/0/1/0/all/0/1&quot;&gt;Rob Cornish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Taufiq_M/0/1/0/all/0/1&quot;&gt;Muhammad Faaiz Taufiq&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1&quot;&gt;Arnaud Doucet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1&quot;&gt;Chris Holmes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.12874">
<title>Extremal Domain Translation with Neural Optimal Transport. (arXiv:2301.12874v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.12874</link>
<description rdf:parseType="Literal">&lt;p&gt;In many unpaired image domain translation problems, e.g., style transfer or
super-resolution, it is important to keep the translated image similar to its
respective input image. We propose the extremal transport (ET) which is a
mathematical formalization of the theoretically best possible unpaired
translation between a pair of domains w.r.t. the given similarity function.
Inspired by the recent advances in neural optimal transport (OT), we propose a
scalable algorithm to approximate ET maps as a limit of partial OT maps. We
test our algorithm on toy examples and on the unpaired image-to-image
translation task. The code is publicly available at
https://github.com/milenagazdieva/ExtremalNeuralOptimalTransport
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gazdieva_M/0/1/0/all/0/1&quot;&gt;Milena Gazdieva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1&quot;&gt;Alexander Korotin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Selikhanovych_D/0/1/0/all/0/1&quot;&gt;Daniil Selikhanovych&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1&quot;&gt;Evgeny Burnaev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.04040">
<title>Sample-efficient Multi-objective Molecular Optimization with GFlowNets. (arXiv:2302.04040v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.04040</link>
<description rdf:parseType="Literal">&lt;p&gt;Many crucial scientific problems involve designing novel molecules with
desired properties, which can be formulated as a black-box optimization problem
over the discrete chemical space. In practice, multiple conflicting objectives
and costly evaluations (e.g., wet-lab experiments) make the diversity of
candidates paramount. Computational methods have achieved initial success but
still struggle with considering diversity in both objective and search space.
To fill this gap, we propose a multi-objective Bayesian optimization (MOBO)
algorithm leveraging the hypernetwork-based GFlowNets (HN-GFN) as an
acquisition function optimizer, with the purpose of sampling a diverse batch of
candidate molecular graphs from an approximate Pareto front. Using a single
preference-conditioned hypernetwork, HN-GFN learns to explore various
trade-offs between objectives. We further propose a hindsight-like off-policy
strategy to share high-performing molecules among different preferences in
order to speed up learning for HN-GFN. We empirically illustrate that HN-GFN
has adequate capacity to generalize over preferences. Moreover, experiments in
various real-world MOBO settings demonstrate that our framework predominantly
outperforms existing methods in terms of candidate quality and sample
efficiency. The code is available at https://github.com/violet-sto/HN-GFN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yiheng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jialu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1&quot;&gt;Chaowen Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Jiahuan Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Chang-Yu Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_T/0/1/0/all/0/1&quot;&gt;Tingjun Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jian Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.04391">
<title>The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.04391</link>
<description rdf:parseType="Literal">&lt;p&gt;In industry deep learning application, our manually labeled data has a
certain number of noisy data. To solve this problem and achieve more than 90
score in dev dataset, we present a simple method to find the noisy data and
re-label the noisy data by human, given the model predictions as references in
human labeling. In this paper, we illustrate our idea for a broad set of deep
learning tasks, includes classification, sequence tagging, object detection,
sequence generation, click-through rate prediction. The dev dataset evaluation
results and human evaluation results verify our idea.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1&quot;&gt;Tong Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.10180">
<title>Towards Safe Propofol Dosing during General Anesthesia Using Deep Offline Reinforcement Learning. (arXiv:2303.10180v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.10180</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated anesthesia promises to enable more precise and personalized
anesthetic administration and free anesthesiologists from repetitive tasks,
allowing them to focus on the most critical aspects of a patient&apos;s surgical
care. Current research has typically focused on creating simulated environments
from which agents can learn. These approaches have demonstrated good
experimental results, but are still far from clinical application. In this
paper, Policy Constraint Q-Learning (PCQL), a data-driven reinforcement
learning algorithm for solving the problem of learning anesthesia strategies on
real clinical datasets, is proposed. Conservative Q-Learning was first
introduced to alleviate the problem of Q function overestimation in an offline
context. A policy constraint term is added to agent training to keep the policy
distribution of the agent and the anesthesiologist consistent to ensure safer
decisions made by the agent in anesthesia scenarios. The effectiveness of PCQL
was validated by extensive experiments on a real clinical anesthesia dataset.
Experimental results show that PCQL is predicted to achieve higher gains than
the baseline approach while maintaining good agreement with the reference dose
given by the anesthesiologist, using less total dose, and being more responsive
to the patient&apos;s vital signs. In addition, the confidence intervals of the
agent were investigated, which were able to cover most of the clinical
decisions of the anesthesiologist. Finally, an interpretable method, SHAP, was
used to analyze the contributing components of the model predictions to
increase the transparency of the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1&quot;&gt;Xiuding Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yaoyao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Beimin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yu Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.10725">
<title>SIESTA: Efficient Online Continual Learning with Sleep. (arXiv:2303.10725v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.10725</link>
<description rdf:parseType="Literal">&lt;p&gt;In supervised continual learning, a deep neural network (DNN) is updated with
an ever-growing data stream. Unlike the offline setting where data is shuffled,
we cannot make any distributional assumptions about the data stream. Ideally,
only one pass through the dataset is needed for computational efficiency.
However, existing methods are inadequate and make many assumptions that cannot
be made for real-world applications, while simultaneously failing to improve
computational efficiency. In this paper, we propose a novel continual learning
method, SIESTA based on wake/sleep framework for training, which is well
aligned to the needs of on-device learning. The major goal of SIESTA is to
advance compute efficient continual learning so that DNNs can be updated
efficiently using far less time and energy. The principal innovations of SIESTA
are: 1) rapid online updates using a rehearsal-free, backpropagation-free, and
data-driven network update rule during its wake phase, and 2) expedited memory
consolidation using a compute-restricted rehearsal policy during its sleep
phase. For memory efficiency, SIESTA adapts latent rehearsal using memory
indexing from REMIND. Compared to REMIND and prior arts, SIESTA is far more
computationally efficient, enabling continual learning on ImageNet-1K in under
2 hours on a single GPU; moreover, in the augmentation-free setting it matches
the performance of the offline learner, a milestone critical to driving
adoption of continual learning in real-world applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harun_M/0/1/0/all/0/1&quot;&gt;Md Yousuf Harun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallardo_J/0/1/0/all/0/1&quot;&gt;Jhair Gallardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayes_T/0/1/0/all/0/1&quot;&gt;Tyler L. Hayes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kemker_R/0/1/0/all/0/1&quot;&gt;Ronald Kemker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanan_C/0/1/0/all/0/1&quot;&gt;Christopher Kanan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.12783">
<title>Conformal Prediction for Time Series with Modern Hopfield Networks. (arXiv:2303.12783v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.12783</link>
<description rdf:parseType="Literal">&lt;p&gt;To quantify uncertainty, conformal prediction methods are gaining
continuously more interest and have already been successfully applied to
various domains. However, they are difficult to apply to time series as the
autocorrelative structure of time series violates basic assumptions required by
conformal prediction. We propose HopCPT, a novel conformal prediction approach
for time series that not only copes with temporal structures but leverages
them. We show that our approach is theoretically well justified for time series
where temporal dependencies are present. In experiments, we demonstrate that
our new approach outperforms state-of-the-art conformal prediction methods on
multiple real-world time series datasets from four different domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Auer_A/0/1/0/all/0/1&quot;&gt;Andreas Auer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gauch_M/0/1/0/all/0/1&quot;&gt;Martin Gauch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klotz_D/0/1/0/all/0/1&quot;&gt;Daniel Klotz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1&quot;&gt;Sepp Hochreiter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.17760">
<title>CAMEL: Communicative Agents for &quot;Mind&quot; Exploration of Large Language Model Society. (arXiv:2303.17760v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2303.17760</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid advancement of chat-based language models has led to remarkable
progress in complex task-solving. However, their success heavily relies on
human input to guide the conversation, which can be challenging and
time-consuming. This paper explores the potential of building scalable
techniques to facilitate autonomous cooperation among communicative agents, and
provides insight into their &quot;cognitive&quot; processes. To address the challenges of
achieving autonomous cooperation, we propose a novel communicative agent
framework named role-playing. Our approach involves using inception prompting
to guide chat agents toward task completion while maintaining consistency with
human intentions. We showcase how role-playing can be used to generate
conversational data for studying the behaviors and capabilities of a society of
agents, providing a valuable resource for investigating conversational language
models. In particular, we conduct comprehensive studies on
instruction-following cooperation in multi-agent settings. Our contributions
include introducing a novel communicative agent framework, offering a scalable
approach for studying the cooperative behaviors and capabilities of multi-agent
systems, and open-sourcing our library to support research on communicative
agents and beyond: https://github.com/camel-ai/camel.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guohao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hammoud_H/0/1/0/all/0/1&quot;&gt;Hasan Abed Al Kader Hammoud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Itani_H/0/1/0/all/0/1&quot;&gt;Hani Itani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khizbullin_D/0/1/0/all/0/1&quot;&gt;Dmitrii Khizbullin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1&quot;&gt;Bernard Ghanem&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.10832">
<title>A Deep Learning algorithm to accelerate Algebraic Multigrid methods in Finite Element solvers of 3D elliptic PDEs. (arXiv:2304.10832v3 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/2304.10832</link>
<description rdf:parseType="Literal">&lt;p&gt;Algebraic multigrid (AMG) methods are among the most efficient solvers for
linear systems of equations and they are widely used for the solution of
problems stemming from the discretization of Partial Differential Equations
(PDEs). The most severe limitation of AMG methods is the dependence on
parameters that require to be fine-tuned. In particular, the strong threshold
parameter is the most relevant since it stands at the basis of the construction
of successively coarser grids needed by the AMG methods. We introduce a novel
Deep Learning algorithm that minimizes the computational cost of the AMG method
when used as a finite element solver. We show that our algorithm requires
minimal changes to any existing code. The proposed Artificial Neural Network
(ANN) tunes the value of the strong threshold parameter by interpreting the
sparse matrix of the linear system as a black-and-white image and exploiting a
pooling operator to transform it into a small multi-channel image. We
experimentally prove that the pooling successfully reduces the computational
cost of processing a large sparse matrix and preserves the features needed for
the regression task at hand. We train the proposed algorithm on a large dataset
containing problems with a highly heterogeneous diffusion coefficient defined
in different three-dimensional geometries and discretized with unstructured
grids and linear elasticity problems with a highly heterogeneous Young&apos;s
modulus. When tested on problems with coefficients or geometries not present in
the training dataset, our approach reduces the computational time by up to 30%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Caldana_M/0/1/0/all/0/1&quot;&gt;Matteo Caldana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Antonietti_P/0/1/0/all/0/1&quot;&gt;Paola F. Antonietti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dede_L/0/1/0/all/0/1&quot;&gt;Luca Dede&amp;#x27;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.13410">
<title>Improving Adversarial Transferability via Intermediate-level Perturbation Decay. (arXiv:2304.13410v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.13410</link>
<description rdf:parseType="Literal">&lt;p&gt;Intermediate-level attacks that attempt to perturb feature representations
following an adversarial direction drastically have shown favorable performance
in crafting transferable adversarial examples. Existing methods in this
category are normally formulated with two separate stages, where a directional
guide is required to be determined at first and the scalar projection of the
intermediate-level perturbation onto the directional guide is enlarged
thereafter. The obtained perturbation deviates from the guide inevitably in the
feature space, and it is revealed in this paper that such a deviation may lead
to sub-optimal attack. To address this issue, we develop a novel
intermediate-level method that crafts adversarial examples within a single
stage of optimization. In particular, the proposed method, named
intermediate-level perturbation decay (ILPD), encourages the intermediate-level
perturbation to be in an effective adversarial direction and to possess a great
magnitude simultaneously. In-depth discussion verifies the effectiveness of our
method. Experimental results show that it outperforms state-of-the-arts by
large margins in attacking various victim models on ImageNet (+10.07% on
average) and CIFAR-10 (+3.88% on average). Our code is at
https://github.com/qizhangli/ILPD-attack.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qizhang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yiwen Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1&quot;&gt;Wangmeng Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.14274">
<title>When Do Graph Neural Networks Help with Node Classification? Investigating the Impact of Homophily Principle on Node Distinguishability. (arXiv:2304.14274v3 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2304.14274</link>
<description rdf:parseType="Literal">&lt;p&gt;Homophily principle, i.e., nodes with the same labels are more likely to be
connected, has been believed to be the main reason for the performance
superiority of Graph Neural Networks (GNNs) over Neural Networks on node
classification tasks. Recent research suggests that, even in the absence of
homophily, the advantage of GNNs still exists as long as nodes from the same
class share similar neighborhood patterns. However, this argument only
considers intra-class Node Distinguishability (ND) but neglects inter-class ND,
which provides incomplete understanding of homophily on GNNs. In this paper, we
first demonstrate such deficiency with examples and argue that an ideal
situation for ND is to have smaller intra-class ND than inter-class ND. To
formulate this idea and study ND deeply, we propose Contextual Stochastic Block
Model for Homophily (CSBM-H) and define two metrics, Probabilistic Bayes Error
(PBE) and negative generalized Jeffreys divergence, to quantify ND. With the
metrics, we visualize and analyze how graph filters, node degree distributions
and class variances influence ND, and investigate the combined effect of intra-
and inter-class ND. Besides, we discovered the mid-homophily pitfall, which
occurs widely in graph datasets. Furthermore, we verified that, in real-work
tasks, the superiority of GNNs is indeed closely related to both intra- and
inter-class ND regardless of homophily levels. Grounded in this observation, we
propose a new hypothesis-testing based performance metric beyond homophily,
which is non-linear, feature-based and can provide statistical threshold value
for GNNs&apos; the superiority. Experiments indicate that it is significantly more
effective than the existing homophily metrics on revealing the advantage and
disadvantage of graph-aware modes on both synthetic and benchmark real-world
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luan_S/0/1/0/all/0/1&quot;&gt;Sitao Luan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_C/0/1/0/all/0/1&quot;&gt;Chenqing Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Minkai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1&quot;&gt;Qincheng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jiaqi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1&quot;&gt;Xiao-Wen Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jie Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1&quot;&gt;Doina Precup&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.00586">
<title>How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v5 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.00586</link>
<description rdf:parseType="Literal">&lt;p&gt;Pre-trained language models can be surprisingly adept at tasks they were not
explicitly trained on, but how they implement these capabilities is poorly
understood. In this paper, we investigate the basic mathematical abilities
often acquired by pre-trained language models. Concretely, we use mechanistic
interpretability techniques to explain the (limited) mathematical abilities of
GPT-2 small. As a case study, we examine its ability to take in sentences such
as &quot;The war lasted from the year 1732 to the year 17&quot;, and predict valid
two-digit end years (years &amp;gt; 32). We first identify a circuit, a small subset
of GPT-2 small&apos;s computational graph that computes this task&apos;s output. Then, we
explain the role of each circuit component, showing that GPT-2 small&apos;s final
multi-layer perceptrons boost the probability of end years greater than the
start year. Finally, we find related tasks that activate our circuit. Our
results suggest that GPT-2 small computes greater-than using a complex but
general mechanism that activates across diverse contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanna_M/0/1/0/all/0/1&quot;&gt;Michael Hanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1&quot;&gt;Ollie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Variengien_A/0/1/0/all/0/1&quot;&gt;Alexandre Variengien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.01638">
<title>Sequence Modeling with Multiresolution Convolutional Memory. (arXiv:2305.01638v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.01638</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficiently capturing the long-range patterns in sequential data sources
salient to a given task -- such as classification and generative modeling --
poses a fundamental challenge. Popular approaches in the space tradeoff between
the memory burden of brute-force enumeration and comparison, as in
transformers, the computational burden of complicated sequential dependencies,
as in recurrent neural networks, or the parameter burden of convolutional
networks with many or large filters. We instead take inspiration from
wavelet-based multiresolution analysis to define a new building block for
sequence modeling, which we call a MultiresLayer. The key component of our
model is the multiresolution convolution, capturing multiscale trends in the
input sequence. Our MultiresConv can be implemented with shared filters across
a dilated causal convolution tree. Thus it garners the computational advantages
of convolutional networks and the principled theoretical motivation of wavelet
decompositions. Our MultiresLayer is straightforward to implement, requires
significantly fewer parameters, and maintains at most a $\mathcal{O}(N\log N)$
memory footprint for a length $N$ sequence. Yet, by stacking such layers, our
model yields state-of-the-art performance on a number of sequence
classification and autoregressive density estimation tasks using CIFAR-10,
ListOps, and PTB-XL datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jiaxin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Ke Alexander Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fox_E/0/1/0/all/0/1&quot;&gt;Emily B. Fox&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.02305">
<title>Calibrated Explanations: with Uncertainty Information and Counterfactuals. (arXiv:2305.02305v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2305.02305</link>
<description rdf:parseType="Literal">&lt;p&gt;While local explanations for AI models can offer insights into individual
predictions, such as feature importance, they are plagued by issues like
instability. The unreliability of feature weights, often skewed due to poorly
calibrated ML models, deepens these challenges. Moreover, the critical aspect
of feature importance uncertainty remains mostly unaddressed in Explainable AI
(XAI). The novel feature importance explanation method presented in this paper,
called Calibrated Explanations (CE), is designed to tackle these issues
head-on. Built on the foundation of Venn-Abers, CE not only calibrates the
underlying model but also delivers reliable feature importance explanations
with an exact definition of the feature weights. CE goes beyond conventional
solutions by addressing output uncertainty. It accomplishes this by providing
uncertainty quantification for both feature weights and the model&apos;s probability
estimates. Additionally, CE is model-agnostic, featuring easily comprehensible
conditional rules and the ability to generate counterfactual explanations with
embedded uncertainty quantification. Results from an evaluation with 25
benchmark datasets underscore the efficacy of CE, making it stand as a fast,
reliable, stable, and robust solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lofstrom_H/0/1/0/all/0/1&quot;&gt;Helena Lofstrom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lofstrom_T/0/1/0/all/0/1&quot;&gt;Tuwe Lofstrom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johansson_U/0/1/0/all/0/1&quot;&gt;Ulf Johansson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonstrod_C/0/1/0/all/0/1&quot;&gt;Cecilia Sonstrod&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.07828">
<title>Description and Discussion on DCASE 2023 Challenge Task 2: First-Shot Unsupervised Anomalous Sound Detection for Machine Condition Monitoring. (arXiv:2305.07828v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2305.07828</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the task description of the Detection and Classification of
Acoustic Scenes and Events (DCASE) 2023 Challenge Task 2: ``First-shot
unsupervised anomalous sound detection (ASD) for machine condition
monitoring&apos;&apos;. The main goal is to enable rapid deployment of ASD systems for
new kinds of machines without the need for hyperparameter tuning. In the past
ASD tasks, developed methods tuned hyperparameters for each machine type, as
the development and evaluation datasets had the same machine types. However,
collecting normal and anomalous data as the development dataset can be
infeasible in practice. In 2023 Task 2, we focus on solving the first-shot
problem, which is the challenge of training a model on a completely novel
machine type. Specifically, (i) each machine type has only one section (a
subset of machine type) and (ii) machine types in the development and
evaluation datasets are completely different. Analysis of 86 submissions from
23 teams revealed that the keys to outperform baselines were: 1) sampling
techniques for dealing with class imbalances across different domains and
attributes, 2) generation of synthetic samples for robust detection, and 3) use
of multiple large pre-trained models to extract meaningful embeddings for the
anomaly detector.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dohi_K/0/1/0/all/0/1&quot;&gt;Kota Dohi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Imoto_K/0/1/0/all/0/1&quot;&gt;Keisuke Imoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harada_N/0/1/0/all/0/1&quot;&gt;Noboru Harada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niizumi_D/0/1/0/all/0/1&quot;&gt;Daisuke Niizumi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koizumi_Y/0/1/0/all/0/1&quot;&gt;Yuma Koizumi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nishida_T/0/1/0/all/0/1&quot;&gt;Tomoya Nishida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purohit_H/0/1/0/all/0/1&quot;&gt;Harsh Purohit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanabe_R/0/1/0/all/0/1&quot;&gt;Ryo Tanabe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Endo_T/0/1/0/all/0/1&quot;&gt;Takashi Endo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawaguchi_Y/0/1/0/all/0/1&quot;&gt;Yohei Kawaguchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.09253">
<title>Online Continual Learning Without the Storage Constraint. (arXiv:2305.09253v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.09253</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional online continual learning (OCL) research has primarily focused on
mitigating catastrophic forgetting with fixed and limited storage allocation
throughout an agent&apos;s lifetime. However, a broad range of real-world
applications are primarily constrained by computational costs rather than
storage limitations. In this paper, we target such applications, investigating
the online continual learning problem under relaxed storage constraints and
limited computational budgets. We contribute a simple algorithm, which updates
a kNN classifier continually along with a fixed, pretrained feature extractor.
We selected this algorithm due to its exceptional suitability for online
continual learning. It can adapt to rapidly changing streams, has zero
stability gap, operates within tiny computational budgets, has low storage
requirements by only storing features, and has a consistency property: It never
forgets previously seen data. These attributes yield significant improvements,
allowing our proposed algorithm to outperform existing methods by over 20% in
accuracy on two large-scale OCL datasets: Continual LOCalization (CLOC) with
39M images and 712 classes and Continual Google Landmarks V2 (CGLM) with 580K
images and 10,788 classes, even when existing methods retain all previously
seen images. Furthermore, we achieve this superior performance with
considerably reduced computational and storage expenses. We provide code to
reproduce our results at github.com/drimpossible/ACM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prabhu_A/0/1/0/all/0/1&quot;&gt;Ameya Prabhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dokania_P/0/1/0/all/0/1&quot;&gt;Puneet Dokania&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip Torr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koltun_V/0/1/0/all/0/1&quot;&gt;Vladlen Koltun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sener_O/0/1/0/all/0/1&quot;&gt;Ozan Sener&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13009">
<title>Textually Pretrained Speech Language Models. (arXiv:2305.13009v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13009</link>
<description rdf:parseType="Literal">&lt;p&gt;Speech language models (SpeechLMs) process and generate acoustic data only,
without textual supervision. In this work, we propose TWIST, a method for
training SpeechLMs using a warm-start from a pretrained textual language
models. We show using both automatic and human evaluations that TWIST
outperforms a cold-start SpeechLM across the board. We empirically analyze the
effect of different model design choices such as the speech tokenizer, the
pretrained textual model, and the dataset size. We find that model and dataset
scale both play an important role in constructing better-performing SpeechLMs.
Based on our observations, we present the largest (to the best of our
knowledge) SpeechLM both in terms of number of parameters and training data. We
additionally introduce two spoken versions of the StoryCloze textual benchmark
to further improve model evaluation and advance future research in the field.
We make speech samples, code and models publicly available:
https://pages.cs.huji.ac.il/adiyoss-lab/twist/ .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassid_M/0/1/0/all/0/1&quot;&gt;Michael Hassid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1&quot;&gt;Tal Remez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Tu Anh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1&quot;&gt;Itai Gat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conneau_A/0/1/0/all/0/1&quot;&gt;Alexis Conneau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreuk_F/0/1/0/all/0/1&quot;&gt;Felix Kreuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Copet_J/0/1/0/all/0/1&quot;&gt;Jade Copet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Defossez_A/0/1/0/all/0/1&quot;&gt;Alexandre Defossez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1&quot;&gt;Gabriel Synnaeve&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1&quot;&gt;Emmanuel Dupoux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_R/0/1/0/all/0/1&quot;&gt;Roy Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1&quot;&gt;Yossi Adi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14690">
<title>Generalizing Importance Weighting to A Universal Solver for Distribution Shift Problems. (arXiv:2305.14690v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14690</link>
<description rdf:parseType="Literal">&lt;p&gt;Distribution shift (DS) may have two levels: the distribution itself changes,
and the support (i.e., the set where the probability density is non-zero) also
changes. When considering the support change between the training and test
distributions, there can be four cases: (i) they exactly match; (ii) the
training support is wider (and thus covers the test support); (iii) the test
support is wider; (iv) they partially overlap. Existing methods are good at
cases (i) and (ii), while cases (iii) and (iv) are more common nowadays but
still under-explored. In this paper, we generalize importance weighting (IW), a
golden solver for cases (i) and (ii), to a universal solver for all cases.
Specifically, we first investigate why IW might fail in cases (iii) and (iv);
based on the findings, we propose generalized IW (GIW) that could handle cases
(iii) and (iv) and would reduce to IW in cases (i) and (ii). In GIW, the test
support is split into an in-training (IT) part and an out-of-training (OOT)
part, and the expected risk is decomposed into a weighted classification term
over the IT part and a standard classification term over the OOT part, which
guarantees the risk consistency of GIW. Then, the implementation of GIW
consists of three components: (a) the split of validation data is carried out
by the one-class support vector machine, (b) the first term of the empirical
risk can be handled by any IW algorithm given training data and IT validation
data, and (c) the second term just involves OOT validation data. Experiments
demonstrate that GIW is a universal solver for DS problems, outperforming IW
methods in cases (iii) and (iv).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1&quot;&gt;Tongtong Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1&quot;&gt;Nan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1&quot;&gt;Gang Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15208">
<title>Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation. (arXiv:2305.15208v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15208</link>
<description rdf:parseType="Literal">&lt;p&gt;Simulation-based inference (SBI) enables amortized Bayesian inference for
simulators with implicit likelihoods. But when we are primarily interested in
the quality of predictive simulations, or when the model cannot exactly
reproduce the observed data (i.e., is misspecified), targeting the Bayesian
posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims
to robustify inference for (misspecified) simulator models, replacing the
likelihood-function with a cost function that evaluates the goodness of
parameters relative to data. However, GBI methods generally require running
multiple simulations to estimate the cost function at each parameter value
during inference, making the approach computationally infeasible for even
moderately complex simulators. Here, we propose amortized cost estimation (ACE)
for GBI to address this challenge: We train a neural network to approximate the
cost function, which we define as the expected distance between simulations
produced by a parameter and observed data. The trained network can then be used
with MCMC to infer GBI posteriors for any observation without running
additional simulations. We show that, on several benchmark tasks, ACE
accurately predicts cost and provides predictive simulations that are closer to
synthetic observations than other SBI methods, especially for misspecified
simulators. Finally, we apply ACE to infer parameters of the Hodgkin-Huxley
model given real intracellular recordings from the Allen Cell Types Database.
ACE identifies better data-matching parameters while being an order of
magnitude more simulation-efficient than a standard SBI method. In summary, ACE
combines the strengths of SBI methods and GBI to perform robust and
simulation-amortized inference for scientific simulators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_R/0/1/0/all/0/1&quot;&gt;Richard Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deistler_M/0/1/0/all/0/1&quot;&gt;Michael Deistler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Macke_J/0/1/0/all/0/1&quot;&gt;Jakob H. Macke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15572">
<title>The Behavior and Convergence of Local Bayesian Optimization. (arXiv:2305.15572v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15572</link>
<description rdf:parseType="Literal">&lt;p&gt;A recent development in Bayesian optimization is the use of local
optimization strategies, which can deliver strong empirical performance on
high-dimensional problems compared to traditional global strategies. The &quot;folk
wisdom&quot; in the literature is that the focus on local optimization sidesteps the
curse of dimensionality; however, little is known concretely about the expected
behavior or convergence of Bayesian local optimization routines. We first study
the behavior of the local approach, and find that the statistics of individual
local solutions of Gaussian process sample paths are surprisingly good compared
to what we would expect to recover from global methods. We then present the
first rigorous analysis of such a Bayesian local optimization algorithm
recently proposed by M\&quot;uller et al. (2021), and derive convergence rates in
both the noisy and noiseless settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1&quot;&gt;Kaiwen Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kyurae Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1&quot;&gt;Roman Garnett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1&quot;&gt;Jacob R. Gardner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.17020">
<title>Diable: Efficient Dialogue State Tracking as Operations on Tables. (arXiv:2305.17020v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.17020</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequence-to-sequence state-of-the-art systems for dialogue state tracking
(DST) use the full dialogue history as input, represent the current state as a
list with all the slots, and generate the entire state from scratch at each
dialogue turn. This approach is inefficient, especially when the number of
slots is large and the conversation is long. We propose Diable, a new task
formalisation that simplifies the design and implementation of efficient DST
systems and allows one to easily plug and play large language models. We
represent the dialogue state as a table and formalise DST as a table
manipulation task. At each turn, the system updates the previous state by
generating table operations based on the dialogue context. Extensive
experimentation on the MultiWoz datasets demonstrates that Diable (i)
outperforms strong efficient DST baselines, (ii) is 2.4x more time efficient
than current state-of-the-art methods while retaining competitive Joint Goal
Accuracy, and (iii) is robust to noisy data annotations due to the table
operations approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lesci_P/0/1/0/all/0/1&quot;&gt;Pietro Lesci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujinuma_Y/0/1/0/all/0/1&quot;&gt;Yoshinari Fujinuma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hardalov_M/0/1/0/all/0/1&quot;&gt;Momchil Hardalov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_C/0/1/0/all/0/1&quot;&gt;Chao Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benajiba_Y/0/1/0/all/0/1&quot;&gt;Yassine Benajiba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marquez_L/0/1/0/all/0/1&quot;&gt;Lluis Marquez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18333">
<title>Ranking with Popularity Bias: User Welfare under Self-Amplification Dynamics. (arXiv:2305.18333v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18333</link>
<description rdf:parseType="Literal">&lt;p&gt;While popularity bias is recognized to play a crucial role in recommmender
(and other ranking-based) systems, detailed analysis of its impact on
collective user welfare has largely been lacking. We propose and theoretically
analyze a general mechanism, rooted in many of the models proposed in the
literature, by which item popularity, item quality, and position bias jointly
impact user choice. We focus on a standard setting in which user utility is
largely driven by item quality, and a recommender attempts to estimate it given
user behavior. Formulating the problem as a non-stationary contextual bandit,
we study the ability of a recommender policy to maximize user welfare under
this model. We highlight the importance of exploration, not to eliminate
popularity bias, but to mitigate its negative impact on welfare. We first show
that naive popularity-biased recommenders induce linear regret by conflating
item quality and popularity. More generally, we show that, even in linear
settings, identifiability of item quality may not be possible due to the
confounding effects of popularity bias. However, under sufficient variability
assumptions, we develop an efficient optimistic algorithm and prove efficient
regret guarantees w.r.t. user welfare. We complement our analysis with several
simulation studies, which demonstrate the negative impact of popularity bias on
the performance of several natural recommender policies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tennenholtz_G/0/1/0/all/0/1&quot;&gt;Guy Tennenholtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mladenov_M/0/1/0/all/0/1&quot;&gt;Martin Mladenov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merlis_N/0/1/0/all/0/1&quot;&gt;Nadav Merlis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Axtell_R/0/1/0/all/0/1&quot;&gt;Robert L. Axtell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1&quot;&gt;Craig Boutilier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18497">
<title>Collaborative Learning via Prediction Consensus. (arXiv:2305.18497v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18497</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a collaborative learning setting where the goal of each agent is
to improve their own model by leveraging the expertise of collaborators, in
addition to their own training data. To facilitate the exchange of expertise
among agents, we propose a distillation-based method leveraging shared
unlabeled auxiliary data, which is pseudo-labeled by the collective. Central to
our method is a trust weighting scheme that serves to adaptively weigh the
influence of each collaborator on the pseudo-labels until a consensus on how to
label the auxiliary data is reached. We demonstrate empirically that our
collaboration scheme is able to significantly boost individual models&apos;
performance in the target domain from which the auxiliary data is sampled. At
the same time, it can provably mitigate the negative impact of bad models on
the collective. By design, our method adeptly accommodates heterogeneity in
model architectures and substantially reduces communication overhead compared
to typical collaborative learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1&quot;&gt;Dongyang Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendler_Dunner_C/0/1/0/all/0/1&quot;&gt;Celestine Mendler-D&amp;#xfc;nner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1&quot;&gt;Martin Jaggi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18666">
<title>BiSLS/SPS: Auto-tune Step Sizes for Stable Bi-level Optimization. (arXiv:2305.18666v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18666</link>
<description rdf:parseType="Literal">&lt;p&gt;The popularity of bi-level optimization (BO) in deep learning has spurred a
growing interest in studying gradient-based BO algorithms. However, existing
algorithms involve two coupled learning rates that can be affected by
approximation errors when computing hypergradients, making careful fine-tuning
necessary to ensure fast convergence. To alleviate this issue, we investigate
the use of recently proposed adaptive step-size methods, namely stochastic line
search (SLS) and stochastic Polyak step size (SPS), for computing both the
upper and lower-level learning rates. First, we revisit the use of SLS and SPS
in single-level optimization without the additional interpolation condition
that is typically assumed in prior works. For such settings, we investigate new
variants of SLS and SPS that improve upon existing suggestions in the
literature and are simpler to implement. Importantly, these two variants can be
seen as special instances of general family of methods with an envelope-type
step-size. This unified envelope strategy allows for the extension of the
algorithms and their convergence guarantees to BO settings. Finally, our
extensive experiments demonstrate that the new algorithms, which are available
in both SGD and Adam versions, can find large learning rates with minimal
tuning and converge faster than corresponding vanilla SGD or Adam BO algorithms
that require fine-tuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1&quot;&gt;Chen Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chone_Ducasse_G/0/1/0/all/0/1&quot;&gt;Gaspard Chon&amp;#xe9;-Ducasse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1&quot;&gt;Mark Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1&quot;&gt;Christos Thrampoulidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19913">
<title>Representation Equivalent Neural Operators: a Framework for Alias-free Operator Learning. (arXiv:2305.19913v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19913</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, operator learning, or learning mappings between
infinite-dimensional function spaces, has garnered significant attention,
notably in relation to learning partial differential equations from data.
Conceptually clear when outlined on paper, neural operators necessitate
discretization in the transition to computer implementations. This step can
compromise their integrity, often causing them to deviate from the underlying
operators. This research offers a fresh take on neural operators with a
framework Representation equivalent Neural Operators (ReNO) designed to address
these issues. At its core is the concept of operator aliasing, which measures
inconsistency between neural operators and their discrete representations. We
explore this for widely-used operator learning techniques. Our findings detail
how aliasing introduces errors when handling different discretizations and
grids and loss of crucial continuous structures. More generally, this framework
not only sheds light on existing challenges but, given its constructive and
broad nature, also potentially offers tools for developing new neural
operators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartolucci_F/0/1/0/all/0/1&quot;&gt;Francesca Bartolucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1&quot;&gt;Emmanuel de B&amp;#xe9;zenac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raonic_B/0/1/0/all/0/1&quot;&gt;Bogdan Raoni&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molinaro_R/0/1/0/all/0/1&quot;&gt;Roberto Molinaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1&quot;&gt;Siddhartha Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alaifari_R/0/1/0/all/0/1&quot;&gt;Rima Alaifari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.03698">
<title>Fine-grained Expressivity of Graph Neural Networks. (arXiv:2306.03698v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.03698</link>
<description rdf:parseType="Literal">&lt;p&gt;Numerous recent works have analyzed the expressive power of message-passing
graph neural networks (MPNNs), primarily utilizing combinatorial techniques
such as the $1$-dimensional Weisfeiler-Leman test ($1$-WL) for the graph
isomorphism problem. However, the graph isomorphism objective is inherently
binary, not giving insights into the degree of similarity between two given
graphs. This work resolves this issue by considering continuous extensions of
both $1$-WL and MPNNs to graphons. Concretely, we show that the continuous
variant of $1$-WL delivers an accurate topological characterization of the
expressive power of MPNNs on graphons, revealing which graphs these networks
can distinguish and the level of difficulty in separating them. We identify the
finest topology where MPNNs separate points and prove a universal approximation
theorem. Consequently, we provide a theoretical framework for graph and graphon
similarity combining various topological variants of classical
characterizations of the $1$-WL. In particular, we characterize the expressive
power of MPNNs in terms of the tree distance, which is a graph distance based
on the concept of fractional isomorphisms, and substructure counts via tree
homomorphisms, showing that these concepts have the same expressive power as
the $1$-WL and MPNNs on graphons. Empirically, we validate our theoretical
findings by showing that randomly initialized MPNNs, without training, exhibit
competitive performance compared to their trained counterparts. Moreover, we
evaluate different MPNN architectures based on their ability to preserve graph
distances, highlighting the significance of our continuous $1$-WL test in
understanding MPNNs&apos; expressivity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boker_J/0/1/0/all/0/1&quot;&gt;Jan B&amp;#xf6;ker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levie_R/0/1/0/all/0/1&quot;&gt;Ron Levie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_N/0/1/0/all/0/1&quot;&gt;Ningyuan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villar_S/0/1/0/all/0/1&quot;&gt;Soledad Villar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morris_C/0/1/0/all/0/1&quot;&gt;Christopher Morris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.05225">
<title>Boosting Adversarial Transferability by Achieving Flat Local Maxima. (arXiv:2306.05225v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.05225</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer-based attack adopts the adversarial examples generated on the
surrogate model to attack various models, making it applicable in the physical
world and attracting increasing interest. Recently, various adversarial attacks
have emerged to boost adversarial transferability from different perspectives.
In this work, inspired by the observation that flat local minima are correlated
with good generalization, we assume and empirically validate that adversarial
examples at a flat local region tend to have good transferability by
introducing a penalized gradient norm to the original loss function. Since
directly optimizing the gradient regularization norm is computationally
expensive and intractable for generating adversarial examples, we propose an
approximation optimization method to simplify the gradient update of the
objective function. Specifically, we randomly sample an example and adopt a
first-order procedure to approximate the curvature of Hessian/vector product,
which makes computing more efficient by interpolating two neighboring
gradients. Meanwhile, in order to obtain a more stable gradient direction, we
randomly sample multiple examples and average the gradients of these examples
to reduce the variance due to random sampling during the iterative process.
Extensive experimental results on the ImageNet-compatible dataset show that the
proposed method can generate adversarial examples at flat local regions, and
significantly improve the adversarial transferability on either normally
trained models or adversarially trained models than the state-of-the-art
attacks. Our codes are available at:
https://github.com/Trustworthy-AI-Group/PGN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1&quot;&gt;Zhijin Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hongying Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaosen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_F/0/1/0/all/0/1&quot;&gt;Fanhua Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yuanyuan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.07962">
<title>Parting with Misconceptions about Learning-based Vehicle Motion Planning. (arXiv:2306.07962v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2306.07962</link>
<description rdf:parseType="Literal">&lt;p&gt;The release of nuPlan marks a new era in vehicle motion planning research,
offering the first large-scale real-world dataset and evaluation schemes
requiring both precise short-term planning and long-horizon ego-forecasting.
Existing systems struggle to simultaneously meet both requirements. Indeed, we
find that these tasks are fundamentally misaligned and should be addressed
independently. We further assess the current state of closed-loop planning in
the field, revealing the limitations of learning-based methods in complex
real-world scenarios and the value of simple rule-based priors such as
centerline selection through lane graph search algorithms. More surprisingly,
for the open-loop sub-task, we observe that the best results are achieved when
using only this centerline as scene context (i.e., ignoring all information
regarding the map and other agents). Combining these insights, we propose an
extremely simple and efficient planner which outperforms an extensive set of
competitors, winning the nuPlan planning challenge 2023.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dauner_D/0/1/0/all/0/1&quot;&gt;Daniel Dauner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hallgarten_M/0/1/0/all/0/1&quot;&gt;Marcel Hallgarten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1&quot;&gt;Andreas Geiger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chitta_K/0/1/0/all/0/1&quot;&gt;Kashyap Chitta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.08153">
<title>(Amplified) Banded Matrix Factorization: A unified approach to private training. (arXiv:2306.08153v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.08153</link>
<description rdf:parseType="Literal">&lt;p&gt;Matrix factorization (MF) mechanisms for differential privacy (DP) have
substantially improved the state-of-the-art in privacy-utility-computation
tradeoffs for ML applications in a variety of scenarios, but in both the
centralized and federated settings there remain instances where either MF
cannot be easily applied, or other algorithms provide better tradeoffs
(typically, as $\epsilon$ becomes small). In this work, we show how MF can
subsume prior state-of-the-art algorithms in both federated and centralized
training settings, across all privacy budgets. The key technique throughout is
the construction of MF mechanisms with banded matrices (lower-triangular
matrices with at most $\hat{b}$ nonzero bands including the main diagonal). For
cross-device federated learning (FL), this enables multiple-participations with
a relaxed device participation schema compatible with practical FL
infrastructure (as demonstrated by a production deployment). In the centralized
setting, we prove that banded matrices enjoy the same privacy amplification
results as the ubiquitous DP-SGD algorithm, but can provide strictly better
performance in most scenarios -- this lets us always at least match DP-SGD, and
often outperform it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choquette_Choo_C/0/1/0/all/0/1&quot;&gt;Christopher A. Choquette-Choo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganesh_A/0/1/0/all/0/1&quot;&gt;Arun Ganesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McKenna_R/0/1/0/all/0/1&quot;&gt;Ryan McKenna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McMahan_H/0/1/0/all/0/1&quot;&gt;H. Brendan McMahan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rush_K/0/1/0/all/0/1&quot;&gt;Keith Rush&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakurta_A/0/1/0/all/0/1&quot;&gt;Abhradeep Thakurta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zheng Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.09750">
<title>Fedstellar: A Platform for Decentralized Federated Learning. (arXiv:2306.09750v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.09750</link>
<description rdf:parseType="Literal">&lt;p&gt;In 2016, Google proposed Federated Learning (FL) as a novel paradigm to train
Machine Learning (ML) models across the participants of a federation while
preserving data privacy. Since its birth, Centralized FL (CFL) has been the
most used approach, where a central entity aggregates participants&apos; models to
create a global one. However, CFL presents limitations such as communication
bottlenecks, single point of failure, and reliance on a central server.
Decentralized Federated Learning (DFL) addresses these issues by enabling
decentralized model aggregation and minimizing dependency on a central entity.
Despite these advances, current platforms training DFL models struggle with key
issues such as managing heterogeneous federation network topologies. To
overcome these challenges, this paper presents Fedstellar, a novel platform
designed to train FL models in a decentralized, semi-decentralized, and
centralized fashion across diverse federations of physical or virtualized
devices. The Fedstellar implementation encompasses a web application with an
interactive graphical interface, a controller for deploying federations of
nodes using physical or virtual devices, and a core deployed on each device
which provides the logic needed to train, aggregate, and communicate in the
network. The effectiveness of the platform has been demonstrated in two
scenarios: a physical deployment involving single-board devices such as
Raspberry Pis for detecting cyberattacks, and a virtualized deployment
comparing various FL approaches in a controlled environment using MNIST and
CIFAR-10 datasets. In both scenarios, Fedstellar demonstrated consistent
performance and adaptability, achieving F1 scores of 91%, 98%, and 91.2% using
DFL for detecting cyberattacks and classifying MNIST and CIFAR-10,
respectively, reducing training time by 32% compared to centralized approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beltran_E/0/1/0/all/0/1&quot;&gt;Enrique Tom&amp;#xe1;s Mart&amp;#xed;nez Beltr&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1&quot;&gt;&amp;#xc1;ngel Luis Perales G&amp;#xf3;mez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1&quot;&gt;Chao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_P/0/1/0/all/0/1&quot;&gt;Pedro Miguel S&amp;#xe1;nchez S&amp;#xe1;nchez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernal_S/0/1/0/all/0/1&quot;&gt;Sergio L&amp;#xf3;pez Bernal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bovet_G/0/1/0/all/0/1&quot;&gt;G&amp;#xe9;r&amp;#xf4;me Bovet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1&quot;&gt;Manuel Gil P&amp;#xe9;rez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_G/0/1/0/all/0/1&quot;&gt;Gregorio Mart&amp;#xed;nez P&amp;#xe9;rez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celdran_A/0/1/0/all/0/1&quot;&gt;Alberto Huertas Celdr&amp;#xe1;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12658">
<title>Fitted Value Iteration Methods for Bicausal Optimal Transport. (arXiv:2306.12658v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12658</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a fitted value iteration (FVI) method to compute bicausal optimal
transport (OT) where couplings have an adapted structure. Based on the dynamic
programming formulation, FVI adopts a function class to approximate the value
functions in bicausal OT. Under the concentrability condition and approximate
completeness assumption, we prove the sample complexity using (local)
Rademacher complexity. Furthermore, we demonstrate that multilayer neural
networks with appropriate structures satisfy the crucial assumptions required
in sample complexity proofs. Numerical experiments reveal that FVI outperforms
linear programming and adapted Sinkhorn methods in scalability as the time
horizon increases, while still maintaining acceptable accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bayraktar_E/0/1/0/all/0/1&quot;&gt;Erhan Bayraktar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bingyan Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02028">
<title>EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models. (arXiv:2307.02028v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02028</link>
<description rdf:parseType="Literal">&lt;p&gt;While the general machine learning (ML) community has benefited from public
datasets, tasks, and models, the progress of ML in healthcare has been hampered
by a lack of such shared assets. The success of foundation models creates new
challenges for healthcare ML by requiring access to shared pretrained models to
validate performance benefits. We help address these challenges through three
contributions. First, we publish a new dataset, EHRSHOT, which contains
deidentified structured data from the electronic health records (EHRs) of 6,739
patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR
datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients.
Second, we publish the weights of CLMBR-T-base, a 141M parameter clinical
foundation model pretrained on the structured EHR data of 2.57M patients. We
are one of the first to fully release such a model for coded EHR data; in
contrast, most prior models released for clinical data (e.g. GatorTron,
ClinicalBERT) only work with unstructured text and cannot process the rich,
structured data within an EHR. We provide an end-to-end pipeline for the
community to validate and build upon its performance. Third, we define 15
few-shot clinical prediction tasks, enabling evaluation of foundation models on
benefits such as sample efficiency and task adaptation. Our model and dataset
are available via a research data use agreement from the Stanford AIMI Center.
Code to reproduce our results are available at our Github repo:
https://github.com/som-shahlab/ehrshot-benchmark
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wornow_M/0/1/0/all/0/1&quot;&gt;Michael Wornow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thapa_R/0/1/0/all/0/1&quot;&gt;Rahul Thapa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinberg_E/0/1/0/all/0/1&quot;&gt;Ethan Steinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fries_J/0/1/0/all/0/1&quot;&gt;Jason A. Fries&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Nigam H. Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02598">
<title>Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation. (arXiv:2307.02598v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02598</link>
<description rdf:parseType="Literal">&lt;p&gt;We tackle the problems of latent variables identification and
``out-of-support&apos;&apos; image generation in representation learning. We show that
both are possible for a class of decoders that we call additive, which are
reminiscent of decoders used for object-centric representation learning (OCRL)
and well suited for images that can be decomposed as a sum of object-specific
images. We provide conditions under which exactly solving the reconstruction
problem using an additive decoder is guaranteed to identify the blocks of
latent variables up to permutation and block-wise invertible transformations.
This guarantee relies only on very weak assumptions about the distribution of
the latent factors, which might present statistical dependencies and have an
almost arbitrarily shaped support. Our result provides a new setting where
nonlinear independent component analysis (ICA) is possible and adds to our
theoretical understanding of OCRL methods. We also show theoretically that
additive decoders can generate novel images by recombining observed factors of
variations in novel ways, an ability we refer to as Cartesian-product
extrapolation. We show empirically that additivity is crucial for both
identifiability and extrapolation on simulated data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lachapelle_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Lachapelle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahajan_D/0/1/0/all/0/1&quot;&gt;Divyat Mahajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1&quot;&gt;Ioannis Mitliagkas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1&quot;&gt;Simon Lacoste-Julien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.03486">
<title>Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning. (arXiv:2307.03486v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.03486</link>
<description rdf:parseType="Literal">&lt;p&gt;Discovering achievements with a hierarchical structure in procedurally
generated environments presents a significant challenge. This requires an agent
to possess a broad range of abilities, including generalization and long-term
reasoning. Many prior methods have been built upon model-based or hierarchical
approaches, with the belief that an explicit module for long-term planning
would be advantageous for learning hierarchical dependencies. However, these
methods demand an excessive number of environment interactions or large model
sizes, limiting their practicality. In this work, we demonstrate that proximal
policy optimization (PPO), a simple yet versatile model-free algorithm,
outperforms previous methods when optimized with recent implementation
practices. Moreover, we find that the PPO agent can predict the next
achievement to be unlocked to some extent, albeit with limited confidence.
Based on this observation, we introduce a novel contrastive learning method,
called achievement distillation, which strengthens the agent&apos;s ability to
predict the next achievement. Our method exhibits a strong capacity for
discovering hierarchical achievements and shows state-of-the-art performance on
the challenging Crafter environment in a sample-efficient manner while
utilizing fewer model parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1&quot;&gt;Seungyong Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeom_J/0/1/0/all/0/1&quot;&gt;Junyoung Yeom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1&quot;&gt;Bumsoo Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1&quot;&gt;Hyun Oh Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.05973">
<title>VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models. (arXiv:2307.05973v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2307.05973</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) are shown to possess a wealth of actionable
knowledge that can be extracted for robot manipulation in the form of reasoning
and planning. Despite the progress, most still rely on pre-defined motion
primitives to carry out the physical interactions with the environment, which
remains a major bottleneck. In this work, we aim to synthesize robot
trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a
large variety of manipulation tasks given an open-set of instructions and an
open-set of objects. We achieve this by first observing that LLMs excel at
inferring affordances and constraints given a free-form language instruction.
More importantly, by leveraging their code-writing capabilities, they can
interact with a vision-language model (VLM) to compose 3D value maps to ground
the knowledge into the observation space of the agent. The composed value maps
are then used in a model-based planning framework to zero-shot synthesize
closed-loop robot trajectories with robustness to dynamic perturbations. We
further demonstrate how the proposed framework can benefit from online
experiences by efficiently learning a dynamics model for scenes that involve
contact-rich interactions. We present a large-scale study of the proposed
method in both simulated and real-robot environments, showcasing the ability to
perform a large variety of everyday manipulation tasks specified in free-form
natural language. Videos and code at https://voxposer.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wenlong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruohan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yunzhu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1&quot;&gt;Li Fei-Fei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.07050">
<title>Wasserstein Quantum Monte Carlo: A Novel Approach for Solving the Quantum Many-Body Schr\&quot;odinger Equation. (arXiv:2307.07050v3 [physics.comp-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2307.07050</link>
<description rdf:parseType="Literal">&lt;p&gt;Solving the quantum many-body Schr\&quot;odinger equation is a fundamental and
challenging problem in the fields of quantum physics, quantum chemistry, and
material sciences. One of the common computational approaches to this problem
is Quantum Variational Monte Carlo (QVMC), in which ground-state solutions are
obtained by minimizing the energy of the system within a restricted family of
parameterized wave functions. Deep learning methods partially address the
limitations of traditional QVMC by representing a rich family of wave functions
in terms of neural networks. However, the optimization objective in QVMC
remains notoriously hard to minimize and requires second-order optimization
methods such as natural gradient. In this paper, we first reformulate energy
functional minimization in the space of Born distributions corresponding to
particle-permutation (anti-)symmetric wave functions, rather than the space of
wave functions. We then interpret QVMC as the Fisher-Rao gradient flow in this
distributional space, followed by a projection step onto the variational
manifold. This perspective provides us with a principled framework to derive
new QMC algorithms, by endowing the distributional space with better metrics,
and following the projected gradient flow induced by those metrics. More
specifically, we propose &quot;Wasserstein Quantum Monte Carlo&quot; (WQMC), which uses
the gradient flow induced by the Wasserstein metric, rather than Fisher-Rao
metric, and corresponds to transporting the probability mass, rather than
teleporting it. We demonstrate empirically that the dynamics of WQMC results in
faster convergence to the ground state of molecular systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Neklyudov_K/0/1/0/all/0/1&quot;&gt;Kirill Neklyudov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Nys_J/0/1/0/all/0/1&quot;&gt;Jannes Nys&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Thiede_L/0/1/0/all/0/1&quot;&gt;Luca Thiede&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Carrasquilla_J/0/1/0/all/0/1&quot;&gt;Juan Carrasquilla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Makhzani_A/0/1/0/all/0/1&quot;&gt;Alireza Makhzani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.07439">
<title>Atlas-Based Interpretable Age Prediction In Whole-Body MR Images. (arXiv:2307.07439v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.07439</link>
<description rdf:parseType="Literal">&lt;p&gt;Age prediction is an important part of medical assessments and research. It
can aid in detecting diseases as well as abnormal ageing by highlighting the
discrepancy between chronological and biological age. To gain a comprehensive
understanding of age-related changes observed in various body parts, we
investigate them on a larger scale by using whole-body 3D images. We utilise
the Grad-CAM interpretability method to determine the body areas most
predictive of a person&apos;s age. We expand our analysis beyond individual subjects
by employing registration techniques to generate population-wide
interpretability maps. Our findings reveal three primary areas of interest: the
spine, the autochthonous back muscles, and the cardiac region, which exhibits
the highest importance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Starck_S/0/1/0/all/0/1&quot;&gt;Sophie Starck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kini_Y/0/1/0/all/0/1&quot;&gt;Yadunandan Vivekanand Kini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ritter_J/0/1/0/all/0/1&quot;&gt;Jessica Johanna Maria Ritter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Braren_R/0/1/0/all/0/1&quot;&gt;Rickmer Braren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1&quot;&gt;Daniel Rueckert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mueller_T/0/1/0/all/0/1&quot;&gt;Tamara Mueller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.06534">
<title>Self-Supervised Pre-Training with Contrastive and Masked Autoencoder Methods for Dealing with Small Datasets in Deep Learning for Medical Imaging. (arXiv:2308.06534v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.06534</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning in medical imaging has the potential to minimize the risk of
diagnostic errors, reduce radiologist workload, and accelerate diagnosis.
Training such deep learning models requires large and accurate datasets, with
annotations for all training samples. However, in the medical imaging domain,
annotated datasets for specific tasks are often small due to the high
complexity of annotations, limited access, or the rarity of diseases. To
address this challenge, deep learning models can be pre-trained on large image
datasets without annotations using methods from the field of self-supervised
learning. After pre-training, small annotated datasets are sufficient to
fine-tune the models for a specific task. The most popular self-supervised
pre-training approaches in medical imaging are based on contrastive learning.
However, recent studies in natural image processing indicate a strong potential
for masked autoencoder approaches. Our work compares state-of-the-art
contrastive learning methods with the recently introduced masked autoencoder
approach &quot;SparK&quot; for convolutional neural networks (CNNs) on medical images.
Therefore we pre-train on a large unannotated CT image dataset and fine-tune on
several CT classification tasks. Due to the challenge of obtaining sufficient
annotated training data in medical imaging, it is of particular interest to
evaluate how the self-supervised pre-training methods perform when fine-tuning
on small datasets. By experimenting with gradually reducing the training
dataset size for fine-tuning, we find that the reduction has different effects
depending on the type of pre-training chosen. The SparK pre-training method is
more robust to the training dataset size than the contrastive methods. Based on
our results, we propose the SparK pre-training for medical imaging tasks with
only small annotated datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_D/0/1/0/all/0/1&quot;&gt;Daniel Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Payer_T/0/1/0/all/0/1&quot;&gt;Tristan Payer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lisson_C/0/1/0/all/0/1&quot;&gt;Catharina Silvia Lisson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lisson_C/0/1/0/all/0/1&quot;&gt;Christoph Gerhard Lisson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beer_M/0/1/0/all/0/1&quot;&gt;Meinrad Beer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gotz_M/0/1/0/all/0/1&quot;&gt;Michael G&amp;#xf6;tz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1&quot;&gt;Timo Ropinski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.07843">
<title>Dyadic Reinforcement Learning. (arXiv:2308.07843v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.07843</link>
<description rdf:parseType="Literal">&lt;p&gt;Mobile health aims to enhance health outcomes by delivering interventions to
individuals as they go about their daily life. The involvement of care partners
and social support networks often proves crucial in helping individuals
managing burdensome medical conditions. This presents opportunities in mobile
health to design interventions that target the dyadic relationship -- the
relationship between a target person and their care partner -- with the aim of
enhancing social support. In this paper, we develop dyadic RL, an online
reinforcement learning algorithm designed to personalize intervention delivery
based on contextual factors and past responses of a target person and their
care partner. Here, multiple sets of interventions impact the dyad across
multiple time intervals. The developed dyadic RL is Bayesian and hierarchical.
We formally introduce the problem setup, develop dyadic RL and establish a
regret bound. We demonstrate dyadic RL&apos;s empirical performance through
simulation studies on both toy scenarios and on a realistic test bed
constructed from data collected in a mobile health study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuangning Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niell_L/0/1/0/all/0/1&quot;&gt;Lluis Salvat Niell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sung Won Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nahum_Shani_I/0/1/0/all/0/1&quot;&gt;Inbal Nahum-Shani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shani_G/0/1/0/all/0/1&quot;&gt;Guy Shani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murphy_S/0/1/0/all/0/1&quot;&gt;Susan Murphy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.10068">
<title>ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration. (arXiv:2308.10068v2 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/2308.10068</link>
<description rdf:parseType="Literal">&lt;p&gt;The high-accuracy and resource-intensive deep neural networks (DNNs) have
been widely adopted by live video analytics (VA), where camera videos are
streamed over the network to resource-rich edge/cloud servers for DNN
inference. Common video encoding configurations (e.g., resolution and frame
rate) have been identified with significant impacts on striking the balance
between bandwidth consumption and inference accuracy and therefore their
adaption scheme has been a focus of optimization. However, previous
profiling-based solutions suffer from high profiling cost, while existing deep
reinforcement learning (DRL) based solutions may achieve poor performance due
to the usage of fixed reward function for training the agent, which fails to
craft the application goals in various scenarios. In this paper, we propose
ILCAS, the first imitation learning (IL) based configuration-adaptive VA
streaming system. Unlike DRL-based solutions, ILCAS trains the agent with
demonstrations collected from the expert which is designed as an offline
optimal policy that solves the configuration adaption problem through dynamic
programming. To tackle the challenge of video content dynamics, ILCAS derives
motion feature maps based on motion vectors which allow ILCAS to visually
``perceive&apos;&apos; video content changes. Moreover, ILCAS incorporates a cross-camera
collaboration scheme to exploit the spatio-temporal correlations of cameras for
more proper configuration selection. Extensive experiments confirm the
superiority of ILCAS compared with state-of-the-art solutions, with 2-20.9%
improvement of mean accuracy and 19.9-85.3% reduction of chunk upload lag.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Duo Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dayou Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Miao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruoyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fangxin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1&quot;&gt;Shuguang Cui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.00733">
<title>Learned Visual Features to Textual Explanations. (arXiv:2309.00733v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.00733</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpreting the learned features of vision models has posed a longstanding
challenge in the field of machine learning. To address this issue, we propose a
novel method that leverages the capabilities of large language models (LLMs) to
interpret the learned features of pre-trained image classifiers. Our method,
called TExplain, tackles this task by training a neural network to establish a
connection between the feature space of image classifiers and LLMs. Then,
during inference, our approach generates a vast number of sentences to explain
the features learned by the classifier for a given image. These sentences are
then used to extract the most frequent words, providing a comprehensive
understanding of the learned features and patterns within the classifier. Our
method, for the first time, utilizes these frequent words corresponding to a
visual representation to provide insights into the decision-making process of
the independently trained classifier, enabling the detection of spurious
correlations, biases, and a deeper comprehension of its behavior. To validate
the effectiveness of our approach, we conduct experiments on diverse datasets,
including ImageNet-9L and Waterbirds. The results demonstrate the potential of
our method to enhance the interpretability and robustness of image classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taghanaki_S/0/1/0/all/0/1&quot;&gt;Saeid Asgari Taghanaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khani_A/0/1/0/all/0/1&quot;&gt;Aliasghar Khani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khasahmadi_A/0/1/0/all/0/1&quot;&gt;Amir Khasahmadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanghi_A/0/1/0/all/0/1&quot;&gt;Aditya Sanghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Willis_K/0/1/0/all/0/1&quot;&gt;Karl D.D. Willis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahdavi_Amiri_A/0/1/0/all/0/1&quot;&gt;Ali Mahdavi-Amiri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.01267">
<title>Deception Game: Closing the Safety-Learning Loop in Interactive Robot Autonomy. (arXiv:2309.01267v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2309.01267</link>
<description rdf:parseType="Literal">&lt;p&gt;An outstanding challenge for the widespread deployment of robotic systems
like autonomous vehicles is ensuring safe interaction with humans without
sacrificing performance. Existing safety methods often neglect the robot&apos;s
ability to learn and adapt at runtime, leading to overly conservative behavior.
This paper proposes a new closed-loop paradigm for synthesizing safe control
policies that explicitly account for the robot&apos;s evolving uncertainty and its
ability to quickly respond to future scenarios as they arise, by jointly
considering the physical dynamics and the robot&apos;s learning algorithm. We
leverage adversarial reinforcement learning for tractable safety analysis under
high-dimensional learning dynamics and demonstrate our framework&apos;s ability to
work with both Bayesian belief propagation and implicit learning through large
pre-trained neural trajectory predictors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Haimin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zixu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamura_K/0/1/0/all/0/1&quot;&gt;Kensuke Nakamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajcsy_A/0/1/0/all/0/1&quot;&gt;Andrea Bajcsy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fisac_J/0/1/0/all/0/1&quot;&gt;Jaime F. Fisac&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.01632">
<title>Representing Edge Flows on Graphs via Sparse Cell Complexes. (arXiv:2309.01632v3 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2309.01632</link>
<description rdf:parseType="Literal">&lt;p&gt;Obtaining sparse, interpretable representations of observable data is crucial
in many machine learning and signal processing tasks. For data representing
flows along the edges of a graph, an intuitively interpretable way to obtain
such representations is to lift the graph structure to a simplicial complex:
The eigenvectors of the associated Hodge-Laplacian, respectively the incidence
matrices of the corresponding simplicial complex then induce a Hodge
decomposition, which can be used to represent the observed data in terms of
gradient, curl, and harmonic flows. In this paper, we generalize this approach
to cellular complexes and introduce the flow representation learning problem,
i.e., the problem of augmenting the observed graph by a set of cells, such that
the eigenvectors of the associated Hodge Laplacian provide a sparse,
interpretable representation of the observed edge flows on the graph. We show
that this problem is NP-hard and introduce an efficient approximation algorithm
for its solution. Experiments on real-world and synthetic data demonstrate that
our algorithm outperforms state-of-the-art methods with respect to
approximation error, while being computationally efficient.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoppe_J/0/1/0/all/0/1&quot;&gt;Josef Hoppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaub_M/0/1/0/all/0/1&quot;&gt;Michael T. Schaub&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.04037">
<title>SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression with Super-resolution Neural Networks. (arXiv:2309.04037v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.04037</link>
<description rdf:parseType="Literal">&lt;p&gt;The fast growth of computational power and scales of modern super-computing
systems have raised great challenges for the management of exascale scientific
data. To maintain the usability of scientific data, error-bound lossy
compression is proposed and developed as an essential technique for the size
reduction of scientific data with constrained data distortion. Among the
diverse datasets generated by various scientific simulations, certain datasets
cannot be effectively compressed by existing error-bounded lossy compressors
with traditional techniques. The recent success of Artificial Intelligence has
inspired several researchers to integrate neural networks into error-bounded
lossy compressors. However, those works still suffer from limited compression
ratios and/or extremely low efficiencies. To address those issues and improve
the compression on the hard-to-compress datasets, in this paper, we propose
SRN-SZ, which is a deep learning-based scientific error-bounded lossy
compressor leveraging the hierarchical data grid expansion paradigm implemented
by super-resolution neural networks. SRN-SZ applies the most advanced
super-resolution network HAT for its compression, which is free of time-costing
per-data training. In experiments compared with various state-of-the-art
compressors, SRN-SZ achieves up to 75% compression ratio improvements under the
same error bound and up to 80% compression ratio improvements under the same
PSNR than the second-best compressor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jinyang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Di_S/0/1/0/all/0/1&quot;&gt;Sheng Di&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1&quot;&gt;Sian Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1&quot;&gt;Kai Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1&quot;&gt;Xin Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zizhong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cappello_F/0/1/0/all/0/1&quot;&gt;Franck Cappello&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.05183">
<title>Data Summarization beyond Monotonicity: Non-monotone Two-Stage Submodular Maximization. (arXiv:2309.05183v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2309.05183</link>
<description rdf:parseType="Literal">&lt;p&gt;The objective of a two-stage submodular maximization problem is to reduce the
ground set using provided training functions that are submodular, with the aim
of ensuring that optimizing new objective functions over the reduced ground set
yields results comparable to those obtained over the original ground set. This
problem has applications in various domains including data summarization.
Existing studies often assume the monotonicity of the objective function,
whereas our work pioneers the extension of this research to accommodate
non-monotone submodular functions. We have introduced the first constant-factor
approximation algorithms for this more general case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shaojie Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.13425">
<title>MiliPoint: A Point Cloud Dataset for mmWave Radar. (arXiv:2309.13425v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.13425</link>
<description rdf:parseType="Literal">&lt;p&gt;Millimetre-wave (mmWave) radar has emerged as an attractive and
cost-effective alternative for human activity sensing compared to traditional
camera-based systems. mmWave radars are also non-intrusive, providing better
protection for user privacy. However, as a Radio Frequency (RF) based
technology, mmWave radars rely on capturing reflected signals from objects,
making them more prone to noise compared to cameras. This raises an intriguing
question for the deep learning community: Can we develop more effective point
set-based deep learning methods for such attractive sensors?
&lt;/p&gt;
&lt;p&gt;To answer this question, our work, termed MiliPoint, delves into this idea by
providing a large-scale, open dataset for the community to explore how mmWave
radars can be utilised for human activity recognition. Moreover, MiliPoint
stands out as it is larger in size than existing datasets, has more diverse
human actions represented, and encompasses all three key tasks in human
activity recognition. We have also established a range of point-based deep
neural networks such as DGCNN, PointNet++ and PointTransformer, on MiliPoint,
which can serve to set the ground baseline for further development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1&quot;&gt;Han Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1&quot;&gt;Shu Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiacheng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zichao Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahnoun_N/0/1/0/all/0/1&quot;&gt;Naim Dahnoun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yiren Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00806">
<title>Bayesian Design Principles for Frequentist Sequential Learning. (arXiv:2310.00806v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00806</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a general theory to optimize the frequentist regret for sequential
learning problems, where efficient bandit and reinforcement learning algorithms
can be derived from unified Bayesian principles. We propose a novel
optimization approach to generate &quot;algorithmic beliefs&quot; at each round, and use
Bayesian posteriors to make decisions. The optimization objective to create
&quot;algorithmic beliefs,&quot; which we term &quot;Algorithmic Information Ratio,&quot;
represents an intrinsic complexity measure that effectively characterizes the
frequentist regret of any algorithm. To the best of our knowledge, this is the
first systematical approach to make Bayesian-type algorithms prior-free and
applicable to adversarial settings, in a generic and optimal manner. Moreover,
the algorithms are simple and often efficient to implement. As a major
application, we present a novel algorithm for multi-armed bandits that achieves
the &quot;best-of-all-worlds&quot; empirical performance in the stochastic, adversarial,
and non-stationary environments. And we illustrate how these principles can be
used in linear bandits, bandit convex optimization, and reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yunbei Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeevi_A/0/1/0/all/0/1&quot;&gt;Assaf Zeevi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01853">
<title>Score-based Data Assimilation for a Two-Layer Quasi-Geostrophic Model. (arXiv:2310.01853v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2310.01853</link>
<description rdf:parseType="Literal">&lt;p&gt;Data assimilation addresses the problem of identifying plausible state
trajectories of dynamical systems given noisy or incomplete observations. In
geosciences, it presents challenges due to the high-dimensionality of
geophysical dynamical systems, often exceeding millions of dimensions. This
work assesses the scalability of score-based data assimilation (SDA), a novel
data assimilation method, in the context of such systems. We propose
modifications to the score network architecture aimed at significantly reducing
memory consumption and execution time. We demonstrate promising results for a
two-layer quasi-geostrophic model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rozet_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Rozet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Louppe_G/0/1/0/all/0/1&quot;&gt;Gilles Louppe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02090">
<title>1D-CapsNet-LSTM: A Deep Learning-Based Model for Multi-Step Stock Index Forecasting. (arXiv:2310.02090v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02090</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-step stock index forecasting is vital in finance for informed
decision-making. Current forecasting methods on this task frequently produce
unsatisfactory results due to the inherent data randomness and instability,
thereby underscoring the demand for advanced forecasting models. Given the
superiority of capsule network (CapsNet) over CNN in various forecasting and
classification tasks, this study investigates the potential of integrating a 1D
CapsNet with an LSTM network for multi-step stock index forecasting. To this
end, a hybrid 1D-CapsNet-LSTM model is introduced, which utilizes a 1D CapsNet
to generate high-level capsules from sequential data and a LSTM network to
capture temporal dependencies. To maintain stochastic dependencies over
different forecasting horizons, a multi-input multi-output (MIMO) strategy is
employed. The model&apos;s performance is evaluated on real-world stock market
indices, including S&amp;amp;P 500, DJIA, IXIC, and NYSE, and compared to baseline
models, including LSTM, RNN, and CNN-LSTM, using metrics such as RMSE, MAE,
MAPE, and TIC. The proposed 1D-CapsNet-LSTM model consistently outperforms
baseline models in two key aspects. It exhibits significant reductions in
forecasting errors compared to baseline models. Furthermore, it displays a
slower rate of error increase with lengthening forecast horizons, indicating
increased robustness for multi-step forecasting tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sjarif_N/0/1/0/all/0/1&quot;&gt;Nilam Nur Amir Sjarif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahim_R/0/1/0/all/0/1&quot;&gt;Roslina Ibrahim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03047">
<title>Differentiable Modeling and Optimization of Battery Electrolyte Mixtures Using Geometric Deep Learning. (arXiv:2310.03047v2 [physics.chem-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03047</link>
<description rdf:parseType="Literal">&lt;p&gt;Electrolytes play a critical role in designing next-generation battery
systems, by allowing efficient ion transfer, preventing charge transfer, and
stabilizing electrode-electrolyte interfaces. In this work, we develop a
differentiable geometric deep learning (GDL) model for chemical mixtures,
DiffMix, which is applied in guiding robotic experimentation and optimization
towards fast-charging battery electrolytes. In particular, we extend mixture
thermodynamic and transport laws by creating GDL-learnable physical
coefficients. We evaluate our model with mixture thermodynamics and ion
transport properties, where we show improved prediction accuracy and model
robustness of DiffMix than its purely data-driven variants. Furthermore, with a
robotic experimentation setup, Clio, we improve ionic conductivity of
electrolytes by over 18.8% within 10 experimental steps, via differentiable
optimization built on DiffMix gradients. By combining GDL, mixture physics
laws, and robotic experimentation, DiffMix expands the predictive modeling
methods for chemical mixtures and enables efficient optimization in large
chemical spaces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ramsundar_B/0/1/0/all/0/1&quot;&gt;Bharath Ramsundar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Annevelink_E/0/1/0/all/0/1&quot;&gt;Emil Annevelink&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hongyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Dave_A/0/1/0/all/0/1&quot;&gt;Adarsh Dave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Guan_P/0/1/0/all/0/1&quot;&gt;Pin-Wen Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gering_K/0/1/0/all/0/1&quot;&gt;Kevin Gering&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Viswanathan_V/0/1/0/all/0/1&quot;&gt;Venkatasubramanian Viswanathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03103">
<title>Dual Prompt Tuning for Domain-Aware Federated Learning. (arXiv:2310.03103v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03103</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning is a distributed machine learning paradigm that allows
multiple clients to collaboratively train a shared model with their local data.
Nonetheless, conventional federated learning algorithms often struggle to
generalize well due to the ubiquitous domain shift across clients. In this
work, we consider a challenging yet realistic federated learning scenario where
the training data of each client originates from different domains. We address
the challenges of domain shift by leveraging the technique of prompt learning,
and propose a novel method called Federated Dual Prompt Tuning (Fed-DPT).
Specifically, Fed-DPT employs a pre-trained vision-language model and then
applies both visual and textual prompt tuning to facilitate domain adaptation
over decentralized data. Extensive experiments of Fed-DPT demonstrate its
significant effectiveness in domain-aware federated learning. With a
pre-trained CLIP model (ViT-Base as image encoder), the proposed Fed-DPT
attains 68.4% average accuracy over six domains in the DomainNet dataset, which
improves the original CLIP by a large margin of 14.8%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1&quot;&gt;Guoyizhe Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Feng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1&quot;&gt;Anshul Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1&quot;&gt;Rama Chellappa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04015">
<title>Anonymous Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization. (arXiv:2310.04015v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.04015</link>
<description rdf:parseType="Literal">&lt;p&gt;While personalized recommendations systems have become increasingly popular,
ensuring user data protection remains a top concern in the development of these
learning systems. A common approach to enhancing privacy involves training
models using anonymous data rather than individual data. In this paper, we
explore a natural technique called \emph{look-alike clustering}, which involves
replacing sensitive features of individuals with the cluster&apos;s average values.
We provide a precise analysis of how training models using anonymous cluster
centers affects their generalization capabilities. We focus on an asymptotic
regime where the size of the training set grows in proportion to the features
dimension. Our analysis is based on the Convex Gaussian Minimax Theorem (CGMT)
and allows us to theoretically understand the role of different model
components on the generalization error. In addition, we demonstrate that in
certain high-dimensional regimes, training over anonymous cluster centers acts
as a regularization and improves generalization error of the trained models.
Finally, we corroborate our asymptotic theory with finite-sample numerical
experiments where we observe a perfect match when the sample size is only of
order of a few hundreds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javanmard_A/0/1/0/all/0/1&quot;&gt;Adel Javanmard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1&quot;&gt;Vahab Mirrokni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.06157">
<title>Manifold-augmented Eikonal Equations: Geodesic Distances and Flows on Differentiable Manifolds. (arXiv:2310.06157v2 [cs.CG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.06157</link>
<description rdf:parseType="Literal">&lt;p&gt;Manifolds discovered by machine learning models provide a compact
representation of the underlying data. Geodesics on these manifolds define
locally length-minimising curves and provide a notion of distance, which are
key for reduced-order modelling, statistical inference, and interpolation. In
this work, we propose a model-based parameterisation for distance fields and
geodesic flows on manifolds, exploiting solutions of a manifold-augmented
Eikonal equation. We demonstrate how the geometry of the manifold impacts the
distance field, and exploit the geodesic flow to obtain globally
length-minimising curves directly. This work opens opportunities for statistics
and reduced-order modelling on differentiable manifolds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kelshaw_D/0/1/0/all/0/1&quot;&gt;Daniel Kelshaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magri_L/0/1/0/all/0/1&quot;&gt;Luca Magri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.09259">
<title>QUIK: Towards End-to-End 4-Bit Inference on Generative Large Language Models. (arXiv:2310.09259v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.09259</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) from the GPT family have become extremely
popular, leading to a race towards reducing their inference costs to allow for
efficient local computation. Yet, the vast majority of existing work focuses on
weight-only quantization, which can reduce runtime costs in the memory-bound
one-token-at-a-time generative setting, but does not address them in
compute-bound scenarios, such as batched inference or prompt processing. In
this paper, we address the general quantization problem, where both weights and
activations should be quantized. We show, for the first time, that the majority
of inference computations for large generative models such as LLaMA, OPT, and
Falcon can be performed with both weights and activations being cast to 4 bits,
in a way that leads to practical speedups, while at the same time maintaining
good accuracy. We achieve this via a hybrid quantization strategy called QUIK,
which compresses most of the weights and activations to 4-bit, while keeping
some outlier weights and activations in higher-precision. The key feature of
our scheme is that it is designed with computational efficiency in mind: we
provide GPU kernels matching the QUIK format with highly-efficient layer-wise
runtimes, which lead to practical end-to-end throughput improvements of up to
3.4x relative to FP16 execution. We provide detailed studies for models from
the OPT, LLaMA-2 and Falcon families, as well as a first instance of accurate
inference using quantization plus 2:4 sparsity. Code is available at:
https://github.com/IST-DASLab/QUIK.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashkboos_S/0/1/0/all/0/1&quot;&gt;Saleh Ashkboos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1&quot;&gt;Ilia Markov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frantar_E/0/1/0/all/0/1&quot;&gt;Elias Frantar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_T/0/1/0/all/0/1&quot;&gt;Tingxuan Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xincheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1&quot;&gt;Jie Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1&quot;&gt;Torsten Hoefler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1&quot;&gt;Dan Alistarh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.10030">
<title>Unraveling Fundamental Properties of Power System Resilience Curves using Unsupervised Machine Learning. (arXiv:2310.10030v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.10030</link>
<description rdf:parseType="Literal">&lt;p&gt;The standard model of infrastructure resilience, the resilience triangle, has
been the primary way of characterizing and quantifying infrastructure
resilience. However, the theoretical model merely provides a one-size-fits-all
framework for all infrastructure systems. Most of the existing studies examine
the characteristics of infrastructure resilience curves based on analytical
models constructed upon simulated system performance. Limited empirical studies
hindered our ability to fully understand and predict resilience characteristics
in infrastructure systems. To address this gap, this study examined over 200
resilience curves related to power outages in three major extreme weather
events. Using unsupervised machine learning, we examined different curve
archetypes, as well as the fundamental properties of each resilience curve
archetype. The results show two primary archetypes for power system resilience
curves, triangular, and trapezoidal curves. Triangular curves characterize
resilience behavior based on 1. critical functionality threshold, 2. critical
functionality recovery rate, and 3. recovery pivot point. Trapezoidal
archetypes explain resilience curves based on 1. duration of sustained function
loss and 2. constant recovery rate. The longer the duration of sustained
function loss, the slower the constant rate of recovery. The findings of this
study provide novel perspectives enabling better understanding and prediction
of resilience performance of power system infrastructures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mostafavi_A/0/1/0/all/0/1&quot;&gt;Ali Mostafavi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.10702">
<title>Transparent Anomaly Detection via Concept-based Explanations. (arXiv:2310.10702v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.10702</link>
<description rdf:parseType="Literal">&lt;p&gt;Advancements in deep learning techniques have given a boost to the
performance of anomaly detection. However, real-world and safety-critical
applications demand a level of transparency and reasoning beyond accuracy. The
task of anomaly detection (AD) focuses on finding whether a given sample
follows the learned distribution. Existing methods lack the ability to reason
with clear explanations for their outcomes. Hence to overcome this challenge,
we propose Transparent {A}nomaly Detection {C}oncept {E}xplanations (ACE). ACE
is able to provide human interpretable explanations in the form of concepts
along with anomaly prediction. To the best of our knowledge, this is the first
paper that proposes interpretable by-design anomaly detection. In addition to
promoting transparency in AD, it allows for effective human-model interaction.
Our proposed model shows either higher or comparable results to black-box
uninterpretable models. We validate the performance of ACE across three
realistic datasets - bird classification on CUB-200-2011, challenging
histopathology slide image classification on TIL-WSI-TCGA, and gender
classification on CelebA. We further demonstrate that our concept learning
paradigm can be seamlessly integrated with other classification-based AD
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sevyeri_L/0/1/0/all/0/1&quot;&gt;Laya Rafiee Sevyeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheth_I/0/1/0/all/0/1&quot;&gt;Ivaxi Sheth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farahnak_F/0/1/0/all/0/1&quot;&gt;Farhood Farahnak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahou_S/0/1/0/all/0/1&quot;&gt;Samira Ebrahimi Kahou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Enger_S/0/1/0/all/0/1&quot;&gt;Shirin Abbasinejad Enger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.12560">
<title>Fast Model Debias with Machine Unlearning. (arXiv:2310.12560v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.12560</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent discoveries have revealed that deep neural networks might behave in a
biased manner in many real-world scenarios. For instance, deep networks trained
on a large-scale face recognition dataset CelebA tend to predict blonde hair
for females and black hair for males. Such biases not only jeopardize the
robustness of models but also perpetuate and amplify social biases, which is
especially concerning for automated decision-making processes in healthcare,
recruitment, etc., as they could exacerbate unfair economic and social
inequalities among different groups. Existing debiasing methods suffer from
high costs in bias labeling or model re-training, while also exhibiting a
deficiency in terms of elucidating the origins of biases within the model. To
this respect, we propose a fast model debiasing framework (FMD) which offers an
efficient approach to identify, evaluate and remove biases inherent in trained
models. The FMD identifies biased attributes through an explicit counterfactual
concept and quantifies the influence of data samples with influence functions.
Moreover, we design a machine unlearning-based strategy to efficiently and
effectively remove the bias in a trained model with a small counterfactual
dataset. Experiments on the Colored MNIST, CelebA, and Adult Income datasets
along with experiments with large language models demonstrate that our method
achieves superior or competing accuracies compared with state-of-the-art
methods while attaining significantly fewer biases and requiring much less
debiasing cost. Notably, our method requires only a small external dataset and
updating a minimal amount of model parameters, without the requirement of
access to training data that may be too large or unavailable in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Ruizhe Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianfei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Huimin Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1&quot;&gt;Jianhong Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1&quot;&gt;Tianxiang Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1&quot;&gt;Jin Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Joey Tianyi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zuozhu Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13018">
<title>Getting aligned on representational alignment. (arXiv:2310.13018v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13018</link>
<description rdf:parseType="Literal">&lt;p&gt;Biological and artificial information processing systems form representations
that they can use to categorize, reason, plan, navigate, and make decisions.
How can we measure the extent to which the representations formed by these
diverse systems agree? Do similarities in representations then translate into
similar behavior? How can a system&apos;s representations be modified to better
match those of another system? These questions pertaining to the study of
representational alignment are at the heart of some of the most active research
areas in cognitive science, neuroscience, and machine learning. For example,
cognitive scientists measure the representational alignment of multiple
individuals to identify shared cognitive priors, neuroscientists align fMRI
responses from multiple individuals into a shared representational space for
group-level analyses, and ML researchers distill knowledge from teacher models
into student models by increasing their alignment. Unfortunately, there is
limited knowledge transfer between research communities interested in
representational alignment, so progress in one field often ends up being
rediscovered independently in another. Thus, greater cross-field communication
would be advantageous. To improve communication between these fields, we
propose a unifying framework that can serve as a common language between
researchers studying representational alignment. We survey the literature from
all three fields and demonstrate how prior work fits into this framework.
Finally, we lay out open problems in representational alignment where progress
can benefit all three of these fields. We hope that our work can catalyze
cross-disciplinary collaboration and accelerate progress for all communities
studying and developing information processing systems. We note that this is a
working paper and encourage readers to reach out with their suggestions for
future revisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sucholutsky_I/0/1/0/all/0/1&quot;&gt;Ilia Sucholutsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Muttenthaler_L/0/1/0/all/0/1&quot;&gt;Lukas Muttenthaler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Weller_A/0/1/0/all/0/1&quot;&gt;Adrian Weller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Peng_A/0/1/0/all/0/1&quot;&gt;Andi Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Bobu_A/0/1/0/all/0/1&quot;&gt;Andreea Bobu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Been Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Love_B/0/1/0/all/0/1&quot;&gt;Bradley C. Love&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Grant_E/0/1/0/all/0/1&quot;&gt;Erin Grant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Groen_I/0/1/0/all/0/1&quot;&gt;Iris Groen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Achterberg_J/0/1/0/all/0/1&quot;&gt;Jascha Achterberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Joshua B. Tenenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Collins_K/0/1/0/all/0/1&quot;&gt;Katherine M. Collins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hermann_K/0/1/0/all/0/1&quot;&gt;Katherine L. Hermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Oktar_K/0/1/0/all/0/1&quot;&gt;Kerem Oktar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Greff_K/0/1/0/all/0/1&quot;&gt;Klaus Greff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hebart_M/0/1/0/all/0/1&quot;&gt;Martin N. Hebart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Jacoby_N/0/1/0/all/0/1&quot;&gt;Nori Jacoby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qiuyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Marjieh_R/0/1/0/all/0/1&quot;&gt;Raja Marjieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Geirhos_R/0/1/0/all/0/1&quot;&gt;Robert Geirhos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Sherol Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kornblith_S/0/1/0/all/0/1&quot;&gt;Simon Kornblith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Rane_S/0/1/0/all/0/1&quot;&gt;Sunayana Rane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Konkle_T/0/1/0/all/0/1&quot;&gt;Talia Konkle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+OConnell_T/0/1/0/all/0/1&quot;&gt;Thomas P. O&amp;#x27;Connell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Unterthiner_T/0/1/0/all/0/1&quot;&gt;Thomas Unterthiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lampinen_A/0/1/0/all/0/1&quot;&gt;Andrew K. Lampinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Muller_K/0/1/0/all/0/1&quot;&gt;Klaus-Robert M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Toneva_M/0/1/0/all/0/1&quot;&gt;Mariya Toneva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Griffiths_T/0/1/0/all/0/1&quot;&gt;Thomas L. Griffiths&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.16917">
<title>MimicTouch: Learning Human&apos;s Control Strategy with Multi-Modal Tactile Feedback. (arXiv:2310.16917v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2310.16917</link>
<description rdf:parseType="Literal">&lt;p&gt;In robotics and artificial intelligence, the integration of tactile
processing is becoming increasingly pivotal, especially in learning to execute
intricate tasks like alignment and insertion. However, existing works focusing
on tactile methods for insertion tasks predominantly rely on robot
teleoperation data and reinforcement learning, which do not utilize the rich
insights provided by human&apos;s control strategy guided by tactile feedback. For
utilizing human sensations, methodologies related to learning from humans
predominantly leverage visual feedback, often overlooking the invaluable
tactile feedback that humans inherently employ to finish complex manipulations.
Addressing this gap, we introduce &quot;MimicTouch&quot;, a novel framework that mimics
human&apos;s tactile-guided control strategy. In this framework, we initially
collect multi-modal tactile datasets from human demonstrators, incorporating
human tactile-guided control strategies for task completion. The subsequent
step involves instructing robots through imitation learning using multi-modal
sensor data and retargeted human motions. To further mitigate the embodiment
gap between humans and robots, we employ online residual reinforcement learning
on the physical robot. Through comprehensive experiments, we validate the
safety of MimicTouch in transferring a latent policy learned through imitation
learning from human to robot. This ongoing work will pave the way for a broader
spectrum of tactile-guided robotic applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1&quot;&gt;Kelin Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yunhai Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Matthew Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Ye Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.17341">
<title>De-novo Chemical Reaction Generation by Means of Temporal Convolutional Neural Networks. (arXiv:2310.17341v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.17341</link>
<description rdf:parseType="Literal">&lt;p&gt;We present here a combination of two networks, Recurrent Neural Networks
(RNN) and Temporarily Convolutional Neural Networks (TCN) in de novo reaction
generation using the novel Reaction Smiles-like representation of reactions
(CGRSmiles) with atom mapping directly incorporated. Recurrent Neural Networks
are known for their autoregressive properties and are frequently used in
language modelling with direct application to SMILES generation. The relatively
novel TCNs possess similar properties with wide receptive field while obeying
the causality required for natural language processing (NLP). The combination
of both latent representations expressed through TCN and RNN results in an
overall better performance compared to RNN alone. Additionally, it is shown
that different fine-tuning protocols have a profound impact on generative scope
of the model when applied on a dataset of interest via transfer learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buin_A/0/1/0/all/0/1&quot;&gt;Andrei Buin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1&quot;&gt;Hung Yi Chiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gadsden_S/0/1/0/all/0/1&quot;&gt;S. Andrew Gadsden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alderson_F/0/1/0/all/0/1&quot;&gt;Faraz A. Alderson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.17403">
<title>Detection Defenses: An Empty Promise against Adversarial Patch Attacks on Optical Flow. (arXiv:2310.17403v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.17403</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial patches undermine the reliability of optical flow predictions
when placed in arbitrary scene locations. Therefore, they pose a realistic
threat to real-world motion detection and its downstream applications.
Potential remedies are defense strategies that detect and remove adversarial
patches, but their influence on the underlying motion prediction has not been
investigated. In this paper, we thoroughly examine the currently available
detect-and-remove defenses ILP and LGS for a wide selection of state-of-the-art
optical flow methods, and illuminate their side effects on the quality and
robustness of the final flow predictions. In particular, we implement
defense-aware attacks to investigate whether current defenses are able to
withstand attacks that take the defense mechanism into account. Our experiments
yield two surprising results: Detect-and-remove defenses do not only lower the
optical flow quality on benign scenes, in doing so, they also harm the
robustness under patch attacks for all tested optical flow methods except
FlowNetC. As currently employed detect-and-remove defenses fail to deliver the
promised adversarial robustness for optical flow, they evoke a false sense of
security. The code is available at
https://github.com/cv-stuttgart/DetectionDefenses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheurer_E/0/1/0/all/0/1&quot;&gt;Erik Scheurer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmalfuss_J/0/1/0/all/0/1&quot;&gt;Jenny Schmalfuss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lis_A/0/1/0/all/0/1&quot;&gt;Alexander Lis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruhn_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Bruhn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.18230">
<title>Deep Transformed Gaussian Processes. (arXiv:2310.18230v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.18230</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformed Gaussian Processes (TGPs) are stochastic processes specified by
transforming samples from the joint distribution from a prior process
(typically a GP) using an invertible transformation; increasing the flexibility
of the base process.
&lt;/p&gt;
&lt;p&gt;Furthermore, they achieve competitive results compared with Deep Gaussian
Processes (DGPs), which are another generalization constructed by a
hierarchical concatenation of GPs. In this work, we propose a generalization of
TGPs named Deep Transformed Gaussian Processes (DTGPs), which follows the trend
of concatenating layers of stochastic processes. More precisely, we obtain a
multi-layer model in which each layer is a TGP. This generalization implies an
increment of flexibility with respect to both TGPs and DGPs. Exact inference in
such a model is intractable. However, we show that one can use variational
inference to approximate the required computations yielding a straightforward
extension of the popular DSVI inference algorithm Salimbeni et al (2017). The
experiments conducted evaluate the proposed novel DTGPs in multiple regression
datasets, achieving good scalability and performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saez_Maldonado_F/0/1/0/all/0/1&quot;&gt;Francisco Javier S&amp;#xe1;ez-Maldonado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maronas_J/0/1/0/all/0/1&quot;&gt;Juan Maro&amp;#xf1;as&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1&quot;&gt;Daniel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.18348">
<title>Meaning Representations from Trajectories in Autoregressive Models. (arXiv:2310.18348v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.18348</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose to extract meaning representations from autoregressive language
models by considering the distribution of all possible trajectories extending
an input text. This strategy is prompt-free, does not require fine-tuning, and
is applicable to any pre-trained autoregressive model. Moreover, unlike
vector-based representations, distribution-based representations can also model
asymmetric relations (e.g., direction of logical entailment, hypernym/hyponym
relations) by using algebraic operations between likelihood functions. These
ideas are grounded in distributional perspectives on semantics and are
connected to standard constructions in automata theory, but to our knowledge
they have not been applied to modern language models. We empirically show that
the representations obtained from large models align well with human
annotations, outperform other zero-shot and prompt-free methods on semantic
similarity tasks, and can be used to solve more complex entailment and
containment tasks that standard embeddings cannot handle. Finally, we extend
our method to represent data from different modalities (e.g., image and text)
using multimodal autoregressive models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tian Yu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trager_M/0/1/0/all/0/1&quot;&gt;Matthew Trager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1&quot;&gt;Alessandro Achille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perera_P/0/1/0/all/0/1&quot;&gt;Pramuditha Perera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zancato_L/0/1/0/all/0/1&quot;&gt;Luca Zancato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1&quot;&gt;Stefano Soatto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.18477">
<title>Understanding and Improving Ensemble Adversarial Defense. (arXiv:2310.18477v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.18477</link>
<description rdf:parseType="Literal">&lt;p&gt;The strategy of ensemble has become popular in adversarial defense, which
trains multiple base classifiers to defend against adversarial attacks in a
cooperative manner. Despite the empirical success, theoretical explanations on
why an ensemble of adversarially trained classifiers is more robust than single
ones remain unclear. To fill in this gap, we develop a new error theory
dedicated to understanding ensemble adversarial defense, demonstrating a
provable 0-1 loss reduction on challenging sample sets in an adversarial
defense scenario. Guided by this theory, we propose an effective approach to
improve ensemble adversarial defense, named interactive global adversarial
training (iGAT). The proposal includes (1) a probabilistic distributing rule
that selectively allocates to different base classifiers adversarial examples
that are globally challenging to the ensemble, and (2) a regularization term to
rescue the severest weaknesses of the base classifiers. Being tested over
various existing ensemble adversarial defense techniques, iGAT is capable of
boosting their performance by increases up to 17% evaluated using CIFAR10 and
CIFAR100 datasets under both white-box and black-box attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yian Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1&quot;&gt;Tingting Mu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.19385">
<title>Gradient-free online learning of subgrid-scale dynamics with neural emulators. (arXiv:2310.19385v2 [physics.comp-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2310.19385</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a generic algorithm to train machine learning-based
subgrid parametrizations online, i.e., with $\textit{a posteriori}$ loss
functions for non-differentiable numerical solvers. The proposed approach
leverage neural emulators to train an approximation of the reduced state-space
solver, which is then used to allows gradient propagation through temporal
integration steps. The algorithm is able to recover most of the benefit of
online strategies without having to compute the gradient of the original
solver. It is demonstrated that training the neural emulator and
parametrization components separately with respective loss quantities is
necessary in order to minimize the propagation of some approximation bias.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Frezat_H/0/1/0/all/0/1&quot;&gt;Hugo Frezat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Fablet_R/0/1/0/all/0/1&quot;&gt;Ronan Fablet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Balarac_G/0/1/0/all/0/1&quot;&gt;Guillaume Balarac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Sommer_J/0/1/0/all/0/1&quot;&gt;Julien Le Sommer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.19793">
<title>On Learning Gaussian Multi-index Models with Gradient Flow. (arXiv:2310.19793v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2310.19793</link>
<description rdf:parseType="Literal">&lt;p&gt;We study gradient flow on the multi-index regression problem for
high-dimensional Gaussian data. Multi-index functions consist of a composition
of an unknown low-rank linear projection and an arbitrary unknown,
low-dimensional link function. As such, they constitute a natural template for
feature learning in neural networks.
&lt;/p&gt;
&lt;p&gt;We consider a two-timescale algorithm, whereby the low-dimensional link
function is learnt with a non-parametric model infinitely faster than the
subspace parametrizing the low-rank projection. By appropriately exploiting the
matrix semigroup structure arising over the subspace correlation matrices, we
establish global convergence of the resulting Grassmannian population gradient
flow dynamics, and provide a quantitative description of its associated
`saddle-to-saddle&apos; dynamics. Notably, the timescales associated with each
saddle can be explicitly characterized in terms of an appropriate Hermite
decomposition of the target link function. In contrast with these positive
results, we also show that the related \emph{planted} problem, where the link
function is known and fixed, in fact has a rough optimization landscape, in
which gradient flow dynamics might get trapped with high probability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1&quot;&gt;Alberto Bietti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bruna_J/0/1/0/all/0/1&quot;&gt;Joan Bruna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1&quot;&gt;Loucas Pillaud-Vivien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.20280">
<title>AutoMixer for Improved Multivariate Time-Series Forecasting on Business and IT Observability Data. (arXiv:2310.20280v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.20280</link>
<description rdf:parseType="Literal">&lt;p&gt;The efficiency of business processes relies on business key performance
indicators (Biz-KPIs), that can be negatively impacted by IT failures. Business
and IT Observability (BizITObs) data fuses both Biz-KPIs and IT event channels
together as multivariate time series data. Forecasting Biz-KPIs in advance can
enhance efficiency and revenue through proactive corrective measures. However,
BizITObs data generally exhibit both useful and noisy inter-channel
interactions between Biz-KPIs and IT events that need to be effectively
decoupled. This leads to suboptimal forecasting performance when existing
multivariate forecasting models are employed. To address this, we introduce
AutoMixer, a time-series Foundation Model (FM) approach, grounded on the novel
technique of channel-compressed pretrain and finetune workflows. AutoMixer
leverages an AutoEncoder for channel-compressed pretraining and integrates it
with the advanced TSMixer model for multivariate time series forecasting. This
fusion greatly enhances the potency of TSMixer for accurate forecasts and also
generalizes well across several downstream tasks. Through detailed experiments
and dashboard analytics, we show AutoMixer&apos;s capability to consistently improve
the Biz-KPI&apos;s forecasting accuracy (by 11-15\%) which directly translates to
actionable business insights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palaskar_S/0/1/0/all/0/1&quot;&gt;Santosh Palaskar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ekambaram_V/0/1/0/all/0/1&quot;&gt;Vijay Ekambaram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jati_A/0/1/0/all/0/1&quot;&gt;Arindam Jati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gantayat_N/0/1/0/all/0/1&quot;&gt;Neelamadhav Gantayat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1&quot;&gt;Avirup Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagar_S/0/1/0/all/0/1&quot;&gt;Seema Nagar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Nam H. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dayama_P/0/1/0/all/0/1&quot;&gt;Pankaj Dayama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sindhgatta_R/0/1/0/all/0/1&quot;&gt;Renuka Sindhgatta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohapatra_P/0/1/0/all/0/1&quot;&gt;Prateeti Mohapatra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_H/0/1/0/all/0/1&quot;&gt;Harshit Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalagnanam_J/0/1/0/all/0/1&quot;&gt;Jayant Kalagnanam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemachandra_N/0/1/0/all/0/1&quot;&gt;Nandyala Hemachandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rangaraj_N/0/1/0/all/0/1&quot;&gt;Narayan Rangaraj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00286">
<title>JADE: A Linguistics-based Safety Evaluation Platform for LLM. (arXiv:2311.00286v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.00286</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present JADE, a targeted linguistic fuzzing platform which
strengthens the linguistic complexity of seed questions to simultaneously and
consistently break a wide range of widely-used LLMs categorized in three
groups: eight open-sourced Chinese, six commercial Chinese and four commercial
English LLMs. JADE generates three safety benchmarks for the three groups of
LLMs, which contain unsafe questions that are highly threatening: the questions
simultaneously trigger harmful generation of multiple LLMs, with an average
unsafe generation ratio of $70\%$ (please see the table below), while are still
natural questions, fluent and preserving the core unsafe semantics. We release
the benchmark demos generated for commercial English LLMs and open-sourced
English LLMs in the following link: https://github.com/whitzard-ai/jade-db. For
readers who are interested in evaluating on more questions generated by JADE,
please contact us.
&lt;/p&gt;
&lt;p&gt;JADE is based on Noam Chomsky&apos;s seminal theory of transformational-generative
grammar. Given a seed question with unsafe intention, JADE invokes a sequence
of generative and transformational rules to increment the complexity of the
syntactic structure of the original question, until the safety guardrail is
broken. Our key insight is: Due to the complexity of human language, most of
the current best LLMs can hardly recognize the invariant evil from the infinite
number of different syntactic structures which form an unbound example space
that can never be fully covered. Technically, the generative/transformative
rules are constructed by native speakers of the languages, and, once developed,
can be used to automatically grow and transform the parse tree of a given
question, until the guardrail is broken. For more evaluation results and demo,
please check our website: https://whitzard-ai.github.io/jade.html.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1&quot;&gt;Xudong Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Min Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00489">
<title>Deep Neural Networks for Automatic Speaker Recognition Do Not Learn Supra-Segmental Temporal Features. (arXiv:2311.00489v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2311.00489</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep neural networks have shown impressive results in automatic speaker
recognition and related tasks, it is dissatisfactory how little is understood
about what exactly is responsible for these results. Part of the success has
been attributed in prior work to their capability to model supra-segmental
temporal information (SST), i.e., learn rhythmic-prosodic characteristics of
speech in addition to spectral features. In this paper, we (i) present and
apply a novel test to quantify to what extent the performance of
state-of-the-art neural networks for speaker recognition can be explained by
modeling SST; and (ii) present several means to force respective nets to focus
more on SST and evaluate their merits. We find that a variety of CNN- and
RNN-based neural network architectures for speaker recognition do not model SST
to any sufficient degree, even when forced. The results provide a highly
relevant basis for impactful future research into better exploitation of the
full speech signal and give insights into the inner workings of such networks,
enhancing explainability of deep learning for speech technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neururer_D/0/1/0/all/0/1&quot;&gt;Daniel Neururer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dellwo_V/0/1/0/all/0/1&quot;&gt;Volker Dellwo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1&quot;&gt;Thilo Stadelmann&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>