<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-09-07T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03202" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03219" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03224" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03227" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03229" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03231" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03232" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03237" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03238" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03239" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03241" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03242" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03244" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03245" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03246" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03249" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03251" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03279" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03292" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03307" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03315" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03318" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03322" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03350" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03351" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03354" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03360" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03386" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03409" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03426" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03437" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03439" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03440" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03447" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03450" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03451" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03468" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03469" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03487" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03530" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03531" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03535" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03537" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03544" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03557" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03561" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03569" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03579" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03581" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03607" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03616" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03619" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03631" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03648" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03659" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03664" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03665" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03671" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03672" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03694" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03702" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03707" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03710" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03720" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03730" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03731" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03748" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03754" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03755" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03759" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03770" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03779" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03780" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03791" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03797" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03800" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03808" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03812" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03818" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03824" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03825" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03827" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03831" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03835" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03837" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03839" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03842" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03843" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03847" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03851" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03873" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03876" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03879" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03883" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03886" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03891" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03893" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03905" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1907.04483" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2002.01444" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.10274" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.12591" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.02613" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.00115" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.06781" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.12191" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.12198" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2202.09671" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2203.09096" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.04151" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.12250" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.02231" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.03680" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.04521" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.08901" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.13008" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.16193" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.15341" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.01448" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.04031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.06566" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.04838" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.08272" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.14051" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.03428" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.04436" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.07853" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.08081" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.13746" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.01311" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.06104" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.09479" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.10226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.09241" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.06145" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.07019" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.08719" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.08754" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12760" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.13596" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06555" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09882" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.14971" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.00452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.00904" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02335" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04014" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.08643" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.09183" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.09199" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.13280" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.15116" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.15223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.16215" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.16360" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.16898" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.16900" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.01108" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.02428" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.02539" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.02556" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.02685" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.02976" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03169" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03190" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.02843" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2309.03202">
<title>Evaluation of Reinforcement Learning Techniques for Trading on a Diverse Portfolio. (arXiv:2309.03202v1 [q-fin.TR])</title>
<link>http://arxiv.org/abs/2309.03202</link>
<description rdf:parseType="Literal">&lt;p&gt;This work seeks to answer key research questions regarding the viability of
reinforcement learning over the S&amp;amp;P 500 index. The on-policy techniques of
Value Iteration (VI) and State-action-reward-state-action (SARSA) are
implemented along with the off-policy technique of Q-Learning. The models are
trained and tested on a dataset comprising multiple years of stock market data
from 2000-2023. The analysis presents the results and findings from training
and testing the models using two different time periods: one including the
COVID-19 pandemic years and one excluding them. The results indicate that
including market data from the COVID-19 period in the training dataset leads to
superior performance compared to the baseline strategies. During testing, the
on-policy approaches (VI and SARSA) outperform Q-learning, highlighting the
influence of bias-variance tradeoff and the generalization capabilities of
simpler policies. However, it is noted that the performance of Q-learning may
vary depending on the stability of future market conditions. Future work is
suggested, including experiments with updated Q-learning policies during
testing and trading diverse individual stocks. Additionally, the exploration of
alternative economic indicators for training the models is proposed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Khare_I/0/1/0/all/0/1&quot;&gt;Ishan S. Khare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Martheswaran_T/0/1/0/all/0/1&quot;&gt;Tarun K. Martheswaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Dassanaike_Perera_A/0/1/0/all/0/1&quot;&gt;Akshana Dassanaike-Perera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Ezekiel_J/0/1/0/all/0/1&quot;&gt;Jonah B. Ezekiel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03219">
<title>Companion Animal Disease Diagnostics based on Literal-aware Medical Knowledge Graph Representation Learning. (arXiv:2309.03219v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.03219</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graph (KG) embedding has been used to benefit the diagnosis of
animal diseases by analyzing electronic medical records (EMRs), such as notes
and veterinary records. However, learning representations to capture entities
and relations with literal information in KGs is challenging as the KGs show
heterogeneous properties and various types of literal information. Meanwhile,
the existing methods mostly aim to preserve graph structures surrounding target
nodes without considering different types of literals, which could also carry
significant information. In this paper, we propose a knowledge graph embedding
model for the efficient diagnosis of animal diseases, which could learn various
types of literal information and graph structure and fuse them into unified
representations, namely LiteralKG. Specifically, we construct a knowledge graph
that is built from EMRs along with literal information collected from various
animal hospitals. We then fuse different types of entities and node feature
information into unified vector representations through gate networks. Finally,
we propose a self-supervised learning task to learn graph structure in pretext
tasks and then towards various downstream tasks. Experimental results on link
prediction tasks demonstrate that our model outperforms the baselines that
consist of state-of-the-art models. The source code is available at
https://github.com/NSLab-CUK/LiteralKG.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_V/0/1/0/all/0/1&quot;&gt;Van Thuy Hoang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1&quot;&gt;Sang Thanh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sangmyeong Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jooho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1&quot;&gt;Luong Vuong Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_O/0/1/0/all/0/1&quot;&gt;O-Joun Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03223">
<title>Examining the Effectiveness of Chatbots in Gathering Family History Information in Comparison to the Standard In-Person Interview-Based Approach. (arXiv:2309.03223v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2309.03223</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the most common things that a genealogist is tasked with is the
gathering of a person&apos;s initial family history, normally via in-person
interviews or with the use of a platform such as ancestry.com, as this can
provide a strong foundation upon which a genealogist may build. However, the
ability to conduct these interviews can often be hindered by both geographical
constraints and the technical proficiency of the interviewee, as the
interviewee in these types of interviews is most often an elderly person with a
lower than average level of technical proficiency. With this in mind, this
study presents what we believe, based on prior research, to be the first
chatbot geared entirely towards the gathering of family histories, and explores
the viability of utilising such a chatbot by comparing the performance and
usability of such a method with the aforementioned alternatives. With a
chatbot-based approach, we show that, though the average time taken to conduct
an interview may be longer than if the user had used ancestry.com or
participated in an in-person interview, the number of mistakes made and the
level of confusion from the user regarding the UI and process required is lower
than the other two methods. Note that the final metric regarding the user&apos;s
confusion is not applicable for the in-person interview sessions due to its
lack of a UI. With refinement, we believe this use of a chatbot could be a
valuable tool for genealogists, especially when dealing with interviewees who
are based in other countries where it is not possible to conduct an in-person
interview.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drumm_K/0/1/0/all/0/1&quot;&gt;Kieron Drumm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1&quot;&gt;Vincent Tran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03224">
<title>No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. (arXiv:2309.03224v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.03224</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) exhibit impressive language understanding and
in-context learning abilities including natural language processing (NLP) tasks
and challenging mathematical reasoning. However, due to the lack of
process-supervision, applying PLMs to mathematical reasoning tasks often fail
to generate correct reasoning steps and final answer even though solutions have
high probabilities. To unleash the mathematical reasoning of finetuned-LLMs
without any further fineutuning steps, we propose a method to endow LLMs with
immediate reaction and delicate reasoning system via Monte Carlo Tree
Search(MCTS) and a light energy function to rank the decision steps. In
particular, We first re-formalize the finetuned-LLMs to a Residual-based Energy
Model~(Residual-EBM) and apply noise contrastive estimation to estimate the
parameters of energy function . Then we use MCTS with energy function as path
verifier to search the output space and evaluating the reasoning path. Through
extensive experiments on two mathematical reasoning benchmarks, namely GSM8k
and MATH, we reveal the extraordinary capabilities of our method that improve
the pass@1 of the finetuned-model without further finetuning or RLHF alignment
by a substantial margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Haotian Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03227">
<title>Learning a Patent-Informed Biomedical Knowledge Graph Reveals Technological Potential of Drug Repositioning Candidates. (arXiv:2309.03227v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.03227</link>
<description rdf:parseType="Literal">&lt;p&gt;Drug repositioning-a promising strategy for discovering new therapeutic uses
for existing drugs-has been increasingly explored in the computational science
literature using biomedical databases. However, the technological potential of
drug repositioning candidates has often been overlooked. This study presents a
novel protocol to comprehensively analyse various sources such as
pharmaceutical patents and biomedical databases, and identify drug
repositioning candidates with both technological potential and scientific
evidence. To this end, first, we constructed a scientific biomedical knowledge
graph (s-BKG) comprising relationships between drugs, diseases, and genes
derived from biomedical databases. Our protocol involves identifying drugs that
exhibit limited association with the target disease but are closely located in
the s-BKG, as potential drug candidates. We constructed a patent-informed
biomedical knowledge graph (p-BKG) by adding pharmaceutical patent information.
Finally, we developed a graph embedding protocol to ascertain the structure of
the p-BKG, thereby calculating the relevance scores of those candidates with
target disease-related patents to evaluate their technological potential. Our
case study on Alzheimer&apos;s disease demonstrates its efficacy and feasibility,
while the quantitative outcomes and systematic methods are expected to bridge
the gap between computational discoveries and successful market applications in
drug repositioning research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jegal_Y/0/1/0/all/0/1&quot;&gt;Yongseung Jegal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jaewoong Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jiho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1&quot;&gt;Ki-Su Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seyoung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Janghyeok Yoon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03229">
<title>Which algorithm to select in sports timetabling?. (arXiv:2309.03229v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.03229</link>
<description rdf:parseType="Literal">&lt;p&gt;Any sports competition needs a timetable, specifying when and where teams
meet each other. The recent International Timetabling Competition (ITC2021) on
sports timetabling showed that, although it is possible to develop general
algorithms, the performance of each algorithm varies considerably over the
problem instances. This paper provides an instance space analysis for sports
timetabling, resulting in powerful insights into the strengths and weaknesses
of eight state-of-the-art algorithms. Based on machine learning techniques, we
propose an algorithm selection system that predicts which algorithm is likely
to perform best when given the characteristics of a sports timetabling problem
instance. Furthermore, we identify which characteristics are important in
making that prediction, providing insights in the performance of the
algorithms, and suggestions to further improve them. Finally, we assess the
empirical hardness of the instances. Our results are based on large
computational experiments involving about 50 years of CPU time on more than 500
newly generated problem instances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bulck_D/0/1/0/all/0/1&quot;&gt;David Van Bulck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goossens_D/0/1/0/all/0/1&quot;&gt;Dries Goossens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clarner_J/0/1/0/all/0/1&quot;&gt;Jan-Patrick Clarner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dimitsas_A/0/1/0/all/0/1&quot;&gt;Angelos Dimitsas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonseca_G/0/1/0/all/0/1&quot;&gt;George H. G. Fonseca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamas_Fernandez_C/0/1/0/all/0/1&quot;&gt;Carlos Lamas-Fernandez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lester_M/0/1/0/all/0/1&quot;&gt;Martin Mariusz Lester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedersen_J/0/1/0/all/0/1&quot;&gt;Jaap Pedersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_A/0/1/0/all/0/1&quot;&gt;Antony E. Phillips&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosati_R/0/1/0/all/0/1&quot;&gt;Roberto Maria Rosati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03231">
<title>Quantum-AI empowered Intelligent Surveillance: Advancing Public Safety Through Innovative Contraband Detection. (arXiv:2309.03231v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2309.03231</link>
<description rdf:parseType="Literal">&lt;p&gt;Surveillance systems have emerged as crucial elements in upholding peace and
security in the modern world. Their ubiquity aids in monitoring suspicious
activities effectively. However, in densely populated environments, continuous
active monitoring becomes impractical, necessitating the development of
intelligent surveillance systems. AI integration in the surveillance domain was
a big revolution, however, speed issues have prevented its widespread
implementation in the field. It has been observed that quantum artificial
intelligence has led to a great breakthrough. Quantum artificial
intelligence-based surveillance systems have shown to be more accurate as well
as capable of performing well in real-time scenarios, which had never been seen
before. In this research, a RentinaNet model is integrated with Quantum CNN and
termed as Quantum-RetinaNet. By harnessing the Quantum capabilities of QCNN,
Quantum-RetinaNet strikes a balance between accuracy and speed. This innovative
integration positions it as a game-changer, addressing the challenges of active
monitoring in densely populated scenarios. As demand for efficient surveillance
solutions continues to grow, Quantum-RetinaNet offers a compelling alternative
to existing CNN models, upholding accuracy standards without sacrificing
real-time performance. The unique attributes of Quantum-RetinaNet have
far-reaching implications for the future of intelligent surveillance. With its
enhanced processing speed, it is poised to revolutionize the field, catering to
the pressing need for rapid yet precise monitoring. As Quantum-RetinaNet
becomes the new standard, it ensures public safety and security while pushing
the boundaries of AI in surveillance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Shah_S/0/1/0/all/0/1&quot;&gt;Syed Atif Ali Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Algeelani_N/0/1/0/all/0/1&quot;&gt;Nasir Algeelani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Al_Sammarraie_N/0/1/0/all/0/1&quot;&gt;Najeeb Al-Sammarraie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03232">
<title>Retail store customer behavior analysis system: Design and Implementation. (arXiv:2309.03232v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03232</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding customer behavior in retail stores plays a crucial role in
improving customer satisfaction by adding personalized value to services.
Behavior analysis reveals both general and detailed patterns in the interaction
of customers with a store items and other people, providing store managers with
insight into customer preferences. Several solutions aim to utilize this data
by recognizing specific behaviors through statistical visualization. However,
current approaches are limited to the analysis of small customer behavior sets,
utilizing conventional methods to detect behaviors. They do not use deep
learning techniques such as deep neural networks, which are powerful methods in
the field of computer vision. Furthermore, these methods provide limited
figures when visualizing the behavioral data acquired by the system. In this
study, we propose a framework that includes three primary parts: mathematical
modeling of customer behaviors, behavior analysis using an efficient deep
learning based system, and individual and group behavior visualization. Each
module and the entire system were validated using data from actual situations
in a retail store.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Tuan Dinh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hihara_K/0/1/0/all/0/1&quot;&gt;Keisuke Hihara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1&quot;&gt;Tung Cao Hoang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Utada_Y/0/1/0/all/0/1&quot;&gt;Yumeka Utada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torii_A/0/1/0/all/0/1&quot;&gt;Akihiko Torii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izumi_N/0/1/0/all/0/1&quot;&gt;Naoki Izumi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thuy_N/0/1/0/all/0/1&quot;&gt;Nguyen Thanh Thuy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_L/0/1/0/all/0/1&quot;&gt;Long Quoc Tran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03234">
<title>Natural Example-Based Explainability: a Survey. (arXiv:2309.03234v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.03234</link>
<description rdf:parseType="Literal">&lt;p&gt;Explainable Artificial Intelligence (XAI) has become increasingly significant
for improving the interpretability and trustworthiness of machine learning
models. While saliency maps have stolen the show for the last few years in the
XAI field, their ability to reflect models&apos; internal processes has been
questioned. Although less in the spotlight, example-based XAI methods have
continued to improve. It encompasses methods that use examples as explanations
for a machine learning model&apos;s predictions. This aligns with the psychological
mechanisms of human reasoning and makes example-based explanations natural and
intuitive for users to understand. Indeed, humans learn and reason by forming
mental representations of concepts based on examples.
&lt;/p&gt;
&lt;p&gt;This paper provides an overview of the state-of-the-art in natural
example-based XAI, describing the pros and cons of each approach. A &quot;natural&quot;
example simply means that it is directly drawn from the training data without
involving any generative process. The exclusion of methods that require
generating examples is justified by the need for plausibility which is in some
regards required to gain a user&apos;s trust. Consequently, this paper will explore
the following family of methods: similar examples, counterfactual and
semi-factual, influential instances, prototypes, and concepts. In particular,
it will compare their semantic definition, their cognitive impact, and added
values. We hope it will encourage and facilitate future work on natural
example-based XAI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poche_A/0/1/0/all/0/1&quot;&gt;Antonin Poch&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hervier_L/0/1/0/all/0/1&quot;&gt;Lucas Hervier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bakkay_M/0/1/0/all/0/1&quot;&gt;Mohamed-Chafik Bakkay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03237">
<title>Federated Learning Over Images: Vertical Decompositions and Pre-Trained Backbones Are Difficult to Beat. (arXiv:2309.03237v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03237</link>
<description rdf:parseType="Literal">&lt;p&gt;We carefully evaluate a number of algorithms for learning in a federated
environment, and test their utility for a variety of image classification
tasks. We consider many issues that have not been adequately considered before:
whether learning over data sets that do not have diverse sets of images affects
the results; whether to use a pre-trained feature extraction &quot;backbone&quot;; how to
evaluate learner performance (we argue that classification accuracy is not
enough), among others. Overall, across a wide variety of settings, we find that
vertically decomposing a neural network seems to give the best results, and
outperforms more standard reconciliation-used methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1&quot;&gt;Erdong Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yuxin Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jermaine_C/0/1/0/all/0/1&quot;&gt;Chris Jermaine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03238">
<title>Implicit Design Choices and Their Impact on Emotion Recognition Model Development and Evaluation. (arXiv:2309.03238v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03238</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotion recognition is a complex task due to the inherent subjectivity in
both the perception and production of emotions. The subjectivity of emotions
poses significant challenges in developing accurate and robust computational
models. This thesis examines critical facets of emotion recognition, beginning
with the collection of diverse datasets that account for psychological factors
in emotion production.
&lt;/p&gt;
&lt;p&gt;To handle the challenge of non-representative training data, this work
collects the Multimodal Stressed Emotion dataset, which introduces controlled
stressors during data collection to better represent real-world influences on
emotion production. To address issues with label subjectivity, this research
comprehensively analyzes how data augmentation techniques and annotation
schemes impact emotion perception and annotator labels. It further handles
natural confounding variables and variations by employing adversarial networks
to isolate key factors like stress from learned emotion representations during
model training. For tackling concerns about leakage of sensitive demographic
variables, this work leverages adversarial learning to strip sensitive
demographic information from multimodal encodings. Additionally, it proposes
optimized sociological evaluation metrics aligned with cost-effective,
real-world needs for model testing.
&lt;/p&gt;
&lt;p&gt;This research advances robust, practical emotion recognition through
multifaceted studies of challenges in datasets, labels, modeling, demographic
and membership variable encoding in representations, and evaluation. The
groundwork has been laid for cost-effective, generalizable emotion recognition
models that are less likely to encode sensitive demographic information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaiswal_M/0/1/0/all/0/1&quot;&gt;Mimansa Jaiswal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03239">
<title>Spatio-Temporal Contrastive Self-Supervised Learning for POI-level Crowd Flow Inference. (arXiv:2309.03239v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03239</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate acquisition of crowd flow at Points of Interest (POIs) is pivotal
for effective traffic management, public service, and urban planning. Despite
this importance, due to the limitations of urban sensing techniques, the data
quality from most sources is inadequate for monitoring crowd flow at each POI.
This renders the inference of accurate crowd flow from low-quality data a
critical and challenging task. The complexity is heightened by three key
factors: 1) \emph{The scarcity and rarity of labeled data}, 2) \emph{The
intricate spatio-temporal dependencies among POIs}, and 3) \emph{The myriad
correlations between precise crowd flow and GPS reports}.
&lt;/p&gt;
&lt;p&gt;To address these challenges, we recast the crowd flow inference problem as a
self-supervised attributed graph representation learning task and introduce a
novel \underline{C}ontrastive \underline{S}elf-learning framework for
\underline{S}patio-\underline{T}emporal data (\model). Our approach initiates
with the construction of a spatial adjacency graph founded on the POIs and
their respective distances. We then employ a contrastive learning technique to
exploit large volumes of unlabeled spatio-temporal data. We adopt a swapped
prediction approach to anticipate the representation of the target subgraph
from similar instances. Following the pre-training phase, the model is
fine-tuned with accurate crowd flow data. Our experiments, conducted on two
real-world datasets, demonstrate that the \model pre-trained on extensive noisy
data consistently outperforms models trained from scratch.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_S/0/1/0/all/0/1&quot;&gt;Songyu Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Ting Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Li Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanping Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Qintian Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Junbo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yu Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03241">
<title>GPT Can Solve Mathematical Problems Without a Calculator. (arXiv:2309.03241v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03241</link>
<description rdf:parseType="Literal">&lt;p&gt;Previous studies have typically assumed that large language models are unable
to accurately perform arithmetic operations, particularly multiplication of &amp;gt;8
digits, and operations involving decimals and fractions, without the use of
calculator tools. This paper aims to challenge this misconception. With
sufficient training data, a 2 billion-parameter language model can accurately
perform multi-digit arithmetic operations with almost 100% accuracy without
data leakage, significantly surpassing GPT-4 (whose multi-digit multiplication
accuracy is only 4.3%). We also demonstrate that our MathGLM, fine-tuned from
GLM-10B on a dataset with additional multi-step arithmetic operations and math
problems described in text, achieves similar performance to GPT-4 on a
5,000-samples Chinese math problem test set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Ming Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_Q/0/1/0/all/0/1&quot;&gt;Qingsong Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Zhihuan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zehai He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yuyi Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1&quot;&gt;Jinfeng Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03242">
<title>Automated Bioinformatics Analysis via AutoBA. (arXiv:2309.03242v1 [q-bio.GN])</title>
<link>http://arxiv.org/abs/2309.03242</link>
<description rdf:parseType="Literal">&lt;p&gt;With the fast-growing and evolving omics data, the demand for streamlined and
adaptable tools to handle the analysis continues to grow. In response to this
need, we introduce Auto Bioinformatics Analysis (AutoBA), an autonomous AI
agent based on a large language model designed explicitly for conventional
omics data analysis. AutoBA simplifies the analytical process by requiring
minimal user input while delivering detailed step-by-step plans for various
bioinformatics tasks. Through rigorous validation by expert bioinformaticians,
AutoBA&apos;s robustness and adaptability are affirmed across a diverse range of
omics analysis cases, including whole genome sequencing (WGS), RNA sequencing
(RNA-seq), single-cell RNA-seq, ChIP-seq, and spatial transcriptomics. AutoBA&apos;s
unique capacity to self-design analysis processes based on input data
variations further underscores its versatility. Compared with online
bioinformatic services, AutoBA deploys the analysis locally, preserving data
privacy. Moreover, different from the predefined pipeline, AutoBA has
adaptability in sync with emerging bioinformatics tools. Overall, AutoBA
represents a convenient tool, offering robustness and adaptability for complex
omics data analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Juexiao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiuying Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haoyang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Xiaopeng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Siyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gao_X/0/1/0/all/0/1&quot;&gt;Xin Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03244">
<title>EGIC: Enhanced Low-Bit-Rate Generative Image Compression Guided by Semantic Segmentation. (arXiv:2309.03244v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.03244</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce EGIC, a novel generative image compression method that allows
traversing the distortion-perception curve efficiently from a single model.
Specifically, we propose an implicitly encoded variant of image interpolation
that predicts the residual between a MSE-optimized and GAN-optimized decoder
output. On the receiver side, the user can then control the impact of the
residual on the GAN-based reconstruction. Together with improved GAN-based
building blocks, EGIC outperforms a wide-variety of perception-oriented and
distortion-oriented baselines, including HiFiC, MRIC and DIRAC, while
performing almost on par with VTM-20.0 on the distortion end. EGIC is simple to
implement, very lightweight (e.g. 0.18x model parameters compared to HiFiC) and
provides excellent interpolation characteristics, which makes it a promising
candidate for practical applications targeting the low bit range.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Korber_N/0/1/0/all/0/1&quot;&gt;Nikolai K&amp;#xf6;rber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kromer_E/0/1/0/all/0/1&quot;&gt;Eduard Kromer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Siebert_A/0/1/0/all/0/1&quot;&gt;Andreas Siebert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hauke_S/0/1/0/all/0/1&quot;&gt;Sascha Hauke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mueller_Gritschneder_D/0/1/0/all/0/1&quot;&gt;Daniel Mueller-Gritschneder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03245">
<title>Testing properties of distributions in the streaming model. (arXiv:2309.03245v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2309.03245</link>
<description rdf:parseType="Literal">&lt;p&gt;We study distribution testing in the standard access model and the
conditional access model when the memory available to the testing algorithm is
bounded. In both scenarios, the samples appear in an online fashion and the
goal is to test the properties of distribution using an optimal number of
samples subject to a memory constraint on how many samples can be stored at a
given time. First, we provide a trade-off between the sample complexity and the
space complexity for testing identity when the samples are drawn according to
the conditional access oracle. We then show that we can learn a succinct
representation of a monotone distribution efficiently with a memory constraint
on the number of samples that are stored that is almost optimal. We also show
that the algorithm for monotone distributions can be extended to a larger class
of decomposable distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sampriti Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasudev_Y/0/1/0/all/0/1&quot;&gt;Yadu Vasudev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03246">
<title>EvoCLINICAL: Evolving Cyber-Cyber Digital Twin with Active Transfer Learning for Automated Cancer Registry System. (arXiv:2309.03246v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03246</link>
<description rdf:parseType="Literal">&lt;p&gt;The Cancer Registry of Norway (CRN) collects information on cancer patients
by receiving cancer messages from different medical entities (e.g., medical
labs, and hospitals) in Norway. Such messages are validated by an automated
cancer registry system: GURI. Its correct operation is crucial since it lays
the foundation for cancer research and provides critical cancer-related
statistics to its stakeholders. Constructing a cyber-cyber digital twin (CCDT)
for GURI can facilitate various experiments and advanced analyses of the
operational state of GURI without requiring intensive interactions with the
real system. However, GURI constantly evolves due to novel medical diagnostics
and treatment, technological advances, etc. Accordingly, CCDT should evolve as
well to synchronize with GURI. A key challenge of achieving such
synchronization is that evolving CCDT needs abundant data labelled by the new
GURI. To tackle this challenge, we propose EvoCLINICAL, which considers the
CCDT developed for the previous version of GURI as the pretrained model and
fine-tunes it with the dataset labelled by querying a new GURI version.
EvoCLINICAL employs a genetic algorithm to select an optimal subset of cancer
messages from a candidate dataset and query GURI with it. We evaluate
EvoCLINICAL on three evolution processes. The precision, recall, and F1 score
are all greater than 91%, demonstrating the effectiveness of EvoCLINICAL.
Furthermore, we replace the active learning part of EvoCLINICAL with random
selection to study the contribution of transfer learning to the overall
performance of EvoCLINICAL. Results show that employing active learning in
EvoCLINICAL increases its performances consistently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Chengjie Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1&quot;&gt;Qinghua Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_T/0/1/0/all/0/1&quot;&gt;Tao Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1&quot;&gt;Shaukat Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwitalla_T/0/1/0/all/0/1&quot;&gt;Thomas Schwitalla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nygaard_J/0/1/0/all/0/1&quot;&gt;Jan F. Nyg&amp;#xe5;rd&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03249">
<title>Graph Theory Applications in Advanced Geospatial Research. (arXiv:2309.03249v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03249</link>
<description rdf:parseType="Literal">&lt;p&gt;Geospatial sciences include a wide range of applications, from environmental
monitoring transportation to infrastructure planning, as well as location-based
analysis and services. Graph theory algorithms in mathematics have emerged as
indispensable tools in these domains due to their capability to model and
analyse spatial relationships efficiently. This technical report explores the
applications of graph theory algorithms in geospatial sciences, highlighting
their role in network analysis, spatial connectivity, geographic information
systems, and various other spatial problem-solving scenarios. It provides a
comprehensive idea about the key concepts and algorithms of graph theory that
assist the modelling processes. The report provides insights into the practical
significance of graph theory in addressing real-world geospatial challenges and
opportunities. It lists the extensive research, innovative technologies and
methodologies implemented in this field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Surajit Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mallick_A/0/1/0/all/0/1&quot;&gt;Archita Mallick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1&quot;&gt;Anuva Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_K/0/1/0/all/0/1&quot;&gt;Kounik De Sarkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03251">
<title>Temporal Inductive Path Neural Network for Temporal Knowledge Graph Reasoning. (arXiv:2309.03251v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.03251</link>
<description rdf:parseType="Literal">&lt;p&gt;Temporal Knowledge Graph (TKG) is an extension of traditional Knowledge Graph
(KG) that incorporates the dimension of time. Reasoning on TKGs is a crucial
task that aims to predict future facts based on historical occurrences. The key
challenge lies in uncovering structural dependencies within historical
subgraphs and temporal patterns. Most existing approaches model TKGs relying on
entity modeling, as nodes in the graph play a crucial role in knowledge
representation. However, the real-world scenario often involves an extensive
number of entities, with new entities emerging over time. This makes it
challenging for entity-dependent methods to cope with extensive volumes of
entities, and effectively handling newly emerging entities also becomes a
significant challenge. Therefore, we propose Temporal Inductive Path Neural
Network (TiPNN), which models historical information in an entity-independent
perspective. Specifically, TiPNN adopts a unified graph, namely history
temporal graph, to comprehensively capture and encapsulate information from
history. Subsequently, we utilize the defined query-aware temporal paths to
model historical path information related to queries on history temporal graph
for the reasoning. Extensive experiments illustrate that the proposed model not
only attains significant performance enhancements but also handles inductive
settings, while additionally facilitating the provision of reasoning evidence
through history temporal graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1&quot;&gt;Hao Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Pengyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1&quot;&gt;Meng Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Pengfei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuanchun Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03279">
<title>Let Quantum Neural Networks Choose Their Own Frequencies. (arXiv:2309.03279v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2309.03279</link>
<description rdf:parseType="Literal">&lt;p&gt;Parameterized quantum circuits as machine learning models are typically well
described by their representation as a partial Fourier series of the input
features, with frequencies uniquely determined by the feature map&apos;s generator
Hamiltonians. Ordinarily, these data-encoding generators are chosen in advance,
fixing the space of functions that can be represented. In this work we consider
a generalization of quantum models to include a set of trainable parameters in
the generator, leading to a trainable frequency (TF) quantum model. We
numerically demonstrate how TF models can learn generators with desirable
properties for solving the task at hand, including non-regularly spaced
frequencies in their spectra and flexible spectral richness. Finally, we
showcase the real-world effectiveness of our approach, demonstrating an
improved accuracy in solving the Navier-Stokes equations using a TF model with
only a single parameter added to each encoding operation. Since TF models
encompass conventional fixed frequency models, they may offer a sensible
default choice for variational quantum machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jaderberg_B/0/1/0/all/0/1&quot;&gt;Ben Jaderberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gentile_A/0/1/0/all/0/1&quot;&gt;Antonio A. Gentile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Berrada_Y/0/1/0/all/0/1&quot;&gt;Youssef Achari Berrada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Shishenina_E/0/1/0/all/0/1&quot;&gt;Elvira Shishenina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Elfving_V/0/1/0/all/0/1&quot;&gt;Vincent E. Elfving&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03292">
<title>Scalable Learning of Intrusion Responses through Recursive Decomposition. (arXiv:2309.03292v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2309.03292</link>
<description rdf:parseType="Literal">&lt;p&gt;We study automated intrusion response for an IT infrastructure and formulate
the interaction between an attacker and a defender as a partially observed
stochastic game. To solve the game we follow an approach where attack and
defense strategies co-evolve through reinforcement learning and self-play
toward an equilibrium. Solutions proposed in previous work prove the
feasibility of this approach for small infrastructures but do not scale to
realistic scenarios due to the exponential growth in computational complexity
with the infrastructure size. We address this problem by introducing a method
that recursively decomposes the game into subgames which can be solved in
parallel. Applying optimal stopping theory we show that the best response
strategies in these subgames exhibit threshold structures, which allows us to
compute them efficiently. To solve the decomposed game we introduce an
algorithm called Decompositional Fictitious Self-Play (DFSP), which learns Nash
equilibria through stochastic approximation. We evaluate the learned strategies
in an emulation environment where real intrusions and response actions can be
executed. The results show that the learned strategies approximate an
equilibrium and that DFSP significantly outperforms a state-of-the-art
algorithm for a realistic infrastructure configuration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hammar_K/0/1/0/all/0/1&quot;&gt;Kim Hammar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Stadler_R/0/1/0/all/0/1&quot;&gt;Rolf Stadler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03307">
<title>Generating quantum feature maps using multi-objective genetic algorithm. (arXiv:2309.03307v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2309.03307</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel approach for efficiently generating quantum feature maps
for quantum-enhanced support vector machines, a kernel-based classifier,
enabling access to high-dimensional Hilbert space. Our method employs a
multi-objective genetic algorithm that simultaneously maximizes classification
accuracy while minimizing both the local and non-local gate costs of the
quantum feature map&apos;s circuit. To achieve this, we define distinct fitness
functions for local gates and entanglement gates. Comparisons with classical
classifiers are given in order to understand the advantages of using quantum
machine learning. Surprisingly, our experiments reveal that the optimal
configuration of quantum circuits for the quantum kernel method incorporates a
proportional number of non-local gates for entanglement, contrary to previous
literature where non-local gates were largely suppressed.
&lt;/p&gt;
&lt;p&gt;Furthermore, we demonstrate that the separability indexes of data can be
effectively leveraged to determine the number of non-local gates required for
the quantum support vector machine&apos;s feature maps. This insight can
significantly aid in selecting appropriate parameters, such as the entanglement
parameter, in various quantum programming packages like quiskit.org based on
data analysis. Our findings offer valuable guidance for enhancing the
efficiency and accuracy of quantum machine learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haiyan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bayro_A/0/1/0/all/0/1&quot;&gt;Allison Bayro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yamamoto_N/0/1/0/all/0/1&quot;&gt;Nao Yamamoto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03315">
<title>Robotic Table Tennis: A Case Study into a High Speed Learning System. (arXiv:2309.03315v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.03315</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a deep-dive into a real-world robotic learning system that, in
previous work, was shown to be capable of hundreds of table tennis rallies with
a human and has the ability to precisely return the ball to desired targets.
This system puts together a highly optimized perception subsystem, a high-speed
low-latency robot controller, a simulation paradigm that can prevent damage in
the real world and also train policies for zero-shot transfer, and automated
real world environment resets that enable autonomous training and evaluation on
physical robots. We complement a complete system description, including
numerous design decisions that are typically not widely disseminated, with a
collection of studies that clarify the importance of mitigating various sources
of latency, accounting for training and deployment distribution shifts,
robustness of the perception system, sensitivity to policy hyper-parameters,
and choice of action space. A video demonstrating the components of the system
and details of experimental results can be found at
https://youtu.be/uFcnWjB42I0.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DAmbrosio_D/0/1/0/all/0/1&quot;&gt;David B. D&amp;#x27;Ambrosio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abelian_J/0/1/0/all/0/1&quot;&gt;Jonathan Abelian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abeyruwan_S/0/1/0/all/0/1&quot;&gt;Saminda Abeyruwan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_M/0/1/0/all/0/1&quot;&gt;Michael Ahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bewley_A/0/1/0/all/0/1&quot;&gt;Alex Bewley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boyd_J/0/1/0/all/0/1&quot;&gt;Justin Boyd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1&quot;&gt;Krzysztof Choromanski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cortes_O/0/1/0/all/0/1&quot;&gt;Omar Cortes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coumans_E/0/1/0/all/0/1&quot;&gt;Erwin Coumans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1&quot;&gt;Tianli Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wenbo Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graesser_L/0/1/0/all/0/1&quot;&gt;Laura Graesser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iscen_A/0/1/0/all/0/1&quot;&gt;Atil Iscen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaitly_N/0/1/0/all/0/1&quot;&gt;Navdeep Jaitly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1&quot;&gt;Deepali Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kangaspunta_J/0/1/0/all/0/1&quot;&gt;Juhana Kangaspunta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kataoka_S/0/1/0/all/0/1&quot;&gt;Satoshi Kataoka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kouretas_G/0/1/0/all/0/1&quot;&gt;Gus Kouretas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuang_Y/0/1/0/all/0/1&quot;&gt;Yuheng Kuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazic_N/0/1/0/all/0/1&quot;&gt;Nevena Lazic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lynch_C/0/1/0/all/0/1&quot;&gt;Corey Lynch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahjourian_R/0/1/0/all/0/1&quot;&gt;Reza Mahjourian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_S/0/1/0/all/0/1&quot;&gt;Sherry Q. Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thinh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oslund_K/0/1/0/all/0/1&quot;&gt;Ken Oslund&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reed_B/0/1/0/all/0/1&quot;&gt;Barney J Reed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reymann_K/0/1/0/all/0/1&quot;&gt;Krista Reymann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanketi_P/0/1/0/all/0/1&quot;&gt;Pannag R. Sanketi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shankar_A/0/1/0/all/0/1&quot;&gt;Anish Shankar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sermanet_P/0/1/0/all/0/1&quot;&gt;Pierre Sermanet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sindhwani_V/0/1/0/all/0/1&quot;&gt;Vikas Sindhwani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Avi Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanhoucke_V/0/1/0/all/0/1&quot;&gt;Vincent Vanhoucke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vesom_G/0/1/0/all/0/1&quot;&gt;Grace Vesom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Peng Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03318">
<title>Fitness Approximation through Machine Learning. (arXiv:2309.03318v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2309.03318</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel approach to performing fitness approximation in genetic
algorithms (GAs) using machine-learning (ML) models, focusing on evolutionary
agents in Gymnasium (game) simulators -- where fitness computation is costly.
Maintaining a dataset of sampled individuals along with their actual fitness
scores, we continually update throughout an evolutionary run a
fitness-approximation ML model. We compare different methods for: 1) switching
between actual and approximate fitness, 2) sampling the population, and 3)
weighting the samples. Experimental findings demonstrate significant
improvement in evolutionary runtimes, with fitness scores that are either
identical or slightly lower than that of the fully run GA -- depending on the
ratio of approximate-to-actual-fitness computation. Our approach is generic and
can be easily applied to many different domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzruia_I/0/1/0/all/0/1&quot;&gt;Itai Tzruia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halperin_T/0/1/0/all/0/1&quot;&gt;Tomer Halperin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sipper_M/0/1/0/all/0/1&quot;&gt;Moshe Sipper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elyasaf_A/0/1/0/all/0/1&quot;&gt;Achiya Elyasaf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03322">
<title>REBOOT: Reuse Data for Bootstrapping Efficient Real-World Dexterous Manipulation. (arXiv:2309.03322v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03322</link>
<description rdf:parseType="Literal">&lt;p&gt;Dexterous manipulation tasks involving contact-rich interactions pose a
significant challenge for both model-based control systems and imitation
learning algorithms. The complexity arises from the need for multi-fingered
robotic hands to dynamically establish and break contacts, balance
non-prehensile forces, and control large degrees of freedom. Reinforcement
learning (RL) offers a promising approach due to its general applicability and
capacity to autonomously acquire optimal manipulation strategies. However, its
real-world application is often hindered by the necessity to generate a large
number of samples, reset the environment, and obtain reward signals. In this
work, we introduce an efficient system for learning dexterous manipulation
skills with RL to alleviate these challenges. The main idea of our approach is
the integration of recent advances in sample-efficient RL and replay buffer
bootstrapping. This combination allows us to utilize data from different tasks
or objects as a starting point for training new tasks, significantly improving
learning efficiency. Additionally, our system completes the real-world training
cycle by incorporating learned resets via an imitation-based pickup policy as
well as learned reward functions, eliminating the need for manual resets and
reward engineering. We demonstrate the benefits of reusing past data as replay
buffer initialization for new tasks, for instance, the fast acquisition of
intricate manipulation skills in the real world on a four-fingered robotic
hand. (Videos: https://sites.google.com/view/reboot-dexterous)
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zheyuan Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rovinsky_A/0/1/0/all/0/1&quot;&gt;Aaron Rovinsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1&quot;&gt;Jianlan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vikash Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03350">
<title>Relay Diffusion: Unifying diffusion process across resolutions for image synthesis. (arXiv:2309.03350v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03350</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models achieved great success in image synthesis, but still face
challenges in high-resolution generation. Through the lens of discrete cosine
transformation, we find the main reason is that \emph{the same noise level on a
higher resolution results in a higher Signal-to-Noise Ratio in the frequency
domain}. In this work, we present Relay Diffusion Model (RDM), which transfers
a low-resolution image or noise into an equivalent high-resolution one for
diffusion model via blurring diffusion and block noise. Therefore, the
diffusion process can continue seamlessly in any new resolution or model
without restarting from pure noise or low-resolution conditioning. RDM achieves
state-of-the-art FID on CelebA-HQ and sFID on ImageNet 256$\times$256,
surpassing previous works such as ADM, LDM and DiT by a large margin. All the
codes and checkpoints are open-sourced at
\url{https://github.com/THUDM/RelayDiffusion}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teng_J/0/1/0/all/0/1&quot;&gt;Jiayan Teng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1&quot;&gt;Wendi Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Ming Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_W/0/1/0/all/0/1&quot;&gt;Wenyi Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wangni_J/0/1/0/all/0/1&quot;&gt;Jianqiao Wangni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhuoyi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03351">
<title>Using Neural Networks for Fast SAR Roughness Estimation of High Resolution Images. (arXiv:2309.03351v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03351</link>
<description rdf:parseType="Literal">&lt;p&gt;The analysis of Synthetic Aperture Radar (SAR) imagery is an important step
in remote sensing applications, and it is a challenging problem due to its
inherent speckle noise. One typical solution is to model the data using the
$G_I^0$ distribution and extract its roughness information, which in turn can
be used in posterior imaging tasks, such as segmentation, classification and
interpretation. This leads to the need of quick and reliable estimation of the
roughness parameter from SAR data, especially with high resolution images.
Unfortunately, traditional parameter estimation procedures are slow and prone
to estimation failures. In this work, we proposed a neural network-based
estimation framework that first learns how to predict underlying parameters of
$G_I^0$ samples and then can be used to estimate the roughness of unseen data.
We show that this approach leads to an estimator that is quicker, yields less
estimation error and is less prone to failures than the traditional estimation
procedures for this problem, even when we use a simple network. More
importantly, we show that this same methodology can be generalized to handle
image inputs and, even if trained on purely synthetic data for a few seconds,
is able to perform real time pixel-wise roughness estimation for high
resolution real SAR imagery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Li Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neto_J/0/1/0/all/0/1&quot;&gt;Jeova Farias Sales Rocha Neto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03353">
<title>Source Camera Identification and Detection in Digital Videos through Blind Forensics. (arXiv:2309.03353v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03353</link>
<description rdf:parseType="Literal">&lt;p&gt;Source camera identification in digital videos is the problem of associating
an unknown digital video with its source device, within a closed set of
possible devices. The existing techniques in source detection of digital videos
try to find a fingerprint of the actual source in the video in form of PRNU
(Photo Response Non--Uniformity), and match it against the SPN (Sensor Pattern
Noise) of each possible device. The highest correlation indicates the correct
source. We investigate the problem of identifying a video source through a
feature based approach using machine learning. In this paper, we present a
blind forensic technique of video source authentication and identification,
based on feature extraction, feature selection and subsequent source
classification. The main aim is to determine whether a claimed source for a
video is actually its original source. If not, we identify its original source.
Our experimental results prove the efficiency of the proposed method compared
to traditional fingerprint based technique.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sameer_V/0/1/0/all/0/1&quot;&gt;Venkata Udaya Sameer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhopadhyay_S/0/1/0/all/0/1&quot;&gt;Shilpa Mukhopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naskar_R/0/1/0/all/0/1&quot;&gt;Ruchira Naskar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dali_I/0/1/0/all/0/1&quot;&gt;Ishaan Dali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03354">
<title>Ensemble linear interpolators: The role of ensembling. (arXiv:2309.03354v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03354</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpolators are unstable. For example, the mininum $\ell_2$ norm least
square interpolator exhibits unbounded test errors when dealing with noisy
data. In this paper, we study how ensemble stabilizes and thus improves the
generalization performance, measured by the out-of-sample prediction risk, of
an individual interpolator. We focus on bagged linear interpolators, as bagging
is a popular randomization-based ensemble method that can be implemented in
parallel. We introduce the multiplier-bootstrap-based bagged least square
estimator, which can then be formulated as an average of the sketched least
square estimators. The proposed multiplier bootstrap encompasses the classical
bootstrap with replacement as a special case, along with a more intriguing
variant which we call the Bernoulli bootstrap.
&lt;/p&gt;
&lt;p&gt;Focusing on the proportional regime where the sample size scales
proportionally with the feature dimensionality, we investigate the
out-of-sample prediction risks of the sketched and bagged least square
estimators in both underparametrized and overparameterized regimes. Our results
reveal the statistical roles of sketching and bagging. In particular, sketching
modifies the aspect ratio and shifts the interpolation threshold of the minimum
$\ell_2$ norm estimator. However, the risk of the sketched estimator continues
to be unbounded around the interpolation threshold due to excessive variance.
In stark contrast, bagging effectively mitigates this variance, leading to a
bounded limiting out-of-sample prediction risk. To further understand this
stability improvement property, we establish that bagging acts as a form of
implicit regularization, substantiated by the equivalence of the bagged
estimator with its explicitly regularized counterpart. We also discuss several
extensions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Mingqi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Qiang Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03360">
<title>ViewMix: Augmentation for Robust Representation in Self-Supervised Learning. (arXiv:2309.03360v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03360</link>
<description rdf:parseType="Literal">&lt;p&gt;Joint Embedding Architecture-based self-supervised learning methods have
attributed the composition of data augmentations as a crucial factor for their
strong representation learning capabilities. While regional dropout strategies
have proven to guide models to focus on lesser indicative parts of the objects
in supervised methods, it hasn&apos;t been adopted by self-supervised methods for
generating positive pairs. This is because the regional dropout methods are not
suitable for the input sampling process of the self-supervised methodology.
Whereas dropping informative pixels from the positive pairs can result in
inefficient training, replacing patches of a specific object with a different
one can steer the model from maximizing the agreement between different
positive pairs. Moreover, joint embedding representation learning methods have
not made robustness their primary training outcome. To this end, we propose the
ViewMix augmentation policy, specially designed for self-supervised learning,
upon generating different views of the same image, patches are cut and pasted
from one view to another. By leveraging the different views created by this
augmentation strategy, multiple joint embedding-based self-supervised
methodologies obtained better localization capability and consistently
outperformed their corresponding baseline methods. It is also demonstrated that
incorporating ViewMix augmentation policy promotes robustness of the
representations in the state-of-the-art methods. Furthermore, our
experimentation and analysis of compute times suggest that ViewMix augmentation
doesn&apos;t introduce any additional overhead compared to other counterparts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Arjon Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_X/0/1/0/all/0/1&quot;&gt;Xin Zhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03386">
<title>Community-Based Hierarchical Positive-Unlabeled (PU) Model Fusion for Chronic Disease Prediction. (arXiv:2309.03386v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03386</link>
<description rdf:parseType="Literal">&lt;p&gt;Positive-Unlabeled (PU) Learning is a challenge presented by binary
classification problems where there is an abundance of unlabeled data along
with a small number of positive data instances, which can be used to address
chronic disease screening problem. State-of-the-art PU learning methods have
resulted in the development of various risk estimators, yet they neglect the
differences among distinct populations. To address this issue, we present a
novel Positive-Unlabeled Learning Tree (PUtree) algorithm. PUtree is designed
to take into account communities such as different age or income brackets, in
tasks of chronic disease prediction. We propose a novel approach for binary
decision-making, which hierarchically builds community-based PU models and then
aggregates their deliverables. Our method can explicate each PU model on the
tree for the optimized non-leaf PU node splitting. Furthermore, a mask-recovery
data augmentation strategy enables sufficient training of the model in
individual communities. Additionally, the proposed approach includes an
adversarial PU risk estimator to capture hierarchical PU-relationships, and a
model fusion network that integrates data from each tree path, resulting in
robust binary classification results. We demonstrate the superior performance
of PUtree as well as its variants on two benchmarks and a new
diabetes-prediction dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xurui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1&quot;&gt;Yangyang Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1&quot;&gt;Changlong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaozhong Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03409">
<title>Large Language Models as Optimizers. (arXiv:2309.03409v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03409</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimization is ubiquitous. While derivative-based algorithms have been
powerful tools for various problems, the absence of gradient imposes challenges
on many real-world applications. In this work, we propose Optimization by
PROmpting (OPRO), a simple and effective approach to leverage large language
models (LLMs) as optimizers, where the optimization task is described in
natural language. In each optimization step, the LLM generates new solutions
from the prompt that contains previously generated solutions with their values,
then the new solutions are evaluated and added to the prompt for the next
optimization step. We first showcase OPRO on linear regression and traveling
salesman problems, then move on to prompt optimization where the goal is to
find instructions that maximize the task accuracy. With a variety of LLMs, we
demonstrate that the best prompts optimized by OPRO outperform human-designed
prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chengrun Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xuezhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yifeng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hanxiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Denny Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinyun Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03426">
<title>Equal Long-term Benefit Rate: Adapting Static Fairness Notions to Sequential Decision Making. (arXiv:2309.03426v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03426</link>
<description rdf:parseType="Literal">&lt;p&gt;Decisions made by machine learning models may have lasting impacts over time,
making long-term fairness a crucial consideration. It has been shown that when
ignoring the long-term effect, naively imposing fairness criterion in static
settings can actually exacerbate bias over time. To explicitly address biases
in sequential decision-making, recent works formulate long-term fairness
notions in Markov Decision Process (MDP) framework. They define the long-term
bias to be the sum of static bias over each time step. However, we demonstrate
that naively summing up the step-wise bias can cause a false sense of fairness
since it fails to consider the importance difference of different time steps
during transition. In this work, we introduce a long-term fairness notion
called Equal Long-term Benefit Rate (ELBERT), which explicitly considers
varying temporal importance and adapts static fairness principles to the
sequential setting. Moreover, we show that the policy gradient of Long-term
Benefit Rate can be analytically reduced to standard policy gradient. This
makes standard policy optimization methods applicable for reducing the bias,
leading to our proposed bias mitigation method ELBERT-PO. Experiments on three
sequential decision making environments show that ELBERT-PO significantly
reduces bias and maintains high utility. Code is available at
https://github.com/Yuancheng-Xu/ELBERT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yuancheng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1&quot;&gt;Chenghao Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanchao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1&quot;&gt;Ruijie Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiyao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jieyu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Furong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03437">
<title>Byzantine-Robust Federated Learning with Variance Reduction and Differential Privacy. (arXiv:2309.03437v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03437</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is designed to preserve data privacy during model
training, where the data remains on the client side (i.e., IoT devices), and
only model updates of clients are shared iteratively for collaborative
learning. However, this process is vulnerable to privacy attacks and Byzantine
attacks: the local model updates shared throughout the FL network will leak
private information about the local training data, and they can also be
maliciously crafted by Byzantine attackers to disturb the learning. In this
paper, we propose a new FL scheme that guarantees rigorous privacy and
simultaneously enhances system robustness against Byzantine attacks. Our
approach introduces sparsification- and momentum-driven variance reduction into
the client-level differential privacy (DP) mechanism, to defend against
Byzantine attackers. The security design does not violate the privacy guarantee
of the client-level DP mechanism; hence, our approach achieves the same
client-level DP guarantee as the state-of-the-art. We conduct extensive
experiments on both IID and non-IID datasets and different tasks and evaluate
the performance of our approach against different Byzantine attacks by
comparing it with state-of-the-art defense methods. The results of our
experiments show the efficacy of our framework and demonstrate its ability to
improve system robustness against Byzantine attacks while achieving a strong
privacy guarantee.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zikai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1&quot;&gt;Rui Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03439">
<title>Personalized Tucker Decomposition: Modeling Commonality and Peculiarity on Tensor Data. (arXiv:2309.03439v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03439</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose personalized Tucker decomposition (perTucker) to address the
limitations of traditional tensor decomposition methods in capturing
heterogeneity across different datasets. perTucker decomposes tensor data into
shared global components and personalized local components. We introduce a mode
orthogonality assumption and develop a proximal gradient regularized block
coordinate descent algorithm that is guaranteed to converge to a stationary
point. By learning unique and common representations across datasets, we
demonstrate perTucker&apos;s effectiveness in anomaly detection, client
classification, and clustering through a simulation study and two case studies
on solar flare detection and tonnage signal classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jiuyun Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_N/0/1/0/all/0/1&quot;&gt;Naichen Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kontar_R/0/1/0/all/0/1&quot;&gt;Raed Al Kontar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1&quot;&gt;Hao Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03440">
<title>Punctate White Matter Lesion Segmentation in Preterm Infants Powered by Counterfactually Generative Learning. (arXiv:2309.03440v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.03440</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate segmentation of punctate white matter lesions (PWMLs) are
fundamental for the timely diagnosis and treatment of related developmental
disorders. Automated PWMLs segmentation from infant brain MR images is
challenging, considering that the lesions are typically small and low-contrast,
and the number of lesions may dramatically change across subjects. Existing
learning-based methods directly apply general network architectures to this
challenging task, which may fail to capture detailed positional information of
PWMLs, potentially leading to severe under-segmentations. In this paper, we
propose to leverage the idea of counterfactual reasoning coupled with the
auxiliary task of brain tissue segmentation to learn fine-grained positional
and morphological representations of PWMLs for accurate localization and
segmentation. A simple and easy-to-implement deep-learning framework (i.e.,
DeepPWML) is accordingly designed. It combines the lesion counterfactual map
with the tissue probability map to train a lightweight PWML segmentation
network, demonstrating state-of-the-art performance on a real-clinical dataset
of infant T1w MR images. The code is available at
\href{https://github.com/ladderlab-xjtu/DeepPWML}{https://github.com/ladderlab-xjtu/DeepPWML}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zehua Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yongheng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Miaomiao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yuying Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xianjun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jin_C/0/1/0/all/0/1&quot;&gt;Chao Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jian Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lian_C/0/1/0/all/0/1&quot;&gt;Chunfeng Lian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03447">
<title>Broadband Ground Motion Synthesis via Generative Adversarial Neural Operators: Development and Validation. (arXiv:2309.03447v1 [physics.geo-ph])</title>
<link>http://arxiv.org/abs/2309.03447</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a data-driven model for ground-motion synthesis using a Generative
Adversarial Neural Operator (GANO) that combines recent advancements in machine
learning and open access strong motion data sets to generate three-component
acceleration time histories conditioned on moment magnitude ($M$), rupture
distance ($R_{rup}$), time-average shear-wave velocity at the top $30m$
($V_{S30}$), and tectonic environment or style of faulting. We use Neural
Operators, a resolution invariant architecture that guarantees that the model
training is independent of the data sampling frequency. We first present the
conditional ground-motion synthesis algorithm (referred to heretofore as
cGM-GANO) and discuss its advantages compared to previous work. Next, we verify
the cGM-GANO framework using simulated ground motions generated with the
Southern California Earthquake Center (SCEC) Broadband Platform (BBP). We
lastly train cGM-GANO on a KiK-net dataset from Japan, showing that the
framework can recover the magnitude, distance, and $V_{S30}$ scaling of Fourier
amplitude and pseudo-spectral accelerations. We evaluate cGM-GANO through
residual analysis with the empirical dataset as well as by comparison with
conventional Ground Motion Models (GMMs) for selected ground motion scenarios.
Results show that cGM-GANO produces consistent median scaling with the GMMs for
the corresponding tectonic environments. The largest misfit is observed at
short distances due to the scarcity of training data. With the exception of
short distances, the aleatory variability of the response spectral ordinates is
also well captured, especially for subduction events due to the adequacy of
training data. Applications of the presented framework include generation of
risk-targeted ground motions for site-specific engineering applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yaozhong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lavrentiadis_G/0/1/0/all/0/1&quot;&gt;Grigorios Lavrentiadis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Asimaki_D/0/1/0/all/0/1&quot;&gt;Domniki Asimaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ross_Z/0/1/0/all/0/1&quot;&gt;Zachary E. Ross&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Azizzadenesheli_K/0/1/0/all/0/1&quot;&gt;Kamyar Azizzadenesheli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03450">
<title>XGen-7B Technical Report. (arXiv:2309.03450v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.03450</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have become ubiquitous across various domains,
transforming the way we interact with information and conduct research.
However, most high-performing LLMs remain confined behind proprietary walls,
hindering scientific progress. Most open-source LLMs, on the other hand, are
limited in their ability to support longer sequence lengths, which is a key
requirement for many tasks that require inference over an input context. To
address this, we have trained XGen, a series of 7B parameter models on up to 8K
sequence length for up to 1.5T tokens. We have also finetuned the XGen models
on public-domain instructional data, creating their instruction-tuned
counterparts (XGen-Inst). We open-source our models for both research
advancements and commercial applications. Our evaluation on standard benchmarks
shows that XGen models achieve comparable or better results when compared with
state-of-the-art open-source LLMs. Our targeted evaluation on long sequence
modeling tasks shows the benefits of our 8K-sequence models over 2K-sequence
open-source LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nijkamp_E/0/1/0/all/0/1&quot;&gt;Erik Nijkamp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1&quot;&gt;Tian Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayashi_H/0/1/0/all/0/1&quot;&gt;Hiroaki Hayashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1&quot;&gt;Bo Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1&quot;&gt;Congying Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_C/0/1/0/all/0/1&quot;&gt;Chen Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vig_J/0/1/0/all/0/1&quot;&gt;Jesse Vig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yavuz_S/0/1/0/all/0/1&quot;&gt;Semih Yavuz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laban_P/0/1/0/all/0/1&quot;&gt;Philippe Laban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_B/0/1/0/all/0/1&quot;&gt;Ben Krause&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purushwalkam_S/0/1/0/all/0/1&quot;&gt;Senthil Purushwalkam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_T/0/1/0/all/0/1&quot;&gt;Tong Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kryscinski_W/0/1/0/all/0/1&quot;&gt;Wojciech Kry&amp;#x15b;ci&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murakhovska_L/0/1/0/all/0/1&quot;&gt;Lidiya Murakhovs&amp;#x27;ka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choubey_P/0/1/0/all/0/1&quot;&gt;Prafulla Kumar Choubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1&quot;&gt;Alex Fabbri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Ye Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1&quot;&gt;Rui Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_L/0/1/0/all/0/1&quot;&gt;Lifu Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhat_M/0/1/0/all/0/1&quot;&gt;Meghana Bhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chien-Sheng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yingbo Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1&quot;&gt;Shafiq Joty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03451">
<title>Cross-domain Sound Recognition for Efficient Underwater Data Analysis. (arXiv:2309.03451v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.03451</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel deep learning approach for analyzing massive
underwater acoustic data by leveraging a model trained on a broad spectrum of
non-underwater (aerial) sounds. Recognizing the challenge in labeling vast
amounts of underwater data, we propose a two-fold methodology to accelerate
this labor-intensive procedure.
&lt;/p&gt;
&lt;p&gt;The first part of our approach involves PCA and UMAP visualization of the
underwater data using the feature vectors of an aerial sound recognition model.
This enables us to cluster the data in a two dimensional space and listen to
points within these clusters to understand their defining characteristics. This
innovative method simplifies the process of selecting candidate labels for
further training.
&lt;/p&gt;
&lt;p&gt;In the second part, we train a neural network model using both the selected
underwater data and the non-underwater dataset. We conducted a quantitative
analysis to measure the precision, recall, and F1 score of our model for
recognizing airgun sounds, a common type of underwater sound. The F1 score
achieved by our model exceeded 84.3%, demonstrating the effectiveness of our
approach in analyzing underwater acoustic data.
&lt;/p&gt;
&lt;p&gt;The methodology presented in this paper holds significant potential to reduce
the amount of labor required in underwater data analysis and opens up new
possibilities for further research in the field of cross-domain data analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jeongsoo Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1&quot;&gt;Dong-Gyun Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+La_H/0/1/0/all/0/1&quot;&gt;Hyoung Sul La&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sangmin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yoonchang Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1&quot;&gt;Eun-Jin Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03452">
<title>Multi-Modality Guidance Network For Missing Modality Inference. (arXiv:2309.03452v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03452</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal models have gained significant success in recent years. Standard
multimodal approaches often assume unchanged modalities from training stage to
inference stage. In practice, however, many scenarios fail to satisfy such
assumptions with missing modalities during inference, leading to limitations on
where multimodal models can be applied. While existing methods mitigate the
problem through reconstructing the missing modalities, it increases unnecessary
computational cost, which could be just as critical, especially for large,
deployed systems. To solve the problem from both sides, we propose a novel
guidance network that promotes knowledge sharing during training, taking
advantage of the multimodal representations to train better single-modality
models for inference. Real-life experiment in violence detection shows that our
proposed framework trains single-modality models that significantly outperform
its traditionally trained counterparts while maintaining the same inference
cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhuokai Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palani_H/0/1/0/all/0/1&quot;&gt;Harish Palani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tianyi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_L/0/1/0/all/0/1&quot;&gt;Lena Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toner_R/0/1/0/all/0/1&quot;&gt;Ruth Toner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03468">
<title>Cross-Image Context Matters for Bongard Problems. (arXiv:2309.03468v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03468</link>
<description rdf:parseType="Literal">&lt;p&gt;Current machine learning methods struggle to solve Bongard problems, which
are a type of IQ test that requires deriving an abstract &quot;concept&quot; from a set
of positive and negative &quot;support&quot; images, and then classifying whether or not
a new query image depicts the key concept. On Bongard-HOI, a benchmark for
natural-image Bongard problems, existing methods have only reached 66% accuracy
(where chance is 50%). Low accuracy is often attributed to neural nets&apos; lack of
ability to find human-like symbolic rules. In this work, we point out that many
existing methods are forfeiting accuracy due to a much simpler problem: they do
not incorporate information contained in the support set as a whole, and rely
instead on information extracted from individual supports. This is a critical
issue, because unlike in few-shot learning tasks concerning object
classification, the &quot;key concept&quot; in a typical Bongard problem can only be
distinguished using multiple positives and multiple negatives. We explore a
variety of simple methods to take this cross-image context into account, and
demonstrate substantial gains over prior methods, leading to new
state-of-the-art performance on Bongard-LOGO (75.3%) and Bongard-HOI (72.45%)
and strong performance on the original Bongard problem set (60.84%).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghuraman_N/0/1/0/all/0/1&quot;&gt;Nikhil Raghuraman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harley_A/0/1/0/all/0/1&quot;&gt;Adam W. Harley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1&quot;&gt;Leonidas Guibas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03469">
<title>Fast FixMatch: Faster Semi-Supervised Learning with Curriculum Batch Size. (arXiv:2309.03469v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03469</link>
<description rdf:parseType="Literal">&lt;p&gt;Advances in Semi-Supervised Learning (SSL) have almost entirely closed the
gap between SSL and Supervised Learning at a fraction of the number of labels.
However, recent performance improvements have often come \textit{at the cost of
significantly increased training computation}. To address this, we propose
Curriculum Batch Size (CBS), \textit{an unlabeled batch size curriculum which
exploits the natural training dynamics of deep neural networks.} A small
unlabeled batch size is used in the beginning of training and is gradually
increased to the end of training. A fixed curriculum is used regardless of
dataset, model or number of epochs, and reduced training computations is
demonstrated on all settings. We apply CBS, strong labeled augmentation,
Curriculum Pseudo Labeling (CPL) \citep{FlexMatch} to FixMatch \citep{FixMatch}
and term the new SSL algorithm Fast FixMatch. We perform an ablation study to
show that strong labeled augmentation and/or CPL do not significantly reduce
training computations, but, in synergy with CBS, they achieve optimal
performance. Fast FixMatch also achieves substantially higher data utilization
compared to previous state-of-the-art. Fast FixMatch achieves between
$2.1\times$ - $3.4\times$ reduced training computations on CIFAR-10 with all
but 40, 250 and 4000 labels removed, compared to vanilla FixMatch, while
attaining the same cited state-of-the-art error rate \citep{FixMatch}. Similar
results are achieved for CIFAR-100, SVHN and STL-10. Finally, Fast MixMatch
achieves between $2.6\times$ - $3.3\times$ reduced training computations in
federated SSL tasks and online/streaming learning SSL tasks, which further
demonstrate the generializbility of Fast MixMatch to different scenarios and
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;John Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1&quot;&gt;Chen Dun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03487">
<title>Privacy-preserving Continual Federated Clustering via Adaptive Resonance Theory. (arXiv:2309.03487v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03487</link>
<description rdf:parseType="Literal">&lt;p&gt;With the increasing importance of data privacy protection, various
privacy-preserving machine learning methods have been proposed. In the
clustering domain, various algorithms with a federated learning framework
(i.e., federated clustering) have been actively studied and showed high
clustering performance while preserving data privacy. However, most of the base
clusterers (i.e., clustering algorithms) used in existing federated clustering
algorithms need to specify the number of clusters in advance. These algorithms,
therefore, are unable to deal with data whose distributions are unknown or
continually changing. To tackle this problem, this paper proposes a
privacy-preserving continual federated clustering algorithm. In the proposed
algorithm, an adaptive resonance theory-based clustering algorithm capable of
continual learning is used as a base clusterer. Therefore, the proposed
algorithm inherits the ability of continual learning. Experimental results with
synthetic and real-world datasets show that the proposed algorithm has superior
clustering performance to state-of-the-art federated clustering algorithms
while realizing data privacy protection and continual learning ability. The
source code is available at \url{https://github.com/Masuyama-lab/FCAC}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masuyama_N/0/1/0/all/0/1&quot;&gt;Naoki Masuyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nojima_Y/0/1/0/all/0/1&quot;&gt;Yusuke Nojima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toda_Y/0/1/0/all/0/1&quot;&gt;Yuichiro Toda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loo_C/0/1/0/all/0/1&quot;&gt;Chu Kiong Loo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishibuchi_H/0/1/0/all/0/1&quot;&gt;Hisao Ishibuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kubota_N/0/1/0/all/0/1&quot;&gt;Naoyuki Kubota&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03530">
<title>Efficient Single Object Detection on Image Patches with Early Exit Enhanced High-Precision CNNs. (arXiv:2309.03530v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03530</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a novel approach for detecting objects using mobile
robots in the context of the RoboCup Standard Platform League, with a primary
focus on detecting the ball. The challenge lies in detecting a dynamic object
in varying lighting conditions and blurred images caused by fast movements. To
address this challenge, the paper presents a convolutional neural network
architecture designed specifically for computationally constrained robotic
platforms. The proposed CNN is trained to achieve high precision classification
of single objects in image patches and to determine their precise spatial
positions. The paper further integrates Early Exits into the existing
high-precision CNN architecture to reduce the computational cost of easily
rejectable cases in the background class. The training process involves a
composite loss function based on confidence and positional losses with dynamic
weighting and data augmentation. The proposed approach achieves a precision of
100% on the validation dataset and a recall of almost 87%, while maintaining an
execution time of around 170 $\mu$s per hypotheses. By combining the proposed
approach with an Early Exit, a runtime optimization of more than 28%, on
average, can be achieved compared to the original CNN. Overall, this paper
provides an efficient solution for an enhanced detection of objects, especially
the ball, in computationally constrained robotic platforms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moos_A/0/1/0/all/0/1&quot;&gt;Arne Moos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03531">
<title>A Robust Negative Learning Approach to Partial Domain Adaptation Using Source Prototypes. (arXiv:2309.03531v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03531</link>
<description rdf:parseType="Literal">&lt;p&gt;This work proposes a robust Partial Domain Adaptation (PDA) framework that
mitigates the negative transfer problem by incorporating a robust
target-supervision strategy. It leverages ensemble learning and includes
diverse, complementary label feedback, alleviating the effect of incorrect
feedback and promoting pseudo-label refinement. Rather than relying exclusively
on first-order moments for distribution alignment, our approach offers explicit
objectives to optimize intra-class compactness and inter-class separation with
the inferred source prototypes and highly-confident target samples in a
domain-invariant fashion. Notably, we ensure source data privacy by eliminating
the need to access the source data during the adaptation phase through a priori
inference of source prototypes. We conducted a series of comprehensive
experiments, including an ablation analysis, covering a range of partial domain
adaptation tasks. Comprehensive evaluations on benchmark datasets corroborate
our framework&apos;s enhanced robustness and generalization, demonstrating its
superiority over existing state-of-the-art PDA approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choudhuri_S/0/1/0/all/0/1&quot;&gt;Sandipan Choudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adeniye_S/0/1/0/all/0/1&quot;&gt;Suli Adeniye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_A/0/1/0/all/0/1&quot;&gt;Arunabha Sen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03535">
<title>Feature Enhancer Segmentation Network (FES-Net) for Vessel Segmentation. (arXiv:2309.03535v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.03535</link>
<description rdf:parseType="Literal">&lt;p&gt;Diseases such as diabetic retinopathy and age-related macular degeneration
pose a significant risk to vision, highlighting the importance of precise
segmentation of retinal vessels for the tracking and diagnosis of progression.
However, existing vessel segmentation methods that heavily rely on
encoder-decoder structures struggle to capture contextual information about
retinal vessel configurations, leading to challenges in reconciling semantic
disparities between encoder and decoder features. To address this, we propose a
novel feature enhancement segmentation network (FES-Net) that achieves accurate
pixel-wise segmentation without requiring additional image enhancement steps.
FES-Net directly processes the input image and utilizes four prompt
convolutional blocks (PCBs) during downsampling, complemented by a shallow
upsampling approach to generate a binary mask for each class. We evaluate the
performance of FES-Net on four publicly available state-of-the-art datasets:
DRIVE, STARE, CHASE, and HRF. The evaluation results clearly demonstrate the
superior performance of FES-Net compared to other competitive approaches
documented in the existing literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Khan_T/0/1/0/all/0/1&quot;&gt;Tariq M. Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Arsalan_M/0/1/0/all/0/1&quot;&gt;Muhammad Arsalan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Iqbal_S/0/1/0/all/0/1&quot;&gt;Shahzaib Iqbal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Razzak_I/0/1/0/all/0/1&quot;&gt;Imran Razzak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Meijering_E/0/1/0/all/0/1&quot;&gt;Erik Meijering&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03537">
<title>Subgraph-based Tight Frames on Graphs with Compact Supports and Vanishing Moments. (arXiv:2309.03537v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2309.03537</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we proposed a novel and general method to construct tight
frames on graphs with compact supports based on a series of hierarchical
partitions. Starting from our abstract construction that generalizes previous
methods based on partition trees, we are able to flexibly incorporate subgraph
Laplacians into our design of graph frames. Consequently, our general methods
permit adjusting the (subgraph) vanishing moments of the framelets and extra
properties, such as directionality, for efficiently representing graph signals
with path-like supports. Several variants are explicitly defined and tested.
Experimental results show our proposed graph frames perform superiorly in
non-linear approximation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zheng_R/0/1/0/all/0/1&quot;&gt;Ruigang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhuang_X/0/1/0/all/0/1&quot;&gt;Xiaosheng Zhuang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03544">
<title>MVD:A Novel Methodology and Dataset for Acoustic Vehicle Type Classification. (arXiv:2309.03544v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.03544</link>
<description rdf:parseType="Literal">&lt;p&gt;Rising urban populations have led to a surge in vehicle use and made traffic
monitoring and management indispensable. Acoustic traffic monitoring (ATM)
offers a cost-effective and efficient alternative to more computationally
expensive methods of monitoring traffic such as those involving computer vision
technologies. In this paper, we present MVD and MVDA: two open datasets for the
development of acoustic traffic monitoring and vehicle-type classification
algorithms, which contain audio recordings of moving vehicles. The dataset
contain four classes- Trucks, Cars, Motorbikes, and a No-vehicle class.
Additionally, we propose a novel and efficient way to accurately classify these
acoustic signals using cepstrum and spectrum based local and global audio
features, and a multi-input neural network. Experimental results show that our
methodology improves upon the established baselines of previous works and
achieves an accuracy of 91.98% and 96.66% on MVD and MVDA Datasets,
respectively. Finally, the proposed model was deployed through an Android
application to make it accessible for testing and demonstrate its efficacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashhad_M/0/1/0/all/0/1&quot;&gt;Mohd Ashhad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_O/0/1/0/all/0/1&quot;&gt;Omar Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ambat_S/0/1/0/all/0/1&quot;&gt;Sooraj K. Ambat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haq_Z/0/1/0/all/0/1&quot;&gt;Zeeshan Ali Haq&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1&quot;&gt;Mansaf Alam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03557">
<title>On the dynamics of multi agent nonlinear filtering and learning. (arXiv:2309.03557v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03557</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiagent systems aim to accomplish highly complex learning tasks through
decentralised consensus seeking dynamics and their use has garnered a great
deal of attention in the signal processing and computational intelligence
societies. This article examines the behaviour of multiagent networked systems
with nonlinear filtering/learning dynamics. To this end, a general formulation
for the actions of an agent in multiagent networked systems is presented and
conditions for achieving a cohesive learning behaviour is given. Importantly,
application of the so derived framework in distributed and federated learning
scenarios are presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Talebi_S/0/1/0/all/0/1&quot;&gt;Sayed Pouria Talebi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mandic_D/0/1/0/all/0/1&quot;&gt;Danilo Mandic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03561">
<title>Trinary Decision Trees for missing value handling. (arXiv:2309.03561v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03561</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces the Trinary decision tree, an algorithm designed to
improve the handling of missing data in decision tree regressors and
classifiers. Unlike other approaches, the Trinary decision tree does not assume
that missing values contain any information about the response. Both
theoretical calculations on estimator bias and numerical illustrations using
real data sets are presented to compare its performance with established
algorithms in different missing data scenarios (Missing Completely at Random
(MCAR), and Informative Missingness (IM)). Notably, the Trinary tree
outperforms its peers in MCAR settings, especially when data is only missing
out-of-sample, while lacking behind in IM settings. A hybrid model, the
TrinaryMIA tree, which combines the Trinary tree and the Missing In Attributes
(MIA) approach, shows robust performance in all types of missingness. Despite
the potential drawback of slower training speed, the Trinary tree offers a
promising and more accurate method of handling missing data in decision tree
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zakrisson_H/0/1/0/all/0/1&quot;&gt;Henning Zakrisson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03564">
<title>Evaluating the Efficacy of Supervised Learning vs Large Language Models for Identifying Cognitive Distortions and Suicidal Risks in Chinese Social Media. (arXiv:2309.03564v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.03564</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models, particularly those akin to the rapidly progressing GPT
series, are gaining traction for their expansive influence. While there is keen
interest in their applicability within medical domains such as psychology,
tangible explorations on real-world data remain scant. Concurrently, users on
social media platforms are increasingly vocalizing personal sentiments; under
specific thematic umbrellas, these sentiments often manifest as negative
emotions, sometimes escalating to suicidal inclinations. Timely discernment of
such cognitive distortions and suicidal risks is crucial to effectively
intervene and potentially avert dire circumstances. Our study ventured into
this realm by experimenting on two pivotal tasks: suicidal risk and cognitive
distortion identification on Chinese social media platforms. Using supervised
learning as a baseline, we examined and contrasted the efficacy of large
language models via three distinct strategies: zero-shot, few-shot, and
fine-tuning. Our findings revealed a discernible performance gap between the
large language models and traditional supervised learning approaches, primarily
attributed to the models&apos; inability to fully grasp subtle categories. Notably,
while GPT-4 outperforms its counterparts in multiple scenarios, GPT-3.5 shows
significant enhancement in suicide risk classification after fine-tuning. To
our knowledge, this investigation stands as the maiden attempt at gauging large
language models on Chinese social media tasks. This study underscores the
forward-looking and transformative implications of using large language models
in the field of psychology. It lays the groundwork for future applications in
psychological research and practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1&quot;&gt;Hongzhi Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qing Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1&quot;&gt;Changwei Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhai_W/0/1/0/all/0/1&quot;&gt;Wei Zhai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1&quot;&gt;Dan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shuo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yi Jing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_H/0/1/0/all/0/1&quot;&gt;Huijing Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bing Xiang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianqiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_G/0/1/0/all/0/1&quot;&gt;Guanghui Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03569">
<title>Sparse Federated Training of Object Detection in the Internet of Vehicles. (arXiv:2309.03569v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03569</link>
<description rdf:parseType="Literal">&lt;p&gt;As an essential component part of the Intelligent Transportation System
(ITS), the Internet of Vehicles (IoV) plays a vital role in alleviating traffic
issues. Object detection is one of the key technologies in the IoV, which has
been widely used to provide traffic management services by analyzing timely and
sensitive vehicle-related information. However, the current object detection
methods are mostly based on centralized deep training, that is, the sensitive
data obtained by edge devices need to be uploaded to the server, which raises
privacy concerns. To mitigate such privacy leakage, we first propose a
federated learning-based framework, where well-trained local models are shared
in the central server. However, since edge devices usually have limited
computing power, plus a strict requirement of low latency in IoVs, we further
propose a sparse training process on edge devices, which can effectively
lighten the model, and ensure its training efficiency on edge devices, thereby
reducing communication overheads. In addition, due to the diverse computing
capabilities and dynamic environment, different sparsity rates are applied to
edge devices. To further guarantee the performance, we propose, FedWeg, an
improved aggregation scheme based on FedAvg, which is designed by the inverse
ratio of sparsity rates. Experiments on the real-life dataset using YOLO show
that the proposed scheme can achieve the required object detection rate while
saving considerable communication costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_L/0/1/0/all/0/1&quot;&gt;Luping Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Ming Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1&quot;&gt;Yuwen Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1&quot;&gt;Lu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhe Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03579">
<title>DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend. (arXiv:2309.03579v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03579</link>
<description rdf:parseType="Literal">&lt;p&gt;Measuring distance or similarity between time-series data is a fundamental
aspect of many applications including classification and clustering. Existing
measures may fail to capture similarities due to local trends (shapes) and may
even produce misleading results. Our goal is to develop a measure that looks
for similar trends occurring around similar times and is easily interpretable
for researchers in applied domains. This is particularly useful for
applications where time-series have a sequence of meaningful local trends that
are ordered, such as in epidemics (a surge to an increase to a peak to a
decrease). We propose a novel measure, DTW+S, which creates an interpretable
&quot;closeness-preserving&quot; matrix representation of the time-series, where each
column represents local trends, and then it applies Dynamic Time Warping to
compute distances between these matrices. We present a theoretical analysis
that supports the choice of this representation. We demonstrate the utility of
DTW+S in ensemble building and clustering of epidemic curves. We also
demonstrate that our approach results in better classification compared to
Dynamic Time Warping for a class of datasets, particularly when local trends
rather than scale play a decisive role.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1&quot;&gt;Ajitesh Srivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03581">
<title>Interactive Hyperparameter Optimization in Multi-Objective Problems via Preference Learning. (arXiv:2309.03581v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03581</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperparameter optimization (HPO) is important to leverage the full potential
of machine learning (ML). In practice, users are often interested in
multi-objective (MO) problems, i.e., optimizing potentially conflicting
objectives, like accuracy and energy consumption. To tackle this, the vast
majority of MO-ML algorithms return a Pareto front of non-dominated machine
learning models to the user. Optimizing the hyperparameters of such algorithms
is non-trivial as evaluating a hyperparameter configuration entails evaluating
the quality of the resulting Pareto front. In literature, there are known
indicators that assess the quality of a Pareto front (e.g., hypervolume, R2) by
quantifying different properties (e.g., volume, proximity to a reference
point). However, choosing the indicator that leads to the desired Pareto front
might be a hard task for a user. In this paper, we propose a human-centered
interactive HPO approach tailored towards multi-objective ML leveraging
preference learning to extract desiderata from users that guide the
optimization. Instead of relying on the user guessing the most suitable
indicator for their needs, our approach automatically learns an appropriate
indicator. Concretely, we leverage pairwise comparisons of distinct Pareto
fronts to learn such an appropriate quality indicator. Then, we optimize the
hyperparameters of the underlying MO-ML algorithm towards this learned
indicator using a state-of-the-art HPO approach. In an experimental study
targeting the environmental impact of ML, we demonstrate that our approach
leads to substantially better Pareto fronts compared to optimizing based on a
wrong indicator pre-selected by the user, and performs comparable in the case
of an advanced user knowing which indicator to pick.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giovanelli_J/0/1/0/all/0/1&quot;&gt;Joseph Giovanelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tornede_A/0/1/0/all/0/1&quot;&gt;Alexander Tornede&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tornede_T/0/1/0/all/0/1&quot;&gt;Tanja Tornede&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1&quot;&gt;Marius Lindauer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03607">
<title>Your Battery Is a Blast! Safeguarding Against Counterfeit Batteries with Authentication. (arXiv:2309.03607v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2309.03607</link>
<description rdf:parseType="Literal">&lt;p&gt;Lithium-ion (Li-ion) batteries are the primary power source in various
applications due to their high energy and power density. Their market was
estimated to be up to 48 billion U.S. dollars in 2022. However, the widespread
adoption of Li-ion batteries has resulted in counterfeit cell production, which
can pose safety hazards to users. Counterfeit cells can cause explosions or
fires, and their prevalence in the market makes it difficult for users to
detect fake cells. Indeed, current battery authentication methods can be
susceptible to advanced counterfeiting techniques and are often not adaptable
to various cells and systems. In this paper, we improve the state of the art on
battery authentication by proposing two novel methodologies, DCAuth and
EISthentication, which leverage the internal characteristics of each cell
through Machine Learning models. Our methods automatically authenticate
lithium-ion battery models and architectures using data from their regular
usage without the need for any external device. They are also resilient to the
most common and critical counterfeit practices and can scale to several
batteries and devices. To evaluate the effectiveness of our proposed
methodologies, we analyze time-series data from a total of 20 datasets that we
have processed to extract meaningful features for our analysis. Our methods
achieve high accuracy in battery authentication for both architectures (up to
0.99) and models (up to 0.96). Moreover, our methods offer comparable
identification performances. By using our proposed methodologies, manufacturers
can ensure that devices only use legitimate batteries, guaranteeing the
operational state of any system and safety measures for the users.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marchiori_F/0/1/0/all/0/1&quot;&gt;Francesco Marchiori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1&quot;&gt;Mauro Conti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03616">
<title>Filtration Surfaces for Dynamic Graph Classification. (arXiv:2309.03616v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03616</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing approaches for classifying dynamic graphs either lift graph kernels
to the temporal domain, or use graph neural networks (GNNs). However, current
baselines have scalability issues, cannot handle a changing node set, or do not
take edge weight information into account. We propose filtration surfaces, a
novel method that is scalable and flexible, to alleviate said restrictions. We
experimentally validate the efficacy of our model and show that filtration
surfaces outperform previous state-of-the-art baselines on datasets that rely
on edge weight information. Our method does so while being either completely
parameter-free or having at most one parameter, and yielding the lowest overall
standard deviation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srambical_F/0/1/0/all/0/1&quot;&gt;Franz Srambical&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1&quot;&gt;Bastian Rieck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03619">
<title>Understanding Self-Supervised Learning of Speech Representation via Invariance and Redundancy Reduction. (arXiv:2309.03619v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.03619</link>
<description rdf:parseType="Literal">&lt;p&gt;The choice of the objective function is crucial in emerging high-quality
representations from self-supervised learning. This paper investigates how
different formulations of the Barlow Twins (BT) objective impact downstream
task performance for speech data. We propose Modified Barlow Twins (MBT) with
normalized latents to enforce scale-invariance and evaluate on speaker
identification, gender recognition and keyword spotting tasks. Our results show
MBT improves representation generalization over original BT, especially when
fine-tuning with limited target data. This highlights the importance of
designing objectives that encourage invariant and transferable representations.
Our analysis provides insights into how the BT learning objective can be
tailored to produce speech representations that excel when adapted to new
downstream tasks. This study is an important step towards developing reusable
self-supervised speech representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brima_Y/0/1/0/all/0/1&quot;&gt;Yusuf Brima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krumnack_U/0/1/0/all/0/1&quot;&gt;Ulf Krumnack&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pika_S/0/1/0/all/0/1&quot;&gt;Simone Pika&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heidemann_G/0/1/0/all/0/1&quot;&gt;Gunther Heidemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03631">
<title>Insights Into the Inner Workings of Transformer Models for Protein Function Prediction. (arXiv:2309.03631v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03631</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivation: We explored how explainable AI (XAI) can help to shed light into
the inner workings of neural networks for protein function prediction, by
extending the widely used XAI method of integrated gradients such that latent
representations inside of transformer models, which were finetuned to Gene
Ontology term and Enzyme Commission number prediction, can be inspected too.
Results: The approach enabled us to identify amino acids in the sequences that
the transformers pay particular attention to, and to show that these relevant
sequence parts reflect expectations from biology and chemistry, both in the
embedding layer and inside of the model, where we identified transformer heads
with a statistically significant correspondence of attribution maps with ground
truth sequence annotations (e.g., transmembrane regions, active sites) across
many proteins. Availability and Implementation: Source code can be accessed at
https://github.com/markuswenzel/xai-proteins .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wenzel_M/0/1/0/all/0/1&quot;&gt;Markus Wenzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gruner_E/0/1/0/all/0/1&quot;&gt;Erik Gr&amp;#xfc;ner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strodthoff_N/0/1/0/all/0/1&quot;&gt;Nils Strodthoff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03648">
<title>Characterizing Lipschitz Stability of GNN for Fairness. (arXiv:2309.03648v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03648</link>
<description rdf:parseType="Literal">&lt;p&gt;The Lipschitz bound, a technique from robust statistics, can limit the
maximum changes in the output concerning the input, taking into account
associated irrelevant biased factors. It is an efficient and provable method
for examining the output stability of machine learning models without incurring
additional computation costs. Recently, Graph Neural Networks (GNNs), which
operate on non-Euclidean data, have gained significant attention. However, no
previous research has investigated the GNN Lipschitz bounds to shed light on
stabilizing model outputs, especially when working on non-Euclidean data with
inherent biases. Given the inherent biases in common graph data used for GNN
training, it poses a serious challenge to constraining the GNN output
perturbations induced by input biases, thereby safeguarding fairness during
training. Recently, despite the Lipschitz constant&apos;s use in controlling the
stability of Euclideanneural networks, the calculation of the precise Lipschitz
constant remains elusive for non-Euclidean neural networks like GNNs,
especially within fairness contexts. To narrow this gap, we begin with the
general GNNs operating on an attributed graph, and formulate a Lipschitz bound
to limit the changes in the output regarding biases associated with the input.
Additionally, we theoretically analyze how the Lipschitz constant of a GNN
model could constrain the output perturbations induced by biases learned from
data for fairness training. We experimentally validate the Lipschitz bound&apos;s
effectiveness in limiting biases of the model output. Finally, from a training
dynamics perspective, we demonstrate why the theoretical Lipschitz bound can
effectively guide the GNN training to better trade-off between accuracy and
fairness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1&quot;&gt;Yaning Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chunhui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jundong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chuxu Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03659">
<title>Towards Comparable Knowledge Distillation in Semantic Image Segmentation. (arXiv:2309.03659v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03659</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge Distillation (KD) is one proposed solution to large model sizes and
slow inference speed in semantic segmentation. In our research we identify 25
proposed distillation loss terms from 14 publications in the last 4 years.
Unfortunately, a comparison of terms based on published results is often
impossible, because of differences in training configurations. A good
illustration of this problem is the comparison of two publications from 2022.
Using the same models and dataset, Structural and Statistical Texture
Distillation (SSTKD) reports an increase of student mIoU of 4.54 and a final
performance of 29.19, while Adaptive Perspective Distillation (APD) only
improves student performance by 2.06 percentage points, but achieves a final
performance of 39.25. The reason for such extreme differences is often a
suboptimal choice of hyperparameters and a resulting underperformance of the
student model used as reference point. In our work, we reveal problems of
insufficient hyperparameter tuning by showing that distillation improvements of
two widely accepted frameworks, SKD and IFVD, vanish when hyperparameters are
optimized sufficiently. To improve comparability of future research in the
field, we establish a solid baseline for three datasets and two student models
and provide extensive information on hyperparameter tuning. We find that only
two out of eight techniques can compete with our simple baseline on the ADE20K
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niemann_O/0/1/0/all/0/1&quot;&gt;Onno Niemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vox_C/0/1/0/all/0/1&quot;&gt;Christopher Vox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Werner_T/0/1/0/all/0/1&quot;&gt;Thorben Werner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03664">
<title>Alzheimer Disease Detection from Raman Spectroscopy of the Cerebrospinal Fluid via Topological Machine Learning. (arXiv:2309.03664v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03664</link>
<description rdf:parseType="Literal">&lt;p&gt;The cerebrospinal fluid (CSF) of 19 subjects who received a clinical
diagnosis of Alzheimer&apos;s disease (AD) as well as of 5 pathological controls
have been collected and analysed by Raman spectroscopy (RS). We investigated
whether the raw and preprocessed Raman spectra could be used to distinguish AD
from controls. First, we applied standard Machine Learning (ML) methods
obtaining unsatisfactory results. Then, we applied ML to a set of topological
descriptors extracted from raw spectra, achieving a very good classification
accuracy (&amp;gt;87%). Although our results are preliminary, they indicate that RS
and topological analysis together may provide an effective combination to
confirm or disprove a clinical diagnosis of AD. The next steps will include
enlarging the dataset of CSF samples to validate the proposed method better
and, possibly, to understand if topological data analysis could support the
characterization of AD subtypes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conti_F/0/1/0/all/0/1&quot;&gt;Francesco Conti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banchelli_M/0/1/0/all/0/1&quot;&gt;Martina Banchelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bessi_V/0/1/0/all/0/1&quot;&gt;Valentina Bessi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cecchi_C/0/1/0/all/0/1&quot;&gt;Cristina Cecchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiti_F/0/1/0/all/0/1&quot;&gt;Fabrizio Chiti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colantonio_S/0/1/0/all/0/1&quot;&gt;Sara Colantonio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DAndrea_C/0/1/0/all/0/1&quot;&gt;Cristiano D&amp;#x27;Andrea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angelis_M/0/1/0/all/0/1&quot;&gt;Marella de Angelis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moroni_D/0/1/0/all/0/1&quot;&gt;Davide Moroni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nacmias_B/0/1/0/all/0/1&quot;&gt;Benedetta Nacmias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pascali_M/0/1/0/all/0/1&quot;&gt;Maria Antonietta Pascali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sorbi_S/0/1/0/all/0/1&quot;&gt;Sandro Sorbi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matteini_P/0/1/0/all/0/1&quot;&gt;Paolo Matteini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03665">
<title>How adversarial attacks can disrupt seemingly stable accurate classifiers. (arXiv:2309.03665v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03665</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial attacks dramatically change the output of an otherwise accurate
learning system using a seemingly inconsequential modification to a piece of
input data. Paradoxically, empirical evidence indicates that even systems which
are robust to large random perturbations of the input data remain susceptible
to small, easily constructed, adversarial perturbations of their inputs. Here,
we show that this may be seen as a fundamental feature of classifiers working
with high dimensional input data. We introduce a simple generic and
generalisable framework for which key behaviours observed in practical systems
arise with high probability -- notably the simultaneous susceptibility of the
(otherwise accurate) model to easily constructed adversarial attacks, and
robustness to random perturbations of the input data. We confirm that the same
phenomena are directly observed in practical neural networks trained on
standard image classification problems, where even large additive random noise
fails to trigger the adversarial instability of the network. A surprising
takeaway is that even small margins separating a classifier&apos;s decision surface
from training and testing data can hide adversarial susceptibility from being
detected using randomly sampled perturbations. Counterintuitively, using
additive noise during training or testing is therefore inefficient for
eradicating or detecting adversarial examples, and more demanding adversarial
training is required.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_O/0/1/0/all/0/1&quot;&gt;Oliver J. Sutton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1&quot;&gt;Qinghua Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1&quot;&gt;Ivan Y. Tyukin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorban_A/0/1/0/all/0/1&quot;&gt;Alexander N. Gorban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastounis_A/0/1/0/all/0/1&quot;&gt;Alexander Bastounis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Higham_D/0/1/0/all/0/1&quot;&gt;Desmond J. Higham&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03671">
<title>Dataset Generation and Bonobo Classification from Weakly Labelled Videos. (arXiv:2309.03671v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03671</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a bonobo detection and classification pipeline built from
the commonly used machine learning methods. Such application is motivated by
the need to test bonobos in their enclosure using touch screen devices without
human assistance. This work introduces a newly acquired dataset based on bonobo
recordings generated semi-automatically. The recordings are weakly labelled and
fed to a macaque detector in order to spatially detect the individual present
in the video. Handcrafted features coupled with different classification
algorithms and deep-learning methods using a ResNet architecture are
investigated for bonobo identification. Performance is compared in terms of
classification accuracy on the splits of the database using different data
separation methods. We demonstrate the importance of data preparation and how a
wrong data separation can lead to false good results. Finally, after a
meaningful separation of the data, the best classification performance is
obtained using a fine-tuned ResNet model and reaches 75% of accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_P/0/1/0/all/0/1&quot;&gt;Pierre-Etienne Martin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03672">
<title>A computationally lightweight safe learning algorithm. (arXiv:2309.03672v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2309.03672</link>
<description rdf:parseType="Literal">&lt;p&gt;Safety is an essential asset when learning control policies for physical
systems, as violating safety constraints during training can lead to expensive
hardware damage. In response to this need, the field of safe learning has
emerged with algorithms that can provide probabilistic safety guarantees
without knowledge of the underlying system dynamics. Those algorithms often
rely on Gaussian process inference. Unfortunately, Gaussian process inference
scales cubically with the number of data points, limiting applicability to
high-dimensional and embedded systems. In this paper, we propose a safe
learning algorithm that provides probabilistic safety guarantees but leverages
the Nadaraya-Watson estimator instead of Gaussian processes. For the
Nadaraya-Watson estimator, we can reach logarithmic scaling with the number of
data points. We provide theoretical guarantees for the estimates, embed them
into a safe learning algorithm, and show numerical experiments on a simulated
seven-degrees-of-freedom robot manipulator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Baumann_D/0/1/0/all/0/1&quot;&gt;Dominik Baumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kowalczyk_K/0/1/0/all/0/1&quot;&gt;Krzysztof Kowalczyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tiels_K/0/1/0/all/0/1&quot;&gt;Koen Tiels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wachel_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; Wachel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03694">
<title>Short-Term Load Forecasting Using A Particle-Swarm Optimized Multi-Head Attention-Augmented CNN-LSTM Network. (arXiv:2309.03694v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03694</link>
<description rdf:parseType="Literal">&lt;p&gt;Short-term load forecasting is of paramount importance in the efficient
operation and planning of power systems, given its inherent non-linear and
dynamic nature. Recent strides in deep learning have shown promise in
addressing this challenge. However, these methods often grapple with
hyperparameter sensitivity, opaqueness in interpretability, and high
computational overhead for real-time deployment. In this paper, I propose a
novel solution that surmounts these obstacles. Our approach harnesses the power
of the Particle-Swarm Optimization algorithm to autonomously explore and
optimize hyperparameters, a Multi-Head Attention mechanism to discern the
salient features crucial for accurate forecasting, and a streamlined framework
for computational efficiency. Our method undergoes rigorous evaluation using a
genuine electricity demand dataset. The results underscore its superiority in
terms of accuracy, robustness, and computational efficiency. Notably, our Mean
Absolute Percentage Error of 1.9376 marks a significant advancement over
existing state-of-the-art approaches, heralding a new era in short-term load
forecasting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quansah_P/0/1/0/all/0/1&quot;&gt;Paapa Kwesi Quansah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03702">
<title>DiffDefense: Defending against Adversarial Attacks via Diffusion Models. (arXiv:2309.03702v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03702</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel reconstruction method that leverages Diffusion
Models to protect machine learning classifiers against adversarial attacks, all
without requiring any modifications to the classifiers themselves. The
susceptibility of machine learning models to minor input perturbations renders
them vulnerable to adversarial attacks. While diffusion-based methods are
typically disregarded for adversarial defense due to their slow reverse
process, this paper demonstrates that our proposed method offers robustness
against adversarial threats while preserving clean accuracy, speed, and
plug-and-play compatibility. Code at:
https://github.com/HondamunigePrasannaSilva/DiffDefence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_H/0/1/0/all/0/1&quot;&gt;Hondamunige Prasanna Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seidenari_L/0/1/0/all/0/1&quot;&gt;Lorenzo Seidenari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bimbo_A/0/1/0/all/0/1&quot;&gt;Alberto Del Bimbo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03707">
<title>A Probabilistic Semi-Supervised Approach with Triplet Markov Chains. (arXiv:2309.03707v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03707</link>
<description rdf:parseType="Literal">&lt;p&gt;Triplet Markov chains are general generative models for sequential data which
take into account three kinds of random variables: (noisy) observations, their
associated discrete labels and latent variables which aim at strengthening the
distribution of the observations and their associated labels. However, in
practice, we do not have at our disposal all the labels associated to the
observations to estimate the parameters of such models. In this paper, we
propose a general framework based on a variational Bayesian inference to train
parameterized triplet Markov chain models in a semi-supervised context. The
generality of our approach enables us to derive semi-supervised algorithms for
a variety of generative models for sequential Bayesian classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morales_K/0/1/0/all/0/1&quot;&gt;Katherine Morales&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Petetin_Y/0/1/0/all/0/1&quot;&gt;Yohan Petetin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03708">
<title>Chat Failures and Troubles: Reasons and Solutions. (arXiv:2309.03708v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.03708</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper examines some common problems in Human-Robot Interaction (HRI)
causing failures and troubles in Chat. A given use case&apos;s design decisions
start with the suitable robot, the suitable chatting model, identifying common
problems that cause failures, identifying potential solutions, and planning
continuous improvement. In conclusion, it is recommended to use a closed-loop
control algorithm that guides the use of trained Artificial Intelligence (AI)
pre-trained models and provides vocabulary filtering, re-train batched models
on new datasets, learn online from data streams, and/or use reinforcement
learning models to self-update the trained models and reduce errors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helal_M/0/1/0/all/0/1&quot;&gt;Manal Helal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holthaus_P/0/1/0/all/0/1&quot;&gt;Patrick Holthaus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakatos_G/0/1/0/all/0/1&quot;&gt;Gabriella Lakatos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amirabdollahian_F/0/1/0/all/0/1&quot;&gt;Farshid Amirabdollahian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03710">
<title>A State Representation for Diminishing Rewards. (arXiv:2309.03710v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03710</link>
<description rdf:parseType="Literal">&lt;p&gt;A common setting in multitask reinforcement learning (RL) demands that an
agent rapidly adapt to various stationary reward functions randomly sampled
from a fixed distribution. In such situations, the successor representation
(SR) is a popular framework which supports rapid policy evaluation by
decoupling a policy&apos;s expected discounted, cumulative state occupancies from a
specific reward function. However, in the natural world, sequential tasks are
rarely independent, and instead reflect shifting priorities based on the
availability and subjective perception of rewarding stimuli. Reflecting this
disjunction, in this paper we study the phenomenon of diminishing marginal
utility and introduce a novel state representation, the $\lambda$
representation ($\lambda$R) which, surprisingly, is required for policy
evaluation in this setting and which generalizes the SR as well as several
other state representations from the literature. We establish the $\lambda$R&apos;s
formal properties and examine its normative advantages in the context of
machine learning, as well as its usefulness for studying natural behaviors,
particularly foraging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moskovitz_T/0/1/0/all/0/1&quot;&gt;Ted Moskovitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hromadka_S/0/1/0/all/0/1&quot;&gt;Samo Hromadka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Touati_A/0/1/0/all/0/1&quot;&gt;Ahmed Touati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borsa_D/0/1/0/all/0/1&quot;&gt;Diana Borsa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahani_M/0/1/0/all/0/1&quot;&gt;Maneesh Sahani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03720">
<title>A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism. (arXiv:2309.03720v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03720</link>
<description rdf:parseType="Literal">&lt;p&gt;Forecasting natural gas consumption, considering seasonality and trends, is
crucial in planning its supply and consumption and optimizing the cost of
obtaining it, mainly by industrial entities. However, in times of threats to
its supply, it is also a critical element that guarantees the supply of this
raw material to meet individual consumers&apos; needs, ensuring society&apos;s energy
security. This article introduces a novel multistep ahead forecasting of
natural gas consumption with change point detection integration for model
collection selection with continual learning capabilities using data stream
processing. The performance of the forecasting models based on the proposed
approach is evaluated in a complex real-world use case of natural gas
consumption forecasting. We employed Hoeffding tree predictors as forecasting
models and the Pruned Exact Linear Time (PELT) algorithm for the change point
detection procedure. The change point detection integration enables selecting a
different model collection for successive time frames. Thus, three model
collection selection procedures (with and without an error feedback loop) are
defined and evaluated for forecasting scenarios with various densities of
detected change points. These models were compared with change point agnostic
baseline approaches. Our experiments show that fewer change points result in a
lower forecasting error regardless of the model collection selection procedure
employed. Also, simpler model collection selection procedures omitting
forecasting error feedback leads to more robust forecasting models suitable for
continual learning tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svoboda_R/0/1/0/all/0/1&quot;&gt;Radek Svoboda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basterrech_S/0/1/0/all/0/1&quot;&gt;Sebastian Basterrech&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozal_J/0/1/0/all/0/1&quot;&gt;J&amp;#x119;drzej Kozal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Platos_J/0/1/0/all/0/1&quot;&gt;Jan Plato&amp;#x161;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wozniak_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Wo&amp;#x17a;niak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03730">
<title>A Causal Perspective on Loan Pricing: Investigating the Impacts of Selection Bias on Identifying Bid-Response Functions. (arXiv:2309.03730v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03730</link>
<description rdf:parseType="Literal">&lt;p&gt;In lending, where prices are specific to both customers and products, having
a well-functioning personalized pricing policy in place is essential to
effective business making. Typically, such a policy must be derived from
observational data, which introduces several challenges. While the problem of
``endogeneity&apos;&apos; is prominently studied in the established pricing literature,
the problem of selection bias (or, more precisely, bid selection bias) is not.
We take a step towards understanding the effects of selection bias by posing
pricing as a problem of causal inference. Specifically, we consider the
reaction of a customer to price a treatment effect. In our experiments, we
simulate varying levels of selection bias on a semi-synthetic dataset on
mortgage loan applications in Belgium. We investigate the potential of
parametric and nonparametric methods for the identification of individual
bid-response functions. Our results illustrate how conventional methods such as
logistic regression and neural networks suffer adversely from selection bias.
In contrast, we implement state-of-the-art methods from causal machine learning
and show their capability to overcome selection bias in pricing data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bockel_Rickermann_C/0/1/0/all/0/1&quot;&gt;Christopher Bockel-Rickermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verboven_S/0/1/0/all/0/1&quot;&gt;Sam Verboven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verdonck_T/0/1/0/all/0/1&quot;&gt;Tim Verdonck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verbeke_W/0/1/0/all/0/1&quot;&gt;Wouter Verbeke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03731">
<title>Learning continuous-valued treatment effects through representation balancing. (arXiv:2309.03731v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03731</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the effects of treatments with an associated dose on an instance&apos;s
outcome, the &quot;dose response&quot;, is relevant in a variety of domains, from
healthcare to business, economics, and beyond. Such effects, also known as
continuous-valued treatment effects, are typically estimated from observational
data, which may be subject to dose selection bias. This means that the
allocation of doses depends on pre-treatment covariates. Previous studies have
shown that conventional machine learning approaches fail to learn accurate
individual estimates of dose responses under the presence of dose selection
bias. In this work, we propose CBRNet, a causal machine learning approach to
estimate an individual dose response from observational data. CBRNet adopts the
Neyman-Rubin potential outcome framework and extends the concept of balanced
representation learning for overcoming selection bias to continuous-valued
treatments. Our work is the first to apply representation balancing in a
continuous-valued treatment setting. We evaluate our method on a newly proposed
benchmark. Our experiments demonstrate CBRNet&apos;s ability to accurately learn
treatment effects under selection bias and competitive performance with respect
to other state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bockel_Rickermann_C/0/1/0/all/0/1&quot;&gt;Christopher Bockel-Rickermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanderschueren_T/0/1/0/all/0/1&quot;&gt;Toon Vanderschueren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berrevoets_J/0/1/0/all/0/1&quot;&gt;Jeroen Berrevoets&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verdonck_T/0/1/0/all/0/1&quot;&gt;Tim Verdonck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verbeke_W/0/1/0/all/0/1&quot;&gt;Wouter Verbeke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03748">
<title>Enhancing Pipeline-Based Conversational Agents with Large Language Models. (arXiv:2309.03748v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.03748</link>
<description rdf:parseType="Literal">&lt;p&gt;The latest advancements in AI and deep learning have led to a breakthrough in
large language model (LLM)-based agents such as GPT-4. However, many commercial
conversational agent development tools are pipeline-based and have limitations
in holding a human-like conversation. This paper investigates the capabilities
of LLMs to enhance pipeline-based conversational agents during two phases: 1)
in the design and development phase and 2) during operations. In 1) LLMs can
aid in generating training data, extracting entities and synonyms,
localization, and persona design. In 2) LLMs can assist in contextualization,
intent classification to prevent conversational breakdown and handle
out-of-scope questions, auto-correcting utterances, rephrasing responses,
formulating disambiguation questions, summarization, and enabling closed
question-answering capabilities. We conducted informal experiments with GPT-4
in the private banking domain to demonstrate the scenarios above with a
practical example. Companies may be hesitant to replace their pipeline-based
agents with LLMs entirely due to privacy concerns and the need for deep
integration within their existing ecosystems. A hybrid approach in which LLMs&apos;
are integrated into the pipeline-based agents allows them to save time and
costs of building and running agents by capitalizing on the capabilities of
LLMs while retaining the integration and privacy safeguards of their existing
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foosherian_M/0/1/0/all/0/1&quot;&gt;Mina Foosherian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purwins_H/0/1/0/all/0/1&quot;&gt;Hendrik Purwins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rathnayake_P/0/1/0/all/0/1&quot;&gt;Purna Rathnayake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1&quot;&gt;Touhidul Alam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teimao_R/0/1/0/all/0/1&quot;&gt;Rui Teimao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thoben_K/0/1/0/all/0/1&quot;&gt;Klaus-Dieter Thoben&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03751">
<title>Medoid Silhouette clustering with automatic cluster number selection. (arXiv:2309.03751v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03751</link>
<description rdf:parseType="Literal">&lt;p&gt;The evaluation of clustering results is difficult, highly dependent on the
evaluated data set and the perspective of the beholder. There are many
different clustering quality measures, which try to provide a general measure
to validate clustering results. A very popular measure is the Silhouette. We
discuss the efficient medoid-based variant of the Silhouette, perform a
theoretical analysis of its properties, provide two fast versions for the
direct optimization, and discuss the use to choose the optimal number of
clusters. We combine ideas from the original Silhouette with the well-known PAM
algorithm and its latest improvements FasterPAM. One of the versions guarantees
equal results to the original variant and provides a run speedup of $O(k^2)$.
In experiments on real data with 30000 samples and $k$=100, we observed a
10464$\times$ speedup compared to the original PAMMEDSIL algorithm.
Additionally, we provide a variant to choose the optimal number of clusters
directly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lenssen_L/0/1/0/all/0/1&quot;&gt;Lars Lenssen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schubert_E/0/1/0/all/0/1&quot;&gt;Erich Schubert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03754">
<title>Convergence Analysis of Decentralized ASGD. (arXiv:2309.03754v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03754</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the last decades, Stochastic Gradient Descent (SGD) has been intensively
studied by the Machine Learning community. Despite its versatility and
excellent performance, the optimization of large models via SGD still is a
time-consuming task. To reduce training time, it is common to distribute the
training process across multiple devices. Recently, it has been shown that the
convergence of asynchronous SGD (ASGD) will always be faster than mini-batch
SGD. However, despite these improvements in the theoretical bounds, most ASGD
convergence-rate proofs still rely on a centralized parameter server, which is
prone to become a bottleneck when scaling out the gradient computations across
many distributed processes.
&lt;/p&gt;
&lt;p&gt;In this paper, we present a novel convergence-rate analysis for decentralized
and asynchronous SGD (DASGD) which does not require partial synchronization
among nodes nor restrictive network topologies. Specifically, we provide a
bound of $\mathcal{O}(\sigma\epsilon^{-2}) +
\mathcal{O}(QS_{avg}\epsilon^{-3/2}) + \mathcal{O}(S_{avg}\epsilon^{-1})$ for
the convergence rate of DASGD, where $S_{avg}$ is the average staleness between
models, $Q$ is a constant that bounds the norm of the gradients, and $\epsilon$
is a (small) error that is allowed within the bound. Furthermore, when
gradients are not bounded, we prove the convergence rate of DASGD to be
$\mathcal{O}(\sigma\epsilon^{-2}) +
\mathcal{O}(\sqrt{\hat{S}_{avg}\hat{S}_{max}}\epsilon^{-1})$, with
$\hat{S}_{max}$ and $\hat{S}_{avg}$ representing a loose version of the average
and maximum staleness, respectively. Our convergence proof holds for a fixed
stepsize and any non-convex, homogeneous, and L-smooth objective function. We
anticipate that our results will be of high relevance for the adoption of DASGD
by a broad community of researchers and developers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tosi_M/0/1/0/all/0/1&quot;&gt;Mauro DL Tosi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Theobald_M/0/1/0/all/0/1&quot;&gt;Martin Theobald&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03755">
<title>TSGBench: Time Series Generation Benchmark. (arXiv:2309.03755v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03755</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthetic Time Series Generation (TSG) is crucial in a range of applications,
including data augmentation, anomaly detection, and privacy preservation.
Although significant strides have been made in this field, existing methods
exhibit three key limitations: (1) They often benchmark against similar model
types, constraining a holistic view of performance capabilities. (2) The use of
specialized synthetic and private datasets introduces biases and hampers
generalizability. (3) Ambiguous evaluation measures, often tied to custom
networks or downstream tasks, hinder consistent and fair comparison.
&lt;/p&gt;
&lt;p&gt;To overcome these limitations, we introduce \textsf{TSGBench}, the inaugural
TSG Benchmark, designed for a unified and comprehensive assessment of TSG
methods. It comprises three modules: (1) a curated collection of publicly
available, real-world datasets tailored for TSG, together with a standardized
preprocessing pipeline; (2) a comprehensive evaluation measures suite including
vanilla measures, new distance-based assessments, and visualization tools; (3)
a pioneering generalization test rooted in Domain Adaptation (DA), compatible
with all methods. We have conducted extensive experiments across ten real-world
datasets from diverse domains, utilizing ten advanced TSG methods and twelve
evaluation measures, all gauged through \textsf{TSGBench}. The results
highlight its remarkable efficacy and consistency. More importantly,
\textsf{TSGBench} delivers a statistical breakdown of method rankings,
illuminating performance variations across different datasets and measures, and
offering nuanced insights into the effectiveness of each method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ang_Y/0/1/0/all/0/1&quot;&gt;Yihao Ang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1&quot;&gt;Yifan Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tung_A/0/1/0/all/0/1&quot;&gt;Anthony K. H. Tung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03759">
<title>M(otion)-mode Based Prediction of Ejection Fraction using Echocardiograms. (arXiv:2309.03759v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.03759</link>
<description rdf:parseType="Literal">&lt;p&gt;Early detection of cardiac dysfunction through routine screening is vital for
diagnosing cardiovascular diseases. An important metric of cardiac function is
the left ventricular ejection fraction (EF), where lower EF is associated with
cardiomyopathy. Echocardiography is a popular diagnostic tool in cardiology,
with ultrasound being a low-cost, real-time, and non-ionizing technology.
However, human assessment of echocardiograms for calculating EF is
time-consuming and expertise-demanding, raising the need for an automated
approach. In this work, we propose using the M(otion)-mode of echocardiograms
for estimating the EF and classifying cardiomyopathy. We generate multiple
artificial M-mode images from a single echocardiogram and combine them using
off-the-shelf model architectures. Additionally, we extend contrastive learning
(CL) to cardiac imaging to learn meaningful representations from exploiting
structures in unlabeled data allowing the model to achieve high accuracy, even
with limited annotations. Our experiments show that the supervised setting
converges with only ten modes and is comparable to the baseline method while
bypassing its cumbersome training process and being computationally much more
efficient. Furthermore, CL using M-mode images is helpful for limited data
scenarios, such as having labels for only 200 patients, which is common in
medical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ozkan_E/0/1/0/all/0/1&quot;&gt;Ece Ozkan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sutter_T/0/1/0/all/0/1&quot;&gt;Thomas M. Sutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yurong Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Balzer_S/0/1/0/all/0/1&quot;&gt;Sebastian Balzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Vogt_J/0/1/0/all/0/1&quot;&gt;Julia E. Vogt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03770">
<title>Neural lasso: a unifying approach of lasso and neural networks. (arXiv:2309.03770v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03770</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, there is a growing interest in combining techniques
attributed to the areas of Statistics and Machine Learning in order to obtain
the benefits of both approaches. In this article, the statistical technique
lasso for variable selection is represented through a neural network. It is
observed that, although both the statistical approach and its neural version
have the same objective function, they differ due to their optimization. In
particular, the neural version is usually optimized in one-step using a single
validation set, while the statistical counterpart uses a two-step optimization
based on cross-validation. The more elaborated optimization of the statistical
method results in more accurate parameter estimation, especially when the
training set is small. For this reason, a modification of the standard approach
for training neural networks, that mimics the statistical framework, is
proposed. During the development of the above modification, a new optimization
algorithm for identifying the significant variables emerged. Experimental
results, using synthetic and real data sets, show that this new optimization
algorithm achieves better performance than any of the three previous
optimization approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Delgado_D/0/1/0/all/0/1&quot;&gt;David Delgado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Curbelo_E/0/1/0/all/0/1&quot;&gt;Ernesto Curbelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carreras_D/0/1/0/all/0/1&quot;&gt;Danae Carreras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03774">
<title>Deep Learning Safety Concerns in Automated Driving Perception. (arXiv:2309.03774v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03774</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in the field of deep learning and impressive performance of
deep neural networks (DNNs) for perception have resulted in an increased demand
for their use in automated driving (AD) systems. The safety of such systems is
of utmost importance and thus requires to consider the unique properties of
DNNs.
&lt;/p&gt;
&lt;p&gt;In order to achieve safety of AD systems with DNN-based perception components
in a systematic and comprehensive approach, so-called safety concerns have been
introduced as a suitable structuring element. On the one hand, the concept of
safety concerns is -- by design -- well aligned to existing standards relevant
for safety of AD systems such as ISO 21448 (SOTIF). On the other hand, it has
already inspired several academic publications and upcoming standards on AI
safety such as ISO PAS 8800.
&lt;/p&gt;
&lt;p&gt;While the concept of safety concerns has been previously introduced, this
paper extends and refines it, leveraging feedback from various domain and
safety experts in the field. In particular, this paper introduces an additional
categorization for a better understanding as well as enabling cross-functional
teams to jointly address the concerns.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abrecht_S/0/1/0/all/0/1&quot;&gt;Stephanie Abrecht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hirsch_A/0/1/0/all/0/1&quot;&gt;Alexander Hirsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raafatnia_S/0/1/0/all/0/1&quot;&gt;Shervin Raafatnia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woehrle_M/0/1/0/all/0/1&quot;&gt;Matthias Woehrle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03779">
<title>CPU frequency scheduling of real-time applications on embedded devices with temporal encoding-based deep reinforcement learning. (arXiv:2309.03779v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03779</link>
<description rdf:parseType="Literal">&lt;p&gt;Small devices are frequently used in IoT and smart-city applications to
perform periodic dedicated tasks with soft deadlines. This work focuses on
developing methods to derive efficient power-management methods for periodic
tasks on small devices. We first study the limitations of the existing Linux
built-in methods used in small devices. We illustrate three typical
workload/system patterns that are challenging to manage with Linux&apos;s built-in
solutions. We develop a reinforcement-learning-based technique with temporal
encoding to derive an effective DVFS governor even with the presence of the
three system patterns. The derived governor uses only one performance counter,
the same as the built-in Linux mechanism, and does not require an explicit task
model for the workload. We implemented a prototype system on the Nvidia Jetson
Nano Board and experimented with it with six applications, including two
self-designed and four benchmark applications. Under different deadline
constraints, our approach can quickly derive a DVFS governor that can adapt to
performance requirements and outperform the built-in Linux approach in energy
saving. On Mibench workloads, with performance slack ranging from 0.04 s to 0.4
s, the proposed method can save 3% - 11% more energy compared to Ondemand.
AudioReg and FaceReg applications tested have 5%- 14% energy-saving
improvement. We have open-sourced the implementation of our in-kernel quantized
neural network engine. The codebase can be found at:
https://github.com/coladog/tinyagent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Ti Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1&quot;&gt;Man Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03780">
<title>Reduced Simulations for High-Energy Physics, a Middle Ground for Data-Driven Physics Research. (arXiv:2309.03780v1 [hep-ex])</title>
<link>http://arxiv.org/abs/2309.03780</link>
<description rdf:parseType="Literal">&lt;p&gt;Subatomic particle track reconstruction (tracking) is a vital task in
High-Energy Physics experiments. Tracking is exceptionally computationally
challenging and fielded solutions, relying on traditional algorithms, do not
scale linearly. Machine Learning (ML) assisted solutions are a promising
answer. We argue that a complexity-reduced problem description and the data
representing it, will facilitate the solution exploration workflow. We provide
the REDuced VIrtual Detector (REDVID) as a complexity-reduced detector model
and particle collision event simulator combo. REDVID is intended as a
simulation-in-the-loop, to both generate synthetic data efficiently and to
simplify the challenge of ML model design. The fully parametric nature of our
tool, with regards to system-level configuration, while in contrast to
physics-accurate simulations, allows for the generation of simplified data for
research and education, at different levels. Resulting from the reduced
complexity, we showcase the computational efficiency of REDVID by providing the
computational cost figures for a multitude of simulation benchmarks. As a
simulation and a generative tool for ML-assisted solution design, REDVID is
highly flexible, reusable and open-source. Reference data sets generated with
REDVID are publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Odyurt_U/0/1/0/all/0/1&quot;&gt;Uraz Odyurt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Swatman_S/0/1/0/all/0/1&quot;&gt;Stephen Nicholas Swatman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Varbanescu_A/0/1/0/all/0/1&quot;&gt;Ana-Lucia Varbanescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Caron_S/0/1/0/all/0/1&quot;&gt;Sascha Caron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03791">
<title>Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences. (arXiv:2309.03791v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03791</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the $ARMOR_D$ methods as novel approaches to enhancing the
adversarial robustness of deep learning models. These methods are based on a
new class of optimal-transport-regularized divergences, constructed via an
infimal convolution between an information divergence and an optimal-transport
(OT) cost. We use these as tools to enhance adversarial robustness by
maximizing the expected loss over a neighborhood of distributions, a technique
known as distributionally robust optimization. Viewed as a tool for
constructing adversarial samples, our method allows samples to be both
transported, according to the OT cost, and re-weighted, according to the
information divergence. We demonstrate the effectiveness of our method on
malware detection and image recognition applications and find that, to our
knowledge, it outperforms existing methods at enhancing the robustness against
adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\%$
against $FGSM$ and $98.18\%$ against $PGD^{40}$ on the MNIST dataset, reducing
the error rate by more than $19.7\%$ and $37.2\%$ respectively compared to
prior methods. Similarly, in malware detection, a discrete (binary) data
domain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack
compared to the previous best-performing adversarial training methods by
$37.0\%$ while lowering false negative and false positive rates by $51.1\%$ and
$57.53\%$, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Birrell_J/0/1/0/all/0/1&quot;&gt;Jeremiah Birrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebrahimi_M/0/1/0/all/0/1&quot;&gt;Mohammadreza Ebrahimi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03797">
<title>Conformal Autoregressive Generation: Beam Search with Coverage Guarantees. (arXiv:2309.03797v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03797</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce two new extensions to the beam search algorithm based on
conformal predictions (CP) to produce sets of sequences with theoretical
coverage guarantees. The first method is very simple and proposes
dynamically-sized subsets of beam search results but, unlike typical CP
procedures, has an upper bound on the achievable guarantee depending on a
post-hoc calibration measure. Our second algorithm introduces the conformal set
prediction procedure as part of the decoding process, producing a variable beam
width which adapts to the current uncertainty. While more complex, this
procedure can achieve coverage guarantees selected a priori. We provide
marginal coverage bounds for each method, and evaluate them empirically on a
selection of tasks drawing from natural language processing and chemistry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deutschmann_N/0/1/0/all/0/1&quot;&gt;Nicolas Deutschmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alberts_M/0/1/0/all/0/1&quot;&gt;Marvin Alberts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinez_M/0/1/0/all/0/1&quot;&gt;Mar&amp;#xed;a Rodr&amp;#xed;guez Mart&amp;#xed;nez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03800">
<title>Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck. (arXiv:2309.03800v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03800</link>
<description rdf:parseType="Literal">&lt;p&gt;This work investigates the nuanced algorithm design choices for deep learning
in the presence of computational-statistical gaps. We begin by considering
offline sparse parity learning, a supervised classification problem which
admits a statistical query lower bound for gradient-based training of a
multilayer perceptron. This lower bound can be interpreted as a multi-resource
tradeoff frontier: successful learning can only occur if one is sufficiently
rich (large model), knowledgeable (large dataset), patient (many training
iterations), or lucky (many random guesses). We show, theoretically and
experimentally, that sparse initialization and increasing network width yield
significant improvements in sample efficiency in this setting. Here, width
plays the role of parallel search: it amplifies the probability of finding
&quot;lottery ticket&quot; neurons, which learn sparse features more sample-efficiently.
Finally, we show that the synthetic sparse parity task can be useful as a proxy
for real problems requiring axis-aligned feature learning. We demonstrate
improved sample efficiency on tabular classification benchmarks by using wide,
sparsely-initialized MLP models; these networks sometimes outperform tuned
random forests.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edelman_B/0/1/0/all/0/1&quot;&gt;Benjamin L. Edelman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1&quot;&gt;Surbhi Goel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malach_E/0/1/0/all/0/1&quot;&gt;Eran Malach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cyril Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03808">
<title>Improved theoretical guarantee for rank aggregation via spectral method. (arXiv:2309.03808v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03808</link>
<description rdf:parseType="Literal">&lt;p&gt;Given pairwise comparisons between multiple items, how to rank them so that
the ranking matches the observations? This problem, known as rank aggregation,
has found many applications in sports, recommendation systems, and other web
applications. As it is generally NP-hard to find a global ranking that
minimizes the mismatch (known as the Kemeny optimization), we focus on the
Erd\&quot;os-R\&apos;enyi outliers (ERO) model for this ranking problem. Here, each
pairwise comparison is a corrupted copy of the true score difference. We
investigate spectral ranking algorithms that are based on unnormalized and
normalized data matrices. The key is to understand their performance in
recovering the underlying scores of each item from the observed data. This
reduces to deriving an entry-wise perturbation error bound between the top
eigenvectors of the unnormalized/normalized data matrix and its population
counterpart. By using the leave-one-out technique, we provide a sharper
$\ell_{\infty}$-norm perturbation bound of the eigenvectors and also derive an
error bound on the maximum displacement for each item, with only $\Omega(n\log
n)$ samples. Our theoretical analysis improves upon the state-of-the-art
results in terms of sample complexity, and our numerical experiments confirm
these theoretical findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhong_Z/0/1/0/all/0/1&quot;&gt;Ziliang Samuel Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ling_S/0/1/0/all/0/1&quot;&gt;Shuyang Ling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03812">
<title>AnthroNet: Conditional Generation of Humans via Anthropometrics. (arXiv:2309.03812v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03812</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel human body model formulated by an extensive set of
anthropocentric measurements, which is capable of generating a wide range of
human body shapes and poses. The proposed model enables direct modeling of
specific human identities through a deep generative architecture, which can
produce humans in any arbitrary pose. It is the first of its kind to have been
trained end-to-end using only synthetically generated data, which not only
provides highly accurate human mesh representations but also allows for precise
anthropometry of the body. Moreover, using a highly diverse animation library,
we articulated our synthetic humans&apos; body and hands to maximize the diversity
of the learnable priors for model training. Our model was trained on a dataset
of $100k$ procedurally-generated posed human meshes and their corresponding
anthropometric measurements. Our synthetic data generator can be used to
generate millions of unique human identities and poses for non-commercial
academic research purposes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Picetti_F/0/1/0/all/0/1&quot;&gt;Francesco Picetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_S/0/1/0/all/0/1&quot;&gt;Shrinath Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leban_J/0/1/0/all/0/1&quot;&gt;Jonathan Leban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahtalebi_S/0/1/0/all/0/1&quot;&gt;Soroosh Shahtalebi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_J/0/1/0/all/0/1&quot;&gt;Jay Patel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jing_P/0/1/0/all/0/1&quot;&gt;Peifeng Jing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chunpu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metze_C/0/1/0/all/0/1&quot;&gt;Charles Metze III&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1&quot;&gt;Cameron Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laidlaw_C/0/1/0/all/0/1&quot;&gt;Cera Laidlaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Warren_J/0/1/0/all/0/1&quot;&gt;James Warren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huynh_K/0/1/0/all/0/1&quot;&gt;Kathy Huynh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Page_R/0/1/0/all/0/1&quot;&gt;River Page&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hogins_J/0/1/0/all/0/1&quot;&gt;Jonathan Hogins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crespi_A/0/1/0/all/0/1&quot;&gt;Adam Crespi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_S/0/1/0/all/0/1&quot;&gt;Sujoy Ganguly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebadi_S/0/1/0/all/0/1&quot;&gt;Salehe Erfanian Ebadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03818">
<title>Empirical Risk Minimization for Losses without Variance. (arXiv:2309.03818v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03818</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers an empirical risk minimization problem under
heavy-tailed settings, where data does not have finite variance, but only has
$p$-th moment with $p \in (1,2)$. Instead of using estimation procedure based
on truncated observed data, we choose the optimizer by minimizing the risk
value. Those risk values can be robustly estimated via using the remarkable
Catoni&apos;s method (Catoni, 2012). Thanks to the structure of Catoni-type
influence functions, we are able to establish excess risk upper bounds via
using generalized generic chaining methods. Moreover, we take computational
issues into consideration. We especially theoretically investigate two types of
optimization methods, robust gradient descent algorithm and empirical
risk-based methods. With an extensive numerical study, we find that the
optimizer based on empirical risks via Catoni-style estimation indeed shows
better performance than other baselines. It indicates that estimation directly
based on truncated data may lead to unsatisfactory results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fang_G/0/1/0/all/0/1&quot;&gt;Guanhua Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Ping Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Samorodnitsky_G/0/1/0/all/0/1&quot;&gt;Gennady Samorodnitsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03824">
<title>Training Acceleration of Low-Rank Decomposed Networks using Sequential Freezing and Rank Quantization. (arXiv:2309.03824v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03824</link>
<description rdf:parseType="Literal">&lt;p&gt;Low Rank Decomposition (LRD) is a model compression technique applied to the
weight tensors of deep learning models in order to reduce the number of
trainable parameters and computational complexity. However, due to high number
of new layers added to the architecture after applying LRD, it may not lead to
a high training/inference acceleration if the decomposition ranks are not small
enough. The issue is that using small ranks increases the risk of significant
accuracy drop after decomposition. In this paper, we propose two techniques for
accelerating low rank decomposed models without requiring to use small ranks
for decomposition. These methods include rank optimization and sequential
freezing of decomposed layers. We perform experiments on both convolutional and
transformer-based models. Experiments show that these techniques can improve
the model throughput up to 60% during training and 37% during inference when
combined together while preserving the accuracy close to that of the original
models
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajimolahoseini_H/0/1/0/all/0/1&quot;&gt;Habib Hajimolahoseini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_W/0/1/0/all/0/1&quot;&gt;Walid Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03825">
<title>Prime and Modulate Learning: Generation of forward models with signed back-propagation and environmental cues. (arXiv:2309.03825v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03825</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks employing error back-propagation for learning can suffer
from exploding and vanishing gradient problems. Numerous solutions have been
proposed such as normalisation techniques or limiting activation functions to
linear rectifying units. In this work we follow a different approach which is
particularly applicable to closed-loop learning of forward models where
back-propagation makes exclusive use of the sign of the error signal to prime
the learning, whilst a global relevance signal modulates the rate of learning.
This is inspired by the interaction between local plasticity and a global
neuromodulation. For example, whilst driving on an empty road, one can allow
for slow step-wise optimisation of actions, whereas, at a busy junction, an
error must be corrected at once. Hence, the error is the priming signal and the
intensity of the experience is a modulating factor in the weight change. The
advantages of this Prime and Modulate paradigm is twofold: it is free from
normalisation and it makes use of relevant cues from the environment to enrich
the learning. We present a mathematical derivation of the learning rule in
z-space and demonstrate the real-time performance with a robotic platform. The
results show a significant improvement in the speed of convergence compared to
that of the conventional back-propagation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daryanavard_S/0/1/0/all/0/1&quot;&gt;Sama Daryanavard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Porr_B/0/1/0/all/0/1&quot;&gt;Bernd Porr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03827">
<title>ArtHDR-Net: Perceptually Realistic and Accurate HDR Content Creation. (arXiv:2309.03827v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03827</link>
<description rdf:parseType="Literal">&lt;p&gt;High Dynamic Range (HDR) content creation has become an important topic for
modern media and entertainment sectors, gaming and Augmented/Virtual Reality
industries. Many methods have been proposed to recreate the HDR counterparts of
input Low Dynamic Range (LDR) images/videos given a single exposure or
multi-exposure LDRs. The state-of-the-art methods focus primarily on the
preservation of the reconstruction&apos;s structural similarity and the pixel-wise
accuracy. However, these conventional approaches do not emphasize preserving
the artistic intent of the images in terms of human visual perception, which is
an essential element in media, entertainment and gaming. In this paper, we
attempt to study and fill this gap. We propose an architecture called
ArtHDR-Net based on a Convolutional Neural Network that uses multi-exposed LDR
features as input. Experimental results show that ArtHDR-Net can achieve
state-of-the-art performance in terms of the HDR-VDP-2 score (i.e., mean
opinion score index) while reaching competitive performance in terms of PSNR
and SSIM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barua_H/0/1/0/all/0/1&quot;&gt;Hrishav Bakul Barua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnasamy_G/0/1/0/all/0/1&quot;&gt;Ganesh Krishnasamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1&quot;&gt;KokSheik Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stefanov_K/0/1/0/all/0/1&quot;&gt;Kalin Stefanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhall_A/0/1/0/all/0/1&quot;&gt;Abhinav Dhall&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03831">
<title>Uncovering Drift in Textual Data: An Unsupervised Method for Detecting and Mitigating Drift in Machine Learning Models. (arXiv:2309.03831v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.03831</link>
<description rdf:parseType="Literal">&lt;p&gt;Drift in machine learning refers to the phenomenon where the statistical
properties of data or context, in which the model operates, change over time
leading to a decrease in its performance. Therefore, maintaining a constant
monitoring process for machine learning model performance is crucial in order
to proactively prevent any potential performance regression. However,
supervised drift detection methods require human annotation and consequently
lead to a longer time to detect and mitigate the drift. In our proposed
unsupervised drift detection method, we follow a two step process. Our first
step involves encoding a sample of production data as the target distribution,
and the model training data as the reference distribution. In the second step,
we employ a kernel-based statistical test that utilizes the maximum mean
discrepancy (MMD) distance metric to compare the reference and target
distributions and estimate any potential drift. Our method also identifies the
subset of production data that is the root cause of the drift. The models
retrained using these identified high drift samples show improved performance
on online customer experience quality metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khaki_S/0/1/0/all/0/1&quot;&gt;Saeed Khaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aditya_A/0/1/0/all/0/1&quot;&gt;Akhouri Abhinav Aditya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karnin_Z/0/1/0/all/0/1&quot;&gt;Zohar Karnin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_O/0/1/0/all/0/1&quot;&gt;Olivia Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandrashekar_S/0/1/0/all/0/1&quot;&gt;Samarth Marudheri Chandrashekar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03835">
<title>Learning from Demonstration via Probabilistic Diagrammatic Teaching. (arXiv:2309.03835v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.03835</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning for Demonstration (LfD) enables robots to acquire new skills by
imitating expert demonstrations, allowing users to communicate their
instructions in an intuitive manner. Recent progress in LfD often relies on
kinesthetic teaching or teleoperation as the medium for users to specify the
demonstrations. Kinesthetic teaching requires physical handling of the robot,
while teleoperation demands proficiency with additional hardware. This paper
introduces an alternative paradigm for LfD called Diagrammatic Teaching.
Diagrammatic Teaching aims to teach robots novel skills by prompting the user
to sketch out demonstration trajectories on 2D images of the scene, these are
then synthesised as a generative model of motion trajectories in 3D task space.
Additionally, we present the Ray-tracing Probabilistic Trajectory Learning
(RPTL) framework for Diagrammatic Teaching. RPTL extracts time-varying
probability densities from the 2D sketches, applies ray-tracing to find
corresponding regions in 3D Cartesian space, and fits a probabilistic model of
motion trajectories to these regions. New motion trajectories, which mimic
those sketched by the user, can then be generated from the probabilistic model.
We empirically validate our framework both in simulation and on real robots,
which include a fixed-base manipulator and a quadruped-mounted manipulator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhi_W/0/1/0/all/0/1&quot;&gt;Weiming Zhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_Roberson_M/0/1/0/all/0/1&quot;&gt;Matthew Johnson-Roberson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03837">
<title>Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications. (arXiv:2309.03837v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03837</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-task learning (MTL) is a powerful approach in deep learning that
leverages the information from multiple tasks during training to improve model
performance. In medical imaging, MTL has shown great potential to solve various
tasks. However, existing MTL architectures in medical imaging are limited in
sharing information across tasks, reducing the potential performance
improvements of MTL. In this study, we introduce a novel attention-based MTL
framework to better leverage inter-task interactions for various tasks from
pixel-level to image-level predictions. Specifically, we propose a Cross-Task
Attention Network (CTAN) which utilizes cross-task attention mechanisms to
incorporate information by interacting across tasks. We validated CTAN on four
medical imaging datasets that span different domains and tasks including:
radiation treatment planning prediction using planning CT images of two
different target cancers (Prostate, OpenKBP); pigmented skin lesion
segmentation and diagnosis using dermatoscopic images (HAM10000); and COVID-19
diagnosis and severity prediction using chest CT scans (STOIC). Our study
demonstrates the effectiveness of CTAN in improving the accuracy of medical
imaging tasks. Compared to standard single-task learning (STL), CTAN
demonstrated a 4.67% improvement in performance and outperformed both widely
used MTL baselines: hard parameter sharing (HPS) with an average performance
improvement of 3.22%; and multi-task attention network (MTAN) with a relative
decrease of 5.38%. These findings highlight the significance of our proposed
MTL framework in solving medical imaging tasks and its potential to improve
their accuracy across domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sangwook Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purdie_T/0/1/0/all/0/1&quot;&gt;Thomas G. Purdie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McIntosh_C/0/1/0/all/0/1&quot;&gt;Chris McIntosh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03839">
<title>Bootstrapping Adaptive Human-Machine Interfaces with Offline Reinforcement Learning. (arXiv:2309.03839v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.03839</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive interfaces can help users perform sequential decision-making tasks
like robotic teleoperation given noisy, high-dimensional command signals (e.g.,
from a brain-computer interface). Recent advances in human-in-the-loop machine
learning enable such systems to improve by interacting with users, but tend to
be limited by the amount of data that they can collect from individual users in
practice. In this paper, we propose a reinforcement learning algorithm to
address this by training an interface to map raw command signals to actions
using a combination of offline pre-training and online fine-tuning. To address
the challenges posed by noisy command signals and sparse rewards, we develop a
novel method for representing and inferring the user&apos;s long-term intent for a
given trajectory. We primarily evaluate our method&apos;s ability to assist users
who can only communicate through noisy, high-dimensional input channels through
a user study in which 12 participants performed a simulated navigation task by
using their eye gaze to modulate a 128-dimensional command signal from their
webcam. The results show that our method enables successful goal navigation
more often than a baseline directional interface, by learning to denoise user
commands signals and provide shared autonomy assistance. We further evaluate on
a simulated Sawyer pushing task with eye gaze control, and the Lunar Lander
game with simulated user commands, and find that our method improves over
baseline interfaces in these domains as well. Extensive ablation experiments
with simulated user commands empirically motivate each component of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jensen Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1&quot;&gt;Siddharth Reddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berseth_G/0/1/0/all/0/1&quot;&gt;Glen Berseth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca D. Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03842">
<title>Early warning via transitions in latent stochastic dynamical systems. (arXiv:2309.03842v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03842</link>
<description rdf:parseType="Literal">&lt;p&gt;Early warnings for dynamical transitions in complex systems or
high-dimensional observation data are essential in many real world
applications, such as gene mutation, brain diseases, natural disasters,
financial crises, and engineering reliability. To effectively extract early
warning signals, we develop a novel approach: the directed anisotropic
diffusion map that captures the latent evolutionary dynamics in low-dimensional
manifold. Applying the methodology to authentic electroencephalogram (EEG)
data, we successfully find the appropriate effective coordinates, and derive
early warning signals capable of detecting the tipping point during the state
transition. Our method bridges the latent dynamics with the original dataset.
The framework is validated to be accurate and effective through numerical
experiments, in terms of density and transition probability. It is shown that
the second coordinate holds meaningful information for critical transition in
various evaluation metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_L/0/1/0/all/0/1&quot;&gt;Lingyu Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Ting Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiao_W/0/1/0/all/0/1&quot;&gt;Wang Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1&quot;&gt;Jinqiao Duan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03843">
<title>Gradient-Based Feature Learning under Structured Data. (arXiv:2309.03843v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03843</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent works have demonstrated that the sample complexity of gradient-based
learning of single index models, i.e. functions that depend on a 1-dimensional
projection of the input data, is governed by their information exponent.
However, these results are only concerned with isotropic data, while in
practice the input often contains additional structure which can implicitly
guide the algorithm. In this work, we investigate the effect of a spiked
covariance structure and reveal several interesting phenomena. First, we show
that in the anisotropic setting, the commonly used spherical gradient dynamics
may fail to recover the true direction, even when the spike is perfectly
aligned with the target direction. Next, we show that appropriate weight
normalization that is reminiscent of batch normalization can alleviate this
issue. Further, by exploiting the alignment between the (spiked) input
covariance and the target, we obtain improved sample complexity compared to the
isotropic case. In particular, under the spiked model with a suitably large
spike, the sample complexity of gradient-based training can be made independent
of the information exponent while also outperforming lower bounds for
rotationally invariant kernel methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mousavi_Hosseini_A/0/1/0/all/0/1&quot;&gt;Alireza Mousavi-Hosseini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Denny Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1&quot;&gt;Taiji Suzuki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Erdogdu_M/0/1/0/all/0/1&quot;&gt;Murat A. Erdogdu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03847">
<title>Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples. (arXiv:2309.03847v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.03847</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of estimating mixtures of Gaussians under the constraint
of differential privacy (DP). Our main result is that $\tilde{O}(k^2 d^4
\log(1/\delta) / \alpha^2 \varepsilon)$ samples are sufficient to estimate a
mixture of $k$ Gaussians up to total variation distance $\alpha$ while
satisfying $(\varepsilon, \delta)$-DP. This is the first finite sample
complexity upper bound for the problem that does not make any structural
assumptions on the GMMs.
&lt;/p&gt;
&lt;p&gt;To solve the problem, we devise a new framework which may be useful for other
tasks. On a high level, we show that if a class of distributions (such as
Gaussians) is (1) list decodable and (2) admits a &quot;locally small&apos;&apos; cover
[BKSW19] with respect to total variation distance, then the class of its
mixtures is privately learnable. The proof circumvents a known barrier
indicating that, unlike Gaussians, GMMs do not admit a locally small cover
[AAL21].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Afzali_M/0/1/0/all/0/1&quot;&gt;Mohammad Afzali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ashtiani_H/0/1/0/all/0/1&quot;&gt;Hassan Ashtiani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liaw_C/0/1/0/all/0/1&quot;&gt;Christopher Liaw&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03851">
<title>CenTime: Event-Conditional Modelling of Censoring in Survival Analysis. (arXiv:2309.03851v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03851</link>
<description rdf:parseType="Literal">&lt;p&gt;Survival analysis is a valuable tool for estimating the time until specific
events, such as death or cancer recurrence, based on baseline observations.
This is particularly useful in healthcare to prognostically predict clinically
important events based on patient data. However, existing approaches often have
limitations; some focus only on ranking patients by survivability, neglecting
to estimate the actual event time, while others treat the problem as a
classification task, ignoring the inherent time-ordered structure of the
events. Furthermore, the effective utilization of censored samples - training
data points where the exact event time is unknown - is essential for improving
the predictive accuracy of the model. In this paper, we introduce CenTime, a
novel approach to survival analysis that directly estimates the time to event.
Our method features an innovative event-conditional censoring mechanism that
performs robustly even when uncensored data is scarce. We demonstrate that our
approach forms a consistent estimator for the event model parameters, even in
the absence of uncensored data. Furthermore, CenTime is easily integrated with
deep learning models with no restrictions on batch size or the number of
uncensored samples. We compare our approach with standard survival analysis
methods, including the Cox proportional-hazard model and DeepHit. Our results
indicate that CenTime offers state-of-the-art performance in predicting
time-to-death while maintaining comparable ranking performance. Our
implementation is publicly available at
https://github.com/ahmedhshahin/CenTime.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahin_A/0/1/0/all/0/1&quot;&gt;Ahmed H. Shahin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1&quot;&gt;An Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whitehead_A/0/1/0/all/0/1&quot;&gt;Alexander C. Whitehead&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alexander_D/0/1/0/all/0/1&quot;&gt;Daniel C. Alexander&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacob_J/0/1/0/all/0/1&quot;&gt;Joseph Jacob&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barber_D/0/1/0/all/0/1&quot;&gt;David Barber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03873">
<title>A Tutorial on the Non-Asymptotic Theory of System Identification. (arXiv:2309.03873v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2309.03873</link>
<description rdf:parseType="Literal">&lt;p&gt;This tutorial serves as an introduction to recently developed non-asymptotic
methods in the theory of -- mainly linear -- system identification. We
emphasize tools we deem particularly useful for a range of problems in this
domain, such as the covering technique, the Hanson-Wright Inequality and the
method of self-normalized martingales. We then employ these tools to give
streamlined proofs of the performance of various least-squares based estimators
for identifying the parameters in autoregressive models. We conclude by
sketching out how the ideas presented herein can be extended to certain
nonlinear identification problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ziemann_I/0/1/0/all/0/1&quot;&gt;Ingvar Ziemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tsiamis_A/0/1/0/all/0/1&quot;&gt;Anastasios Tsiamis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_B/0/1/0/all/0/1&quot;&gt;Bruce Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jedra_Y/0/1/0/all/0/1&quot;&gt;Yassir Jedra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Matni_N/0/1/0/all/0/1&quot;&gt;Nikolai Matni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pappas_G/0/1/0/all/0/1&quot;&gt;George J. Pappas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03876">
<title>OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs. (arXiv:2309.03876v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.03876</link>
<description rdf:parseType="Literal">&lt;p&gt;Instruction-tuned Large Language Models (LLMs) have recently showcased
remarkable ability to generate fitting responses to natural language
instructions. However, an open research question concerns the inherent biases
of trained models and their responses. For instance, if the data used to tune
an LLM is dominantly written by persons with a specific political bias, we
might expect generated answers to share this bias. Current research work seeks
to de-bias such models, or suppress potentially biased answers. With this
demonstration, we take a different view on biases in instruction-tuning: Rather
than aiming to suppress them, we aim to make them explicit and transparent. To
this end, we present OpinionGPT, a web demo in which users can ask questions
and select all biases they wish to investigate. The demo will answer this
question using a model fine-tuned on text representing each of the selected
biases, allowing side-by-side comparison. To train the underlying model, we
identified 11 different biases (political, geographic, gender, age) and derived
an instruction-tuning corpus in which each answer was written by members of one
of these demographics. This paper presents OpinionGPT, illustrates how we
trained the bias-aware model and showcases the web application (available at
https://opiniongpt.informatik.hu-berlin.de).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haller_P/0/1/0/all/0/1&quot;&gt;Patrick Haller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aynetdinov_A/0/1/0/all/0/1&quot;&gt;Ansar Aynetdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akbik_A/0/1/0/all/0/1&quot;&gt;Alan Akbik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03879">
<title>Better Practices for Domain Adaptation. (arXiv:2309.03879v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.03879</link>
<description rdf:parseType="Literal">&lt;p&gt;Distribution shifts are all too common in real-world applications of machine
learning. Domain adaptation (DA) aims to address this by providing various
frameworks for adapting models to the deployment data without using labels.
However, the domain shift scenario raises a second more subtle challenge: the
difficulty of performing hyperparameter optimisation (HPO) for these adaptation
algorithms without access to a labelled validation set. The unclear validation
protocol for DA has led to bad practices in the literature, such as performing
HPO using the target test labels when, in real-world scenarios, they are not
available. This has resulted in over-optimism about DA research progress
compared to reality. In this paper, we analyse the state of DA when using good
evaluation practice, by benchmarking a suite of candidate validation criteria
and using them to assess popular adaptation algorithms. We show that there are
challenges across all three branches of domain adaptation methodology including
Unsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and
Test Time Adaptation (TTA). While the results show that realistically
achievable performance is often worse than expected, they also show that using
proper validation splits is beneficial, as well as showing that some previously
unexplored validation metrics provide the best options to date. Altogether, our
improved practices covering data, training, validation and hyperparameter
optimisation form a new rigorous pipeline to improve benchmarking, and hence
research progress, within this important field going forward.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ericsson_L/0/1/0/all/0/1&quot;&gt;Linus Ericsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Da Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1&quot;&gt;Timothy M. Hospedales&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03883">
<title>DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models. (arXiv:2309.03883v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.03883</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their impressive capabilities, large language models (LLMs) are prone
to hallucinations, i.e., generating content that deviates from facts seen
during pretraining. We propose a simple decoding strategy for reducing
hallucinations with pretrained LLMs that does not require conditioning on
retrieved external knowledge nor additional fine-tuning. Our approach obtains
the next-token distribution by contrasting the differences in logits obtained
from projecting the later layers versus earlier layers to the vocabulary space,
exploiting the fact that factual knowledge in an LLMs has generally been shown
to be localized to particular transformer layers. We find that this Decoding by
Contrasting Layers (DoLa) approach is able to better surface factual knowledge
and reduce the generation of incorrect facts. DoLa consistently improves the
truthfulness across multiple choices tasks and open-ended generation tasks, for
example improving the performance of LLaMA family models on TruthfulQA by
12-17% absolute points, demonstrating its potential in making LLMs reliably
generate truthful facts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1&quot;&gt;Yung-Sung Chuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yujia Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Hongyin Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1&quot;&gt;James Glass&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1&quot;&gt;Pengcheng He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03886">
<title>A Function Interpretation Benchmark for Evaluating Interpretability Methods. (arXiv:2309.03886v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.03886</link>
<description rdf:parseType="Literal">&lt;p&gt;Labeling neural network submodules with human-legible descriptions is useful
for many downstream tasks: such descriptions can surface failures, guide
interventions, and perhaps even explain important model behaviors. To date,
most mechanistic descriptions of trained networks have involved small models,
narrowly delimited phenomena, and large amounts of human labor. Labeling all
human-interpretable sub-computations in models of increasing size and
complexity will almost certainly require tools that can generate and validate
descriptions automatically. Recently, techniques that use learned models
in-the-loop for labeling have begun to gain traction, but methods for
evaluating their efficacy are limited and ad-hoc. How should we validate and
compare open-ended labeling tools? This paper introduces FIND (Function
INterpretation and Description), a benchmark suite for evaluating the building
blocks of automated interpretability methods. FIND contains functions that
resemble components of trained neural networks, and accompanying descriptions
of the kind we seek to generate. The functions are procedurally constructed
across textual and numeric domains, and involve a range of real-world
complexities, including noise, composition, approximation, and bias. We
evaluate new and existing methods that use language models (LMs) to produce
code-based and language descriptions of function behavior. We find that an
off-the-shelf LM augmented with only black-box access to functions can
sometimes infer their structure, acting as a scientist by forming hypotheses,
proposing experiments, and updating descriptions in light of new data. However,
LM-based descriptions tend to capture global function behavior and miss local
corruptions. These results show that FIND will be useful for characterizing the
performance of more sophisticated interpretability methods before they are
applied to real-world models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwettmann_S/0/1/0/all/0/1&quot;&gt;Sarah Schwettmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaham_T/0/1/0/all/0/1&quot;&gt;Tamar Rott Shaham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Materzynska_J/0/1/0/all/0/1&quot;&gt;Joanna Materzynska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_N/0/1/0/all/0/1&quot;&gt;Neil Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1&quot;&gt;Jacob Andreas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1&quot;&gt;David Bau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1&quot;&gt;Antonio Torralba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03891">
<title>ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous Grasping and Articulation. (arXiv:2309.03891v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.03891</link>
<description rdf:parseType="Literal">&lt;p&gt;We present ArtiGrasp, a novel method to synthesize bi-manual hand-object
interactions that include grasping and articulation. This task is challenging
due to the diversity of the global wrist motions and the precise finger control
that are necessary to articulate objects. ArtiGrasp leverages reinforcement
learning and physics simulations to train a policy that controls the global and
local hand pose. Our framework unifies grasping and articulation within a
single policy guided by a single hand pose reference. Moreover, to facilitate
the training of the precise finger control required for articulation, we
present a learning curriculum with increasing difficulty. It starts with
single-hand manipulation of stationary objects and continues with multi-agent
training including both hands and non-stationary objects. To evaluate our
method, we introduce Dynamic Object Grasping and Articulation, a task that
involves bringing an object into a target articulated pose. This task requires
grasping, relocation, and articulation. We show our method&apos;s efficacy towards
this task. We further demonstrate that our method can generate motions with
noisy hand-object pose estimates from an off-the-shelf image-based regressor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christen_S/0/1/0/all/0/1&quot;&gt;Sammy Christen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1&quot;&gt;Zicong Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Luocheng Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwangbo_J/0/1/0/all/0/1&quot;&gt;Jemin Hwangbo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jie Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1&quot;&gt;Otmar Hilliges&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03893">
<title>DiffusionEngine: Diffusion Model is Scalable Data Engine for Object Detection. (arXiv:2309.03893v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.03893</link>
<description rdf:parseType="Literal">&lt;p&gt;Data is the cornerstone of deep learning. This paper reveals that the
recently developed Diffusion Model is a scalable data engine for object
detection. Existing methods for scaling up detection-oriented data often
require manual collection or generative models to obtain target images,
followed by data augmentation and labeling to produce training pairs, which are
costly, complex, or lacking diversity. To address these issues, we
presentDiffusionEngine (DE), a data scaling-up engine that provides
high-quality detection-oriented training pairs in a single stage. DE consists
of a pre-trained diffusion model and an effective Detection-Adapter,
contributing to generating scalable, diverse and generalizable detection data
in a plug-and-play manner. Detection-Adapter is learned to align the implicit
semantic and location knowledge in off-the-shelf diffusion models with
detection-aware signals to make better bounding-box predictions. Additionally,
we contribute two datasets, i.e., COCO-DE and VOC-DE, to scale up existing
detection benchmarks for facilitating follow-up research. Extensive experiments
demonstrate that data scaling-up via DE can achieve significant improvements in
diverse scenarios, such as various detection algorithms, self-supervised
pre-training, data-sparse, label-scarce, cross-domain, and semi-supervised
learning. For example, when using DE with a DINO-based adapter to scale up
data, mAP is improved by 3.1% on COCO, 7.6% on VOC, and 11.5% on Clipart.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Manlin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jie Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1&quot;&gt;Yuxi Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Ming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1&quot;&gt;Jie Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1&quot;&gt;Xuefeng Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Rui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1&quot;&gt;Min Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_A/0/1/0/all/0/1&quot;&gt;Andy J. Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03905">
<title>ImageBind-LLM: Multi-modality Instruction Tuning. (arXiv:2309.03905v1 [cs.MM])</title>
<link>http://arxiv.org/abs/2309.03905</link>
<description rdf:parseType="Literal">&lt;p&gt;We present ImageBind-LLM, a multi-modality instruction tuning method of large
language models (LLMs) via ImageBind. Existing works mainly focus on language
and image instruction tuning, different from which, our ImageBind-LLM can
respond to multi-modality conditions, including audio, 3D point clouds, video,
and their embedding-space arithmetic by only image-text alignment training.
During training, we adopt a learnable bind network to align the embedding space
between LLaMA and ImageBind&apos;s image encoder. Then, the image features
transformed by the bind network are added to word tokens of all layers in
LLaMA, which progressively injects visual instructions via an attention-free
and zero-initialized gating mechanism. Aided by the joint embedding of
ImageBind, the simple image-text training enables our model to exhibit superior
multi-modality instruction-following capabilities. During inference, the
multi-modality inputs are fed into the corresponding ImageBind encoders, and
processed by a proposed visual cache model for further cross-modal embedding
enhancement. The training-free cache model retrieves from three million image
features extracted by ImageBind, which effectively mitigates the
training-inference modality discrepancy. Notably, with our approach,
ImageBind-LLM can respond to instructions of diverse modalities and demonstrate
significant language generation quality. Code is released at
https://github.com/OpenGVLab/LLaMA-Adapter.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jiaming Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Renrui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1&quot;&gt;Wenqi Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1&quot;&gt;Peng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Peng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1&quot;&gt;Han Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kaipeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chris Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1&quot;&gt;Song Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1&quot;&gt;Ziyu Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1&quot;&gt;Xudong Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1&quot;&gt;Shuai Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yafei Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiaoxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1&quot;&gt;Xiangyu Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongsheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1&quot;&gt;Yu Qiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1907.04483">
<title>Copula Representations and Error Surface Projections for the Exclusive Or Problem. (arXiv:1907.04483v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1907.04483</link>
<description rdf:parseType="Literal">&lt;p&gt;The exclusive or (xor) function is one of the simplest examples that
illustrate why nonlinear feedforward networks are superior to linear regression
for machine learning applications. We review the xor representation and
approximation problems and discuss their solutions in terms of probabilistic
logic and associative copula functions. After briefly reviewing the
specification of feedforward networks, we compare the dynamics of learned error
surfaces with different activation functions such as RELU and tanh through a
set of colorful three-dimensional charts. The copula representations extend xor
from Boolean to real values, thereby providing a convenient way to demonstrate
the concept of cross-validation on in-sample and out-sample data sets. Our
approach is pedagogical and is meant to be a machine learning prolegomenon.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freedman_R/0/1/0/all/0/1&quot;&gt;Roy S. Freedman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2002.01444">
<title>Proper Learning of Linear Dynamical Systems as a Non-Commutative Polynomial Optimisation Problem. (arXiv:2002.01444v5 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2002.01444</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been much recent progress in forecasting the next observation of a
linear dynamical system (LDS), which is known as the improper learning, as well
as in the estimation of its system matrices, which is known as the proper
learning of LDS. We present an approach to proper learning of LDS, which in
spite of the non-convexity of the problem, guarantees global convergence of
numerical solutions to a least-squares estimator. We present promising
computational results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhou_Q/0/1/0/all/0/1&quot;&gt;Quan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Marecek_J/0/1/0/all/0/1&quot;&gt;Jakub Marecek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.10274">
<title>Graph Fairing Convolutional Networks for Anomaly Detection. (arXiv:2010.10274v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2010.10274</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph convolution is a fundamental building block for many deep neural
networks on graph-structured data. In this paper, we introduce a simple, yet
very effective graph convolutional network with skip connections for
semi-supervised anomaly detection. The proposed layerwise propagation rule of
our model is theoretically motivated by the concept of implicit fairing in
geometry processing, and comprises a graph convolution module for aggregating
information from immediate node neighbors and a skip connection module for
combining layer-wise neighborhood representations. This propagation rule is
derived from the iterative solution of the implicit fairing equation via the
Jacobi method. In addition to capturing information from distant graph nodes
through skip connections between the network&apos;s layers, our approach exploits
both the graph structure and node features for learning discriminative node
representations. These skip connections are integrated by design in our
proposed network architecture. The effectiveness of our model is demonstrated
through extensive experiments on five benchmark datasets, achieving better or
comparable anomaly detection results against strong baseline methods. We also
demonstrate through an ablation study that skip connection helps improve the
model performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mesgaran_M/0/1/0/all/0/1&quot;&gt;Mahsa Mesgaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamza_A/0/1/0/all/0/1&quot;&gt;A. Ben Hamza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.12591">
<title>BoXHED2.0: Scalable boosting of dynamic survival analysis. (arXiv:2103.12591v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2103.12591</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern applications of survival analysis increasingly involve time-dependent
covariates. The Python package BoXHED2.0 is a tree-boosted hazard estimator
that is fully nonparametric, and is applicable to survival settings far more
general than right-censoring, including recurring events and competing risks.
BoXHED2.0 is also scalable to the point of being on the same order of speed as
parametric boosted survival models, in part because its core is written in C++
and it also supports the use of GPUs and multicore CPUs. BoXHED2.0 is available
from PyPI and also from www.github.com/BoXHED.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pakbin_A/0/1/0/all/0/1&quot;&gt;Arash Pakbin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaochen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mortazavi_B/0/1/0/all/0/1&quot;&gt;Bobak J. Mortazavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Donald K.K. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.02613">
<title>Bridging the Gap Between Target Networks and Functional Regularization. (arXiv:2106.02613v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2106.02613</link>
<description rdf:parseType="Literal">&lt;p&gt;Bootstrapping is behind much of the successes of deep Reinforcement Learning.
However, learning the value function via bootstrapping often leads to unstable
training due to fast-changing target values. Target Networks are employed to
stabilize training by using an additional set of lagging parameters to estimate
the target values. Despite the popularity of Target Networks, their effect on
the optimization is still misunderstood. In this work, we show that they act as
an implicit regularizer which can be beneficial in some cases, but also have
disadvantages such as being inflexible and can result in instabilities, even
when vanilla TD(0) converges. To overcome these issues, we propose an explicit
Functional Regularization alternative that is flexible and a convex regularizer
in function space and we theoretically study its convergence. We conduct an
experimental study across a range of environments, discount factors, and
off-policiness data collections to investigate the effectiveness of the
regularization induced by Target Networks and Functional Regularization in
terms of performance, accuracy, and stability. Our findings emphasize that
Functional Regularization can be used as a drop-in replacement for Target
Networks and result in performance improvement. Furthermore, adjusting both the
regularization weight and the network update period in Functional
Regularization can result in further performance improvements compared to
solely adjusting the network update period as typically done with Target
Networks. Our approach also enhances the ability to networks to recover
accurate $Q$-values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Piche_A/0/1/0/all/0/1&quot;&gt;Alexandre Pich&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thomas_V/0/1/0/all/0/1&quot;&gt;Valentin Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pardinas_R/0/1/0/all/0/1&quot;&gt;Rafael Pardinas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marino_J/0/1/0/all/0/1&quot;&gt;Joseph Marino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marconi_G/0/1/0/all/0/1&quot;&gt;Gian Maria Marconi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1&quot;&gt;Christopher Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Mohammad Emtiyaz Khan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.00115">
<title>Comparing Sequential Forecasters. (arXiv:2110.00115v5 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/2110.00115</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider two forecasters, each making a single prediction for a sequence of
events over time. We ask a relatively basic question: how might we compare
these forecasters, either online or post-hoc, while avoiding unverifiable
assumptions on how the forecasts and outcomes were generated? In this paper, we
present a rigorous answer to this question by designing novel sequential
inference procedures for estimating the time-varying difference in forecast
scores. To do this, we employ confidence sequences (CS), which are sequences of
confidence intervals that can be continuously monitored and are valid at
arbitrary data-dependent stopping times (&quot;anytime-valid&quot;). The widths of our
CSs are adaptive to the underlying variance of the score differences.
Underlying their construction is a game-theoretic statistical framework, in
which we further identify e-processes and p-processes for sequentially testing
a weak null hypothesis -- whether one forecaster outperforms another on average
(rather than always). Our methods do not make distributional assumptions on the
forecasts or outcomes; our main theorems apply to any bounded scores, and we
later provide alternative methods for unbounded scores. We empirically validate
our approaches by comparing real-world baseball and weather forecasters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choe_Y/0/1/0/all/0/1&quot;&gt;Yo Joong Choe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1&quot;&gt;Aaditya Ramdas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.06781">
<title>Q-Learning for MDPs with General Spaces: Convergence and Near Optimality via Quantization under Weak Continuity. (arXiv:2111.06781v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.06781</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning algorithms often require finiteness of state and
action spaces in Markov decision processes (MDPs) (also called controlled
Markov chains) and various efforts have been made in the literature towards the
applicability of such algorithms for continuous state and action spaces. In
this paper, we show that under very mild regularity conditions (in particular,
involving only weak continuity of the transition kernel of an MDP), Q-learning
for standard Borel MDPs via quantization of states and actions (called
Quantized Q-Learning) converges to a limit, and furthermore this limit
satisfies an optimality equation which leads to near optimality with either
explicit performance bounds or which are guaranteed to be asymptotically
optimal. Our approach builds on (i) viewing quantization as a measurement
kernel and thus a quantized MDP as a partially observed Markov decision process
(POMDP), (ii) utilizing near optimality and convergence results of Q-learning
for POMDPs, and (iii) finally, near-optimality of finite state model
approximations for MDPs with weakly continuous kernels which we show to
correspond to the fixed point of the constructed POMDP. Thus, our paper
presents a very general convergence and approximation result for the
applicability of Q-learning for continuous MDPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kara_A/0/1/0/all/0/1&quot;&gt;Ali Devran Kara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saldi_N/0/1/0/all/0/1&quot;&gt;Naci Saldi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuksel_S/0/1/0/all/0/1&quot;&gt;Serdar Y&amp;#xfc;ksel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.12191">
<title>Kernelized Concept Erasure. (arXiv:2201.12191v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2201.12191</link>
<description rdf:parseType="Literal">&lt;p&gt;The representation space of neural models for textual data emerges in an
unsupervised manner during training. Understanding how those representations
encode human-interpretable concepts is a fundamental problem. One prominent
approach for the identification of concepts in neural representations is
searching for a linear subspace whose erasure prevents the prediction of the
concept from the representations. However, while many linear erasure algorithms
are tractable and interpretable, neural networks do not necessarily represent
concepts in a linear manner. To identify non-linearly encoded concepts, we
propose a kernelization of a linear minimax game for concept erasure. We
demonstrate that it is possible to prevent specific non-linear adversaries from
predicting the concept. However, the protection does not transfer to different
nonlinear adversaries. Therefore, exhaustively erasing a non-linearly encoded
concept remains an open problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1&quot;&gt;Shauli Ravfogel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vargas_F/0/1/0/all/0/1&quot;&gt;Francisco Vargas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1&quot;&gt;Yoav Goldberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1&quot;&gt;Ryan Cotterell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.12198">
<title>Limitation of Characterizing Implicit Regularization by Data-independent Functions. (arXiv:2201.12198v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2201.12198</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, understanding the implicit regularization of neural networks
(NNs) has become a central task in deep learning theory. However, implicit
regularization is itself not completely defined and well understood. In this
work, we attempt to mathematically define and study implicit regularization.
Importantly, we explore the limitations of a common approach to characterizing
implicit regularization using data-independent functions. We propose two
dynamical mechanisms, i.e., Two-point and One-point Overlapping mechanisms,
based on which we provide two recipes for producing classes of
one-hidden-neuron NNs that provably cannot be fully characterized by a type of
or all data-independent functions. Following the previous works, our results
further emphasize the profound data dependency of implicit regularization in
general, inspiring us to study in detail the data dependency of NN implicit
regularization in the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Leyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhi-Qin John Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1&quot;&gt;Tao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yaoyu Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2202.09671">
<title>Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders. (arXiv:2202.09671v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2202.09671</link>
<description rdf:parseType="Literal">&lt;p&gt;Employing a forward diffusion chain to gradually map the data to a noise
distribution, diffusion-based generative models learn how to generate the data
by inferring a reverse diffusion chain. However, this approach is slow and
costly because it needs many forward and reverse steps. We propose a faster and
cheaper approach that adds noise not until the data become pure random noise,
but until they reach a hidden noisy data distribution that we can confidently
learn. Then, we use fewer reverse steps to generate data by starting from this
hidden distribution that is made similar to the noisy data. We reveal that the
proposed model can be cast as an adversarial auto-encoder empowered by both the
diffusion process and a learnable implicit prior. Experimental results show
even with a significantly smaller number of reverse diffusion steps, the
proposed truncated diffusion probabilistic models can provide consistent
improvements over the non-truncated ones in terms of performance in both
unconditional and text-guided image generations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_H/0/1/0/all/0/1&quot;&gt;Huangjie Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_P/0/1/0/all/0/1&quot;&gt;Pengcheng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Weizhu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Mingyuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2203.09096">
<title>DeepAD: A Robust Deep Learning Model of Alzheimer&apos;s Disease Progression for Real-World Clinical Applications. (arXiv:2203.09096v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2203.09096</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to predict the future trajectory of a patient is a key step
toward the development of therapeutics for complex diseases such as Alzheimer&apos;s
disease (AD). However, most machine learning approaches developed for
prediction of disease progression are either single-task or single-modality
models, which can not be directly adopted to our setting involving multi-task
learning with high dimensional images. Moreover, most of those approaches are
trained on a single dataset (i.e. cohort), which can not be generalized to
other cohorts. We propose a novel multimodal multi-task deep learning model to
predict AD progression by analyzing longitudinal clinical and neuroimaging data
from multiple cohorts. Our proposed model integrates high dimensional MRI
features from a 3D convolutional neural network with other data modalities,
including clinical and demographic information, to predict the future
trajectory of patients. Our model employs an adversarial loss to alleviate the
study-specific imaging bias, in particular the inter-study domain shifts. In
addition, a Sharpness-Aware Minimization (SAM) optimization technique is
applied to further improve model generalization. The proposed model is trained
and tested on various datasets in order to evaluate and validate the results.
Our results showed that 1) our model yields significant improvement over the
baseline models, and 2) models using extracted neuroimaging features from 3D
convolutional neural network outperform the same models when applied to
MRI-derived volumetric features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashemifar_S/0/1/0/all/0/1&quot;&gt;Somaye Hashemifar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iriondo_C/0/1/0/all/0/1&quot;&gt;Claudia Iriondo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casey_E/0/1/0/all/0/1&quot;&gt;Evan Casey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hejrati_M/0/1/0/all/0/1&quot;&gt;Mohsen Hejrati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Initiative_f/0/1/0/all/0/1&quot;&gt;for Alzheimer&amp;#x27;s Disease Neuroimaging Initiative&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.04151">
<title>Auto-SDE: Learning effective reduced dynamics from data-driven stochastic dynamical systems. (arXiv:2205.04151v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2205.04151</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiscale stochastic dynamical systems have been widely adopted to
scientific and engineering problems due to their capability of depicting
complex phenomena in many real world applications. This work is devoted to
investigating the effective reduced dynamics for a slow-fast stochastic
dynamical system. Given observation data on a short-term period satisfying some
unknown slow-fast stochastic system, we propose a novel algorithm including a
neural network called Auto-SDE to learn invariant slow manifold. Our approach
captures the evolutionary nature of a series of time-dependent autoencoder
neural networks with the loss constructed from a discretized stochastic
differential equation. Our algorithm is also proved to be accurate, stable and
effective through numerical experiments under various evaluation metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_L/0/1/0/all/0/1&quot;&gt;Lingyu Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Ting Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dai_M/0/1/0/all/0/1&quot;&gt;Min Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1&quot;&gt;Jinqiao Duan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.12250">
<title>Efficient anti-symmetrization of a neural network layer by taming the sign problem. (arXiv:2205.12250v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.12250</link>
<description rdf:parseType="Literal">&lt;p&gt;Explicit antisymmetrization of a neural network is a potential candidate for
a universal function approximator for generic antisymmetric functions, which
are ubiquitous in quantum physics. However, this procedure is a priori
factorially costly to implement, making it impractical for large numbers of
particles. The strategy also suffers from a sign problem. Namely, due to
near-exact cancellation of positive and negative contributions, the magnitude
of the antisymmetrized function may be significantly smaller than before
anti-symmetrization. We show that the anti-symmetric projection of a two-layer
neural network can be evaluated efficiently, opening the door to using a
generic antisymmetric layer as a building block in anti-symmetric neural
network Ansatzes. This approximation is effective when the sign problem is
controlled, and we show that this property depends crucially the choice of
activation function under standard Xavier/He initialization methods. As a
consequence, using a smooth activation function requires re-scaling of the
neural network weights compared to standard initializations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abrahamsen_N/0/1/0/all/0/1&quot;&gt;Nilin Abrahamsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Lin Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.02231">
<title>Models of human preference for learning reward functions. (arXiv:2206.02231v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.02231</link>
<description rdf:parseType="Literal">&lt;p&gt;The utility of reinforcement learning is limited by the alignment of reward
functions with the interests of human stakeholders. One promising method for
alignment is to learn the reward function from human-generated preferences
between pairs of trajectory segments, a type of reinforcement learning from
human feedback (RLHF). These human preferences are typically assumed to be
informed solely by partial return, the sum of rewards along each segment. We
find this assumption to be flawed and propose modeling human preferences
instead as informed by each segment&apos;s regret, a measure of a segment&apos;s
deviation from optimal decision-making. Given infinitely many preferences
generated according to regret, we prove that we can identify a reward function
equivalent to the reward function that generated those preferences, and we
prove that the previous partial return model lacks this identifiability
property in multiple contexts. We empirically show that our proposed regret
preference model outperforms the partial return preference model with finite
training data in otherwise the same setting. Additionally, we find that our
proposed regret preference model better predicts real human preferences and
also learns reward functions from these preferences that lead to policies that
are better human-aligned. Overall, this work establishes that the choice of
preference model is impactful, and our proposed regret preference model
provides an improvement upon a core assumption of recent research. We have open
sourced our experimental code, the human preferences dataset we gathered, and
our training and preference elicitation interfaces for gathering a such a
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knox_W/0/1/0/all/0/1&quot;&gt;W. Bradley Knox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hatgis_Kessell_S/0/1/0/all/0/1&quot;&gt;Stephane Hatgis-Kessell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Booth_S/0/1/0/all/0/1&quot;&gt;Serena Booth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1&quot;&gt;Scott Niekum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1&quot;&gt;Peter Stone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allievi_A/0/1/0/all/0/1&quot;&gt;Alessandro Allievi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.03680">
<title>Accelerating Numerical Solvers for Large-Scale Simulation of Dynamical System via NeurVec. (arXiv:2208.03680v2 [cs.CE] UPDATED)</title>
<link>http://arxiv.org/abs/2208.03680</link>
<description rdf:parseType="Literal">&lt;p&gt;The large-scale simulation of dynamical systems is critical in numerous
scientific and engineering disciplines. However, traditional numerical solvers
are limited by the choice of step sizes when estimating integration, resulting
in a trade-off between accuracy and computational efficiency. To address this
challenge, we introduce a deep learning-based corrector called Neural Vector
(NeurVec), which can compensate for integration errors and enable larger time
step sizes in simulations. Our extensive experiments on a variety of complex
dynamical system benchmarks demonstrate that NeurVec exhibits remarkable
generalization capability on a continuous phase space, even when trained using
limited and discrete data. NeurVec significantly accelerates traditional
solvers, achieving speeds tens to hundreds of times faster while maintaining
high levels of accuracy and stability. Moreover, NeurVec&apos;s simple-yet-effective
design, combined with its ease of implementation, has the potential to
establish a new paradigm for fast-solving differential equations based on deep
learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhongzhan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1&quot;&gt;Senwei Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haizhao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Liang Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.04521">
<title>The Space of Adversarial Strategies. (arXiv:2209.04521v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2209.04521</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples, inputs designed to induce worst-case behavior in
machine learning models, have been extensively studied over the past decade.
Yet, our understanding of this phenomenon stems from a rather fragmented pool
of knowledge; at present, there are a handful of attacks, each with disparate
assumptions in threat models and incomparable definitions of optimality. In
this paper, we propose a systematic approach to characterize worst-case (i.e.,
optimal) adversaries. We first introduce an extensible decomposition of attacks
in adversarial machine learning by atomizing attack components into surfaces
and travelers. With our decomposition, we enumerate over components to create
576 attacks (568 of which were previously unexplored). Next, we propose the
Pareto Ensemble Attack (PEA): a theoretical attack that upper-bounds attack
performance. With our new attacks, we measure performance relative to the PEA
on: both robust and non-robust models, seven datasets, and three extended
lp-based threat models incorporating compute costs, formalizing the Space of
Adversarial Strategies. From our evaluation we find that attack performance to
be highly contextual: the domain, model robustness, and threat model can have a
profound influence on attack efficacy. Our investigation suggests that future
studies measuring the security of machine learning should: (1) be
contextualized to the domain &amp;amp; threat models, and (2) go beyond the handful of
known attacks used today.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheatsley_R/0/1/0/all/0/1&quot;&gt;Ryan Sheatsley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoak_B/0/1/0/all/0/1&quot;&gt;Blaine Hoak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pauley_E/0/1/0/all/0/1&quot;&gt;Eric Pauley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDaniel_P/0/1/0/all/0/1&quot;&gt;Patrick McDaniel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.08901">
<title>Global Optimization for Cardinality-constrained Minimum Sum-of-Squares Clustering via Semidefinite Programming. (arXiv:2209.08901v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2209.08901</link>
<description rdf:parseType="Literal">&lt;p&gt;The minimum sum-of-squares clustering (MSSC), or k-means type clustering, has
been recently extended to exploit prior knowledge on the cardinality of each
cluster. Such knowledge is used to increase performance as well as solution
quality. In this paper, we propose a global optimization approach based on the
branch-and-cut technique to solve the cardinality-constrained MSSC. For the
lower bound routine, we use the semidefinite programming (SDP) relaxation
recently proposed by Rujeerapaiboon et al. [SIAM J. Optim. 29(2), 1211-1239,
(2019)]. However, this relaxation can be used in a branch-and-cut method only
for small-size instances. Therefore, we derive a new SDP relaxation that scales
better with the instance size and the number of clusters. In both cases, we
strengthen the bound by adding polyhedral cuts. Benefiting from a tailored
branching strategy which enforces pairwise constraints, we reduce the
complexity of the problems arising in the children nodes. For the upper bound,
instead, we present a local search procedure that exploits the solution of the
SDP relaxation solved at each node. Computational results show that the
proposed algorithm globally solves, for the first time, real-world instances of
size 10 times larger than those solved by state-of-the-art exact methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Piccialli_V/0/1/0/all/0/1&quot;&gt;Veronica Piccialli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sudoso_A/0/1/0/all/0/1&quot;&gt;Antonio M. Sudoso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.13008">
<title>USE-Evaluator: Performance Metrics for Medical Image Segmentation Models with Uncertain, Small or Empty Reference Annotations. (arXiv:2209.13008v4 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2209.13008</link>
<description rdf:parseType="Literal">&lt;p&gt;Performance metrics for medical image segmentation models are used to measure
the agreement between the reference annotation and the predicted segmentation.
Usually, overlap metrics, such as the Dice, are used as a metric to evaluate
the performance of these models in order for results to be comparable. However,
there is a mismatch between the distributions of cases and difficulty level of
segmentation tasks in public data sets compared to clinical practice. Common
metrics fail to measure the impact of this mismatch, especially for clinical
data sets that include low signal pathologies, a difficult segmentation task,
and uncertain, small, or empty reference annotations. This limitation may
result in ineffective research of machine learning practitioners in designing
and optimizing models. Dimensions of evaluating clinical value include
consideration of the uncertainty of reference annotations, independence from
reference annotation volume size, and evaluation of classification of empty
reference annotations. We study how uncertain, small, and empty reference
annotations influence the value of metrics for medical image segmentation on an
in-house data set regardless of the model. We examine metrics behavior on the
predictions of a standard deep learning framework in order to identify metrics
with clinical value. We compare to a public benchmark data set (BraTS 2019)
with a high-signal pathology and certain, larger, and no empty reference
annotations. We may show machine learning practitioners, how uncertain, small,
or empty reference annotations require a rethinking of the evaluation and
optimizing procedures. The evaluation code was released to encourage further
analysis of this topic.
https://github.com/SophieOstmeier/UncertainSmallEmpty.git
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ostmeier_S/0/1/0/all/0/1&quot;&gt;Sophie Ostmeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Axelrod_B/0/1/0/all/0/1&quot;&gt;Brian Axelrod&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bertels_J/0/1/0/all/0/1&quot;&gt;Jeroen Bertels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Isensee_F/0/1/0/all/0/1&quot;&gt;Fabian Isensee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lansberg_M/0/1/0/all/0/1&quot;&gt;Maarten G.Lansberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Christensen_S/0/1/0/all/0/1&quot;&gt;Soren Christensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Albers_G/0/1/0/all/0/1&quot;&gt;Gregory W. Albers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Li-Jia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Heit_J/0/1/0/all/0/1&quot;&gt;Jeremy J. Heit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.16193">
<title>M3FGM:a node masking and multi-granularity message passing-based federated graph model for spatial-temporal data prediction. (arXiv:2210.16193v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.16193</link>
<description rdf:parseType="Literal">&lt;p&gt;Researchers are solving the challenges of spatial-temporal prediction by
combining Federated Learning (FL) and graph models with respect to the
constrain of privacy and security. In order to make better use of the power of
graph model, some researchs also combine split learning(SL). However, there are
still several issues left unattended: 1) Clients might not be able to access
the server during inference phase; 2) The graph of clients designed manually in
the server model may not reveal the proper relationship between clients. This
paper proposes a new GNN-oriented split federated learning method, named node
{\bfseries M}asking and {\bfseries M}ulti-granularity {\bfseries M}essage
passing-based Federated Graph Model (M$^3$FGM) for the above issues. For the
first issue, the server model of M$^3$FGM employs a MaskNode layer to simulate
the case of clients being offline. We also redesign the decoder of the client
model using a dual-sub-decoders structure so that each client model can use its
local data to predict independently when offline. As for the second issue, a
new GNN layer named Multi-Granularity Message Passing (MGMP) layer enables each
client node to perceive global and local information. We conducted extensive
experiments in two different scenarios on two real traffic datasets. Results
show that M$^3$FGM outperforms the baselines and variant models, achieves the
best results in both datasets and scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yuxing Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1&quot;&gt;Yanwen Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Song Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1&quot;&gt;Jiachi Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.15341">
<title>Non-inferiority of Deep Learning Acute Ischemic Stroke Segmentation on Non-Contrast CT Compared to Expert Neuroradiologists. (arXiv:2211.15341v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2211.15341</link>
<description rdf:parseType="Literal">&lt;p&gt;To determine if a convolutional neural network (CNN) deep learning model can
accurately segment acute ischemic changes on non-contrast CT compared to
neuroradiologists. Non-contrast CT (NCCT) examinations from 232 acute ischemic
stroke patients who were enrolled in the DEFUSE 3 trial were included in this
study. Three experienced neuroradiologists independently segmented hypodensity
that reflected the ischemic core on each scan. The neuroradiologist with the
most experience (expert A) served as the ground truth for deep learning model
training. Two additional neuroradiologists (experts B and C) segmentations were
used for data testing. The 232 studies were randomly split into training and
test sets. The training set was further randomly divided into 5 folds with
training and validation sets. A 3-dimensional CNN architecture was trained and
optimized to predict the segmentations of expert A from NCCT. The performance
of the model was assessed using a set of volume, overlap, and distance metrics
using non-inferiority thresholds of 20%, 3ml, and 3mm. The optimized model
trained on expert A was compared to test experts B and C. We used a one-sided
Wilcoxon signed-rank test to test for the non-inferiority of the model-expert
compared to the inter-expert agreement. The final model performance for the
ischemic core segmentation task reached a performance of 0.46+-0.09 Surface
Dice at Tolerance 5mm and 0.47+-0.13 Dice when trained on expert A. Compared to
the two test neuroradiologists the model-expert agreement was non-inferior to
the inter-expert agreement, p &amp;lt; 0.05. The CNN accurately delineates the
hypodense ischemic core on NCCT in acute ischemic stroke patients with an
accuracy comparable to neuroradiologists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ostmeier_S/0/1/0/all/0/1&quot;&gt;Sophie Ostmeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Axelrod_B/0/1/0/all/0/1&quot;&gt;Brian Axelrod&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Verhaaren_B/0/1/0/all/0/1&quot;&gt;Benjamin F.J. Verhaaren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Christensen_S/0/1/0/all/0/1&quot;&gt;Soren Christensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mahammedi_A/0/1/0/all/0/1&quot;&gt;Abdelkader Mahammedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yongkai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pulli_B/0/1/0/all/0/1&quot;&gt;Benjamin Pulli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Li-Jia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zaharchuk_G/0/1/0/all/0/1&quot;&gt;Greg Zaharchuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Heit_J/0/1/0/all/0/1&quot;&gt;Jeremy J. Heit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.01448">
<title>PGFed: Personalize Each Client&apos;s Global Objective for Federated Learning. (arXiv:2212.01448v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.01448</link>
<description rdf:parseType="Literal">&lt;p&gt;Personalized federated learning has received an upsurge of attention due to
the mediocre performance of conventional federated learning (FL) over
heterogeneous data. Unlike conventional FL which trains a single global
consensus model, personalized FL allows different models for different clients.
However, existing personalized FL algorithms only implicitly transfer the
collaborative knowledge across the federation by embedding the knowledge into
the aggregated model or regularization. We observed that this implicit
knowledge transfer fails to maximize the potential of each client&apos;s empirical
risk toward other clients. Based on our observation, in this work, we propose
Personalized Global Federated Learning (PGFed), a novel personalized FL
framework that enables each client to personalize its own global objective by
explicitly and adaptively aggregating the empirical risks of itself and other
clients. To avoid massive (O(N^2)) communication overhead and potential privacy
leakage while achieving this, each client&apos;s risk is estimated through a
first-order approximation for other clients&apos; adaptive risk aggregation. On top
of PGFed, we develop a momentum upgrade, dubbed PGFedMo, to more efficiently
utilize clients&apos; empirical risks. Our extensive experiments on four datasets
under different federated settings show consistent improvements of PGFed over
previous state-of-the-art methods. The code is publicly available at
https://github.com/ljaiverson/pgfed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1&quot;&gt;Jun Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendieta_M/0/1/0/all/0/1&quot;&gt;Matias Mendieta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1&quot;&gt;Shandong Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.04031">
<title>On Root Cause Localization and Anomaly Mitigation through Causal Inference. (arXiv:2212.04031v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.04031</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to a wide spectrum of applications in the real world, such as security,
financial surveillance, and health risk, various deep anomaly detection models
have been proposed and achieved state-of-the-art performance. However, besides
being effective, in practice, the practitioners would further like to know what
causes the abnormal outcome and how to further fix it. In this work, we propose
RootCLAM, which aims to achieve Root Cause Localization and Anomaly Mitigation
from a causal perspective. Especially, we formulate anomalies caused by
external interventions on the normal causal mechanism and aim to locate the
abnormal features with external interventions as root causes. After that, we
further propose an anomaly mitigation approach that aims to recommend
mitigation actions on abnormal features to revert the abnormal outcomes such
that the counterfactuals guided by the causal mechanism are normal. Experiments
on three datasets show that our approach can locate the root causes and further
flip the abnormal labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1&quot;&gt;Xiao Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yongkai Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1&quot;&gt;Shuhan Yuan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.06566">
<title>How to select an objective function using information theory. (arXiv:2212.06566v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.06566</link>
<description rdf:parseType="Literal">&lt;p&gt;In machine learning or scientific computing, model performance is measured
with an objective function. But why choose one objective over another?
Information theory gives one answer: To maximize the information in the model,
select the most likely objective function or whichever represents the error in
the fewest bits. To evaluate different objectives, transform them into
likelihood functions. As likelihoods, their relative magnitudes represent how
much we should prefer one objective versus another, and the log of their
magnitude represents the expected uncertainty of the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hodson_T/0/1/0/all/0/1&quot;&gt;Timothy O. Hodson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Over_T/0/1/0/all/0/1&quot;&gt;Thomas M. Over&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_T/0/1/0/all/0/1&quot;&gt;Tyler J. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marshall_L/0/1/0/all/0/1&quot;&gt;Lucy M. Marshall&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.04838">
<title>LB-SimTSC: An Efficient Similarity-Aware Graph Neural Network for Semi-Supervised Time Series Classification. (arXiv:2301.04838v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.04838</link>
<description rdf:parseType="Literal">&lt;p&gt;Time series classification is an important data mining task that has received
a lot of interest in the past two decades. Due to the label scarcity in
practice, semi-supervised time series classification with only a few labeled
samples has become popular. Recently, Similarity-aware Time Series
Classification (SimTSC) is proposed to address this problem by using a graph
neural network classification model on the graph generated from pairwise
Dynamic Time Warping (DTW) distance of batch data. It shows excellent accuracy
and outperforms state-of-the-art deep learning models in several few-label
settings. However, since SimTSC relies on pairwise DTW distances, the quadratic
complexity of DTW limits its usability to only reasonably sized datasets. To
address this challenge, we propose a new efficient semi-supervised time series
classification technique, LB-SimTSC, with a new graph construction module.
Instead of using DTW, we propose to utilize a lower bound of DTW, LB_Keogh, to
approximate the dissimilarity between instances in linear time, while retaining
the relative proximity relationships one would have obtained via computing DTW.
We construct the pairwise distance matrix using LB_Keogh and build a graph for
the graph neural network. We apply this approach to the ten largest datasets
from the well-known UCR time series classification archive. The results
demonstrate that this approach can be up to 104x faster than SimTSC when
constructing the graph on large datasets without significantly decreasing
classification accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xi_W/0/1/0/all/0/1&quot;&gt;Wenjie Xi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1&quot;&gt;Arnav Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Li Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jessica Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.08272">
<title>Revisiting Hidden Representations in Transfer Learning for Medical Imaging. (arXiv:2302.08272v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2302.08272</link>
<description rdf:parseType="Literal">&lt;p&gt;While a key component to the success of deep learning is the availability of
massive amounts of training data, medical image datasets are often limited in
diversity and size. Transfer learning has the potential to bridge the gap
between related yet different domains. For medical applications, however, it
remains unclear whether it is more beneficial to pre-train on natural or
medical images. We aim to shed light on this problem by comparing
initialization on ImageNet and RadImageNet on seven medical classification
tasks. Our work includes a replication study, which yields results contrary to
previously published findings. In our experiments, ResNet50 models pre-trained
on ImageNet tend to outperform those trained on RadImageNet. To gain further
insights, we investigate the learned representations using Canonical
Correlation Analysis (CCA) and compare the predictions of the different models.
Our results indicate that, contrary to intuition, ImageNet and RadImageNet may
converge to distinct intermediate representations, which appear to diverge
further during fine-tuning. Despite these distinct representations, the
predictions of the models remain similar. Our findings show that the similarity
between networks before and after fine-tuning does not correlate with
performance gains, suggesting that the advantages of transfer learning might
not solely originate from the reuse of features in the early layers of a
convolutional neural network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juodelyte_D/0/1/0/all/0/1&quot;&gt;Dovile Juodelyte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jimenez_Sanchez_A/0/1/0/all/0/1&quot;&gt;Amelia Jim&amp;#xe9;nez-S&amp;#xe1;nchez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheplygina_V/0/1/0/all/0/1&quot;&gt;Veronika Cheplygina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.14051">
<title>Internet Explorer: Targeted Representation Learning on the Open Web. (arXiv:2302.14051v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.14051</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern vision models typically rely on fine-tuning general-purpose models
pre-trained on large, static datasets. These general-purpose models only
capture the knowledge within their pre-training datasets, which are tiny,
out-of-date snapshots of the Internet -- where billions of images are uploaded
each day. We suggest an alternate approach: rather than hoping our static
datasets transfer to our desired tasks after large-scale pre-training, we
propose dynamically utilizing the Internet to quickly train a small-scale model
that does extremely well on the task at hand. Our approach, called Internet
Explorer, explores the web in a self-supervised manner to progressively find
relevant examples that improve performance on a desired target dataset. It
cycles between searching for images on the Internet with text queries,
self-supervised training on downloaded images, determining which images were
useful, and prioritizing what to search for next. We evaluate Internet Explorer
across several datasets and show that it outperforms or matches CLIP oracle
performance by using just a single GPU desktop to actively query the Internet
for 30--40 hours. Results, visualizations, and videos at
https://internet-explorer-ssl.github.io/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Alexander C. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_E/0/1/0/all/0/1&quot;&gt;Ellis Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efros_A/0/1/0/all/0/1&quot;&gt;Alexei A. Efros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1&quot;&gt;Deepak Pathak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.03428">
<title>Towards provably efficient quantum algorithms for large-scale machine-learning models. (arXiv:2303.03428v4 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2303.03428</link>
<description rdf:parseType="Literal">&lt;p&gt;Large machine learning models are revolutionary technologies of artificial
intelligence whose bottlenecks include huge computational expenses, power, and
time used both in the pre-training and fine-tuning process. In this work, we
show that fault-tolerant quantum computing could possibly provide provably
efficient resolutions for generic (stochastic) gradient descent algorithms,
scaling as $\mathcal{O}(T^2 \times \text{polylog}(n))$, where $n$ is the size
of the models and $T$ is the number of iterations in the training, as long as
the models are both sufficiently dissipative and sparse, with small learning
rates. Based on earlier efficient quantum algorithms for dissipative
differential equations, we find and prove that similar algorithms work for
(stochastic) gradient descent, the primary algorithm for machine learning. In
practice, we benchmark instances of large machine learning models from 7
million to 103 million parameters. We find that, in the context of sparse
training, a quantum enhancement is possible at the early stage of learning
after model pruning, motivating a sparse parameter download and re-upload
scheme. Our work shows solidly that fault-tolerant quantum algorithms could
potentially contribute to most state-of-the-art, large-scale machine-learning
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Junyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Minzhao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jin-Peng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ye_Z/0/1/0/all/0/1&quot;&gt;Ziyu Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yunfei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Alexeev_Y/0/1/0/all/0/1&quot;&gt;Yuri Alexeev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Eisert_J/0/1/0/all/0/1&quot;&gt;Jens Eisert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jiang_L/0/1/0/all/0/1&quot;&gt;Liang Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.04436">
<title>A comparison of rational and neural network based approximations. (arXiv:2303.04436v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2303.04436</link>
<description rdf:parseType="Literal">&lt;p&gt;Rational and neural network based approximations are efficient tools in
modern approximation. These approaches are able to produce accurate
approximations to nonsmooth and non-Lipschitz functions, including multivariate
domain functions. In this paper we compare the efficiency of function
approximation using rational approximation, neural network and their
combinations. It was found that rational approximation is superior to neural
network based approaches with the same number of decision variables. Our
numerical experiments demonstrate the efficiency of rational approximation,
even when the number of approximation parameters (that is, the dimension of the
corresponding optimisation problems) is small. Another important contribution
of this paper lies in the improvement of rational approximation algorithms.
Namely, the optimisation based algorithms for rational approximation can be
adjusted to in such a way that the conditioning number of the constraint
matrices are controlled. This simple adjustment enables us to work with high
dimension optimisation problems and improve the design of the neural network.
The main strength of neural networks is in their ability to handle models with
a large number of variables: complex models are decomposed in several simple
optimisation problems. Therefore the the large number of decision variables is
in the nature of neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Peiris_V/0/1/0/all/0/1&quot;&gt;Vinesha Peiris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Millan_R/0/1/0/all/0/1&quot;&gt;Reinier Diaz Millan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sukhorukova_N/0/1/0/all/0/1&quot;&gt;Nadezda Sukhorukova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ugon_J/0/1/0/all/0/1&quot;&gt;Julien Ugon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.07853">
<title>ReFit: A Framework for Refinement of Weakly Supervised Semantic Segmentation using Object Border Fitting for Medical Images. (arXiv:2303.07853v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.07853</link>
<description rdf:parseType="Literal">&lt;p&gt;Weakly Supervised Semantic Segmentation (WSSS) relying only on image-level
supervision is a promising approach to deal with the need for Segmentation
networks, especially for generating a large number of pixel-wise masks in a
given dataset. However, most state-of-the-art image-level WSSS techniques lack
an understanding of the geometric features embedded in the images since the
network cannot derive any object boundary information from just image-level
labels. We define a boundary here as the line separating an object and its
background, or two different objects. To address this drawback, we are
proposing our novel ReFit framework, which deploys state-of-the-art class
activation maps combined with various post-processing techniques in order to
achieve fine-grained higher-accuracy segmentation masks. To achieve this, we
investigate a state-of-the-art unsupervised segmentation network that can be
used to construct a boundary map, which enables ReFit to predict object
locations with sharper boundaries. By applying our method to WSSS predictions,
we achieved up to 10% improvement over the current state-of-the-art WSSS
methods for medical imaging. The framework is open-source, to ensure that our
results are reproducible, and accessible online at
https://github.com/bharathprabakaran/ReFit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prabakaran_B/0/1/0/all/0/1&quot;&gt;Bharath Srinivas Prabakaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ostrowski_E/0/1/0/all/0/1&quot;&gt;Erik Ostrowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1&quot;&gt;Muhammad Shafique&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.08081">
<title>Explanation Shift: How Did the Distribution Shift Impact the Model?. (arXiv:2303.08081v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.08081</link>
<description rdf:parseType="Literal">&lt;p&gt;As input data distributions evolve, the predictive performance of machine
learning models tends to deteriorate. In practice, new input data tend to come
without target labels. Then, state-of-the-art techniques model input data
distributions or model prediction distributions and try to understand issues
regarding the interactions between learned models and shifting distributions.
We suggest a novel approach that models how explanation characteristics shift
when affected by distribution shifts. We find that the modeling of explanation
shifts can be a better indicator for detecting out-of-distribution model
behaviour than state-of-the-art techniques. We analyze different types of
distribution shifts using synthetic examples and real-world data sets. We
provide an algorithmic method that allows us to inspect the interaction between
data set features and learned models and compare them to the state-of-the-art.
We release our methods in an open-source Python package, as well as the code
used to reproduce our experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mougan_C/0/1/0/all/0/1&quot;&gt;Carlos Mougan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broelemann_K/0/1/0/all/0/1&quot;&gt;Klaus Broelemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masip_D/0/1/0/all/0/1&quot;&gt;David Masip&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1&quot;&gt;Gjergji Kasneci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiropanis_T/0/1/0/all/0/1&quot;&gt;Thanassis Thiropanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Staab_S/0/1/0/all/0/1&quot;&gt;Steffen Staab&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.13746">
<title>Achieving Occam&apos;s Razor: Deep Learning for Optimal Model Reduction. (arXiv:2303.13746v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.13746</link>
<description rdf:parseType="Literal">&lt;p&gt;All fields of science depend on mathematical models. Occam&apos;s razor refers to
the principle that good models should exclude parameters beyond those minimally
required to describe the systems they represent. This is because redundancy can
lead to incorrect estimates of model parameters from data, and thus inaccurate
or ambiguous conclusions. Here, we show how deep learning can be powerfully
leveraged to address Occam&apos;s razor. FixFit, our new method, uses a feedforward
deep neural network with a bottleneck layer to characterize and predict the
behavior of a given model from its input parameters. FixFit has three major
benefits. First, it provides a metric to quantify the original model&apos;s degree
of complexity. Second, it allows for the unique fitting of data. Third, it
provides an unbiased way to discriminate between experimental hypotheses that
add value versus those that do not. In two use cases, we demonstrate the broad
applicability of this method across scientific domains. To validate the method
using a known system, we apply FixFit to recover known composite parameters for
the Kepler orbit model. To illustrate how the method can be applied to less
well-established fields, we use it to identify parameters for a multi-scale
brain model and reduce the search space for viable candidate mechanisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antal_B/0/1/0/all/0/1&quot;&gt;Botond B Antal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chesebro_A/0/1/0/all/0/1&quot;&gt;Anthony G Chesebro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strey_H/0/1/0/all/0/1&quot;&gt;Helmut H Strey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mujica_Parodi_L/0/1/0/all/0/1&quot;&gt;Lilianne R Mujica-Parodi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weistuch_C/0/1/0/all/0/1&quot;&gt;Corey Weistuch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.01311">
<title>Knowledge Graphs in Practice: Characterizing their Users, Challenges, and Visualization Opportunities. (arXiv:2304.01311v3 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/2304.01311</link>
<description rdf:parseType="Literal">&lt;p&gt;This study presents insights from interviews with nineteen Knowledge Graph
(KG) practitioners who work in both enterprise and academic settings on a wide
variety of use cases. Through this study, we identify critical challenges
experienced by KG practitioners when creating, exploring, and analyzing KGs
that could be alleviated through visualization design. Our findings reveal
three major personas among KG practitioners - KG Builders, Analysts, and
Consumers - each of whom have their own distinct expertise and needs. We
discover that KG Builders would benefit from schema enforcers, while KG
Analysts need customizable query builders that provide interim query results.
For KG Consumers, we identify a lack of efficacy for node-link diagrams, and
the need for tailored domain-specific visualizations to promote KG adoption and
comprehension. Lastly, we find that implementing KGs effectively in practice
requires both technical and social solutions that are not addressed with
current tools, technologies, and collaborative workflows. From the analysis of
our interviews, we distill several visualization research directions to improve
KG usability, including knowledge cards that balance digestibility and
discoverability, timeline views to track temporal changes, interfaces that
support organic discovery, and semantic explanations for AI and machine
learning predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Harry Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Appleby_G/0/1/0/all/0/1&quot;&gt;Gabriel Appleby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brumar_C/0/1/0/all/0/1&quot;&gt;Camelia Daniela Brumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_R/0/1/0/all/0/1&quot;&gt;Remco Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suh_A/0/1/0/all/0/1&quot;&gt;Ashley Suh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.06104">
<title>Primal-Dual Contextual Bayesian Optimization for Control System Online Optimization with Time-Average Constraints. (arXiv:2304.06104v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.06104</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of online performance optimization of
constrained closed-loop control systems, where both the objective and the
constraints are unknown black-box functions affected by exogenous time-varying
contextual disturbances. A primal-dual contextual Bayesian optimization
algorithm is proposed that achieves sublinear cumulative regret with respect to
the dynamic optimal solution under certain regularity conditions. Furthermore,
the algorithm achieves zero time-average constraint violation, ensuring that
the average value of the constraint function satisfies the desired constraint.
The method is applied to both sampled instances from Gaussian processes and a
continuous stirred tank reactor parameter tuning problem; simulation results
show that the method simultaneously provides close-to-optimal performance and
maintains constraint feasibility on average. This contrasts current
state-of-the-art methods, which either suffer from large cumulative regret or
severe constraint violations for the case studies presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Wenjie Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yuning Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svetozarevic_B/0/1/0/all/0/1&quot;&gt;Bratislav Svetozarevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_C/0/1/0/all/0/1&quot;&gt;Colin N. Jones&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.09479">
<title>DiFaReli: Diffusion Face Relighting. (arXiv:2304.09479v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.09479</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel approach to single-view face relighting in the wild.
Handling non-diffuse effects, such as global illumination or cast shadows, has
long been a challenge in face relighting. Prior work often assumes Lambertian
surfaces, simplified lighting models or involves estimating 3D shape, albedo,
or a shadow map. This estimation, however, is error-prone and requires many
training examples with lighting ground truth to generalize well. Our work
bypasses the need for accurate estimation of intrinsic components and can be
trained solely on 2D images without any light stage data, multi-view images, or
lighting ground truth. Our key idea is to leverage a conditional diffusion
implicit model (DDIM) for decoding a disentangled light encoding along with
other encodings related to 3D shape and facial identity inferred from
off-the-shelf estimators. We also propose a novel conditioning technique that
eases the modeling of the complex interaction between light and geometry by
using a rendered shading reference to spatially modulate the DDIM. We achieve
state-of-the-art performance on standard benchmark Multi-PIE and can
photorealistically relight in-the-wild images. Please visit our page:
https://diffusion-face-relighting.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponglertnapakorn_P/0/1/0/all/0/1&quot;&gt;Puntawat Ponglertnapakorn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tritrong_N/0/1/0/all/0/1&quot;&gt;Nontawat Tritrong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suwajanakorn_S/0/1/0/all/0/1&quot;&gt;Supasorn Suwajanakorn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.10226">
<title>Domain Generalization for Mammographic Image Analysis with Contrastive Learning. (arXiv:2304.10226v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.10226</link>
<description rdf:parseType="Literal">&lt;p&gt;The deep learning technique has been shown to be effectively addressed
several image analysis tasks in the computer-aided diagnosis scheme for
mammography. The training of an efficacious deep learning model requires large
data with diverse styles and qualities. The diversity of data often comes from
the use of various scanners of vendors. But, in practice, it is impractical to
collect a sufficient amount of diverse data for training. To this end, a novel
contrastive learning is developed to equip the deep learning models with better
style generalization capability. Specifically, the multi-style and multi-view
unsupervised self-learning scheme is carried out to seek robust feature
embedding against style diversity as a pretrained model. Afterward, the
pretrained network is further fine-tuned to the downstream tasks, e.g., mass
detection, matching, BI-RADS rating, and breast density classification. The
proposed method has been evaluated extensively and rigorously with mammograms
from various vendor style domains and several public datasets. The experimental
results suggest that the proposed domain generalization method can effectively
improve performance of four mammographic image tasks on the data from both seen
and unseen domains, and outperform many state-of-the-art (SOTA) generalization
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zheren Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1&quot;&gt;Zhiming Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lichi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_C/0/1/0/all/0/1&quot;&gt;Chenjin Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_X/0/1/0/all/0/1&quot;&gt;Xi Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Dongdong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xiangyu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1&quot;&gt;Yajia Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zaiyi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chunling Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1&quot;&gt;Dinggang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;Jie-Zhi Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.09241">
<title>Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples. (arXiv:2305.09241v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.09241</link>
<description rdf:parseType="Literal">&lt;p&gt;Safeguarding data from unauthorized exploitation is vital for privacy and
security, especially in recent rampant research in security breach such as
adversarial/membership attacks. To this end, \textit{unlearnable examples}
(UEs) have been recently proposed as a compelling protection, by adding
imperceptible perturbation to data so that models trained on them cannot
classify them accurately on original clean distribution. Unfortunately, we find
UEs provide a false sense of security, because they cannot stop unauthorized
users from utilizing other unprotected data to remove the protection, by
turning unlearnable data into learnable again. Motivated by this observation,
we formally define a new threat by introducing \textit{learnable unauthorized
examples} (LEs) which are UEs with their protection removed. The core of this
approach is a novel purification process that projects UEs onto the manifold of
LEs. This is realized by a new joint-conditional diffusion model which denoises
UEs conditioned on the pixel and perceptual similarity between UEs and LEs.
Extensive experiments demonstrate that LE delivers state-of-the-art countering
performance against both supervised UEs and unsupervised UEs in various
scenarios, which is the first generalizable countermeasure to UEs across
supervised learning and unsupervised learning. Our code is available at
\url{https://github.com/jiangw-0/LE_JCDP}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1&quot;&gt;Wan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diao_Y/0/1/0/all/0/1&quot;&gt;Yunfeng Diao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;He Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jianxin Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Meng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_R/0/1/0/all/0/1&quot;&gt;Richang Hong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.06145">
<title>LDMRes-Net: Enabling Efficient Medical Image Segmentation on IoT and Edge Platforms. (arXiv:2306.06145v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.06145</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we propose LDMRes-Net, a lightweight dual-multiscale residual
block-based computational neural network tailored for medical image
segmentation on IoT and edge platforms. Conventional U-Net-based models face
challenges in meeting the speed and efficiency demands of real-time clinical
applications, such as disease monitoring, radiation therapy, and image-guided
surgery. LDMRes-Net overcomes these limitations with its remarkably low number
of learnable parameters (0.072M), making it highly suitable for
resource-constrained devices. The model&apos;s key innovation lies in its dual
multi-residual block architecture, which enables the extraction of refined
features on multiple scales, enhancing overall segmentation performance. To
further optimize efficiency, the number of filters is carefully selected to
prevent overlap, reduce training time, and improve computational efficiency.
The study includes comprehensive evaluations, focusing on segmentation of the
retinal image of vessels and hard exudates crucial for the diagnosis and
treatment of ophthalmology. The results demonstrate the robustness,
generalizability, and high segmentation accuracy of LDMRes-Net, positioning it
as an efficient tool for accurate and rapid medical image segmentation in
diverse clinical applications, particularly on IoT and edge platforms. Such
advances hold significant promise for improving healthcare outcomes and
enabling real-time medical image analysis in resource-limited settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Iqbal_S/0/1/0/all/0/1&quot;&gt;Shahzaib Iqbal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Khan_T/0/1/0/all/0/1&quot;&gt;Tariq M. Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Naqvi_S/0/1/0/all/0/1&quot;&gt;Syed S. Naqvi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Usman_M/0/1/0/all/0/1&quot;&gt;Muhammad Usman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Razzak_I/0/1/0/all/0/1&quot;&gt;Imran Razzak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.07019">
<title>Dynamic Causal Graph Convolutional Network for Traffic Prediction. (arXiv:2306.07019v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.07019</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling complex spatiotemporal dependencies in correlated traffic series is
essential for traffic prediction. While recent works have shown improved
prediction performance by using neural networks to extract spatiotemporal
correlations, their effectiveness depends on the quality of the graph
structures used to represent the spatial topology of the traffic network. In
this work, we propose a novel approach for traffic prediction that embeds
time-varying dynamic Bayesian network to capture the fine spatiotemporal
topology of traffic data. We then use graph convolutional networks to generate
traffic forecasts. To enable our method to efficiently model nonlinear traffic
propagation patterns, we develop a deep learning-based module as a
hyper-network to generate stepwise dynamic causal graphs. Our experimental
results on a real traffic dataset demonstrate the superior prediction
performance of the proposed method. The code is available at
https://github.com/MonBG/DCGCN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Junpeng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Ziyue Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhishuai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1&quot;&gt;Lei Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1&quot;&gt;Rui Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chen Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.08719">
<title>Off-policy Evaluation in Doubly Inhomogeneous Environments. (arXiv:2306.08719v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/2306.08719</link>
<description rdf:parseType="Literal">&lt;p&gt;This work aims to study off-policy evaluation (OPE) under scenarios where two
key reinforcement learning (RL) assumptions -- temporal stationarity and
individual homogeneity are both violated. To handle the ``double
inhomogeneities&quot;, we propose a class of latent factor models for the reward and
observation transition functions, under which we develop a general OPE
framework that consists of both model-based and model-free approaches. To our
knowledge, this is the first paper that develops statistically sound OPE
methods in offline RL with double inhomogeneities. It contributes to a deeper
understanding of OPE in environments, where standard RL assumptions are not
met, and provides several practical approaches in these settings. We establish
the theoretical properties of the proposed value estimators and empirically
show that our approach outperforms competing methods that ignore either
temporal nonstationarity or individual heterogeneity. Finally, we illustrate
our method on a data set from the Medical Information Mart for Intensive Care.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bian_Z/0/1/0/all/0/1&quot;&gt;Zeyu Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shi_C/0/1/0/all/0/1&quot;&gt;Chengchun Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qi_Z/0/1/0/all/0/1&quot;&gt;Zhengling Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.08754">
<title>ClimSim: An open large-scale dataset for training high-resolution physics emulators in hybrid multi-scale climate simulators. (arXiv:2306.08754v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.08754</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern climate projections lack adequate spatial and temporal resolution due
to computational constraints. A consequence is inaccurate and imprecise
predictions of critical processes such as storms. Hybrid methods that combine
physics with machine learning (ML) have introduced a new generation of higher
fidelity climate simulators that can sidestep Moore&apos;s Law by outsourcing
compute-hungry, short, high-resolution simulations to ML emulators. However,
this hybrid ML-physics simulation approach requires domain-specific treatment
and has been inaccessible to ML experts because of lack of training data and
relevant, easy-to-use workflows. We present ClimSim, the largest-ever dataset
designed for hybrid ML-physics research. It comprises multi-scale climate
simulations, developed by a consortium of climate scientists and ML
researchers. It consists of 5.7 billion pairs of multivariate input and output
vectors that isolate the influence of locally-nested, high-resolution,
high-fidelity physics on a host climate simulator&apos;s macro-scale physical state.
&lt;/p&gt;
&lt;p&gt;The dataset is global in coverage, spans multiple years at high sampling
frequency, and is designed such that resulting emulators are compatible with
downstream coupling into operational climate simulators. We implement a range
of deterministic and stochastic regression baselines to highlight the ML
challenges and their scoring. The data
(https://huggingface.co/datasets/LEAP/ClimSim_high-res,
https://huggingface.co/datasets/LEAP/ClimSim_low-res, and
https://huggingface.co/datasets/LEAP/ClimSim_low-res_aqua-planet) and code
(https://leap-stc.github.io/ClimSim) are released openly to support the
development of hybrid ML-physics and high-fidelity climate simulations for the
benefit of science and society.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Sungduk Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hannah_W/0/1/0/all/0/1&quot;&gt;Walter M. Hannah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1&quot;&gt;Liran Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jerry Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhouri_M/0/1/0/all/0/1&quot;&gt;Mohamed Aziz Bhouri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1&quot;&gt;Ritwik Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn L&amp;#xfc;tjens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Will_J/0/1/0/all/0/1&quot;&gt;Justus C. Will&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behrens_G/0/1/0/all/0/1&quot;&gt;Gunnar Behrens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Busecke_J/0/1/0/all/0/1&quot;&gt;Julius J. M. Busecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loose_N/0/1/0/all/0/1&quot;&gt;Nora Loose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stern_C/0/1/0/all/0/1&quot;&gt;Charles Stern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beucler_T/0/1/0/all/0/1&quot;&gt;Tom Beucler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harrop_B/0/1/0/all/0/1&quot;&gt;Bryce E. Harrop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hilman_B/0/1/0/all/0/1&quot;&gt;Benjamin R. Hilman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jenney_A/0/1/0/all/0/1&quot;&gt;Andrea M. Jenney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferretti_S/0/1/0/all/0/1&quot;&gt;Savannah L. Ferretti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1&quot;&gt;Nana Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brenowitz_N/0/1/0/all/0/1&quot;&gt;Noah D. Brenowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eyring_V/0/1/0/all/0/1&quot;&gt;Veronika Eyring&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geneva_N/0/1/0/all/0/1&quot;&gt;Nicholas Geneva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gentine_P/0/1/0/all/0/1&quot;&gt;Pierre Gentine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1&quot;&gt;Stephan Mandt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_J/0/1/0/all/0/1&quot;&gt;Jaideep Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramaniam_A/0/1/0/all/0/1&quot;&gt;Akshay Subramaniam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vondrick_C/0/1/0/all/0/1&quot;&gt;Carl Vondrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1&quot;&gt;Rose Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zanna_L/0/1/0/all/0/1&quot;&gt;Laure Zanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1&quot;&gt;Tian Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abernathey_R/0/1/0/all/0/1&quot;&gt;Ryan P. Abernathey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1&quot;&gt;Fiaz Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bader_D/0/1/0/all/0/1&quot;&gt;David C. Bader&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baldi_P/0/1/0/all/0/1&quot;&gt;Pierre Baldi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barnes_E/0/1/0/all/0/1&quot;&gt;Elizabeth A. Barnes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bretherton_C/0/1/0/all/0/1&quot;&gt;Christopher S. Bretherton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caldwell_P/0/1/0/all/0/1&quot;&gt;Peter M. Caldwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chuang_W/0/1/0/all/0/1&quot;&gt;Wayne Chuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yilun Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iglesias_Suarez_F/0/1/0/all/0/1&quot;&gt;Fernando Iglesias-Suarez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jantre_S/0/1/0/all/0/1&quot;&gt;Sanket Jantre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kashinath_K/0/1/0/all/0/1&quot;&gt;Karthik Kashinath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khairoutdinov_M/0/1/0/all/0/1&quot;&gt;Marat Khairoutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurth_T/0/1/0/all/0/1&quot;&gt;Thorsten Kurth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lutsko_N/0/1/0/all/0/1&quot;&gt;Nicholas J. Lutsko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1&quot;&gt;Po-Lun Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mooers_G/0/1/0/all/0/1&quot;&gt;Griffin Mooers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neelin_J/0/1/0/all/0/1&quot;&gt;J. David Neelin&lt;/a&gt;, et al. (7 additional authors not shown)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12760">
<title>Blended-NeRF: Zero-Shot Object Generation and Blending in Existing Neural Radiance Fields. (arXiv:2306.12760v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12760</link>
<description rdf:parseType="Literal">&lt;p&gt;Editing a local region or a specific object in a 3D scene represented by a
NeRF or consistently blending a new realistic object into the scene is
challenging, mainly due to the implicit nature of the scene representation. We
present Blended-NeRF, a robust and flexible framework for editing a specific
region of interest in an existing NeRF scene, based on text prompts, along with
a 3D ROI box. Our method leverages a pretrained language-image model to steer
the synthesis towards a user-provided text prompt, along with a 3D MLP model
initialized on an existing NeRF scene to generate the object and blend it into
a specified region in the original scene. We allow local editing by localizing
a 3D ROI box in the input scene, and blend the content synthesized inside the
ROI with the existing scene using a novel volumetric blending technique. To
obtain natural looking and view-consistent results, we leverage existing and
new geometric priors and 3D augmentations for improving the visual fidelity of
the final result. We test our framework both qualitatively and quantitatively
on a variety of real 3D scenes and text prompts, demonstrating realistic
multi-view consistent results with much flexibility and diversity compared to
the baselines. Finally, we show the applicability of our framework for several
3D editing applications, including adding new objects to a scene,
removing/replacing/altering existing objects, and texture conversion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gordon_O/0/1/0/all/0/1&quot;&gt;Ori Gordon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avrahami_O/0/1/0/all/0/1&quot;&gt;Omri Avrahami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lischinski_D/0/1/0/all/0/1&quot;&gt;Dani Lischinski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12774">
<title>Pure Exploration in Bandits with Linear Constraints. (arXiv:2306.12774v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12774</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of identifying the optimal policy with a fixed
confidence level in a multi-armed bandit setup, when \emph{the arms are subject
to linear constraints}. Unlike the standard best-arm identification problem
which is well studied, the optimal policy in this case may not be deterministic
and could mix between several arms. This changes the geometry of the problem
which we characterize via an information-theoretic lower bound. We introduce
two asymptotically optimal algorithms for this setting, one based on the
Track-and-Stop method and the other based on a game-theoretic approach. Both
these algorithms try to track an optimal allocation based on the lower bound
and computed by a weighted projection onto the boundary of a normal cone.
Finally, we provide empirical results that validate our bounds and visualize
how constraints change the hardness of the problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlsson_E/0/1/0/all/0/1&quot;&gt;Emil Carlsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1&quot;&gt;Debabrota Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johansson_F/0/1/0/all/0/1&quot;&gt;Fredrik D. Johansson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubhashi_D/0/1/0/all/0/1&quot;&gt;Devdatt Dubhashi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.13596">
<title>Max-Margin Token Selection in Attention Mechanism. (arXiv:2306.13596v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.13596</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention mechanism is a central component of the transformer architecture
which led to the phenomenal success of large language models. However, the
theoretical principles underlying the attention mechanism are poorly
understood, especially its nonconvex optimization dynamics. In this work, we
explore the seminal softmax-attention model $f(\boldsymbol{X})=\langle
\boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where
$\boldsymbol{X}$ is the token sequence and
$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are trainable parameters. We
prove that running gradient descent on $\boldsymbol{p}$, or equivalently
$\boldsymbol{W}$, converges in direction to a max-margin solution that
separates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearly
formalizes attention as an optimal token selection mechanism. Remarkably, our
results are applicable to general data and precisely characterize
$\textit{optimality}$ of tokens in terms of the value embeddings
$\boldsymbol{Xv}$ and problem geometry. We also provide a broader
regularization path analysis that establishes the margin maximizing nature of
attention even for nonlinear prediction heads. When optimizing $\boldsymbol{v}$
and $\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions
under which the regularization paths directionally converge to their respective
hard-margin SVM solutions where $\boldsymbol{v}$ separates the input features
based on their labels. Interestingly, the SVM formulation of $\boldsymbol{p}$
is influenced by the support vector geometry of $\boldsymbol{v}$. Finally, we
verify our theoretical findings via numerical experiments and provide insights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarzanagh_D/0/1/0/all/0/1&quot;&gt;Davoud Ataee Tarzanagh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingcong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuechen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06555">
<title>Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06555</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the expressive power of deep neural networks for a
diverse range of activation functions. An activation function set $\mathscr{A}$
is defined to encompass the majority of commonly used activation functions,
such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$,
$\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$,
$\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$,
$\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and
$\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in
\mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be
approximated to arbitrary precision by a $\varrho$-activated network of width
$4N$ and depth $2L$ on any bounded set. This finding enables the extension of
most approximation results achieved with $\mathtt{ReLU}$ networks to a wide
variety of other activation functions, at the cost of slightly larger
constants.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shijun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jianfeng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Hongkai Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09882">
<title>Adversarial Likelihood Estimation With One-Way Flows. (arXiv:2307.09882v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.09882</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) can produce high-quality samples, but
do not provide an estimate of the probability density around the samples.
However, it has been noted that maximizing the log-likelihood within an
energy-based setting can lead to an adversarial framework where the
discriminator provides unnormalized density (often called energy). We further
develop this perspective, incorporate importance sampling, and show that 1)
Wasserstein GAN performs a biased estimate of the partition function, and we
propose instead to use an unbiased estimator; and 2) when optimizing for
likelihood, one must maximize generator entropy. This is hypothesized to
provide a better mode coverage. Different from previous works, we explicitly
compute the density of the generated samples. This is the key enabler to
designing an unbiased estimator of the partition function and computation of
the generator entropy term. The generator density is obtained via a new type of
flow network, called one-way flow network, that is less constrained in terms of
architecture, as it does not require a tractable inverse function. Our
experimental results show that our method converges faster, produces comparable
sample quality to GANs with similar architecture, successfully avoids
over-fitting to commonly used datasets and produces smooth low-dimensional
latent representations of the training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ben_Dov_O/0/1/0/all/0/1&quot;&gt;Omri Ben-Dov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1&quot;&gt;Pravir Singh Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abrevaya_V/0/1/0/all/0/1&quot;&gt;Victoria Abrevaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1&quot;&gt;Michael J. Black&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_P/0/1/0/all/0/1&quot;&gt;Partha Ghosh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.14971">
<title>Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models. (arXiv:2307.14971v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.14971</link>
<description rdf:parseType="Literal">&lt;p&gt;With the overwhelming trend of mask image modeling led by MAE, generative
pre-training has shown a remarkable potential to boost the performance of
fundamental models in 2D vision. However, in 3D vision, the over-reliance on
Transformer-based backbones and the unordered nature of point clouds have
restricted the further development of generative pre-training. In this paper,
we propose a novel 3D-to-2D generative pre-training method that is adaptable to
any point cloud model. We propose to generate view images from different
instructed poses via the cross-attention mechanism as the pre-training scheme.
Generating view images has more precise supervision than its point cloud
counterpart, thus assisting 3D backbones to have a finer comprehension of the
geometrical structure and stereoscopic relations of the point cloud.
Experimental results have proved the superiority of our proposed 3D-to-2D
generative pre-training over previous pre-training methods. Our method is also
effective in boosting the performance of architecture-oriented approaches,
achieving state-of-the-art performance when fine-tuning on ScanObjectNN
classification and ShapeNetPart segmentation tasks. Code is available at
https://github.com/wangzy22/TAP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xumin Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1&quot;&gt;Yongming Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jie Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiwen Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.00452">
<title>A Majority Invariant Approach to Patch Robustness Certification for Deep Learning Models. (arXiv:2308.00452v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.00452</link>
<description rdf:parseType="Literal">&lt;p&gt;Patch robustness certification ensures no patch within a given bound on a
sample can manipulate a deep learning model to predict a different label.
However, existing techniques cannot certify samples that cannot meet their
strict bars at the classifier or patch region levels. This paper proposes
MajorCert. MajorCert firstly finds all possible label sets manipulatable by the
same patch region on the same sample across the underlying classifiers, then
enumerates their combinations element-wise, and finally checks whether the
majority invariant of all these combinations is intact to certify samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1&quot;&gt;Qilin Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1&quot;&gt;Zhengyuan Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haipeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1&quot;&gt;W.K. Chan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.00904">
<title>VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference. (arXiv:2308.00904v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.00904</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference plays a vital role in diverse domains like epidemiology,
healthcare, and economics. De-confounding and counterfactual prediction in
observational data has emerged as a prominent concern in causal inference
research. While existing models tackle observed confounders, the presence of
unobserved confounders remains a significant challenge, distorting causal
inference and impacting counterfactual outcome accuracy. To address this, we
propose a novel variational learning model of unobserved confounders for
counterfactual inference (VLUCI), which generates the posterior distribution of
unobserved confounders. VLUCI relaxes the unconfoundedness assumption often
overlooked by most causal inference methods. By disentangling observed and
unobserved confounders, VLUCI constructs a doubly variational inference model
to approximate the distribution of unobserved confounders, which are used for
inferring more accurate counterfactual outcomes. Extensive experiments on
synthetic and semi-synthetic datasets demonstrate VLUCI&apos;s superior performance
in inferring unobserved confounders. It is compatible with state-of-the-art
counterfactual inference models, significantly improving inference accuracy at
both group and individual levels. Additionally, VLUCI provides confidence
intervals for counterfactual outcomes, aiding decision-making in risk-sensitive
domains. We further clarify the considerations when applying VLUCI to cases
where unobserved confounders don&apos;t strictly conform to our model assumptions
using the public IHDP dataset as an example, highlighting the practical
advantages of VLUCI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yonghe Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1&quot;&gt;Siwei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1&quot;&gt;Yun Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Huiyan Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02335">
<title>RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification. (arXiv:2308.02335v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.02335</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph classification is a crucial task in many real-world multimedia
applications, where graphs can represent various multimedia data types such as
images, videos, and social networks. Previous efforts have applied graph neural
networks (GNNs) in balanced situations where the class distribution is
balanced. However, real-world data typically exhibit long-tailed class
distributions, resulting in a bias towards the head classes when using GNNs and
limited generalization ability over the tail classes. Recent approaches mainly
focus on re-balancing different classes during model training, which fails to
explicitly introduce new knowledge and sacrifices the performance of the head
classes. To address these drawbacks, we propose a novel framework called
Retrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature
extractor and an unbiased classifier in a decoupled manner. In the feature
extractor training stage, we develop a graph retrieval module to search for
relevant graphs that directly enrich the intra-class diversity for the tail
classes. Moreover, we innovatively optimize a category-centered supervised
contrastive loss to obtain discriminative representations, which is more
suitable for long-tailed scenarios. In the classifier fine-tuning stage, we
balance the classifier weights with two weight regularization techniques, i.e.,
Max-norm and weight decay. Experiments on various popular benchmarks verify the
superiority of the proposed method against state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1&quot;&gt;Zhengyang Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ju_W/0/1/0/all/0/1&quot;&gt;Wei Ju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1&quot;&gt;Yifang Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Ming Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03944">
<title>GraPhSyM: Graph Physical Synthesis Model. (arXiv:2308.03944v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03944</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we introduce GraPhSyM, a Graph Attention Network (GATv2) model
for fast and accurate estimation of post-physical synthesis circuit delay and
area metrics from pre-physical synthesis circuit netlists. Once trained,
GraPhSyM provides accurate visibility of final design metrics to early EDA
stages, such as logic synthesis, without running the slow physical synthesis
flow, enabling global co-optimization across stages. Additionally, the swift
and precise feedback provided by GraPhSyM is instrumental for
machine-learning-based EDA optimization frameworks. Given a gate-level netlist
of a circuit represented as a graph, GraPhSyM utilizes graph structure,
connectivity, and electrical property features to predict the impact of
physical synthesis transformations such as buffer insertion and gate sizing.
When trained on a dataset of 6000 prefix adder designs synthesized at an
aggressive delay target, GraPhSyM can accurately predict the post-synthesis
delay (98.3%) and area (96.1%) metrics of unseen adders with a fast 0.22s
inference time. Furthermore, we illustrate the compositionality of GraPhSyM by
employing the model trained on a fixed delay target to accurately anticipate
post-synthesis metrics at a variety of unseen delay targets. Lastly, we report
promising generalization capabilities of the GraPhSyM model when it is
evaluated on circuits different from the adders it was exclusively trained on.
The results show the potential for GraPhSyM to serve as a powerful tool for
advanced optimization techniques and as an oracle for EDA machine learning
frameworks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agiza_A/0/1/0/all/0/1&quot;&gt;Ahmed Agiza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1&quot;&gt;Rajarshi Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ene_T/0/1/0/all/0/1&quot;&gt;Teodor Dumitru Ene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godil_S/0/1/0/all/0/1&quot;&gt;Saad Godil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reda_S/0/1/0/all/0/1&quot;&gt;Sherief Reda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1&quot;&gt;Bryan Catanzaro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04014">
<title>Continual Pre-Training of Large Language Models: How to (re)warm your model?. (arXiv:2308.04014v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.04014</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) are routinely pre-trained on billions of tokens,
only to restart the process over again once new data becomes available. A much
cheaper and more efficient solution would be to enable the continual
pre-training of these models, i.e. updating pre-trained models with new data
instead of re-training them from scratch. However, the distribution shift
induced by novel data typically results in degraded performance on past data.
Taking a step towards efficient continual pre-training, in this work, we
examine the effect of different warm-up strategies. Our hypothesis is that the
learning rate must be re-increased to improve compute efficiency when training
on a new dataset. We study the warmup phase of models pre-trained on the Pile
(upstream data, 300B tokens) as we continue to pre-train on SlimPajama
(downstream data, 297B tokens), following a linear warmup and cosine decay
schedule. We conduct all experiments on the Pythia 410M language model
architecture and evaluate performance through validation perplexity. We
experiment with different pre-training checkpoints, various maximum learning
rates, and various warmup lengths. Our results show that while rewarming models
first increases the loss on upstream and downstream data, in the longer run it
improves the downstream performance, outperforming models trained from
scratch$\unicode{x2013}$even for a large downstream dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1&quot;&gt;Kshitij Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Therien_B/0/1/0/all/0/1&quot;&gt;Benjamin Th&amp;#xe9;rien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahim_A/0/1/0/all/0/1&quot;&gt;Adam Ibrahim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richter_M/0/1/0/all/0/1&quot;&gt;Mats L. Richter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anthony_Q/0/1/0/all/0/1&quot;&gt;Quentin Anthony&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1&quot;&gt;Eugene Belilovsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1&quot;&gt;Irina Rish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1&quot;&gt;Timoth&amp;#xe9;e Lesort&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.08643">
<title>Towards Personalized Federated Learning via Heterogeneous Model Reassembly. (arXiv:2308.08643v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.08643</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper focuses on addressing the practical yet challenging problem of
model heterogeneity in federated learning, where clients possess models with
different network structures. To track this problem, we propose a novel
framework called pFedHR, which leverages heterogeneous model reassembly to
achieve personalized federated learning. In particular, we approach the problem
of heterogeneous model personalization as a model-matching optimization task on
the server side. Moreover, pFedHR automatically and dynamically generates
informative and diverse personalized candidates with minimal human
intervention. Furthermore, our proposed heterogeneous model reassembly
technique mitigates the adverse impact introduced by using public data with
different distributions from the client data to a certain extent. Experimental
results demonstrate that pFedHR outperforms baselines on three datasets under
both IID and Non-IID settings. Additionally, pFedHR effectively reduces the
adverse impact of using different public data and dynamically generates diverse
personalized models in an automated manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiaqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xingyi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1&quot;&gt;Suhan Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Che_L/0/1/0/all/0/1&quot;&gt;Liwei Che&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1&quot;&gt;Lingjuan Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1&quot;&gt;Dongkuan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1&quot;&gt;Fenglong Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.09183">
<title>RatGPT: Turning online LLMs into Proxies for Malware Attacks. (arXiv:2308.09183v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2308.09183</link>
<description rdf:parseType="Literal">&lt;p&gt;The evolution of Generative AI and the capabilities of the newly released
Large Language Models (LLMs) open new opportunities in software engineering.
However, they also lead to new challenges in cybersecurity. Recently,
researchers have shown the possibilities of using LLMs such as ChatGPT to
generate malicious content that can directly be exploited or guide
inexperienced hackers to weaponize tools and code. These studies covered
scenarios that still require the attacker to be in the middle of the loop. In
this study, we leverage openly available plugins and use an LLM as proxy
between the attacker and the victim. We deliver a proof-of-concept where
ChatGPT is used for the dissemination of malicious software while evading
detection, alongside establishing the communication to a command and control
(C2) server to receive commands to interact with a victim&apos;s system. Finally, we
present the general approach as well as essential elements in order to stay
undetected and make the attack a success. This proof-of-concept highlights
significant cybersecurity issues with openly available plugins and LLMs, which
require the development of security guidelines, controls, and mitigation
strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beckerich_M/0/1/0/all/0/1&quot;&gt;Mika Beckerich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plein_L/0/1/0/all/0/1&quot;&gt;Laura Plein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coronado_S/0/1/0/all/0/1&quot;&gt;Sergio Coronado&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.09199">
<title>Polynomial Bounds for Learning Noisy Optical Physical Unclonable Functions and Connections to Learning With Errors. (arXiv:2308.09199v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.09199</link>
<description rdf:parseType="Literal">&lt;p&gt;It is shown that a class of optical physical unclonable functions (PUFs) can
be learned to arbitrary precision with arbitrarily high probability, even in
the presence of noise, given access to polynomially many challenge-response
pairs and polynomially bounded computational power, under mild assumptions
about the distributions of the noise and challenge vectors. This extends the
results of Rh\&quot;uramir et al. (2013), who showed a subset of this class of PUFs
to be learnable in polynomial time in the absence of noise, under the
assumption that the optics of the PUF were either linear or had negligible
nonlinear effects. We derive polynomial bounds for the required number of
samples and the computational complexity of a linear regression algorithm,
based on size parameters of the PUF, the distributions of the challenge and
noise vectors, and the probability and accuracy of the regression algorithm,
with a similar analysis to one done by Bootle et al. (2018), who demonstrated a
learning attack on a poorly implemented version of the Learning With Errors
problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albright_A/0/1/0/all/0/1&quot;&gt;Apollo Albright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gelfand_B/0/1/0/all/0/1&quot;&gt;Boris Gelfand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dixon_M/0/1/0/all/0/1&quot;&gt;Michael Dixon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.13280">
<title>AtmoRep: A stochastic model of atmosphere dynamics using large scale representation learning. (arXiv:2308.13280v2 [physics.ao-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2308.13280</link>
<description rdf:parseType="Literal">&lt;p&gt;The atmosphere affects humans in a multitude of ways, from loss of life due
to adverse weather effects to long-term social and economic impacts on
societies. Computer simulations of atmospheric dynamics are, therefore, of
great importance for the well-being of our and future generations. Here, we
propose AtmoRep, a novel, task-independent stochastic computer model of
atmospheric dynamics that can provide skillful results for a wide range of
applications. AtmoRep uses large-scale representation learning from artificial
intelligence to determine a general description of the highly complex,
stochastic dynamics of the atmosphere from the best available estimate of the
system&apos;s historical trajectory as constrained by observations. This is enabled
by a novel self-supervised learning objective and a unique ensemble that
samples from the stochastic model with a variability informed by the one in the
historical record. The task-independent nature of AtmoRep enables skillful
results for a diverse set of applications without specifically training for
them and we demonstrate this for nowcasting, temporal interpolation, model
correction, and counterfactuals. We also show that AtmoRep can be improved with
additional data, for example radar observations, and that it can be extended to
tasks such as downscaling. Our work establishes that large-scale neural
networks can provide skillful, task-independent models of atmospheric dynamics.
With this, they provide a novel means to make the large record of atmospheric
observations accessible for applications and for scientific inquiry,
complementing existing simulations based on first principles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lessig_C/0/1/0/all/0/1&quot;&gt;Christian Lessig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Luise_I/0/1/0/all/0/1&quot;&gt;Ilaria Luise&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gong_B/0/1/0/all/0/1&quot;&gt;Bing Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Langguth_M/0/1/0/all/0/1&quot;&gt;Michael Langguth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Stadler_S/0/1/0/all/0/1&quot;&gt;Scarlet Stadler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Schultz_M/0/1/0/all/0/1&quot;&gt;Martin Schultz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.15116">
<title>Mixup-Augmented Meta-Learning for Sample-Efficient Fine-Tuning of Protein Simulators. (arXiv:2308.15116v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.15116</link>
<description rdf:parseType="Literal">&lt;p&gt;Molecular dynamics simulations have emerged as a fundamental instrument for
studying biomolecules. At the same time, it is desirable to perform simulations
of a collection of particles under various conditions in which the molecules
can fluctuate. In this paper, we explore and adapt the soft prompt-based
learning method to molecular dynamics tasks. Our model can remarkably
generalize to unseen and out-of-distribution scenarios with limited training
data. While our work focuses on temperature as a test case, the versatility of
our approach allows for efficient simulation through any continuous dynamic
conditions, such as pressure and volumes. Our framework has two stages: 1)
Pre-trains with data mixing technique, augments molecular structure data and
temperature prompts, then applies a curriculum learning method by increasing
the ratio of them smoothly. 2) Meta-learning-based fine-tuning framework
improves sample-efficiency of fine-tuning process and gives the soft
prompt-tuning better initialization points. Comprehensive experiments reveal
that our framework excels in accuracy for in-domain data and demonstrates
strong generalization capabilities for unseen and out-of-distribution samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jingbang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1&quot;&gt;Xingwei Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Shuangjia Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1&quot;&gt;Hao Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jie Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.15223">
<title>Evaluating Explanation Methods for Multivariate Time Series Classification. (arXiv:2308.15223v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.15223</link>
<description rdf:parseType="Literal">&lt;p&gt;Multivariate time series classification is an important computational task
arising in applications where data is recorded over time and over multiple
channels. For example, a smartwatch can record the acceleration and orientation
of a person&apos;s motion, and these signals are recorded as multivariate time
series. We can classify this data to understand and predict human movement and
various properties such as fitness levels. In many applications classification
alone is not enough, we often need to classify but also understand what the
model learns (e.g., why was a prediction given, based on what information in
the data). The main focus of this paper is on analysing and evaluating
explanation methods tailored to Multivariate Time Series Classification (MTSC).
We focus on saliency-based explanation methods that can point out the most
relevant channels and time series points for the classification decision. We
analyse two popular and accurate multivariate time series classifiers, ROCKET
and dResNet, as well as two popular explanation methods, SHAP and dCAM. We
study these methods on 3 synthetic datasets and 2 real-world datasets and
provide a quantitative and qualitative analysis of the explanations provided.
We find that flattening the multivariate datasets by concatenating the channels
works as well as using multivariate classifiers directly and adaptations of
SHAP for MTSC work quite well. Additionally, we also find that the popular
synthetic datasets we used are not suitable for time series analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serramazza_D/0/1/0/all/0/1&quot;&gt;Davide Italo Serramazza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thu Trang Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thach Le Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ifrim_G/0/1/0/all/0/1&quot;&gt;Georgiana Ifrim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.16215">
<title>Deep Video Codec Control. (arXiv:2308.16215v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.16215</link>
<description rdf:parseType="Literal">&lt;p&gt;Lossy video compression is commonly used when transmitting and storing video
data. Unified video codecs (e.g., H.264 or H.265) remain the de facto standard,
despite the availability of advanced (neural) compression approaches.
Transmitting videos in the face of dynamic network bandwidth conditions
requires video codecs to adapt to vastly different compression strengths. Rate
control modules augment the codec&apos;s compression such that bandwidth constraints
are satisfied and video distortion is minimized. While, both standard video
codes and their rate control modules are developed to minimize video distortion
w.r.t. human quality assessment, preserving the downstream performance of deep
vision models is not considered. In this paper, we present the first end-to-end
learnable deep video codec control considering both bandwidth constraints and
downstream vision performance, while not breaking existing standardization. We
demonstrate for two common vision tasks (semantic segmentation and optical flow
estimation) and on two different datasets that our deep codec control better
preserves downstream performance than using 2-pass average bit rate control
while meeting dynamic bandwidth constraints and adhering to standardizations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Reich_C/0/1/0/all/0/1&quot;&gt;Christoph Reich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Debnath_B/0/1/0/all/0/1&quot;&gt;Biplob Debnath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Patel_D/0/1/0/all/0/1&quot;&gt;Deep Patel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Prangemeier_T/0/1/0/all/0/1&quot;&gt;Tim Prangemeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chakradhar_S/0/1/0/all/0/1&quot;&gt;Srimat Chakradhar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.16360">
<title>Emoji Promotes Developer Participation and Issue Resolution on GitHub. (arXiv:2308.16360v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/2308.16360</link>
<description rdf:parseType="Literal">&lt;p&gt;Although remote working is increasingly adopted during the pandemic, many are
concerned by the low-efficiency in the remote working. Missing in text-based
communication are non-verbal cues such as facial expressions and body language,
which hinders the effective communication and negatively impacts the work
outcomes. Prevalent on social media platforms, emojis, as alternative
non-verbal cues, are gaining popularity in the virtual workspaces well. In this
paper, we study how emoji usage influences developer participation and issue
resolution in virtual workspaces. To this end, we collect GitHub issues for a
one-year period and apply causal inference techniques to measure the causal
effect of emojis on the outcome of issues, controlling for confounders such as
issue content, repository, and author information. We find that emojis can
significantly reduce the resolution time of issues and attract more user
participation. We also compare the heterogeneous effect on different types of
issues. These findings deepen our understanding of the developer communities,
and they provide design implications on how to facilitate interactions and
broaden developer participation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuhang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1&quot;&gt;Xuan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1&quot;&gt;Ge Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1&quot;&gt;Qiaozhu Mei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ai_W/0/1/0/all/0/1&quot;&gt;Wei Ai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.16898">
<title>Transformers as Support Vector Machines. (arXiv:2308.16898v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.16898</link>
<description rdf:parseType="Literal">&lt;p&gt;Since its inception in &quot;Attention Is All You Need&quot;, transformer architecture
has led to revolutionary advancements in NLP. The attention layer within the
transformer admits a sequence of input tokens $X$ and makes them interact
through pairwise similarities computed as softmax$(XQK^\top X^\top)$, where
$(K,Q)$ are the trainable key-query parameters. In this work, we establish a
formal equivalence between the optimization geometry of self-attention and a
hard-margin SVM problem that separates optimal input tokens from non-optimal
tokens using linear constraints on the outer-products of token pairs. This
formalism allows us to characterize the implicit bias of 1-layer transformers
optimized with gradient descent: (1) Optimizing the attention layer with
vanishing regularization, parameterized by $(K,Q)$, converges in direction to
an SVM solution minimizing the nuclear norm of the combined parameter
$W=KQ^\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm
objective. We characterize this convergence, highlighting that it can occur
toward locally-optimal directions rather than global ones. (2) Complementing
this, we prove the local/global directional convergence of gradient descent
under suitable geometric conditions. Importantly, we show that
over-parameterization catalyzes global convergence by ensuring the feasibility
of the SVM problem and by guaranteeing a benign optimization landscape devoid
of stationary points. (3) While our theory applies primarily to linear
prediction heads, we propose a more general SVM equivalence that predicts the
implicit bias with nonlinear heads. Our findings are applicable to arbitrary
datasets and their validity is verified via experiments. We also introduce
several open problems and research directions. We believe these findings
inspire the interpretation of transformers as a hierarchy of SVMs that
separates and selects optimal tokens.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarzanagh_D/0/1/0/all/0/1&quot;&gt;Davoud Ataee Tarzanagh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingcong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1&quot;&gt;Christos Thrampoulidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.16900">
<title>Learning to Taste: A Multimodal Wine Dataset. (arXiv:2308.16900v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.16900</link>
<description rdf:parseType="Literal">&lt;p&gt;We present WineSensed, a large multimodal wine dataset for studying the
relations between visual perception, language, and flavor. The dataset
encompasses 897k images of wine labels and 824k reviews of wines curated from
the Vivino platform. It has over 350k unique vintages, annotated with year,
region, rating, alcohol percentage, price, and grape composition. We obtained
fine-grained flavor annotations on a subset by conducting a wine-tasting
experiment with 256 participants who were asked to rank wines based on their
similarity in flavor, resulting in more than 5k pairwise flavor distances. We
propose a low-dimensional concept embedding algorithm that combines human
experience with automatic machine similarity kernels. We demonstrate that this
shared concept embedding space improves upon separate embedding spaces for
coarse flavor classification (alcohol percentage, country, grape, price,
rating) and aligns with the intricate human perception of flavor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bender_T/0/1/0/all/0/1&quot;&gt;Thoranna Bender&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sorensen_S/0/1/0/all/0/1&quot;&gt;Simon Moe S&amp;#xf8;rensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kashani_A/0/1/0/all/0/1&quot;&gt;Alireza Kashani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hjorleifsson_K/0/1/0/all/0/1&quot;&gt;K. Eldjarn Hjorleifsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hyldig_G/0/1/0/all/0/1&quot;&gt;Grethe Hyldig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf8;ren Hauberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1&quot;&gt;Serge Belongie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Warburg_F/0/1/0/all/0/1&quot;&gt;Frederik Warburg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.01108">
<title>Acoustic-to-articulatory inversion for dysarthric speech: Are pre-trained self-supervised representations favorable?. (arXiv:2309.01108v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2309.01108</link>
<description rdf:parseType="Literal">&lt;p&gt;$ $Acoustic-to-articulatory inversion (AAI) involves mapping from the
acoustic space to the articulatory space. Signal-processing features like the
MFCCs, have been widely used for the AAI task. For subjects with dysarthric
speech, AAI is challenging because of an imprecise and indistinct
pronunciation. In this work, we perform AAI for dysarthric speech using
representations from pre-trained self-supervised learning (SSL) models. We
demonstrate the impact of different pre-trained features on this challenging
AAI task, at low-resource conditions. In addition, we also condition x-vectors
to the extracted SSL features to train a BLSTM network. In the seen case, we
experiment with three AAI training schemes (subject-specific, pooled, and
fine-tuned). The results, consistent across training schemes, reveal that
DeCoAR, in the fine-tuned scheme, achieves a relative improvement of the
Pearson Correlation Coefficient (CC) by ${\sim}$1.81\% and ${\sim}$4.56\% for
healthy controls and patients, respectively, over MFCCs. In the unseen case, we
observe similar average trends for different SSL features. Overall, SSL
networks like wav2vec, APC, and DeCoAR, which are trained with feature
reconstruction or future timestep prediction tasks, perform well in predicting
dysarthric articulatory trajectories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Maharana_S/0/1/0/all/0/1&quot;&gt;Sarthak Kumar Maharana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Adidam_K/0/1/0/all/0/1&quot;&gt;Krishna Kamal Adidam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nandi_S/0/1/0/all/0/1&quot;&gt;Shoumik Nandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Srivastava_A/0/1/0/all/0/1&quot;&gt;Ajitesh Srivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.02428">
<title>Enhancing Deep Learning Models through Tensorization: A Comprehensive Survey and Framework. (arXiv:2309.02428v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.02428</link>
<description rdf:parseType="Literal">&lt;p&gt;The burgeoning growth of public domain data and the increasing complexity of
deep learning model architectures have underscored the need for more efficient
data representation and analysis techniques. This paper is motivated by the
work of Helal (2023) and aims to present a comprehensive overview of
tensorization. This transformative approach bridges the gap between the
inherently multidimensional nature of data and the simplified 2-dimensional
matrices commonly used in linear algebra-based machine learning algorithms.
This paper explores the steps involved in tensorization, multidimensional data
sources, various multiway analysis methods employed, and the benefits of these
approaches. A small example of Blind Source Separation (BSS) is presented
comparing 2-dimensional algorithms and a multiway algorithm in Python. Results
indicate that multiway analysis is more expressive. Contrary to the intuition
of the dimensionality curse, utilising multidimensional datasets in their
native form and applying multiway analysis methods grounded in multilinear
algebra reveal a profound capacity to capture intricate interrelationships
among various dimensions while, surprisingly, reducing the number of model
parameters and accelerating processing. A survey of the multi-away analysis
methods and integration with various Deep Neural Networks models is presented
using case studies in different domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helal_M/0/1/0/all/0/1&quot;&gt;Manal Helal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.02539">
<title>A Generalized Bandsplit Neural Network for Cinematic Audio Source Separation. (arXiv:2309.02539v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2309.02539</link>
<description rdf:parseType="Literal">&lt;p&gt;Cinematic audio source separation is a relatively new subtask of audio source
separation, with the aim of extracting the dialogue stem, the music stem, and
the effects stem from their mixture. In this work, we developed a model
generalizing the Bandsplit RNN for any complete or overcomplete partitions of
the frequency axis. Psycho-acoustically motivated frequency scales were used to
inform the band definitions which are now defined with redundancy for more
reliable feature extraction. A loss function motivated by the signal-to-noise
ratio and the sparsity-promoting property of the 1-norm was proposed. We
additionally exploit the information-sharing property of a common-encoder setup
to reduce computational complexity during both training and inference, improve
separation performance for hard-to-generalize classes of sounds, and allow
flexibility during inference time with easily detachable decoders. Our best
model sets the state of the art on the Divide and Remaster dataset with
performance above the ideal ratio mask for the dialogue stem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Watcharasupat_K/0/1/0/all/0/1&quot;&gt;Karn N. Watcharasupat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chih-Wei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ding_Y/0/1/0/all/0/1&quot;&gt;Yiwei Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Orife_I/0/1/0/all/0/1&quot;&gt;Iroro Orife&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hipple_A/0/1/0/all/0/1&quot;&gt;Aaron J. Hipple&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Williams_P/0/1/0/all/0/1&quot;&gt;Phillip A. Williams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kramer_S/0/1/0/all/0/1&quot;&gt;Scott Kramer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lerch_A/0/1/0/all/0/1&quot;&gt;Alexander Lerch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wolcott_W/0/1/0/all/0/1&quot;&gt;William Wolcott&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.02556">
<title>Domain Adaptation for Efficiently Fine-tuning Vision Transformer with Encrypted Images. (arXiv:2309.02556v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.02556</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep neural networks (DNNs) trained with transformed data
have been applied to various applications such as privacy-preserving learning,
access control, and adversarial defenses. However, the use of transformed data
decreases the performance of models. Accordingly, in this paper, we propose a
novel method for fine-tuning models with transformed images under the use of
the vision transformer (ViT). The proposed domain adaptation method does not
cause the accuracy degradation of models, and it is carried out on the basis of
the embedding structure of ViT. In experiments, we confirmed that the proposed
method prevents accuracy degradation even when using encrypted images with the
CIFAR-10 and CIFAR-100 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagamori_T/0/1/0/all/0/1&quot;&gt;Teru Nagamori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shiota_S/0/1/0/all/0/1&quot;&gt;Sayaka Shiota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiya_H/0/1/0/all/0/1&quot;&gt;Hitoshi Kiya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.02685">
<title>Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation. (arXiv:2309.02685v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2309.02685</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have verified that equivariant methods can significantly
improve the data efficiency, generalizability, and robustness in robot
learning. Meanwhile, denoising diffusion-based generative modeling has recently
gained significant attention as a promising approach for robotic manipulation
learning from demonstrations with stochastic behaviors. In this paper, we
present Diffusion-EDFs, a novel approach that incorporates spatial
roto-translation equivariance, i.e., SE(3)-equivariance to diffusion generative
modeling. By integrating SE(3)-equivariance into our model architectures, we
demonstrate that our proposed method exhibits remarkable data efficiency,
requiring only 5 to 10 task demonstrations for effective end-to-end training.
Furthermore, our approach showcases superior generalizability compared to
previous diffusion-based manipulation methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_H/0/1/0/all/0/1&quot;&gt;Hyunwoo Ryu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jiwoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1&quot;&gt;Junwoo Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_H/0/1/0/all/0/1&quot;&gt;Hyun Seok Ahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1&quot;&gt;Joohwan Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1&quot;&gt;Taehan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yubin Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jongeun Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horowitz_R/0/1/0/all/0/1&quot;&gt;Roberto Horowitz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.02976">
<title>Natural and Robust Walking using Reinforcement Learning without Demonstrations in High-Dimensional Musculoskeletal Models. (arXiv:2309.02976v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2309.02976</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans excel at robust bipedal walking in complex natural environments. In
each step, they adequately tune the interaction of biomechanical muscle
dynamics and neuronal signals to be robust against uncertainties in ground
conditions. However, it is still not fully understood how the nervous system
resolves the musculoskeletal redundancy to solve the multi-objective control
problem considering stability, robustness, and energy efficiency. In computer
simulations, energy minimization has been shown to be a successful optimization
target, reproducing natural walking with trajectory optimization or
reflex-based control methods. However, these methods focus on particular
motions at a time and the resulting controllers are limited when compensating
for perturbations. In robotics, reinforcement learning~(RL) methods recently
achieved highly stable (and efficient) locomotion on quadruped systems, but the
generation of human-like walking with bipedal biomechanical models has required
extensive use of expert data sets. This strong reliance on demonstrations often
results in brittle policies and limits the application to new behaviors,
especially considering the potential variety of movements for high-dimensional
musculoskeletal models in 3D. Achieving natural locomotion with RL without
sacrificing its incredible robustness might pave the way for a novel approach
to studying human walking in complex natural environments. Videos:
https://sites.google.com/view/naturalwalkingrl
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schumacher_P/0/1/0/all/0/1&quot;&gt;Pierre Schumacher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geijtenbeek_T/0/1/0/all/0/1&quot;&gt;Thomas Geijtenbeek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caggiano_V/0/1/0/all/0/1&quot;&gt;Vittorio Caggiano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vikash Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1&quot;&gt;Syn Schmitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martius_G/0/1/0/all/0/1&quot;&gt;Georg Martius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haeufle_D/0/1/0/all/0/1&quot;&gt;Daniel F. B. Haeufle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03169">
<title>Impression-Informed Multi-Behavior Recommender System: A Hierarchical Graph Attention Approach. (arXiv:2309.03169v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2309.03169</link>
<description rdf:parseType="Literal">&lt;p&gt;While recommender systems have significantly benefited from implicit
feedback, they have often missed the nuances of multi-behavior interactions
between users and items. Historically, these systems either amalgamated all
behaviors, such as \textit{impression} (formerly \textit{view}),
\textit{add-to-cart}, and \textit{buy}, under a singular &apos;interaction&apos; label,
or prioritized only the target behavior, often the \textit{buy} action,
discarding valuable auxiliary signals. Although recent advancements tried
addressing this simplification, they primarily gravitated towards optimizing
the target behavior alone, battling with data scarcity. Additionally, they
tended to bypass the nuanced hierarchy intrinsic to behaviors. To bridge these
gaps, we introduce the \textbf{H}ierarchical \textbf{M}ulti-behavior
\textbf{G}raph Attention \textbf{N}etwork (HMGN). This pioneering framework
leverages attention mechanisms to discern information from both inter and
intra-behaviors while employing a multi-task Hierarchical Bayesian Personalized
Ranking (HBPR) for optimization. Recognizing the need for scalability, our
approach integrates a specialized multi-behavior sub-graph sampling technique.
Moreover, the adaptability of HMGN allows for the seamless inclusion of
knowledge metadata and time-series data. Empirical results attest to our
model&apos;s prowess, registering a notable performance boost of up to 64\% in
NDCG@100 metrics over conventional graph neural network methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Dong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhargavi_D/0/1/0/all/0/1&quot;&gt;Divya Bhargavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravipati_V/0/1/0/all/0/1&quot;&gt;Vidya Sagar Ravipati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03190">
<title>Blink: Link Local Differential Privacy in Graph Neural Networks via Bayesian Estimation. (arXiv:2309.03190v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.03190</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks (GNNs) have gained an increasing amount of popularity
due to their superior capability in learning node embeddings for various graph
inference tasks, but training them can raise privacy concerns. To address this,
we propose using link local differential privacy over decentralized nodes,
enabling collaboration with an untrusted server to train GNNs without revealing
the existence of any link. Our approach spends the privacy budget separately on
links and degrees of the graph for the server to better denoise the graph
topology using Bayesian estimation, alleviating the negative impact of LDP on
the accuracy of the trained GNNs. We bound the mean absolute error of the
inferred link probabilities against the ground truth graph topology. We then
propose two variants of our LDP mechanism complementing each other in different
privacy settings, one of which estimates fewer links under lower privacy
budgets to avoid false positive link estimates when the uncertainty is high,
while the other utilizes more information and performs better given relatively
higher privacy budgets. Furthermore, we propose a hybrid variant that combines
both strategies and is able to perform better across different privacy budgets.
Extensive experiments show that our approach outperforms existing methods in
terms of accuracy under varying privacy budgets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaochen Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1&quot;&gt;Vincent Y. F. Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1&quot;&gt;Xiaokui Xiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.02843">
<title>Knowledge Distillation Layer that Lets the Student Decide. (arXiv:2309.02843v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2309.02843</link>
<description rdf:parseType="Literal">&lt;p&gt;Typical technique in knowledge distillation (KD) is regularizing the learning
of a limited capacity model (student) by pushing its responses to match a
powerful model&apos;s (teacher). Albeit useful especially in the penultimate layer
and beyond, its action on student&apos;s feature transform is rather implicit,
limiting its practice in the intermediate layers. To explicitly embed the
teacher&apos;s knowledge in feature transform, we propose a learnable KD layer for
the student which improves KD with two distinct abilities: i) learning how to
leverage the teacher&apos;s knowledge, enabling to discard nuisance information, and
ii) feeding forward the transferred knowledge deeper. Thus, the student enjoys
the teacher&apos;s knowledge during the inference besides training. Formally, we
repurpose 1x1-BN-ReLU-1x1 convolution block to assign a semantic vector to each
local region according to the template (supervised by the teacher) that the
corresponding region of the student matches. To facilitate template learning in
the intermediate layers, we propose a novel form of supervision based on the
teacher&apos;s decisions. Through rigorous experimentation, we demonstrate the
effectiveness of our approach on 3 popular classification benchmarks. Code is
available at: https://github.com/adagorgun/letKD-framework
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorgun_A/0/1/0/all/0/1&quot;&gt;Ada Gorgun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurbuz_Y/0/1/0/all/0/1&quot;&gt;Yeti Z. Gurbuz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alatan_A/0/1/0/all/0/1&quot;&gt;A. Aydin Alatan&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>