<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-11-15T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08417" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08421" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08422" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08426" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08427" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08428" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08429" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08430" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08433" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08434" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08438" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08439" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08442" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08460" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08479" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08502" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08503" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08504" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08524" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08526" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08530" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08533" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08536" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08539" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08543" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08549" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08557" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08568" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08569" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08572" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08576" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08585" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08594" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08607" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08610" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08615" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08620" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08622" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08623" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08635" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08636" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08640" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08644" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08655" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08657" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08661" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08666" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08669" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08675" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08677" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08687" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08690" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08692" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08695" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08716" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08724" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08744" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08745" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08755" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08788" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08815" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08817" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08819" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08845" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08851" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08870" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08874" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08877" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08902" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08909" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08914" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08935" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08936" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08949" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08972" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08978" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08979" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08990" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09006" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09014" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09017" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09018" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09027" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09058" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09064" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09065" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09068" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09101" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09109" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09114" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09115" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09127" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09128" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09137" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09142" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09145" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09165" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09184" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09188" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09190" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09195" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09197" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2003.04103" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.14201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.05410" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.03427" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.11986" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.03279" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.01251" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.04053" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.06025" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.09858" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.13081" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.02474" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.14407" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.00805" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.02998" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.13034" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.10851" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.14400" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.12322" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.04764" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.10405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.11562" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.12554" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.05763" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.14516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.03292" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.03571" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06295" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06348" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.08703" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.09863" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.11531" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12102" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14463" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.17170" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18497" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19011" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.03530" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.06190" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11281" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11971" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12370" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.16248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.17108" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.17833" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08423" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08433" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.13390" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15053" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.00755" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.10238" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.14119" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.15452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.08534" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12632" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.17370" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00239" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.07250" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.09336" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.11305" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13913" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.14085" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.14421" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.15612" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.15681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.17658" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.18306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00684" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00735" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02762" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.03217" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04037" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04818" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05836" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.06281" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.06928" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.07079" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.07636" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.07772" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08360" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.08379" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.15447" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.01514" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.07786" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2311.08417">
<title>Image complexity based fMRI-BOLD visual network categorization across visual datasets using topological descriptors and deep-hybrid learning. (arXiv:2311.08417v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.08417</link>
<description rdf:parseType="Literal">&lt;p&gt;This study proposes a new approach that investigates differences in
topological characteristics of visual networks, which are constructed using
fMRI BOLD time-series corresponding to visual datasets of COCO, ImageNet, and
SUN. A publicly available BOLD5000 dataset is utilized that contains fMRI scans
while viewing 5254 images of diverse complexities. The objective of this study
is to examine how network topology differs in response to distinct visual
stimuli from these visual datasets. To achieve this, 0- and 1-dimensional
persistence diagrams are computed for each visual network representing COCO,
ImageNet, and SUN. For extracting suitable features from topological
persistence diagrams, K-means clustering is executed. The extracted K-means
cluster features are fed to a novel deep-hybrid model that yields accuracy in
the range of 90%-95% in classifying these visual networks. To understand
vision, this type of visual network categorization across visual datasets is
important as it captures differences in BOLD signals while perceiving images
with different contexts and complexities. Furthermore, distinctive topological
patterns of visual network associated with each dataset, as revealed from this
study, could potentially lead to the development of future neuroimaging
biomarkers for diagnosing visual processing disorders like visual agnosia or
prosopagnosia, and tracking changes in visual cognition over time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bhattacharya_D/0/1/0/all/0/1&quot;&gt;Debanjali Bhattacharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sinha_N/0/1/0/all/0/1&quot;&gt;Neelam Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+R%2E_Y/0/1/0/all/0/1&quot;&gt;Yashwanth R.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chattopadhyay_A/0/1/0/all/0/1&quot;&gt;Amit Chattopadhyay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08421">
<title>Surrogate Neural Networks to Estimate Parametric Sensitivity of Ocean Models. (arXiv:2311.08421v1 [physics.ao-ph])</title>
<link>http://arxiv.org/abs/2311.08421</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling is crucial to understanding the effect of greenhouse gases, warming,
and ice sheet melting on the ocean. At the same time, ocean processes affect
phenomena such as hurricanes and droughts. Parameters in the models that cannot
be physically measured have a significant effect on the model output. For an
idealized ocean model, we generated perturbed parameter ensemble data and
trained surrogate neural network models. The neural surrogates accurately
predicted the one-step forward dynamics, of which we then computed the
parametric sensitivity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yixuan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Cucuzzella_E/0/1/0/all/0/1&quot;&gt;Elizabeth Cucuzzella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Brus_S/0/1/0/all/0/1&quot;&gt;Steven Brus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Narayanan_S/0/1/0/all/0/1&quot;&gt;Sri Hari Krishna Narayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Nadiga_B/0/1/0/all/0/1&quot;&gt;Balu Nadiga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Roekel_L/0/1/0/all/0/1&quot;&gt;Luke Van Roekel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Huckelheim_J/0/1/0/all/0/1&quot;&gt;Jan H&amp;#xfc;ckelheim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Madireddy_S/0/1/0/all/0/1&quot;&gt;Sandeep Madireddy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08422">
<title>k-Parameter Approach for False In-Season Anomaly Suppression in Daily Time Series Anomaly Detection. (arXiv:2311.08422v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08422</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting anomalies in a daily time series with a weekly pattern is a common
task with a wide range of applications. A typical way of performing the task is
by using decomposition method. However, the method often generates false
positive results where a data point falls within its weekly range but is just
off from its weekday position. We refer to this type of anomalies as &quot;in-season
anomalies&quot;, and propose a k-parameter approach to address the issue. The
approach provides configurable extra tolerance for in-season anomalies to
suppress misleading alerts while preserving real positives. It yields favorable
result.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_V/0/1/0/all/0/1&quot;&gt;Vincent Yuansang Zha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kommaraju_V/0/1/0/all/0/1&quot;&gt;Vaishnavi Kommaraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obi_Njoku_O/0/1/0/all/0/1&quot;&gt;Okenna Obi-Njoku&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dakshinamoorthy_V/0/1/0/all/0/1&quot;&gt;Vijay Dakshinamoorthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agnihotri_A/0/1/0/all/0/1&quot;&gt;Anirudh Agnihotri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirsten_N/0/1/0/all/0/1&quot;&gt;Nantes Kirsten&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08426">
<title>Non-Contact Breathing Rate Detection Using Optical Flow. (arXiv:2311.08426v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.08426</link>
<description rdf:parseType="Literal">&lt;p&gt;Breathing rate is a vital health metric that is an invaluable indicator of
the overall health of a person. In recent years, the non-contact measurement of
health signals such as breathing rate has been a huge area of development, with
a wide range of applications from telemedicine to driver monitoring systems.
This paper presents an investigation into a method of non-contact breathing
rate detection using a motion detection algorithm, optical flow. Optical flow
is used to successfully measure breathing rate by tracking the motion of
specific points on the body. In this study, the success of optical flow when
using different sets of points is evaluated. Testing shows that both chest and
facial movement can be used to determine breathing rate but to different
degrees of success. The chest generates very accurate signals, with an RMSE of
0.63 on the tested videos. Facial points can also generate reliable signals
when there is minimal head movement but are much more vulnerable to noise
caused by head/body movements. These findings highlight the potential of
optical flow as a non-invasive method for breathing rate detection and
emphasize the importance of selecting appropriate points to optimize accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Maxwell_R/0/1/0/all/0/1&quot;&gt;Robyn Maxwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hanley_T/0/1/0/all/0/1&quot;&gt;Timothy Hanley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Golden_D/0/1/0/all/0/1&quot;&gt;Dara Golden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Andonie_A/0/1/0/all/0/1&quot;&gt;Adara Andonie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lemley_J/0/1/0/all/0/1&quot;&gt;Joseph Lemley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Parsi_A/0/1/0/all/0/1&quot;&gt;Ashkan Parsi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08427">
<title>Towards a Transportable Causal Network Model Based on Observational Healthcare Data. (arXiv:2311.08427v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08427</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the last decades, many prognostic models based on artificial
intelligence techniques have been used to provide detailed predictions in
healthcare. Unfortunately, the real-world observational data used to train and
validate these models are almost always affected by biases that can strongly
impact the outcomes validity: two examples are values missing not-at-random and
selection bias. Addressing them is a key element in achieving transportability
and in studying the causal relationships that are critical in clinical decision
making, going beyond simpler statistical approaches based on probabilistic
association.
&lt;/p&gt;
&lt;p&gt;In this context, we propose a novel approach that combines selection
diagrams, missingness graphs, causal discovery and prior knowledge into a
single graphical model to estimate the cardiovascular risk of adolescent and
young females who survived breast cancer. We learn this model from data
comprising two different cohorts of patients. The resulting causal network
model is validated by expert clinicians in terms of risk assessment, accuracy
and explainability, and provides a prognostic model that outperforms competing
machine learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernasconi_A/0/1/0/all/0/1&quot;&gt;Alice Bernasconi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zanga_A/0/1/0/all/0/1&quot;&gt;Alessio Zanga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucas_P/0/1/0/all/0/1&quot;&gt;Peter J.F. Lucas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stella_M/0/1/0/all/0/1&quot;&gt;Marco Scutari Fabio Stella&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08428">
<title>Deep Phenotyping of Non-Alcoholic Fatty Liver Disease Patients with Genetic Factors for Insights into the Complex Disease. (arXiv:2311.08428v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/2311.08428</link>
<description rdf:parseType="Literal">&lt;p&gt;Non-alcoholic fatty liver disease (NAFLD) is a prevalent chronic liver
disorder characterized by the excessive accumulation of fat in the liver in
individuals who do not consume significant amounts of alcohol, including risk
factors like obesity, insulin resistance, type 2 diabetes, etc. We aim to
identify subgroups of NAFLD patients based on demographic, clinical, and
genetic characteristics for precision medicine. The genomic and phenotypic data
(3,408 cases and 4,739 controls) for this study were gathered from participants
in Mayo Clinic Tapestry Study (IRB#19-000001) and their electric health
records, including their demographic, clinical, and comorbidity data, and the
genotype information through whole exome sequencing performed at Helix using
the Exome+$^\circledR$ Assay according to standard procedure
(www$.$helix$.$com). Factors highly relevant to NAFLD were determined by the
chi-square test and stepwise backward-forward regression model. Latent class
analysis (LCA) was performed on NAFLD cases using significant indicator
variables to identify subgroups. The optimal clustering revealed 5 latent
subgroups from 2,013 NAFLD patients (mean age 60.6 years and 62.1% women),
while a polygenic risk score based on 6 single-nucleotide polymorphism (SNP)
variants and disease outcomes were used to analyze the subgroups. The groups
are characterized by metabolic syndrome, obesity, different comorbidities,
psychoneurological factors, and genetic factors. Odds ratios were utilized to
compare the risk of complex diseases, such as fibrosis, cirrhosis, and
hepatocellular carcinoma (HCC), as well as liver failure between the clusters.
Cluster 2 has a significantly higher complex disease outcome compared to other
clusters. Keywords: Fatty liver disease; Polygenic risk score; Precision
medicine; Deep phenotyping; NAFLD comorbidities; Latent class analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Priya_T/0/1/0/all/0/1&quot;&gt;Tahmina Sultana Priya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Leng_F/0/1/0/all/0/1&quot;&gt;Fan Leng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Luehrs_A/0/1/0/all/0/1&quot;&gt;Anthony C. Luehrs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Klee_E/0/1/0/all/0/1&quot;&gt;Eric W. Klee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Allen_A/0/1/0/all/0/1&quot;&gt;Alina M. Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lazaridis_K/0/1/0/all/0/1&quot;&gt;Konstantinos N. Lazaridis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Danfeng/0/1/0/all/0/1&quot;&gt;Danfeng&lt;/a&gt; (Daphne)Yao, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tian_S/0/1/0/all/0/1&quot;&gt;Shulan Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08429">
<title>Purpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?. (arXiv:2311.08429v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08429</link>
<description rdf:parseType="Literal">&lt;p&gt;Traffic simulators are used to generate data for learning in intelligent
transportation systems (ITSs). A key question is to what extent their modelling
assumptions affect the capabilities of ITSs to adapt to various scenarios when
deployed in the real world. This work focuses on two simulators commonly used
to train reinforcement learning (RL) agents for traffic applications, CityFlow
and SUMO. A controlled virtual experiment varying driver behavior and
simulation scale finds evidence against distributional equivalence in
RL-relevant measures from these simulators, with the root mean squared error
and KL divergence being significantly greater than 0 for all assessed measures.
While granular real-world validation generally remains infeasible, these
findings suggest that traffic simulators are not a deus ex machina for RL
training: understanding the impacts of inter-simulator differences is necessary
to train and deploy RL-based ITSs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Rex Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carley_K/0/1/0/all/0/1&quot;&gt;Kathleen M. Carley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1&quot;&gt;Fei Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadeh_N/0/1/0/all/0/1&quot;&gt;Norman Sadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08430">
<title>Rankitect: Ranking Architecture Search Battling World-class Engineers at Meta Scale. (arXiv:2311.08430v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08430</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Architecture Search (NAS) has demonstrated its efficacy in computer
vision and potential for ranking systems. However, prior work focused on
academic problems, which are evaluated at small scale under well-controlled
fixed baselines. In industry system, such as ranking system in Meta, it is
unclear whether NAS algorithms from the literature can outperform production
baselines because of: (1) scale - Meta ranking systems serve billions of users,
(2) strong baselines - the baselines are production models optimized by
hundreds to thousands of world-class engineers for years since the rise of deep
learning, (3) dynamic baselines - engineers may have established new and
stronger baselines during NAS search, and (4) efficiency - the search pipeline
must yield results quickly in alignment with the productionization life cycle.
In this paper, we present Rankitect, a NAS software framework for ranking
systems at Meta. Rankitect seeks to build brand new architectures by composing
low level building blocks from scratch. Rankitect implements and improves
state-of-the-art (SOTA) NAS methods for comprehensive and fair comparison under
the same search space, including sampling-based NAS, one-shot NAS, and
Differentiable NAS (DNAS). We evaluate Rankitect by comparing to multiple
production ranking models at Meta. We find that Rankitect can discover new
models from scratch achieving competitive tradeoff between Normalized Entropy
loss and FLOPs. When utilizing search space designed by engineers, Rankitect
can generate better models than engineers, achieving positive offline
evaluation and online A/B test at Meta scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Wei Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Kuang-Hung Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fedorov_I/0/1/0/all/0/1&quot;&gt;Igor Fedorov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Hang Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_W/0/1/0/all/0/1&quot;&gt;Weiwei Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassani_K/0/1/0/all/0/1&quot;&gt;Kaveh Hassani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Mengying Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1&quot;&gt;Lin Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Buyun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1&quot;&gt;Dehua Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhengxing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1&quot;&gt;Guang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1&quot;&gt;Fangqiu Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jiyan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1&quot;&gt;Yuchen Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1&quot;&gt;Liang Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wen-Yen Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08433">
<title>Clinical Characteristics and Laboratory Biomarkers in ICU-admitted Septic Patients with and without Bacteremia. (arXiv:2311.08433v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/2311.08433</link>
<description rdf:parseType="Literal">&lt;p&gt;Few studies have investigated the diagnostic utilities of biomarkers for
predicting bacteremia among septic patients admitted to intensive care units
(ICU). Therefore, this study evaluated the prediction power of laboratory
biomarkers to utilize those markers with high performance to optimize the
predictive model for bacteremia. This retrospective cross-sectional study was
conducted at the ICU department of Gyeongsang National University Changwon
Hospital in 2019. Adult patients qualifying SEPSIS-3 (increase in sequential
organ failure score greater than or equal to 2) criteria with at least two sets
of blood culture were selected. Collected data was initially analyzed
independently to identify the significant predictors, which was then used to
build the multivariable logistic regression (MLR) model. A total of 218
patients with 48 cases of true bacteremia were analyzed in this research. Both
CRP and PCT showed a substantial area under the curve (AUC) value for
discriminating bacteremia among septic patients (0.757 and 0.845,
respectively). To further enhance the predictive accuracy, we combined PCT,
bilirubin, neutrophil lymphocyte ratio (NLR), platelets, lactic acid,
erythrocyte sedimentation rate (ESR), and Glasgow Coma Scale (GCS) score to
build the predictive model with an AUC of 0.907 (95% CI, 0.843 to 0.956). In
addition, a high association between bacteremia and mortality rate was
discovered through the survival analysis (0.004). While PCT is certainly a
useful index for distinguishing patients with and without bacteremia by itself,
our MLR model indicates that the accuracy of bacteremia prediction
substantially improves by the combined use of PCT, bilirubin, NLR, platelets,
lactic acid, ESR, and GCS score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Baek_S/0/1/0/all/0/1&quot;&gt;Sangwon Baek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seung Jun Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08434">
<title>Uplift Modeling based on Graph Neural Network Combined with Causal Knowledge. (arXiv:2311.08434v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08434</link>
<description rdf:parseType="Literal">&lt;p&gt;Uplift modeling is a fundamental component of marketing effect modeling,
which is commonly employed to evaluate the effects of treatments on outcomes.
Through uplift modeling, we can identify the treatment with the greatest
benefit. On the other side, we can identify clients who are likely to make
favorable decisions in response to a certain treatment. In the past, uplift
modeling approaches relied heavily on the difference-in-difference (DID)
architecture, paired with a machine learning model as the estimation learner,
while neglecting the link and confidential information between features. We
proposed a framework based on graph neural networks that combine causal
knowledge with an estimate of uplift value. Firstly, we presented a causal
representation technique based on CATE (conditional average treatment effect)
estimation and adjacency matrix structure learning. Secondly, we suggested a
more scalable uplift modeling framework based on graph convolution networks for
combining causal knowledge. Our findings demonstrate that this method works
effectively for predicting uplift values, with small errors in typical
simulated data, and its effectiveness has been verified in actual industry
marketing data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haowen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1&quot;&gt;Xinyan Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yangze Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Longhan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jing Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08438">
<title>LocaliseBot: Multi-view 3D object localisation with differentiable rendering for robot grasping. (arXiv:2311.08438v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08438</link>
<description rdf:parseType="Literal">&lt;p&gt;Robot grasp typically follows five stages: object detection, object
localisation, object pose estimation, grasp pose estimation, and grasp
planning. We focus on object pose estimation. Our approach relies on three
pieces of information: multiple views of the object, the camera&apos;s extrinsic
parameters at those viewpoints, and 3D CAD models of objects. The first step
involves a standard deep learning backbone (FCN ResNet) to estimate the object
label, semantic segmentation, and a coarse estimate of the object pose with
respect to the camera. Our novelty is using a refinement module that starts
from the coarse pose estimate and refines it by optimisation through
differentiable rendering. This is a purely vision-based approach that avoids
the need for other information such as point cloud or depth images. We evaluate
our object pose estimation approach on the ShapeNet dataset and show
improvements over the state of the art. We also show that the estimated object
pose results in 99.65% grasp accuracy with the ground truth grasp candidates on
the Object Clutter Indoor Dataset (OCID) Grasp dataset, as computed using
standard practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijayaraghavan_S/0/1/0/all/0/1&quot;&gt;Sujal Vijayaraghavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alqasemi_R/0/1/0/all/0/1&quot;&gt;Redwan Alqasemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_R/0/1/0/all/0/1&quot;&gt;Rajiv Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1&quot;&gt;Sudeep Sarkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08439">
<title>A Unified Approach for Comprehensive Analysis of Various Spectral and Tissue Doppler Echocardiography. (arXiv:2311.08439v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.08439</link>
<description rdf:parseType="Literal">&lt;p&gt;Doppler echocardiography offers critical insights into cardiac function and
phases by quantifying blood flow velocities and evaluating myocardial motion.
However, previous methods for automating Doppler analysis, ranging from initial
signal processing techniques to advanced deep learning approaches, have been
constrained by their reliance on electrocardiogram (ECG) data and their
inability to process Doppler views collectively. We introduce a novel unified
framework using a convolutional neural network for comprehensive analysis of
spectral and tissue Doppler echocardiography images that combines automatic
measurements and end-diastole (ED) detection into a singular method. The
network automatically recognizes key features across various Doppler views,
with novel Doppler shape embedding and anti-aliasing modules enhancing
interpretation and ensuring consistent analysis. Empirical results indicate a
consistent outperformance in performance metrics, including dice similarity
coefficients (DSC) and intersection over union (IoU). The proposed framework
demonstrates strong agreement with clinicians in Doppler automatic measurements
and competitive performance in ED detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jeon_J/0/1/0/all/0/1&quot;&gt;Jaeik Jeon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jiyeon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jang_Y/0/1/0/all/0/1&quot;&gt;Yeonggul Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yoon_Y/0/1/0/all/0/1&quot;&gt;Yeonyee E. Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jeong_D/0/1/0/all/0/1&quot;&gt;Dawun Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Youngtaek Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seung-Ah Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chang_H/0/1/0/all/0/1&quot;&gt;Hyuk-Jae Chang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08442">
<title>Mean-field variational inference with the TAP free energy: Geometric and statistical properties in linear models. (arXiv:2311.08442v1 [math.ST])</title>
<link>http://arxiv.org/abs/2311.08442</link>
<description rdf:parseType="Literal">&lt;p&gt;We study mean-field variational inference in a Bayesian linear model when the
sample size n is comparable to the dimension p. In high dimensions, the common
approach of minimizing a Kullback-Leibler divergence from the posterior
distribution, or maximizing an evidence lower bound, may deviate from the true
posterior mean and underestimate posterior uncertainty. We study instead
minimization of the TAP free energy, showing in a high-dimensional asymptotic
framework that it has a local minimizer which provides a consistent estimate of
the posterior marginals and may be used for correctly calibrated posterior
inference. Geometrically, we show that the landscape of the TAP free energy is
strongly convex in an extensive neighborhood of this local minimizer, which
under certain general conditions can be found by an Approximate Message Passing
(AMP) algorithm. We then exhibit an efficient algorithm that linearly converges
to the minimizer within this local neighborhood. In settings where it is
conjectured that no efficient algorithm can find this local neighborhood, we
prove analogous geometric properties for a local minimizer of the TAP free
energy reachable by AMP, and show that posterior inference based on this
minimizer remains correctly calibrated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Celentano_M/0/1/0/all/0/1&quot;&gt;Michael Celentano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Fan_Z/0/1/0/all/0/1&quot;&gt;Zhou Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Licong Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mei_S/0/1/0/all/0/1&quot;&gt;Song Mei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08460">
<title>Surrogate Modeling for Computationally Expensive Simulations of Supernovae in High-Resolution Galaxy Simulations. (arXiv:2311.08460v1 [astro-ph.GA])</title>
<link>http://arxiv.org/abs/2311.08460</link>
<description rdf:parseType="Literal">&lt;p&gt;Some stars are known to explode at the end of their lives, called supernovae
(SNe). The substantial amount of matter and energy that SNe release provides
significant feedback to star formation and gas dynamics in a galaxy. SNe
release a substantial amount of matter and energy to the interstellar medium,
resulting in significant feedback to star formation and gas dynamics in a
galaxy. While such feedback has a crucial role in galaxy formation and
evolution, in simulations of galaxy formation, it has only been implemented
using simple {\it sub-grid models} instead of numerically solving the evolution
of gas elements around SNe in detail due to a lack of resolution. We develop a
method combining machine learning and Gibbs sampling to predict how a supernova
(SN) affects the surrounding gas. The fidelity of our model in the thermal
energy and momentum distribution outperforms the low-resolution SN simulations.
Our method can replace the SN sub-grid models and help properly simulate
un-resolved SN feedback in galaxy formation simulations. We find that employing
our new approach reduces the necessary computational cost to $\sim$ 1 percent
compared to directly resolving SN feedback.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Hirashima_K/0/1/0/all/0/1&quot;&gt;Keiya Hirashima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Moriwaki_K/0/1/0/all/0/1&quot;&gt;Kana Moriwaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Fujii_M/0/1/0/all/0/1&quot;&gt;Michiko S. Fujii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Hirai_Y/0/1/0/all/0/1&quot;&gt;Yutaka Hirai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Saitoh_T/0/1/0/all/0/1&quot;&gt;Takayuki R. Saitoh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Makino_J/0/1/0/all/0/1&quot;&gt;Junichiro Makino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1&quot;&gt;Shirley Ho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08479">
<title>Leveraging Foundation Models to Improve Lightweight Clients in Federated Learning. (arXiv:2311.08479v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08479</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) is a distributed training paradigm that enables
clients scattered across the world to cooperatively learn a global model
without divulging confidential data. However, FL faces a significant challenge
in the form of heterogeneous data distributions among clients, which leads to a
reduction in performance and robustness. A recent approach to mitigating the
impact of heterogeneous data distributions is through the use of foundation
models, which offer better performance at the cost of larger computational
overheads and slower inference speeds. We introduce foundation model
distillation to assist in the federated training of lightweight client models
and increase their performance under heterogeneous data settings while keeping
inference costs low. Our results show improvement in the global model
performance on a balanced testing set, which contains rarely observed samples,
even under extreme non-IID client data distributions. We conduct a thorough
evaluation of our framework with different foundation model backbones on
CIFAR10, with varying degrees of heterogeneous data distributions ranging from
class-specific data partitions across clients to dirichlet data sampling,
parameterized by values between 0.01 and 1.0.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xidong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1&quot;&gt;Wan-Yi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Willmott_D/0/1/0/all/0/1&quot;&gt;Devin Willmott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Condessa_F/0/1/0/all/0/1&quot;&gt;Filipe Condessa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yufei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenzhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganesh_M/0/1/0/all/0/1&quot;&gt;Madan Ravi Ganesh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08502">
<title>Variational Quantum Eigensolver with Constraints (VQEC): Solving Constrained Optimization Problems via VQE. (arXiv:2311.08502v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2311.08502</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational quantum approaches have shown great promise in finding
near-optimal solutions to computationally challenging tasks. Nonetheless,
enforcing constraints in a disciplined fashion has been largely unexplored. To
address this gap, this work proposes a hybrid quantum-classical algorithmic
paradigm termed VQEC that extends the celebrated VQE to handle optimization
with constraints. As with the standard VQE, the vector of optimization
variables is captured by the state of a variational quantum circuit (VQC). To
deal with constraints, VQEC optimizes a Lagrangian function classically over
both the VQC parameters as well as the dual variables associated with
constraints. To comply with the quantum setup, variables are updated via a
perturbed primal-dual method leveraging the parameter shift rule. Among a wide
gamut of potential applications, we showcase how VQEC can approximately solve
quadratically-constrained binary optimization (QCBO) problems, find stochastic
binary policies satisfying quadratic constraints on the average and in
probability, and solve large-scale linear programs (LP) over the probability
simplex. Under an assumption on the error for the VQC to approximate an
arbitrary probability mass function (PMF), we provide bounds on the optimality
gap attained by a VQC. Numerical tests on a quantum simulator investigate the
effect of various parameters and corroborate that VQEC can generate
high-quality solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Thinh Viet Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kekatos_V/0/1/0/all/0/1&quot;&gt;Vassilis Kekatos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08503">
<title>MADG: Margin-based Adversarial Learning for Domain Generalization. (arXiv:2311.08503v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08503</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain Generalization (DG) techniques have emerged as a popular approach to
address the challenges of domain shift in Deep Learning (DL), with the goal of
generalizing well to the target domain unseen during the training. In recent
years, numerous methods have been proposed to address the DG setting, among
which one popular approach is the adversarial learning-based methodology. The
main idea behind adversarial DG methods is to learn domain-invariant features
by minimizing a discrepancy metric. However, most adversarial DG methods use
0-1 loss based $\mathcal{H}\Delta\mathcal{H}$ divergence metric. In contrast,
the margin loss-based discrepancy metric has the following advantages: more
informative, tighter, practical, and efficiently optimizable. To mitigate this
gap, this work proposes a novel adversarial learning DG algorithm, MADG,
motivated by a margin loss-based discrepancy metric. The proposed MADG model
learns domain-invariant features across all source domains and uses adversarial
training to generalize well to the unseen target domain. We also provide a
theoretical analysis of the proposed MADG model based on the unseen target
error bound. Specifically, we construct the link between the source and unseen
domains in the real-valued hypothesis space and derive the generalization bound
using margin loss and Rademacher complexity. We extensively experiment with the
MADG model on popular real-world DG datasets, VLCS, PACS, OfficeHome,
DomainNet, and TerraIncognita. We evaluate the proposed algorithm on
DomainBed&apos;s benchmark and observe consistent performance across all the
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dayal_A/0/1/0/all/0/1&quot;&gt;Aveen Dayal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+B%2E_V/0/1/0/all/0/1&quot;&gt;Vimal K. B.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cenkeramaddi_L/0/1/0/all/0/1&quot;&gt;Linga Reddy Cenkeramaddi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohan_C/0/1/0/all/0/1&quot;&gt;C. Krishna Mohan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Abhinav Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1&quot;&gt;Vineeth N Balasubramanian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08504">
<title>On semi-supervised estimation using exponential tilt mixture models. (arXiv:2311.08504v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.08504</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider a semi-supervised setting with a labeled dataset of binary responses
and predictors and an unlabeled dataset with only the predictors. Logistic
regression is equivalent to an exponential tilt model in the labeled
population. For semi-supervised estimation, we develop further analysis and
understanding of a statistical approach using exponential tilt mixture (ETM)
models and maximum nonparametric likelihood estimation, while allowing that the
class proportions may differ between the unlabeled and labeled data. We derive
asymptotic properties of ETM-based estimation and demonstrate improved
efficiency over supervised logistic regression in a random sampling setup and
an outcome-stratified sampling setup previously used. Moreover, we reconcile
such efficiency improvement with the existing semiparametric efficiency theory
when the class proportions in the unlabeled and labeled data are restricted to
be the same. We also provide a simulation study to numerically illustrate our
theoretical findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Ye Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tan_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Tan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08516">
<title>LLMs cannot find reasoning errors, but can correct them!. (arXiv:2311.08516v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2311.08516</link>
<description rdf:parseType="Literal">&lt;p&gt;While self-correction has shown promise in improving LLM outputs in terms of
style and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent
attempts to self-correct logical or reasoning errors often cause correct
answers to become incorrect, resulting in worse performances overall (Huang et
al., 2023). In this paper, we break down the self-correction process into two
core components: mistake finding and output correction. For mistake finding, we
release BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought
reasoning traces. We provide benchmark numbers for several state-of-the-art
LLMs, and demonstrate that LLMs generally struggle with finding logical
mistakes. For output correction, we propose a backtracking method which
provides large improvements when given information on mistake location. We
construe backtracking as a lightweight alternative to reinforcement learning
methods, and show that it remains effective with a reward model at 60-70%
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tyen_G/0/1/0/all/0/1&quot;&gt;Gladys Tyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mansoor_H/0/1/0/all/0/1&quot;&gt;Hassan Mansoor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Peter Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mak_T/0/1/0/all/0/1&quot;&gt;Tony Mak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carbune_V/0/1/0/all/0/1&quot;&gt;Victor C&amp;#x103;rbune&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08524">
<title>Cross-dataset domain adaptation for the classification COVID-19 using chest computed tomography images. (arXiv:2311.08524v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.08524</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting COVID-19 patients using Computed Tomography (CT) images of the
lungs is an active area of research. Datasets of CT images from COVID-19
patients are becoming available. Deep learning (DL) solutions and in particular
Convolutional Neural Networks (CNN) have achieved impressive results for the
classification of COVID-19 CT images, but only when the training and testing
take place within the same dataset. Work on the cross-dataset problem is still
limited and the achieved results are low. Our work tackles the cross-dataset
problem through a Domain Adaptation (DA) technique with deep learning. Our
proposed solution, COVID19-DANet, is based on pre-trained CNN backbone for
feature extraction. For this task, we select the pre-trained Efficientnet-B3
CNN because it has achieved impressive classification accuracy in previous
work. The backbone CNN is followed by a prototypical layer which is a concept
borrowed from prototypical networks in few-shot learning (FSL). It computes a
cosine distance between given samples and the class prototypes and then
converts them to class probabilities using the Softmax function. To train the
COVID19-DANet model, we propose a combined loss function that is composed of
the standard cross-entropy loss for class discrimination and another entropy
loss computed over the unlabelled target set only. This so-called unlabelled
target entropy loss is minimized and maximized in an alternative fashion, to
reach the two objectives of class discrimination and domain invariance.
COVID19-DANet is tested under four cross-dataset scenarios using the
SARS-CoV-2-CT and COVID19-CT datasets and has achieved encouraging results
compared to recent work in the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ouni_R/0/1/0/all/0/1&quot;&gt;Ridha Ouni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Alhichri_H/0/1/0/all/0/1&quot;&gt;Haikel Alhichri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08526">
<title>GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer. (arXiv:2311.08526v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08526</link>
<description rdf:parseType="Literal">&lt;p&gt;Named Entity Recognition (NER) is essential in various Natural Language
Processing (NLP) applications. Traditional NER models are effective but limited
to a set of predefined entity types. In contrast, Large Language Models (LLMs)
can extract arbitrary entities through natural language instructions, offering
greater flexibility. However, their size and cost, particularly for those
accessed via APIs like ChatGPT, make them impractical in resource-limited
scenarios. In this paper, we introduce a compact NER model trained to identify
any type of entity. Leveraging a bidirectional transformer encoder, our model,
GLiNER, facilitates parallel entity extraction, an advantage over the slow
sequential token generation of LLMs. Through comprehensive testing, GLiNER
demonstrate strong performance, outperforming both ChatGPT and fine-tuned LLMs
in zero-shot evaluations on various NER benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaratiana_U/0/1/0/all/0/1&quot;&gt;Urchade Zaratiana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomeh_N/0/1/0/all/0/1&quot;&gt;Nadi Tomeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holat_P/0/1/0/all/0/1&quot;&gt;Pierre Holat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charnois_T/0/1/0/all/0/1&quot;&gt;Thierry Charnois&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08530">
<title>SceneScore: Learning a Cost Function for Object Arrangement. (arXiv:2311.08530v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.08530</link>
<description rdf:parseType="Literal">&lt;p&gt;Arranging objects correctly is a key capability for robots which unlocks a
wide range of useful tasks. A prerequisite for creating successful arrangements
is the ability to evaluate the desirability of a given arrangement. Our method
&quot;SceneScore&quot; learns a cost function for arrangements, such that desirable,
human-like arrangements have a low cost. We learn the distribution of training
arrangements offline using an energy-based model, solely from example images
without requiring environment interaction or human supervision. Our model is
represented by a graph neural network which learns object-object relations,
using graphs constructed from images. Experiments demonstrate that the learned
cost function can be used to predict poses for missing objects, generalise to
novel objects using semantic features, and can be composed with other cost
functions to satisfy constraints at inference time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapelyukh_I/0/1/0/all/0/1&quot;&gt;Ivan Kapelyukh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1&quot;&gt;Edward Johns&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08533">
<title>Natural Language Processing for Financial Regulation. (arXiv:2311.08533v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08533</link>
<description rdf:parseType="Literal">&lt;p&gt;This article provides an understanding of Natural Language Processing
techniques in the framework of financial regulation, more specifically in order
to perform semantic matching search between rules and policy when no dataset is
available for supervised learning. We outline how to outperform simple
pre-trained sentences-transformer models using freely available resources and
explain the mathematical concepts behind the key building blocks of Natural
Language Processing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achitouv_I/0/1/0/all/0/1&quot;&gt;Ixandra Achitouv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorduza_D/0/1/0/all/0/1&quot;&gt;Dragos Gorduza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacquier_A/0/1/0/all/0/1&quot;&gt;Antoine Jacquier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08536">
<title>Low-Frequency Load Identification using CNN-BiLSTM Attention Mechanism. (arXiv:2311.08536v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2311.08536</link>
<description rdf:parseType="Literal">&lt;p&gt;Non-intrusive Load Monitoring (NILM) is an established technique for
effective and cost-efficient electricity consumption management. The method is
used to estimate appliance-level power consumption from aggregated power
measurements. This paper presents a hybrid learning approach, consisting of a
convolutional neural network (CNN) and a bidirectional long short-term memory
(BILSTM), featuring an integrated attention mechanism, all within the context
of disaggregating low-frequency power data. While prior research has been
mainly focused on high-frequency data disaggregation, our study takes a
distinct direction by concentrating on low-frequency data. The proposed hybrid
CNN-BILSTM model is adept at extracting both temporal (time-related) and
spatial (location-related) features, allowing it to precisely identify energy
consumption patterns at the appliance level. This accuracy is further enhanced
by the attention mechanism, which aids the model in pinpointing crucial parts
of the data for more precise event detection and load disaggregation. We
conduct simulations using the existing low-frequency REDD dataset to assess our
model performance. The results demonstrate that our proposed approach
outperforms existing methods in terms of accuracy and computation time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Azzam_A/0/1/0/all/0/1&quot;&gt;Amanie Azzam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sanami_S/0/1/0/all/0/1&quot;&gt;Saba Sanami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Aghdam_A/0/1/0/all/0/1&quot;&gt;Amir G. Aghdam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08539">
<title>Physical Adversarial Examples for Multi-Camera Systems. (arXiv:2311.08539v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08539</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks build the foundation of several intelligent systems, which,
however, are known to be easily fooled by adversarial examples. Recent advances
made these attacks possible even in air-gapped scenarios, where the autonomous
system observes its surroundings by, e.g., a camera. We extend these ideas in
our research and evaluate the robustness of multi-camera setups against such
physical adversarial examples. This scenario becomes ever more important with
the rise in popularity of autonomous vehicles, which fuse the information of
several cameras for their driving decision. While we find that multi-camera
setups provide some robustness towards past attack methods, we see that this
advantage reduces when optimizing on multiple perspectives at once. We propose
a novel attack method that we call Transcender-MC, where we incorporate online
3D renderings and perspective projections in the training process. Moreover, we
motivate that certain data augmentation techniques can facilitate the
generation of successful adversarial examples even further. Transcender-MC is
11% more effective in successfully attacking multi-camera setups than
state-of-the-art methods. Our findings offer valuable insights regarding the
resilience of object detection in a setup with multiple cameras and motivate
the need of developing adequate defense mechanisms against them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radutoiu_A/0/1/0/all/0/1&quot;&gt;Ana R&amp;#x103;du&amp;#x163;oiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulze_J/0/1/0/all/0/1&quot;&gt;Jan-Philipp Schulze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sperl_P/0/1/0/all/0/1&quot;&gt;Philip Sperl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bottinger_K/0/1/0/all/0/1&quot;&gt;Konstantin B&amp;#xf6;ttinger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08543">
<title>2D-RC: Two-Dimensional Neural Network Approach for OTFS Symbol Detection. (arXiv:2311.08543v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2311.08543</link>
<description rdf:parseType="Literal">&lt;p&gt;Orthogonal time frequency space (OTFS) is a promising modulation scheme for
wireless communication in high-mobility scenarios. Recently, a reservoir
computing (RC) based approach has been introduced for online subframe-based
symbol detection in the OTFS system, where only a limited number of
over-the-air (OTA) pilot symbols are utilized for training. However, this
approach does not leverage the domain knowledge specific to the OTFS system.
This paper introduces a novel two-dimensional RC (2D-RC) method that
incorporates the structural knowledge of the OTFS system into the design for
online symbol detection on a subframe basis. Specifically, as the channel
response acts as a two-dimensional (2D) operation over the transmitted
information symbols in the delay-Doppler (DD) domain, the 2D-RC is designed to
have a 2D structure to equalize the channel. With the introduced architecture,
the 2D-RC can benefit from the predictable channel representation in the DD
domain. Moreover, unlike the previous work that requires multiple RCs to learn
the channel feature, the 2D-RC only requires a single neural network for
detection. Experimental results demonstrate the effectiveness of the 2D-RC
approach across different OTFS system variants and modulation orders.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiarui Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Said_K/0/1/0/all/0/1&quot;&gt;Karim Said&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Lizhong Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lingjia Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08549">
<title>Manifold learning in Wasserstein space. (arXiv:2311.08549v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.08549</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper aims at building the theoretical foundations for manifold learning
algorithms in the space of absolutely continuous probability measures on a
compact and convex subset of $\mathbb{R}^d$, metrized with the Wasserstein-2
distance $W$. We begin by introducing a natural construction of submanifolds
$\Lambda$ of probability measures equipped with metric $W_\Lambda$, the
geodesic restriction of $W$ to $\Lambda$. In contrast to other constructions,
these submanifolds are not necessarily flat, but still allow for local
linearizations in a similar fashion to Riemannian submanifolds of
$\mathbb{R}^d$. We then show how the latent manifold structure of
$(\Lambda,W_{\Lambda})$ can be learned from samples $\{\lambda_i\}_{i=1}^N$ of
$\Lambda$ and pairwise extrinsic Wasserstein distances $W$ only. In particular,
we show that the metric space $(\Lambda,W_{\Lambda})$ can be asymptotically
recovered in the sense of Gromov--Wasserstein from a graph with nodes
$\{\lambda_i\}_{i=1}^N$ and edge weights $W(\lambda_i,\lambda_j)$. In addition,
we demonstrate how the tangent space at a sample $\lambda$ can be
asymptotically recovered via spectral analysis of a suitable &quot;covariance
operator&quot; using optimal transport maps from $\lambda$ to sufficiently close and
diverse samples $\{\lambda_i\}_{i=1}^N$. The paper closes with some explicit
constructions of submanifolds $\Lambda$ and numerical examples on the recovery
of tangent spaces through spectral analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hamm_K/0/1/0/all/0/1&quot;&gt;Keaton Hamm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moosmuller_C/0/1/0/all/0/1&quot;&gt;Caroline Moosm&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schmitzer_B/0/1/0/all/0/1&quot;&gt;Bernhard Schmitzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thorpe_M/0/1/0/all/0/1&quot;&gt;Matthew Thorpe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08557">
<title>Low-light Pedestrian Detection in Visible and Infrared Image Feeds: Issues and Challenges. (arXiv:2311.08557v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08557</link>
<description rdf:parseType="Literal">&lt;p&gt;Pedestrian detection has become a cornerstone for several high-level tasks,
including autonomous driving, intelligent transportation, and traffic
surveillance. There are several works focussed on pedestrian detection using
visible images, mainly in the daytime. However, this task is very intriguing
when the environmental conditions change to poor lighting or nighttime.
Recently, new ideas have been spurred to use alternative sources, such as Far
InfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light
conditions. This study comprehensively reviews recent developments in low-light
pedestrian detection approaches. It systematically categorizes and analyses
various algorithms from region-based to non-region-based and graph-based
learning methodologies by highlighting their methodologies, implementation
issues, and challenges. It also outlines the key benchmark datasets that can be
used for research and development of advanced pedestrian detection algorithms,
particularly in low-light situations
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vachhani_H/0/1/0/all/0/1&quot;&gt;Hrishikesh Vachhani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akilan_T/0/1/0/all/0/1&quot;&gt;Thangarajah Akilan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devmurari_Y/0/1/0/all/0/1&quot;&gt;Yash Devmurari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaik_N/0/1/0/all/0/1&quot;&gt;Nisharaff Shaik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1&quot;&gt;Dhruvisha Patel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08568">
<title>Adversarial Imitation Learning On Aggregated Data. (arXiv:2311.08568v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08568</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse Reinforcement Learning (IRL) learns an optimal policy, given some
expert demonstrations, thus avoiding the need for the tedious process of
specifying a suitable reward function. However, current methods are constrained
by at least one of the following requirements. The first one is the need to
fully solve a forward Reinforcement Learning (RL) problem in the inner loop of
the algorithm, which might be prohibitively expensive in many complex
environments. The second one is the need for full trajectories from the
experts, which might not be easily available. The third one is the assumption
that the expert data is homogeneous rather than a collection from various
experts or possibly alternative solutions to the same task. Such constraints
make IRL approaches either not scalable or not usable on certain existing
systems. In this work we propose an approach which removes these requirements
through a dynamic, adaptive method called Adversarial Imitation Learning on
Aggregated Data (AILAD). It learns conjointly both a non linear reward function
and the associated optimal policy using an adversarial framework. The reward
learner only uses aggregated data. Moreover, it generates diverse behaviors
producing a distribution over the aggregated data matching that of the experts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woillemont_P/0/1/0/all/0/1&quot;&gt;Pierre Le Pelletier de Woillemont&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labory_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Labory&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corruble_V/0/1/0/all/0/1&quot;&gt;Vincent Corruble&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08569">
<title>Uncertainty Quantification in Neural-Network Based Pain Intensity Estimation. (arXiv:2311.08569v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08569</link>
<description rdf:parseType="Literal">&lt;p&gt;Improper pain management can lead to severe physical or mental consequences,
including suffering, and an increased risk of opioid dependency. Assessing the
presence and severity of pain is imperative to prevent such outcomes and
determine the appropriate intervention. However, the evaluation of pain
intensity is challenging because different individuals experience pain
differently. To overcome this, researchers have employed machine learning
models to evaluate pain intensity objectively. However, these efforts have
primarily focused on point estimation of pain, disregarding the inherent
uncertainty and variability present in the data and model. Consequently, the
point estimates provide only partial information for clinical decision-making.
This study presents a neural network-based method for objective pain interval
estimation, incorporating uncertainty quantification. This work explores three
algorithms: the bootstrap method, lower and upper bound estimation (LossL)
optimized by genetic algorithm, and modified lower and upper bound estimation
(LossS) optimized by gradient descent algorithm. Our empirical results reveal
that LossS outperforms the other two by providing a narrower prediction
interval. As LossS outperforms, we assessed its performance in three different
scenarios for pain assessment: (1) a generalized approach (single model for the
entire population), (2) a personalized approach (separate model for each
individual), and (3) a hybrid approach (separate model for each cluster of
individuals). Our findings demonstrate the hybrid approach&apos;s superior
performance, with notable practicality in clinical contexts. It has the
potential to be a valuable tool for clinicians, enabling objective pain
intensity assessment while taking uncertainty into account. This capability is
crucial in facilitating effective pain management and reducing the risks
associated with improper treatment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozek_B/0/1/0/all/0/1&quot;&gt;Burcu Ozek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhenyuan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radhakrishnan_S/0/1/0/all/0/1&quot;&gt;Srinivasan Radhakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamarthi_S/0/1/0/all/0/1&quot;&gt;Sagar Kamarthi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08572">
<title>Parameter-Efficient Multilingual Summarisation: An Empirical Study. (arXiv:2311.08572v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08572</link>
<description rdf:parseType="Literal">&lt;p&gt;With the increasing prevalence of Large Language Models, traditional full
fine-tuning approaches face growing challenges, especially in memory-intensive
tasks. This paper investigates the potential of Parameter-Efficient
Fine-Tuning, focusing on Low-Rank Adaptation (LoRA), for complex and
under-explored multilingual summarisation tasks. We conduct an extensive study
across different data availability scenarios, including full-data, low-data,
and cross-lingual transfer, leveraging models of different sizes. Our findings
reveal that LoRA lags behind full fine-tuning when trained with full data,
however, it excels in low-data scenarios and cross-lingual transfer.
Interestingly, as models scale up, the performance gap between LoRA and full
fine-tuning diminishes. Additionally, we investigate effective strategies for
few-shot cross-lingual transfer, finding that continued LoRA tuning achieves
the best performance compared to both full fine-tuning and dynamic composition
of language-specific LoRA modules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whitehouse_C/0/1/0/all/0/1&quot;&gt;Chenxi Whitehouse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huot_F/0/1/0/all/0/1&quot;&gt;Fantine Huot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastings_J/0/1/0/all/0/1&quot;&gt;Jasmijn Bastings&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1&quot;&gt;Mostafa Dehghani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1&quot;&gt;Chu-Cheng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1&quot;&gt;Mirella Lapata&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08576">
<title>Towards Evaluating AI Systems for Moral Status Using Self-Reports. (arXiv:2311.08576v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08576</link>
<description rdf:parseType="Literal">&lt;p&gt;As AI systems become more advanced and widely deployed, there will likely be
increasing debate over whether AI systems could have conscious experiences,
desires, or other states of potential moral significance. It is important to
inform these discussions with empirical evidence to the extent possible. We
argue that under the right circumstances, self-reports, or an AI system&apos;s
statements about its own internal states, could provide an avenue for
investigating whether AI systems have states of moral significance.
Self-reports are the main way such states are assessed in humans (&quot;Are you in
pain?&quot;), but self-reports from current systems like large language models are
spurious for many reasons (e.g. often just reflecting what humans would say).
To make self-reports more appropriate for this purpose, we propose to train
models to answer many kinds of questions about themselves with known answers,
while avoiding or limiting training incentives that bias self-reports. The hope
of this approach is that models will develop introspection-like capabilities,
and that these capabilities will generalize to questions about states of moral
significance. We then propose methods for assessing the extent to which these
techniques have succeeded: evaluating self-report consistency across contexts
and between similar models, measuring the confidence and resilience of models&apos;
self-reports, and using interpretability to corroborate self-reports. We also
discuss challenges for our approach, from philosophical difficulties in
interpreting self-reports to technical reasons why our proposal might fail. We
hope our discussion inspires philosophers and AI researchers to criticize and
improve our proposed methodology, as well as to run experiments to test whether
self-reports can be made reliable enough to provide information about states of
moral significance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1&quot;&gt;Ethan Perez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_R/0/1/0/all/0/1&quot;&gt;Robert Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08585">
<title>Unsupervised segmentation of irradiation$\unicode{x2010}$induced order$\unicode{x2010}$disorder phase transitions in electron microscopy. (arXiv:2311.08585v1 [cond-mat.mtrl-sci])</title>
<link>http://arxiv.org/abs/2311.08585</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for the unsupervised segmentation of electron microscopy
images, which are powerful descriptors of materials and chemical systems.
Images are oversegmented into overlapping chips, and similarity graphs are
generated from embeddings extracted from a domain$\unicode{x2010}$pretrained
convolutional neural network (CNN). The Louvain method for community detection
is then applied to perform segmentation. The graph representation provides an
intuitive way of presenting the relationship between chips and communities. We
demonstrate our method to track irradiation$\unicode{x2010}$induced amorphous
fronts in thin films used for catalysis and electronics. This method has
potential for &quot;on$\unicode{x2010}$the$\unicode{x2010}$fly&quot; segmentation to
guide emerging automated electron microscopes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Ter_Petrosyan_A/0/1/0/all/0/1&quot;&gt;Arman H Ter-Petrosyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Bilbrey_J/0/1/0/all/0/1&quot;&gt;Jenna A Bilbrey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Doty_C/0/1/0/all/0/1&quot;&gt;Christina M Doty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Matthews_B/0/1/0/all/0/1&quot;&gt;Bethany E Matthews&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Le Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yingge Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Lang_E/0/1/0/all/0/1&quot;&gt;Eric Lang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Hattar_K/0/1/0/all/0/1&quot;&gt;Khalid Hattar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Spurgeon_S/0/1/0/all/0/1&quot;&gt;Steven R Spurgeon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08594">
<title>Variational Temporal IRT: Fast, Accurate, and Explainable Inference of Dynamic Learner Proficiency. (arXiv:2311.08594v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08594</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamic Item Response Models extend the standard Item Response Theory (IRT)
to capture temporal dynamics in learner ability. While these models have the
potential to allow instructional systems to actively monitor the evolution of
learner proficiency in real time, existing dynamic item response models rely on
expensive inference algorithms that scale poorly to massive datasets. In this
work, we propose Variational Temporal IRT (VTIRT) for fast and accurate
inference of dynamic learner proficiency. VTIRT offers orders of magnitude
speedup in inference runtime while still providing accurate inference.
Moreover, the proposed algorithm is intrinsically interpretable by virtue of
its modular design. When applied to 9 real student datasets, VTIRT consistently
yields improvements in predicting future learner performance over other learner
proficiency models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yunsung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankaranarayanan_S/0/1/0/all/0/1&quot;&gt;Sreechan Sankaranarayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piech_C/0/1/0/all/0/1&quot;&gt;Chris Piech&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thille_C/0/1/0/all/0/1&quot;&gt;Candace Thille&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08607">
<title>Towards Generalizable SER: Soft Labeling and Data Augmentation for Modeling Temporal Emotion Shifts in Large-Scale Multilingual Speech. (arXiv:2311.08607v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08607</link>
<description rdf:parseType="Literal">&lt;p&gt;Recognizing emotions in spoken communication is crucial for advanced
human-machine interaction. Current emotion detection methodologies often
display biases when applied cross-corpus. To address this, our study
amalgamates 16 diverse datasets, resulting in 375 hours of data across
languages like English, Chinese, and Japanese. We propose a soft labeling
system to capture gradational emotional intensities. Using the Whisper encoder
and data augmentation methods inspired by contrastive learning, our method
emphasizes the temporal dynamics of emotions. Our validation on four
multilingual datasets demonstrates notable zero-shot generalization. We publish
our open source model weights and initial promising results after fine-tuning
on Hume-Prosody.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osman_M/0/1/0/all/0/1&quot;&gt;Mohamed Osman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nadeem_T/0/1/0/all/0/1&quot;&gt;Tamer Nadeem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoriba_G/0/1/0/all/0/1&quot;&gt;Ghada Khoriba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08610">
<title>Converting Transformers to Polynomial Form for Secure Inference Over Homomorphic Encryption. (arXiv:2311.08610v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08610</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing privacy-preserving deep learning models is a major challenge within
the deep learning community. Homomorphic Encryption (HE) has emerged as one of
the most promising approaches in this realm, enabling the decoupling of
knowledge between the model owner and the data owner. Despite extensive
research and application of this technology, primarily in convolutional neural
networks, incorporating HE into transformer models has been challenging because
of the difficulties in converting these models into a polynomial form. We break
new ground by introducing the first polynomial transformer, providing the first
demonstration of secure inference over HE with transformers. This includes a
transformer architecture tailored for HE, alongside a novel method for
converting operators to their polynomial equivalent. This innovation enables us
to perform secure inference on LMs with WikiText-103. It also allows us to
perform image classification with CIFAR-100 and Tiny-ImageNet. Our models yield
results comparable to traditional methods, bridging the performance gap with
transformers of similar scale and underscoring the viability of HE for
state-of-the-art applications. Finally, we assess the stability of our models
and conduct a series of ablations to quantify the contribution of each model
component.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zimerman_I/0/1/0/all/0/1&quot;&gt;Itamar Zimerman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baruch_M/0/1/0/all/0/1&quot;&gt;Moran Baruch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drucker_N/0/1/0/all/0/1&quot;&gt;Nir Drucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ezov_G/0/1/0/all/0/1&quot;&gt;Gilad Ezov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soceanu_O/0/1/0/all/0/1&quot;&gt;Omri Soceanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1&quot;&gt;Lior Wolf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08615">
<title>Non-Uniform Smoothness for Gradient Descent. (arXiv:2311.08615v1 [math.OC])</title>
<link>http://arxiv.org/abs/2311.08615</link>
<description rdf:parseType="Literal">&lt;p&gt;The analysis of gradient descent-type methods typically relies on the
Lipschitz continuity of the objective gradient. This generally requires an
expensive hyperparameter tuning process to appropriately calibrate a stepsize
for a given problem. In this work we introduce a local first-order smoothness
oracle (LFSO) which generalizes the Lipschitz continuous gradients smoothness
condition and is applicable to any twice-differentiable function. We show that
this oracle can encode all relevant problem information for tuning stepsizes
for a suitably modified gradient descent method and give global and local
convergence results. We also show that LFSOs in this modified first-order
method can yield global linear convergence rates for non-strongly convex
problems with extremely flat minima, and thus improve over the lower bound on
rates achievable by general (accelerated) first-order methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Berahas_A/0/1/0/all/0/1&quot;&gt;Albert S. Berahas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Roberts_L/0/1/0/all/0/1&quot;&gt;Lindon Roberts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Roosta_F/0/1/0/all/0/1&quot;&gt;Fred Roosta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08620">
<title>Toucan: Token-Aware Character Level Language Modeling. (arXiv:2311.08620v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08620</link>
<description rdf:parseType="Literal">&lt;p&gt;Character-level language models obviate the need for separately trained
tokenizers, but efficiency suffers from longer sequence lengths. Learning to
combine character representations into tokens has made training these models
more efficient, but they still require decoding characters individually. We
propose Toucan, an augmentation to character-level models to make them
&quot;token-aware&quot;. Comparing our method to prior work, we demonstrate significant
speed-ups in character generation without a loss in language modeling
performance. We then explore differences between our learned dynamic
tokenization of character sequences with popular fixed vocabulary solutions
such as Byte-Pair Encoding and WordPiece, finding our approach leads to a
greater amount of longer sequences tokenized as single items. Our project and
code are available at https://nlp.jhu.edu/nuggets/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fleshman_W/0/1/0/all/0/1&quot;&gt;William Fleshman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1&quot;&gt;Benjamin Van Durme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08622">
<title>Multiple-Question Multiple-Answer Text-VQA. (arXiv:2311.08622v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08622</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Multiple-Question Multiple-Answer (MQMA), a novel approach to do
text-VQA in encoder-decoder transformer models. The text-VQA task requires a
model to answer a question by understanding multi-modal content: text
(typically from OCR) and an associated image. To the best of our knowledge,
almost all previous approaches for text-VQA process a single question and its
associated content to predict a single answer. In order to answer multiple
questions from the same image, each question and content are fed into the model
multiple times. In contrast, our proposed MQMA approach takes multiple
questions and content as input at the encoder and predicts multiple answers at
the decoder in an auto-regressive manner at the same time. We make several
novel architectural modifications to standard encoder-decoder transformers to
support MQMA. We also propose a novel MQMA denoising pre-training task which is
designed to teach the model to align and delineate multiple questions and
content with associated answers. MQMA pre-trained model achieves
state-of-the-art results on multiple text-VQA datasets, each with strong
baselines. Specifically, on OCR-VQA (+2.5%), TextVQA (+1.4%), ST-VQA (+0.6%),
DocVQA (+1.1%) absolute improvements over the previous state-of-the-art
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1&quot;&gt;Peng Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Appalaraju_S/0/1/0/all/0/1&quot;&gt;Srikar Appalaraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manmatha_R/0/1/0/all/0/1&quot;&gt;R. Manmatha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yusheng Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahadevan_V/0/1/0/all/0/1&quot;&gt;Vijay Mahadevan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08623">
<title>DEED: Dynamic Early Exit on Decoder for Accelerating Encoder-Decoder Transformer Models. (arXiv:2311.08623v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08623</link>
<description rdf:parseType="Literal">&lt;p&gt;Encoder-decoder transformer models have achieved great success on various
vision-language (VL) tasks, but they suffer from high inference latency.
Typically, the decoder takes up most of the latency because of the
auto-regressive decoding. To accelerate the inference, we propose an approach
of performing Dynamic Early Exit on Decoder (DEED). We build a multi-exit
encoder-decoder transformer model which is trained with deep supervision so
that each of its decoder layers is capable of generating plausible predictions.
In addition, we leverage simple yet practical techniques, including shared
generation head and adaptation modules, to keep accuracy when exiting at
shallow decoder layers. Based on the multi-exit model, we perform step-level
dynamic early exit during inference, where the model may decide to use fewer
decoder layers based on its confidence of the current layer at each individual
decoding step. Considering different number of decoder layers may be used at
different decoding steps, we compute deeper-layer decoder features of previous
decoding steps just-in-time, which ensures the features from different decoding
steps are semantically aligned. We evaluate our approach with two
state-of-the-art encoder-decoder transformer models on various VL tasks. We
show our approach can reduce overall inference latency by 30%-60% with
comparable or even higher accuracy compared to baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1&quot;&gt;Peng Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1&quot;&gt;Pengkai Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Appalaraju_S/0/1/0/all/0/1&quot;&gt;Srikar Appalaraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahadevan_V/0/1/0/all/0/1&quot;&gt;Vijay Mahadevan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manmatha_R/0/1/0/all/0/1&quot;&gt;R. Manmatha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08635">
<title>Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event Prediction. (arXiv:2311.08635v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08635</link>
<description rdf:parseType="Literal">&lt;p&gt;Traffic congestion event prediction is an important yet challenging task in
intelligent transportation systems. Many existing works about traffic
prediction integrate various temporal encoders and graph convolution networks
(GCNs), called spatio-temporal graph-based neural networks, which focus on
predicting dense variables such as flow, speed and demand in time snapshots,
but they can hardly forecast the traffic congestion events that are sparsely
distributed on the continuous time axis. In recent years, neural point process
(NPP) has emerged as an appropriate framework for event prediction in
continuous time scenarios. However, most conventional works about NPP cannot
model the complex spatio-temporal dependencies and congestion evolution
patterns. To address these limitations, we propose a spatio-temporal graph
neural point process framework, named STGNPP for traffic congestion event
prediction. Specifically, we first design the spatio-temporal graph learning
module to fully capture the long-range spatio-temporal dependencies from the
historical traffic state data along with the road network. The extracted
spatio-temporal hidden representation and congestion event information are then
fed into a continuous gated recurrent unit to model the congestion evolution
patterns. In particular, to fully exploit the periodic information, we also
improve the intensity function calculation of the point process with a periodic
gated mechanism. Finally, our model simultaneously predicts the occurrence time
and duration of the next congestion. Extensive experiments on two real-world
datasets demonstrate that our method achieves superior performance in
comparison to existing state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_G/0/1/0/all/0/1&quot;&gt;Guangyin Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lingbo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Fuxian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jincai Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08636">
<title>Supervised low-rank semi-nonnegative matrix factorization with frequency regularization for forecasting spatio-temporal data. (arXiv:2311.08636v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.08636</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel methodology for forecasting spatio-temporal data using
supervised semi-nonnegative matrix factorization (SSNMF) with frequency
regularization. Matrix factorization is employed to decompose spatio-temporal
data into spatial and temporal components. To improve clarity in the temporal
patterns, we introduce a nonnegativity constraint on the time domain along with
regularization in the frequency domain. Specifically, regularization in the
frequency domain involves selecting features in the frequency space, making an
interpretation in the frequency domain more convenient. We propose two methods
in the frequency domain: soft and hard regularizations, and provide convergence
guarantees to first-order stationary points of the corresponding constrained
optimization problem. While our primary motivation stems from geophysical data
analysis based on GRACE (Gravity Recovery and Climate Experiment) data, our
methodology has the potential for wider application. Consequently, when
applying our methodology to GRACE data, we find that the results with the
proposed methodology are comparable to previous research in the field of
geophysical sciences but offer clearer interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Keunsu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lyu_H/0/1/0/all/0/1&quot;&gt;Hanbaek Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jinsu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jung_J/0/1/0/all/0/1&quot;&gt;Jae-Hun Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08640">
<title>Multistage Collaborative Knowledge Distillation from Large Language Models. (arXiv:2311.08640v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08640</link>
<description rdf:parseType="Literal">&lt;p&gt;We study semi-supervised sequence prediction tasks where labeled data are too
scarce to effectively finetune a model and at the same time few-shot prompting
of a large language model (LLM) has suboptimal performance. This happens when a
task, such as parsing, is expensive to annotate and also unfamiliar to a
pretrained LLM. In this paper, we present a discovery that student models
distilled from a prompted LLM can often generalize better than their teacher on
such tasks. Leveraging this finding, we propose a new distillation method,
multistage collaborative knowledge distillation from an LLM (MCKD), for such
tasks. MCKD first prompts an LLM using few-shot in-context learning to produce
pseudolabels for unlabeled data. Then, at each stage of distillation, a pair of
students are trained on disjoint partitions of the pseudolabeled data. Each
student subsequently produces new and improved pseudolabels for the unseen
partition to supervise the next round of student(s) with. We show the benefit
of multistage cross-partition labeling on two constituency parsing tasks. On
CRAFT biomedical parsing, 3-stage MCKD with 50 labeled examples matches the
performance of supervised finetuning with 500 examples and outperforms the
prompted LLM and vanilla KD by 7.5% and 3.7% parsing F1, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jiachen Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wenlong Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drozdov_A/0/1/0/all/0/1&quot;&gt;Andrew Drozdov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rozonoyer_B/0/1/0/all/0/1&quot;&gt;Benjamin Rozonoyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sultan_M/0/1/0/all/0/1&quot;&gt;Md Arafat Sultan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jay-Yoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1&quot;&gt;Mohit Iyyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1&quot;&gt;Andrew McCallum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08644">
<title>Interpretable by Design: Wrapper Boxes Combine Neural Performance with Faithful Explanations. (arXiv:2311.08644v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08644</link>
<description rdf:parseType="Literal">&lt;p&gt;Can we preserve the accuracy of neural models while also providing faithful
explanations? We present wrapper boxes, a general approach to generate
faithful, example-based explanations for model predictions while maintaining
predictive performance. After training a neural model as usual, its learned
feature representation is input to a classic, interpretable model to perform
the actual prediction. This simple strategy is surprisingly effective, with
results largely comparable to those of the original neural model, as shown
across three large pre-trained language models, two datasets of varying scale,
four classic models, and four evaluation metrics. Moreover, because these
classic models are interpretable by design, the subset of training examples
that determine classic model predictions can be shown directly to users.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yiheng Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Juni Jessy Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lease_M/0/1/0/all/0/1&quot;&gt;Matthew Lease&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08655">
<title>Review of AlexNet for Medical Image Classification. (arXiv:2311.08655v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08655</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the rapid development of deep learning has led to a wide
range of applications in the field of medical image classification. The
variants of neural network models with ever-increasing performance share some
commonalities: to try to mitigate overfitting, improve generalization, avoid
gradient vanishing and exploding, etc. AlexNet first utilizes the dropout
technique to mitigate overfitting and the ReLU activation function to avoid
gradient vanishing. Therefore, we focus our discussion on AlexNet, which has
contributed greatly to the development of CNNs in 2012. After reviewing over 40
papers, including journal papers and conference papers, we give a narrative on
the technical details, advantages, and application areas of AlexNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1&quot;&gt;Wenhao Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Junding Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shuihua Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yudong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08657">
<title>ConeQuest: A Benchmark for Cone Segmentation on Mars. (arXiv:2311.08657v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08657</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the years, space scientists have collected terabytes of Mars data from
satellites and rovers. One important set of features identified in Mars orbital
images is pitted cones, which are interpreted to be mud volcanoes believed to
form in regions that were once saturated in water (i.e., a lake or ocean).
Identifying pitted cones globally on Mars would be of great importance, but
expert geologists are unable to sort through the massive orbital image archives
to identify all examples. However, this task is well suited for computer
vision. Although several computer vision datasets exist for various
Mars-related tasks, there is currently no open-source dataset available for
cone detection/segmentation. Furthermore, previous studies trained models using
data from a single region, which limits their applicability for global
detection and mapping. Motivated by this, we introduce ConeQuest, the first
expert-annotated public dataset to identify cones on Mars. ConeQuest consists
of &amp;gt;13k samples from 3 different regions of Mars. We propose two benchmark
tasks using ConeQuest: (i) Spatial Generalization and (ii) Cone-size
Generalization. We finetune and evaluate widely-used segmentation models on
both benchmark tasks. Results indicate that cone segmentation is a challenging
open problem not solved by existing segmentation models, which achieve an
average IoU of 52.52% and 42.55% on in-distribution data for tasks (i) and
(ii), respectively. We believe this new benchmark dataset will facilitate the
development of more accurate and robust models for cone segmentation. Data and
code are available at https://github.com/kerner-lab/ConeQuest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purohit_M/0/1/0/all/0/1&quot;&gt;Mirali Purohit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adler_J/0/1/0/all/0/1&quot;&gt;Jacob Adler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kerner_H/0/1/0/all/0/1&quot;&gt;Hannah Kerner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08661">
<title>Deep Neural Network Identification of Limnonectes Species and New Class Detection Using Image Data. (arXiv:2311.08661v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.08661</link>
<description rdf:parseType="Literal">&lt;p&gt;As is true of many complex tasks, the work of discovering, describing, and
understanding the diversity of life on Earth (viz., biological systematics and
taxonomy) requires many tools. Some of this work can be accomplished as it has
been done in the past, but some aspects present us with challenges which
traditional knowledge and tools cannot adequately resolve. One such challenge
is presented by species complexes in which the morphological similarities among
the group members make it difficult to reliably identify known species and
detect new ones. We address this challenge by developing new tools using the
principles of machine learning to resolve two specific questions related to
species complexes. The first question is formulated as a classification problem
in statistics and machine learning and the second question is an
out-of-distribution (OOD) detection problem. We apply these tools to a species
complex comprising Southeast Asian stream frogs (Limnonectes kuhlii complex)
and employ a morphological character (hind limb skin texture) traditionally
treated qualitatively in a quantitative and objective manner. We demonstrate
that deep neural networks can successfully automate the classification of an
image into a known species group for which it has been trained. We further
demonstrate that the algorithm can successfully classify an image into a new
class if the image does not belong to the existing classes. Additionally, we
use the larger MNIST dataset to test the performance of our OOD detection
algorithm. We finish our paper with some concluding remarks regarding the
application of these methods to species complexes and our efforts to document
true biodiversity. This paper has online supplementary materials.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_L/0/1/0/all/0/1&quot;&gt;Li Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Yili Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smith_E/0/1/0/all/0/1&quot;&gt;Eric P. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McLeod_D/0/1/0/all/0/1&quot;&gt;David S. McLeod&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deng_X/0/1/0/all/0/1&quot;&gt;Xinwei Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Freeman_L/0/1/0/all/0/1&quot;&gt;Laura J. Freeman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08666">
<title>It Takes Two to Negotiate: Modeling Social Exchange in Online Multiplayer Games. (arXiv:2311.08666v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08666</link>
<description rdf:parseType="Literal">&lt;p&gt;Online games are dynamic environments where players interact with each other,
which offers a rich setting for understanding how players negotiate their way
through the game to an ultimate victory. This work studies online player
interactions during the turn-based strategy game, Diplomacy. We annotated a
dataset of over 10,000 chat messages for different negotiation strategies and
empirically examined their importance in predicting long- and short-term game
outcomes. Although negotiation strategies can be predicted reasonably
accurately through the linguistic modeling of the chat messages, more is needed
for predicting short-term outcomes such as trustworthiness. On the other hand,
they are essential in graph-aware reinforcement learning approaches to predict
long-term outcomes, such as a player&apos;s success, based on their prior
negotiation history. We close with a discussion of the implications and impact
of our work. The dataset is available at
https://github.com/kj2013/claff-diplomacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaidka_K/0/1/0/all/0/1&quot;&gt;Kokil Jaidka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_H/0/1/0/all/0/1&quot;&gt;Hansin Ahuja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ng_L/0/1/0/all/0/1&quot;&gt;Lynnette Ng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08669">
<title>Understanding Calibration for Multilingual Question Answering Models. (arXiv:2311.08669v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08669</link>
<description rdf:parseType="Literal">&lt;p&gt;Multilingual pre-trained language models are incredibly effective at Question
Answering (QA), a core task in Natural Language Understanding, achieving high
accuracies on several multilingual benchmarks. However, little is known about
how well they are calibrated. In this paper, we study the calibration
properties of several pre-trained multilingual large language models (LLMs) on
a variety of question-answering tasks. We perform extensive experiments,
spanning both extractive and generative QA model designs and diverse languages,
spanning both high-resource and low-resource ones. We study different
dimensions of calibration in in-distribution, out-of-distribution, and
cross-lingual transfer settings, and investigate strategies to improve it,
including post-hoc methods and regularized fine-tuning. We demonstrate
automatically translated data augmentation as a highly effective technique to
improve model calibration. We also conduct a number of ablation experiments to
study the effect of model size on calibration and how multilingual models
compare with their monolingual counterparts for diverse tasks and languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yahan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1&quot;&gt;Soham Dan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1&quot;&gt;Dan Roth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1&quot;&gt;Insup Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08675">
<title>Coreset Selection with Prioritized Multiple Objectives. (arXiv:2311.08675v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08675</link>
<description rdf:parseType="Literal">&lt;p&gt;Coreset selection is powerful in reducing computational costs and
accelerating data processing for deep learning algorithms. It strives to
identify a small subset from large-scale data, so that training only on the
subset practically performs on par with full data. When coreset selection is
applied in realistic scenes, under the premise that the identified coreset has
achieved comparable model performance, practitioners regularly desire the
identified coreset can have a size as small as possible for lower costs and
greater acceleration. Motivated by this desideratum, for the first time, we
pose the problem of &quot;coreset selection with prioritized multiple objectives&quot;,
in which the smallest coreset size under model performance constraints is
explored. Moreover, to address this problem, an innovative method is proposed,
which maintains optimization priority order over the model performance and
coreset size, and efficiently optimizes them in the coreset selection
procedure. Theoretically, we provide the convergence guarantee of the proposed
method. Empirically, extensive experiments confirm its superiority compared
with previous strategies, often yielding better model performance with smaller
coreset sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1&quot;&gt;Xiaobo Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiale Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shaokun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qingyun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tongliang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08677">
<title>Federated Learning for Sparse Principal Component Analysis. (arXiv:2311.08677v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08677</link>
<description rdf:parseType="Literal">&lt;p&gt;In the rapidly evolving realm of machine learning, algorithm effectiveness
often faces limitations due to data quality and availability. Traditional
approaches grapple with data sharing due to legal and privacy concerns. The
federated learning framework addresses this challenge. Federated learning is a
decentralized approach where model training occurs on client sides, preserving
privacy by keeping data localized. Instead of sending raw data to a central
server, only model updates are exchanged, enhancing data security. We apply
this framework to Sparse Principal Component Analysis (SPCA) in this work. SPCA
aims to attain sparse component loadings while maximizing data variance for
improved interpretability. Beside the L1 norm regularization term in
conventional SPCA, we add a smoothing function to facilitate gradient-based
optimization methods. Moreover, in order to improve computational efficiency,
we introduce a least squares approximation to original SPCA. This enables
analytic solutions on the optimization processes, leading to substantial
computational improvements. Within the federated framework, we formulate SPCA
as a consensus optimization problem, which can be solved using the Alternating
Direction Method of Multipliers (ADMM). Our extensive experiments involve both
IID and non-IID random features across various data owners. Results on
synthetic and public datasets affirm the efficacy of our federated SPCA
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciou_S/0/1/0/all/0/1&quot;&gt;Sin Cheng Ciou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pin Jui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tseng_E/0/1/0/all/0/1&quot;&gt;Elvin Y. Tseng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yuh-Jye Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08687">
<title>An Eye on Clinical BERT: Investigating Language Model Generalization for Diabetic Eye Disease Phenotyping. (arXiv:2311.08687v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08687</link>
<description rdf:parseType="Literal">&lt;p&gt;Diabetic eye disease is a major cause of blindness worldwide. The ability to
monitor relevant clinical trajectories and detect lapses in care is critical to
managing the disease and preventing blindness. Alas, much of the information
necessary to support these goals is found only in the free text of the
electronic medical record. To fill this information gap, we introduce a system
for extracting evidence from clinical text of 19 clinical concepts related to
diabetic eye disease and inferring relevant attributes for each. In developing
this ophthalmology phenotyping system, we are also afforded a unique
opportunity to evaluate the effectiveness of clinical language models at
adapting to new clinical domains. Across multiple training paradigms, we find
that BERT language models pretrained on out-of-distribution clinical data offer
no significant improvement over BERT language models pretrained on non-clinical
data for our domain. Our study tempers recent claims that language models
pretrained on clinical data are necessary for clinical NLP tasks and highlights
the importance of not treating clinical language data as a single homogeneous
domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harrigian_K/0/1/0/all/0/1&quot;&gt;Keith Harrigian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1&quot;&gt;Tina Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzales_A/0/1/0/all/0/1&quot;&gt;Anthony Gonzales&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1&quot;&gt;Cindy X. Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dredze_M/0/1/0/all/0/1&quot;&gt;Mark Dredze&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08690">
<title>Enabling CMF Estimation in Data-Constrained Scenarios: A Semantic-Encoding Knowledge Mining Model. (arXiv:2311.08690v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08690</link>
<description rdf:parseType="Literal">&lt;p&gt;Precise estimation of Crash Modification Factors (CMFs) is central to
evaluating the effectiveness of various road safety treatments and prioritizing
infrastructure investment accordingly. While customized study for each
countermeasure scenario is desired, the conventional CMF estimation approaches
rely heavily on the availability of crash data at given sites. This not only
makes the estimation costly, but the results are also less transferable, since
the intrinsic similarities between different safety countermeasure scenarios
are not fully explored. Aiming to fill this gap, this study introduces a novel
knowledge-mining framework for CMF prediction. This framework delves into the
connections of existing countermeasures and reduces the reliance of CMF
estimation on crash data availability and manual data collection. Specifically,
it draws inspiration from human comprehension processes and introduces advanced
Natural Language Processing (NLP) techniques to extract intricate variations
and patterns from existing CMF knowledge. It effectively encodes unstructured
countermeasure scenarios into machine-readable representations and models the
complex relationships between scenarios and CMF values. This new data-driven
framework provides a cost-effective and adaptable solution that complements the
case-specific approaches for CMF estimation, which is particularly beneficial
when availability of crash data or time imposes constraints. Experimental
validation using real-world CMF Clearinghouse data demonstrates the
effectiveness of this new approach, which shows significant accuracy
improvements compared to baseline methods. This approach provides insights into
new possibilities of harnessing accumulated transportation knowledge in various
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1&quot;&gt;Yanlin Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Michael Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08692">
<title>Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models. (arXiv:2311.08692v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08692</link>
<description rdf:parseType="Literal">&lt;p&gt;The complementary potential of Large Language Models (LLM) assumes
off-the-shelf LLMs have heterogeneous expertise in a wide range of domains and
tasks so that an ensemble of LLMs can achieve consistently better performance.
Existing ensemble methods for LLMs mainly focus on reward model ranking of
outputs, leading to significant computation overhead. To combat this issue, we
revisit the complementary potential of LLMs and further elaborate it by mining
latent expertise with off-the-shelf reward models. We propose Zooter, a
reward-guided routing method distilling rewards on training queries to train a
routing function, which can precisely distribute each query to the LLM with
expertise about it. We also integrate a tag-based label enhancement to mitigate
noise from uncertainty when using rewards as silver supervision. Zooter shows
computation efficiency in inference as it introduces only a minor computation
overhead of a routing function compared with reward model ranking methods. We
evaluate Zooter on a comprehensive benchmark collection with 26 subsets on
different domains and tasks. Zooter outperforms the best single model on
average and ranks first on 44% of tasks, even surpassing multiple reward model
ranking methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1&quot;&gt;Keming Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1&quot;&gt;Hongyi Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1&quot;&gt;Runji Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Junyang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1&quot;&gt;Zheng Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1&quot;&gt;Chang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jingren Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08695">
<title>Attribute Diversity Determines the Systematicity Gap in VQA. (arXiv:2311.08695v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08695</link>
<description rdf:parseType="Literal">&lt;p&gt;The degree to which neural networks can generalize to new combinations of
familiar concepts, and the conditions under which they are able to do so, has
long been an open question. In this work, we study the systematicity gap in
visual question answering: the performance difference between reasoning on
previously seen and unseen combinations of object attributes. To test, we
introduce a novel diagnostic dataset, CLEVR-HOPE. We find that while increased
quantity of training data does not reduce the systematicity gap, increased
training data diversity of the attributes in the unseen combination does. In
all, our experiments suggest that the more distinct attribute type combinations
are seen during training, the more systematic we can expect the resulting model
to be.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berlot_Attwell_I/0/1/0/all/0/1&quot;&gt;Ian Berlot-Attwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carrell_A/0/1/0/all/0/1&quot;&gt;A. Michael Carrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_K/0/1/0/all/0/1&quot;&gt;Kumar Krishna Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1&quot;&gt;Yash Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1&quot;&gt;Naomi Saphra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08716">
<title>Scalable Federated Learning for Clients with Different Input Image Sizes and Numbers of Output Categories. (arXiv:2311.08716v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08716</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning is a privacy-preserving training method which consists of
training from a plurality of clients but without sharing their confidential
data. However, previous work on federated learning do not explore suitable
neural network architectures for clients with different input images sizes and
different numbers of output categories. In this paper, we propose an effective
federated learning method named ScalableFL, where the depths and widths of the
local models for each client are adjusted according to the clients&apos; input image
size and the numbers of output categories. In addition, we provide a new bound
for the generalization gap of federated learning. In particular, this bound
helps to explain the effectiveness of our scalable neural network approach. We
demonstrate the effectiveness of ScalableFL in several heterogeneous client
settings for both image classification and object detection tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nitta_S/0/1/0/all/0/1&quot;&gt;Shuhei Nitta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suzuki_T/0/1/0/all/0/1&quot;&gt;Taiji Suzuki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mulet_A/0/1/0/all/0/1&quot;&gt;Albert Rodr&amp;#xed;guez Mulet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yaguchi_A/0/1/0/all/0/1&quot;&gt;Atsushi Yaguchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hirai_R/0/1/0/all/0/1&quot;&gt;Ryusuke Hirai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08724">
<title>Method for Text Entity Linking in Power Distribution Scheduling Oriented to Power Distribution Network Knowledge Graph. (arXiv:2311.08724v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08724</link>
<description rdf:parseType="Literal">&lt;p&gt;The proposed method for linking entities in power distribution dispatch texts
to a power distribution network knowledge graph is based on a deep
understanding of these networks. This method leverages the unique features of
entities in both the power distribution network&apos;s knowledge graph and the
dispatch texts, focusing on their semantic, phonetic, and syntactic
characteristics. An enhanced model, the Lexical Semantic Feature-based Skip
Convolutional Neural Network (LSF-SCNN), is utilized for effectively matching
dispatch text entities with those in the knowledge graph. The efficacy of this
model, compared to a control model, is evaluated through cross-validation
methods in real-world power distribution dispatch scenarios. The results
indicate that the LSF-SCNN model excels in accurately linking a variety of
entity types, demonstrating high overall accuracy in entity linking when the
process is conducted in English.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Che Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Sizhe Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08744">
<title>Towards Graph-Aware Diffusion Modeling for Collaborative Filtering. (arXiv:2311.08744v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2311.08744</link>
<description rdf:parseType="Literal">&lt;p&gt;Recovering masked feedback with neural models is a popular paradigm in
recommender systems. Seeing the success of diffusion models in solving
ill-posed inverse problems, we introduce a conditional diffusion framework for
collaborative filtering that iteratively reconstructs a user&apos;s hidden
preferences guided by its historical interactions. To better align with the
intrinsic characteristics of implicit feedback data, we implement forward
diffusion by applying synthetic smoothing filters to interaction signals on an
item-item graph. The resulting reverse diffusion can be interpreted as a
personalized process that gradually refines preference scores. Through graph
Fourier transform, we equivalently characterize this model as an anisotropic
Gaussian diffusion in the graph spectral domain, establishing both forward and
reverse formulations. Our model outperforms state-of-the-art methods by a large
margin on one dataset and yields competitive results on the others.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yunqin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Hui Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08745">
<title>Using Stochastic Gradient Descent to Smooth Nonconvex Functions: Analysis of Implicit Graduated Optimization with Optimal Noise Scheduling. (arXiv:2311.08745v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08745</link>
<description rdf:parseType="Literal">&lt;p&gt;The graduated optimization approach is a heuristic method for finding
globally optimal solutions for nonconvex functions and has been theoretically
analyzed in several studies. This paper defines a new family of nonconvex
functions for graduated optimization, discusses their sufficient conditions,
and provides a convergence analysis of the graduated optimization algorithm for
them. It shows that stochastic gradient descent (SGD) with mini-batch
stochastic gradients has the effect of smoothing the function, the degree of
which is determined by the learning rate and batch size. This finding provides
theoretical insights from a graduated optimization perspective on why large
batch sizes fall into sharp local minima, why decaying learning rates and
increasing batch sizes are superior to fixed learning rates and batch sizes,
and what the optimal learning rate scheduling is. To the best of our knowledge,
this is the first paper to provide a theoretical explanation for these aspects.
Moreover, a new graduated optimization framework that uses a decaying learning
rate and increasing batch size is analyzed and experimental results of image
classification that support our theoretical findings are reported.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sato_N/0/1/0/all/0/1&quot;&gt;Naoki Sato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iiduka_H/0/1/0/all/0/1&quot;&gt;Hideaki Iiduka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08755">
<title>Environment-independent mmWave Fall Detection with Interacting Multiple Model. (arXiv:2311.08755v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2311.08755</link>
<description rdf:parseType="Literal">&lt;p&gt;The ageing society brings attention to daily elderly care through sensing
technologies. The future smart home is expected to enable in-home daily
monitoring, such as fall detection, for seniors in a non-invasive,
non-cooperative, and non-contact manner. The mmWave radar is a promising
candidate technology for its privacy-preserving and non-contact manner.
However, existing solutions suffer from low accuracy and robustness due to
environment dependent features. In this paper, we present FADE
(\underline{FA}ll \underline{DE}tection), a practical fall detection radar
system with enhanced accuracy and robustness in real-world scenarios. The key
enabler underlying FADE is an interacting multiple model (IMM) state estimator
that can extract environment-independent features for highly accurate and
instantaneous fall detection. Furthermore, we proposed a robust multiple-user
tracking system to deal with noises from the environment and other human
bodies. We deployed our algorithm on low computing power and low power
consumption system-on-chip (SoC) composed of data front end, DSP, and ARM
processor, and tested its performance in real-world. The experiment shows that
the accuracy of fall detection is up to 95\%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xuyao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiazhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jiang_W/0/1/0/all/0/1&quot;&gt;Wenchao Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08774">
<title>Two-stage Joint Transductive and Inductive learning for Nuclei Segmentation. (arXiv:2311.08774v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.08774</link>
<description rdf:parseType="Literal">&lt;p&gt;AI-assisted nuclei segmentation in histopathological images is a crucial task
in the diagnosis and treatment of cancer diseases. It decreases the time
required to manually screen microscopic tissue images and can resolve the
conflict between pathologists during diagnosis. Deep Learning has proven useful
in such a task. However, lack of labeled data is a significant barrier for deep
learning-based approaches. In this study, we propose a novel approach to nuclei
segmentation that leverages the available labelled and unlabelled data. The
proposed method combines the strengths of both transductive and inductive
learning, which have been previously attempted separately, into a single
framework. Inductive learning aims at approximating the general function and
generalizing to unseen test data, while transductive learning has the potential
of leveraging the unlabelled test data to improve the classification. To the
best of our knowledge, this is the first study to propose such a hybrid
approach for medical image segmentation. Moreover, we propose a novel two-stage
transductive inference scheme. We evaluate our approach on MoNuSeg benchmark to
demonstrate the efficacy and potential of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ali_H/0/1/0/all/0/1&quot;&gt;Hesham Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tondji_I/0/1/0/all/0/1&quot;&gt;Idriss Tondji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Siam_M/0/1/0/all/0/1&quot;&gt;Mennatullah Siam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08788">
<title>X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented Instruction Tuning with Auxiliary Evaluation Aspects. (arXiv:2311.08788v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08788</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural Language Generation (NLG) typically involves evaluating the generated
text in various aspects (e.g., consistency and naturalness) to obtain a
comprehensive assessment. However, multi-aspect evaluation remains challenging
as it may require the evaluator to generalize to any given evaluation aspect
even if it&apos;s absent during training. In this paper, we introduce X-Eval, a
two-stage instruction tuning framework to evaluate the text in both seen and
unseen aspects customized by end users. X-Eval consists of two learning stages:
the vanilla instruction tuning stage that improves the model&apos;s ability to
follow evaluation instructions, and an enhanced instruction tuning stage that
exploits the connections between fine-grained evaluation aspects to better
assess text quality. To support the training of X-Eval, we collect
AspectInstruct, the first instruction tuning dataset tailored for multi-aspect
NLG evaluation spanning 27 diverse evaluation aspects with 65 tasks. To enhance
task diversity, we devise an augmentation strategy that converts human rating
annotations into diverse forms of NLG evaluation tasks, including scoring,
comparison, ranking, and Boolean question answering. Extensive experiments
across three essential categories of NLG tasks: dialogue generation,
summarization, and data-to-text coupled with 21 aspects in meta-evaluation,
demonstrate that our X-Eval enables even a lightweight language model to
achieve a comparable if not higher correlation with human judgments compared to
the state-of-the-art NLG evaluators, such as GPT-4.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Minqian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Ying Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhiyang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yixin Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_E/0/1/0/all/0/1&quot;&gt;Eunah Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vaibhav Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghanadan_R/0/1/0/all/0/1&quot;&gt;Reza Ghanadan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lifu Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08815">
<title>Self-Supervised Disentanglement by Leveraging Structure in Data Augmentations. (arXiv:2311.08815v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08815</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised representation learning often uses data augmentations to
induce some invariance to &quot;style&quot; attributes of the data. However, with
downstream tasks generally unknown at training time, it is difficult to deduce
a priori which attributes of the data are indeed &quot;style&quot; and can be safely
discarded. To address this, we introduce a more principled approach that seeks
to disentangle style features rather than discard them. The key idea is to add
multiple style embedding spaces where: (i) each is invariant to all-but-one
augmentation; and (ii) joint entropy is maximized. We formalize our structured
data-augmentation procedure from a causal latent-variable-model perspective,
and prove identifiability of both content and (multiple blocks of) style
variables. We empirically demonstrate the benefits of our approach on synthetic
datasets and then present promising but limited results on ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eastwood_C/0/1/0/all/0/1&quot;&gt;Cian Eastwood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kugelgen_J/0/1/0/all/0/1&quot;&gt;Julius von K&amp;#xfc;gelgen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ericsson_L/0/1/0/all/0/1&quot;&gt;Linus Ericsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouchacourt_D/0/1/0/all/0/1&quot;&gt;Diane Bouchacourt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1&quot;&gt;Pascal Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1&quot;&gt;Mark Ibrahim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08817">
<title>MAP&apos;s not dead yet: Uncovering true language model modes by conditioning away degeneracy. (arXiv:2311.08817v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08817</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been widely observed that exact or approximate MAP (mode-seeking)
decoding from natural language generation (NLG) models consistently leads to
degenerate outputs (Stahlberg and Byrne, 2019, Holtzman et al., 2019). This has
generally been attributed to either a fundamental inadequacy of modes in models
or weaknesses in language modeling. Contrastingly in this work, we emphasize
that degenerate modes can even occur in the absence of any model error, due to
contamination of the training data. Specifically, we show that mixing even a
tiny amount of low-entropy noise with a population text distribution can cause
the data distribution&apos;s mode to become degenerate, implying that any models
trained on it will be as well. As the unconditional mode of NLG models will
often be degenerate, we therefore propose to apply MAP decoding to the model&apos;s
distribution conditional on avoiding specific degeneracies. Using exact-search,
we empirically verify that the length-conditional modes of machine translation
models and language models are indeed more fluent and topical than their
unconditional modes. For the first time, we also share many examples of exact
modal sequences from these models, and from several variants of the LLaMA-7B
model. Notably, the modes of the LLaMA models are still degenerate, showing
that improvements in modeling have not fixed this issue. Because of the cost of
exact mode finding algorithms, we develop an approximate mode finding approach,
ACBS, which finds sequences that are both high-likelihood and high-quality. We
apply this approach to LLaMA-7B, a model which was not trained for instruction
following, and find that we are able to elicit reasonable outputs without any
finetuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoshida_D/0/1/0/all/0/1&quot;&gt;Davis Yoshida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_K/0/1/0/all/0/1&quot;&gt;Kartik Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gimpel_K/0/1/0/all/0/1&quot;&gt;Kevin Gimpel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08819">
<title>Frequency Domain-based Dataset Distillation. (arXiv:2311.08819v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08819</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents FreD, a novel parameterization method for dataset
distillation, which utilizes the frequency domain to distill a small-sized
synthetic dataset from a large-sized original dataset. Unlike conventional
approaches that focus on the spatial domain, FreD employs frequency-based
transforms to optimize the frequency representations of each data instance. By
leveraging the concentration of spatial domain information on specific
frequency components, FreD intelligently selects a subset of frequency
dimensions for optimization, leading to a significant reduction in the required
budget for synthesizing an instance. Through the selection of frequency
dimensions based on the explained variance, FreD demonstrates both theoretical
and empirical evidence of its ability to operate efficiently within a limited
budget, while better preserving the information of the original dataset
compared to conventional parameterization methods. Furthermore, based on the
orthogonal compatibility of FreD with existing methods, we confirm that FreD
consistently improves the performances of existing distillation methods over
the evaluation scenarios with different benchmark datasets. We release the code
at https://github.com/sdh0818/FreD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_D/0/1/0/all/0/1&quot;&gt;Donghyeok Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1&quot;&gt;Seungjae Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1&quot;&gt;Il-Chul Moon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08845">
<title>Statistical learning by sparse deep neural networks. (arXiv:2311.08845v1 [math.ST])</title>
<link>http://arxiv.org/abs/2311.08845</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a deep neural network estimator based on empirical risk
minimization with l_1-regularization. We derive a general bound for its excess
risk in regression and classification (including multiclass), and prove that it
is adaptively nearly-minimax (up to log-factors) simultaneously across the
entire range of various function classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Abramovich_F/0/1/0/all/0/1&quot;&gt;Felix Abramovich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08851">
<title>Data Augmentations in Deep Weight Spaces. (arXiv:2311.08851v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08851</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning in weight spaces, where neural networks process the weights of other
deep neural networks, has emerged as a promising research direction with
applications in various fields, from analyzing and editing neural fields and
implicit neural representations, to network pruning and quantization. Recent
works designed architectures for effective learning in that space, which takes
into account its unique, permutation-equivariant, structure. Unfortunately, so
far these architectures suffer from severe overfitting and were shown to
benefit from large datasets. This poses a significant challenge because
generating data for this learning setup is laborious and time-consuming since
each data sample is a full set of network weights that has to be trained. In
this paper, we address this difficulty by investigating data augmentations for
weight spaces, a set of techniques that enable generating new data examples on
the fly without having to train additional input weight space elements. We
first review several recently proposed data augmentation schemes %that were
proposed recently and divide them into categories. We then introduce a novel
augmentation scheme based on the Mixup method. We evaluate the performance of
these techniques on existing benchmarks as well as new benchmarks we generate,
which can be valuable for future studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shamsian_A/0/1/0/all/0/1&quot;&gt;Aviv Shamsian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;David W. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navon_A/0/1/0/all/0/1&quot;&gt;Aviv Navon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kofinas_M/0/1/0/all/0/1&quot;&gt;Miltiadis Kofinas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achituve_I/0/1/0/all/0/1&quot;&gt;Idan Achituve&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valperga_R/0/1/0/all/0/1&quot;&gt;Riccardo Valperga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burghouts_G/0/1/0/all/0/1&quot;&gt;Gertjan J. Burghouts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gavves_E/0/1/0/all/0/1&quot;&gt;Efstratios Gavves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1&quot;&gt;Cees G. M. Snoek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fetaya_E/0/1/0/all/0/1&quot;&gt;Ethan Fetaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1&quot;&gt;Gal Chechik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maron_H/0/1/0/all/0/1&quot;&gt;Haggai Maron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08870">
<title>One-Shot Federated Learning with Classifier-Guided Diffusion Models. (arXiv:2311.08870v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08870</link>
<description rdf:parseType="Literal">&lt;p&gt;One-shot federated learning (OSFL) has gained attention in recent years due
to its low communication cost. However, most of the existing methods require
auxiliary datasets or training generators, which hinders their practicality in
real-world scenarios. In this paper, we explore the novel opportunities that
diffusion models bring to OSFL and propose FedCADO, utilizing guidance from
client classifiers to generate data that complies with clients&apos; distributions
and subsequently training the aggregated model on the server. Specifically, our
method involves targeted optimizations in two aspects. On one hand, we
conditionally edit the randomly sampled initial noises, embedding them with
specified semantics and distributions, resulting in a significant improvement
in both the quality and stability of generation. On the other hand, we employ
the BN statistics from the classifiers to provide detailed guidance during
generation. These tailored optimizations enable us to limitlessly generate
datasets, which closely resemble the distribution and quality of the original
client dataset. Our method effectively handles the heterogeneous client models
and the problems of non-IID features or labels. In terms of privacy protection,
our method avoids training any generator or transferring any auxiliary
information on clients, eliminating any additional privacy leakage risks.
Leveraging the extensive knowledge stored in the pre-trained diffusion model,
the synthetic datasets can assist us in surpassing the knowledge limitations of
the client samples, resulting in aggregation models that even outperform the
performance ceiling of centralized training in some cases, which is
convincingly demonstrated in the sufficient quantification and visualization
experiments conducted on three large-scale multi-domain image datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Mingzhao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1&quot;&gt;Shangchao Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1&quot;&gt;Xiangyang Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08874">
<title>Towards Label Embedding -- Measuring classification difficulty. (arXiv:2311.08874v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08874</link>
<description rdf:parseType="Literal">&lt;p&gt;Uncertainty quantification in machine learning is a timely and vast field of
research. In supervised learning, uncertainty can already occur in the very
first stage of the training process, the labelling step. In particular, this is
the case when not every instance can be unambiguously classified. The problem
occurs for classifying instances, where classes may overlap or instances can
not be clearly categorised. In other words, there is inevitable ambiguity in
the annotation step and not necessarily a &apos;ground truth&apos;. We look exemplary at
the classification of satellite images. Each image is annotated independently
by multiple labellers and classified into local climate zones (LCZs). For each
instance we have multiple votes, leading to a distribution of labels rather
than a single value. The main idea of this work is that we do not assume a
ground truth label but embed the votes into a K-dimensional space, with K as
the number of possible categories. The embedding is derived from the voting
distribution in a Bayesian setup, modelled via a Dirichlet-Multinomial model.
We estimate the model and posteriors using a stochastic Expectation
Maximisation algorithm with Markov Chain Monte Carlo steps. While we focus on
the particular example of LCZ classification, the methods developed in this
paper readily extend to other situations where multiple annotators
independently label texts or images. We also apply our approach to two other
benchmark datasets for image classification to demonstrate this. Besides the
embeddings themselves, we can investigate the resulting correlation matrices,
which can be seen as generalised confusion matrices and reflect the semantic
similarities of the original classes very well for all three exemplary
datasets. The insights gained are valuable and can serve as general label
embedding if a single ground truth per observation cannot be guaranteed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hechinger_K/0/1/0/all/0/1&quot;&gt;Katharina Hechinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koller_C/0/1/0/all/0/1&quot;&gt;Christoph Koller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiao Xiang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kauermann_G/0/1/0/all/0/1&quot;&gt;G&amp;#xf6;ran Kauermann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08877">
<title>Llamas Know What GPTs Don&apos;t Show: Surrogate Models for Confidence Estimation. (arXiv:2311.08877v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.08877</link>
<description rdf:parseType="Literal">&lt;p&gt;To maintain user trust, large language models (LLMs) should signal low
confidence on examples where they are incorrect, instead of misleading the
user. The standard approach of estimating confidence is to use the softmax
probabilities of these models, but as of November 2023, state-of-the-art LLMs
such as GPT-4 and Claude-v1.3 do not provide access to these probabilities. We
first study eliciting confidence linguistically -- asking an LLM for its
confidence in its answer -- which performs reasonably (80.5% AUC on GPT-4
averaged across 12 question-answering datasets -- 7% above a random baseline)
but leaves room for improvement. We then explore using a surrogate confidence
model -- using a model where we do have probabilities to evaluate the original
model&apos;s confidence in a given question. Surprisingly, even though these
probabilities come from a different and often weaker model, this method leads
to higher AUC than linguistic confidences on 9 out of 12 datasets. Our best
method composing linguistic confidences and surrogate model probabilities gives
state-of-the-art confidence estimates on all 12 datasets (84.6% average AUC on
GPT-4).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrivastava_V/0/1/0/all/0/1&quot;&gt;Vaishnavi Shrivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Ananya Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08902">
<title>On the Importance of Step-wise Embeddings for Heterogeneous Clinical Time-Series. (arXiv:2311.08902v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08902</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in deep learning architectures for sequence modeling have not
fully transferred to tasks handling time-series from electronic health records.
In particular, in problems related to the Intensive Care Unit (ICU), the
state-of-the-art remains to tackle sequence classification in a tabular manner
with tree-based methods. Recent findings in deep learning for tabular data are
now surpassing these classical methods by better handling the severe
heterogeneity of data input features. Given the similar level of feature
heterogeneity exhibited by ICU time-series and motivated by these findings, we
explore these novel methods&apos; impact on clinical sequence modeling tasks. By
jointly using such advances in deep learning for tabular data, our primary
objective is to underscore the importance of step-wise embeddings in
time-series modeling, which remain unexplored in machine learning methods for
clinical data. On a variety of clinically relevant tasks from two large-scale
ICU datasets, MIMIC-III and HiRID, our work provides an exhaustive analysis of
state-of-the-art methods for tabular time-series as time-step embedding models,
showing overall performance improvement. In particular, we evidence the
importance of feature grouping in clinical time-series, with significant
performance gains when considering features within predefined semantic groups
in the step-wise embedding module.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuznetsova_R/0/1/0/all/0/1&quot;&gt;Rita Kuznetsova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pace_A/0/1/0/all/0/1&quot;&gt;Aliz&amp;#xe9;e Pace&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burger_M/0/1/0/all/0/1&quot;&gt;Manuel Burger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeche_H/0/1/0/all/0/1&quot;&gt;Hugo Y&amp;#xe8;che&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1&quot;&gt;Gunnar R&amp;#xe4;tsch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08909">
<title>DLAS: An Exploration and Assessment of the Deep Learning Acceleration Stack. (arXiv:2311.08909v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08909</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks (DNNs) are extremely computationally demanding, which
presents a large barrier to their deployment on resource-constrained devices.
Since such devices are where many emerging deep learning applications lie
(e.g., drones, vision-based medical technology), significant bodies of work
from both the machine learning and systems communities have attempted to
provide optimizations to accelerate DNNs. To help unify these two perspectives,
in this paper we combine machine learning and systems techniques within the
Deep Learning Acceleration Stack (DLAS), and demonstrate how these layers can
be tightly dependent on each other with an across-stack perturbation study. We
evaluate the impact on accuracy and inference time when varying different
parameters of DLAS across two datasets, seven popular DNN architectures, four
DNN compression techniques, three algorithmic primitives with sparse and dense
variants, untuned and auto-scheduled code generation, and four hardware
platforms. Our evaluation highlights how perturbations across DLAS parameters
can cause significant variation and across-stack interactions. The highest
level observation from our evaluation is that the model size, accuracy, and
inference time are not guaranteed to be correlated. Overall we make 13 key
observations, including that speedups provided by compression techniques are
very hardware dependent, and that compiler auto-tuning can significantly alter
what the best algorithm to use for a given configuration is. With DLAS, we aim
to provide a reference framework to aid machine learning and systems
practitioners in reasoning about the context in which their respective DNN
acceleration solutions exist in. With our evaluation strongly motivating the
need for co-design, we believe that DLAS can be a valuable concept for
exploring the next generation of co-designed accelerated deep learning
solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gibson_P/0/1/0/all/0/1&quot;&gt;Perry Gibson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cano_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Cano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crowley_E/0/1/0/all/0/1&quot;&gt;Elliot J. Crowley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1&quot;&gt;Amos Storkey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OBoyle_M/0/1/0/all/0/1&quot;&gt;Michael O&amp;#x27;Boyle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08914">
<title>Efficiently Escaping Saddle Points for Non-Convex Policy Optimization. (arXiv:2311.08914v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08914</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy gradient (PG) is widely used in reinforcement learning due to its
scalability and good performance. In recent years, several variance-reduced PG
methods have been proposed with a theoretical guarantee of converging to an
approximate first-order stationary point (FOSP) with the sample complexity of
$O(\epsilon^{-3})$. However, FOSPs could be bad local optima or saddle points.
Moreover, these algorithms often use importance sampling (IS) weights which
could impair the statistical effectiveness of variance reduction. In this
paper, we propose a variance-reduced second-order method that uses second-order
information in the form of Hessian vector products (HVP) and converges to an
approximate second-order stationary point (SOSP) with sample complexity of
$\tilde{O}(\epsilon^{-3})$. This rate improves the best-known sample complexity
for achieving approximate SOSPs by a factor of $O(\epsilon^{-0.5})$. Moreover,
the proposed variance reduction technique bypasses IS weights by using HVP
terms. Our experimental results show that the proposed algorithm outperforms
the state of the art and is more robust to changes in random seeds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khorasani_S/0/1/0/all/0/1&quot;&gt;Sadegh Khorasani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salehkaleybar_S/0/1/0/all/0/1&quot;&gt;Saber Salehkaleybar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1&quot;&gt;Negar Kiyavash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1&quot;&gt;Niao He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grossglauser_M/0/1/0/all/0/1&quot;&gt;Matthias Grossglauser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08935">
<title>Supported Trust Region Optimization for Offline Reinforcement Learning. (arXiv:2311.08935v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08935</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline reinforcement learning suffers from the out-of-distribution issue and
extrapolation error. Most policy constraint methods regularize the density of
the trained policy towards the behavior policy, which is too restrictive in
most cases. We propose Supported Trust Region optimization (STR) which performs
trust region policy optimization with the policy constrained within the support
of the behavior policy, enjoying the less restrictive support constraint. We
show that, when assuming no approximation and sampling error, STR guarantees
strict policy improvement until convergence to the optimal support-constrained
policy in the dataset. Further with both errors incorporated, STR still
guarantees safe policy improvement for each step. Empirical results validate
the theory of STR and demonstrate its state-of-the-art performance on MuJoCo
locomotion domains and much more challenging AntMaze domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1&quot;&gt;Yixiu Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongchang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1&quot;&gt;Xiangyang Ji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08936">
<title>Confident Naturalness Explanation (CNE): A Framework to Explain and Assess Patterns Forming Naturalness. (arXiv:2311.08936v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08936</link>
<description rdf:parseType="Literal">&lt;p&gt;Protected natural areas are regions that have been minimally affected by
human activities such as urbanization, agriculture, and other human
interventions. To better understand and map the naturalness of these areas,
machine learning models can be used to analyze satellite imagery. Specifically,
explainable machine learning methods show promise in uncovering patterns that
contribute to the concept of naturalness within these protected environments.
Additionally, addressing the uncertainty inherent in machine learning models is
crucial for a comprehensive understanding of this concept. However, existing
approaches have limitations. They either fail to provide explanations that are
both valid and objective or struggle to offer a quantitative metric that
accurately measures the contribution of specific patterns to naturalness, along
with the associated confidence. In this paper, we propose a novel framework
called the Confident Naturalness Explanation (CNE) framework. This framework
combines explainable machine learning and uncertainty quantification to assess
and explain naturalness. We introduce a new quantitative metric that describes
the confident contribution of patterns to the concept of naturalness.
Furthermore, we generate an uncertainty-aware segmentation mask for each input
sample, highlighting areas where the model lacks knowledge. To demonstrate the
effectiveness of our framework, we apply it to a study site in Fennoscandia
using two open-source satellite datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emam_A/0/1/0/all/0/1&quot;&gt;Ahmed Emam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farag_M/0/1/0/all/0/1&quot;&gt;Mohamed Farag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roscher_R/0/1/0/all/0/1&quot;&gt;Ribana Roscher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08945">
<title>A Single-Loop Algorithm for Decentralized Bilevel Optimization. (arXiv:2311.08945v1 [math.OC])</title>
<link>http://arxiv.org/abs/2311.08945</link>
<description rdf:parseType="Literal">&lt;p&gt;Bilevel optimization has received more and more attention recently due to its
wide applications in machine learning. In this paper, we consider bilevel
optimization in decentralized networks. In particular, we propose a novel
single-loop algorithm for solving decentralized bilevel optimization with
strongly convex lower level problem. Our algorithm is fully single-loop and
does not require heavy matrix-vector multiplications when approximating the
hypergradient. Moreover, unlike existing methods for decentralized bilevel
optimization and federated bilevel optimization, our algorithm does not require
any gradient heterogeneity assumption. Our analysis shows that the proposed
algorithm achieves the best known convergence rate for bilevel optimization
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Youran Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shiqian Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Junfeng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yin_C/0/1/0/all/0/1&quot;&gt;Chao Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08949">
<title>Automated Volume Corrected Mitotic Index Calculation Through Annotation-Free Deep Learning using Immunohistochemistry as Reference Standard. (arXiv:2311.08949v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.08949</link>
<description rdf:parseType="Literal">&lt;p&gt;The volume-corrected mitotic index (M/V-Index) was shown to provide
prognostic value in invasive breast carcinomas. However, despite its prognostic
significance, it is not established as the standard method for assessing
aggressive biological behaviour, due to the high additional workload associated
with determining the epithelial proportion. In this work, we show that using a
deep learning pipeline solely trained with an annotation-free,
immunohistochemistry-based approach, provides accurate estimations of
epithelial segmentation in canine breast carcinomas. We compare our automatic
framework with the manually annotated M/V-Index in a study with three
board-certified pathologists. Our results indicate that the deep learning-based
pipeline shows expert-level performance, while providing time efficiency and
reproducibility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ammeling_J/0/1/0/all/0/1&quot;&gt;Jonas Ammeling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hecker_M/0/1/0/all/0/1&quot;&gt;Moritz Hecker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ganz_J/0/1/0/all/0/1&quot;&gt;Jonathan Ganz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Donovan_T/0/1/0/all/0/1&quot;&gt;Taryn A. Donovan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bertram_C/0/1/0/all/0/1&quot;&gt;Christof A. Bertram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Breininger_K/0/1/0/all/0/1&quot;&gt;Katharina Breininger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Aubreville_M/0/1/0/all/0/1&quot;&gt;Marc Aubreville&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08972">
<title>Unsupervised approaches based on optimal transport and convex analysis for inverse problems in imaging. (arXiv:2311.08972v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.08972</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised deep learning approaches have recently become one of the crucial
research areas in imaging owing to their ability to learn expressive and
powerful reconstruction operators even when paired high-quality training data
is scarcely available. In this chapter, we review theoretically principled
unsupervised learning schemes for solving imaging inverse problems, with a
particular focus on methods rooted in optimal transport and convex analysis. We
begin by reviewing the optimal transport-based unsupervised approaches such as
the cycle-consistency-based models and learned adversarial regularization
methods, which have clear probabilistic interpretations. Subsequently, we give
an overview of a recent line of works on provably convergent learned
optimization algorithms applied to accelerate the solution of imaging inverse
problems, alongside their dedicated unsupervised training schemes. We also
survey a number of provably convergent plug-and-play algorithms (based on
gradient-step deep denoisers), which are among the most important and widely
applied unsupervised approaches for imaging problems. At the end of this
survey, we provide an overview of a few related unsupervised learning
frameworks that complement our focused schemes. Together with a detailed
survey, we provide an overview of the key mathematical results that underlie
the methods reviewed in the chapter to keep our discussion self-contained.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carioni_M/0/1/0/all/0/1&quot;&gt;Marcello Carioni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1&quot;&gt;Subhadip Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1&quot;&gt;Hong Ye Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Junqi Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08978">
<title>Probability of Collision of satellites and space debris for short-term encounters: Rederivation and fast-to-compute upper and lower bounds. (arXiv:2311.08978v1 [astro-ph.EP])</title>
<link>http://arxiv.org/abs/2311.08978</link>
<description rdf:parseType="Literal">&lt;p&gt;The proliferation of space debris in LEO has become a major concern for the
space industry. With the growing interest in space exploration, the prediction
of potential collisions between objects in orbit has become a crucial issue. It
is estimated that, in orbit, there are millions of fragments a few millimeters
in size and thousands of inoperative satellites and discarded rocket stages.
Given the high speeds that these fragments can reach, even fragments a few
millimeters in size can cause fractures in a satellite&apos;s hull or put a serious
crack in the window of a space shuttle. The conventional method proposed by
Akella and Alfriend in 2000 remains widely used to estimate the probability of
collision in short-term encounters. Given the small period of time, it is
assumed that, during the encounter: (1) trajectories are represented by
straight lines with constant velocity; (2) there is no velocity uncertainty and
the position exhibits a stationary distribution throughout the encounter; and
(3) position uncertainties are independent and represented by Gaussian
distributions. This study introduces a novel derivation based on first
principles that naturally allows for tight and fast upper and lower bounds for
the probability of collision. We tested implementations of both probability and
bound computations with the original and our formulation on a real CDM dataset
used in ESA&apos;s Collision Avoidance Challenge. Our approach reduces the
calculation of the probability to two one-dimensional integrals and has the
potential to significantly reduce the processing time compared to the
traditional method, from 80% to nearly real-time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Ferreira_R/0/1/0/all/0/1&quot;&gt;Ricardo Ferreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Soares_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe1;udia Soares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Guimaraes_M/0/1/0/all/0/1&quot;&gt;Marta Guimar&amp;#xe3;es&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08979">
<title>A Multimodal Dataset of 21,412 Recorded Nights for Sleep and Respiratory Research. (arXiv:2311.08979v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.08979</link>
<description rdf:parseType="Literal">&lt;p&gt;This study introduces a novel, rich dataset obtained from home sleep apnea
tests using the FDA-approved WatchPAT-300 device, collected from 7,077
participants over 21,412 nights. The dataset comprises three levels of sleep
data: raw multi-channel time-series from sensors, annotated sleep events, and
computed summary statistics, which include 447 features related to sleep
architecture, sleep apnea, and heart rate variability (HRV). We present
reference values for Apnea/Hypopnea Index (AHI), sleep efficiency, Wake After
Sleep Onset (WASO), and HRV sample entropy, stratified by age and sex.
Moreover, we demonstrate that the dataset improves the predictive capability
for various health related traits, including body composition, bone density,
blood sugar levels and cardiovascular health. These results illustrate the
dataset&apos;s potential to advance sleep research, personalized healthcare, and
machine learning applications in biomedicine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diament_A/0/1/0/all/0/1&quot;&gt;Alon Diament&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorodetski_M/0/1/0/all/0/1&quot;&gt;Maria Gorodetski&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jankelow_A/0/1/0/all/0/1&quot;&gt;Adam Jankelow&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keshet_A/0/1/0/all/0/1&quot;&gt;Ayya Keshet&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shor_T/0/1/0/all/0/1&quot;&gt;Tal Shor&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weissglas_Volkov_D/0/1/0/all/0/1&quot;&gt;Daphna Weissglas-Volkov&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossman_H/0/1/0/all/0/1&quot;&gt;Hagai Rossman&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Segal_E/0/1/0/all/0/1&quot;&gt;Eran Segal&lt;/a&gt; (2) ((1) Pheno.AI, Tel-Aviv, Israel, (2) Weizmann Institute of Science, Rehovot, Israel)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08990">
<title>sQUlearn $\unicode{x2013}$ A Python Library for Quantum Machine Learning. (arXiv:2311.08990v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2311.08990</link>
<description rdf:parseType="Literal">&lt;p&gt;sQUlearn introduces a user-friendly, NISQ-ready Python library for quantum
machine learning (QML), designed for seamless integration with classical
machine learning tools like scikit-learn. The library&apos;s dual-layer architecture
serves both QML researchers and practitioners, enabling efficient prototyping,
experimentation, and pipelining. sQUlearn provides a comprehensive toolset that
includes both quantum kernel methods and quantum neural networks, along with
features like customizable data encoding strategies, automated execution
handling, and specialized kernel regularization techniques. By focusing on
NISQ-compatibility and end-to-end automation, sQUlearn aims to bridge the gap
between current quantum computing capabilities and practical machine learning
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kreplin_D/0/1/0/all/0/1&quot;&gt;David A. Kreplin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Willmann_M/0/1/0/all/0/1&quot;&gt;Moritz Willmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Schnabel_J/0/1/0/all/0/1&quot;&gt;Jan Schnabel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rapp_F/0/1/0/all/0/1&quot;&gt;Frederic Rapp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Roth_M/0/1/0/all/0/1&quot;&gt;Marco Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09006">
<title>Data Similarity is Not Enough to Explain Language Model Performance. (arXiv:2311.09006v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.09006</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models achieve high performance on many but not all downstream
tasks. The interaction between pretraining data and task data is commonly
assumed to determine this variance: a task with data that is more similar to a
model&apos;s pretraining data is assumed to be easier for that model. We test
whether distributional and example-specific similarity measures (embedding-,
token- and model-based) correlate with language model performance through a
large-scale comparison of the Pile and C4 pretraining datasets with downstream
benchmarks. Similarity correlates with performance for multilingual datasets,
but in other benchmarks, we surprisingly find that similarity metrics are not
correlated with accuracy or even each other. This suggests that the
relationship between pretraining data and downstream tasks is more complex than
often assumed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yauney_G/0/1/0/all/0/1&quot;&gt;Gregory Yauney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reif_E/0/1/0/all/0/1&quot;&gt;Emily Reif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mimno_D/0/1/0/all/0/1&quot;&gt;David Mimno&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09014">
<title>Adversarial Attacks to Reward Machine-based Reinforcement Learning. (arXiv:2311.09014v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09014</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, Reward Machines (RMs) have stood out as a simple yet
effective automata-based formalism for exposing and exploiting task structure
in reinforcement learning settings. Despite their relevance, little to no
attention has been directed to the study of their security implications and
robustness to adversarial scenarios, likely due to their recent appearance in
the literature. With my thesis, I aim to provide the first analysis of the
security of RM-based reinforcement learning techniques, with the hope of
motivating further research in the field, and I propose and evaluate a novel
class of attacks on RM-based techniques: blinding attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nodari_L/0/1/0/all/0/1&quot;&gt;Lorenzo Nodari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09017">
<title>Semidefinite programs simulate approximate message passing robustly. (arXiv:2311.09017v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2311.09017</link>
<description rdf:parseType="Literal">&lt;p&gt;Approximate message passing (AMP) is a family of iterative algorithms that
generalize matrix power iteration. AMP algorithms are known to optimally solve
many average-case optimization problems. In this paper, we show that a large
class of AMP algorithms can be simulated in polynomial time by \emph{local
statistics hierarchy} semidefinite programs (SDPs), even when an unknown
principal minor of measure $1/\mathrm{polylog}(\mathrm{dimension})$ is
adversarially corrupted. Ours are the first robust guarantees for many of these
problems. Further, our results offer an interesting counterpoint to strong
lower bounds against less constrained SDP relaxations for average-case
max-cut-gain (a.k.a. &quot;optimizing the Sherrington-Kirkpatrick Hamiltonian&quot;) and
other problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivkov_M/0/1/0/all/0/1&quot;&gt;Misha Ivkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schramm_T/0/1/0/all/0/1&quot;&gt;Tselil Schramm&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09018">
<title>On the Foundation of Distributionally Robust Reinforcement Learning. (arXiv:2311.09018v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09018</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the need for a robust policy in the face of environment shifts
between training and the deployment, we contribute to the theoretical
foundation of distributionally robust reinforcement learning (DRRL). This is
accomplished through a comprehensive modeling framework centered around
distributionally robust Markov decision processes (DRMDPs). This framework
obliges the decision maker to choose an optimal policy under the worst-case
distributional shift orchestrated by an adversary. By unifying and extending
existing formulations, we rigorously construct DRMDPs that embraces various
modeling attributes for both the decision maker and the adversary. These
attributes include adaptability granularity, exploring history-dependent,
Markov, and Markov time-homogeneous decision maker and adversary dynamics.
Additionally, we delve into the flexibility of shifts induced by the adversary,
examining SA and S-rectangularity. Within this DRMDP framework, we investigate
conditions for the existence or absence of the dynamic programming principle
(DPP). From an algorithmic standpoint, the existence of DPP holds significant
implications, as the vast majority of existing data and computationally
efficiency RL algorithms are reliant on the DPP. To study its existence, we
comprehensively examine combinations of controller and adversary attributes,
providing streamlined proofs grounded in a unified methodology. We also offer
counterexamples for settings in which a DPP with full generality is absent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shengbo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Si_N/0/1/0/all/0/1&quot;&gt;Nian Si&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blanchet_J/0/1/0/all/0/1&quot;&gt;Jose Blanchet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhengyuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09027">
<title>Assessing the Robustness of Intelligence-Driven Reinforcement Learning. (arXiv:2311.09027v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09027</link>
<description rdf:parseType="Literal">&lt;p&gt;Robustness to noise is of utmost importance in reinforcement learning
systems, particularly in military contexts where high stakes and uncertain
environments prevail. Noise and uncertainty are inherent features of military
operations, arising from factors such as incomplete information, adversarial
actions, or unpredictable battlefield conditions. In RL, noise can critically
impact decision-making, mission success, and the safety of personnel. Reward
machines offer a powerful tool to express complex reward structures in RL
tasks, enabling the design of tailored reinforcement signals that align with
mission objectives. This paper considers the problem of the robustness of
intelligence-driven reinforcement learning based on reward machines. The
preliminary results presented suggest the need for further research in
evidential reasoning and learning to harden current state-of-the-art
reinforcement learning approaches before being mission-critical-ready.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nodari_L/0/1/0/all/0/1&quot;&gt;Lorenzo Nodari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cerutti_F/0/1/0/all/0/1&quot;&gt;Federico Cerutti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09058">
<title>New Horizons in Parameter Regularization: A Constraint Approach. (arXiv:2311.09058v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09058</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents constrained parameter regularization (CPR), an alternative
to traditional weight decay. Instead of applying a constant penalty uniformly
to all parameters, we enforce an upper bound on a statistical measure (e.g.,
the L$_2$-norm) of individual parameter groups. This reformulates learning as a
constrained optimization problem. To solve this, we utilize an adaptation of
the augmented Lagrangian method. Our approach allows for varying regularization
strengths across different parameter groups, removing the need for explicit
penalty coefficients in the regularization terms. CPR only requires two
hyperparameters and introduces no measurable runtime overhead. We offer
empirical evidence of CPR&apos;s effectiveness through experiments in the &quot;grokking&quot;
phenomenon, image classification, and language modeling. Our findings show that
CPR can counteract the effects of grokking, and it consistently matches or
surpasses the performance of traditional weight decay.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franke_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rg K.H. Franke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hefenbrock_M/0/1/0/all/0/1&quot;&gt;Michael Hefenbrock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koehler_G/0/1/0/all/0/1&quot;&gt;Gregor Koehler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09064">
<title>Imagine the Unseen World: A Benchmark for Systematic Generalization in Visual World Models. (arXiv:2311.09064v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.09064</link>
<description rdf:parseType="Literal">&lt;p&gt;Systematic compositionality, or the ability to adapt to novel situations by
creating a mental model of the world using reusable pieces of knowledge,
remains a significant challenge in machine learning. While there has been
considerable progress in the language domain, efforts towards systematic visual
imagination, or envisioning the dynamical implications of a visual observation,
are in their infancy. We introduce the Systematic Visual Imagination Benchmark
(SVIB), the first benchmark designed to address this problem head-on. SVIB
offers a novel framework for a minimal world modeling problem, where models are
evaluated based on their ability to generate one-step image-to-image
transformations under a latent world dynamics. The framework provides benefits
such as the possibility to jointly optimize for systematic perception and
imagination, a range of difficulty levels, and the ability to control the
fraction of possible factor combinations used during training. We provide a
comprehensive evaluation of various baseline models on SVIB, offering insight
into the current state-of-the-art in systematic visual imagination. We hope
that this benchmark will help advance visual systematic compositionality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yeongbin Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1&quot;&gt;Gautam Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Junyeong Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gulcehre_C/0/1/0/all/0/1&quot;&gt;Caglar Gulcehre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1&quot;&gt;Sungjin Ahn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09065">
<title>Damped Proximal Augmented Lagrangian Method for weakly-Convex Problems with Convex Constraints. (arXiv:2311.09065v1 [math.OC])</title>
<link>http://arxiv.org/abs/2311.09065</link>
<description rdf:parseType="Literal">&lt;p&gt;We give a damped proximal augmented Lagrangian method (DPALM) for solving
problems with a weakly-convex objective and convex linear/nonlinear
constraints. Instead of taking a full stepsize, DPALM adopts a damped dual
stepsize to ensure the boundedness of dual iterates. We show that DPALM can
produce a (near) $\vareps$-KKT point within $O(\vareps^{-2})$ outer iterations
if each DPALM subproblem is solved to a proper accuracy. In addition, we
establish overall iteration complexity of DPALM when the objective is either a
regularized smooth function or in a regularized compositional form. For the
former case, DPALM achieves the complexity of
$\widetilde{\mathcal{O}}\left(\varepsilon^{-2.5} \right)$ to produce an
$\varepsilon$-KKT point by applying an accelerated proximal gradient (APG)
method to each DPALM subproblem. For the latter case, the complexity of DPALM
is $\widetilde{\mathcal{O}}\left(\varepsilon^{-3} \right)$ to produce a near
$\varepsilon$-KKT point by using an APG to solve a Moreau-envelope smoothed
version of each subproblem. Our outer iteration complexity and the overall
complexity either generalize existing best ones from unconstrained or
linear-constrained problems to convex-constrained ones, or improve over the
best-known results on solving the same-structured problems. Furthermore,
numerical experiments on linearly/quadratically constrained non-convex
quadratic programs and linear-constrained robust nonlinear least squares are
conducted to demonstrate the empirical efficiency of the proposed DPALM over
several state-of-the art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dahal_H/0/1/0/all/0/1&quot;&gt;Hari Dahal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yangyang Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09068">
<title>Learning Fair Division from Bandit Feedback. (arXiv:2311.09068v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09068</link>
<description rdf:parseType="Literal">&lt;p&gt;This work addresses learning online fair division under uncertainty, where a
central planner sequentially allocates items without precise knowledge of
agents&apos; values or utilities. Departing from conventional online algorithm, the
planner here relies on noisy, estimated values obtained after allocating items.
We introduce wrapper algorithms utilizing \textit{dual averaging}, enabling
gradual learning of both the type distribution of arriving items and agents&apos;
values through bandit feedback. This approach enables the algorithms to
asymptotically achieve optimal Nash social welfare in linear Fisher markets
with agents having additive utilities. We establish regret bounds in Nash
social welfare and empirically validate the superior performance of our
proposed algorithms across synthetic and empirical datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamada_H/0/1/0/all/0/1&quot;&gt;Hakuei Yamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komiyama_J/0/1/0/all/0/1&quot;&gt;Junpei Komiyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abe_K/0/1/0/all/0/1&quot;&gt;Kenshi Abe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwasaki_A/0/1/0/all/0/1&quot;&gt;Atsushi Iwasaki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09101">
<title>Towards A Unified View of Answer Calibration for Multi-Step Reasoning. (arXiv:2311.09101v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.09101</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) employing Chain-of-Thought (CoT) prompting have
broadened the scope for improving multi-step reasoning capabilities. Usually,
answer calibration strategies such as step-level or path-level calibration play
a vital role in multi-step reasoning. While effective, there remains a
significant gap in our understanding of the key factors that drive their
success. In this paper, we break down the design of recent answer calibration
strategies and present a unified view which establishes connections between
them. We then conduct a thorough evaluation on these strategies from a unified
view, systematically scrutinizing step-level and path-level answer calibration
across multiple paths. Our study holds the potential to illuminate key insights
for optimizing multi-step reasoning with answer calibration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1&quot;&gt;Shumin Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1&quot;&gt;Ningyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oo_N/0/1/0/all/0/1&quot;&gt;Nay Oo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1&quot;&gt;Bryan Hooi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09109">
<title>Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge Graph Completion?. (arXiv:2311.09109v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.09109</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graphs (KGs) consist of links that describe relationships between
entities. Due to the difficulty of manually enumerating all relationships
between entities, automatically completing them is essential for KGs. Knowledge
Graph Completion (KGC) is a task that infers unseen relationships between
entities in a KG. Traditional embedding-based KGC methods, such as RESCAL,
TransE, DistMult, ComplEx, RotatE, HAKE, HousE, etc., infer missing links using
only the knowledge from training data. In contrast, the recent Pre-trained
Language Model (PLM)-based KGC utilizes knowledge obtained during pre-training.
Therefore, PLM-based KGC can estimate missing links between entities by reusing
memorized knowledge from pre-training without inference. This approach is
problematic because building KGC models aims to infer unseen links between
entities. However, conventional evaluations in KGC do not consider inference
and memorization abilities separately. Thus, a PLM-based KGC method, which
achieves high performance in current KGC evaluations, may be ineffective in
practical applications. To address this issue, we analyze whether PLM-based KGC
methods make inferences or merely access memorized knowledge. For this purpose,
we propose a method for constructing synthetic datasets specified in this
analysis and conclude that PLMs acquire the inference abilities required for
KGC through pre-training, even though the performance improvements mostly come
from textual information of entities and relations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sakai_Y/0/1/0/all/0/1&quot;&gt;Yusuke Sakai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamigaito_H/0/1/0/all/0/1&quot;&gt;Hidetaka Kamigaito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayashi_K/0/1/0/all/0/1&quot;&gt;Katsuhiko Hayashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1&quot;&gt;Taro Watanabe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09114">
<title>Ever: Mitigating Hallucination in Large Language Models through Real-Time Verification and Rectification. (arXiv:2311.09114v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.09114</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have demonstrated remarkable proficiency in
generating fluent text. However, they often encounter the challenge of
generating inaccurate or hallucinated content. This issue is common in both
non-retrieval-based generation and retrieval-augmented generation approaches,
and existing post-hoc rectification methods may not address the accumulated
hallucination errors that may be caused by the &quot;snowballing&quot; issue, especially
in reasoning tasks. To tackle these challenges, we introduce a novel approach
called Real-time Verification and Rectification (Ever). Instead of waiting
until the end of the generation process to rectify hallucinations, Ever employs
a real-time, step-wise generation and hallucination rectification strategy. The
primary objective is to detect and rectify hallucinations as they occur during
the text generation process. When compared to both retrieval-based and
non-retrieval-based baselines, Ever demonstrates a significant improvement in
generating trustworthy and factually accurate text across a diverse range of
tasks, including short-form QA, biography generation, and multi-hop reasoning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1&quot;&gt;Haoqiang Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1&quot;&gt;Juntong Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1&quot;&gt;Huaxiu Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09115">
<title>HEALNet -- Hybrid Multi-Modal Fusion for Heterogeneous Biomedical Data. (arXiv:2311.09115v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09115</link>
<description rdf:parseType="Literal">&lt;p&gt;Technological advances in medical data collection such as high-resolution
histopathology and high-throughput genomic sequencing have contributed to the
rising requirement for multi-modal biomedical modelling, specifically for
image, tabular, and graph data. Most multi-modal deep learning approaches use
modality-specific architectures that are trained separately and cannot capture
the crucial cross-modal information that motivates the integration of different
data sources. This paper presents the Hybrid Early-fusion Attention Learning
Network (HEALNet): a flexible multi-modal fusion architecture, which a)
preserves modality-specific structural information, b) captures the cross-modal
interactions and structural information in a shared latent space, c) can
effectively handle missing modalities during training and inference, and d)
enables intuitive model inspection by learning on the raw data input instead of
opaque embeddings. We conduct multi-modal survival analysis on Whole Slide
Images and Multi-omic data on four cancer cohorts of The Cancer Genome Atlas
(TCGA). HEALNet achieves state-of-the-art performance, substantially improving
over both uni-modal and recent multi-modal baselines, whilst being robust in
scenarios with missing modalities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemker_K/0/1/0/all/0/1&quot;&gt;Konstantin Hemker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smidjievski_N/0/1/0/all/0/1&quot;&gt;Nikola Smidjievski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamnik_M/0/1/0/all/0/1&quot;&gt;Mateja Jamnik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09127">
<title>Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts. (arXiv:2311.09127v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2311.09127</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing work on jailbreak Multimodal Large Language Models (MLLMs) has
focused primarily on adversarial examples in model inputs, with less attention
to vulnerabilities in model APIs. To fill the research gap, we carry out the
following work: 1) We discover a system prompt leakage vulnerability in GPT-4V.
Through carefully designed dialogue, we successfully steal the internal system
prompts of GPT-4V. This finding indicates potential exploitable security risks
in MLLMs; 2)Based on the acquired system prompts, we propose a novel MLLM
jailbreaking attack method termed SASP (Self-Adversarial Attack via System
Prompt). By employing GPT-4 as a red teaming tool against itself, we aim to
search for potential jailbreak prompts leveraging stolen system prompts.
Furthermore, in pursuit of better performance, we also add human modification
based on GPT-4&apos;s analysis, which further improves the attack success rate to
98.7\%; 3) We evaluated the effect of modifying system prompts to defend
against jailbreaking attacks. Results show that appropriately designed system
prompts can significantly reduce jailbreak success rates. Overall, our work
provides new insights into enhancing MLLM security, demonstrating the important
role of system prompts in jailbreaking, which could be leveraged to greatly
facilitate jailbreak success rates while also holding the potential for
defending against jailbreaks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yuanwei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yixin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1&quot;&gt;Pan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Lichao Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09128">
<title>Fast Detection of Phase Transitions with Multi-Task Learning-by-Confusion. (arXiv:2311.09128v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09128</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning has been successfully used to study phase transitions. One
of the most popular approaches to identifying critical points from data without
prior knowledge of the underlying phases is the learning-by-confusion scheme.
As input, it requires system samples drawn from a grid of the parameter whose
change is associated with potential phase transitions. Up to now, the scheme
required training a distinct binary classifier for each possible splitting of
the grid into two sides, resulting in a computational cost that scales linearly
with the number of grid points. In this work, we propose and showcase an
alternative implementation that only requires the training of a single
multi-class classifier. Ideally, such multi-task learning eliminates the
scaling with respect to the number of grid points. In applications to the Ising
model and an image dataset generated with Stable Diffusion, we find significant
speedups that closely correspond to the ideal case, with only minor deviations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arnold_J/0/1/0/all/0/1&quot;&gt;Julian Arnold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schafer_F/0/1/0/all/0/1&quot;&gt;Frank Sch&amp;#xe4;fer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lorch_N/0/1/0/all/0/1&quot;&gt;Niels L&amp;#xf6;rch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09137">
<title>Causal prediction models for medication safety monitoring: The diagnosis of vancomycin-induced acute kidney injury. (arXiv:2311.09137v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09137</link>
<description rdf:parseType="Literal">&lt;p&gt;The current best practice approach for the retrospective diagnosis of adverse
drug events (ADEs) in hospitalized patients relies on a full patient chart
review and a formal causality assessment by multiple medical experts. This
evaluation serves to qualitatively estimate the probability of causation (PC);
the probability that a drug was a necessary cause of an adverse event. This
practice is manual, resource intensive and prone to human biases, and may thus
benefit from data-driven decision support. Here, we pioneer a causal modeling
approach using observational data to estimate a lower bound of the PC
(PC$_{low}$). This method includes two key causal inference components: (1) the
target trial emulation framework and (2) estimation of individualized treatment
effects using machine learning. We apply our method to the clinically relevant
use-case of vancomycin-induced acute kidney injury in intensive care patients,
and compare our causal model-based PC$_{low}$ estimates to qualitative
estimates of the PC provided by a medical expert. Important limitations and
potential improvements are discussed, and we conclude that future improved
causal models could provide essential data-driven support for medication safety
monitoring in hospitalized patients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kom_I/0/1/0/all/0/1&quot;&gt;Izak Yasrebi-de Kom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klopotowska_J/0/1/0/all/0/1&quot;&gt;Joanna Klopotowska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dongelmans_D/0/1/0/all/0/1&quot;&gt;Dave Dongelmans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keizer_N/0/1/0/all/0/1&quot;&gt;Nicolette De Keizer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jager_K/0/1/0/all/0/1&quot;&gt;Kitty Jager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abu_Hanna_A/0/1/0/all/0/1&quot;&gt;Ameen Abu-Hanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cina_G/0/1/0/all/0/1&quot;&gt;Giovanni Cin&amp;#xe0;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09142">
<title>Machine-learning parameter tracking with partial state observation. (arXiv:2311.09142v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09142</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex and nonlinear dynamical systems often involve parameters that change
with time, accurate tracking of which is essential to tasks such as state
estimation, prediction, and control. Existing machine-learning methods require
full state observation of the underlying system and tacitly assume adiabatic
changes in the parameter. Formulating an inverse problem and exploiting
reservoir computing, we develop a model-free and fully data-driven framework to
accurately track time-varying parameters from partial state observation in real
time. In particular, with training data from a subset of the dynamical
variables of the system for a small number of known parameter values, the
framework is able to accurately predict the parameter variations in time. Low-
and high-dimensional, Markovian and non-Markovian nonlinear dynamical systems
are used to demonstrate the power of the machine-learning based
parameter-tracking framework. Pertinent issues affecting the tracking
performance are addressed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhai_Z/0/1/0/all/0/1&quot;&gt;Zheng-Meng Zhai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moradi_M/0/1/0/all/0/1&quot;&gt;Mohammadamin Moradi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glaz_B/0/1/0/all/0/1&quot;&gt;Bryan Glaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haile_M/0/1/0/all/0/1&quot;&gt;Mulugeta Haile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1&quot;&gt;Ying-Cheng Lai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09145">
<title>Model Agnostic Explainable Selective Regression via Uncertainty Estimation. (arXiv:2311.09145v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09145</link>
<description rdf:parseType="Literal">&lt;p&gt;With the wide adoption of machine learning techniques, requirements have
evolved beyond sheer high performance, often requiring models to be
trustworthy. A common approach to increase the trustworthiness of such systems
is to allow them to refrain from predicting. Such a framework is known as
selective prediction. While selective prediction for classification tasks has
been widely analyzed, the problem of selective regression is understudied. This
paper presents a novel approach to selective regression that utilizes
model-agnostic non-parametric uncertainty estimation. Our proposed framework
showcases superior performance compared to state-of-the-art selective
regressors, as demonstrated through comprehensive benchmarking on 69 datasets.
Finally, we use explainable AI techniques to gain an understanding of the
drivers behind selective regression. We implement our selective regression
method in the open-source Python package doubt and release the code used to
reproduce our experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pugnana_A/0/1/0/all/0/1&quot;&gt;Andrea Pugnana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mougan_C/0/1/0/all/0/1&quot;&gt;Carlos Mougan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nielsen_D/0/1/0/all/0/1&quot;&gt;Dan Saattrup Nielsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09165">
<title>Approaching adverse event detection utilizing transformers on clinical time-series. (arXiv:2311.09165v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09165</link>
<description rdf:parseType="Literal">&lt;p&gt;Patients being admitted to a hospital will most often be associated with a
certain clinical development during their stay. However, there is always a risk
of patients being subject to the wrong diagnosis or to a certain treatment not
pertaining to the desired effect, potentially leading to adverse events. Our
research aims to develop an anomaly detection system for identifying deviations
from expected clinical trajectories. To address this goal we analyzed 16 months
of vital sign recordings obtained from the Nordland Hospital Trust (NHT). We
employed an self-supervised framework based on the STraTS transformer
architecture to represent the time series data in a latent space. These
representations were then subjected to various clustering techniques to explore
potential patient phenotypes based on their clinical progress. While our
preliminary results from this ongoing research are promising, they underscore
the importance of enhancing the dataset with additional demographic information
from patients. This additional data will be crucial for a more comprehensive
evaluation of the method&apos;s performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fredriksen_H/0/1/0/all/0/1&quot;&gt;Helge Fredriksen&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burman_P/0/1/0/all/0/1&quot;&gt;Per Joel Burman&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woldaregay_A/0/1/0/all/0/1&quot;&gt;Ashenafi Woldaregay&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikalsen_K/0/1/0/all/0/1&quot;&gt;Karl &amp;#xd8;yvind Mikalsen&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nymo_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe5;le Nymo&lt;/a&gt; (3) ((1) UiT - The Arctic University of Norway, (2) The Norwegian Centre for Clinical Artificial Intelligence, (3) Nordland Hospital Trust)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09184">
<title>Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization. (arXiv:2311.09184v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.09184</link>
<description rdf:parseType="Literal">&lt;p&gt;While large language models (LLMs) already achieve strong performance on
standard generic summarization benchmarks, their performance on more complex
summarization task settings is less studied. Therefore, we benchmark LLMs on
instruction controllable text summarization, where the model input consists of
both a source article and a natural language requirement for the desired
summary characteristics. To this end, we curate an evaluation-only dataset for
this task setting and conduct human evaluation on 5 LLM-based summarization
systems. We then benchmark LLM-based automatic evaluation for this task with 4
different evaluation protocols and 11 LLMs, resulting in 40 evaluation methods
in total. Our study reveals that instruction controllable text summarization
remains a challenging task for LLMs, since (1) all LLMs evaluated still make
factual and other types of errors in their summaries; (2) all LLM-based
evaluation methods cannot achieve a strong alignment with human annotators when
judging the quality of candidate summaries; (3) different LLMs show large
performance gaps in summary generation and evaluation. We make our collected
benchmark, InstruSum, publicly available to facilitate future research in this
direction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yixin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1&quot;&gt;Alexander R. Fabbri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiawen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yilun Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Simeng Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1&quot;&gt;Shafiq Joty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1&quot;&gt;Pengfei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1&quot;&gt;Dragomir Radev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chien-Sheng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1&quot;&gt;Arman Cohan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09188">
<title>Towards Verifiable Text Generation with Symbolic References. (arXiv:2311.09188v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.09188</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have demonstrated an impressive ability to
synthesize plausible and fluent text. However they remain vulnerable to
hallucinations, and thus their outputs generally require manual human
verification for high-stakes applications, which can be time-consuming and
difficult. This paper proposes symbolically grounded generation (SymGen) as a
simple approach for enabling easier validation of an LLM&apos;s output. SymGen
prompts an LLM to interleave its regular output text with explicit symbolic
references to fields present in some conditioning data (e.g., a table in JSON
format). The references can be used to display the provenance of different
spans of text in the generation, reducing the effort required for manual
verification. Across data-to-text and question answering experiments, we find
that LLMs are able to directly output text that makes use of symbolic
references while maintaining fluency and accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hennigen_L/0/1/0/all/0/1&quot;&gt;Lucas Torroba Hennigen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1&quot;&gt;Shannon Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nrusimha_A/0/1/0/all/0/1&quot;&gt;Aniruddha Nrusimha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gapp_B/0/1/0/all/0/1&quot;&gt;Bernhard Gapp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1&quot;&gt;David Sontag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yoon Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09190">
<title>On the Computation of the Gaussian Rate-Distortion-Perception Function. (arXiv:2311.09190v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2311.09190</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the computation of the rate-distortion-perception
function (RDPF) for a multivariate Gaussian source under mean squared error
(MSE) distortion and, respectively, Kullback-Leibler divergence, geometric
Jensen-Shannon divergence, squared Hellinger distance, and squared
Wasserstein-2 distance perception metrics. To this end, we first characterize
the analytical bounds of the scalar Gaussian RDPF for the aforementioned
divergence functions, also providing the RDPF-achieving forward &quot;test-channel&quot;
realization. Focusing on the multivariate case, we establish that, for
tensorizable distortion and perception metrics, the optimal solution resides on
the vector space spanned by the eigenvector of the source covariance matrix.
Consequently, the multivariate optimization problem can be expressed as a
function of the scalar Gaussian RDPFs of the source marginals, constrained by
global distortion and perception levels. Leveraging this characterization, we
design an alternating minimization scheme based on the block nonlinear
Gauss-Seidel method, which optimally solves the problem while identifying the
Gaussian RDPF-achieving realization. Furthermore, the associated algorithmic
embodiment is provided, as well as the convergence and the rate of convergence
characterization. Lastly, for the &quot;perfect realism&quot; regime, the analytical
solution for the multivariate Gaussian RDPF is obtained. We corroborate our
results with numerical simulations and draw connections to existing results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serra_G/0/1/0/all/0/1&quot;&gt;Giuseppe Serra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stavrou_P/0/1/0/all/0/1&quot;&gt;Photios A. Stavrou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kountouris_M/0/1/0/all/0/1&quot;&gt;Marios Kountouris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09195">
<title>Self-Supervised Curriculum Generation for Autonomous Reinforcement Learning without Task-Specific Knowledge. (arXiv:2311.09195v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09195</link>
<description rdf:parseType="Literal">&lt;p&gt;A significant bottleneck in applying current reinforcement learning
algorithms to real-world scenarios is the need to reset the environment between
every episode. This reset process demands substantial human intervention,
making it difficult for the agent to learn continuously and autonomously.
Several recent works have introduced autonomous reinforcement learning (ARL)
algorithms that generate curricula for jointly training reset and forward
policies. While their curricula can reduce the number of required manual resets
by taking into account the agent&apos;s learning progress, they rely on
task-specific knowledge, such as predefined initial states or reset reward
functions. In this paper, we propose a novel ARL algorithm that can generate a
curriculum adaptive to the agent&apos;s learning progress without task-specific
knowledge. Our curriculum empowers the agent to autonomously reset to diverse
and informative initial states. To achieve this, we introduce a success
discriminator that estimates the success probability from each initial state
when the agent follows the forward policy. The success discriminator is trained
with relabeled transitions in a self-supervised manner. Our experimental
results demonstrate that our ARL algorithm can generate an adaptive curriculum
and enable the agent to efficiently bootstrap to solve sparse-reward maze
navigation tasks, outperforming baselines with significantly fewer manual
resets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sang-Hyun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1&quot;&gt;Seung-Woo Seo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09197">
<title>A Unified Approach to Learning Ising Models: Beyond Independence and Bounded Width. (arXiv:2311.09197v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.09197</link>
<description rdf:parseType="Literal">&lt;p&gt;We revisit the problem of efficiently learning the underlying parameters of
Ising models from data. Current algorithmic approaches achieve essentially
optimal sample complexity when given i.i.d. samples from the stationary measure
and the underlying model satisfies &quot;width&quot; bounds on the total $\ell_1$
interaction involving each node. We show that a simple existing approach based
on node-wise logistic regression provably succeeds at recovering the underlying
model in several new settings where these assumptions are violated:
&lt;/p&gt;
&lt;p&gt;(1) Given dynamically generated data from a wide variety of local Markov
chains, like block or round-robin dynamics, logistic regression recovers the
parameters with optimal sample complexity up to $\log\log n$ factors. This
generalizes the specialized algorithm of Bresler, Gamarnik, and Shah [IEEE
Trans. Inf. Theory&apos;18] for structure recovery in bounded degree graphs from
Glauber dynamics.
&lt;/p&gt;
&lt;p&gt;(2) For the Sherrington-Kirkpatrick model of spin glasses, given
$\mathsf{poly}(n)$ independent samples, logistic regression recovers the
parameters in most of the known high-temperature regime via a simple reduction
to weaker structural properties of the measure. This improves on recent work of
Anari, Jain, Koehler, Pham, and Vuong [ArXiv&apos;23] which gives distribution
learning at higher temperature.
&lt;/p&gt;
&lt;p&gt;(3) As a simple byproduct of our techniques, logistic regression achieves an
exponential improvement in learning from samples in the M-regime of data
considered by Dutt, Lokhov, Vuffray, and Misra [ICML&apos;21] as well as novel
guarantees for learning from the adversarial Glauber dynamics of Chin, Moitra,
Mossel, and Sandon [ArXiv&apos;23].
&lt;/p&gt;
&lt;p&gt;Our approach thus significantly generalizes the elegant analysis of Wu,
Sanghavi, and Dimakis [Neurips&apos;19] without any algorithmic modification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaitonde_J/0/1/0/all/0/1&quot;&gt;Jason Gaitonde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mossel_E/0/1/0/all/0/1&quot;&gt;Elchanan Mossel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2003.04103">
<title>Flexible numerical optimization with ensmallen. (arXiv:2003.04103v4 [cs.MS] UPDATED)</title>
<link>http://arxiv.org/abs/2003.04103</link>
<description rdf:parseType="Literal">&lt;p&gt;This report provides an introduction to the ensmallen numerical optimization
library, as well as a deep dive into the technical details of how it works. The
library provides a fast and flexible C++ framework for mathematical
optimization of arbitrary user-supplied functions. A large set of pre-built
optimizers is provided, including many variants of Stochastic Gradient Descent
and Quasi-Newton optimizers. Several types of objective functions are
supported, including differentiable, separable, constrained, and categorical
objective functions. Implementation of a new optimizer requires only one
method, while a new objective function requires typically only one or two C++
methods. Through internal use of C++ template metaprogramming, ensmallen
provides support for arbitrary user-supplied callbacks and automatic inference
of unsupplied methods without any runtime overhead. Empirical comparisons show
that ensmallen outperforms other optimization frameworks (such as Julia and
SciPy), sometimes by large margins. The library is available at
https://ensmallen.org and is distributed under the permissive BSD license.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Curtin_R/0/1/0/all/0/1&quot;&gt;Ryan R. Curtin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edel_M/0/1/0/all/0/1&quot;&gt;Marcus Edel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prabhu_R/0/1/0/all/0/1&quot;&gt;Rahul Ganesh Prabhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basak_S/0/1/0/all/0/1&quot;&gt;Suryoday Basak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lou_Z/0/1/0/all/0/1&quot;&gt;Zhihao Lou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanderson_C/0/1/0/all/0/1&quot;&gt;Conrad Sanderson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.14201">
<title>CNTLS: A Benchmark Dataset for Abstractive or Extractive Chinese Timeline Summarization. (arXiv:2105.14201v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2105.14201</link>
<description rdf:parseType="Literal">&lt;p&gt;Timeline summarization (TLS) involves creating summaries of long-running
events using dated summaries from numerous news articles. However, limited data
availability has significantly slowed down the development of timeline
summarization. In this paper, we introduce the CNTLS dataset, a versatile
resource for Chinese timeline summarization. CNTLS encompasses 77 real-life
topics, each with 2524 documents and summarizes nearly 60\% days duration
compression on average all topics.
&lt;/p&gt;
&lt;p&gt;We meticulously analyze the corpus using well-known metrics, focusing on the
style of the summaries and the complexity of the summarization task.
Specifically, we evaluate the performance of various extractive and generative
summarization systems on the CNTLS corpus to provide benchmarks and support
further research. To the best of our knowledge, CNTLS is the first Chinese
timeline summarization dataset. The dataset and source code are
released\footnote{Code and data available at:
\emph{\url{https://github.com/OpenSUM/CNTLS}}.}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1&quot;&gt;Qianren Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiazheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianxin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.05410">
<title>DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection. (arXiv:2106.05410v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.05410</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-supervised anomaly detection aims to detect anomalies from normal
samples using a model that is trained on normal data. With recent advancements
in deep learning, researchers have designed efficient deep anomaly detection
methods. Existing works commonly use neural networks to map the data into a
more informative representation and then apply an anomaly detection algorithm.
In this paper, we propose a method, DASVDD, that jointly learns the parameters
of an autoencoder while minimizing the volume of an enclosing hyper-sphere on
its latent representation. We propose an anomaly score which is a combination
of autoencoder&apos;s reconstruction error and the distance from the center of the
enclosing hypersphere in the latent representation. Minimizing this anomaly
score aids us in learning the underlying distribution of the normal class
during training. Including the reconstruction error in the anomaly score
ensures that DASVDD does not suffer from the common hypersphere collapse issue
since the DASVDD model does not converge to the trivial solution of mapping all
inputs to a constant point in the latent representation. Experimental
evaluations on several benchmark datasets show that the proposed method
outperforms the commonly used state-of-the-art anomaly detection algorithms
while maintaining robust performance across different anomaly classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hojjati_H/0/1/0/all/0/1&quot;&gt;Hadi Hojjati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Armanfard_N/0/1/0/all/0/1&quot;&gt;Narges Armanfard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.03427">
<title>Deep Learning for Two-Sided Matching. (arXiv:2107.03427v2 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/2107.03427</link>
<description rdf:parseType="Literal">&lt;p&gt;We initiate the study of deep learning for the automated design of two-sided
matching mechanisms. What is of most interest is to use machine learning to
understand the possibility of new tradeoffs between strategy-proofness and
stability. These properties cannot be achieved simultaneously, but the
efficient frontier is not understood. We introduce novel differentiable
surrogates for quantifying ordinal strategy-proofness and stability and use
them to train differentiable matching mechanisms that map discrete preferences
to valid randomized matchings. We demonstrate that the efficient frontier
characterized by these learned mechanisms is substantially better than that
achievable through a convex combination of baselines of deferred acceptance
(stable and strategy-proof for only one side of the market), top trading cycles
(strategy-proof for one side, but not stable), and randomized serial
dictatorship (strategy-proof for both sides, but not stable). This gives a new
target for economic theory and opens up new possibilities for machine learning
pipelines in matching market design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravindranath_S/0/1/0/all/0/1&quot;&gt;Sai Srivatsa Ravindranath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zhe Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shira Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jonathan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kominers_S/0/1/0/all/0/1&quot;&gt;Scott D. Kominers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parkes_D/0/1/0/all/0/1&quot;&gt;David C. Parkes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.11986">
<title>Gradient Masked Averaging for Federated Learning. (arXiv:2201.11986v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2201.11986</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is an emerging paradigm that permits a large number
of clients with heterogeneous data to coordinate learning of a unified global
model without the need to share data amongst each other. A major challenge in
federated learning is the heterogeneity of data across client, which can
degrade the performance of standard FL algorithms. Standard FL algorithms
involve averaging of model parameters or gradient updates to approximate the
global model at the server. However, we argue that in heterogeneous settings,
averaging can result in information loss and lead to poor generalization due to
the bias induced by dominant client gradients. We hypothesize that to
generalize better across non-i.i.d datasets, the algorithms should focus on
learning the invariant mechanism that is constant while ignoring spurious
mechanisms that differ across clients. Inspired from recent works in
Out-of-Distribution generalization, we propose a gradient masked averaging
approach for FL as an alternative to the standard averaging of client updates.
This aggregation technique for client updates can be adapted as a drop-in
replacement in most existing federated algorithms. We perform extensive
experiments on multiple FL algorithms with in-distribution, real-world,
feature-skewed out-of-distribution, and quantity imbalanced datasets and show
that it provides consistent improvements, particularly in the case of
heterogeneous clients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenison_I/0/1/0/all/0/1&quot;&gt;Irene Tenison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sreeramadas_S/0/1/0/all/0/1&quot;&gt;Sai Aravind Sreeramadas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mugunthan_V/0/1/0/all/0/1&quot;&gt;Vaikkunth Mugunthan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1&quot;&gt;Edouard Oyallon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1&quot;&gt;Irina Rish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1&quot;&gt;Eugene Belilovsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.03279">
<title>Probabilistic Control and Majorization of Optimal Control. (arXiv:2205.03279v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.03279</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic control design is founded on the principle that a rational
agent attempts to match modelled with an arbitrary desired closed-loop system
trajectory density. The framework was originally proposed as a tractable
alternative to traditional optimal control design, parametrizing desired
behaviour through fictitious transition and policy densities and using the
information projection as a proximity measure. In this work we introduce an
alternative parametrization of desired closed-loop behaviour and explore
alternative proximity measures between densities. It is then illustrated how
the associated probabilistic control problems solve into uncertain or
probabilistic policies. Our main result is to show that the probabilistic
control objectives majorize conventional, stochastic and risk sensitive,
optimal control objectives. This observation allows us to identify two
probabilistic fixed point iterations that converge to the deterministic optimal
control policies establishing an explicit connection between either
formulations. Further we demonstrate that the risk sensitive optimal control
formulation is also technically equivalent to a Maximum Likelihood estimation
problem on a probabilistic graph model where the notion of costs is directly
encoded into the model. The associated treatment of the estimation problem is
then shown to coincide with the moment projected probabilistic control
formulation. That way optimal decision making can be reformulated as an
iterative inference problem. Based on these insights we discuss directions for
algorithmic development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lefebvre_T/0/1/0/all/0/1&quot;&gt;Tom Lefebvre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.01251">
<title>Using Representation Expressiveness and Learnability to Evaluate Self-Supervised Learning Methods. (arXiv:2206.01251v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.01251</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of evaluating the quality of self-supervised learning
(SSL) models without access to supervised labels, while being agnostic to the
architecture, learning algorithm or data manipulation used during training. We
argue that representations can be evaluated through the lens of expressiveness
and learnability. We propose to use the Intrinsic Dimension (ID) to assess
expressiveness and introduce Cluster Learnability (CL) to assess learnability.
CL is measured in terms of the performance of a KNN classifier trained to
predict labels obtained by clustering the representations with K-means. We thus
combine CL and ID into a single predictor -- CLID. Through a large-scale
empirical study with a diverse family of SSL algorithms, we find that CLID
better correlates with in-distribution model performance than other competing
recent evaluation schemes. We also benchmark CLID on out-of-domain
generalization, where CLID serves as a predictor of the transfer performance of
SSL models on several visual classification tasks, yielding improvements with
respect to the competing baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yuchen Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baratin_A/0/1/0/all/0/1&quot;&gt;Aristide Baratin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laroche_R/0/1/0/all/0/1&quot;&gt;Romain Laroche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1&quot;&gt;Aaron Courville&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sordoni_A/0/1/0/all/0/1&quot;&gt;Alessandro Sordoni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.04053">
<title>On the Need and Applicability of Causality for Fair Machine Learning. (arXiv:2207.04053v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2207.04053</link>
<description rdf:parseType="Literal">&lt;p&gt;Besides its common use cases in epidemiology, political, and social sciences,
causality turns out to be crucial in evaluating the fairness of automated
decisions, both in a legal and everyday sense. We provide arguments and
examples, of why causality is particularly important for fairness evaluation.
In particular, we point out the social impact of non-causal predictions and the
legal anti-discrimination process that relies on causal claims. We conclude
with a discussion about the challenges and limitations of applying causality in
practical scenarios as well as possible solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binkyte_R/0/1/0/all/0/1&quot;&gt;R&amp;#x16b;ta Binkyt&amp;#x117;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grozdanovski_L/0/1/0/all/0/1&quot;&gt;Ljupcho Grozdanovski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhioua_S/0/1/0/all/0/1&quot;&gt;Sami Zhioua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.06025">
<title>URANUS: Radio Frequency Tracking, Classification and Identification of Unmanned Aircraft Vehicles. (arXiv:2207.06025v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2207.06025</link>
<description rdf:parseType="Literal">&lt;p&gt;Safety and security issues for Critical Infrastructures are growing as
attackers adopt drones as an attack vector flying in sensitive airspaces, such
as airports, military bases, city centers, and crowded places. Despite the use
of UAVs for logistics, shipping recreation activities, and commercial
applications, their usage poses severe concerns to operators due to the
violations and the invasions of the restricted airspaces. A cost-effective and
real-time framework is needed to detect the presence of drones in such cases.
In this contribution, we propose an efficient radio frequency-based detection
framework called URANUS. We leverage real-time data provided by the Radio
Frequency/Direction Finding system, and radars in order to detect, classify and
identify drones (multi-copter and fixed-wings) invading no-drone zones. We
adopt a Multilayer Perceptron neural network to identify and classify UAVs in
real-time, with $90$% accuracy. For the tracking task, we use a Random Forest
model to predict the position of a drone with an MSE $\approx0.29$, MAE
$\approx0.04$, and $R^2\approx 0.93$. Furthermore, coordinate regression is
performed using Universal Transverse Mercator coordinates to ensure high
accuracy. Our analysis shows that URANUS is an ideal framework for identifying,
classifying, and tracking UAVs that most Critical Infrastructure operators can
adopt.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lofu_D/0/1/0/all/0/1&quot;&gt;Domenico Lof&amp;#xf9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gennaro_P/0/1/0/all/0/1&quot;&gt;Pietro Di Gennaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tedeschi_P/0/1/0/all/0/1&quot;&gt;Pietro Tedeschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1&quot;&gt;Tommaso Di Noia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sciascio_E/0/1/0/all/0/1&quot;&gt;Eugenio Di Sciascio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.09858">
<title>GenHPF: General Healthcare Predictive Framework with Multi-task Multi-source Learning. (arXiv:2207.09858v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2207.09858</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the remarkable progress in the development of predictive models for
healthcare, applying these algorithms on a large scale has been challenging.
Algorithms trained on a particular task, based on specific data formats
available in a set of medical records, tend to not generalize well to other
tasks or databases in which the data fields may differ. To address this
challenge, we propose General Healthcare Predictive Framework (GenHPF), which
is applicable to any EHR with minimal preprocessing for multiple prediction
tasks. GenHPF resolves heterogeneity in medical codes and schemas by converting
EHRs into a hierarchical textual representation while incorporating as many
features as possible. To evaluate the efficacy of GenHPF, we conduct multi-task
learning experiments with single-source and multi-source settings, on three
publicly available EHR datasets with different schemas for 12 clinically
meaningful prediction tasks. Our framework significantly outperforms baseline
models that utilize domain knowledge in multi-source learning, improving
average AUROC by 1.2%P in pooled learning and 2.6%P in transfer learning while
also showing comparable results when trained on a single EHR dataset.
Furthermore, we demonstrate that self-supervised pretraining using multi-source
datasets is effective when combined with GenHPF, resulting in a 0.6%P AUROC
improvement compared to models without pretraining. By eliminating the need for
preprocessing and feature engineering, we believe that this work offers a solid
framework for multi-task and multi-source learning that can be leveraged to
speed up the scaling and usage of predictive algorithms in healthcare.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hur_K/0/1/0/all/0/1&quot;&gt;Kyunghoon Hur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1&quot;&gt;Jungwoo Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jiyoun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1&quot;&gt;Min Jae Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_E/0/1/0/all/0/1&quot;&gt;Eunbyeol Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1&quot;&gt;Seong-Eun Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Young-Hak Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atallah_L/0/1/0/all/0/1&quot;&gt;Louis Atallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1&quot;&gt;Edward Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.13081">
<title>Future-Dependent Value-Based Off-Policy Evaluation in POMDPs. (arXiv:2207.13081v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2207.13081</link>
<description rdf:parseType="Literal">&lt;p&gt;We study off-policy evaluation (OPE) for partially observable MDPs (POMDPs)
with general function approximation. Existing methods such as sequential
importance sampling estimators and fitted-Q evaluation suffer from the curse of
horizon in POMDPs. To circumvent this problem, we develop a novel model-free
OPE method by introducing future-dependent value functions that take future
proxies as inputs. Future-dependent value functions play similar roles as
classical value functions in fully-observable MDPs. We derive a new Bellman
equation for future-dependent value functions as conditional moment equations
that use history proxies as instrumental variables. We further propose a
minimax learning method to learn future-dependent value functions using the new
Bellman equation. We obtain the PAC result, which implies our OPE estimator is
consistent as long as futures and histories contain sufficient information
about latent states, and the Bellman completeness. Finally, we extend our
methods to learning of dynamics and establish the connection between our
approach and the well-known spectral learning methods in POMDPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uehara_M/0/1/0/all/0/1&quot;&gt;Masatoshi Uehara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiyohara_H/0/1/0/all/0/1&quot;&gt;Haruka Kiyohara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bennett_A/0/1/0/all/0/1&quot;&gt;Andrew Bennett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1&quot;&gt;Nan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kallus_N/0/1/0/all/0/1&quot;&gt;Nathan Kallus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1&quot;&gt;Chengchun Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1&quot;&gt;Wen Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.02474">
<title>CFARnet: deep learning for target detection with constant false alarm rate. (arXiv:2208.02474v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2208.02474</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of target detection with a constant false alarm rate
(CFAR). This constraint is crucial in many practical applications and is a
standard requirement in classical composite hypothesis testing. In settings
where classical approaches are computationally expensive or where only data
samples are given, machine learning methodologies are advantageous. CFAR is
less understood in these settings. To close this gap, we introduce a framework
of CFAR constrained detectors. Theoretically, we prove that a CFAR constrained
Bayes optimal detector is asymptotically equivalent to the classical
generalized likelihood ratio test (GLRT). Practically, we develop a deep
learning framework for fitting neural networks that approximate it. Experiments
of target detection in different setting demonstrate that the proposed CFARnet
allows a flexible tradeoff between CFAR and accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diskin_T/0/1/0/all/0/1&quot;&gt;Tzvi Diskin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beer_Y/0/1/0/all/0/1&quot;&gt;Yiftach Beer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okun_U/0/1/0/all/0/1&quot;&gt;Uri Okun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiesel_A/0/1/0/all/0/1&quot;&gt;Ami Wiesel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.14407">
<title>An Analysis of Model-Based Reinforcement Learning From Abstracted Observations. (arXiv:2208.14407v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2208.14407</link>
<description rdf:parseType="Literal">&lt;p&gt;Many methods for Model-based Reinforcement learning (MBRL) in Markov decision
processes (MDPs) provide guarantees for both the accuracy of the model they can
deliver and the learning efficiency. At the same time, state abstraction
techniques allow for a reduction of the size of an MDP while maintaining a
bounded loss with respect to the original problem. Therefore, it may come as a
surprise that no such guarantees are available when combining both techniques,
i.e., where MBRL merely observes abstract states. Our theoretical analysis
shows that abstraction can introduce a dependence between samples collected
online (e.g., in the real world). That means that, without taking this
dependence into account, results for MBRL do not directly extend to this
setting. Our result shows that we can use concentration inequalities for
martingales to overcome this problem. This result makes it possible to extend
the guarantees of existing MBRL algorithms to the setting with abstraction. We
illustrate this by combining R-MAX, a prototypical MBRL algorithm, with
abstraction, thus producing the first performance guarantees for model-based
&apos;RL from Abstracted Observations&apos;: model-based reinforcement learning with an
abstract model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Starre_R/0/1/0/all/0/1&quot;&gt;Rolf A. N. Starre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loog_M/0/1/0/all/0/1&quot;&gt;Marco Loog&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Congeduti_E/0/1/0/all/0/1&quot;&gt;Elena Congeduti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliehoek_F/0/1/0/all/0/1&quot;&gt;Frans A. Oliehoek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.00805">
<title>Limitations of neural network training due to numerical instability of backpropagation. (arXiv:2210.00805v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.00805</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the training of deep neural networks by gradient descent where
floating-point arithmetic is used to compute the gradients. In this framework
and under realistic assumptions, we demonstrate that it is highly unlikely to
find ReLU neural networks that maintain, in the course of training with
gradient descent, superlinearly many affine pieces with respect to their number
of layers. In virtually all approximation theoretical arguments that yield
high-order polynomial rates of approximation, sequences of ReLU neural networks
with exponentially many affine pieces compared to their numbers of layers are
used. As a consequence, we conclude that approximating sequences of ReLU neural
networks resulting from gradient descent in practice differ substantially from
theoretically constructed sequences. The assumptions and the theoretical
results are compared to a numerical study, which yields concurring results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karner_C/0/1/0/all/0/1&quot;&gt;Clemens Karner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazeev_V/0/1/0/all/0/1&quot;&gt;Vladimir Kazeev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petersen_P/0/1/0/all/0/1&quot;&gt;Philipp Christian Petersen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.02998">
<title>ThoraX-PriorNet: A Novel Attention-Based Architecture Using Anatomical Prior Probability Maps for Thoracic Disease Classification. (arXiv:2210.02998v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2210.02998</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: Computer-aided disease diagnosis and prognosis based on medical
images is a rapidly emerging field. Many Convolutional Neural Network (CNN)
architectures have been developed by researchers for disease classification and
localization from chest X-ray images. It is known that different thoracic
disease lesions are more likely to occur in specific anatomical regions
compared to others. This article aims to incorporate this disease and
region-dependent prior probability distribution within a deep learning
framework. Methods: We present the ThoraX-PriorNet, a novel attention-based CNN
model for thoracic disease classification. We first estimate a
disease-dependent spatial probability, i.e., an anatomical prior, that
indicates the probability of occurrence of a disease in a specific region in a
chest X-ray image. Next, we develop a novel attention-based classification
model that combines information from the estimated anatomical prior and
automatically extracted chest region of interest (ROI) masks to provide
attention to the feature maps generated from a deep convolution network. Unlike
previous works that utilize various self-attention mechanisms, the proposed
method leverages the extracted chest ROI masks along with the probabilistic
anatomical prior information, which selects the region of interest for
different diseases to provide attention. Results: The proposed method shows
superior performance in disease classification on the NIH ChestX-ray14 dataset
compared to existing state-of-the-art methods while reaching an area under the
ROC curve (%AUC) of 84.67. Regarding disease localization, the anatomy prior
attention method shows competitive performance compared to state-of-the-art
methods, achieving an accuracy of 0.80, 0.63, 0.49, 0.33, 0.28, 0.21, and 0.04
with an Intersection over Union (IoU) threshold of 0.1, 0.2, 0.3, 0.4, 0.5,
0.6, and 0.7, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hossain_M/0/1/0/all/0/1&quot;&gt;Md. Iqbal Hossain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zunaed_M/0/1/0/all/0/1&quot;&gt;Mohammad Zunaed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ahmed_M/0/1/0/all/0/1&quot;&gt;Md. Kawsar Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hossain_S/0/1/0/all/0/1&quot;&gt;S. M. Jawwad Hossain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hasan_A/0/1/0/all/0/1&quot;&gt;Anwarul Hasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hasan_T/0/1/0/all/0/1&quot;&gt;Taufiq Hasan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.13034">
<title>Beyond Vectors: Subspace Representations for Set Operations of Embeddings. (arXiv:2210.13034v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2210.13034</link>
<description rdf:parseType="Literal">&lt;p&gt;In natural language processing (NLP), the role of embeddings in representing
linguistic semantics is crucial. Despite the prevalence of vector
representations in embedding sets, they exhibit limitations in expressiveness
and lack comprehensive set operations. To address this, we attempt to formulate
and apply sets and their operations within pre-trained embedding spaces.
Inspired by quantum logic, we propose to go beyond the conventional vector set
representation with our novel subspace-based approach. This methodology
constructs subspaces using pre-trained embedding sets, effectively preserving
semantic nuances previously overlooked, and consequently consistently improving
performance in downstream tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishibashi_Y/0/1/0/all/0/1&quot;&gt;Yoichi Ishibashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yokoi_S/0/1/0/all/0/1&quot;&gt;Sho Yokoi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudoh_K/0/1/0/all/0/1&quot;&gt;Katsuhito Sudoh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamura_S/0/1/0/all/0/1&quot;&gt;Satoshi Nakamura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.10851">
<title>Reward is not Necessary: How to Create a Modular &amp; Compositional Self-Preserving Agent for Life-Long Learning. (arXiv:2211.10851v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2211.10851</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement Learning views the maximization of rewards and avoidance of
punishments as central to explaining goal-directed behavior. However, over a
life, organisms will need to learn about many different aspects of the world&apos;s
structure: the states of the world and state-vector transition dynamics. The
number of combinations of states grows exponentially as an agent incorporates
new knowledge, and there is no obvious weighted combination of pre-existing
rewards or costs defined for a given combination of states, as such a weighting
would need to encode information about good and bad combinations prior to an
agent&apos;s experience in the world. Therefore, we must develop more naturalistic
accounts of behavior and motivation in large state-spaces. We show that it is
possible to use only the intrinsic motivation metric of empowerment, which
measures the agent&apos;s capacity to realize many possible futures under a
transition operator. We propose to scale empowerment to hierarchical
state-spaces by using Operator Bellman Equations. These equations produce
state-time feasibility functions, which are compositional hierarchical
state-time transition operators that map an initial state and time when an
agent begins a policy to the final states and times of completing a goal.
Because these functions are hierarchical operators we can define hierarchical
empowerment measures on them. An agent can then optimize plans to distant
states and times to maximize its hierarchical empowerment-gain, allowing it to
discover goals that bring about a more favorable coupling of its internal
structure (physiological states) to its external environment (world structure &amp;amp;
spatial state). Life-long agents could therefore be primarily animated by
principles of compositionality and empowerment, exhibiting self-concern for the
growth &amp;amp; maintenance of their own structural integrity without recourse to
reward-maximization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ringstrom_T/0/1/0/all/0/1&quot;&gt;Thomas J. Ringstrom&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.14400">
<title>Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and Besov Spaces. (arXiv:2211.14400v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2211.14400</link>
<description rdf:parseType="Literal">&lt;p&gt;Let $\Omega = [0,1]^d$ be the unit cube in $\mathbb{R}^d$. We study the
problem of how efficiently, in terms of the number of parameters, deep neural
networks with the ReLU activation function can approximate functions in the
Sobolev spaces $W^s(L_q(\Omega))$ and Besov spaces $B^s_r(L_q(\Omega))$, with
error measured in the $L_p(\Omega)$ norm. This problem is important when
studying the application of neural networks in a variety of fields, including
scientific computing and signal processing, and has previously been solved only
when $p=q=\infty$. Our contribution is to provide a complete solution for all
$1\leq p,q\leq \infty$ and $s &amp;gt; 0$ for which the corresponding Sobolev or Besov
space compactly embeds into $L_p$. The key technical tool is a novel
bit-extraction technique which gives an optimal encoding of sparse vectors.
This enables us to obtain sharp upper bounds in the non-linear regime where $p
&amp;gt; q$. We also provide a novel method for deriving $L_p$-approximation lower
bounds based upon VC-dimension when $p &amp;lt; \infty$. Our results show that very
deep ReLU networks significantly outperform classical methods of approximation
in terms of the number of parameters, but that this comes at the cost of
parameters which are not encodable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Siegel_J/0/1/0/all/0/1&quot;&gt;Jonathan W. Siegel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.12322">
<title>Infrared Image Super-Resolution: Systematic Review, and Future Trends. (arXiv:2212.12322v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2212.12322</link>
<description rdf:parseType="Literal">&lt;p&gt;Image Super-Resolution (SR) is essential for a wide range of computer vision
and image processing tasks. Investigating infrared (IR) image (or thermal
images) super-resolution is a continuing concern within the development of deep
learning. This survey aims to provide a comprehensive perspective of IR image
super-resolution, including its applications, hardware imaging system dilemmas,
and taxonomy of image processing methodologies. In addition, the datasets and
evaluation metrics in IR image super-resolution tasks are also discussed.
Furthermore, the deficiencies in current technologies and possible promising
directions for the community to explore are highlighted. To cope with the rapid
development in this field, we intend to regularly update the relevant excellent
work at \url{https://github.com/yongsongH/Infrared_Image_SR_Survey
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yongsong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Miyazaki_T/0/1/0/all/0/1&quot;&gt;Tomo Miyazaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaofeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Omachi_S/0/1/0/all/0/1&quot;&gt;Shinichiro Omachi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.04764">
<title>Analyzing Inexact Hypergradients for Bilevel Learning. (arXiv:2301.04764v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2301.04764</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating hyperparameters has been a long-standing problem in machine
learning. We consider the case where the task at hand is modeled as the
solution to an optimization problem. Here the exact gradient with respect to
the hyperparameters cannot be feasibly computed and approximate strategies are
required. We introduce a unified framework for computing hypergradients that
generalizes existing methods based on the implicit function theorem and
automatic differentiation/backpropagation, showing that these two seemingly
disparate approaches are actually tightly connected. Our framework is extremely
flexible, allowing its subproblems to be solved with any suitable method, to
any degree of accuracy. We derive a priori and computable a posteriori error
bounds for all our methods, and numerically show that our a posteriori bounds
are usually more accurate. Our numerical results also show that, surprisingly,
for efficient bilevel optimization, the choice of hypergradient algorithm is at
least as important as the choice of lower-level solver.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ehrhardt_M/0/1/0/all/0/1&quot;&gt;Matthias J. Ehrhardt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Roberts_L/0/1/0/all/0/1&quot;&gt;Lindon Roberts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.10405">
<title>Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v6 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2301.10405</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently decades have witnessed the empirical success of framing Knowledge
Graph (KG) embeddings via language models. However, language model-based KG
embeddings are usually deployed as static artifacts, making them difficult to
modify post-deployment without re-training after deployment. To address this
issue, we propose a new task of editing language model-based KG embeddings in
this paper. This task is designed to facilitate rapid, data-efficient updates
to KG embeddings without compromising the performance of other aspects. We
build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and
evaluate several knowledge editing baselines demonstrating the limited ability
of previous models to handle the proposed challenging task. We further propose
a simple yet strong baseline dubbed KGEditor, which utilizes additional
parametric layers of the hyper network to edit/add facts. Our comprehensive
experimental results reveal that KGEditor excels in updating specific facts
without impacting the overall performance, even when faced with limited
training resources. Code and datasets are available in
https://github.com/zjunlp/PromptKG/tree/main/deltaKG.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Siyuan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1&quot;&gt;Ningyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_B/0/1/0/all/0/1&quot;&gt;Bozhong Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qingbing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huajun Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.11562">
<title>Arbitrariness and Prediction: The Confounding Role of Variance in Fair Classification. (arXiv:2301.11562v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.11562</link>
<description rdf:parseType="Literal">&lt;p&gt;Variance in predictions across different trained models is a significant,
under-explored source of error in fair binary classification. In practice, the
variance on some data examples is so large that decisions can be effectively
arbitrary. To investigate this problem, we take an experimental approach and
make four overarching contributions: We: 1) Define a metric called
self-consistency, derived from variance, which we use as a proxy for measuring
and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains
from classification when a prediction would be arbitrary; 3) Conduct the
largest to-date empirical study of the role of variance (vis-a-vis
self-consistency and arbitrariness) in fair binary classification; and, 4)
Release a toolkit that makes the US Home Mortgage Disclosure Act (HMDA)
datasets easily usable for future research. Altogether, our experiments reveal
shocking insights about the reliability of conclusions on benchmark datasets.
Most fair binary classification benchmarks are close-to-fair when taking into
account the amount of arbitrariness present in predictions -- before we even
try to apply any fairness interventions. This finding calls into question the
practical utility of common algorithmic fairness methods, and in turn suggests
that we should reconsider how we choose to measure fairness in binary
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1&quot;&gt;A. Feder Cooper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Katherine Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choksi_M/0/1/0/all/0/1&quot;&gt;Madiha Choksi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barocas_S/0/1/0/all/0/1&quot;&gt;Solon Barocas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1&quot;&gt;Christopher De Sa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grimmelmann_J/0/1/0/all/0/1&quot;&gt;James Grimmelmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1&quot;&gt;Jon Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1&quot;&gt;Siddhartha Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Baobao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.12554">
<title>Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing. (arXiv:2301.12554v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.12554</link>
<description rdf:parseType="Literal">&lt;p&gt;While prior research has proposed a plethora of methods that build neural
classifiers robust against adversarial robustness, practitioners are still
reluctant to adopt them due to their unacceptably severe clean accuracy
penalties. This paper significantly alleviates this accuracy-robustness
trade-off by mixing the output probabilities of a standard classifier and a
robust classifier, where the standard network is optimized for clean accuracy
and is not robust in general. We show that the robust base classifier&apos;s
confidence difference for correct and incorrect examples is the key to this
improvement. In addition to providing intuitions and empirical evidence, we
theoretically certify the robustness of the mixed classifier under realistic
assumptions. Furthermore, we adapt an adversarial input detector into a mixing
network that adaptively adjusts the mixture of the two base models, further
reducing the accuracy penalty of achieving robustness. The proposed flexible
method, termed &quot;adaptive smoothing&quot;, can work in conjunction with existing or
even future methods that improve clean accuracy, robustness, or adversary
detection. Our empirical evaluation considers strong attack methods, including
AutoAttack and adaptive attack. On the CIFAR-100 dataset, our method achieves
an 85.21% clean accuracy while maintaining a 38.72% $\ell_\infty$-AutoAttacked
($\epsilon = 8/255$) accuracy, becoming the second most robust method on the
RobustBench CIFAR-100 benchmark as of submission, while improving the clean
accuracy by ten percentage points compared with all listed models. The code
that implements our method is available at
https://github.com/Bai-YT/AdaptiveSmoothing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yatong Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anderson_B/0/1/0/all/0/1&quot;&gt;Brendon G. Anderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_A/0/1/0/all/0/1&quot;&gt;Aerin Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sojoudi_S/0/1/0/all/0/1&quot;&gt;Somayeh Sojoudi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.05763">
<title>Towards Multi-User Activity Recognition through Facilitated Training Data and Deep Learning for Human-Robot Collaboration Applications. (arXiv:2302.05763v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.05763</link>
<description rdf:parseType="Literal">&lt;p&gt;Human-robot interaction (HRI) research is progressively addressing
multi-party scenarios, where a robot interacts with more than one human user at
the same time. Conversely, research is still at an early stage for human-robot
collaboration. The use of machine learning techniques to handle such type of
collaboration requires data that are less feasible to produce than in a typical
HRC setup. This work outlines scenarios of concurrent tasks for non-dyadic HRC
applications. Based upon these concepts, this study also proposes an
alternative way of gathering data regarding multi-user activity, by collecting
data related to single users and merging them in post-processing, to reduce the
effort involved in producing recordings of pair settings. To validate this
statement, 3D skeleton poses of activity of single users were collected and
merged in pairs. After this, such datapoints were used to separately train a
long short-term memory (LSTM) network and a variational autoencoder (VAE)
composed of spatio-temporal graph convolutional networks (STGCN) to recognise
the joint activities of the pairs of people. The results showed that it is
possible to make use of data collected in this way for pair HRC settings and
get similar performances compared to using training data regarding groups of
users recorded under the same settings, relieving from the technical
difficulties involved in producing these data.
&lt;/p&gt;
&lt;p&gt;The related code and collected data are publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Semeraro_F/0/1/0/all/0/1&quot;&gt;Francesco Semeraro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carberry_J/0/1/0/all/0/1&quot;&gt;Jon Carberry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cangelosi_A/0/1/0/all/0/1&quot;&gt;Angelo Cangelosi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.14516">
<title>OVeNet: Offset Vector Network for Semantic Segmentation. (arXiv:2303.14516v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.14516</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic segmentation is a fundamental task in visual scene understanding. We
focus on the supervised setting, where ground-truth semantic annotations are
available. Based on knowledge about the high regularity of real-world scenes,
we propose a method for improving class predictions by learning to selectively
exploit information from neighboring pixels. In particular, our method is based
on the prior that for each pixel, there is a seed pixel in its close
neighborhood sharing the same prediction with the former. Motivated by this
prior, we design a novel two-head network, named Offset Vector Network
(OVeNet), which generates both standard semantic predictions and a dense 2D
offset vector field indicating the offset from each pixel to the respective
seed pixel, which is used to compute an alternative, seed-based semantic
prediction. The two predictions are adaptively fused at each pixel using a
learnt dense confidence map for the predicted offset vector field. We supervise
offset vectors indirectly via optimizing the seed-based prediction and via a
novel loss on the confidence map. Compared to the baseline state-of-the-art
architectures HRNet and HRNet+OCR on which OVeNet is built, the latter achieves
significant performance gains on three prominent benchmarks for semantic
segmentation, namely Cityscapes, ACDC and ADE20K. Code is available at
https://github.com/stamatisalex/OVeNet
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alexandropoulos_S/0/1/0/all/0/1&quot;&gt;Stamatis Alexandropoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sakaridis_C/0/1/0/all/0/1&quot;&gt;Christos Sakaridis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maragos_P/0/1/0/all/0/1&quot;&gt;Petros Maragos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.03292">
<title>SE-shapelets: Semi-supervised Clustering of Time Series Using Representative Shapelets. (arXiv:2304.03292v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.03292</link>
<description rdf:parseType="Literal">&lt;p&gt;Shapelets that discriminate time series using local features (subsequences)
are promising for time series clustering. Existing time series clustering
methods may fail to capture representative shapelets because they discover
shapelets from a large pool of uninformative subsequences, and thus result in
low clustering accuracy. This paper proposes a Semi-supervised Clustering of
Time Series Using Representative Shapelets (SE-Shapelets) method, which
utilizes a small number of labeled and propagated pseudo-labeled time series to
help discover representative shapelets, thereby improving the clustering
accuracy. In SE-Shapelets, we propose two techniques to discover representative
shapelets for the effective clustering of time series. 1) A \textit{salient
subsequence chain} ($SSC$) that can extract salient subsequences (as candidate
shapelets) of a labeled/pseudo-labeled time series, which helps remove massive
uninformative subsequences from the pool. 2) A \textit{linear discriminant
selection} ($LDS$) algorithm to identify shapelets that can capture
representative local features of time series in different classes, for
convenient clustering. Experiments on UCR time series datasets demonstrate that
SE-shapelets discovers representative shapelets and achieves higher clustering
accuracy than counterpart semi-supervised time series clustering methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_B/0/1/0/all/0/1&quot;&gt;Borui Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1&quot;&gt;Guangyan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Shuiqiao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1&quot;&gt;Yong Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_C/0/1/0/all/0/1&quot;&gt;Chi-Hung Chi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.03571">
<title>$\beta$-Variational autoencoders and transformers for reduced-order modelling of fluid flows. (arXiv:2304.03571v2 [physics.flu-dyn] UPDATED)</title>
<link>http://arxiv.org/abs/2304.03571</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational autoencoder (VAE) architectures have the potential to develop
reduced-order models (ROMs) for chaotic fluid flows. We propose a method for
learning compact and near-orthogonal ROMs using a combination of a $\beta$-VAE
and a transformer, tested on numerical data from a two-dimensional viscous flow
in both periodic and chaotic regimes. The $\beta$-VAE is trained to learn a
compact latent representation of the flow velocity, and the transformer is
trained to predict the temporal dynamics in latent space. Using the $\beta$-VAE
to learn disentangled representations in latent-space, we obtain a more
interpretable flow model with features that resemble those observed in the
proper orthogonal decomposition, but with a more efficient representation.
Using Poincar\&apos;e maps, the results show that our method can capture the
underlying dynamics of the flow outperforming other prediction models. The
proposed method has potential applications in other fields such as weather
forecasting, structural dynamics or biomedical engineering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Solera_Rico_A/0/1/0/all/0/1&quot;&gt;Alberto Solera-Rico&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Vila_C/0/1/0/all/0/1&quot;&gt;Carlos Sanmiguel Vila&lt;/a&gt; (1 and 2), &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gomez_M/0/1/0/all/0/1&quot;&gt;M. A. G&amp;#xf3;mez&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuning Wang&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Almashjary_A/0/1/0/all/0/1&quot;&gt;Abdulrahman Almashjary&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Dawson_S/0/1/0/all/0/1&quot;&gt;Scott T. M. Dawson&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Vinuesa_R/0/1/0/all/0/1&quot;&gt;Ricardo Vinuesa&lt;/a&gt; (4) (1: Aerospace Engineering Research Group, Universidad Carlos III de Madrid, Legan&amp;#xe9;s, Spain 2: Subdirectorate General of Terrestrial Systems, Spanish National Institute for Aerospace Technology (INTA), San Mart&amp;#xed;n de la Vega, Spain 3: Mechanical, Materials, and Aerospace Engineering Department, Illinois Institute of Technology, Chicago, USA 4: FLOW, Engineering Mechanics, KTH Royal Institute of Technology, Stockholm, Sweden)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06295">
<title>Extracting Diagnosis Pathways from Electronic Health Records Using Deep Reinforcement Learning. (arXiv:2305.06295v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06295</link>
<description rdf:parseType="Literal">&lt;p&gt;Clinical diagnosis guidelines aim at specifying the steps that may lead to a
diagnosis. Inspired by guidelines, we aim to learn the optimal sequence of
actions to perform in order to obtain a correct diagnosis from electronic
health records. We apply various deep reinforcement learning algorithms to this
task and experiment on a synthetic but realistic dataset to differentially
diagnose anemia and its subtypes and particularly evaluate the robustness of
various approaches to noise and missing data. Experimental results show that
the deep reinforcement learning algorithms show competitive performance
compared to the state-of-the-art methods with the added advantage that they
enable the progressive generation of a pathway to the suggested diagnosis,
which can both guide and explain the decision process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muyama_L/0/1/0/all/0/1&quot;&gt;Lillian Muyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neuraz_A/0/1/0/all/0/1&quot;&gt;Antoine Neuraz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coulet_A/0/1/0/all/0/1&quot;&gt;Adrien Coulet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06348">
<title>Supervised learning with probabilistic morphisms and kernel mean embeddings. (arXiv:2305.06348v5 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06348</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper I propose a generative model of supervised learning that
unifies two approaches to supervised learning, using a concept of a correct
loss function. Addressing two measurability problems, which have been ignored
in statistical learning theory, I propose to use convergence in outer
probability to characterize the consistency of a learning algorithm. Building
upon these results, I extend a result due to Cucker-Smale, which addresses the
learnability of a regression model, to the setting of a conditional probability
estimation problem. Additionally, I present a variant of Vapnik-Stefanuyk&apos;s
regularization method for solving stochastic ill-posed problems, and using it
to prove the generalizability of overparameterized supervised learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Le_H/0/1/0/all/0/1&quot;&gt;H&amp;#xf4;ng V&amp;#xe2;n L&amp;#xea;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.08703">
<title>Schema-adaptable Knowledge Graph Construction. (arXiv:2305.08703v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.08703</link>
<description rdf:parseType="Literal">&lt;p&gt;Conventional Knowledge Graph Construction (KGC) approaches typically follow
the static information extraction paradigm with a closed set of pre-defined
schema. As a result, such approaches fall short when applied to dynamic
scenarios or domains, whereas a new type of knowledge emerges. This
necessitates a system that can handle evolving schema automatically to extract
information for KGC. To address this need, we propose a new task called
schema-adaptable KGC, which aims to continually extract entity, relation, and
event based on a dynamically changing schema graph without re-training. We
first split and convert existing datasets based on three principles to build a
benchmark, i.e., horizontal schema expansion, vertical schema expansion, and
hybrid schema expansion; then investigate the schema-adaptable performance of
several well-known approaches such as Text2Event, TANL, UIE and GPT-3.5. We
further propose a simple yet effective baseline dubbed \textsc{AdaKGC}, which
contains schema-enriched prefix instructor and schema-conditioned dynamic
decoding to better handle evolving schema. Comprehensive experimental results
illustrate that AdaKGC can outperform baselines but still have room for
improvement. We hope the proposed work can deliver benefits to the community.
Code and datasets available at https://github.com/zjunlp/AdaKGC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1&quot;&gt;Hongbin Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gui_H/0/1/0/all/0/1&quot;&gt;Honghao Gui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Xin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huajun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1&quot;&gt;Ningyu Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.09863">
<title>Explaining black box text modules in natural language with language models. (arXiv:2305.09863v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2305.09863</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have demonstrated remarkable prediction
performance for a growing array of tasks. However, their rapid proliferation
and increasing opaqueness have created a growing need for interpretability.
Here, we ask whether we can automatically obtain natural language explanations
for black box text modules. A &quot;text module&quot; is any function that maps text to a
scalar continuous value, such as a submodule within an LLM or a fitted model of
a brain region. &quot;Black box&quot; indicates that we only have access to the module&apos;s
inputs/outputs.
&lt;/p&gt;
&lt;p&gt;We introduce Summarize and Score (SASC), a method that takes in a text module
and returns a natural language explanation of the module&apos;s selectivity along
with a score for how reliable the explanation is. We study SASC in 3 contexts.
First, we evaluate SASC on synthetic modules and find that it often recovers
ground truth explanations. Second, we use SASC to explain modules found within
a pre-trained BERT model, enabling inspection of the model&apos;s internals.
Finally, we show that SASC can generate explanations for the response of
individual fMRI voxels to language stimuli, with potential applications to
fine-grained brain mapping. All code for using SASC and reproducing results is
made available on Github.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_C/0/1/0/all/0/1&quot;&gt;Chandan Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsu_A/0/1/0/all/0/1&quot;&gt;Aliyah R. Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1&quot;&gt;Richard Antonello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1&quot;&gt;Shailee Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1&quot;&gt;Alexander G. Huth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Bin Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.11531">
<title>Generalizing to new geometries with Geometry-Aware Autoregressive Models (GAAMs) for fast calorimeter simulation. (arXiv:2305.11531v5 [physics.ins-det] UPDATED)</title>
<link>http://arxiv.org/abs/2305.11531</link>
<description rdf:parseType="Literal">&lt;p&gt;Generation of simulated detector response to collision products is crucial to
data analysis in particle physics, but computationally very expensive. One
subdetector, the calorimeter, dominates the computational time due to the high
granularity of its cells and complexity of the interactions. Generative models
can provide more rapid sample production, but currently require significant
effort to optimize performance for specific detector geometries, often
requiring many models to describe the varying cell sizes and arrangements,
without the ability to generalize to other geometries. We develop a
$\textit{geometry-aware}$ autoregressive model, which learns how the
calorimeter response varies with geometry, and is capable of generating
simulated responses to unseen geometries without additional training. The
geometry-aware model outperforms a baseline unaware model by over $50\%$ in
several metrics such as the Wasserstein distance between the generated and the
true distributions of key quantities which summarize the simulated response. A
single geometry-aware model could replace the hundreds of generative models
currently designed for calorimeter simulation by physicists analyzing data
collected at the Large Hadron Collider. This proof-of-concept study motivates
the design of a foundational model that will be a crucial tool for the study of
future detectors, dramatically reducing the large upfront investment usually
needed to develop generative calorimeter models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Junze Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ghosh_A/0/1/0/all/0/1&quot;&gt;Aishik Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Smith_D/0/1/0/all/0/1&quot;&gt;Dylan Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Baldi_P/0/1/0/all/0/1&quot;&gt;Pierre Baldi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Whiteson_D/0/1/0/all/0/1&quot;&gt;Daniel Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12102">
<title>Unified Embedding: Battle-Tested Feature Representations for Web-Scale ML Systems. (arXiv:2305.12102v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12102</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning high-quality feature embeddings efficiently and effectively is
critical for the performance of web-scale machine learning systems. A typical
model ingests hundreds of features with vocabularies on the order of millions
to billions of tokens. The standard approach is to represent each feature value
as a d-dimensional embedding, introducing hundreds of billions of parameters
for extremely high-cardinality features. This bottleneck has led to substantial
progress in alternative embedding algorithms. Many of these methods, however,
make the assumption that each feature uses an independent embedding table. This
work introduces a simple yet highly effective framework, Feature Multiplexing,
where one single representation space is used across many different categorical
features. Our theoretical and empirical analysis reveals that multiplexed
embeddings can be decomposed into components from each constituent feature,
allowing models to distinguish between features. We show that multiplexed
representations lead to Pareto-optimal parameter-accuracy tradeoffs for three
public benchmark datasets. Further, we propose a highly practical approach
called Unified Embedding with three major benefits: simplified feature
configuration, strong adaptation to dynamic data distributions, and
compatibility with modern hardware. Unified embedding gives significant
improvements in offline and online metrics compared to highly competitive
baselines across five web-scale search, ads, and recommender systems, where it
serves billions of users across the world in industry-leading products.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coleman_B/0/1/0/all/0/1&quot;&gt;Benjamin Coleman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1&quot;&gt;Wang-Cheng Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fahrbach_M/0/1/0/all/0/1&quot;&gt;Matthew Fahrbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruoxi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1&quot;&gt;Lichan Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1&quot;&gt;Ed H. Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1&quot;&gt;Derek Zhiyuan Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14463">
<title>ReadMe++: Benchmarking Multilingual Language Models for Multi-Domain Readability Assessment. (arXiv:2305.14463v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14463</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a systematic study and comprehensive evaluation of large language
models for automatic multilingual readability assessment. In particular, we
construct ReadMe++, a multilingual multi-domain dataset with human annotations
of 9757 sentences in Arabic, English, French, Hindi, and Russian collected from
112 different data sources. ReadMe++ offers more domain and language diversity
than existing readability datasets, making it ideal for benchmarking
multilingual and non-English language models (including mBERT, XLM-R, mT5,
Llama-2, GPT-4, etc.) in the supervised, unsupervised, and few-shot prompting
settings. Our experiments reveal that models fine-tuned on ReadMe++ outperform
those trained on single-domain datasets, showcasing superior performance on
multi-domain readability assessment and cross-lingual transfer capabilities. We
also compare to traditional readability metrics (such as Flesch-Kincaid Grade
Level and Open Source Metric for Measuring Arabic Narratives), as well as the
state-of-the-art unsupervised metric RSRS (Martinc et al., 2021). We will make
our data and code publicly available at: https://github.com/tareknaous/readme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naous_T/0/1/0/all/0/1&quot;&gt;Tarek Naous&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryan_M/0/1/0/all/0/1&quot;&gt;Michael J. Ryan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lavrouk_A/0/1/0/all/0/1&quot;&gt;Anton Lavrouk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_M/0/1/0/all/0/1&quot;&gt;Mohit Chandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Wei Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.17170">
<title>Error Bounds for Learning with Vector-Valued Random Features. (arXiv:2305.17170v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2305.17170</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper provides a comprehensive error analysis of learning with
vector-valued random features (RF). The theory is developed for RF ridge
regression in a fully general infinite-dimensional input-output setting, but
nonetheless applies to and improves existing finite-dimensional analyses. In
contrast to comparable work in the literature, the approach proposed here
relies on a direct analysis of the underlying risk functional and completely
avoids the explicit RF ridge regression solution formula in terms of random
matrices. This removes the need for concentration results in random matrix
theory or their generalizations to random operators. The main results
established in this paper include strong consistency of vector-valued RF
estimators under model misspecification and minimax optimal convergence rates
in the well-specified setting. The parameter complexity (number of random
features) and sample complexity (number of labeled data) required to achieve
such rates are comparable with Monte Carlo intuition and free from logarithmic
factors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lanthaler_S/0/1/0/all/0/1&quot;&gt;Samuel Lanthaler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nelsen_N/0/1/0/all/0/1&quot;&gt;Nicholas H. Nelsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18497">
<title>Collaborative Learning via Prediction Consensus. (arXiv:2305.18497v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18497</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a collaborative learning setting where the goal of each agent is
to improve their own model by leveraging the expertise of collaborators, in
addition to their own training data. To facilitate the exchange of expertise
among agents, we propose a distillation-based method leveraging shared
unlabeled auxiliary data, which is pseudo-labeled by the collective. Central to
our method is a trust weighting scheme that serves to adaptively weigh the
influence of each collaborator on the pseudo-labels until a consensus on how to
label the auxiliary data is reached. We demonstrate empirically that our
collaboration scheme is able to significantly boost the performance of
individual models in the target domain from which the auxiliary data is
sampled. By design, our method adeptly accommodates heterogeneity in model
architectures and substantially reduces communication overhead compared to
typical collaborative learning methods. At the same time, it can provably
mitigate the negative impact of bad models on the collective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1&quot;&gt;Dongyang Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendler_Dunner_C/0/1/0/all/0/1&quot;&gt;Celestine Mendler-D&amp;#xfc;nner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1&quot;&gt;Martin Jaggi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19011">
<title>MiniSUPERB: Lightweight Benchmark for Self-supervised Speech Models. (arXiv:2305.19011v3 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19011</link>
<description rdf:parseType="Literal">&lt;p&gt;SUPERB was proposed to evaluate the generalizability of self-supervised
learning (SSL) speech models across various tasks. However, it incurs high
computational costs due to the large datasets and diverse tasks. In this paper,
we introduce MiniSUPERB, a lightweight benchmark that efficiently evaluates SSL
speech models with comparable results to SUPERB but lower computational costs
significantly. We carefully select representative tasks, sample datasets, and
extract model representations offline. Our approach achieves a Spearman&apos;s rank
correlation of 0.954 and 0.982 with SUPERB Paper and SUPERB Challenge,
respectively. Additionally, we reduce the computational cost by 97% in terms of
Multiply-ACcumulate operations (MACs). Furthermore, we evaluate SSL speech
models in few-shot scenarios and observe significant variations in their
performance. To our knowledge, this is the first study to examine both the
computational cost of the model itself and the cost of evaluating it on a
benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Hsiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huang-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chang_K/0/1/0/all/0/1&quot;&gt;Kai-Wei Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hsu_W/0/1/0/all/0/1&quot;&gt;Winston Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hung-yi Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.03530">
<title>RLtools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control. (arXiv:2306.03530v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.03530</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Reinforcement Learning (RL) has been demonstrated to yield capable
agents and control policies in several domains but is commonly plagued by
prohibitively long training times. Additionally, in the case of continuous
control problems, the applicability of learned policies on real-world embedded
devices is limited due to the lack of real-time guarantees and portability of
existing deep learning libraries. To address these challenges, we present
RLtools, a dependency-free, header-only, pure C++ library for deep supervised
and reinforcement learning. Leveraging the template meta-programming
capabilities of recent C++ standards, we provide composable components that can
be tightly integrated by the compiler. Its novel architecture allows RLtools to
be used seamlessly on a heterogeneous set of platforms, from HPC clusters over
workstations and laptops to smartphones, smartwatches, and microcontrollers.
Specifically, due to the tight integration of the RL algorithms with simulation
environments, RLtools can solve popular RL problems like the Pendulum-v1
swing-up about 7 to 15 times faster in terms of wall-clock training time
compared to other popular RL frameworks when using TD3. We also provide a
low-overhead and parallelized interface to the MuJoCo simulator, showing that
our PPO implementation achieves state of the art returns in the Ant-v4
environment while being 25%-30% faster in terms of wall-clock training time.
Finally, we also benchmark the policy inference on a diverse set of
microcontrollers and show that in most cases our optimized inference
implementation is much faster than even the manufacturer&apos;s DSP libraries. To
the best of our knowledge, RLtools enables the first-ever demonstration of
training a deep RL algorithm directly on a microcontroller, giving rise to the
field of TinyRL. The source code is available through our project page at
https://rl.tools.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eschmann_J/0/1/0/all/0/1&quot;&gt;Jonas Eschmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albani_D/0/1/0/all/0/1&quot;&gt;Dario Albani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loianno_G/0/1/0/all/0/1&quot;&gt;Giuseppe Loianno&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.06190">
<title>$FastDoc$: Domain-Specific Fast Pre-training Technique using Document-Level Metadata and Taxonomy. (arXiv:2306.06190v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.06190</link>
<description rdf:parseType="Literal">&lt;p&gt;As the demand for sophisticated Natural Language Processing (NLP) models
continues to grow, so does the need for efficient pre-training techniques.
Current NLP models undergo resource-intensive pre-training. In response, we
introduce $FastDoc$ (Fast Pre-training Technique using Document-Level Metadata
and Taxonomy), a novel approach designed to significantly reduce computational
demands. $FastDoc$ leverages document metadata and domain-specific taxonomy as
supervision signals. It involves continual pre-training of an open-domain
transformer encoder using sentence-level embeddings, followed by fine-tuning
using token-level embeddings. We evaluate $FastDoc$ on six tasks across nine
datasets spanning three distinct domains. Remarkably, $FastDoc$ achieves
remarkable compute reductions of approximately 1,000x, 4,500x, 500x compared to
competitive approaches in Customer Support, Scientific, and Legal domains,
respectively. Importantly, these efficiency gains do not compromise performance
relative to competitive baselines. Furthermore, reduced pre-training data
mitigates catastrophic forgetting, ensuring consistent performance in
open-domain scenarios. $FastDoc$ offers a promising solution for
resource-efficient pre-training, with potential applications spanning various
domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nandy_A/0/1/0/all/0/1&quot;&gt;Abhilash Nandy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapadnis_M/0/1/0/all/0/1&quot;&gt;Manav Nitin Kapadnis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patnaik_S/0/1/0/all/0/1&quot;&gt;Sohan Patnaik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Butala_Y/0/1/0/all/0/1&quot;&gt;Yash Parag Butala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1&quot;&gt;Pawan Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1&quot;&gt;Niloy Ganguly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11281">
<title>Towards Characterizing Domain Counterfactuals For Invertible Latent Causal Models. (arXiv:2306.11281v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11281</link>
<description rdf:parseType="Literal">&lt;p&gt;Answering counterfactual queries has many important applications such as
knowledge discovery and explainability, but is challenging when causal
variables are unobserved and we only see a projection onto an observation
space, for instance, image pixels. One approach is to recover the latent
Structural Causal Model (SCM), but this typically needs unrealistic
assumptions, such as linearity of the causal mechanisms. Another approach is to
use na\&quot;ive ML approximations, such as generative models, to generate
counterfactual samples; however, these lack guarantees of accuracy. In this
work, we strive to strike a balance between practicality and theoretical
guarantees by focusing on a specific type of causal query called domain
counterfactuals, which hypothesizes what a sample would have looked like if it
had been generated in a different domain (or environment). Concretely, by only
assuming invertibility, sparse domain interventions and access to observational
data from different domains, we aim to improve domain counterfactual estimation
both theoretically and practically with less restrictive assumptions. We define
domain counterfactually equivalent models and prove necessary and sufficient
properties for equivalent models that provide a tight characterization of the
domain counterfactual equivalence classes. Building upon this result, we prove
that every equivalence class contains a model where all intervened variables
are at the end when topologically sorted by the causal DAG. This surprising
result suggests that a model design that only allows intervention in the last
$k$ latent variables may improve model estimation for counterfactuals. We then
test this model design on extensive simulated and image-based experiments which
show the sparse canonical model indeed improves counterfactual estimation over
baseline non-sparse models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zeyu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_R/0/1/0/all/0/1&quot;&gt;Ruqi Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulinski_S/0/1/0/all/0/1&quot;&gt;Sean Kulinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kocaoglu_M/0/1/0/all/0/1&quot;&gt;Murat Kocaoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inouye_D/0/1/0/all/0/1&quot;&gt;David I. Inouye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11971">
<title>AdCraft: An Advanced Reinforcement Learning Benchmark Environment for Search Engine Marketing Optimization. (arXiv:2306.11971v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11971</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce AdCraft, a novel benchmark environment for the Reinforcement
Learning (RL) community distinguished by its stochastic and non-stationary
properties. The environment simulates bidding and budgeting dynamics within
Search Engine Marketing (SEM), a digital marketing technique utilizing paid
advertising to enhance the visibility of websites on search engine results
pages (SERPs). The performance of SEM advertisement campaigns depends on
several factors, including keyword selection, ad design, bid management, budget
adjustments, and performance monitoring. Deep RL recently emerged as a
potential strategy to optimize campaign profitability within the complex and
dynamic landscape of SEM, but it requires substantial data, which may be costly
or infeasible to acquire in practice. Our customizable environment enables
practitioners to assess and enhance the robustness of RL algorithms pertinent
to SEM bid and budget management without such costs. Through a series of
experiments within the environment, we demonstrate the challenges imposed on
agent convergence and performance by sparsity and non-stationarity. We hope
these challenges further encourage discourse and development around effective
strategies for managing real-world uncertainties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomrokchi_M/0/1/0/all/0/1&quot;&gt;Maziar Gomrokchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levin_O/0/1/0/all/0/1&quot;&gt;Owen Levin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roach_J/0/1/0/all/0/1&quot;&gt;Jeffrey Roach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_J/0/1/0/all/0/1&quot;&gt;Jonah White&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12370">
<title>PriorBand: Practical Hyperparameter Optimization in the Age of Deep Learning. (arXiv:2306.12370v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12370</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperparameters of Deep Learning (DL) pipelines are crucial for their
downstream performance. While a large number of methods for Hyperparameter
Optimization (HPO) have been developed, their incurred costs are often
untenable for modern DL. Consequently, manual experimentation is still the most
prevalent approach to optimize hyperparameters, relying on the researcher&apos;s
intuition, domain knowledge, and cheap preliminary explorations. To resolve
this misalignment between HPO algorithms and DL researchers, we propose
PriorBand, an HPO algorithm tailored to DL, able to utilize both expert beliefs
and cheap proxy tasks. Empirically, we demonstrate PriorBand&apos;s efficiency
across a range of DL benchmarks and show its gains under informative expert
input and robustness against poor expert beliefs
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mallik_N/0/1/0/all/0/1&quot;&gt;Neeratyoy Mallik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergman_E/0/1/0/all/0/1&quot;&gt;Edward Bergman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hvarfner_C/0/1/0/all/0/1&quot;&gt;Carl Hvarfner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoll_D/0/1/0/all/0/1&quot;&gt;Danny Stoll&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janowski_M/0/1/0/all/0/1&quot;&gt;Maciej Janowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1&quot;&gt;Marius Lindauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nardi_L/0/1/0/all/0/1&quot;&gt;Luigi Nardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.16248">
<title>Latent SDEs on Homogeneous Spaces. (arXiv:2306.16248v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.16248</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of variational Bayesian inference in a latent
variable model where a (possibly complex) observed stochastic process is
governed by the solution of a latent stochastic differential equation (SDE).
Motivated by the challenges that arise when trying to learn an (almost
arbitrary) latent neural SDE from large-scale data, such as efficient gradient
computation, we take a step back and study a specific subclass instead. In our
case, the SDE evolves on a homogeneous latent space and is induced by
stochastic dynamics of the corresponding (matrix) Lie group. In learning
problems, SDEs on the unit $n$-sphere are arguably the most relevant
incarnation of this setup. Notably, for variational inference, the sphere not
only facilitates using a truly uninformative prior SDE, but we also obtain a
particularly simple and intuitive expression for the Kullback-Leibler
divergence between the approximate posterior and prior process in the evidence
lower bound. Experiments demonstrate that a latent SDE of the proposed type can
be learned efficiently by means of an existing one-step geometric
Euler-Maruyama scheme. Despite restricting ourselves to a less diverse class of
SDEs, we achieve competitive or even state-of-the-art performance on various
time series interpolation and classification benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1&quot;&gt;Sebastian Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graf_F/0/1/0/all/0/1&quot;&gt;Florian Graf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwitt_R/0/1/0/all/0/1&quot;&gt;Roland Kwitt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.17108">
<title>ManimML: Communicating Machine Learning Architectures with Animation. (arXiv:2306.17108v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.17108</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been an explosion in interest in machine learning (ML) in recent
years due to its applications to science and engineering. However, as ML
techniques have advanced, tools for explaining and visualizing novel ML
algorithms have lagged behind. Animation has been shown to be a powerful tool
for making engaging visualizations of systems that dynamically change over
time, which makes it well suited to the task of communicating ML algorithms.
However, the current approach to animating ML algorithms is to handcraft
applications that highlight specific algorithms or use complex generalized
animation software. We developed ManimML, an open-source Python library for
easily generating animations of ML algorithms directly from code. We sought to
leverage ML practitioners&apos; preexisting knowledge of programming rather than
requiring them to learn complex animation software. ManimML has a familiar
syntax for specifying neural networks that mimics popular deep learning
frameworks like Pytorch. A user can take a preexisting neural network
architecture and easily write a specification for an animation in ManimML,
which will then automatically compose animations for different components of
the system into a final animation of the entire neural network. ManimML is open
source and available at https://github.com/helblazer811/ManimML.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helbling_A/0/1/0/all/0/1&quot;&gt;Alec Helbling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1&quot;&gt;Duen Horng Chau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.17833">
<title>Resetting the Optimizer in Deep RL: An Empirical Study. (arXiv:2306.17833v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.17833</link>
<description rdf:parseType="Literal">&lt;p&gt;We focus on the task of approximating the optimal value function in deep
reinforcement learning. This iterative process is comprised of solving a
sequence of optimization problems where the loss function changes per
iteration. The common approach to solving this sequence of problems is to
employ modern variants of the stochastic gradient descent algorithm such as
Adam. These optimizers maintain their own internal parameters such as estimates
of the first-order and the second-order moments of the gradient, and update
them over time. Therefore, information obtained in previous iterations is used
to solve the optimization problem in the current iteration. We demonstrate that
this can contaminate the moment estimates because the optimization landscape
can change arbitrarily from one iteration to the next one. To hedge against
this negative effect, a simple idea is to reset the internal parameters of the
optimizer when starting a new iteration. We empirically investigate this
resetting idea by employing various optimizers in conjunction with the Rainbow
algorithm. We demonstrate that this simple modification significantly improves
the performance of deep RL on the Atari benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asadi_K/0/1/0/all/0/1&quot;&gt;Kavosh Asadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fakoor_R/0/1/0/all/0/1&quot;&gt;Rasool Fakoor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabach_S/0/1/0/all/0/1&quot;&gt;Shoham Sabach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08423">
<title>Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems. (arXiv:2307.08423v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08423</link>
<description rdf:parseType="Literal">&lt;p&gt;Advances in artificial intelligence (AI) are fueling a new paradigm of
discoveries in natural sciences. Today, AI has started to advance natural
sciences by improving, accelerating, and enabling our understanding of natural
phenomena at a wide range of spatial and temporal scales, giving rise to a new
area of research known as AI for science (AI4Science). Being an emerging
research paradigm, AI4Science is unique in that it is an enormous and highly
interdisciplinary area. Thus, a unified and technical treatment of this field
is needed yet challenging. This work aims to provide a technically thorough
account of a subarea of AI4Science; namely, AI for quantum, atomistic, and
continuum systems. These areas aim at understanding the physical world from the
subatomic (wavefunctions and electron density), atomic (molecules, proteins,
materials, and interactions), to macro (fluids, climate, and subsurface) scales
and form an important subarea of AI4Science. A unique advantage of focusing on
these areas is that they largely share a common set of challenges, thereby
allowing a unified and foundational treatment. A key common challenge is how to
capture physics first principles, especially symmetries, in natural systems by
deep learning methods. We provide an in-depth yet intuitive account of
techniques to achieve equivariance to symmetry transformations. We also discuss
other common technical challenges, including explainability,
out-of-distribution generalization, knowledge transfer with foundation and
large language models, and uncertainty quantification. To facilitate learning
and education, we provide categorized lists of resources that we found to be
useful. We strive to be thorough and unified and hope this initial effort may
trigger more community interests and efforts to further advance AI4Science.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Limei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helwig_J/0/1/0/all/0/1&quot;&gt;Jacob Helwig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Youzhi Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1&quot;&gt;Cong Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yaochen Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Meng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yuchao Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1&quot;&gt;Keqiang Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adams_K/0/1/0/all/0/1&quot;&gt;Keir Adams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1&quot;&gt;Maurice Weiler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiner Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1&quot;&gt;Tianfan Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yucheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Haiyang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;YuQing Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1&quot;&gt;Xiang Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strasser_A/0/1/0/all/0/1&quot;&gt;Alex Strasser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shenglong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yuanqi Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxton_A/0/1/0/all/0/1&quot;&gt;Alexandra Saxton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1&quot;&gt;Hongyi Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lawrence_H/0/1/0/all/0/1&quot;&gt;Hannah Lawrence&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stark_H/0/1/0/all/0/1&quot;&gt;Hannes St&amp;#xe4;rk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gui_S/0/1/0/all/0/1&quot;&gt;Shurui Gui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_C/0/1/0/all/0/1&quot;&gt;Carl Edwards&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1&quot;&gt;Nicholas Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ladera_A/0/1/0/all/0/1&quot;&gt;Adriana Ladera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tailin Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofgard_E/0/1/0/all/0/1&quot;&gt;Elyssa F. Hofgard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tehrani_A/0/1/0/all/0/1&quot;&gt;Aria Mansouri Tehrani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Rui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daigavane_A/0/1/0/all/0/1&quot;&gt;Ameya Daigavane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bohde_M/0/1/0/all/0/1&quot;&gt;Montgomery Bohde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurtin_J/0/1/0/all/0/1&quot;&gt;Jerry Kurtin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qian Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phung_T/0/1/0/all/0/1&quot;&gt;Tuong Phung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Minkai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_C/0/1/0/all/0/1&quot;&gt;Chaitanya K. Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathis_S/0/1/0/all/0/1&quot;&gt;Simon V. Mathis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1&quot;&gt;Kamyar Azizzadenesheli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_A/0/1/0/all/0/1&quot;&gt;Ada Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aspuru_Guzik_A/0/1/0/all/0/1&quot;&gt;Al&amp;#xe1;n Aspuru-Guzik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1&quot;&gt;Erik Bekkers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1&quot;&gt;Michael Bronstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1&quot;&gt;Marinka Zitnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1&quot;&gt;Pietro Li&amp;#xf2;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1&quot;&gt;Rose Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1&quot;&gt;Heng Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1&quot;&gt;Regina Barzilay&lt;/a&gt;, et al. (6 additional authors not shown)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08433">
<title>From random-walks to graph-sprints: a low-latency node embedding framework on continuous-time dynamic graphs. (arXiv:2307.08433v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08433</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world datasets have an underlying dynamic graph structure, where
entities and their interactions evolve over time. Machine learning models
should consider these dynamics in order to harness their full potential in
downstream tasks. Previous approaches for graph representation learning have
focused on either sampling k-hop neighborhoods, akin to breadth-first search,
or random walks, akin to depth-first search. However, these methods are
computationally expensive and unsuitable for real-time, low-latency inference
on dynamic graphs. To overcome these limitations, we propose graph-sprints a
general purpose feature extraction framework for continuous-time-dynamic-graphs
(CTDGs) that has low latency and is competitive with state-of-the-art, higher
latency models. To achieve this, a streaming, low latency approximation to the
random-walk based features is proposed. In our framework, time-aware node
embeddings summarizing multi-hop information are computed using only single-hop
operations on the incoming edges. We evaluate our proposed approach on three
open-source datasets and two in-house datasets, and compare with three
state-of-the-art algorithms (TGN-attn, TGN-ID, Jodie). We demonstrate that our
graph-sprints features, combined with a machine learning classifier, achieve
competitive performance (outperforming all baselines for the node
classification tasks in five datasets). Simultaneously, graph-sprints
significantly reduce inference latencies, achieving close to an order of
magnitude speed-up in our experimental setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eddin_A/0/1/0/all/0/1&quot;&gt;Ahmad Naser Eddin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bono_J/0/1/0/all/0/1&quot;&gt;Jacopo Bono&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aparicio_D/0/1/0/all/0/1&quot;&gt;David Apar&amp;#xed;cio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreira_H/0/1/0/all/0/1&quot;&gt;Hugo Ferreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ascensao_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Ascens&amp;#xe3;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_P/0/1/0/all/0/1&quot;&gt;Pedro Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bizarro_P/0/1/0/all/0/1&quot;&gt;Pedro Bizarro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.13390">
<title>Counterfactual Explanation via Search in Gaussian Mixture Distributed Latent Space. (arXiv:2307.13390v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.13390</link>
<description rdf:parseType="Literal">&lt;p&gt;Counterfactual Explanations (CEs) are an important tool in Algorithmic
Recourse for addressing two questions: 1. What are the crucial factors that led
to an automated prediction/decision? 2. How can these factors be changed to
achieve a more favorable outcome from a user&apos;s perspective? Thus, guiding the
user&apos;s interaction with AI systems by proposing easy-to-understand explanations
and easy-to-attain feasible changes is essential for the trustworthy adoption
and long-term acceptance of AI systems. In the literature, various methods have
been proposed to generate CEs, and different quality measures have been
suggested to evaluate these methods. However, the generation of CEs is usually
computationally expensive, and the resulting suggestions are unrealistic and
thus non-actionable. In this paper, we introduce a new method to generate CEs
for a pre-trained binary classifier by first shaping the latent space of an
autoencoder to be a mixture of Gaussian distributions. CEs are then generated
in latent space by linear interpolation between the query sample and the
centroid of the target class. We show that our method maintains the
characteristics of the input sample during the counterfactual search. In
various experiments, we show that the proposed method is competitive based on
different quality measures on image and tabular datasets -- efficiently returns
results that are closer to the original data manifold compared to three
state-of-the-art methods, which are essential for realistic high-dimensional
machine learning applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broelemann_K/0/1/0/all/0/1&quot;&gt;Klaus Broelemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1&quot;&gt;Gjergji Kasneci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15053">
<title>On (Normalised) Discounted Cumulative Gain as an Off-Policy Evaluation Metric for Top-$n$ Recommendation. (arXiv:2307.15053v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2307.15053</link>
<description rdf:parseType="Literal">&lt;p&gt;Approaches to recommendation are typically evaluated in one of two ways: (1)
via a (simulated) online experiment, often seen as the gold standard, or (2)
via some offline evaluation procedure, where the goal is to approximate the
outcome of an online experiment. Several offline evaluation metrics have been
adopted in the literature, inspired by ranking metrics prevalent in the field
of Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one
such metric that has seen widespread adoption in empirical studies, and higher
(n)DCG values have been used to present new methods as the state-of-the-art in
top-$n$ recommendation for many years.
&lt;/p&gt;
&lt;p&gt;Our work takes a critical look at this approach, and investigates when we can
expect such metrics to approximate the gold standard outcome of an online
experiment. We formally present the assumptions that are necessary to consider
DCG an unbiased estimator of online reward and provide a derivation for this
metric from first principles, highlighting where we deviate from its
traditional uses in IR. Importantly, we show that normalising the metric
renders it inconsistent, in that even when DCG is unbiased, ranking competing
methods by their normalised DCG can invert their relative order. Through a
correlation analysis between off- and on-line experiments conducted on a
large-scale recommendation platform, we show that our unbiased DCG estimates
strongly correlate with online reward, even when some of the metric&apos;s inherent
assumptions are violated. This statement no longer holds for its normalised
variant, suggesting that nDCG&apos;s practical utility may be limited.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeunen_O/0/1/0/all/0/1&quot;&gt;Olivier Jeunen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potapov_I/0/1/0/all/0/1&quot;&gt;Ivan Potapov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ustimenko_A/0/1/0/all/0/1&quot;&gt;Aleksei Ustimenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.00755">
<title>The Bias Amplification Paradox in Text-to-Image Generation. (arXiv:2308.00755v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.00755</link>
<description rdf:parseType="Literal">&lt;p&gt;Bias amplification is a phenomenon in which models exacerbate biases or
stereotypes present in the training data. In this paper, we study bias
amplification in the text-to-image domain using Stable Diffusion by comparing
gender ratios in training vs. generated images. We find that the model appears
to amplify gender-occupation biases found in the training data (LAION)
considerably. However, we discover that amplification can be largely attributed
to discrepancies between training captions and model prompts. For example, an
inherent difference is that captions from the training data often contain
explicit gender information while our prompts do not, which leads to a
distribution shift and consequently inflates bias measures. Once we account for
distributional differences between texts used for training and generation when
evaluating amplification, we observe that amplification decreases drastically.
Our findings illustrate the challenges of comparing biases in models and their
training data, and highlight confounding factors that impact analyses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seshadri_P/0/1/0/all/0/1&quot;&gt;Preethi Seshadri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sameer Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elazar_Y/0/1/0/all/0/1&quot;&gt;Yanai Elazar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.10238">
<title>Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit. (arXiv:2308.10238v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.10238</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the real-valued combinatorial pure exploration of the multi-armed
bandit (R-CPE-MAB) problem. In R-CPE-MAB, a player is given $d$ stochastic
arms, and the reward of each arm $s\in\{1, \ldots, d\}$ follows an unknown
distribution with mean $\mu_s$. In each time step, a player pulls a single arm
and observes its reward. The player&apos;s goal is to identify the optimal
\emph{action} $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in
\mathcal{A}} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$ from a finite-sized
real-valued \emph{action set} $\mathcal{A}\subset \mathbb{R}^{d}$ with as few
arm pulls as possible. Previous methods in the R-CPE-MAB assume that the size
of the action set $\mathcal{A}$ is polynomial in $d$. We introduce an algorithm
named the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm,
which is the first algorithm that can work even when the size of the action set
is exponentially large in $d$. We also introduce a novel problem-dependent
sample complexity lower bound of the R-CPE-MAB problem, and show that the
GenTS-Explore algorithm achieves the optimal sample complexity up to a
problem-dependent constant factor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamura_S/0/1/0/all/0/1&quot;&gt;Shintaro Nakamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.14119">
<title>Semi-Supervised Learning in the Few-Shot Zero-Shot Scenario. (arXiv:2308.14119v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.14119</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-Supervised Learning (SSL) is a framework that utilizes both labeled and
unlabeled data to enhance model performance. Conventional SSL methods operate
under the assumption that labeled and unlabeled data share the same label
space. However, in practical real-world scenarios, especially when the labeled
training dataset is limited in size, some classes may be totally absent from
the labeled set. To address this broader context, we propose a general approach
to augment existing SSL methods, enabling them to effectively handle situations
where certain classes are missing. This is achieved by introducing an
additional term into their objective function, which penalizes the
KL-divergence between the probability vectors of the true class frequencies and
the inferred class frequencies. Our experimental results reveal significant
improvements in accuracy when compared to state-of-the-art SSL, open-set SSL,
and open-world SSL methods. We conducted these experiments on two benchmark
image classification datasets, CIFAR-100 and STL-10, with the most remarkable
improvements observed when the labeled data is severely limited, with only a
few labeled examples per class
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fluss_N/0/1/0/all/0/1&quot;&gt;Noam Fluss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hacohen_G/0/1/0/all/0/1&quot;&gt;Guy Hacohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinshall_D/0/1/0/all/0/1&quot;&gt;Daphna Weinshall&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.15452">
<title>When Do Program-of-Thoughts Work for Reasoning?. (arXiv:2308.15452v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.15452</link>
<description rdf:parseType="Literal">&lt;p&gt;In the realm of embodied artificial intelligence, the reasoning capabilities
of Large Language Models (LLMs) play a pivotal role. Although there are
effective methods like program-of-thought prompting for LLMs which uses
programming language to tackle complex reasoning tasks, the specific impact of
code data on the improvement of reasoning capabilities remains under-explored.
To address this gap, we propose complexity-impacted reasoning score (CIRS),
which combines structural and logical attributes, to measure the correlation
between code and reasoning abilities. Specifically, we use the abstract syntax
tree to encode the structural information and calculate logical complexity by
considering the difficulty and the cyclomatic complexity. Through an empirical
analysis, we find not all code data of complexity can be learned or understood
by LLMs. Optimal level of complexity is critical to the improvement of
reasoning abilities by program-aided prompting. Then we design an
auto-synthesizing and stratifying algorithm, and apply it to instruction
generation for mathematical reasoning and code data filtering for code
generation tasks. Extensive results demonstrates the effectiveness of our
proposed approach. Code will be integrated into the EasyInstruct framework at
https://github.com/zjunlp/EasyInstruct.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1&quot;&gt;Zhen Bi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1&quot;&gt;Ningyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yinuo Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1&quot;&gt;Shumin Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1&quot;&gt;Guozhou Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huajun Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.08534">
<title>Towards Last-layer Retraining for Group Robustness with Fewer Annotations. (arXiv:2309.08534v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.08534</link>
<description rdf:parseType="Literal">&lt;p&gt;Empirical risk minimization (ERM) of neural networks is prone to
over-reliance on spurious correlations and poor generalization on minority
groups. The recent deep feature reweighting (DFR) technique achieves
state-of-the-art group robustness via simple last-layer retraining, but it
requires held-out group and class annotations to construct a group-balanced
reweighting dataset. In this work, we examine this impractical requirement and
find that last-layer retraining can be surprisingly effective with no group
annotations (other than for model selection) and only a handful of class
annotations. We first show that last-layer retraining can greatly improve
worst-group accuracy even when the reweighting dataset has only a small
proportion of worst-group data. This implies a &quot;free lunch&quot; where holding out a
subset of training data to retrain the last layer can substantially outperform
ERM on the entire dataset with no additional data or annotations. To further
improve group robustness, we introduce a lightweight method called selective
last-layer finetuning (SELF), which constructs the reweighting dataset using
misclassifications or disagreements. Our empirical and theoretical results
present the first evidence that model disagreement upsamples worst-group data,
enabling SELF to nearly match DFR on four well-established benchmarks across
vision and language tasks with no group annotations and less than 3% of the
held-out class annotations. Our code is available at
https://github.com/tmlabonte/last-layer-retraining.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LaBonte_T/0/1/0/all/0/1&quot;&gt;Tyler LaBonte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muthukumar_V/0/1/0/all/0/1&quot;&gt;Vidya Muthukumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Abhishek Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12632">
<title>Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?. (arXiv:2309.12632v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.12632</link>
<description rdf:parseType="Literal">&lt;p&gt;Following the great success of various deep learning methods in image and
object classification, the biomedical image processing society is also
overwhelmed with their applications to various automatic diagnosis cases.
Unfortunately, most of the deep learning-based classification attempts in the
literature solely focus on the aim of extreme accuracy scores, without
considering interpretability, or patient-wise separation of training and test
data. For example, most lung nodule classification papers using deep learning
randomly shuffle data and split it into training, validation, and test sets,
causing certain images from the CT scan of a person to be in the training set,
while other images of the exact same person to be in the validation or testing
image sets. This can result in reporting misleading accuracy rates and the
learning of irrelevant features, ultimately reducing the real-life usability of
these models. When the deep neural networks trained on the traditional, unfair
data shuffling method are challenged with new patient images, it is observed
that the trained models perform poorly. In contrast, deep neural networks
trained with strict patient-level separation maintain their accuracy rates even
when new patient images are tested. Heat-map visualizations of the activations
of the deep neural networks trained with strict patient-level separation
indicate a higher degree of focus on the relevant nodules. We argue that the
research question posed in the title has a positive answer only if the deep
neural networks are trained with images of patients that are strictly isolated
from the validation and testing patient sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashames_M/0/1/0/all/0/1&quot;&gt;Mohamad M.A. Ashames&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demir_A/0/1/0/all/0/1&quot;&gt;Ahmet Demir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerek_O/0/1/0/all/0/1&quot;&gt;Omer N. Gerek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fidan_M/0/1/0/all/0/1&quot;&gt;Mehmet Fidan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gulmezoglu_M/0/1/0/all/0/1&quot;&gt;M. Bilginer Gulmezoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ergin_S/0/1/0/all/0/1&quot;&gt;Semih Ergin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koc_M/0/1/0/all/0/1&quot;&gt;Mehmet Koc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barkana_A/0/1/0/all/0/1&quot;&gt;Atalay Barkana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calisir_C/0/1/0/all/0/1&quot;&gt;Cuneyt Calisir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.17370">
<title>Graph-based Neural Weather Prediction for Limited Area Modeling. (arXiv:2309.17370v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.17370</link>
<description rdf:parseType="Literal">&lt;p&gt;The rise of accurate machine learning methods for weather forecasting is
creating radical new possibilities for modeling the atmosphere. In the time of
climate change, having access to high-resolution forecasts from models like
these is also becoming increasingly vital. While most existing Neural Weather
Prediction (NeurWP) methods focus on global forecasting, an important question
is how these techniques can be applied to limited area modeling. In this work
we adapt the graph-based NeurWP approach to the limited area setting and
propose a multi-scale hierarchical model extension. Our approach is validated
by experiments with a local model for the Nordic region.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oskarsson_J/0/1/0/all/0/1&quot;&gt;Joel Oskarsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Landelius_T/0/1/0/all/0/1&quot;&gt;Tomas Landelius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindsten_F/0/1/0/all/0/1&quot;&gt;Fredrik Lindsten&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00239">
<title>AdaptNet: Policy Adaptation for Physics-Based Character Control. (arXiv:2310.00239v3 [cs.GR] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00239</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by humans&apos; ability to adapt skills in the learning of new ones,
this paper presents AdaptNet, an approach for modifying the latent space of
existing policies to allow new behaviors to be quickly learned from like tasks
in comparison to learning from scratch. Building on top of a given
reinforcement learning controller, AdaptNet uses a two-tier hierarchy that
augments the original state embedding to support modest changes in a behavior
and further modifies the policy network layers to make more substantive
changes. The technique is shown to be effective for adapting existing
physics-based controllers to a wide range of new styles for locomotion, new
task targets, changes in character morphology and extensive changes in
environment. Furthermore, it exhibits significant increase in learning
efficiency, as indicated by greatly reduced training times when compared to
training from scratch or using other approaches that modify existing policies.
Code is available at https://motion-lab.github.io/AdaptNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Pei Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1&quot;&gt;Kaixiang Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andrews_S/0/1/0/all/0/1&quot;&gt;Sheldon Andrews&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kry_P/0/1/0/all/0/1&quot;&gt;Paul G. Kry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neff_M/0/1/0/all/0/1&quot;&gt;Michael Neff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGuire_M/0/1/0/all/0/1&quot;&gt;Morgan McGuire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karamouzas_I/0/1/0/all/0/1&quot;&gt;Ioannis Karamouzas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zordan_V/0/1/0/all/0/1&quot;&gt;Victor Zordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01258">
<title>MobileNVC: Real-time 1080p Neural Video Compression on a Mobile Device. (arXiv:2310.01258v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.01258</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural video codecs have recently become competitive with standard codecs
such as HEVC in the low-delay setting. However, most neural codecs are large
floating-point networks that use pixel-dense warping operations for temporal
modeling, making them too computationally expensive for deployment on mobile
devices. Recent work has demonstrated that running a neural decoder in real
time on mobile is feasible, but shows this only for 720p RGB video. This work
presents the first neural video codec that decodes 1080p YUV420 video in real
time on a mobile device. Our codec relies on two major contributions. First, we
design an efficient codec that uses a block-based motion compensation algorithm
available on the warping core of the mobile accelerator, and we show how to
quantize this model to integer precision. Second, we implement a fast decoder
pipeline that concurrently runs neural network components on the neural signal
processor, parallel entropy coding on the mobile GPU, and warping on the
warping core. Our codec outperforms the previous on-device codec by a large
margin with up to 48% BD-rate savings, while reducing the MAC count on the
receiver side by $10 \times$. We perform a careful ablation to demonstrate the
effect of the introduced motion compensation scheme, and ablate the effect of
model quantization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rozendaal_T/0/1/0/all/0/1&quot;&gt;Ties van Rozendaal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Singhal_T/0/1/0/all/0/1&quot;&gt;Tushar Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Le_H/0/1/0/all/0/1&quot;&gt;Hoang Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sautiere_G/0/1/0/all/0/1&quot;&gt;Guillaume Sautiere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Said_A/0/1/0/all/0/1&quot;&gt;Amir Said&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Buska_K/0/1/0/all/0/1&quot;&gt;Krishna Buska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Raha_A/0/1/0/all/0/1&quot;&gt;Anjuman Raha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kalatzis_D/0/1/0/all/0/1&quot;&gt;Dimitris Kalatzis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mehta_H/0/1/0/all/0/1&quot;&gt;Hitarth Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mayer_F/0/1/0/all/0/1&quot;&gt;Frank Mayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nagel_M/0/1/0/all/0/1&quot;&gt;Markus Nagel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wiggers_A/0/1/0/all/0/1&quot;&gt;Auke Wiggers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.07250">
<title>Synthesizing Missing MRI Sequences from Available Modalities using Generative Adversarial Networks in BraTS Dataset. (arXiv:2310.07250v3 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2310.07250</link>
<description rdf:parseType="Literal">&lt;p&gt;Glioblastoma is a highly aggressive and lethal form of brain cancer. Magnetic
resonance imaging (MRI) plays a significant role in the diagnosis, treatment
planning, and follow-up of glioblastoma patients due to its non-invasive and
radiation-free nature. The International Brain Tumor Segmentation (BraTS)
challenge has contributed to generating numerous AI algorithms to accurately
and efficiently segment glioblastoma sub-compartments using four structural
(T1, T1Gd, T2, T2-FLAIR) MRI scans. However, these four MRI sequences may not
always be available. To address this issue, Generative Adversarial Networks
(GANs) can be used to synthesize the missing MRI sequences. In this paper, we
implement and utilize an open-source GAN approach that takes any three MRI
sequences as input to generate the missing fourth structural sequence. Our
proposed approach is contributed to the community-driven generally nuanced deep
learning framework (GaNDLF) and demonstrates promising results in synthesizing
high-quality and realistic MRI sequences, enabling clinicians to improve their
diagnostic capabilities and support the application of AI methods to brain
tumor MRI quantification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hamamci_I/0/1/0/all/0/1&quot;&gt;Ibrahim Ethem Hamamci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.09336">
<title>Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task. (arXiv:2310.09336v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.09336</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern generative models exhibit unprecedented capabilities to generate
extremely realistic data. However, given the inherent compositionality of the
real world, reliable use of these models in practical applications requires
that they exhibit the capability to compose a novel set of concepts to generate
outputs not seen in the training data set. Prior work demonstrates that recent
diffusion models do exhibit intriguing compositional generalization abilities,
but also fail unpredictably. Motivated by this, we perform a controlled study
for understanding compositional generalization in conditional diffusion models
in a synthetic setting, varying different attributes of the training data and
measuring the model&apos;s ability to generate samples out-of-distribution. Our
results show: (i) the order in which the ability to generate samples from a
concept and compose them emerges is governed by the structure of the underlying
data-generating process; (ii) performance on compositional tasks exhibits a
sudden &quot;emergence&quot; due to multiplicative reliance on the performance of
constituent tasks, partially explaining emergent phenomena seen in generative
models; and (iii) composing concepts with lower frequency in the training data
to generate out-of-distribution samples requires considerably more optimization
steps compared to generating in-distribution samples. Overall, our study lays a
foundation for understanding capabilities and compositionality in generative
models from a data-centric perspective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okawa_M/0/1/0/all/0/1&quot;&gt;Maya Okawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1&quot;&gt;Ekdeep Singh Lubana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1&quot;&gt;Robert P. Dick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1&quot;&gt;Hidenori Tanaka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.11305">
<title>MiniZero: Comparative Analysis of AlphaZero and MuZero on Go, Othello, and Atari Games. (arXiv:2310.11305v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2310.11305</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents MiniZero, a zero-knowledge learning framework that
supports four state-of-the-art algorithms, including AlphaZero, MuZero, Gumbel
AlphaZero, and Gumbel MuZero. While these algorithms have demonstrated
super-human performance in many games, it remains unclear which among them is
most suitable or efficient for specific tasks. Through MiniZero, we
systematically evaluate the performance of each algorithm in two board games,
9x9 Go and 8x8 Othello, as well as 57 Atari games. For two board games, using
more simulations generally results in higher performance. However, the choice
of AlphaZero and MuZero may differ based on game properties. For Atari games,
both MuZero and Gumbel MuZero are worth considering. Since each game has unique
characteristics, different algorithms and simulations yield varying results. In
addition, we introduce an approach, called progressive simulation, which
progressively increases the simulation budget during training to allocate
computation more efficiently. Our empirical results demonstrate that
progressive simulation achieves significantly superior performance in two board
games. By making our framework and trained models publicly available, this
paper contributes a benchmark for future research on zero-knowledge learning
algorithms, assisting researchers in algorithm selection and comparison against
these zero-knowledge learning baselines. Our code and data are available at
https://rlg.iis.sinica.edu.tw/papers/minizero.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Ti-Rong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guei_H/0/1/0/all/0/1&quot;&gt;Hung Guei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1&quot;&gt;Po-Wei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1&quot;&gt;Pei-Chiun Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1&quot;&gt;Ting Han Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shih_C/0/1/0/all/0/1&quot;&gt;Chung-Chin Shih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1&quot;&gt;Yun-Jui Tsai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13913">
<title>Pre-Training on Large-Scale Generated Docking Conformations with HelixDock to Unlock the Potential of Protein-ligand Structure Prediction Models. (arXiv:2310.13913v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13913</link>
<description rdf:parseType="Literal">&lt;p&gt;Protein-ligand structure prediction is an essential task in drug discovery,
predicting the binding interactions between small molecules (ligands) and
target proteins (receptors). Although conventional physics-based docking tools
are widely utilized, their accuracy is compromised by limited conformational
sampling and imprecise scoring functions. Recent advances have incorporated
deep learning techniques to improve the accuracy of structure prediction.
Nevertheless, the experimental validation of docking conformations remains
costly, it raises concerns regarding the generalizability of these deep
learning-based methods due to the limited training data. In this work, we show
that by pre-training a geometry-aware SE(3)-Equivariant neural network on a
large-scale docking conformation generated by traditional physics-based docking
tools and then fine-tuning with a limited set of experimentally validated
receptor-ligand complexes, we can achieve outstanding performance. This process
involved the generation of 100 million docking conformations, consuming roughly
1 million CPU core days. The proposed model, HelixDock, aims to acquire the
physical knowledge encapsulated by the physics-based docking tools during the
pre-training phase. HelixDock has been benchmarked against both physics-based
and deep learning-based baselines, showing that it outperforms its closest
competitor by over 40% for RMSD. HelixDock also exhibits enhanced performance
on a dataset that poses a greater challenge, thereby highlighting its
robustness. Moreover, our investigation reveals the scaling laws governing
pre-trained structure prediction models, indicating a consistent enhancement in
performance with increases in model parameters and pre-training data. This
study illuminates the strategic advantage of leveraging a vast and varied
repository of generated data to advance the frontiers of AI-driven drug
discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lihang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1&quot;&gt;Donglong He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1&quot;&gt;Xianbin Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jingbo Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shanzhuo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaonan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chai_H/0/1/0/all/0/1&quot;&gt;Hua Chai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Jingzhou He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Liang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yonghui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1&quot;&gt;Xiaomin Fang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.14085">
<title>Adaptive, Doubly Optimal No-Regret Learning in Strongly Monotone and Exp-Concave Games with Gradient Feedback. (arXiv:2310.14085v3 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/2310.14085</link>
<description rdf:parseType="Literal">&lt;p&gt;Online gradient descent (OGD) is well known to be doubly optimal under strong
convexity or monotonicity assumptions: (1) in the single-agent setting, it
achieves an optimal regret of $\Theta(\log T)$ for strongly convex cost
functions; and (2) in the multi-agent setting of strongly monotone games, with
each agent employing OGD, we obtain last-iterate convergence of the joint
action to a unique Nash equilibrium at an optimal rate of
$\Theta(\frac{1}{T})$. While these finite-time guarantees highlight its merits,
OGD has the drawback that it requires knowing the strong convexity/monotonicity
parameters. In this paper, we design a fully adaptive OGD algorithm,
\textsf{AdaOGD}, that does not require a priori knowledge of these parameters.
In the single-agent setting, our algorithm achieves $O(\log^2(T))$ regret under
strong convexity, which is optimal up to a log factor. Further, if each agent
employs \textsf{AdaOGD} in strongly monotone games, the joint action converges
in a last-iterate sense to a unique Nash equilibrium at a rate of
$O(\frac{\log^3 T}{T})$, again optimal up to log factors. We illustrate our
algorithms in a learning version of the classical newsvendor problem, where due
to lost sales, only (noisy) gradient feedback can be observed. Our results
immediately yield the first feasible and near-optimal algorithm for both the
single-retailer and multi-retailer settings. We also extend our results to the
more general setting of exp-concave cost functions and games, using the online
Newton step (ONS) algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tianyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhengyuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.14421">
<title>On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers. (arXiv:2310.14421v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2310.14421</link>
<description rdf:parseType="Literal">&lt;p&gt;Simply-verifiable mathematical conditions for existence, uniqueness and
explicit analytical computation of minimal adversarial paths (MAP) and minimal
adversarial distances (MAD) for (locally) uniquely-invertible classifiers, for
generalized linear models (GLM), and for entropic AI (EAI) are formulated and
proven. Practical computation of MAP and MAD, their comparison and
interpretations for various classes of AI tools (for neuronal networks, boosted
random forests, GLM and EAI) are demonstrated on the common synthetic
benchmarks: on a double Swiss roll spiral and its extensions, as well as on the
two biomedical data problems (for the health insurance claim predictions, and
for the heart attack lethality classification). On biomedical applications it
is demonstrated how MAP provides unique minimal patient-specific
risk-mitigating interventions in the predefined subsets of accessible control
variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Horenko_I/0/1/0/all/0/1&quot;&gt;Illia Horenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.15612">
<title>Machine Translation for Nko: Tools, Corpora and Baseline Results. (arXiv:2310.15612v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.15612</link>
<description rdf:parseType="Literal">&lt;p&gt;Currently, there is no usable machine translation system for Nko, a language
spoken by tens of millions of people across multiple West African countries,
which holds significant cultural and educational value.
&lt;/p&gt;
&lt;p&gt;To address this issue, we present a set of tools, resources, and baseline
results aimed towards the development of usable machine translation systems for
Nko and other languages that do not currently have sufficiently large parallel
text corpora available.
&lt;/p&gt;
&lt;p&gt;(1) Fria$\parallel$el: A novel collaborative parallel text curation software
that incorporates quality control through copyedit-based workflows.
&lt;/p&gt;
&lt;p&gt;(2) Expansion of the FLoRes-200 and NLLB-Seed corpora with 2,009 and 6,193
high-quality Nko translations in parallel with 204 and 40 other languages.
&lt;/p&gt;
&lt;p&gt;(3) nicolingua-0005: A collection of trilingual and bilingual corpora with
130,850 parallel segments and monolingual corpora containing over 3 million Nko
words.
&lt;/p&gt;
&lt;p&gt;(4) Baseline bilingual and multilingual neural machine translation results
with the best model scoring 30.83 English-Nko chrF++ on FLoRes-devtest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doumbouya_M/0/1/0/all/0/1&quot;&gt;Moussa Koulako Bala Doumbouya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diane_B/0/1/0/all/0/1&quot;&gt;Baba Mamadi Dian&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cisse_S/0/1/0/all/0/1&quot;&gt;Solo Farabado Ciss&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diane_D/0/1/0/all/0/1&quot;&gt;Djibrila Dian&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sow_A/0/1/0/all/0/1&quot;&gt;Abdoulaye Sow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doumbouya_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;r&amp;#xe9; Moussa Doumbouya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bangoura_D/0/1/0/all/0/1&quot;&gt;Daouda Bangoura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bayo_F/0/1/0/all/0/1&quot;&gt;Fod&amp;#xe9; Moriba Bayo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conde_I/0/1/0/all/0/1&quot;&gt;Ibrahima Sory 2. Cond&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diane_K/0/1/0/all/0/1&quot;&gt;Kalo Mory Dian&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piech_C/0/1/0/all/0/1&quot;&gt;Chris Piech&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1&quot;&gt;Christopher Manning&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.15681">
<title>Fixed-Budget Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit. (arXiv:2310.15681v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.15681</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the real-valued combinatorial pure exploration of the multi-armed
bandit in the fixed-budget setting. We first introduce the Combinatorial
Successive Asign (CSA) algorithm, which is the first algorithm that can
identify the best action even when the size of the action class is
exponentially large with respect to the number of arms. We show that the upper
bound of the probability of error of the CSA algorithm matches a lower bound up
to a logarithmic factor in the exponent. Then, we introduce another algorithm
named the Minimax Combinatorial Successive Accepts and Rejects
(Minimax-CombSAR) algorithm for the case where the size of the action class is
polynomial, and show that it is optimal, which matches a lower bound. Finally,
we experimentally compare the algorithms with previous methods and show that
our algorithm performs better.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamura_S/0/1/0/all/0/1&quot;&gt;Shintaro Nakamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.17658">
<title>Is Channel Independent strategy optimal for Time Series Forecasting?. (arXiv:2310.17658v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.17658</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been an emergence of various models for long-term time series
forecasting. Recent studies have demonstrated that a single linear layer, using
Channel Dependent (CD) or Channel Independent (CI) modeling, can even
outperform a large number of sophisticated models. However, current research
primarily considers CD and CI as two complementary yet mutually exclusive
approaches, unable to harness these two extremes simultaneously. And it is also
a challenging issue that both CD and CI are static strategies that cannot be
determined to be optimal for a specific dataset without extensive experiments.
In this paper, we reconsider whether the current CI strategy is the best
solution for time series forecasting. First, we propose a simple yet effective
strategy called CSC, which stands for $\mathbf{C}$hannel
$\mathbf{S}$elf-$\mathbf{C}$lustering strategy, for linear models. Our Channel
Self-Clustering (CSC) enhances CI strategy&apos;s performance improvements while
reducing parameter size, for exmpale by over 10 times on electricity dataset,
and significantly cutting training time. Second, we further propose Channel
Rearrangement (CR), a method for deep models inspired by the self-clustering.
CR attains competitive performance against baselines. Finally, we also discuss
whether it is best to forecast the future values using the historical values of
the same channel as inputs. We hope our findings and methods could inspire new
solutions beyond CD/CI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peiwen_Y/0/1/0/all/0/1&quot;&gt;Yuan Peiwen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Changsheng_Z/0/1/0/all/0/1&quot;&gt;Zhu Changsheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.18306">
<title>Supervised and Penalized Baseline Correction. (arXiv:2310.18306v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2310.18306</link>
<description rdf:parseType="Literal">&lt;p&gt;Spectroscopic measurements can show distorted spectral shapes arising from a
mixture of absorbing and scattering contributions. These distortions (or
baselines) often manifest themselves as non-constant offsets or low-frequency
oscillations. As a result, these baselines can adversely affect analytical and
quantitative results. Baseline correction is an umbrella term where one applies
pre-processing methods to obtain baseline spectra (the unwanted distortions)
and then remove the distortions by differencing. However, current state-of-the
art baseline correction methods do not utilize analyte concentrations even if
they are available, or even if they contribute significantly to the observed
spectral variability. We examine a class of state-of-the-art methods (penalized
baseline correction) and modify them such that they can accommodate a priori
analyte concentrations such that prediction can be enhanced. Performance will
be assessed on two near infra-red data sets across both classical penalized
baseline correction methods (without analyte information) and modified
penalized baseline correction methods (leveraging analyte information).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Andries_E/0/1/0/all/0/1&quot;&gt;Erik Andries&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nikzad_Langerodi_R/0/1/0/all/0/1&quot;&gt;Ramin Nikzad-Langerodi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00684">
<title>Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation. (arXiv:2311.00684v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.00684</link>
<description rdf:parseType="Literal">&lt;p&gt;An ideal length-extrapolatable Transformer language model can handle
sequences longer than the training length without any fine-tuning. Such
long-context utilization capability relies heavily on a flexible positional
embedding design. Upon investigating the flexibility of existing large
pre-trained Transformer language models, we find that the T5 family deserves a
closer look, as its positional embeddings capture rich and flexible attention
patterns. However, T5 suffers from the dispersed attention issue: the longer
the input sequence, the flatter the attention distribution. To alleviate the
issue, we propose two attention alignment strategies via temperature scaling.
Our findings show improvement on the long-context utilization capability of T5
on language modeling, retrieval, multi-document question answering, and code
completion tasks without any fine-tuning. This suggests that a flexible
positional embedding design and attention alignment can go a long way toward
Transformer length extrapolation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_T/0/1/0/all/0/1&quot;&gt;Ta-Chung Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1&quot;&gt;Ting-Han Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudnicky_A/0/1/0/all/0/1&quot;&gt;Alexander I. Rudnicky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00735">
<title>PET Tracer Conversion among Brain PET via Variable Augmented Invertible Network. (arXiv:2311.00735v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.00735</link>
<description rdf:parseType="Literal">&lt;p&gt;Positron emission tomography (PET) serves as an essential tool for diagnosis
of encephalopathy and brain science research. However, it suffers from the
limited choice of tracers. Nowadays, with the wide application of PET imaging
in neuropsychiatric treatment, 6-18F-fluoro-3, 4-dihydroxy-L-phenylalanine
(DOPA) has been found to be more effective than 18F-labeled
fluorine-2-deoxyglucose (FDG) in the field. Nevertheless, due to the complexity
of its preparation and other limitations, DOPA is far less widely used than
FDG. To address this issue, a tracer conversion invertible neural network
(TC-INN) for image projection is developed to map FDG images to DOPA images
through deep learning. More diagnostic information is obtained by generating
PET images from FDG to DOPA. Specifically, the proposed TC-INN consists of two
separate phases, one for training traceable data, the other for rebuilding new
data. The reference DOPA PET image is used as a learning target for the
corresponding network during the training process of tracer conversion.
Meanwhile, the invertible network iteratively estimates the resultant DOPA PET
data and compares it to the reference DOPA PET data. Notably, the reversible
model employs variable enhancement technique to achieve better power
generation. Moreover, image registration needs to be performed before training
due to the angular deviation of the acquired FDG and DOPA data information.
Experimental results exhibited excellent generation capability in mapping
between FDG and DOPA, suggesting that PET tracer conversion has great potential
in the case of limited tracer applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1&quot;&gt;Bohui Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xubiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Pengfei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shirui Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1&quot;&gt;Xinchong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiangsong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weirui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bingxuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiegen Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02762">
<title>Fast Sparse 3D Convolution Network with VDB. (arXiv:2311.02762v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2311.02762</link>
<description rdf:parseType="Literal">&lt;p&gt;We proposed a new Convolution Neural Network implementation optimized for
sparse 3D data inference. This implementation uses NanoVDB as the data
structure to store the sparse tensor. It leaves a relatively small memory
footprint while maintaining high performance. We demonstrate that this
architecture is around 20 times faster than the state-of-the-art dense CNN
model on a high-resolution 3D object classification network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1&quot;&gt;Fangjun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_A/0/1/0/all/0/1&quot;&gt;Anyong Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sifakis_E/0/1/0/all/0/1&quot;&gt;Eftychios Sifakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.03217">
<title>Leveraging Transformers to Improve Breast Cancer Classification and Risk Assessment with Multi-modal and Longitudinal Data. (arXiv:2311.03217v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2311.03217</link>
<description rdf:parseType="Literal">&lt;p&gt;Breast cancer screening, primarily conducted through mammography, is often
supplemented with ultrasound for women with dense breast tissue. However,
existing deep learning models analyze each modality independently, missing
opportunities to integrate information across imaging modalities and time. In
this study, we present Multi-modal Transformer (MMT), a neural network that
utilizes mammography and ultrasound synergistically, to identify patients who
currently have cancer and estimate the risk of future cancer for patients who
are currently cancer-free. MMT aggregates multi-modal data through
self-attention and tracks temporal tissue changes by comparing current exams to
prior imaging. Trained on 1.3 million exams, MMT achieves an AUROC of 0.943 in
detecting existing cancers, surpassing strong uni-modal baselines. For 5-year
risk prediction, MMT attains an AUROC of 0.826, outperforming prior
mammography-based risk models. Our research highlights the value of multi-modal
and longitudinal imaging in cancer diagnosis and risk stratification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yiqiu Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jungkyu Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yeung_F/0/1/0/all/0/1&quot;&gt;Frank Yeung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Goldberg_E/0/1/0/all/0/1&quot;&gt;Eliana Goldberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Heacock_L/0/1/0/all/0/1&quot;&gt;Laura Heacock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shamout_F/0/1/0/all/0/1&quot;&gt;Farah Shamout&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Geras_K/0/1/0/all/0/1&quot;&gt;Krzysztof J. Geras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04037">
<title>Causal Discovery Under Local Privacy. (arXiv:2311.04037v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2311.04037</link>
<description rdf:parseType="Literal">&lt;p&gt;Differential privacy is a widely adopted framework designed to safeguard the
sensitive information of data providers within a data set. It is based on the
application of controlled noise at the interface between the server that stores
and processes the data, and the data consumers. Local differential privacy is a
variant that allows data providers to apply the privatization mechanism
themselves on their data individually. Therefore it provides protection also in
contexts in which the server, or even the data collector, cannot be trusted.
The introduction of noise, however, inevitably affects the utility of the data,
particularly by distorting the correlations between individual data components.
This distortion can prove detrimental to tasks such as causal discovery. In
this paper, we consider various well-known locally differentially private
mechanisms and compare the trade-off between the privacy they provide, and the
accuracy of the causal structure produced by algorithms for causal learning
when applied to data obfuscated by these mechanisms. Our analysis yields
valuable insights for selecting appropriate local differentially private
protocols for causal discovery tasks. We foresee that our findings will aid
researchers and practitioners in conducting locally private causal discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binkyte_R/0/1/0/all/0/1&quot;&gt;R&amp;#x16b;ta Binkyt&amp;#x117;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinzon_C/0/1/0/all/0/1&quot;&gt;Carlos Pinz&amp;#xf3;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lestyan_S/0/1/0/all/0/1&quot;&gt;Szilvia Lesty&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1&quot;&gt;Kangsoo Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arcolezi_H/0/1/0/all/0/1&quot;&gt;H&amp;#xe9;ber H. Arcolezi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1&quot;&gt;Catuscia Palamidessi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04378">
<title>Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models. (arXiv:2311.04378v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.04378</link>
<description rdf:parseType="Literal">&lt;p&gt;Watermarking generative models consists of planting a statistical signal
(watermark) in a model&apos;s output so that it can be later verified that the
output was generated by the given model. A strong watermarking scheme satisfies
the property that a computationally bounded attacker cannot erase the watermark
without causing significant quality degradation. In this paper, we study the
(im)possibility of strong watermarking schemes. We prove that, under
well-specified and natural assumptions, strong watermarking is impossible to
achieve. This holds even in the private detection algorithm setting, where the
watermark insertion and detection algorithms share a secret key, unknown to the
attacker. To prove this result, we introduce a generic efficient watermark
attack; the attacker is not required to know the private key of the scheme or
even which scheme is used. Our attack is based on two assumptions: (1) The
attacker has access to a &quot;quality oracle&quot; that can evaluate whether a candidate
output is a high-quality response to a prompt, and (2) The attacker has access
to a &quot;perturbation oracle&quot; which can modify an output with a nontrivial
probability of maintaining quality, and which induces an efficiently mixing
random walk on high-quality outputs. We argue that both assumptions can be
satisfied in practice by an attacker with weaker computational capabilities
than the watermarked model itself, to which the attacker has only black-box
access. Furthermore, our assumptions will likely only be easier to satisfy over
time as models grow in capabilities and modalities. We demonstrate the
feasibility of our attack by instantiating it to attack three existing
watermarking schemes for large language models: Kirchenbauer et al. (2023),
Kuditipudi et al. (2023), and Zhao et al. (2023). The same attack successfully
removes the watermarks planted by all three schemes, with only minor quality
degradation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hanlin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edelman_B/0/1/0/all/0/1&quot;&gt;Benjamin L. Edelman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Francati_D/0/1/0/all/0/1&quot;&gt;Danilo Francati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venturi_D/0/1/0/all/0/1&quot;&gt;Daniele Venturi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ateniese_G/0/1/0/all/0/1&quot;&gt;Giuseppe Ateniese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barak_B/0/1/0/all/0/1&quot;&gt;Boaz Barak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04818">
<title>Cross-Silo Federated Learning Across Divergent Domains with Iterative Parameter Alignment. (arXiv:2311.04818v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.04818</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning from the collective knowledge of data dispersed across private
sources can provide neural networks with enhanced generalization capabilities.
Federated learning, a method for collaboratively training a machine learning
model across remote clients, achieves this by combining client models via the
orchestration of a central server. However, current approaches face two
critical limitations: i) they struggle to converge when client domains are
sufficiently different, and ii) current aggregation techniques produce an
identical global model for each client. In this work, we address these issues
by reformulating the typical federated learning setup: rather than learning a
single global model, we learn N models each optimized for a common objective.
To achieve this, we apply a weighted distance minimization to model parameters
shared in a peer-to-peer topology. The resulting framework, Iterative Parameter
Alignment, applies naturally to the cross-silo setting, and has the following
properties: (i) a unique solution for each participant, with the option to
globally converge each model in the federation, and (ii) an optional
early-stopping mechanism to elicit fairness among peers in collaborative
learning settings. These characteristics jointly provide a flexible new
framework for iteratively learning from peer models trained on disparate
datasets. We find that the technique achieves competitive results on a variety
of data partitions compared to state-of-the-art approaches. Further, we show
that the method is robust to divergent domains (i.e. disjoint classes across
peers) where existing approaches struggle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorbett_M/0/1/0/all/0/1&quot;&gt;Matt Gorbett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shirazi_H/0/1/0/all/0/1&quot;&gt;Hossein Shirazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_I/0/1/0/all/0/1&quot;&gt;Indrakshi Ray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05836">
<title>Uncertainty-aware Single View Volumetric Rendering for Medical Neural Radiance Fields. (arXiv:2311.05836v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2311.05836</link>
<description rdf:parseType="Literal">&lt;p&gt;In the field of clinical medicine, computed tomography (CT) is an effective
medical imaging modality for the diagnosis of various pathologies. Compared
with X-ray images, CT images can provide more information, including
multi-planar slices and three-dimensional structures for clinical diagnosis.
However, CT imaging requires patients to be exposed to large doses of ionizing
radiation for a long time, which may cause irreversible physical harm. In this
paper, we propose an Uncertainty-aware MedNeRF (UMedNeRF) network based on
generated radiation fields. The network can learn a continuous representation
of CT projections from 2D X-ray images by obtaining the internal structure and
depth information and using adaptive loss weights to ensure the quality of the
generated images. Our model is trained on publicly available knee and chest
datasets, and we show the results of CT projection rendering with a single
X-ray and compare our method with other methods based on generated radiation
fields.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jing Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fan_Q/0/1/0/all/0/1&quot;&gt;Qinrui Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hu_S/0/1/0/all/0/1&quot;&gt;Shu Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lyu_S/0/1/0/all/0/1&quot;&gt;Siwei Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.06281">
<title>Efficient Parallelization of an Ubiquitous Sequential Computation. (arXiv:2311.06281v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2311.06281</link>
<description rdf:parseType="Literal">&lt;p&gt;We find a succinct expression for computing the sequence $x_t = a_t x_{t-1} +
b_t$ in parallel with two prefix sums, given $t = (1, 2, \dots, n)$, $a_t \in
\mathbb{R}^n$, $b_t \in \mathbb{R}^n$, and initial value $x_0 \in \mathbb{R}$.
On $n$ parallel processors, the computation of $n$ elements incurs
$\mathcal{O}(\log n)$ time and $\mathcal{O}(n)$ space. Sequences of this form
are ubiquitous in science and engineering, making efficient parallelization
useful for a vast number of applications. We implement our expression in
software, test it on parallel hardware, and verify that it executes faster than
sequential computation by a factor of $\frac{n}{\log n}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinsen_F/0/1/0/all/0/1&quot;&gt;Franz A. Heinsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.06928">
<title>Attention for Causal Relationship Discovery from Biological Neural Dynamics. (arXiv:2311.06928v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.06928</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the potential of the transformer models for learning
Granger causality in networks with complex nonlinear dynamics at every node, as
in neurobiological and biophysical networks. Our study primarily focuses on a
proof-of-concept investigation based on simulated neural dynamics, for which
the ground-truth causality is known through the underlying connectivity matrix.
For transformer models trained to forecast neuronal population dynamics, we
show that the cross attention module effectively captures the causal
relationship among neurons, with an accuracy equal or superior to that for the
most popular Granger causality analysis method. While we acknowledge that
real-world neurobiology data will bring further challenges, including dynamic
connectivity and unobserved variability, this research offers an encouraging
preliminary glimpse into the utility of the transformer model for causal
representation learning in neuroscience.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Ziyu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabassum_A/0/1/0/all/0/1&quot;&gt;Anika Tabassum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1&quot;&gt;Shruti Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mi_L/0/1/0/all/0/1&quot;&gt;Lu Mi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1&quot;&gt;J. Nathan Kutz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shea_Brown_E/0/1/0/all/0/1&quot;&gt;Eric Shea-Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1&quot;&gt;Seung-Hwan Lim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.07079">
<title>Sample Dominance Aware Framework via Non-Parametric Estimation for Spontaneous Brain-Computer Interface. (arXiv:2311.07079v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.07079</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has shown promise in decoding brain signals, such as
electroencephalogram (EEG), in the field of brain-computer interfaces (BCIs).
However, the non-stationary characteristics of EEG signals pose challenges for
training neural networks to acquire appropriate knowledge. Inconsistent EEG
signals resulting from these non-stationary characteristics can lead to poor
performance. Therefore, it is crucial to investigate and address sample
inconsistency to ensure robust performance in spontaneous BCIs. In this study,
we introduce the concept of sample dominance as a measure of EEG signal
inconsistency and propose a method to modulate its effect on network training.
We present a two-stage dominance score estimation technique that compensates
for performance degradation caused by sample inconsistencies. Our proposed
method utilizes non-parametric estimation to infer sample inconsistency and
assigns each sample a dominance score. This score is then aggregated with the
loss function during training to modulate the impact of sample inconsistency.
Furthermore, we design a curriculum learning approach that gradually increases
the influence of inconsistent signals during training to improve overall
performance. We evaluate our proposed method using public spontaneous BCI
dataset. The experimental results confirm that our findings highlight the
importance of addressing sample dominance for achieving robust performance in
spontaneous BCIs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1&quot;&gt;Byeong-Hoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwon_B/0/1/0/all/0/1&quot;&gt;Byoung-Hee Kwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seong-Whan Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.07636">
<title>Attention-based Multi-task Learning for Base Editor Outcome Prediction. (arXiv:2311.07636v2 [q-bio.GN] UPDATED)</title>
<link>http://arxiv.org/abs/2311.07636</link>
<description rdf:parseType="Literal">&lt;p&gt;Human genetic diseases often arise from point mutations, emphasizing the
critical need for precise genome editing techniques. Among these, base editing
stands out as it allows targeted alterations at the single nucleotide level.
However, its clinical application is hindered by low editing efficiency and
unintended mutations, necessitating extensive trial-and-error experimentation
in the laboratory. To speed up this process, we present an attention-based
two-stage machine learning model that learns to predict the likelihood of all
possible editing outcomes for a given genomic target sequence. We further
propose a multi-task learning schema to jointly learn multiple base editors
(i.e. variants) at once. Our model&apos;s predictions consistently demonstrated a
strong correlation with the actual experimental results on multiple datasets
and base editor variants. These results provide further validation for the
models&apos; capacity to enhance and accelerate the process of refining base editing
designs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Mollaysa_A/0/1/0/all/0/1&quot;&gt;Amina Mollaysa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Allam_A/0/1/0/all/0/1&quot;&gt;Ahmed Allam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Krauthammer_M/0/1/0/all/0/1&quot;&gt;Michael Krauthammer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.07772">
<title>In-context Learning and Gradient Descent Revisited. (arXiv:2311.07772v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.07772</link>
<description rdf:parseType="Literal">&lt;p&gt;In-context learning (ICL) has shown impressive results in few-shot learning
tasks, yet its underlying mechanism is still not fully understood. Recent works
suggest that ICL can be thought of as a gradient descent (GD) based
optimization process. While promising, these results mainly focus on simplified
settings of ICL and provide only a preliminary evaluation of the similarities
between the two methods. In this work, we revisit the comparison between ICL
and GD-based finetuning and study what properties of ICL an equivalent process
must follow. We highlight a major difference in the flow of information between
ICL and standard finetuning. Namely, ICL can only rely on information from
lower layers at every point, while finetuning depends on loss gradients from
deeper layers. We refer to this discrepancy as Layer Causality and show that a
layer causal variant of the finetuning process aligns with ICL on par with
vanilla finetuning and is even better in most cases across relevant metrics. To
the best of our knowledge, this is the first work to discuss this discrepancy
explicitly and suggest a solution that tackles this problem with minimal
changes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Natan_T/0/1/0/all/0/1&quot;&gt;Tomer Bar Natan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deutch_G/0/1/0/all/0/1&quot;&gt;Gilad Deutch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magar_N/0/1/0/all/0/1&quot;&gt;Nadav Magar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dar_G/0/1/0/all/0/1&quot;&gt;Guy Dar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08360">
<title>The Transient Nature of Emergent In-Context Learning in Transformers. (arXiv:2311.08360v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.08360</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer neural networks can exhibit a surprising capacity for in-context
learning (ICL) despite not being explicitly trained for it. Prior work has
provided a deeper understanding of how ICL emerges in transformers, e.g.
through the lens of mechanistic interpretability, Bayesian inference, or by
examining the distributional properties of training data. However, in each of
these cases, ICL is treated largely as a persistent phenomenon; namely, once
ICL emerges, it is assumed to persist asymptotically. Here, we show that the
emergence of ICL during transformer training is, in fact, often transient. We
train transformers on synthetic data designed so that both ICL and in-weights
learning (IWL) strategies can lead to correct predictions. We find that ICL
first emerges, then disappears and gives way to IWL, all while the training
loss decreases, indicating an asymptotic preference for IWL. The transient
nature of ICL is observed in transformers across a range of model sizes and
datasets, raising the question of how much to &quot;overtrain&quot; transformers when
seeking compact, cheaper-to-run models. We find that L2 regularization may
offer a path to more persistent ICL that removes the need for early stopping
based on ICL-style validation tasks. Finally, we present initial evidence that
ICL transience may be caused by competition between ICL and IWL circuits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Aaditya K. Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_S/0/1/0/all/0/1&quot;&gt;Stephanie C.Y. Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moskovitz_T/0/1/0/all/0/1&quot;&gt;Ted Moskovitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grant_E/0/1/0/all/0/1&quot;&gt;Erin Grant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxe_A/0/1/0/all/0/1&quot;&gt;Andrew M. Saxe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1&quot;&gt;Felix Hill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.08379">
<title>Scheming AIs: Will AIs fake alignment during training in order to get power?. (arXiv:2311.08379v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/2311.08379</link>
<description rdf:parseType="Literal">&lt;p&gt;This report examines whether advanced AIs that perform well in training will
be doing so in order to gain power later -- a behavior I call &quot;scheming&quot; (also
sometimes called &quot;deceptive alignment&quot;). I conclude that scheming is a
disturbingly plausible outcome of using baseline machine learning methods to
train goal-directed AIs sophisticated enough to scheme (my subjective
probability on such an outcome, given these conditions, is roughly 25%). In
particular: if performing well in training is a good strategy for gaining power
(as I think it might well be), then a very wide variety of goals would motivate
scheming -- and hence, good training performance. This makes it plausible that
training might either land on such a goal naturally and then reinforce it, or
actively push a model&apos;s motivations towards such a goal as an easy way of
improving performance. What&apos;s more, because schemers pretend to be aligned on
tests designed to reveal their motivations, it may be quite difficult to tell
whether this has occurred. However, I also think there are reasons for comfort.
In particular: scheming may not actually be such a good strategy for gaining
power; various selection pressures in training might work against schemer-like
goals (for example, relative to non-schemers, schemers need to engage in extra
instrumental reasoning, which might harm their training performance); and we
may be able to increase such pressures intentionally. The report discusses
these and a wide variety of other considerations in detail, and it suggests an
array of empirical research directions for probing the topic further.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlsmith_J/0/1/0/all/0/1&quot;&gt;Joe Carlsmith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.15447">
<title>On Wasted Contributions: Understanding the Dynamics of Contributor-Abandoned Pull Requests. (arXiv:2110.15447v2 [cs.SE] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2110.15447</link>
<description rdf:parseType="Literal">&lt;p&gt;Pull-based development has enabled numerous volunteers to contribute to
open-source projects with fewer barriers. Nevertheless, a considerable amount
of pull requests (PRs) with valid contributions are abandoned by their
contributors, wasting the effort and time put in by both the contributors and
maintainers. To better understand the underlying dynamics of
contributor-abandoned PRs, we conduct a mixed-methods study using both
quantitative and qualitative methods. We curate a dataset consisting of 265,325
PRs including 4,450 abandoned ones from ten popular and mature GitHub projects
and measure 16 features characterizing PRs, contributors, review processes, and
projects. Using statistical and machine learning techniques, we find that
complex PRs, novice contributors, and lengthy reviews have a higher probability
of abandonment and the rate of PR abandonment fluctuates alongside the
projects&apos; maturity or workload. To identify why contributors abandon their PRs,
we also manually examine a random sample of 354 abandoned PRs. We observe that
the most frequent abandonment reasons are related to the obstacles faced by
contributors, followed by the hurdles imposed by maintainers during the review
process. Finally, we survey the top core maintainers of the studied projects to
understand their perspectives on dealing with PR abandonment and on our
findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khatoonabadi_S/0/1/0/all/0/1&quot;&gt;SayedHassan Khatoonabadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_D/0/1/0/all/0/1&quot;&gt;Diego Elias Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdalkareem_R/0/1/0/all/0/1&quot;&gt;Rabe Abdalkareem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shihab_E/0/1/0/all/0/1&quot;&gt;Emad Shihab&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.01514">
<title>Tunable Quantum Neural Networks in the QPAC-Learning Framework. (arXiv:2205.01514v4 [quant-ph] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2205.01514</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we investigate the performances of tunable quantum neural
networks in the Quantum Probably Approximately Correct (QPAC) learning
framework. Tunable neural networks are quantum circuits made of
multi-controlled X gates. By tuning the set of controls these circuits are able
to approximate any Boolean functions. This architecture is particularly suited
to be used in the QPAC-learning framework as it can handle the superposition
produced by the oracle. In order to tune the network so that it can approximate
a target concept, we have devised and implemented an algorithm based on
amplitude amplification. The numerical results show that this approach can
efficiently learn concepts from a simple class.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ngoc_V/0/1/0/all/0/1&quot;&gt;Viet Pham Ngoc&lt;/a&gt; (Imperial College London), &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tuckey_D/0/1/0/all/0/1&quot;&gt;David Tuckey&lt;/a&gt; (Imperial College London), &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wiklicky_H/0/1/0/all/0/1&quot;&gt;Herbert Wiklicky&lt;/a&gt; (Imperial College London)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.07786">
<title>Predicting the First Response Latency of Maintainers and Contributors in Pull Requests. (arXiv:2311.07786v1 [cs.SE] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2311.07786</link>
<description rdf:parseType="Literal">&lt;p&gt;The success of a Pull Request (PR) depends on the responsiveness of the
maintainers and the contributor during the review process. Being aware of the
expected waiting times can lead to better interactions and managed expectations
for both the maintainers and the contributor. In this paper, we propose a
machine-learning approach to predict the first response latency of the
maintainers following the submission of a PR, and the first response latency of
the contributor after receiving the first response from the maintainers. We
curate a dataset of 20 large and popular open-source projects on GitHub and
extract 21 features to characterize projects, contributors, PRs, and review
processes. Using these features, we then evaluate seven types of classifiers to
identify the best-performing models. We also perform permutation feature
importance and SHAP analyses to understand the importance and impact of
different features on the predicted response latencies. Our best-performing
models achieve an average improvement of 33% in AUC-ROC and 58% in AUC-PR for
maintainers, as well as 42% in AUC-ROC and 95% in AUC-PR for contributors
compared to a no-skilled classifier across the projects. Our findings indicate
that PRs submitted earlier in the week, containing an average or slightly
above-average number of commits, and with concise descriptions are more likely
to receive faster first responses from the maintainers. Similarly, PRs with a
lower first response latency from maintainers, that received the first response
of maintainers earlier in the week, and containing an average or slightly
above-average number of commits tend to receive faster first responses from the
contributors. Additionally, contributors with a higher acceptance rate and a
history of timely responses in the project are likely to both obtain and
provide faster first responses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khatoonabadi_S/0/1/0/all/0/1&quot;&gt;SayedHassan Khatoonabadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdellatif_A/0/1/0/all/0/1&quot;&gt;Ahmad Abdellatif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_D/0/1/0/all/0/1&quot;&gt;Diego Elias Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shihab_E/0/1/0/all/0/1&quot;&gt;Emad Shihab&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>