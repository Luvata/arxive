<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.AI updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Artificial Intelligence (cs.AI) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-08-06T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Artificial Intelligence</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01919" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01921" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01923" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01929" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01930" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01936" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01937" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01941" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01947" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01971" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.01976" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02000" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02024" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02030" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02032" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02033" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02034" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02038" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02041" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02042" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02043" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02044" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02047" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02053" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02058" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02060" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02065" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02066" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02084" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02092" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02116" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02117" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02121" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02126" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02151" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02182" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02193" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02199" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02205" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02219" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02231" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02239" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02282" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02287" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02293" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02294" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02312" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02317" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02335" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02357" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02362" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02369" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02370" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02382" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02408" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02409" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02412" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02415" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02419" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02427" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02432" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02435" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02439" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02441" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02443" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02448" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02454" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02457" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02459" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02490" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.07871" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.12850" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.08549" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.00679" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.09196" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.01491" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.11070" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.11239" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.00516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.06813" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.11098" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.12336" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.12745" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.13035" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.10224" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06710" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19148" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19860" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.00393" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.06548" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00925" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.13892" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.16104" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2308.01916">
<title>Semi Supervised Meta Learning for Spatiotemporal Learning. (arXiv:2308.01916v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.01916</link>
<description rdf:parseType="Literal">&lt;p&gt;We approached the goal of applying meta-learning to self-supervised masked
autoencoders for spatiotemporal learning in three steps. Broadly, we seek to
understand the impact of applying meta-learning to existing state-of-the-art
representation learning architectures. Thus, we test spatiotemporal learning
through: a meta-learning architecture only, a representation learning
architecture only, and an architecture applying representation learning
alongside a meta learning architecture. We utilize the Memory Augmented Neural
Network (MANN) architecture to apply meta-learning to our framework.
Specifically, we first experiment with applying a pre-trained MAE and
fine-tuning on our small-scale spatiotemporal dataset for video reconstruction
tasks. Next, we experiment with training an MAE encoder and applying a
classification head for action classification tasks. Finally, we experiment
with applying a pre-trained MAE and fine-tune with MANN backbone for action
classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waseem_F/0/1/0/all/0/1&quot;&gt;Faraz Waseem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muthukumar_P/0/1/0/all/0/1&quot;&gt;Pratyush Muthukumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01919">
<title>Emotion recognition based on multi-modal electrophysiology multi-head attention Contrastive Learning. (arXiv:2308.01919v1 [cs.MM])</title>
<link>http://arxiv.org/abs/2308.01919</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotion recognition is an important research direction in artificial
intelligence, helping machines understand and adapt to human emotional states.
Multimodal electrophysiological(ME) signals, such as EEG, GSR,
respiration(Resp), and temperature(Temp), are effective biomarkers for
reflecting changes in human emotions. However, using electrophysiological
signals for emotion recognition faces challenges such as data scarcity,
inconsistent labeling, and difficulty in cross-individual generalization. To
address these issues, we propose ME-MHACL, a self-supervised contrastive
learning-based multimodal emotion recognition method that can learn meaningful
feature representations from unlabeled electrophysiological signals and use
multi-head attention mechanisms for feature fusion to improve recognition
performance. Our method includes two stages: first, we use the Meiosis method
to group sample and augment unlabeled electrophysiological signals and design a
self-supervised contrastive learning task; second, we apply the trained feature
extractor to labeled electrophysiological signals and use multi-head attention
mechanisms for feature fusion. We conducted experiments on two public datasets,
DEAP and MAHNOB-HCI, and our method outperformed existing benchmark methods in
emotion recognition tasks and had good cross-individual generalization ability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yunfei Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wu Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01921">
<title>Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats. (arXiv:2308.01921v1 [q-bio.BM])</title>
<link>http://arxiv.org/abs/2308.01921</link>
<description rdf:parseType="Literal">&lt;p&gt;Fast screening of drug molecules based on the ligand binding affinity is an
important step in the drug discovery pipeline. Graph neural fingerprint is a
promising method for developing molecular docking surrogates with high
throughput and great fidelity. In this study, we built a COVID-19 drug docking
dataset of about 300,000 drug candidates on 23 coronavirus protein targets.
With this dataset, we trained graph neural fingerprint docking models for
high-throughput virtual COVID-19 drug screening. The graph neural fingerprint
models yield high prediction accuracy on docking scores with the mean squared
error lower than $0.21$ kcal/mol for most of the docking targets, showing
significant improvement over conventional circular fingerprint methods. To make
the neural fingerprints transferable for unknown targets, we also propose a
transferable graph neural fingerprint method trained on multiple targets. With
comparable accuracy to target-specific graph neural fingerprint models, the
transferable model exhibits superb training and data efficiency. We highlight
that the impact of this study extends beyond COVID-19 dataset, as our approach
for fast virtual ligand screening can be easily adapted and integrated into a
general machine learning-accelerated pipeline to battle future bio-threats.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ren_Y/0/1/0/all/0/1&quot;&gt;Yihui Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kagawa_A/0/1/0/all/0/1&quot;&gt;Ai Kagawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Carbone_M/0/1/0/all/0/1&quot;&gt;Matthew R. Carbone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Samuel Yen-Chi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Qu_X/0/1/0/all/0/1&quot;&gt;Xiaohui Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yoo_S/0/1/0/all/0/1&quot;&gt;Shinjae Yoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Clyde_A/0/1/0/all/0/1&quot;&gt;Austin Clyde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ramanathan_A/0/1/0/all/0/1&quot;&gt;Arvind Ramanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Stevens_R/0/1/0/all/0/1&quot;&gt;Rick L. Stevens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Dam_H/0/1/0/all/0/1&quot;&gt;Hubertus J. J. van Dam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Deyu Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01923">
<title>An Empirical Study on Fairness Improvement with Multiple Protected Attributes. (arXiv:2308.01923v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.01923</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing research mostly improves the fairness of Machine Learning (ML)
software regarding a single protected attribute at a time, but this is
unrealistic given that many users have multiple protected attributes. This
paper conducts an extensive study of fairness improvement regarding multiple
protected attributes, covering 11 state-of-the-art fairness improvement
methods. We analyze the effectiveness of these methods with different datasets,
metrics, and ML models when considering multiple protected attributes. The
results reveal that improving fairness for a single protected attribute can
largely decrease fairness regarding unconsidered protected attributes. This
decrease is observed in up to 88.3% of scenarios (57.5% on average). More
surprisingly, we find little difference in accuracy loss when considering
single and multiple protected attributes, indicating that accuracy can be
maintained in the multiple-attribute paradigm. However, the effect on precision
and recall when handling multiple protected attributes is about 5 times and 8
times that of a single attribute. This has important implications for future
fairness research: reporting only accuracy as the ML performance metric, which
is currently common in the literature, is inadequate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhenpeng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jie M. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarro_F/0/1/0/all/0/1&quot;&gt;Federica Sarro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harman_M/0/1/0/all/0/1&quot;&gt;Mark Harman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01929">
<title>A Transformer-based Prediction Method for Depth of Anesthesia During Target-controlled Infusion of Propofol and Remifentanil. (arXiv:2308.01929v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.01929</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurately predicting anesthetic effects is essential for target-controlled
infusion systems. The traditional (PK-PD) models for Bispectral index (BIS)
prediction require manual selection of model parameters, which can be
challenging in clinical settings. Recently proposed deep learning methods can
only capture general trends and may not predict abrupt changes in BIS. To
address these issues, we propose a transformer-based method for predicting the
depth of anesthesia (DOA) using drug infusions of propofol and remifentanil.
Our method employs long short-term memory (LSTM) and gate residual network
(GRN) networks to improve the efficiency of feature fusion and applies an
attention mechanism to discover the interactions between the drugs. We also use
label distribution smoothing and reweighting losses to address data imbalance.
Experimental results show that our proposed method outperforms traditional
PK-PD models and previous deep learning methods, effectively predicting
anesthetic depth under sudden and deep anesthesia conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yongkang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1&quot;&gt;Siyuan Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Mingjin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhijing Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuanhui Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01930">
<title>Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features. (arXiv:2308.01930v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.01930</link>
<description rdf:parseType="Literal">&lt;p&gt;Diabetes is a prevalent chronic condition that compromises the health of
millions of people worldwide. Minimally invasive methods are needed to prevent
and control diabetes but most devices for measuring glucose levels are invasive
and not amenable for continuous monitoring. Here, we present an alternative
method to overcome these shortcomings based on non-invasive optical
photoplethysmography (PPG) for detecting diabetes. We classify non-Diabetic and
Diabetic patients using the PPG signal and metadata for training Logistic
Regression (LR) and eXtreme Gradient Boosting (XGBoost) algorithms. We used PPG
signals from a publicly available dataset. To prevent overfitting, we divided
the data into five folds for cross-validation. By ensuring that patients in the
training set are not in the testing set, the model&apos;s performance can be
evaluated on unseen subjects&apos; data, providing a more accurate assessment of its
generalization. Our model achieved an F1-Score and AUC of $58.8\pm20.0\%$ and
$79.2\pm15.0\%$ for LR and $51.7\pm16.5\%$ and $73.6\pm17.0\%$ for XGBoost,
respectively. Feature analysis suggested that PPG morphological features
contains diabetes-related information alongside metadata. Our findings are
within the same range reported in the literature, indicating that machine
learning methods are promising for developing remote, non-invasive, and
continuous measurement devices for detecting and preventing diabetes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveira_F/0/1/0/all/0/1&quot;&gt;Filipe A. C. Oliveira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dias_F/0/1/0/all/0/1&quot;&gt;Felipe M. Dias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toledo_M/0/1/0/all/0/1&quot;&gt;Marcelo A. F. Toledo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardenas_D/0/1/0/all/0/1&quot;&gt;Diego A. C. Cardenas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Almeida_D/0/1/0/all/0/1&quot;&gt;Douglas A. Almeida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_E/0/1/0/all/0/1&quot;&gt;Estela Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krieger_J/0/1/0/all/0/1&quot;&gt;Jose E. Krieger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutierrez_M/0/1/0/all/0/1&quot;&gt;Marco A. Gutierrez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01936">
<title>Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?. (arXiv:2308.01936v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2308.01936</link>
<description rdf:parseType="Literal">&lt;p&gt;A hallmark of intelligence is the ability to use a familiar domain to make
inferences about a less familiar domain, known as analogical reasoning. In this
article, we delve into the performance of Large Language Models (LLMs) in
dealing with progressively complex analogies expressed in unstructured text. We
discuss analogies at four distinct levels of complexity: lexical analogies,
syntactic analogies, semantic analogies, and pragmatic analogies. As the
analogies become more complex, they require increasingly extensive, diverse
knowledge beyond the textual content, unlikely to be found in the lexical
co-occurrence statistics that power LLMs. To address this, we discuss the
necessity of employing Neuro-symbolic AI techniques that combine statistical
and symbolic AI, informing the representation of unstructured text to highlight
and augment relevant content, provide abstraction and guide the mapping
process. Our knowledge-informed approach maintains the efficiency of LLMs while
preserving the ability to explain analogies for pedagogical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijesiriwardene_T/0/1/0/all/0/1&quot;&gt;Thilini Wijesiriwardene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1&quot;&gt;Amit Sheth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shalin_V/0/1/0/all/0/1&quot;&gt;Valerie L. Shalin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Amitava Das&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01937">
<title>Training Data Protection with Compositional Diffusion Models. (arXiv:2308.01937v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.01937</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Compartmentalized Diffusion Models (CDM), a method to train
different diffusion models (or prompts) on distinct data sources and
arbitrarily compose them at inference time. The individual models can be
trained in isolation, at different times, and on different distributions and
domains and can be later composed to achieve performance comparable to a
paragon model trained on all data simultaneously. Furthermore, each model only
contains information about the subset of the data it was exposed to during
training, enabling several forms of training data protection. In particular,
CDMs are the first method to enable both selective forgetting and continual
learning for large-scale diffusion models, as well as allowing serving
customized models based on the user&apos;s access rights. CDMs also allow
determining the importance of a subset of the data in generating particular
samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golatkar_A/0/1/0/all/0/1&quot;&gt;Aditya Golatkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1&quot;&gt;Alessandro Achille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swaminathan_A/0/1/0/all/0/1&quot;&gt;Ashwin Swaminathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1&quot;&gt;Stefano Soatto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01941">
<title>Digital twin brain: a bridge between biological intelligence and artificial intelligence. (arXiv:2308.01941v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/2308.01941</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, advances in neuroscience and artificial intelligence have
paved the way for unprecedented opportunities for understanding the complexity
of the brain and its emulation by computational systems. Cutting-edge
advancements in neuroscience research have revealed the intricate relationship
between brain structure and function, while the success of artificial neural
networks highlights the importance of network architecture. Now is the time to
bring them together to better unravel how intelligence emerges from the brain&apos;s
multiscale repositories. In this review, we propose the Digital Twin Brain
(DTB) as a transformative platform that bridges the gap between biological and
artificial intelligence. It consists of three core elements: the brain
structure that is fundamental to the twinning process, bottom-layer models to
generate brain functions, and its wide spectrum of applications. Crucially,
brain atlases provide a vital constraint, preserving the brain&apos;s network
organization within the DTB. Furthermore, we highlight open questions that
invite joint efforts from interdisciplinary fields and emphasize the
far-reaching implications of the DTB. The DTB can offer unprecedented insights
into the emergence of intelligence and neurological disorders, which holds
tremendous promise for advancing our understanding of both biological and
artificial intelligence, and ultimately propelling the development of
artificial general intelligence and facilitating precision mental healthcare.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Hui Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chu_C/0/1/0/all/0/1&quot;&gt;Congying Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Lingzhong Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Song_M/0/1/0/all/0/1&quot;&gt;Ming Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiaqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yawei Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zheng_R/0/1/0/all/0/1&quot;&gt;Ruonan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Junyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhengyi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Jiang_T/0/1/0/all/0/1&quot;&gt;Tianzi Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01947">
<title>Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model. (arXiv:2308.01947v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.01947</link>
<description rdf:parseType="Literal">&lt;p&gt;Different from the current node-level anomaly detection task, the goal of
graph-level anomaly detection is to find abnormal graphs that significantly
differ from others in a graph set. Due to the scarcity of research on the work
of graph-level anomaly detection, the detailed description of graph-level
anomaly is insufficient. Furthermore, existing works focus on capturing
anomalous graph information to learn better graph representations, but they
ignore the importance of an effective anomaly score function for evaluating
abnormal graphs. Thus, in this work, we first define anomalous graph
information including node and graph property anomalies in a graph set and
adopt node-level and graph-level information differences to identify them,
respectively. Then, we introduce a discriminative graph-level anomaly detection
framework with dual-students-teacher model, where the teacher model with a
heuristic loss are trained to make graph representations more divergent. Then,
two competing student models trained by normal and abnormal graphs respectively
fit graph representations of the teacher model in terms of node-level and
graph-level representation perspectives. Finally, we combine representation
errors between two student models to discriminatively distinguish anomalous
graphs. Extensive experiment analysis demonstrates that our method is effective
for the graph-level anomaly detection task on graph datasets in the real world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1&quot;&gt;Fu Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xuexiong Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jia Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jian Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1&quot;&gt;Shan Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zitong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1&quot;&gt;Haonan Gong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01971">
<title>SpaDen : Sparse and Dense Keypoint Estimation for Real-World Chart Understanding. (arXiv:2308.01971v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.01971</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel bottom-up approach for the extraction of chart data. Our
model utilizes images of charts as inputs and learns to detect keypoints (KP),
which are used to reconstruct the components within the plot area. Our novelty
lies in detecting a fusion of continuous and discrete KP as predicted heatmaps.
A combination of sparse and dense per-pixel objectives coupled with a uni-modal
self-attention-based feature-fusion layer is applied to learn KP embeddings.
Further leveraging deep metric learning for unsupervised clustering, allows us
to segment the chart plot area into various objects. By further matching the
chart components to the legend, we are able to obtain the data series names. A
post-processing threshold is applied to the KP embeddings to refine the object
reconstructions and improve accuracy. Our extensive experiments include an
evaluation of different modules for KP estimation and the combination of deep
layer aggregation and corner pooling approaches. The results of our experiments
provide extensive evaluation for the task of real-world chart data extraction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1&quot;&gt;Saleem Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1&quot;&gt;Pengyu Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doermann_D/0/1/0/all/0/1&quot;&gt;David Doermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Setlur_S/0/1/0/all/0/1&quot;&gt;Srirangaraj Setlur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Govindaraju_V/0/1/0/all/0/1&quot;&gt;Venu Govindaraju&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.01976">
<title>Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces. (arXiv:2308.01976v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.01976</link>
<description rdf:parseType="Literal">&lt;p&gt;Typographical errors are a major source of frustration for visitors of online
marketplaces. Because of the domain-specific nature of these marketplaces and
the very short queries users tend to search for, traditional spell cheking
solutions do not perform well in correcting typos. We present a data
augmentation method to address the lack of annotated typo data and train a
recurrent neural network to learn context-limited domain-specific embeddings.
Those embeddings are deployed in a real-time inferencing API for the Microsoft
AppSource marketplace to find the closest match between a misspelled user query
and the available product names. Our data efficient solution shows that
controlled high quality synthetic data may be a powerful tool especially
considering the current climate of large language models which rely on
prohibitively huge and often uncontrolled datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ubrangala_D/0/1/0/all/0/1&quot;&gt;Dayananda Ubrangala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_J/0/1/0/all/0/1&quot;&gt;Juhi Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kondapalli_R/0/1/0/all/0/1&quot;&gt;Ravi Prasad Kondapalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+R_K/0/1/0/all/0/1&quot;&gt;Kiran R&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwala_A/0/1/0/all/0/1&quot;&gt;Amit Agarwala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boue_L/0/1/0/all/0/1&quot;&gt;Laurent Bou&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02000">
<title>On the Transition from Neural Representation to Symbolic Knowledge. (arXiv:2308.02000v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2308.02000</link>
<description rdf:parseType="Literal">&lt;p&gt;Bridging the huge disparity between neural and symbolic representation can
potentially enable the incorporation of symbolic thinking into neural networks
from essence. Motivated by how human gradually builds complex symbolic
representation from the prototype symbols that are learned through perception
and environmental interactions. We propose a Neural-Symbolic Transitional
Dictionary Learning (TDL) framework that employs an EM algorithm to learn a
transitional representation of data that compresses high-dimension information
of visual parts of an input into a set of tensors as neural variables and
discover the implicit predicate structure in a self-supervised way. We
implement the framework with a diffusion model by regarding the decomposition
of input as a cooperative game, then learn predicates by prototype clustering.
We additionally use RL enabled by the Markovian of diffusion models to further
tune the learned prototypes by incorporating subjective factors. Extensive
experiments on 3 abstract compositional visual objects datasets that require
the model to segment parts without any visual features like texture, color, or
shadows apart from shape and 3 neural/symbolic downstream tasks demonstrate the
learned representation enables interpretable decomposition of visual input and
smooth adaption to downstream tasks which are not available by existing
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;Junyan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chin_P/0/1/0/all/0/1&quot;&gt;Peter Chin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02024">
<title>Evaluation of STT-MRAM as a Scratchpad for Training in ML Accelerators. (arXiv:2308.02024v1 [cs.AR])</title>
<link>http://arxiv.org/abs/2308.02024</link>
<description rdf:parseType="Literal">&lt;p&gt;Progress in artificial intelligence and machine learning over the past decade
has been driven by the ability to train larger deep neural networks (DNNs),
leading to a compute demand that far exceeds the growth in hardware performance
afforded by Moore&apos;s law. Training DNNs is an extremely memory-intensive
process, requiring not just the model weights but also activations and
gradients for an entire minibatch to be stored. The need to provide
high-density and low-leakage on-chip memory motivates the exploration of
emerging non-volatile memory for training accelerators. Spin-Transfer-Torque
MRAM (STT-MRAM) offers several desirable properties for training accelerators,
including 3-4x higher density than SRAM, significantly reduced leakage power,
high endurance and reasonable access time. On the one hand, MRAM write
operations require high write energy and latency due to the need to ensure
reliable switching.
&lt;/p&gt;
&lt;p&gt;In this study, we perform a comprehensive device-to-system evaluation and
co-optimization of STT-MRAM for efficient ML training accelerator design. We
devised a cross-layer simulation framework to evaluate the effectiveness of
STT-MRAM as a scratchpad replacing SRAM in a systolic-array-based DNN
accelerator. To address the inefficiency of writes in STT-MRAM, we propose to
reduce write voltage and duration. To evaluate the ensuing accuracy-efficiency
trade-off, we conduct a thorough analysis of the error tolerance of input
activations, weights, and errors during the training. We propose heterogeneous
memory configurations that enable training convergence with good accuracy. We
show that MRAM provide up to 15-22x improvement in system level energy across a
suite of DNN benchmarks under iso-capacity and iso-area scenarios. Further
optimizing STT-MRAM write operations can provide over 2x improvement in write
energy for minimal degradation in application-level training accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sourjya Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Cheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1&quot;&gt;Anand Raghunathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02030">
<title>Perceptions of the Fourth Industrial Revolution and Artificial Intelligence Impact on Society. (arXiv:2308.02030v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02030</link>
<description rdf:parseType="Literal">&lt;p&gt;The Fourth Industrial Revolution, particularly Artificial Intelligence (AI),
has had a profound impact on society, raising concerns about its implications
and ethical considerations. The emergence of text generative AI tools like
ChatGPT has further intensified concerns regarding ethics, security, privacy,
and copyright. This study aims to examine the perceptions of individuals in
different information flow categorizations toward AI. The results reveal key
themes in participant-supplied definitions of AI and the fourth industrial
revolution, emphasizing the replication of human intelligence, machine
learning, automation, and the integration of digital technologies. Participants
expressed concerns about job replacement, privacy invasion, and inaccurate
information provided by AI. However, they also recognized the benefits of AI,
such as solving complex problems and increasing convenience. Views on
government involvement in shaping the fourth industrial revolution varied, with
some advocating for strict regulations and others favoring support and
development. The anticipated changes brought by the fourth industrial
revolution include automation, potential job impacts, increased social
disconnect, and reliance on technology. Understanding these perceptions is
crucial for effectively managing the challenges and opportunities associated
with AI in the evolving digital landscape.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agbaji_D/0/1/0/all/0/1&quot;&gt;Daniel Agbaji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lund_B/0/1/0/all/0/1&quot;&gt;Brady Lund&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannuru_N/0/1/0/all/0/1&quot;&gt;Nishith Reddy Mannuru&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02031">
<title>Knowledge-enhanced Neuro-Symbolic AI for Cybersecurity and Privacy. (arXiv:2308.02031v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02031</link>
<description rdf:parseType="Literal">&lt;p&gt;Neuro-Symbolic Artificial Intelligence (AI) is an emerging and quickly
advancing field that combines the subsymbolic strengths of (deep) neural
networks and explicit, symbolic knowledge contained in knowledge graphs to
enhance explainability and safety in AI systems. This approach addresses a key
criticism of current generation systems, namely their inability to generate
human-understandable explanations for their outcomes and ensure safe behaviors,
especially in scenarios with \textit{unknown unknowns} (e.g. cybersecurity,
privacy). The integration of neural networks, which excel at exploring complex
data spaces, and symbolic knowledge graphs, which represent domain knowledge,
allows AI systems to reason, learn, and generalize in a manner understandable
to experts. This article describes how applications in cybersecurity and
privacy, two most demanding domains in terms of the need for AI to be
explainable while being highly accurate in complex environments, can benefit
from Neuro-Symbolic AI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piplai_A/0/1/0/all/0/1&quot;&gt;Aritran Piplai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kotal_A/0/1/0/all/0/1&quot;&gt;Anantaa Kotal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohseni_S/0/1/0/all/0/1&quot;&gt;Seyedreza Mohseni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaur_M/0/1/0/all/0/1&quot;&gt;Manas Gaur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1&quot;&gt;Sudip Mittal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1&quot;&gt;Anupam Joshi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02032">
<title>JusticeBot: A Methodology for Building Augmented Intelligence Tools for Laypeople to Increase Access to Justice. (arXiv:2308.02032v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02032</link>
<description rdf:parseType="Literal">&lt;p&gt;Laypeople (i.e. individuals without legal training) may often have trouble
resolving their legal problems. In this work, we present the JusticeBot
methodology. This methodology can be used to build legal decision support
tools, that support laypeople in exploring their legal rights in certain
situations, using a hybrid case-based and rule-based reasoning approach. The
system ask the user questions regarding their situation and provides them with
legal information, references to previous similar cases and possible next
steps. This information could potentially help the user resolve their issue,
e.g. by settling their case or enforcing their rights in court. We present the
methodology for building such tools, which consists of discovering typically
applied legal rules from legislation and case law, and encoding previous cases
to support the user. We also present an interface to build tools using this
methodology and a case study of the first deployed JusticeBot version, focused
on landlord-tenant disputes, which has been used by thousands of individuals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Westermann_H/0/1/0/all/0/1&quot;&gt;Hannes Westermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benyekhlef_K/0/1/0/all/0/1&quot;&gt;Karim Benyekhlef&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02033">
<title>AI and the EU Digital Markets Act: Addressing the Risks of Bigness in Generative AI. (arXiv:2308.02033v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02033</link>
<description rdf:parseType="Literal">&lt;p&gt;As AI technology advances rapidly, concerns over the risks of bigness in
digital markets are also growing. The EU&apos;s Digital Markets Act (DMA) aims to
address these risks. Still, the current framework may not adequately cover
generative AI systems that could become gateways for AI-based services. This
paper argues for integrating certain AI software as core platform services and
classifying certain developers as gatekeepers under the DMA. We also propose an
assessment of gatekeeper obligations to ensure they cover generative AI
services. As the EU considers generative AI-specific rules and possible DMA
amendments, this paper provides insights towards diversity and openness in
generative AI services.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yasar_A/0/1/0/all/0/1&quot;&gt;Ayse Gizem Yasar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chong_A/0/1/0/all/0/1&quot;&gt;Andrew Chong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_E/0/1/0/all/0/1&quot;&gt;Evan Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilbert_T/0/1/0/all/0/1&quot;&gt;Thomas Krendl Gilbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hladikova_S/0/1/0/all/0/1&quot;&gt;Sarah Hladikova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maio_R/0/1/0/all/0/1&quot;&gt;Roland Maio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mougan_C/0/1/0/all/0/1&quot;&gt;Carlos Mougan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1&quot;&gt;Xudong Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Shubham Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoica_A/0/1/0/all/0/1&quot;&gt;Ana-Andreea Stoica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thais_S/0/1/0/all/0/1&quot;&gt;Savannah Thais&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zilka_M/0/1/0/all/0/1&quot;&gt;Miri Zilka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02034">
<title>The Growth of E-Bike Use: A Machine Learning Approach. (arXiv:2308.02034v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02034</link>
<description rdf:parseType="Literal">&lt;p&gt;We present our work on electric bicycles (e-bikes) and their implications for
policymakers in the United States. E-bikes have gained significant popularity
as a fast and eco-friendly transportation option. As we strive for a
sustainable energy plan, understanding the growth and impact of e-bikes is
crucial for policymakers. Our mathematical modeling offers insights into the
value of e-bikes and their role in the future. Using an ARIMA model, a
supervised machine-learning algorithm, we predicted the growth of e-bike sales
in the U.S. Our model, trained on historical sales data from January 2006 to
December 2022, projected sales of 1.3 million units in 2025 and 2.113 million
units in 2028. To assess the factors contributing to e-bike usage, we employed
a Random Forest regression model. The most significant factors influencing
e-bike sales growth were disposable personal income and popularity.
Furthermore, we examined the environmental and health impacts of e-bikes.
Through Monte Carlo simulations, we estimated the reduction in carbon emissions
due to e-bike use and the calories burned through e-biking. Our findings
revealed that e-bike usage in the U.S. resulted in a reduction of 15,737.82
kilograms of CO2 emissions in 2022. Additionally, e-bike users burned
approximately 716,630.727 kilocalories through their activities in the same
year. Our research provides valuable insights for policymakers, emphasizing the
potential of e-bikes as a sustainable transportation solution. By understanding
the growth factors and quantifying the environmental and health benefits,
policymakers can make informed decisions about integrating e-bikes into future
energy and transportation strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Aditya Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chitgopekar_S/0/1/0/all/0/1&quot;&gt;Samarth Chitgopekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_A/0/1/0/all/0/1&quot;&gt;Alexander Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Joseph Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Megan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grattoni_C/0/1/0/all/0/1&quot;&gt;Christopher Grattoni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02038">
<title>CLGT: A Graph Transformer for Student Performance Prediction in Collaborative Learning. (arXiv:2308.02038v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02038</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling and predicting the performance of students in collaborative learning
paradigms is an important task. Most of the research presented in literature
regarding collaborative learning focuses on the discussion forums and social
learning networks. There are only a few works that investigate how students
interact with each other in team projects and how such interactions affect
their academic performance. In order to bridge this gap, we choose a software
engineering course as the study subject. The students who participate in a
software engineering course are required to team up and complete a software
project together. In this work, we construct an interaction graph based on the
activities of students grouped in various teams. Based on this student
interaction graph, we present an extended graph transformer framework for
collaborative learning (CLGT) for evaluating and predicting the performance of
students. Moreover, the proposed CLGT contains an interpretation module that
explains the prediction results and visualizes the student interaction
patterns. The experimental results confirm that the proposed CLGT outperforms
the baseline models in terms of performing predictions based on the real-world
datasets. Moreover, the proposed CLGT differentiates the students with poor
performance in the collaborative learning paradigm and gives teachers early
warnings, so that appropriate assistance can be provided.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_T/0/1/0/all/0/1&quot;&gt;Tianhao Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1&quot;&gt;Wenjun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1&quot;&gt;Jian Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pengrui_Z/0/1/0/all/0/1&quot;&gt;Zhao Pengrui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yanjun Pu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02041">
<title>Regulating AI manipulation: Applying Insights from behavioral economics and psychology to enhance the practicality of the EU AI Act. (arXiv:2308.02041v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02041</link>
<description rdf:parseType="Literal">&lt;p&gt;The EU AI Act Article 5 is designed to regulate AI manipulation to prevent
potential harmful consequences. However, the practical implementation of this
legislation is challenging due to the ambiguous terminologies and the unclear
presentations of manipulative techniques. Moreover, the Article 5 also suffers
criticize of inadequate protective efficacy. This paper attempts to clarify
terminologies and to enhance the protective efficacy by integrating insights
from psychology and behavioral economics. Firstly, this paper employs cognitive
psychology research to elucidate the term subliminal techniques and its
associated representation. Additionally, this paper extends the study of
heuristics: a set of thinking shortcuts which can be aroused for behavior
changing from behavior economics to the realm of manipulative techniques. The
elucidation and expansion of terminologies not only provide a more accurate
understanding of the legal provision but also enhance its protective efficacy.
Secondly, this paper proposes five classical heuristics and their associated
examples to illustrate how can AI arouse those heuristics to alter users
behavior. The enumeration of heuristics serves as a practical guide for
stakeholders such as AI developers, algorithm auditors, users, and legal
practitioners, enabling them to identify manipulative techniques and implement
countermeasures. Finally, this paper critically evaluates the protective
efficacy of Article 5 for both the general public and vulnerable groups. This
paper argues that the current protective efficacy of Article 5 is insufficient
and thus proposes specific revision suggestions to terms a and b in Article 5
to enhance its protective efficacy. This work contributes to the ongoing
discourse on AI ethics and legal regulations, providing a practical guide for
interpreting and applying the EU AI Act Article 5.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1&quot;&gt;Huixin Zhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02042">
<title>A short review of the main concerns in A.I. development and application within the public sector supported by NLP and TM. (arXiv:2308.02042v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02042</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial Intelligence is not a new subject, and business, industry and
public sectors have used it in different ways and contexts and considering
multiple concerns. This work reviewed research papers published in ACM Digital
Library and IEEE Xplore conference proceedings in the last two years supported
by fundamental concepts of Natural Language Processing (NLP) and Text Mining
(TM). The objective was to capture insights regarding data privacy, ethics,
interpretability, explainability, trustworthiness, and fairness in the public
sector. The methodology has saved analysis time and could retrieve papers
containing relevant information. The results showed that fairness was the most
frequent concern. The least prominent topic was data privacy (although embedded
in most articles), while the most prominent was trustworthiness. Finally,
gathering helpful insights about those concerns regarding A.I. applications in
the public sector was also possible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreira_C/0/1/0/all/0/1&quot;&gt;Carlos Ferreira&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02043">
<title>Disease Insight through Digital Biomarkers Developed by Remotely Collected Wearables and Smartphone Data. (arXiv:2308.02043v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02043</link>
<description rdf:parseType="Literal">&lt;p&gt;Digital Biomarkers and remote patient monitoring can provide valuable and
timely insights into how a patient is coping with their condition (disease
progression, treatment response, etc.), complementing treatment in traditional
healthcare settings.Smartphones with embedded and connected sensors have
immense potential for improving healthcare through various apps and mHealth
(mobile health) platforms. This capability could enable the development of
reliable digital biomarkers from long-term longitudinal data collected remotely
from patients. We built an open-source platform, RADAR-base, to support
large-scale data collection in remote monitoring studies. RADAR-base is a
modern remote data collection platform built around Confluent&apos;s Apache Kafka,
to support scalability, extensibility, security, privacy and quality of data.
It provides support for study design and set-up, active (eg PROMs) and passive
(eg. phone sensors, wearable devices and IoT) remote data collection
capabilities with feature generation (eg. behavioural, environmental and
physiological markers). The backend enables secure data transmission, and
scalable solutions for data storage, management and data access. The platform
has successfully collected longitudinal data for various cohorts in a number of
disease areas including Multiple Sclerosis, Depression, Epilepsy, ADHD,
Alzheimer, Autism and Lung diseases. Digital biomarkers developed through
collected data are providing useful insights into different diseases.
RADAR-base provides a modern open-source, community-driven solution for remote
monitoring, data collection, and digital phenotyping of physical and mental
health diseases. Clinicians can use digital biomarkers to augment their
decision making for the prevention, personalisation and early intervention of
disease.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashid_Z/0/1/0/all/0/1&quot;&gt;Zulqarnain Rashid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Folarin_A/0/1/0/all/0/1&quot;&gt;Amos A Folarin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranjan_Y/0/1/0/all/0/1&quot;&gt;Yatharth Ranjan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conde_P/0/1/0/all/0/1&quot;&gt;Pauline Conde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankesara_H/0/1/0/all/0/1&quot;&gt;Heet Sankesara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuezhou Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Shaoxiong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stewart_C/0/1/0/all/0/1&quot;&gt;Callum Stewart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laiou_P/0/1/0/all/0/1&quot;&gt;Petroula Laiou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1&quot;&gt;Richard JB Dobson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02044">
<title>Artificial Intelligence in archival and historical scholarship workflow: HTS and ChatGPT. (arXiv:2308.02044v1 [cs.DL])</title>
<link>http://arxiv.org/abs/2308.02044</link>
<description rdf:parseType="Literal">&lt;p&gt;This article examines the impact of Artificial Intelligence on the archival
heritage digitization processes, specifically regarding the manuscripts&apos;
automatic transcription, their correction, and normalization. It highlights how
digitality has compelled scholars to redefine Archive and History field and has
facilitated the accessibility of analogue sources through digitization and
integration into big data. The study focuses on two AI systems, namely
Transkribus and ChatGPT, which enable efficient analysis and transcription of
digitized sources. The article presents a test of ChatGPT, which was utilized
to normalize the text of 366 letters stored in the Correspondence section of
the Biscari Archive (Catania). Although the AI exhibited some limitations that
resulted in inaccuracies, the corrected texts met expectations. Overall, the
article concludes that digitization and AI can significantly enhance archival
and historical research by allowing the analysis of vast amounts of data and
the application of computational linguistic tools.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spina_S/0/1/0/all/0/1&quot;&gt;Salvatore Spina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02047">
<title>Acceptable risks in Europe&apos;s proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough. (arXiv:2308.02047v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02047</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper critically evaluates the European Commission&apos;s proposed AI Act&apos;s
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
&quot;trustworthy&quot; AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated &quot;as far as possible&quot;, having regard to the &quot;state of the art&quot;. This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament&apos;s most recent draft amendments to the risk management provisions
introduce &quot;reasonableness&quot;, cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament&apos;s approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fraser_H/0/1/0/all/0/1&quot;&gt;Henry Fraser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villarino_J/0/1/0/all/0/1&quot;&gt;Jose-Miguel Bello y Villarino&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02053">
<title>The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations. (arXiv:2308.02053v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.02053</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have seen widespread deployment in various
real-world applications. Understanding these biases is crucial to comprehend
the potential downstream consequences when using LLMs to make decisions,
particularly for historically disadvantaged groups. In this work, we propose a
simple method for analyzing and comparing demographic bias in LLMs, through the
lens of job recommendations. We demonstrate the effectiveness of our method by
measuring intersectional biases within ChatGPT and LLaMA, two cutting-edge
LLMs. Our experiments primarily focus on uncovering gender identity and
nationality bias; however, our method can be extended to examine biases
associated with any intersection of demographic identities. We identify
distinct biases in both models toward various demographic identities, such as
both models consistently suggesting low-paying jobs for Mexican workers or
preferring to recommend secretarial roles to women. Our study highlights the
importance of measuring the bias of LLMs in downstream applications to
understand the potential for harm and inequitable outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salinas_A/0/1/0/all/0/1&quot;&gt;Abel Salinas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_P/0/1/0/all/0/1&quot;&gt;Parth Vipul Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yuzhong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCormack_R/0/1/0/all/0/1&quot;&gt;Robert McCormack&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morstatter_F/0/1/0/all/0/1&quot;&gt;Fred Morstatter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02058">
<title>Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2308.02058</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommender systems that include some reliability measure of their
predictions tend to be more conservative in forecasting, due to their
constraint to preserve reliability. This leads to a significant drop in the
coverage and novelty that these systems can provide. In this paper, we propose
the inclusion of a new term in the learning process of matrix
factorization-based recommender systems, called recklessness, which enables the
control of the risk level desired when making decisions about the reliability
of a prediction. Experimental results demonstrate that recklessness not only
allows for risk regulation but also improves the quantity and quality of
predictions provided by the recommender system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Lopez_D/0/1/0/all/0/1&quot;&gt;Diego P&amp;#xe9;rez-L&amp;#xf3;pez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortega_F/0/1/0/all/0/1&quot;&gt;Fernando Ortega&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_Prieto_A/0/1/0/all/0/1&quot;&gt;&amp;#xc1;ngel Gonz&amp;#xe1;lez-Prieto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duenas_Lerin_J/0/1/0/all/0/1&quot;&gt;Jorge Due&amp;#xf1;as-Ler&amp;#xed;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02060">
<title>Accurate Neural Network Pruning Requires Rethinking Sparse Optimization. (arXiv:2308.02060v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02060</link>
<description rdf:parseType="Literal">&lt;p&gt;Obtaining versions of deep neural networks that are both highly-accurate and
highly-sparse is one of the main challenges in the area of model compression,
and several high-performance pruning techniques have been investigated by the
community. Yet, much less is known about the interaction between sparsity and
the standard stochastic optimization techniques used for training sparse
networks, and most existing work uses standard dense schedules and
hyperparameters for training sparse networks. In this work, we examine the
impact of high sparsity on model training using the standard computer vision
and natural language processing sparsity benchmarks. We begin by showing that
using standard dense training recipes for sparse training is suboptimal, and
results in under-training. We provide new approaches for mitigating this issue
for both sparse pre-training of vision models (e.g. ResNet50/ImageNet) and
sparse fine-tuning of language models (e.g. BERT/GLUE), achieving
state-of-the-art results in both settings in the high-sparsity regime, and
providing detailed analyses for the difficulty of sparse training in both
scenarios. Our work sets a new threshold in terms of the accuracies that can be
achieved under high sparsity, and should inspire further research into
improving sparse model training, to reach higher accuracies under high
sparsity, but also to do so efficiently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuznedelev_D/0/1/0/all/0/1&quot;&gt;Denis Kuznedelev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurtic_E/0/1/0/all/0/1&quot;&gt;Eldar Kurtic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iofinova_E/0/1/0/all/0/1&quot;&gt;Eugenia Iofinova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frantar_E/0/1/0/all/0/1&quot;&gt;Elias Frantar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peste_A/0/1/0/all/0/1&quot;&gt;Alexandra Peste&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1&quot;&gt;Dan Alistarh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02065">
<title>On the Biometric Capacity of Generative Face Models. (arXiv:2308.02065v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.02065</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been tremendous progress in generating realistic faces with high
fidelity over the past few years. Despite this progress, a crucial question
remains unanswered: &quot;Given a generative face model, how many unique identities
can it generate?&quot; In other words, what is the biometric capacity of the
generative face model? A scientific basis for answering this question will
benefit evaluating and comparing different generative face models and establish
an upper bound on their scalability. This paper proposes a statistical approach
to estimate the biometric capacity of generated face images in a hyperspherical
feature space. We employ our approach on multiple generative models, including
unconditional generators like StyleGAN, Latent Diffusion Model, and &quot;Generated
Photos,&quot; as well as DCFace, a class-conditional generator. We also estimate
capacity w.r.t. demographic attributes such as gender and age. Our capacity
estimates indicate that (a) under ArcFace representation at a false acceptance
rate (FAR) of 0.1%, StyleGAN3 and DCFace have a capacity upper bound of
$1.43\times10^6$ and $1.190\times10^4$, respectively; (b) the capacity reduces
drastically as we lower the desired FAR with an estimate of $1.796\times10^4$
and $562$ at FAR of 1% and 10%, respectively, for StyleGAN3; (c) there is no
discernible disparity in the capacity w.r.t gender; and (d) for some generative
models, there is an appreciable disparity in the capacity w.r.t age. Code is
available at https://github.com/human-analysis/capacity-generative-face-models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boddeti_V/0/1/0/all/0/1&quot;&gt;Vishnu Naresh Boddeti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sreekumar_G/0/1/0/all/0/1&quot;&gt;Gautam Sreekumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ross_A/0/1/0/all/0/1&quot;&gt;Arun Ross&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02066">
<title>Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives. (arXiv:2308.02066v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.02066</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-task learning (MTL) seeks to learn a single model to accomplish
multiple tasks by leveraging shared information among the tasks. Existing MTL
models, however, have been known to suffer from negative interference among
tasks. Efforts to mitigate task interference have focused on either
loss/gradient balancing or implicit parameter partitioning with partial
overlaps among the tasks. In this paper, we propose ETR-NLP to mitigate task
interference through a synergistic combination of non-learnable primitives
(NLPs) and explicit task routing (ETR). Our key idea is to employ non-learnable
primitives to extract a diverse set of task-agnostic features and recombine
them into a shared branch common to all tasks and explicit task-specific
branches reserved for each task. The non-learnable primitives and the explicit
decoupling of learnable parameters into shared and task-specific ones afford
the flexibility needed for minimizing task interference. We evaluate the
efficacy of ETR-NLP networks for both image-level classification and
pixel-level dense prediction MTL problems. Experimental results indicate that
ETR-NLP significantly outperforms state-of-the-art baselines with fewer
learnable parameters and similar FLOPs across all datasets. Code is available
at this \href{https://github.com/zhichao-lu/etr-nlp-mtl}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1&quot;&gt;Chuntao Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhichao Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shangguang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_R/0/1/0/all/0/1&quot;&gt;Ran Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boddeti_V/0/1/0/all/0/1&quot;&gt;Vishnu Naresh Boddeti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02084">
<title>Efficient Model Adaptation for Continual Learning at the Edge. (arXiv:2308.02084v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02084</link>
<description rdf:parseType="Literal">&lt;p&gt;Most machine learning (ML) systems assume stationary and matching data
distributions during training and deployment. This is often a false assumption.
When ML models are deployed on real devices, data distributions often shift
over time due to changes in environmental factors, sensor characteristics, and
task-of-interest. While it is possible to have a human-in-the-loop to monitor
for distribution shifts and engineer new architectures in response to these
shifts, such a setup is not cost-effective. Instead, non-stationary automated
ML (AutoML) models are needed. This paper presents the
Encoder-Adaptor-Reconfigurator (EAR) framework for efficient continual learning
under domain shifts. The EAR framework uses a fixed deep neural network (DNN)
feature encoder and trains shallow networks on top of the encoder to handle
novel data. The EAR framework is capable of 1) detecting when new data is
out-of-distribution (OOD) by combining DNNs with hyperdimensional computing
(HDC), 2) identifying low-parameter neural adaptors to adapt the model to the
OOD data using zero-shot neural architecture search (ZS-NAS), and 3) minimizing
catastrophic forgetting on previous tasks by progressively growing the neural
architecture as needed and dynamically routing data through the appropriate
adaptors and reconfigurators for handling domain-incremental and
class-incremental continual learning. We systematically evaluate our approach
on several benchmark datasets for domain adaptation and demonstrate strong
performance compared to state-of-the-art algorithms for OOD detection and
few-/zero-shot NAS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniels_Z/0/1/0/all/0/1&quot;&gt;Zachary A. Daniels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jun Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lomnitz_M/0/1/0/all/0/1&quot;&gt;Michael Lomnitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_P/0/1/0/all/0/1&quot;&gt;Phil Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghavan_A/0/1/0/all/0/1&quot;&gt;Aswin Raghavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Joe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piacentino_M/0/1/0/all/0/1&quot;&gt;Michael Piacentino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;David Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02092">
<title>N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets. (arXiv:2308.02092v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.02092</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate transcription of proper names and technical terms is particularly
important in speech-to-text applications for business conversations. These
words, which are essential to understanding the conversation, are often rare
and therefore likely to be under-represented in text and audio training data,
creating a significant challenge in this domain. We present a two-step keyword
boosting mechanism that successfully works on normalized unigrams and n-grams
rather than just single tokens, which eliminates missing hits issues with
boosting raw targets. In addition, we show how adjusting the boosting weight
logic avoids over-boosting multi-token keywords. This improves our keyword
recognition rate by 26% relative on our proprietary in-domain dataset and 2% on
LibriSpeech. This method is particularly useful on targets that involve
non-alphabetic characters or have non-standard pronunciations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wang Yau Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nadig_S/0/1/0/all/0/1&quot;&gt;Shreekantha Nadig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1&quot;&gt;Karol Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_Z/0/1/0/all/0/1&quot;&gt;Zafarullah Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Riqiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vandieken_S/0/1/0/all/0/1&quot;&gt;Simon Vandieken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robertson_J/0/1/0/all/0/1&quot;&gt;Jonas Robertson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mailhot_F/0/1/0/all/0/1&quot;&gt;Fred Mailhot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02116">
<title>AdvFAS: A robust face anti-spoofing framework against adversarial examples. (arXiv:2308.02116v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.02116</link>
<description rdf:parseType="Literal">&lt;p&gt;Ensuring the reliability of face recognition systems against presentation
attacks necessitates the deployment of face anti-spoofing techniques. Despite
considerable advancements in this domain, the ability of even the most
state-of-the-art methods to defend against adversarial examples remains
elusive. While several adversarial defense strategies have been proposed, they
typically suffer from constrained practicability due to inevitable trade-offs
between universality, effectiveness, and efficiency. To overcome these
challenges, we thoroughly delve into the coupled relationship between
adversarial detection and face anti-spoofing. Based on this, we propose a
robust face anti-spoofing framework, namely AdvFAS, that leverages two coupled
scores to accurately distinguish between correctly detected and wrongly
detected face images. Extensive experiments demonstrate the effectiveness of
our framework in a variety of settings, including different attacks, datasets,
and backbones, meanwhile enjoying high accuracy on clean examples. Moreover, we
successfully apply the proposed method to detect real-world adversarial
examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiawei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xiao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Heng Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1&quot;&gt;Mingzhi Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Bihui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1&quot;&gt;Jianteng Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yandong Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zhaoxia Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hang Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02117">
<title>VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs. (arXiv:2308.02117v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02117</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) conduct message passing which aggregates local
neighbors to update node representations. Such message passing leads to
scalability issues in practical latency-constrained applications. To address
this issue, recent methods adopt knowledge distillation (KD) to learn
computationally-efficient multi-layer perceptron (MLP) by mimicking the output
of GNN. However, the existing GNN representation space may not be expressive
enough for representing diverse local structures of the underlying graph, which
limits the knowledge transfer from GNN to MLP. Here we present a novel
framework VQGraph to learn a powerful graph representation space for bridging
GNNs and MLPs. We adopt the encoder of a variant of a vector-quantized
variational autoencoder (VQ-VAE) as a structure-aware graph tokenizer, which
explicitly represents the nodes of diverse local structures as numerous
discrete tokens and constitutes a meaningful codebook. Equipped with the
learned codebook, we propose a new token-based distillation objective based on
soft token assignments to sufficiently transfer the structural knowledge from
GNN to MLP. Extensive experiments and analyses demonstrate the strong
performance of VQGraph, where we achieve new state-of-the-art performance on
GNN-MLP distillation in both transductive and inductive settings across seven
graph datasets. We show that VQGraph with better performance infers faster than
GNNs by 828x, and also achieves accuracy improvement over GNNs and stand-alone
MLPs by 3.90% and 28.05% on average, respectively. Code:
https://github.com/YangLing0818/VQGraph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Ling Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Ye Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Minkai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhongyi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1&quot;&gt;Shenda Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_W/0/1/0/all/0/1&quot;&gt;Wei Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wentao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1&quot;&gt;Bin Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Muhan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02121">
<title>Model Provenance via Model DNA. (arXiv:2308.02121v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02121</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the life cycle of the machine learning (ML) model is an
intriguing area of research (e.g., understanding where the model comes from,
how it is trained, and how it is used). This paper focuses on a novel problem
within this field, namely Model Provenance (MP), which concerns the
relationship between a target model and its pre-training model and aims to
determine whether a source model serves as the provenance for a target model.
This is an important problem that has significant implications for ensuring the
security and intellectual property of machine learning models but has not
received much attention in the literature. To fill in this gap, we introduce a
novel concept of Model DNA which represents the unique characteristics of a
machine learning model. We utilize a data-driven and model-driven
representation learning method to encode the model&apos;s training data and
input-output information as a compact and comprehensive representation (i.e.,
DNA) of the model. Using this model DNA, we develop an efficient framework for
model provenance identification, which enables us to identify whether a source
model is a pre-training model of a target model. We conduct evaluations on both
computer vision and natural language processing tasks using various models,
datasets, and scenarios to demonstrate the effectiveness of our approach in
accurately identifying model provenance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mu_X/0/1/0/all/0/1&quot;&gt;Xin Mu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yehong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiaqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1&quot;&gt;Yang Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yue Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02126">
<title>Semantics-guided Transformer-based Sensor Fusion for Improved Waypoint Prediction. (arXiv:2308.02126v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2308.02126</link>
<description rdf:parseType="Literal">&lt;p&gt;Sensor fusion approaches for intelligent self-driving agents remain key to
driving scene understanding given visual global contexts acquired from input
sensors. Specifically, for the local waypoint prediction task, single-modality
networks are still limited by strong dependency on the sensitivity of the input
sensor, and thus recent works promote the use of multiple sensors in fusion in
feature level. While it is well known that multiple data modalities promote
mutual contextual exchange, deployment to practical driving scenarios requires
global 3D scene understanding in real-time with minimal computations, thus
placing greater significance on training strategies given a limited number of
practically usable sensors. In this light, we exploit carefully selected
auxiliary tasks that are highly correlated with the target task of interest
(e.g., traffic light recognition and semantic segmentation) by fusing auxiliary
task features and also using auxiliary heads for waypoint prediction based on
imitation learning. Our multi-task feature fusion augments and improves the
base network, TransFuser, by significant margins for safer and more complete
road navigation in CARLA simulator as validated on the Town05 Benchmark through
extensive experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1&quot;&gt;Hwan-Soo Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1&quot;&gt;Jongoh Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1&quot;&gt;Young Hoo Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1&quot;&gt;Kuk-Jin Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jong-Hwan Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02151">
<title>Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization. (arXiv:2308.02151v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.02151</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent months have seen the emergence of a powerful new trend in which large
language models (LLMs) are augmented to become autonomous language agents
capable of performing objective oriented multi-step tasks on their own, rather
than merely responding to queries from human users. Most existing language
agents, however, are not optimized using environment-specific rewards. Although
some agents enable iterative refinement through verbal feedback, they do not
reason and plan in ways that are compatible with gradient-based learning from
rewards. This paper introduces a principled framework for reinforcing large
language agents by learning a retrospective model, which automatically tunes
the language agent prompts from environment feedback through policy gradient.
Specifically, our proposed agent architecture learns from rewards across
multiple environments and tasks, for fine-tuning a pre-trained language model
which refines the language agent prompt by summarizing the root cause of prior
failed attempts and proposing action plans. Experimental results on various
tasks demonstrate that the language agents improve over time and that our
approach considerably outperforms baselines that do not properly leverage
gradients from the environment. This demonstrates that using policy gradient
optimization to improve language agents, for which we believe our work is one
of the first, seems promising and can be applied to optimize other models in
the agent architecture to enhance agent performances over time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1&quot;&gt;Weiran Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinecke_S/0/1/0/all/0/1&quot;&gt;Shelby Heinecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niebles_J/0/1/0/all/0/1&quot;&gt;Juan Carlos Niebles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yihao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1&quot;&gt;Le Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murthy_R/0/1/0/all/0/1&quot;&gt;Rithesh Murthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianguo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1&quot;&gt;Devansh Arpit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1&quot;&gt;Ran Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mui_P/0/1/0/all/0/1&quot;&gt;Phil Mui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02182">
<title>AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification. (arXiv:2308.02182v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2308.02182</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning (DL) has been successfully applied to encrypted network traffic
classification in experimental settings. However, in production use, it has
been shown that a DL classifier&apos;s performance inevitably decays over time.
Re-training the model on newer datasets has been shown to only partially
improve its performance. Manually re-tuning the model architecture to meet the
performance expectations on newer datasets is time-consuming and requires
domain expertise. We propose AutoML4ETC, a novel tool to automatically design
efficient and high-performing neural architectures for encrypted traffic
classification. We define a novel, powerful search space tailored specifically
for the near real-time classification of encrypted traffic using packet header
bytes. We show that with different search strategies over our search space,
AutoML4ETC generates neural architectures that outperform the state-of-the-art
encrypted traffic classifiers on several datasets, including public benchmark
datasets and real-world TLS and QUIC traffic collected from the Orange mobile
network. In addition to being more accurate, AutoML4ETC&apos;s architectures are
significantly more efficient and lighter in terms of the number of parameters.
Finally, we make AutoML4ETC publicly available for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malekghaini_N/0/1/0/all/0/1&quot;&gt;Navid Malekghaini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akbari_E/0/1/0/all/0/1&quot;&gt;Elham Akbari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salahuddin_M/0/1/0/all/0/1&quot;&gt;Mohammad A. Salahuddin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Limam_N/0/1/0/all/0/1&quot;&gt;Noura Limam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boutaba_R/0/1/0/all/0/1&quot;&gt;Raouf Boutaba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathieu_B/0/1/0/all/0/1&quot;&gt;Bertrand Mathieu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moteau_S/0/1/0/all/0/1&quot;&gt;Stephanie Moteau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuffin_S/0/1/0/all/0/1&quot;&gt;Stephane Tuffin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02193">
<title>Explaining Relation Classification Models with Semantic Extents. (arXiv:2308.02193v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.02193</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the development of large pretrained language models, such as
BERT and GPT, significantly improved information extraction systems on various
tasks, including relation classification. State-of-the-art systems are highly
accurate on scientific benchmarks. A lack of explainability is currently a
complicating factor in many real-world applications. Comprehensible systems are
necessary to prevent biased, counterintuitive, or harmful decisions.
&lt;/p&gt;
&lt;p&gt;We introduce semantic extents, a concept to analyze decision patterns for the
relation classification task. Semantic extents are the most influential parts
of texts concerning classification decisions. Our definition allows similar
procedures to determine semantic extents for humans and models. We provide an
annotation tool and a software framework to determine semantic extents for
humans and models conveniently and reproducibly. Comparing both reveals that
models tend to learn shortcut patterns from data. These patterns are hard to
detect with current interpretability methods, such as input reductions. Our
approach can help detect and eliminate spurious decision patterns during model
development. Semantic extents can increase the reliability and security of
natural language processing systems. Semantic extents are an essential step in
enabling applications in critical areas like healthcare or finance. Moreover,
our work opens new research directions for developing methods to explain deep
learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kloser_L/0/1/0/all/0/1&quot;&gt;Lars Kl&amp;#xf6;ser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Busgen_A/0/1/0/all/0/1&quot;&gt;Andre B&amp;#xfc;sgen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohl_P/0/1/0/all/0/1&quot;&gt;Philipp Kohl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kraft_B/0/1/0/all/0/1&quot;&gt;Bodo Kraft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zundorf_A/0/1/0/all/0/1&quot;&gt;Albert Z&amp;#xfc;ndorf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02199">
<title>A Survey of Spanish Clinical Language Models. (arXiv:2308.02199v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.02199</link>
<description rdf:parseType="Literal">&lt;p&gt;This survey focuses in encoder Language Models for solving tasks in the
clinical domain in the Spanish language. We review the contributions of 17
corpora focused mainly in clinical tasks, then list the most relevant Spanish
Language Models and Spanish Clinical Language models. We perform a thorough
comparison of these models by benchmarking them over a curated subset of the
available corpora, in order to find the best-performing ones; in total more
than 3000 models were fine-tuned for this study. All the tested corpora and the
best models are made publically available in an accessible way, so that the
results can be reproduced by independent teams or challenged in the future when
new Spanish Clinical Language models are created.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subies_G/0/1/0/all/0/1&quot;&gt;Guillem Garc&amp;#xed;a Subies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jimenez_A/0/1/0/all/0/1&quot;&gt;&amp;#xc1;lvaro Barbero Jim&amp;#xe9;nez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_P/0/1/0/all/0/1&quot;&gt;Paloma Mart&amp;#xed;nez Fern&amp;#xe1;ndez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02205">
<title>Towards Personalized Prompt-Model Retrieval for Generative Recommendation. (arXiv:2308.02205v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2308.02205</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommender Systems are built to retrieve relevant items to satisfy users&apos;
information needs. The candidate corpus usually consists of a finite set of
items that are ready to be served, such as videos, products, or articles. With
recent advances in Generative AI such as GPT and Diffusion models, a new form
of recommendation task is yet to be explored where items are to be created by
generative models with personalized prompts. Taking image generation as an
example, with a single prompt from the user and access to a generative model,
it is possible to generate hundreds of new images in a few minutes. How shall
we attain personalization in the presence of &quot;infinite&quot; items? In this
preliminary study, we propose a two-stage framework, namely Prompt-Model
Retrieval and Generated Item Ranking, to approach this new task formulation. We
release GEMRec-18K, a prompt-model interaction dataset with 18K images
generated by 200 publicly-available generative models paired with a diverse set
of 90 textual prompts. Our findings demonstrate the promise of generative model
recommendation as a novel personalization problem and the limitations of
existing evaluation metrics. We highlight future directions for the RecSys
community to advance towards generative recommender systems. Our code and
dataset are available at https://github.com/MAPS-research/GEMRec.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yuanhe Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haoming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1&quot;&gt;Hongyi Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02219">
<title>Federated Learning: Organizational Opportunities, Challenges, and Adoption Strategies. (arXiv:2308.02219v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02219</link>
<description rdf:parseType="Literal">&lt;p&gt;Restrictive rules for data sharing in many industries have led to the
development of \ac{FL}. \ac{FL} is a \ac{ML} technique that allows distributed
clients to train models collaboratively without the need to share their
respective training data with others. In this article, we first explore the
technical basics of FL and its potential applications. Second, we present a
conceptual framework for the adoption of \ac{FL}, mapping organizations along
the lines of their \ac{AI} capabilities and environment. We then discuss why
exemplary organizations in different industries, including industry consortia,
established banks, public authorities, and data-intensive SMEs might consider
different approaches to \ac{FL}. To conclude, we argue that \ac{FL} presents an
institutional shift with ample interdisciplinary research opportunities for the
business and information systems engineering community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_J/0/1/0/all/0/1&quot;&gt;Joaquin Delgado Fernandez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brennecke_M/0/1/0/all/0/1&quot;&gt;Martin Brennecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbereau_T/0/1/0/all/0/1&quot;&gt;Tom Barbereau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rieger_A/0/1/0/all/0/1&quot;&gt;Alexander Rieger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fridgen_G/0/1/0/all/0/1&quot;&gt;Gilbert Fridgen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02231">
<title>Should we trust web-scraped data?. (arXiv:2308.02231v1 [econ.GN])</title>
<link>http://arxiv.org/abs/2308.02231</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing adoption of econometric and machine-learning approaches by
empirical researchers has led to a widespread use of one data collection
method: web scraping. Web scraping refers to the use of automated computer
programs to access websites and download their content. The key argument of
this paper is that na\&quot;ive web scraping procedures can lead to sampling bias in
the collected data. This article describes three sources of sampling bias in
web-scraped data. More specifically, sampling bias emerges from web content
being volatile (i.e., being subject to change), personalized (i.e., presented
in response to request characteristics), and unindexed (i.e., abundance of a
population register). In a series of examples, I illustrate the prevalence and
magnitude of sampling bias. To support researchers and reviewers, this paper
provides recommendations on anticipating, detecting, and overcoming sampling
bias in web-scraped data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Foerderer_J/0/1/0/all/0/1&quot;&gt;Jens Foerderer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02239">
<title>DTF-Net: Category-Level Pose Estimation and Shape Reconstruction via Deformable Template Field. (arXiv:2308.02239v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.02239</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating 6D poses and reconstructing 3D shapes of objects in open-world
scenes from RGB-depth image pairs is challenging. Many existing methods rely on
learning geometric features that correspond to specific templates while
disregarding shape variations and pose differences among objects in the same
category. As a result, these methods underperform when handling unseen object
instances in complex environments. In contrast, other approaches aim to achieve
category-level estimation and reconstruction by leveraging normalized geometric
structure priors, but the static prior-based reconstruction struggles with
substantial intra-class variations. To solve these problems, we propose the
DTF-Net, a novel framework for pose estimation and shape reconstruction based
on implicit neural fields of object categories. In DTF-Net, we design a
deformable template field to represent the general category-wise shape latent
features and intra-category geometric deformation features. The field
establishes continuous shape correspondences, deforming the category template
into arbitrary observed instances to accomplish shape reconstruction. We
introduce a pose regression module that shares the deformation features and
template codes from the fields to estimate the accurate 6D pose of each object
in the scene. We integrate a multi-modal representation extraction module to
extract object features and semantic masks, enabling end-to-end inference.
Moreover, during training, we implement a shape-invariant training strategy and
a viewpoint sampling method to further enhance the model&apos;s capability to
extract object pose features. Extensive experiments on the REAL275 and CAMERA25
datasets demonstrate the superiority of DTF-Net in both synthetic and real
scenes. Furthermore, we show that DTF-Net effectively supports grasping tasks
with a real robot arm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haowen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhen Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1&quot;&gt;Zhengping Che&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Dong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1&quot;&gt;Feifei Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yakun Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_X/0/1/0/all/0/1&quot;&gt;Xiuquan Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jian Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02282">
<title>DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization. (arXiv:2308.02282v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02282</link>
<description rdf:parseType="Literal">&lt;p&gt;Time series remains one of the most challenging modalities in machine
learning research. The out-of-distribution (OOD) detection and generalization
on time series tend to suffer due to its non-stationary property, i.e., the
distribution changes over time. The dynamic distributions inside time series
pose great challenges to existing algorithms to identify invariant
distributions since they mainly focus on the scenario where the domain
information is given as prior knowledge. In this paper, we attempt to exploit
subdomains within a whole dataset to counteract issues induced by
non-stationary for generalized representation learning. We propose DIVERSIFY, a
general framework, for OOD detection and generalization on dynamic
distributions of time series. DIVERSIFY takes an iterative process: it first
obtains the &quot;worst-case&quot; latent distribution scenario via adversarial training,
then reduces the gap between these latent distributions. We implement DIVERSIFY
via combining existing OOD detection methods according to either extracted
features or outputs of models for detection while we also directly utilize
outputs for classification. In addition, theoretical insights illustrate that
DIVERSIFY is theoretically supported. Extensive experiments are conducted on
seven datasets with different OOD settings across gesture recognition, speech
commands recognition, wearable stress and affect detection, and sensor-based
human activity recognition. Qualitative and quantitative results demonstrate
that DIVERSIFY learns more generalized features and significantly outperforms
other baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1&quot;&gt;Wang Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xinwei Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiqiang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1&quot;&gt;Xiangyang Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02287">
<title>Frustratingly Easy Model Generalization by Dummy Risk Minimization. (arXiv:2308.02287v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02287</link>
<description rdf:parseType="Literal">&lt;p&gt;Empirical risk minimization (ERM) is a fundamental machine learning paradigm.
However, its generalization ability is limited in various tasks. In this paper,
we devise Dummy Risk Minimization (DuRM), a frustratingly easy and general
technique to improve the generalization of ERM. DuRM is extremely simple to
implement: just enlarging the dimension of the output logits and then
optimizing using standard gradient descent. Moreover, we validate the efficacy
of DuRM on both theoretical and empirical analysis. Theoretically, we show that
DuRM derives greater variance of the gradient, which facilitates model
generalization by observing better flat local minima. Empirically, we conduct
evaluations of DuRM across different datasets, modalities, and network
architectures on diverse tasks, including conventional classification, semantic
segmentation, out-of-distribution generalization, adverserial training, and
long-tailed recognition. Results demonstrate that DuRM could consistently
improve the performance under all tasks with an almost free lunch manner.
Furthermore, we show that DuRM is compatible with existing generalization
techniques and we discuss possible limitations. We hope that DuRM could trigger
new interest in the fundamental research on risk minimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Juncheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xixu Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shujun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02293">
<title>A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])</title>
<link>http://arxiv.org/abs/2308.02293</link>
<description rdf:parseType="Literal">&lt;p&gt;While highly expressive parametric models including deep neural networks have
an advantage to model complicated concepts, training such highly non-linear
models is known to yield a high risk of notorious overfitting. To address this
issue, this study considers a $k$th order total variation ($k$-TV)
regularization, which is defined as the squared integral of the $k$th order
derivative of the parametric models to be trained; penalizing the $k$-TV is
expected to yield a smoother function, which is expected to avoid overfitting.
While the $k$-TV terms applied to general parametric models are computationally
intractable due to the integration, this study provides a stochastic
optimization algorithm, that can efficiently train general models with the
$k$-TV regularization without conducting explicit numerical integration. The
proposed approach can be applied to the training of even deep neural networks
whose structure is arbitrary, as it can be implemented by only a simple
stochastic gradient descent algorithm and automatic differentiation. Our
numerical experiments demonstrate that the neural networks trained with the
$K$-TV terms are more ``resilient&apos;&apos; than those with the conventional parameter
regularization. The proposed algorithm also can be extended to the
physics-informed training of neural networks (PINNs).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Okuno_A/0/1/0/all/0/1&quot;&gt;Akifumi Okuno&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02294">
<title>Learning to Select the Relevant History Turns in Conversational Question Answering. (arXiv:2308.02294v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.02294</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing demand for the web-based digital assistants has given a rapid
rise in the interest of the Information Retrieval (IR) community towards the
field of conversational question answering (ConvQA). However, one of the
critical aspects of ConvQA is the effective selection of conversational history
turns to answer the question at hand. The dependency between relevant history
selection and correct answer prediction is an intriguing but under-explored
area. The selected relevant context can better guide the system so as to where
exactly in the passage to look for an answer. Irrelevant context, on the other
hand, brings noise to the system, thereby resulting in a decline in the model&apos;s
performance. In this paper, we propose a framework, DHS-ConvQA (Dynamic History
Selection in Conversational Question Answering), that first generates the
context and question entities for all the history turns, which are then pruned
on the basis of similarity they share in common with the question at hand. We
also propose an attention-based mechanism to re-rank the pruned terms based on
their calculated weights of how useful they are in answering the question. In
the end, we further aid the model by highlighting the terms in the re-ranked
conversational history using a binary classification task and keeping the
useful terms (predicted as 1) and ignoring the irrelevant terms (predicted as
0). We demonstrate the efficacy of our proposed framework with extensive
experimental results on CANARD and QuAC -- the two popularly utilized datasets
in ConvQA. We demonstrate that selecting relevant turns works better than
rewriting the original question. We also investigate how adding the irrelevant
history turns negatively impacts the model&apos;s performance and discuss the
research challenges that demand more attention from the IR community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaib_M/0/1/0/all/0/1&quot;&gt;Munazza Zaib&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Emma Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1&quot;&gt;Quan Z. Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagar_S/0/1/0/all/0/1&quot;&gt;Subhash Sagar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1&quot;&gt;Adnan Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02312">
<title>Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions. (arXiv:2308.02312v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2308.02312</link>
<description rdf:parseType="Literal">&lt;p&gt;Q&amp;amp;A platforms have been an integral part of the web-help-seeking behavior of
programmers over the past decade. However, with the recent introduction of
ChatGPT, the paradigm of web-help-seeking behavior is experiencing a shift.
Despite the popularity of ChatGPT, no comprehensive study has been conducted to
evaluate the characteristics or usability of ChatGPT&apos;s answers to software
engineering questions. To bridge the gap, we conducted the first in-depth
analysis of ChatGPT&apos;s answers to 517 Stack Overflow (SO) questions and examined
the correctness, consistency, comprehensiveness, and conciseness of ChatGPT&apos;s
answers. Furthermore, we conducted a large-scale linguistic analysis, and a
user study to understand the characteristics of ChatGPT answers from linguistic
and human aspects. Our analysis shows that 52\% of ChatGPT answers are
incorrect and 77\% are verbose. Nonetheless, ChatGPT answers are still
preferred 39.34\% of the time due to their comprehensiveness and
well-articulated language style. Our result implies the necessity of close
examination and rectification of errors in ChatGPT, at the same time creating
awareness among its users of the risks associated with seemingly correct
ChatGPT answers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kabir_S/0/1/0/all/0/1&quot;&gt;Samia Kabir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Udo_Imeh_D/0/1/0/all/0/1&quot;&gt;David N. Udo-Imeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kou_B/0/1/0/all/0/1&quot;&gt;Bonan Kou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02317">
<title>A Controllable Co-Creative Agent for Game System Design. (arXiv:2308.02317v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2308.02317</link>
<description rdf:parseType="Literal">&lt;p&gt;Many advancements have been made in procedural content generation for games,
and with mixed-initiative co-creativity, have the potential for great benefits
to human designers. However, co-creative systems for game generation are
typically limited to specific genres, rules, or games, limiting the creativity
of the designer. We seek to model games abstractly enough to apply to any
genre, focusing on designing game systems and mechanics, and create a
controllable, co-creative agent that can collaborate on these designs. We
present a model of games using state-machine-like components and resource
flows, a set of controllable metrics, a design evaluator simulating
playthroughs with these metrics, and an evolutionary design balancer and
generator. We find this system to be both able to express a wide range of games
and able to be human-controllable for future co-creative applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_R/0/1/0/all/0/1&quot;&gt;Rohan Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhiyu Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1&quot;&gt;Mark Riedl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02335">
<title>RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification. (arXiv:2308.02335v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02335</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph classification is a crucial task in many real-world multimedia
applications, where graphs can represent various multimedia data types such as
images, videos, and social networks. Previous efforts have applied graph neural
networks (GNNs) in balanced situations where the class distribution is
balanced. However, real-world data typically exhibit long-tailed class
distributions, resulting in a bias towards the head classes when using GNNs and
limited generalization ability over the tail classes. Recent approaches mainly
focus on re-balancing different classes during model training, which fails to
explicitly introduce new knowledge and sacrifices the performance of the head
classes. To address these drawbacks, we propose a novel framework called
Retrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature
extractor and an unbiased classifier in a decoupled manner. In the feature
extractor training stage, we develop a graph retrieval module to search for
relevant graphs that directly enrich the intra-class diversity for the tail
classes. Moreover, we innovatively optimize a category-centered supervised
contrastive loss to obtain discriminative representations, which is more
suitable for long-tailed scenarios. In the classifier fine-tuning stage, we
balance the classifier weights with two weight regularization techniques, i.e.,
Max-norm and weight decay. Experiments on various popular benchmarks verify the
superiority of the proposed method against state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1&quot;&gt;Zhengyang Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ju_W/0/1/0/all/0/1&quot;&gt;Wei Ju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1&quot;&gt;Yifang Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Ming Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02353">
<title>Adapting to Change: Robust Counterfactual Explanations in Dynamic Data Landscapes. (arXiv:2308.02353v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02353</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel semi-supervised Graph Counterfactual Explainer (GCE)
methodology, Dynamic GRAph Counterfactual Explainer (DyGRACE). It leverages
initial knowledge about the data distribution to search for valid
counterfactuals while avoiding using information from potentially outdated
decision functions in subsequent time steps. Employing two graph autoencoders
(GAEs), DyGRACE learns the representation of each class in a binary
classification scenario. The GAEs minimise the reconstruction error between the
original graph and its learned representation during training. The method
involves (i) optimising a parametric density function (implemented as a
logistic regression function) to identify counterfactuals by maximising the
factual autoencoder&apos;s reconstruction error, (ii) minimising the counterfactual
autoencoder&apos;s error, and (iii) maximising the similarity between the factual
and counterfactual graphs. This semi-supervised approach is independent of an
underlying black-box oracle. A logistic regression model is trained on a set of
graph pairs to learn weights that aid in finding counterfactuals. At inference,
for each unseen graph, the logistic regressor identifies the best
counterfactual candidate using these learned weights, while the GAEs can be
iteratively updated to represent the continual adaptation of the learned graph
representation over iterations. DyGRACE is quite effective and can act as a
drift detector, identifying distributional drift based on differences in
reconstruction errors between iterations. It avoids reliance on the oracle&apos;s
predictions in successive iterations, thereby increasing the efficiency of
counterfactual discovery. DyGRACE, with its capacity for contrastive learning
and drift detection, will offer new avenues for semi-supervised learning and
explanation generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prenkaj_B/0/1/0/all/0/1&quot;&gt;Bardh Prenkaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villaizan_Vallelado_M/0/1/0/all/0/1&quot;&gt;Mario Villaizan-Vallelado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leemann_T/0/1/0/all/0/1&quot;&gt;Tobias Leemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1&quot;&gt;Gjergji Kasneci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02357">
<title>Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text. (arXiv:2308.02357v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.02357</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent advances in large language models (LLM) and foundation models with
emergent capabilities have been shown to improve the performance of many NLP
tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs
can be used for KG construction or completion while existing KGs can be used
for different tasks such as making LLM outputs explainable or fact-checking in
Neuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to
evaluate the capabilities of language models to generate KGs from natural
language text guided by an ontology. Given an input ontology and a set of
sentences, the task is to extract facts from the text while complying with the
given ontology (concepts, relations, domain/range constraints) and being
faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen
with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19
ontologies and 4,860 sentences. We define seven evaluation metrics to measure
fact extraction performance, ontology conformance, and hallucinations by LLMs.
Furthermore, we provide results for two baseline models, Vicuna-13B and
Alpaca-LoRA-13B using automatic prompt generation from test cases. The baseline
results show that there is room for improvement using both Semantic Web and
Natural Language Processing techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1&quot;&gt;Nandana Mihindukulasooriya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_S/0/1/0/all/0/1&quot;&gt;Sanju Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Enguix_C/0/1/0/all/0/1&quot;&gt;Carlos F. Enguix&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lata_K/0/1/0/all/0/1&quot;&gt;Kusum Lata&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02362">
<title>Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings. (arXiv:2308.02362v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2308.02362</link>
<description rdf:parseType="Literal">&lt;p&gt;The emergence of vertical federated learning (VFL) has stimulated concerns
about the imperfection in privacy protection, as shared feature embeddings may
reveal sensitive information under privacy attacks. This paper studies the
delicate equilibrium between data privacy and task utility goals of VFL under
differential privacy (DP). To address the generality issue of prior arts, this
paper advocates a flexible and generic approach that decouples the two goals
and addresses them successively. Specifically, we initially derive a rigorous
privacy guarantee by applying norm clipping on shared feature embeddings, which
is applicable across various datasets and models. Subsequently, we demonstrate
that task utility can be optimized via adaptive adjustments on the scale and
distribution of feature embeddings in an accuracy-appreciative way, without
compromising established DP mechanisms. We concretize our observation into the
proposed VFL-AFE framework, which exhibits effectiveness against privacy
attacks and the capacity to retain favorable task utility, as substantiated by
extensive experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mi_Y/0/1/0/all/0/1&quot;&gt;Yuxi Mi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hongquan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1&quot;&gt;Yewei Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yiheng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1&quot;&gt;Jihong Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Shuigeng Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02369">
<title>Universal Defensive Underpainting Patch: Making Your Text Invisible to Optical Character Recognition. (arXiv:2308.02369v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.02369</link>
<description rdf:parseType="Literal">&lt;p&gt;Optical Character Recognition (OCR) enables automatic text extraction from
scanned or digitized text images, but it also makes it easy to pirate valuable
or sensitive text from these images. Previous methods to prevent OCR piracy by
distorting characters in text images are impractical in real-world scenarios,
as pirates can capture arbitrary portions of the text images, rendering the
defenses ineffective. In this work, we propose a novel and effective defense
mechanism termed the Universal Defensive Underpainting Patch (UDUP) that
modifies the underpainting of text images instead of the characters. UDUP is
created through an iterative optimization process to craft a small, fixed-size
defensive patch that can generate non-overlapping underpainting for text images
of any size. Experimental results show that UDUP effectively defends against
unauthorized OCR under the setting of any screenshot range or complex image
background. It is agnostic to the content, size, colors, and languages of
characters, and is robust to typical image operations such as scaling and
compressing. In addition, the transferability of UDUP is demonstrated by
evading several off-the-shelf OCRs. The code is available at
https://github.com/QRICKDD/UDUP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1&quot;&gt;JiaCheng Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1&quot;&gt;Li Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiahao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_D/0/1/0/all/0/1&quot;&gt;Diqun Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Rangding Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1&quot;&gt;Dengpan Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Lingchen Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1&quot;&gt;Jinyu Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02370">
<title>A Machine Learning Method for Predicting Traffic Signal Timing from Probe Vehicle Data. (arXiv:2308.02370v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02370</link>
<description rdf:parseType="Literal">&lt;p&gt;Traffic signals play an important role in transportation by enabling traffic
flow management, and ensuring safety at intersections. In addition, knowing the
traffic signal phase and timing data can allow optimal vehicle routing for time
and energy efficiency, eco-driving, and the accurate simulation of signalized
road networks. In this paper, we present a machine learning (ML) method for
estimating traffic signal timing information from vehicle probe data. To the
authors best knowledge, very few works have presented ML techniques for
determining traffic signal timing parameters from vehicle probe data. In this
work, we develop an Extreme Gradient Boosting (XGBoost) model to estimate
signal cycle lengths and a neural network model to determine the corresponding
red times per phase from probe data. The green times are then be derived from
the cycle length and red times. Our results show an error of less than 0.56 sec
for cycle length, and red times predictions within 7.2 sec error on average.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ugirumurera_J/0/1/0/all/0/1&quot;&gt;Juliette Ugirumurera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Severino_J/0/1/0/all/0/1&quot;&gt;Joseph Severino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bensen_E/0/1/0/all/0/1&quot;&gt;Erik A. Bensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qichao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macfarlane_J/0/1/0/all/0/1&quot;&gt;Jane Macfarlane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02382">
<title>Scaling Survival Analysis in Healthcare with Federated Survival Forests: A Comparative Study on Heart Failure and Breast Cancer Genomics. (arXiv:2308.02382v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02382</link>
<description rdf:parseType="Literal">&lt;p&gt;Survival analysis is a fundamental tool in medicine, modeling the time until
an event of interest occurs in a population. However, in real-world
applications, survival data are often incomplete, censored, distributed, and
confidential, especially in healthcare settings where privacy is critical. The
scarcity of data can severely limit the scalability of survival models to
distributed applications that rely on large data pools. Federated learning is a
promising technique that enables machine learning models to be trained on
multiple datasets without compromising user privacy, making it particularly
well-suited for addressing the challenges of survival data and large-scale
survival applications. Despite significant developments in federated learning
for classification and regression, many directions remain unexplored in the
context of survival analysis. In this work, we propose an extension of the
Federated Survival Forest algorithm, called FedSurF++. This federated ensemble
method constructs random survival forests in heterogeneous federations.
Specifically, we investigate several new tree sampling methods from client
forests and compare the results with state-of-the-art survival models based on
neural networks. The key advantage of FedSurF++ is its ability to achieve
comparable performance to existing methods while requiring only a single
communication round to complete. The extensive empirical investigation results
in a significant improvement from the algorithmic and privacy preservation
perspectives, making the original FedSurF algorithm more efficient, robust, and
private. We also present results on two real-world datasets demonstrating the
success of FedSurF++ in real-world healthcare studies. Our results underscore
the potential of FedSurF++ to improve the scalability and effectiveness of
survival analysis in distributed settings while preserving user privacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Archetti_A/0/1/0/all/0/1&quot;&gt;Alberto Archetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ieva_F/0/1/0/all/0/1&quot;&gt;Francesca Ieva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matteucci_M/0/1/0/all/0/1&quot;&gt;Matteo Matteucci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02408">
<title>Evaluating the structure of cognitive tasks with transfer learning. (arXiv:2308.02408v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2308.02408</link>
<description rdf:parseType="Literal">&lt;p&gt;Electroencephalography (EEG) decoding is a challenging task due to the
limited availability of labelled data. While transfer learning is a promising
technique to address this challenge, it assumes that transferable data domains
and task are known, which is not the case in this setting. This study
investigates the transferability of deep learning representations between
different EEG decoding tasks. We conduct extensive experiments using
state-of-the-art decoding models on two recently released EEG datasets, ERP
CORE and M$^3$CV, containing over 140 subjects and 11 distinct cognitive tasks.
We measure the transferability of learned representations by pre-training deep
neural networks on one task and assessing their ability to decode subsequent
tasks. Our experiments demonstrate that, even with linear probing transfer,
significant improvements in decoding performance can be obtained, with gains of
up to 28% compare with the pure supervised approach. Additionally, we discover
evidence that certain decoding paradigms elicit specific and narrow brain
activities, while others benefit from pre-training on a broad range of
representations. By revealing which tasks transfer well and demonstrating the
benefits of transfer learning for EEG decoding, our findings have practical
implications for mitigating data scarcity in this setting. The transfer maps
generated also provide insights into the hierarchical relations between
cognitive tasks, hence enhancing our understanding of how these tasks are
connected from a neuroscientific standpoint.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Aristimunha_B/0/1/0/all/0/1&quot;&gt;Bruno Aristimunha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Camargo_R/0/1/0/all/0/1&quot;&gt;Raphael Y. de Camargo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pinaya_W/0/1/0/all/0/1&quot;&gt;Walter H. Lopez Pinaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chevallier_S/0/1/0/all/0/1&quot;&gt;Sylvain Chevallier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gramfort_A/0/1/0/all/0/1&quot;&gt;Alexandre Gramfort&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rommel_C/0/1/0/all/0/1&quot;&gt;Cedric Rommel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02409">
<title>Mental Workload Estimation with Electroencephalogram Signals by Combining Multi-Space Deep Models. (arXiv:2308.02409v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2308.02409</link>
<description rdf:parseType="Literal">&lt;p&gt;The human brain is in a continuous state of activity during both work and
rest. Mental activity is a daily process, and when the brain is overworked, it
can have negative effects on human health. In recent years, great attention has
been paid to early detection of mental health problems because it can help
prevent serious health problems and improve quality of life. Several signals
are used to assess mental state, but the electroencephalogram (EEG) is widely
used by researchers because of the large amount of information it provides
about the brain. This paper aims to classify mental workload into three states
and estimate continuum levels. Our method combines multiple dimensions of space
to achieve the best results for mental estimation. In the time domain approach,
we use Temporal Convolutional Networks, and in the frequency domain, we propose
a new architecture called the Multi-Dimensional Residual Block, which combines
residual blocks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Hong-Hai Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Iyortsuun_N/0/1/0/all/0/1&quot;&gt;Ngumimi Karen Iyortsuun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hyung-Jeong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_G/0/1/0/all/0/1&quot;&gt;Guee-Sang Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Soo-Hyung Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02412">
<title>Self-Supervised Learning for WiFi CSI-Based Human Activity Recognition: A Systematic Study. (arXiv:2308.02412v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2308.02412</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, with the advancement of the Internet of Things (IoT), WiFi
CSI-based HAR has gained increasing attention from academic and industry
communities. By integrating the deep learning technology with CSI-based HAR,
researchers achieve state-of-the-art performance without the need of expert
knowledge. However, the scarcity of labeled CSI data remains the most prominent
challenge when applying deep learning models in the context of CSI-based HAR
due to the privacy and incomprehensibility of CSI-based HAR data. On the other
hand, SSL has emerged as a promising approach for learning meaningful
representations from data without heavy reliance on labeled examples.
Therefore, considerable efforts have been made to address the challenge of
insufficient data in deep learning by leveraging SSL algorithms. In this paper,
we undertake a comprehensive inventory and analysis of the potential held by
different categories of SSL algorithms, including those that have been
previously studied and those that have not yet been explored, within the field.
We provide an in-depth investigation of SSL algorithms in the context of WiFi
CSI-based HAR. We evaluate four categories of SSL algorithms using three
publicly available CSI HAR datasets, each encompassing different tasks and
environmental settings. To ensure relevance to real-world applications, we
design performance metrics that align with specific requirements. Furthermore,
our experimental findings uncover several limitations and blind spots in
existing work, highlighting the barriers that need to be addressed before SSL
can be effectively deployed in real-world WiFi-based HAR applications. Our
results also serve as a practical guideline for industry practitioners and
provide valuable insights for future research endeavors in this field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Ke Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiangtao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zheng_D/0/1/0/all/0/1&quot;&gt;Dingchang Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02415">
<title>Car-Driver Drowsiness Assessment through 1D Temporal Convolutional Networks. (arXiv:2308.02415v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2308.02415</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the scientific progress of Advanced Driver Assistance System
solutions (ADAS) has played a key role in enhancing the overall safety of
driving. ADAS technology enables active control of vehicles to prevent
potentially risky situations. An important aspect that researchers have focused
on is the analysis of the driver attention level, as recent reports confirmed a
rising number of accidents caused by drowsiness or lack of attentiveness. To
address this issue, various studies have suggested monitoring the driver
physiological state, as there exists a well-established connection between the
Autonomic Nervous System (ANS) and the level of attention. For our study, we
designed an innovative bio-sensor comprising near-infrared LED emitters and
photo-detectors, specifically a Silicon PhotoMultiplier device. This allowed us
to assess the driver physiological status by analyzing the associated
PhotoPlethysmography (PPG) signal.Furthermore, we developed an embedded
time-domain hyper-filtering technique in conjunction with a 1D Temporal
Convolutional architecture that embdes a progressive dilation setup. This
integrated system enables near real-time classification of driver drowsiness,
yielding remarkable accuracy levels of approximately 96%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rundo_F/0/1/0/all/0/1&quot;&gt;Francesco Rundo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Spampinato_C/0/1/0/all/0/1&quot;&gt;Concetto Spampinato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rundo_M/0/1/0/all/0/1&quot;&gt;Michael Rundo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02419">
<title>Multimodal Indoor Localisation in Parkinson&apos;s Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting. (arXiv:2308.02419v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2308.02419</link>
<description rdf:parseType="Literal">&lt;p&gt;Parkinson&apos;s disease (PD) is a slowly progressive, debilitating
neurodegenerative disease which causes motor symptoms including gait
dysfunction. Motor fluctuations are alterations between periods with a positive
response to levodopa therapy (&quot;on&quot;) and periods marked by re-emergency of PD
symptoms (&quot;off&quot;) as the response to medication wears off. These fluctuations
often affect gait speed and they increase in their disabling impact as PD
progresses. To improve the effectiveness of current indoor localisation
methods, a transformer-based approach utilising dual modalities which provide
complementary views of movement, Received Signal Strength Indicator (RSSI) and
accelerometer data from wearable devices, is proposed. A sub-objective aims to
evaluate whether indoor localisation, including its in-home gait speed features
(i.e. the time taken to walk between rooms), could be used to evaluate motor
fluctuations by detecting whether the person with PD is taking levodopa
medications or withholding them. To properly evaluate our proposed method, we
use a free-living dataset where the movements and mobility are greatly varied
and unstructured as expected in real-world conditions. 24 participants lived in
pairs (consisting of one person with PD, one control) for five days in a smart
home with various sensors. Our evaluation on the resulting dataset demonstrates
that our proposed network outperforms other methods for indoor localisation.
The sub-objective evaluation shows that precise room-level localisation
predictions, transformed into in-home gait speed features, produce accurate
predictions on whether the PD participant is taking or withholding their
medications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jovan_F/0/1/0/all/0/1&quot;&gt;Ferdian Jovan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Morgan_C/0/1/0/all/0/1&quot;&gt;Catherine Morgan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+McConville_R/0/1/0/all/0/1&quot;&gt;Ryan McConville&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tonkin_E/0/1/0/all/0/1&quot;&gt;Emma L. Tonkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Craddock_I/0/1/0/all/0/1&quot;&gt;Ian Craddock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Whone_A/0/1/0/all/0/1&quot;&gt;Alan Whone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02424">
<title>Implementing Smart Contracts: The case of NFT-rental with pay-per-like. (arXiv:2308.02424v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02424</link>
<description rdf:parseType="Literal">&lt;p&gt;Non-fungible tokens(NFTs) are on the rise. They can represent artworks
exhibited for marketing purposes on webpages of companies or online stores --
analogously to physical artworks. Lending of NFTs is an attractive form of
passive income for owners but comes with risks (e.g., items are not returned)
and costs for escrow agents. Similarly, renters have difficulties in
anticipating the impact of artworks, e.g., how spectators of NFTs perceive
them. To address these challenges, we introduce an NFT rental solution based on
a pay-per-like pricing model using blockchain technology, i.e., smart contracts
based on the Ethereum chain. We find that blockchain solutions enjoy many
advantages also reported for other applications, but interestingly, we also
observe dark sides of (large) blockchain fees. Blockchain solutions appear
unfair to niche artists and potentially hamper cultural diversity. Furthermore,
a trust-cost tradeoff arises to handle fraud caused by manipulation from
parties outside the blockchain. All code for the solution is publicly available
at: https://github.com/asopi/rental-project
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sopi_A/0/1/0/all/0/1&quot;&gt;Alfred Sopi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1&quot;&gt;Johannes Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brocke_J/0/1/0/all/0/1&quot;&gt;Jan vom Brocke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02427">
<title>Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training. (arXiv:2308.02427v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2308.02427</link>
<description rdf:parseType="Literal">&lt;p&gt;While effective, the backpropagation (BP) algorithm exhibits limitations in
terms of biological plausibility, computational cost, and suitability for
online learning. As a result, there has been a growing interest in developing
alternative biologically plausible learning approaches that rely on local
learning rules. This study focuses on the primarily unsupervised similarity
matching (SM) framework, which aligns with observed mechanisms in biological
systems and offers online, localized, and biologically plausible algorithms. i)
To scale SM to large datasets, we propose an implementation of Convolutional
Nonnegative SM using PyTorch. ii) We introduce a localized supervised SM
objective reminiscent of canonical correlation analysis, facilitating stacking
SM layers. iii) We leverage the PyTorch implementation for pre-training
architectures such as LeNet and compare the evaluation of features against
BP-trained models. This work combines biologically plausible algorithms with
computational efficiency opening multiple avenues for further explorations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bahroun_Y/0/1/0/all/0/1&quot;&gt;Yanis Bahroun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1&quot;&gt;Shagesh Sridharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1&quot;&gt;Atithi Acharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chklovskii_D/0/1/0/all/0/1&quot;&gt;Dmitri B. Chklovskii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sengupta_A/0/1/0/all/0/1&quot;&gt;Anirvan M. Sengupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02432">
<title>Performance of Large Language Models in a Computer Science Degree Program. (arXiv:2308.02432v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02432</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models such as ChatGPT-3.5 and GPT-4.0 are ubiquitous and
dominate the current discourse. Their transformative capabilities have led to a
paradigm shift in how we interact with and utilize (text-based) information.
Each day, new possibilities to leverage the capabilities of these models
emerge. This paper presents findings on the performance of different large
language models in a university of applied sciences&apos; undergraduate computer
science degree program. Our primary objective is to assess the effectiveness of
these models within the curriculum by employing them as educational aids. By
prompting the models with lecture material, exercise tasks, and past exams, we
aim to evaluate their proficiency across different computer science domains. We
showcase the strong performance of current large language models while
highlighting limitations and constraints within the context of such a degree
program. We found that ChatGPT-3.5 averaged 79.9% of the total score in 10
tested modules, BingAI achieved 68.4%, and LLaMa, in the 65 billion parameter
variant, 20%. Despite these convincing results, even GPT-4.0 would not pass the
degree program - due to limitations in mathematical calculations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kruger_T/0/1/0/all/0/1&quot;&gt;Tim Kr&amp;#xfc;ger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gref_M/0/1/0/all/0/1&quot;&gt;Michael Gref&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02435">
<title>Designing Fiduciary Artificial Intelligence. (arXiv:2308.02435v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02435</link>
<description rdf:parseType="Literal">&lt;p&gt;A fiduciary is a trusted agent that has the legal duty to act with loyalty
and care towards a principal that employs them. When fiduciary organizations
interact with users through a digital interface, or otherwise automate their
operations with artificial intelligence, they will need to design these AI
systems to be compliant with their duties. This article synthesizes recent work
in computer science and law to develop a procedure for designing and auditing
Fiduciary AI. The designer of a Fiduciary AI should understand the context of
the system, identify its principals, and assess the best interests of those
principals. Then the designer must be loyal with respect to those interests,
and careful in an contextually appropriate way. We connect the steps in this
procedure to dimensions of Trustworthy AI, such as privacy and alignment.
Fiduciary AI is a promising means to address the incompleteness of data
subject&apos;s consent when interacting with complex technical systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benthall_S/0/1/0/all/0/1&quot;&gt;Sebastian Benthall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shekman_D/0/1/0/all/0/1&quot;&gt;David Shekman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02439">
<title>A large language model-assisted education tool to provide feedback on open-ended responses. (arXiv:2308.02439v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02439</link>
<description rdf:parseType="Literal">&lt;p&gt;Open-ended questions are a favored tool among instructors for assessing
student understanding and encouraging critical exploration of course material.
Providing feedback for such responses is a time-consuming task that can lead to
overwhelmed instructors and decreased feedback quality. Many instructors resort
to simpler question formats, like multiple-choice questions, which provide
immediate feedback but at the expense of personalized and insightful comments.
Here, we present a tool that uses large language models (LLMs), guided by
instructor-defined criteria, to automate responses to open-ended questions. Our
tool delivers rapid personalized feedback, enabling students to quickly test
their knowledge and identify areas for improvement. We provide open-source
reference implementations both as a web application and as a Jupyter Notebook
widget that can be used with instructional coding or math notebooks. With
instructor guidance, LLMs hold promise to enhance student learning outcomes and
elevate instructional methodologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matelsky_J/0/1/0/all/0/1&quot;&gt;Jordan K. Matelsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parodi_F/0/1/0/all/0/1&quot;&gt;Felipe Parodi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tony Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lange_R/0/1/0/all/0/1&quot;&gt;Richard D. Lange&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kording_K/0/1/0/all/0/1&quot;&gt;Konrad P. Kording&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02441">
<title>How to Design and Deliver Courses for Higher Education in the AI Era: Insights from Exam Data Analysis. (arXiv:2308.02441v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02441</link>
<description rdf:parseType="Literal">&lt;p&gt;In this position paper, we advocate for the idea that courses and exams in
the AI era have to be designed based on two factors: (1) the strengths and
limitations of AI, and (2) the pedagogical educational objectives. Based on
insights from the Delors report on education [1], we first address the role of
education and recall the main objectives that educational institutes must
strive to achieve independently of any technology. We then explore the
strengths and limitations of AI, based on current advances in AI. We explain
how courses and exams can be designed based on these strengths and limitations
of AI, providing different examples in the IT, English, and Art domains. We
show how we adopted a pedagogical approach that is inspired from the Socratic
teaching method from January 2023 to May 2023. Then, we present the data
analysis results of seven ChatGPT-authorized exams conducted between December
2022 and March 2023. Our exam data results show that there is no correlation
between students&apos; grades and whether or not they use ChatGPT to answer their
exam questions. Finally, we present a new exam system that allows us to apply
our pedagogical approach in the AI era.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wazan_A/0/1/0/all/0/1&quot;&gt;Ahmad Samer Wazan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taj_I/0/1/0/all/0/1&quot;&gt;Imran Taj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shoufan_A/0/1/0/all/0/1&quot;&gt;Abdulhadi Shoufan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laborde_R/0/1/0/all/0/1&quot;&gt;Romain Laborde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venant_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Venant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02443">
<title>AI Literature Review Suite. (arXiv:2308.02443v1 [cs.DL])</title>
<link>http://arxiv.org/abs/2308.02443</link>
<description rdf:parseType="Literal">&lt;p&gt;The process of conducting literature reviews is often time-consuming and
labor-intensive. To streamline this process, I present an AI Literature Review
Suite that integrates several functionalities to provide a comprehensive
literature review. This tool leverages the power of open access science, large
language models (LLMs) and natural language processing to enable the searching,
downloading, and organizing of PDF files, as well as extracting content from
articles. Semantic search queries are used for data retrieval, while text
embeddings and summarization using LLMs present succinct literature reviews.
Interaction with PDFs is enhanced through a user-friendly graphical user
interface (GUI). The suite also features integrated programs for bibliographic
organization, interaction and query, and literature review summaries. This tool
presents a robust solution to automate and optimize the process of literature
review in academic and industrial research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tovar_D/0/1/0/all/0/1&quot;&gt;David A. Tovar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02448">
<title>From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence. (arXiv:2308.02448v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2308.02448</link>
<description rdf:parseType="Literal">&lt;p&gt;In 2020, the U.S. Department of Defense officially disclosed a set of ethical
principles to guide the use of Artificial Intelligence (AI) technologies on
future battlefields. Despite stark differences, there are core similarities
between the military and medical service. Warriors on battlefields often face
life-altering circumstances that require quick decision-making. Medical
providers experience similar challenges in a rapidly changing healthcare
environment, such as in the emergency department or during surgery treating a
life-threatening condition. Generative AI, an emerging technology designed to
efficiently generate valuable information, holds great promise. As computing
power becomes more accessible and the abundance of health data, such as
electronic health records, electrocardiograms, and medical images, increases,
it is inevitable that healthcare will be revolutionized by this technology.
Recently, generative AI has captivated the research community, leading to
debates about its application in healthcare, mainly due to concerns about
transparency and related issues. Meanwhile, concerns about the potential
exacerbation of health disparities due to modeling biases have raised notable
ethical concerns regarding the use of this technology in healthcare. However,
the ethical principles for generative AI in healthcare have been understudied,
and decision-makers often fail to consider the significance of generative AI.
In this paper, we propose GREAT PLEA ethical principles, encompassing
governance, reliability, equity, accountability, traceability, privacy,
lawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to
proactively address the ethical dilemmas and challenges posed by the
integration of generative AI in healthcare.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1&quot;&gt;David Oniani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hilsman_J/0/1/0/all/0/1&quot;&gt;Jordan Hilsman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1&quot;&gt;Yifan Peng&lt;/a&gt;, COL (Ret.) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poropatich_R/0/1/0/all/0/1&quot;&gt;Ronald K. Poropatich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pamplin_C/0/1/0/all/0/1&quot;&gt;COL Jeremy C. Pamplin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Legault_L/0/1/0/all/0/1&quot;&gt;LTC Gary L. Legault&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanshan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02454">
<title>SoK: Assessing the State of Applied Federated Machine Learning. (arXiv:2308.02454v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.02454</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning (ML) has shown significant potential in various
applications; however, its adoption in privacy-critical domains has been
limited due to concerns about data privacy. A promising solution to this issue
is Federated Machine Learning (FedML), a model-to-data approach that
prioritizes data privacy. By enabling ML algorithms to be applied directly to
distributed data sources without sharing raw data, FedML offers enhanced
privacy protections, making it suitable for privacy-critical environments.
Despite its theoretical benefits, FedML has not seen widespread practical
implementation. This study aims to explore the current state of applied FedML
and identify the challenges hindering its practical adoption. Through a
comprehensive systematic literature review, we assess 74 relevant papers to
analyze the real-world applicability of FedML. Our analysis focuses on the
characteristics and emerging trends of FedML implementations, as well as the
motivational drivers and application domains. We also discuss the encountered
challenges in integrating FedML into real-life settings. By shedding light on
the existing landscape and potential obstacles, this research contributes to
the further development and implementation of FedML in privacy-critical
scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1&quot;&gt;Tobias M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stabler_M/0/1/0/all/0/1&quot;&gt;Maximilian St&amp;#xe4;bler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gascon_H/0/1/0/all/0/1&quot;&gt;Hugo Gasc&amp;#xf3;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koster_F/0/1/0/all/0/1&quot;&gt;Frank K&amp;#xf6;ster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matthes_F/0/1/0/all/0/1&quot;&gt;Florian Matthes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02457">
<title>A Survey on Temporal Knowledge Graph Completion: Taxonomy, Progress, and Prospects. (arXiv:2308.02457v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2308.02457</link>
<description rdf:parseType="Literal">&lt;p&gt;Temporal characteristics are prominently evident in a substantial volume of
knowledge, which underscores the pivotal role of Temporal Knowledge Graphs
(TKGs) in both academia and industry. However, TKGs often suffer from
incompleteness for three main reasons: the continuous emergence of new
knowledge, the weakness of the algorithm for extracting structured information
from unstructured data, and the lack of information in the source dataset.
Thus, the task of Temporal Knowledge Graph Completion (TKGC) has attracted
increasing attention, aiming to predict missing items based on the available
information. In this paper, we provide a comprehensive review of TKGC methods
and their details. Specifically, this paper mainly consists of three
components, namely, 1)Background, which covers the preliminaries of TKGC
methods, loss functions required for training, as well as the dataset and
evaluation protocol; 2)Interpolation, that estimates and predicts the missing
elements or set of elements through the relevant available information. It
further categorizes related TKGC methods based on how to process temporal
information; 3)Extrapolation, which typically focuses on continuous TKGs and
predicts future events, and then classifies all extrapolation methods based on
the algorithms they utilize. We further pinpoint the challenges and discuss
future research directions of TKGC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiapu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Boyue Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_M/0/1/0/all/0/1&quot;&gt;Meikang Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1&quot;&gt;Shirui Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_B/0/1/0/all/0/1&quot;&gt;Bo Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Heng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1&quot;&gt;Linhao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tengfei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yongli Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1&quot;&gt;Baocai Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wen Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02459">
<title>Nonprehensile Planar Manipulation through Reinforcement Learning with Multimodal Categorical Exploration. (arXiv:2308.02459v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2308.02459</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing robot controllers capable of achieving dexterous nonprehensile
manipulation, such as pushing an object on a table, is challenging. The
underactuated and hybrid-dynamics nature of the problem, further complicated by
the uncertainty resulting from the frictional interactions, requires
sophisticated control behaviors. Reinforcement Learning (RL) is a powerful
framework for developing such robot controllers. However, previous RL
literature addressing the nonprehensile pushing task achieves low accuracy,
non-smooth trajectories, and only simple motions, i.e. without rotation of the
manipulated object. We conjecture that previously used unimodal exploration
strategies fail to capture the inherent hybrid-dynamics of the task, arising
from the different possible contact interaction modes between the robot and the
object, such as sticking, sliding, and separation. In this work, we propose a
multimodal exploration approach through categorical distributions, which
enables us to train planar pushing RL policies for arbitrary starting and
target object poses, i.e. positions and orientations, and with improved
accuracy. We show that the learned policies are robust to external disturbances
and observation noise, and scale to tasks with multiple pushers. Furthermore,
we validate the transferability of the learned policies, trained entirely in
simulation, to a physical robot hardware using the KUKA iiwa robot arm. See our
supplemental video: https://youtu.be/vTdva1mgrk4.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrandis_J/0/1/0/all/0/1&quot;&gt;Juan Del Aguila Ferrandis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moura_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Moura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijayakumar_S/0/1/0/all/0/1&quot;&gt;Sethu Vijayakumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02490">
<title>MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2308.02490</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose MM-Vet, an evaluation benchmark that examines large multimodal
models (LMMs) on complicated multimodal tasks. Recent LMMs have shown various
intriguing abilities, such as solving math problems written on the blackboard,
reasoning about events and celebrities in news images, and explaining visual
jokes. Rapid model advancements pose challenges to evaluation benchmark
development. Problems include: (1) How to systematically structure and evaluate
the complicated multimodal tasks; (2) How to design evaluation metrics that
work well across question and answer types; and (3) How to give model insights
beyond a simple performance ranking. To this end, we present MM-Vet, designed
based on the insight that the intriguing ability to solve complicated tasks is
often achieved by a generalist model being able to integrate different core
vision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and
examines the 16 integrations of interest derived from the capability
combination. For evaluation metrics, we propose an LLM-based evaluator for
open-ended outputs. The evaluator enables the evaluation across different
question types and answer styles, resulting in a unified scoring metric. We
evaluate representative LMMs on MM-Vet, providing insights into the
capabilities of different LMM system paradigms and models. Code and data are
available at https://github.com/yuweihao/MM-Vet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Weihao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhengyuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Linjie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianfeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1&quot;&gt;Kevin Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zicheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinchao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lijuan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.07871">
<title>Mondrian Forest for Data Stream Classification Under Memory Constraints. (arXiv:2205.07871v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.07871</link>
<description rdf:parseType="Literal">&lt;p&gt;Supervised learning algorithms generally assume the availability of enough
memory to store their data model during the training and test phases. However,
in the Internet of Things, this assumption is unrealistic when data comes in
the form of infinite data streams, or when learning algorithms are deployed on
devices with reduced amounts of memory. In this paper, we adapt the online
Mondrian forest classification algorithm to work with memory constraints on
data streams. In particular, we design five out-of-memory strategies to update
Mondrian trees with new data points when the memory limit is reached. Moreover,
we design trimming mechanisms to make Mondrian trees more robust to concept
drifts under memory constraints. We evaluate our algorithms on a variety of
real and simulated datasets, and we conclude with recommendations on their use
in different situations: the Extend Node strategy appears as the best
out-of-memory strategy in all configurations, whereas different trimming
mechanisms should be adopted depending on whether a concept drift is expected.
All our methods are implemented in the OrpailleCC open-source library and are
ready to be used on embedded systems and connected objects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khannouz_M/0/1/0/all/0/1&quot;&gt;Martin Khannouz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glatard_T/0/1/0/all/0/1&quot;&gt;Tristan Glatard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.12850">
<title>SSIVD-Net: A Novel Salient Super Image Classification &amp; Detection Technique for Weaponized Violence. (arXiv:2207.12850v7 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2207.12850</link>
<description rdf:parseType="Literal">&lt;p&gt;Detection of violence and weaponized violence in closed-circuit television
(CCTV) footage requires a comprehensive approach. In this work, we introduce
the \emph{Smart-City CCTV Violence Detection (SCVD)} dataset, specifically
designed to facilitate the learning of weapon distribution in surveillance
videos. To tackle the complexities of analyzing 3D surveillance video for
violence recognition tasks, we propose a novel technique called,
\emph{SSIVD-Net} (\textbf{S}alient-\textbf{S}uper-\textbf{I}mage for
\textbf{V}iolence \textbf{D}etection). Our method reduces 3D video data
complexity, dimensionality, and information loss while improving inference,
performance, and explainability through the use of Salient-Super-Image
representations. Considering the scalability and sustainability requirements of
futuristic smart cities, the authors introduce the \emph{Salient-Classifier}, a
novel architecture combining a kernelized approach with a residual learning
strategy. We evaluate variations of SSIVD-Net and Salient Classifier on our
SCVD dataset and benchmark against state-of-the-art (SOTA) models commonly
employed in violence detection. Our approach exhibits significant improvements
in detecting both weaponized and non-weaponized violence instances. By
advancing the SOTA in violence detection, our work offers a practical and
scalable solution suitable for real-world applications. The proposed
methodology not only addresses the challenges of violence detection in CCTV
footage but also contributes to the understanding of weapon distribution in
smart surveillance. Ultimately, our research findings should enable smarter and
more secure cities, as well as enhance public safety measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aremu_T/0/1/0/all/0/1&quot;&gt;Toluwani Aremu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhiyuan_L/0/1/0/all/0/1&quot;&gt;Li Zhiyuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alameeri_R/0/1/0/all/0/1&quot;&gt;Reem Alameeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Mustaqeem Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saddik_A/0/1/0/all/0/1&quot;&gt;Abdulmotaleb El Saddik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.08549">
<title>Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS). (arXiv:2210.08549v3 [stat.AP] UPDATED)</title>
<link>http://arxiv.org/abs/2210.08549</link>
<description rdf:parseType="Literal">&lt;p&gt;With a rising attention for the issue of PM2.5 or PM0.3, particulate matters
have become not only a potential threat to both the environment and human, but
also a harming existence to instruments onboard International Space Station
(ISS). Our team is aiming to relate various concentration of particulate
matters to magnetic fields, humidity, acceleration, temperature, pressure and
CO2 concentration. Our goal is to establish an early warning system (EWS),
which is able to forecast the levels of particulate matters and provides ample
reaction time for astronauts to protect their instruments in some experiments
or increase the accuracy of the measurements; In addition, the constructed
model can be further developed into a prototype of a remote-sensing smoke alarm
for applications related to fires. In this article, we will implement the
Bi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for
past 90 minutes and predict the levels of particulates which over 2.5
micrometer per 0.1 liter for the next 1 minute, which is classified as an early
warning
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hou_P/0/1/0/all/0/1&quot;&gt;Po-Han Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_W/0/1/0/all/0/1&quot;&gt;Wei-Chih Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hou_H/0/1/0/all/0/1&quot;&gt;Hong-Chun Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yu-Hao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shue_J/0/1/0/all/0/1&quot;&gt;Jih-Hong Shue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.00679">
<title>Formal Controller Synthesis for Markov Jump Linear Systems with Uncertain Dynamics. (arXiv:2212.00679v5 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2212.00679</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated synthesis of provably correct controllers for cyber-physical
systems is crucial for deployment in safety-critical scenarios. However, hybrid
features and stochastic or unknown behaviours make this problem challenging. We
propose a method for synthesising controllers for Markov jump linear systems
(MJLSs), a class of discrete-time models for cyber-physical systems, so that
they certifiably satisfy probabilistic computation tree logic (PCTL) formulae.
An MJLS consists of a finite set of stochastic linear dynamics and discrete
jumps between these dynamics that are governed by a Markov decision process
(MDP). We consider the cases where the transition probabilities of this MDP are
either known up to an interval or completely unknown. Our approach is based on
a finite-state abstraction that captures both the discrete (mode-jumping) and
continuous (stochastic linear) behaviour of the MJLS. We formalise this
abstraction as an interval MDP (iMDP) for which we compute intervals of
transition probabilities using sampling techniques from the so-called &apos;scenario
approach&apos;, resulting in a probabilistically sound approximation. We apply our
method to multiple realistic benchmark problems, in particular, a temperature
control and an aerial vehicle delivery problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rickard_L/0/1/0/all/0/1&quot;&gt;Luke Rickard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Badings_T/0/1/0/all/0/1&quot;&gt;Thom Badings&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Romao_L/0/1/0/all/0/1&quot;&gt;Licio Romao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Abate_A/0/1/0/all/0/1&quot;&gt;Alessandro Abate&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.09196">
<title>Emergent Analogical Reasoning in Large Language Models. (arXiv:2212.09196v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2212.09196</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent advent of large language models has reinvigorated debate over
whether human cognitive capacities might emerge in such generic models given
sufficient training data. Of particular interest is the ability of these models
to reason about novel problems zero-shot, without any direct training. In human
cognition, this capacity is closely tied to an ability to reason by analogy.
Here, we performed a direct comparison between human reasoners and a large
language model (the text-davinci-003 variant of GPT-3) on a range of analogical
tasks, including a non-visual matrix reasoning task based on the rule structure
of Raven&apos;s Standard Progressive Matrices. We found that GPT-3 displayed a
surprisingly strong capacity for abstract pattern induction, matching or even
surpassing human capabilities in most settings; preliminary tests of GPT-4
indicated even better performance. Our results indicate that large language
models such as GPT-3 have acquired an emergent ability to find zero-shot
solutions to a broad range of analogy problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webb_T/0/1/0/all/0/1&quot;&gt;Taylor Webb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holyoak_K/0/1/0/all/0/1&quot;&gt;Keith J. Holyoak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1&quot;&gt;Hongjing Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.01491">
<title>DiSProD: Differentiable Symbolic Propagation of Distributions for Planning. (arXiv:2302.01491v4 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2302.01491</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper introduces DiSProD, an online planner developed for environments
with probabilistic transitions in continuous state and action spaces. DiSProD
builds a symbolic graph that captures the distribution of future trajectories,
conditioned on a given policy, using independence assumptions and approximate
propagation of distributions. The symbolic graph provides a differentiable
representation of the policy&apos;s value, enabling efficient gradient-based
optimization for long-horizon search. The propagation of approximate
distributions can be seen as an aggregation of many trajectories, making it
well-suited for dealing with sparse rewards and stochastic environments. An
extensive experimental evaluation compares DiSProD to state-of-the-art planners
in discrete-time planning and real-time control of robotic systems. The
proposed method improves over existing planners in handling stochastic
environments, sensitivity to search depth, sparsity of rewards, and large
action spaces. Additional real-world experiments demonstrate that DiSProD can
control ground vehicles and surface vessels to successfully navigate around
obstacles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_P/0/1/0/all/0/1&quot;&gt;Palash Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chapagain_A/0/1/0/all/0/1&quot;&gt;Ashutosh Chapagain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Weizhe Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khardon_R/0/1/0/all/0/1&quot;&gt;Roni Khardon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.11070">
<title>Universal Morphology Control via Contextual Modulation. (arXiv:2302.11070v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2302.11070</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning a universal policy across different robot morphologies can
significantly improve learning efficiency and generalization in continuous
control. However, it poses a challenging multi-task reinforcement learning
problem, as the optimal policy may be quite different across robots and
critically depend on the morphology. Existing methods utilize graph neural
networks or transformers to handle heterogeneous state and action spaces across
different morphologies, but pay little attention to the dependency of a robot&apos;s
control policy on its morphology context. In this paper, we propose a
hierarchical architecture to better model this dependency via contextual
modulation, which includes two key submodules: (1) Instead of enforcing hard
parameter sharing across robots, we use hypernetworks to generate
morphology-dependent control parameters; (2) We propose a fixed attention
mechanism that solely depends on the morphology to modulate the interactions
between different limbs in a robot. Experimental results show that our method
not only improves learning performance on a diverse set of training robots, but
also generalizes better to unseen morphologies in a zero-shot fashion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zheng Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beck_J/0/1/0/all/0/1&quot;&gt;Jacob Beck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.11239">
<title>Explainable Contextual Anomaly Detection using Quantile Regression Forests. (arXiv:2302.11239v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.11239</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional anomaly detection methods aim to identify objects that deviate
from most other objects by treating all features equally. In contrast,
contextual anomaly detection methods aim to detect objects that deviate from
other objects within a context of similar objects by dividing the features into
contextual features and behavioral features. In this paper, we develop
connections between dependency-based traditional anomaly detection methods and
contextual anomaly detection methods. Based on resulting insights, we propose a
novel approach to inherently interpretable contextual anomaly detection that
uses Quantile Regression Forests to model dependencies between features.
Extensive experiments on various synthetic and real-world datasets demonstrate
that our method outperforms state-of-the-art anomaly detection methods in
identifying contextual anomalies in terms of accuracy and interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leeuwen_M/0/1/0/all/0/1&quot;&gt;Matthijs van Leeuwen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.00516">
<title>Exploiting Multiple Abstractions in Episodic RL via Reward Shaping. (arXiv:2303.00516v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.00516</link>
<description rdf:parseType="Literal">&lt;p&gt;One major limitation to the applicability of Reinforcement Learning (RL) to
many practical domains is the large number of samples required to learn an
optimal policy. To address this problem and improve learning efficiency, we
consider a linear hierarchy of abstraction layers of the Markov Decision
Process (MDP) underlying the target domain. Each layer is an MDP representing a
coarser model of the one immediately below in the hierarchy. In this work, we
propose a novel form of Reward Shaping where the solution obtained at the
abstract level is used to offer rewards to the more concrete MDP, in such a way
that the abstract solution guides the learning in the more complex domain. In
contrast with other works in Hierarchical RL, our technique has few
requirements in the design of the abstract models and it is also tolerant to
modeling errors, thus making the proposed approach practical. We formally
analyze the relationship between the abstract models and the exploration
heuristic induced in the lower-level domain. Moreover, we prove that the method
guarantees optimal convergence and we demonstrate its effectiveness
experimentally.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cipollone_R/0/1/0/all/0/1&quot;&gt;Roberto Cipollone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giacomo_G/0/1/0/all/0/1&quot;&gt;Giuseppe De Giacomo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Favorito_M/0/1/0/all/0/1&quot;&gt;Marco Favorito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iocchi_L/0/1/0/all/0/1&quot;&gt;Luca Iocchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patrizi_F/0/1/0/all/0/1&quot;&gt;Fabio Patrizi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.06813">
<title>Meaningful human command: Advance control directives as a method to enable moral and legal responsibility for autonomous weapons systems. (arXiv:2303.06813v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2303.06813</link>
<description rdf:parseType="Literal">&lt;p&gt;21st Century war is increasing in speed, with conventional forces combined
with massed use of autonomous systems and human-machine integration. However, a
significant challenge is how humans can ensure moral and legal responsibility
for systems operating outside of normal temporal parameters. This chapter
considers whether humans can stand outside of real time and authorise actions
for autonomous systems by the prior establishment of a contract, for actions to
occur in a future context particularly in faster than real time or in very slow
operations where human consciousness and concentration could not remain well
informed. The medical legal precdent found in &apos;advance care directives&apos;
suggests how the time-consuming, deliberative process required for
accountability and responsibility of weapons systems may be achievable outside
real time captured in an &apos;advance control driective&apos; (ACD). The chapter
proposes &apos;autonomy command&apos; scaffolded and legitimised through the construction
of ACD ahead of the deployment of autonomous systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devitt_S/0/1/0/all/0/1&quot;&gt;Susannah Kate Devitt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.11098">
<title>A closer look at the training dynamics of knowledge distillation. (arXiv:2303.11098v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.11098</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we revisit the efficacy of knowledge distillation as a function
matching and metric learning problem. In doing so we verify three important
design decisions, namely the normalisation, soft maximum function, and
projection layers as key ingredients. We theoretically show that the projector
implicitly encodes information on past examples, enabling relational gradients
for the student. We then show that the normalisation of representations is
tightly coupled with the training dynamics of this projector, which can have a
large impact on the students performance. Finally, we show that a simple soft
maximum function can be used to address any significant capacity gap problems.
Experimental results on various benchmark datasets demonstrate that using these
insights can lead to superior or comparable performance to state-of-the-art
knowledge distillation techniques, despite being much more computationally
efficient. In particular, we obtain these results across image classification
(CIFAR100 and ImageNet), object detection (COCO2017), and on more difficult
distillation objectives, such as training data efficient transformers, whereby
we attain a 77.2% top-1 accuracy with DeiT-Ti on ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miles_R/0/1/0/all/0/1&quot;&gt;Roy Miles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikolajczyk_K/0/1/0/all/0/1&quot;&gt;Krystian Mikolajczyk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.12336">
<title>A multi-functional simulation platform for on-demand ride service operations. (arXiv:2303.12336v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2303.12336</link>
<description rdf:parseType="Literal">&lt;p&gt;On-demand ride services or ride-sourcing services have been experiencing fast
development in the past decade. Various mathematical models and optimization
algorithms have been developed to help ride-sourcing platforms design
operational strategies with higher efficiency. However, due to cost and
reliability issues (implementing an immature algorithm for real operations may
result in system turbulence), it is commonly infeasible to validate these
models and train/test these optimization algorithms within real-world ride
sourcing platforms. Acting as a useful test bed, a simulation platform for
ride-sourcing systems will be very important to conduct algorithm
training/testing or model validation through trails and errors. While previous
studies have established a variety of simulators for their own tasks, it lacks
a fair and public platform for comparing the models or algorithms proposed by
different researchers. In addition, the existing simulators still face many
challenges, ranging from their closeness to real environments of ride-sourcing
systems, to the completeness of different tasks they can implement. To address
the challenges, we propose a novel multi-functional and open-sourced simulation
platform for ride-sourcing systems, which can simulate the behaviors and
movements of various agents on a real transportation network. It provides a few
accessible portals for users to train and test various optimization algorithms,
especially reinforcement learning algorithms, for a variety of tasks, including
on-demand matching, idle vehicle repositioning, and dynamic pricing. In
addition, it can be used to test how well the theoretical models approximate
the simulated outcomes. Evaluated on real-world data based experiments, the
simulator is demonstrated to be an efficient and effective test bed for various
tasks related to on-demand ride service operations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Siyuan Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Taijie Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuhao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_J/0/1/0/all/0/1&quot;&gt;Jintao Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zhengfei Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hai Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.12745">
<title>Audio-Visual Deception Detection: DOLOS Dataset and Parameter-Efficient Crossmodal Learning. (arXiv:2303.12745v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.12745</link>
<description rdf:parseType="Literal">&lt;p&gt;Deception detection in conversations is a challenging yet important task,
having pivotal applications in many fields such as credibility assessment in
business, multimedia anti-frauds, and custom security. Despite this, deception
detection research is hindered by the lack of high-quality deception datasets,
as well as the difficulties of learning multimodal features effectively. To
address this issue, we introduce DOLOS\footnote {The name ``DOLOS&quot; comes from
Greek mythology.}, the largest gameshow deception detection dataset with rich
deceptive conversations. DOLOS includes 1,675 video clips featuring 213
subjects, and it has been labeled with audio-visual feature annotations. We
provide train-test, duration, and gender protocols to investigate the impact of
different factors. We benchmark our dataset on previously proposed deception
detection approaches. To further improve the performance by fine-tuning fewer
parameters, we propose Parameter-Efficient Crossmodal Learning (PECL), where a
Uniform Temporal Adapter (UT-Adapter) explores temporal attention in
transformer-based architectures, and a crossmodal fusion module, Plug-in
Audio-Visual Fusion (PAVF), combines crossmodal information from audio-visual
features. Based on the rich fine-grained audio-visual annotations on DOLOS, we
also exploit multi-task learning to enhance performance by concurrently
predicting deception and audio-visual features. Experimental results
demonstrate the desired quality of the DOLOS dataset and the effectiveness of
the PECL. The DOLOS dataset and the source codes are available at
https://github.com/NMS05/Audio-Visual-Deception-Detection-DOLOS-Dataset-and-Parameter-Efficient-Crossmodal-Learning/tree/main.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xiaobao Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Selvaraj_N/0/1/0/all/0/1&quot;&gt;Nithish Muthuchamy Selvaraj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zitong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_A/0/1/0/all/0/1&quot;&gt;Adams Wai-Kin Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1&quot;&gt;Bingquan Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kot_A/0/1/0/all/0/1&quot;&gt;Alex Kot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.13035">
<title>SPeC: A Soft Prompt-Based Calibration on Performance Variability of Large Language Model in Clinical Notes Summarization. (arXiv:2303.13035v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2303.13035</link>
<description rdf:parseType="Literal">&lt;p&gt;Electronic health records (EHRs) store an extensive array of patient
information, encompassing medical histories, diagnoses, treatments, and test
outcomes. These records are crucial for enabling healthcare providers to make
well-informed decisions regarding patient care. Summarizing clinical notes
further assists healthcare professionals in pinpointing potential health risks
and making better-informed decisions. This process contributes to reducing
errors and enhancing patient outcomes by ensuring providers have access to the
most pertinent and current patient data. Recent research has shown that
incorporating prompts with large language models (LLMs) substantially boosts
the efficacy of summarization tasks. However, we show that this approach also
leads to increased output variance, resulting in notably divergent outputs even
when prompts share similar meanings. To tackle this challenge, we introduce a
model-agnostic Soft Prompt-Based Calibration (SPeC) pipeline that employs soft
prompts to diminish variance while preserving the advantages of prompt-based
summarization. Experimental findings on multiple clinical note tasks and LLMs
indicate that our method not only bolsters performance but also effectively
curbs variance for various LLMs, providing a more uniform and dependable
solution for summarizing vital medical information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1&quot;&gt;Yu-Neng Chuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1&quot;&gt;Ruixiang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1&quot;&gt;Xiaoqian Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.10224">
<title>Multi-view Vision-Prompt Fusion Network: Can 2D Pre-trained Model Boost 3D Point Cloud Data-scarce Learning?. (arXiv:2304.10224v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.10224</link>
<description rdf:parseType="Literal">&lt;p&gt;Point cloud based 3D deep model has wide applications in many applications
such as autonomous driving, house robot, and so on. Inspired by the recent
prompt learning in natural language processing, this work proposes a novel
Multi-view Vision-Prompt Fusion Network (MvNet) for few-shot 3D point cloud
classification. MvNet investigates the possibility of leveraging the
off-the-shelf 2D pre-trained models to achieve the few-shot classification,
which can alleviate the over-dependence issue of the existing baseline models
towards the large-scale annotated 3D point cloud data. Specifically, MvNet
first encodes a 3D point cloud into multi-view image features for a number of
different views. Then, a novel multi-view prompt fusion module is developed to
effectively fuse information from different views to bridge the gap between 3D
point cloud data and 2D pre-trained models. A set of 2D image prompts can then
be derived to better describe the suitable prior knowledge for a large-scale
pre-trained image model for few-shot 3D point cloud classification. Extensive
experiments on ModelNet, ScanObjectNN, and ShapeNet datasets demonstrate that
MvNet achieves new state-of-the-art performance for 3D few-shot point cloud
image classification. The source code of this work will be available soon.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1&quot;&gt;Haoyang Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Baopu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06710">
<title>Null-text Guidance in Diffusion Models is Secretly a Cartoon-style Creator. (arXiv:2305.06710v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06710</link>
<description rdf:parseType="Literal">&lt;p&gt;Classifier-free guidance is an effective sampling technique in diffusion
models that has been widely adopted. The main idea is to extrapolate the model
in the direction of text guidance and away from null-text guidance. In this
paper, we demonstrate that null-text guidance in diffusion models is secretly a
cartoon-style creator, i.e., the generated images can be efficiently
transformed into cartoons by simply perturbing the null-text guidance.
Specifically, we proposed two disturbance methods, i.e., Rollback disturbance
(Back-D) and Image disturbance (Image-D), to construct misalignment between the
noisy images used for predicting null-text guidance and text guidance
(subsequently referred to as \textbf{null-text noisy image} and \textbf{text
noisy image} respectively) in the sampling process. Back-D achieves
cartoonization by altering the noise level of null-text noisy image via
replacing $x_t$ with $x_{t+\Delta t}$. Image-D, alternatively, produces
high-fidelity, diverse cartoons by defining $x_t$ as a clean input image, which
further improves the incorporation of finer image details. Through
comprehensive experiments, we delved into the principle of noise disturbing for
null-text and uncovered that the efficacy of disturbance depends on the
correlation between the null-text noisy image and the source image. Moreover,
our proposed techniques, which can generate cartoon images and cartoonize
specific ones, are training-free and easily integrated as a plug-and-play
component in any classifier-free guided diffusion model. Project page is
available at \url{https://nulltextforcartoon.github.io/}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jing Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1&quot;&gt;Heliang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chaoyue Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_L/0/1/0/all/0/1&quot;&gt;Long Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wanrong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1&quot;&gt;Wenjing Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19148">
<title>Mitigating Label Biases for In-context Learning. (arXiv:2305.19148v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19148</link>
<description rdf:parseType="Literal">&lt;p&gt;Various design settings for in-context learning (ICL), such as the choice and
order of the in-context examples, can bias a model toward a particular
prediction without being reflective of an understanding of the task. While many
studies discuss these design choices, there have been few systematic
investigations into categorizing them and mitigating their impact. In this
work, we define a typology for three types of label biases in ICL for text
classification: vanilla-label bias, context-label bias, and domain-label bias
(which we conceptualize and detect for the first time).
&lt;/p&gt;
&lt;p&gt;Our analysis demonstrates that prior label bias calibration methods fall
short of addressing all three types of biases. Specifically, domain-label bias
restricts LLMs to random-level performance on many tasks regardless of the
choice of in-context examples. To mitigate the effect of these biases, we
propose a simple bias calibration method that estimates a language model&apos;s
label bias using random in-domain words from the task corpus. After controlling
for this estimated bias when making predictions, our novel domain-context
calibration significantly improves the ICL performance of GPT-J and GPT-3 on a
wide range of tasks. The gain is substantial on tasks with large domain-label
bias (up to 37% in Macro-F1). Furthermore, our results generalize to models
with different scales, pretraining methods, and manually-designed task
instructions, showing the prevalence of label biases in ICL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Y/0/1/0/all/0/1&quot;&gt;Yu Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1&quot;&gt;Yifan Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zeming Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1&quot;&gt;Antoine Bosselut&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19860">
<title>A Survey on Large Language Models for Recommendation. (arXiv:2305.19860v3 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19860</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have emerged as powerful tools in the field of
Natural Language Processing (NLP) and have recently gained significant
attention in the domain of Recommendation Systems (RS). These models, trained
on massive amounts of data using self-supervised learning, have demonstrated
remarkable success in learning universal representations and have the potential
to enhance various aspects of recommendation systems by some effective transfer
techniques such as fine-tuning and prompt tuning, and so on. The crucial aspect
of harnessing the power of language models in enhancing recommendation quality
is the utilization of their high-quality representations of textual features
and their extensive coverage of external knowledge to establish correlations
between items and users. To provide a comprehensive understanding of the
existing LLM-based recommendation systems, this survey presents a taxonomy that
categorizes these models into two major paradigms, respectively Discriminative
LLM for Recommendation (DLLM4Rec) and Generative LLM for Recommendation
(GLLM4Rec), with the latter being systematically sorted out for the first time.
Furthermore, we systematically review and analyze existing LLM-based
recommendation systems within each paradigm, providing insights into their
methodologies, techniques, and performance. Additionally, we identify key
challenges and several valuable findings to provide researchers and
practitioners with inspiration. We have also created a GitHub repository to
index relevant papers on LLMs for recommendation,
https://github.com/WLiK/LLM4Rec.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Likang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zhi Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_Z/0/1/0/all/0/1&quot;&gt;Zhaopeng Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1&quot;&gt;Hongchao Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1&quot;&gt;Tingjia Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1&quot;&gt;Chuan Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Chen Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hengshu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Hui Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1&quot;&gt;Enhong Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.00393">
<title>Teacher Agent: A Knowledge Distillation-Free Framework for Rehearsal-based Video Incremental Learning. (arXiv:2306.00393v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.00393</link>
<description rdf:parseType="Literal">&lt;p&gt;Rehearsal-based video incremental learning often employs knowledge
distillation to mitigate catastrophic forgetting of previously learned data.
However, this method faces two major challenges for video task: substantial
computing resources from loading teacher model and limited replay capability
from performance-limited teacher model. To address these problems, we first
propose a knowledge distillation-free framework for rehearsal-based video
incremental learning called \textit{Teacher Agent}. Instead of loading
parameter-heavy teacher networks, we introduce an agent generator that is
either parameter-free or uses only a few parameters to obtain accurate and
reliable soft labels. This method not only greatly reduces the computing
requirement but also circumvents the problem of knowledge misleading caused by
inaccurate predictions of the teacher model. Moreover, we put forward a
self-correction loss which provides an effective regularization signal for the
review of old knowledge, which in turn alleviates the problem of catastrophic
forgetting. Further, to ensure that the samples in the memory buffer are
memory-efficient and representative, we introduce a unified sampler for
rehearsal-based video incremental learning to mine fixed-length key video
frames. Interestingly, based on the proposed strategies, the network exhibits a
high level of robustness against spatial resolution reduction when compared to
the baseline. Extensive experiments demonstrate the advantages of our method,
yielding significant performance improvements while utilizing only half the
spatial resolution of video clips as network inputs in the incremental phases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shengqin Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1&quot;&gt;Yaoyu Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haokui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qingshan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1&quot;&gt;Yuankai Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Peng Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.06548">
<title>Inductive reasoning in humans and large language models. (arXiv:2306.06548v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.06548</link>
<description rdf:parseType="Literal">&lt;p&gt;The impressive recent performance of large language models has led many to
wonder to what extent they can serve as models of general intelligence or are
similar to human cognition. We address this issue by applying GPT-3.5 and GPT-4
to a classic problem in human inductive reasoning known as property induction.
Over two experiments, we elicit human judgments on a range of property
induction tasks spanning multiple domains. Although GPT-3.5 struggles to
capture many aspects of human behaviour, GPT-4 is much more successful: for the
most part, its performance qualitatively matches that of humans, and the only
notable exception is its failure to capture the phenomenon of premise
non-monotonicity. Our work demonstrates that property induction allows for
interesting comparisons between human and machine intelligence and provides two
large datasets that can serve as benchmarks for future work in this vein.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Simon J. Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ransom_K/0/1/0/all/0/1&quot;&gt;Keith Ransom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perfors_A/0/1/0/all/0/1&quot;&gt;Andrew Perfors&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kemp_C/0/1/0/all/0/1&quot;&gt;Charles Kemp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00925">
<title>Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution. (arXiv:2307.00925v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.00925</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic similarity measures are widely used in natural language processing
to catalyze various computer-related tasks. However, no single semantic
similarity measure is the most appropriate for all tasks, and researchers often
use ensemble strategies to ensure performance. This research work proposes a
method for automatically designing semantic similarity ensembles. In fact, our
proposed method uses grammatical evolution, for the first time, to
automatically select and aggregate measures from a pool of candidates to create
an ensemble that maximizes correlation to human judgment. The method is
evaluated on several benchmark datasets and compared to state-of-the-art
ensembles, showing that it can significantly improve similarity assessment
accuracy and outperform existing methods in some cases. As a result, our
research demonstrates the potential of using grammatical evolution to
automatically compare text and prove the benefits of using ensembles for
semantic similarity tasks. The source code that illustrates our approach can be
downloaded from https://github.com/jorge-martinez-gil/sesige.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinez_Gil_J/0/1/0/all/0/1&quot;&gt;Jorge Martinez-Gil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.13892">
<title>AI4GCC-Team -- Below Sea Level: Score and Real World Relevance. (arXiv:2307.13892v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/2307.13892</link>
<description rdf:parseType="Literal">&lt;p&gt;As our submission for track three of the AI for Global Climate Cooperation
(AI4GCC) competition, we propose a negotiation protocol for use in the RICE-N
climate-economic simulation. Our proposal seeks to address the challenges of
carbon leakage through methods inspired by the Carbon Border Adjustment
Mechanism (CBAM) and Climate Clubs (CC). We demonstrate the effectiveness of
our approach by comparing simulated outcomes to representative concentration
pathways (RCP) and shared socioeconomic pathways (SSP). Our protocol results in
a temperature rise comparable to RCP 3.4/4.5 and SSP 2. Furthermore, we provide
an analysis of our protocol&apos;s World Trade Organization compliance,
administrative and political feasibility, and ethical concerns. We recognize
that our proposal risks hurting the least developing countries, and we suggest
specific corrective measures to avoid exacerbating existing inequalities, such
as technology sharing and wealth redistribution. Future research should improve
the RICE-N tariff mechanism and implement actions allowing for the
aforementioned corrective measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wozny_P/0/1/0/all/0/1&quot;&gt;Phillip Wozny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renting_B/0/1/0/all/0/1&quot;&gt;Bram Renting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loftin_R/0/1/0/all/0/1&quot;&gt;Robert Loftin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wieners_C/0/1/0/all/0/1&quot;&gt;Claudia Wieners&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acar_E/0/1/0/all/0/1&quot;&gt;Erman Acar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.16104">
<title>AI Increases Global Access to Reliable Flood Forecasts. (arXiv:2307.16104v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.16104</link>
<description rdf:parseType="Literal">&lt;p&gt;Floods are one of the most common and impactful natural disasters, with a
disproportionate impact in developing countries that often lack dense
streamflow monitoring networks. Accurate and timely warnings are critical for
mitigating flood risks, but accurate hydrological simulation models typically
must be calibrated to long data records in each watershed where they are
applied. We developed an Artificial Intelligence (AI) model to predict extreme
hydrological events at timescales up to 7 days in advance. This model
significantly outperforms current state of the art global hydrology models (the
Copernicus Emergency Management Service Global Flood Awareness System) across
all continents, lead times, and return periods. AI is especially effective at
forecasting in ungauged basins, which is important because only a few percent
of the world&apos;s watersheds have stream gauges, with a disproportionate number of
ungauged basins in developing countries that are especially vulnerable to the
human impacts of flooding. We produce forecasts of extreme events in South
America and Africa that achieve reliability approaching the current state of
the art in Europe and North America, and we achieve reliability at between 4
and 6-day lead times that are similar to current state of the art nowcasts
(0-day lead time). Additionally, we achieve accuracies over 10-year return
period events that are similar to current accuracies over 2-year return period
events, meaning that AI can provide warnings earlier and over larger and more
impactful events. The model that we develop in this paper has been incorporated
into an operational early warning system that produces publicly available (free
and open) forecasts in real time in over 80 countries. This work using AI and
open data highlights a need for increasing the availability of hydrological
data to continue to improve global access to reliable flood warnings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nearing_G/0/1/0/all/0/1&quot;&gt;Grey Nearing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_D/0/1/0/all/0/1&quot;&gt;Deborah Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dube_V/0/1/0/all/0/1&quot;&gt;Vusumuzi Dube&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gauch_M/0/1/0/all/0/1&quot;&gt;Martin Gauch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilon_O/0/1/0/all/0/1&quot;&gt;Oren Gilon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harrigan_S/0/1/0/all/0/1&quot;&gt;Shaun Harrigan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassidim_A/0/1/0/all/0/1&quot;&gt;Avinatan Hassidim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kratzert_F/0/1/0/all/0/1&quot;&gt;Frederik Kratzert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metzger_A/0/1/0/all/0/1&quot;&gt;Asher Metzger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nevo_S/0/1/0/all/0/1&quot;&gt;Sella Nevo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pappenberger_F/0/1/0/all/0/1&quot;&gt;Florian Pappenberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prudhomme_C/0/1/0/all/0/1&quot;&gt;Christel Prudhomme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shalev_G/0/1/0/all/0/1&quot;&gt;Guy Shalev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shenzis_S/0/1/0/all/0/1&quot;&gt;Shlomo Shenzis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tekalign_T/0/1/0/all/0/1&quot;&gt;Tadele Tekalign&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weitzner_D/0/1/0/all/0/1&quot;&gt;Dana Weitzner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matias_Y/0/1/0/all/0/1&quot;&gt;Yoss Matias&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>