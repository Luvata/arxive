<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2024-01-21T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10238" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10241" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10247" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10253" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10254" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10255" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10257" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10265" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10266" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10270" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10278" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10282" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10283" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10284" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10285" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10287" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10288" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10289" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10290" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10293" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10294" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10297" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10298" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10299" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10300" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10304" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10305" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10310" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10313" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10314" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10316" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10334" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10337" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10338" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10354" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10355" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10360" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10361" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10364" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10370" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10371" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10373" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10375" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10383" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10385" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10386" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10393" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10394" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10396" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10419" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10432" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10442" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10446" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10447" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10451" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10458" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10460" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10463" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10467" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10474" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10478" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10490" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10495" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10510" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10518" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10522" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10529" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10535" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10541" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10547" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10549" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10566" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10586" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10590" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10603" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10620" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10632" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10637" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10643" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10646" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10648" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10652" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10653" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10657" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10685" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10686" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10689" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10690" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10700" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10710" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10724" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10726" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10745" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10746" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10747" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10748" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10749" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10753" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10754" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10765" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10790" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10791" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10794" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10799" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10800" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10805" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10809" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10811" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10816" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10819" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10825" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10831" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10839" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10840" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10841" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10843" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10844" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10859" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10862" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10874" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10886" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.01243" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.06826" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.10891" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.05158" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2203.16031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.05359" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.14102" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.01409" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.07626" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.02672" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.13350" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.00219" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.01521" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.09726" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.06120" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.13854" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.02506" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.02901" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.03183" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.15954" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.17046" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.11171" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.03077" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14402" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.00119" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.10822" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.17248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.12871" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.04452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.07988" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11623" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.14393" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01202" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03298" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03320" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04965" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.05492" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.12955" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13384" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.03976" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.07202" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.11809" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.12399" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.15497" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.18426" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.00067" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.01185" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05225" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08010" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10401" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.13110" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.13486" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.15591" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00110" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.04336" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.07494" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.07961" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.08169" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.08216" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.08897" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.09691" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.09796" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.09902" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.10191" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2401.10238">
<title>Interplay between Cryptocurrency Transactions and Online Financial Forums. (arXiv:2401.10238v1 [q-fin.GN])</title>
<link>http://arxiv.org/abs/2401.10238</link>
<description rdf:parseType="Literal">&lt;p&gt;Cryptocurrencies are a type of digital money meant to provide security and
anonymity while using cryptography techniques. Although cryptocurrencies
represent a breakthrough and provide some important benefits, their usage poses
some risks that are a result of the lack of supervising institutions and
transparency. Because disinformation and volatility is discouraging for
personal investors, cryptocurrencies emerged hand-in-hand with the
proliferation of online users&apos; communities and forums as places to share
information that can alleviate users&apos; mistrust. This research focuses on the
study of the interplay between these cryptocurrency forums and fluctuations in
cryptocurrency values. In particular, the most popular cryptocurrency Bitcoin
(BTC) and a related active discussion community, Bitcointalk, are analyzed.
This study shows that the activity of Bitcointalk forum keeps a direct
relationship with the trend in the values of BTC, therefore analysis of this
interaction would be a perfect base to support personal investments in a
non-regulated market and, to confirm whether cryptocurrency forums show
evidences to detect abnormal behaviors in BTC values as well as to predict or
estimate these values. The experiment highlights that forum data can explain
specific events in the financial field. It also underlines the relevance of
quotes (regular mechanism to response a post) at periods: (1) when there is a
high concentration of posts around certain topics; (2) when peaks in the BTC
price are observed; and, (3) when the BTC price gradually shifts downwards and
users intend to sell.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Vilas_A/0/1/0/all/0/1&quot;&gt;Ana Fern&amp;#xe1;ndez Vilas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Redondo_R/0/1/0/all/0/1&quot;&gt;Rebeca P. D&amp;#xed;az Redondo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Cancela_D/0/1/0/all/0/1&quot;&gt;Daniel Couto Cancela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Pazos_A/0/1/0/all/0/1&quot;&gt;Alejandro Torrado Pazos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10241">
<title>Zero Bubble Pipeline Parallelism. (arXiv:2401.10241v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2401.10241</link>
<description rdf:parseType="Literal">&lt;p&gt;Pipeline parallelism is one of the key components for large-scale distributed
training, yet its efficiency suffers from pipeline bubbles which were deemed
inevitable. In this work, we introduce a scheduling strategy that, to our
knowledge, is the first to successfully achieve zero pipeline bubbles under
synchronous training semantics. The key idea behind this improvement is to
split the backward computation into two parts, one that computes gradient for
the input and another that computes for the parameters. Based on this idea, we
handcraft novel pipeline schedules that significantly outperform the baseline
methods. We further develop an algorithm that automatically finds an optimal
schedule based on specific model configuration and memory limit. Additionally,
to truly achieve zero bubble, we introduce a novel technique to bypass
synchronizations during the optimizer step. Experimental evaluations show that
our method outperforms the 1F1B schedule up to 23% in throughput under a
similar memory limit. This number can be further pushed to 31% when the memory
constraint is relaxed. We believe our results mark a major step forward in
harnessing the true potential of pipeline parallelism. We open sourced our
implementation based on the popular Megatron-LM repository on
https://github.com/sail-sg/zero-bubble-pipeline-parallelism.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_P/0/1/0/all/0/1&quot;&gt;Penghui Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1&quot;&gt;Xinyi Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1&quot;&gt;Guangxing Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1&quot;&gt;Min Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10247">
<title>Resolution Chromatography of Diffusion Models. (arXiv:2401.10247v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10247</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models generate high-resolution images through iterative stochastic
processes. In particular, the denoising method is one of the most popular
approaches that predicts the noise in samples and denoises it at each time
step. It has been commonly observed that the resolution of generated samples
changes over time, starting off blurry and coarse, and becoming sharper and
finer. In this paper, we introduce &quot;resolution chromatography&quot; that indicates
the signal generation rate of each resolution, which is very helpful concept to
mathematically explain this coarse-to-fine behavior in generation process, to
understand the role of noise schedule, and to design time-dependent modulation.
Using resolution chromatography, we determine which resolution level becomes
dominant at a specific time step, and experimentally verify our theory with
text-to-image diffusion models. We also propose some direct applications
utilizing the concept: upscaling pre-trained models to higher resolutions and
time-dependent prompt composing. Our theory not only enables a better
understanding of numerous pre-existing techniques for manipulating image
generation, but also suggests the potential for designing better noise
schedules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1&quot;&gt;Juno Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1&quot;&gt;Yong-Hyun Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1&quot;&gt;Junghyo Jo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10253">
<title>Hybrid-Task Meta-Learning: A Graph Neural Network Approach for Scalable and Transferable Bandwidth Allocation. (arXiv:2401.10253v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2401.10253</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we develop a deep learning-based bandwidth allocation policy
that is: 1) scalable with the number of users and 2) transferable to different
communication scenarios, such as non-stationary wireless channels, different
quality-of-service (QoS) requirements, and dynamically available resources. To
support scalability, the bandwidth allocation policy is represented by a graph
neural network (GNN), with which the number of training parameters does not
change with the number of users. To enable the generalization of the GNN, we
develop a hybrid-task meta-learning (HML) algorithm that trains the initial
parameters of the GNN with different communication scenarios during
meta-training. Next, during meta-testing, a few samples are used to fine-tune
the GNN with unseen communication scenarios. Simulation results demonstrate
that our HML approach can improve the initial performance by $8.79\%$, and
sampling efficiency by $73\%$, compared with existing benchmarks. After
fine-tuning, our near-optimal GNN-based policy can achieve close to the same
reward with much lower inference complexity compared to the optimal policy
obtained using iterative optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_X/0/1/0/all/0/1&quot;&gt;Xin Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+She_C/0/1/0/all/0/1&quot;&gt;Changyang She&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeoh_P/0/1/0/all/0/1&quot;&gt;Phee Lep Yeoh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yuhong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vucetic_B/0/1/0/all/0/1&quot;&gt;Branka Vucetic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yonghui Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10254">
<title>Beyond the Frame: Single and mutilple video summarization method with user-defined length. (arXiv:2401.10254v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10254</link>
<description rdf:parseType="Literal">&lt;p&gt;Video smmarization is a crucial method to reduce the time of videos which
reduces the spent time to watch/review a long video. This apporach has became
more important as the amount of publisehed video is increasing everyday. A
single or multiple videos can be summarized into a relatively short video using
various of techniques from multimodal audio-visual techniques, to natural
language processing approaches. Audiovisual techniques may be used to recognize
significant visual events and pick the most important parts, while NLP
techniques can be used to evaluate the audio transcript and extract the main
sentences (timestamps) and corresponding video frames from the original video.
Another approach is to use the best of both domain. Meaning that we can use
audio-visual cues as well as video transcript to extract and summarize the
video. In this paper, we combine a variety of NLP techniques (extractive and
contect-based summarizers) with video processing techniques to convert a long
video into a single relatively short video. We design this toll in a way that
user can specify the relative length of the summarized video. We have also
explored ways of summarizing and concatenating multiple videos into a single
short video which will help having most important concepts from the same
subject in a single short video. Out approach shows that video summarizing is a
difficult but significant work, with substantial potential for further research
and development, and it is possible thanks to the development of NLP models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalkhorani_V/0/1/0/all/0/1&quot;&gt;Vahid Ahmadi Kalkhorani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qingquan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1&quot;&gt;Guanqun Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1&quot;&gt;Ting Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10255">
<title>Nowcasting Madagascar&apos;s real GDP using machine learning algorithms. (arXiv:2401.10255v1 [econ.GN])</title>
<link>http://arxiv.org/abs/2401.10255</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the predictive power of different machine learning algorithms
to nowcast Madagascar&apos;s gross domestic product (GDP). We trained popular
regression models, including linear regularized regression (Ridge, Lasso,
Elastic-net), dimensionality reduction model (principal component regression),
k-nearest neighbors algorithm (k-NN regression), support vector regression
(linear SVR), and tree-based ensemble models (Random forest and XGBoost
regressions), on 10 Malagasy quarterly macroeconomic leading indicators over
the period 2007Q1--2022Q4, and we used simple econometric models as a
benchmark. We measured the nowcast accuracy of each model by calculating the
root mean square error (RMSE), mean absolute error (MAE), and mean absolute
percentage error (MAPE). Our findings reveal that the Ensemble Model, formed by
aggregating individual predictions, consistently outperforms traditional
econometric models. We conclude that machine learning models can deliver more
accurate and timely nowcasts of Malagasy economic performance and provide
policymakers with additional guidance for data-driven decision making.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Ramaharo_F/0/1/0/all/0/1&quot;&gt;Franck Ramaharo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Rasolofomanana_G/0/1/0/all/0/1&quot;&gt;Gerzhino Rasolofomanana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10257">
<title>Curriculum Design Helps Spiking Neural Networks to Classify Time Series. (arXiv:2401.10257v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2401.10257</link>
<description rdf:parseType="Literal">&lt;p&gt;Spiking Neural Networks (SNNs) have a greater potential for modeling time
series data than Artificial Neural Networks (ANNs), due to their inherent
neuron dynamics and low energy consumption. However, it is difficult to
demonstrate their superiority in classification accuracy, because current
efforts mainly focus on designing better network structures. In this work,
enlighten by brain-inspired science, we find that, not only the structure but
also the learning process should be human-like. To achieve this, we investigate
the power of Curriculum Learning (CL) on SNNs by designing a novel method named
CSNN with two theoretically guaranteed mechanisms: The active-to-dormant
training order makes the curriculum similar to that of human learning and
suitable for spiking neurons; The value-based regional encoding makes the
neuron activity to mimic the brain memory when learning sequential data.
Experiments on multiple time series sources including simulated, sensor,
motion, and healthcare demonstrate that CL has a more positive effect on SNNs
than ANNs with about twice the accuracy change, and CSNN can increase about 3%
SNNs&apos; accuracy by improving network sparsity, neuron firing status, anti-noise
ability, and convergence speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1&quot;&gt;Chenxi Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongyan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1&quot;&gt;Moxian Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Can_D/0/1/0/all/0/1&quot;&gt;Derun Can&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1&quot;&gt;Shenda Hong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10262">
<title>Null Space Properties of Neural Networks with Applications to Image Steganography. (arXiv:2401.10262v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10262</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the null space properties of neural networks. We extend
the null space definition from linear to nonlinear maps and discuss the
presence of a null space in neural networks. The null space of a given neural
network can tell us the part of the input data that makes no contribution to
the final prediction so that we can use it to trick the neural network. This
reveals an inherent weakness in neural networks that can be exploited. One
application described here leads to a method of image steganography. Through
experiments on image datasets such as MNIST, we show that we can use null space
components to force the neural network to choose a selected hidden image class,
even though the overall image can be made to look like a completely different
image. We conclude by showing comparisons between what a human viewer would
see, and the part of the image that the neural network is actually using to
make predictions and, hence, show that what the neural network ``sees&apos;&apos; is
completely different than what we would expect.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Short_K/0/1/0/all/0/1&quot;&gt;Kevin M. Short&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10265">
<title>The Best Time for an Update: Risk-Sensitive Minimization of Age-Based Metrics. (arXiv:2401.10265v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2401.10265</link>
<description rdf:parseType="Literal">&lt;p&gt;Popular methods to quantify transmitted data quality are the Age of
Information (AoI), the Query Age of Information (QAoI), and the Age of
Incorrect Information (AoII). We consider these metrics in a point-to-point
wireless communication system, where the transmitter monitors a process and
sends status updates to a receiver. The challenge is to decide on the best time
for an update, balancing the transmission energy and the age-based metric at
the receiver. Due to the inherent risk of high age-based metric values causing
complications such as unstable system states, we introduce the new concept of
risky states to denote states with high age-based metric. We use this new
notion of risky states to quantify and minimize this risk of experiencing high
age-based metrics by directly deriving the frequency of risky states as a novel
risk-metric. Building on this foundation, we introduce two risk-sensitive
strategies for AoI, QAoI and AoII. The first strategy uses system knowledge,
i.e., channel quality and packet arrival probability, to find an optimal
strategy that transmits when the age-based metric exceeds a tunable threshold.
A lower threshold leads to higher risk-sensitivity. The second strategy uses an
enhanced Q-learning approach and balances the age-based metric, the
transmission energy and the frequency of risky states without requiring
knowledge about the system. Numerical results affirm our risk-sensitive
strategies&apos; high effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sombre_W/0/1/0/all/0/1&quot;&gt;Wanja de Sombre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortiz_A/0/1/0/all/0/1&quot;&gt;Andrea Ortiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aurzada_F/0/1/0/all/0/1&quot;&gt;Frank Aurzada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klein_A/0/1/0/all/0/1&quot;&gt;Anja Klein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10266">
<title>Intelligent Condition Monitoring of Industrial Plants: An Overview of Methodologies and Uncertainty Management Strategies. (arXiv:2401.10266v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10266</link>
<description rdf:parseType="Literal">&lt;p&gt;Condition monitoring plays a significant role in the safety and reliability
of modern industrial systems. Artificial intelligence (AI) approaches are
gaining attention from academia and industry as a growing subject in industrial
applications and as a powerful way of identifying faults. This paper provides
an overview of intelligent condition monitoring and fault detection and
diagnosis methods for industrial plants with a focus on the open-source
benchmark Tennessee Eastman Process (TEP). In this survey, the most popular and
state-of-the-art deep learning (DL) and machine learning (ML) algorithms for
industrial plant condition monitoring, fault detection, and diagnosis are
summarized and the advantages and disadvantages of each algorithm are studied.
Challenges like imbalanced data, unlabelled samples and how deep learning
models can handle them are also covered. Finally, a comparison of the
accuracies and specifications of different algorithms utilizing the Tennessee
Eastman Process (TEP) is conducted. This research will be beneficial for both
researchers who are new to the field and experts, as it covers the literature
on condition monitoring and state-of-the-art methods alongside the challenges
and possible solutions to them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahang_M/0/1/0/all/0/1&quot;&gt;Maryam Ahang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charter_T/0/1/0/all/0/1&quot;&gt;Todd Charter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ogunfowora_O/0/1/0/all/0/1&quot;&gt;Oluwaseyi Ogunfowora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khadivi_M/0/1/0/all/0/1&quot;&gt;Maziyar Khadivi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_M/0/1/0/all/0/1&quot;&gt;Mostafa Abbasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Najjaran_H/0/1/0/all/0/1&quot;&gt;Homayoun Najjaran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10270">
<title>Migrating Birds Optimization-Based Feature Selection for Text Classification. (arXiv:2401.10270v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2401.10270</link>
<description rdf:parseType="Literal">&lt;p&gt;This research introduces a novel approach, MBO-NB, that leverages Migrating
Birds Optimization (MBO) coupled with Naive Bayes as an internal classifier to
address feature selection challenges in text classification having large number
of features. Focusing on computational efficiency, we preprocess raw data using
the Information Gain algorithm, strategically reducing the feature count from
an average of 62221 to 2089. Our experiments demonstrate MBO-NB&apos;s superior
effectiveness in feature reduction compared to other existing techniques,
emphasizing an increased classification accuracy. The successful integration of
Naive Bayes within MBO presents a well-rounded solution. In individual
comparisons with Particle Swarm Optimization (PSO), MBO-NB consistently
outperforms by an average of 6.9% across four setups. This research offers
valuable insights into enhancing feature selection methods, providing a
scalable and effective solution for text classification
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaya_C/0/1/0/all/0/1&quot;&gt;Cem Kaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kilimci_Z/0/1/0/all/0/1&quot;&gt;Zeynep Hilal Kilimci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uysal_M/0/1/0/all/0/1&quot;&gt;Mitat Uysal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaya_M/0/1/0/all/0/1&quot;&gt;Murat Kaya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10278">
<title>EEGFormer: Towards Transferable and Interpretable Large-Scale EEG Foundation Model. (arXiv:2401.10278v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10278</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning has emerged as a highly effective approach in the
fields of natural language processing and computer vision. It is also
applicable to brain signals such as electroencephalography (EEG) data, given
the abundance of available unlabeled data that exist in a wide spectrum of
real-world medical applications ranging from seizure detection to wave
analysis. The existing works leveraging self-supervised learning on EEG
modeling mainly focus on pretraining upon each individual dataset corresponding
to a single downstream task, which cannot leverage the power of abundant data,
and they may derive sub-optimal solutions with a lack of generalization.
Moreover, these methods rely on end-to-end model learning which is not easy for
humans to understand. In this paper, we present a novel EEG foundation model,
namely EEGFormer, pretrained on large-scale compound EEG data. The pretrained
model cannot only learn universal representations on EEG signals with adaptable
performance on various downstream tasks but also provide interpretable outcomes
of the useful patterns within the data. To validate the effectiveness of our
model, we extensively evaluate it on various downstream tasks and assess the
performance under different transfer settings. Furthermore, we demonstrate how
the learned model exhibits transferable anomaly detection performance and
provides valuable interpretability of the acquired patterns via self-supervised
learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ren_K/0/1/0/all/0/1&quot;&gt;Kan Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Song_K/0/1/0/all/0/1&quot;&gt;Kaitao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yansen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yifan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Dongsheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Qiu_L/0/1/0/all/0/1&quot;&gt;Lili Qiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10282">
<title>BioDiffusion: A Versatile Diffusion Model for Biomedical Signal Synthesis. (arXiv:2401.10282v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10282</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning tasks involving biomedical signals frequently grapple with
issues such as limited data availability, imbalanced datasets, labeling
complexities, and the interference of measurement noise. These challenges often
hinder the optimal training of machine learning algorithms. Addressing these
concerns, we introduce BioDiffusion, a diffusion-based probabilistic model
optimized for the synthesis of multivariate biomedical signals. BioDiffusion
demonstrates excellence in producing high-fidelity, non-stationary,
multivariate signals for a range of tasks including unconditional,
label-conditional, and signal-conditional generation. Leveraging these
synthesized signals offers a notable solution to the aforementioned challenges.
Our research encompasses both qualitative and quantitative assessments of the
synthesized data quality, underscoring its capacity to bolster accuracy in
machine learning tasks tied to biomedical signals. Furthermore, when juxtaposed
with current leading time-series generative models, empirical evidence suggests
that BioDiffusion outperforms them in biomedical signal generation quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaomin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sakevych_M/0/1/0/all/0/1&quot;&gt;Mykhailo Sakevych&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Atkinson_G/0/1/0/all/0/1&quot;&gt;Gentry Atkinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Metsis_V/0/1/0/all/0/1&quot;&gt;Vangelis Metsis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10283">
<title>Window Stacking Meta-Models for Clinical EEG Classification. (arXiv:2401.10283v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10283</link>
<description rdf:parseType="Literal">&lt;p&gt;Windowing is a common technique in EEG machine learning classification and
other time series tasks. However, a challenge arises when employing this
technique: computational expense inhibits learning global relationships across
an entire recording or set of recordings. Furthermore, the labels inherited by
windows from their parent recordings may not accurately reflect the content of
that window in isolation. To resolve these issues, we introduce a multi-stage
model architecture, incorporating meta-learning principles tailored to
time-windowed data aggregation. We further tested two distinct strategies to
alleviate these issues: lengthening the window and utilizing overlapping to
augment data. Our methods, when tested on the Temple University Hospital
Abnormal EEG Corpus (TUAB), dramatically boosted the benchmark accuracy from
89.8 percent to 99.0 percent. This breakthrough performance surpasses prior
performance projections for this dataset and paves the way for clinical
applications of machine learning solutions to EEG interpretation challenges. On
a broader and more varied dataset from the Temple University Hospital EEG
Corpus (TUEG), we attained an accuracy of 86.7%, nearing the assumed
performance ceiling set by variable inter-rater agreement on such datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yixuan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kandasamy_R/0/1/0/all/0/1&quot;&gt;Rohan Kandasamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Canham_L/0/1/0/all/0/1&quot;&gt;Luke J. W. Canham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Western_D/0/1/0/all/0/1&quot;&gt;David Western&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10284">
<title>MorpheusNet: Resource efficient sleep stage classifier for embedded on-line systems. (arXiv:2401.10284v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10284</link>
<description rdf:parseType="Literal">&lt;p&gt;Sleep Stage Classification (SSC) is a labor-intensive task, requiring experts
to examine hours of electrophysiological recordings for manual classification.
This is a limiting factor when it comes to leveraging sleep stages for
therapeutic purposes. With increasing affordability and expansion of wearable
devices, automating SSC may enable deployment of sleep-based therapies at
scale. Deep Learning has gained increasing attention as a potential method to
automate this process. Previous research has shown accuracy comparable to
manual expert scores. However, previous approaches require sizable amount of
memory and computational resources. This constrains the ability to classify in
real time and deploy models on the edge. To address this gap, we aim to provide
a model capable of predicting sleep stages in real-time, without requiring
access to external computational sources (e.g., mobile phone, cloud). The
algorithm is power efficient to enable use on embedded battery powered systems.
Our compact sleep stage classifier can be deployed on most off-the-shelf
microcontrollers (MCU) with constrained hardware settings. This is due to the
memory footprint of our approach requiring significantly fewer operations. The
model was tested on three publicly available data bases and achieved
performance comparable to the state of the art, whilst reducing model
complexity by orders of magnitude (up to 280 times smaller compared to state of
the art). We further optimized the model with quantization of parameters to 8
bits with only an average drop of 0.95% in accuracy. When implemented in
firmware, the quantized model achieves a latency of 1.6 seconds on an Arm
CortexM4 processor, allowing its use for on-line SSC-based therapies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kavoosi_A/0/1/0/all/0/1&quot;&gt;Ali Kavoosi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mitchell_M/0/1/0/all/0/1&quot;&gt;Morgan P. Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kariyawasam_R/0/1/0/all/0/1&quot;&gt;Raveen Kariyawasam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fleming_J/0/1/0/all/0/1&quot;&gt;John E. Fleming&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lewis_P/0/1/0/all/0/1&quot;&gt;Penny Lewis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Johansen_Berg_H/0/1/0/all/0/1&quot;&gt;Heidi Johansen-Berg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cagnan_H/0/1/0/all/0/1&quot;&gt;Hayriye Cagnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Denison_T/0/1/0/all/0/1&quot;&gt;Timothy Denison&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10285">
<title>Analyzing Brain Activity During Learning Tasks with EEG and Machine Learning. (arXiv:2401.10285v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10285</link>
<description rdf:parseType="Literal">&lt;p&gt;This study aimed to analyze brain activity during various STEM activities,
exploring the feasibility of classifying between different tasks. EEG brain
data from twenty subjects engaged in five cognitive tasks were collected and
segmented into 4-second clips. Power spectral densities of brain frequency
waves were then analyzed. Testing different k-intervals with XGBoost, Random
Forest, and Bagging Classifier revealed that Random Forest performed best,
achieving a testing accuracy of 91.07% at an interval size of two. When
utilizing all four EEG channels, cognitive flexibility was most recognizable.
Task-specific classification accuracy showed the right frontal lobe excelled in
mathematical processing and planning, the left frontal lobe in cognitive
flexibility and mental flexibility, and the left temporoparietal lobe in
connections. Notably, numerous connections between frontal and temporoparietal
lobes were observed during STEM activities. This study contributes to a deeper
understanding of implementing machine learning in analyzing brain activity and
sheds light on the brain&apos;s mechanisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cho_R/0/1/0/all/0/1&quot;&gt;Ryan Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zaman_M/0/1/0/all/0/1&quot;&gt;Mobasshira Zaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyu Taek Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hwang_J/0/1/0/all/0/1&quot;&gt;Jaejin Hwang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10287">
<title>Open-Source Fermionic Neural Networks with Ionic Charge Initialization. (arXiv:2401.10287v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10287</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding accurate solutions to the electronic Schr\&quot;odinger equation plays an
important role in discovering important molecular and material energies and
characteristics. Consequently, solving systems with large numbers of electrons
has become increasingly important. Variational Monte Carlo (VMC) methods,
especially those approximated through deep neural networks, are promising in
this regard. In this paper, we aim to integrate one such model called the
FermiNet, a post-Hartree-Fock (HF) Deep Neural Network (DNN) model, into a
standard and widely used open source library, DeepChem. We also propose novel
initialization techniques to overcome the difficulties associated with the
assignment of excess or lack of electrons for ions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pranesh_S/0/1/0/all/0/1&quot;&gt;Shai Pranesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1&quot;&gt;Venkat Viswanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramsundar_B/0/1/0/all/0/1&quot;&gt;Bharath Ramsundar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10288">
<title>CLAN: A Contrastive Learning based Novelty Detection Framework for Human Activity Recognition. (arXiv:2401.10288v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10288</link>
<description rdf:parseType="Literal">&lt;p&gt;In ambient assisted living, human activity recognition from time series
sensor data mainly focuses on predefined activities, often overlooking new
activity patterns. We propose CLAN, a two-tower contrastive learning-based
novelty detection framework with diverse types of negative pairs for human
activity recognition. It is tailored to challenges with human activity
characteristics, including the significance of temporal and frequency features,
complex activity dynamics, shared features across activities, and sensor
modality variations. The framework aims to construct invariant representations
of known activity robust to the challenges. To generate suitable negative
pairs, it selects data augmentation methods according to the temporal and
frequency characteristics of each dataset. It derives the key representations
against meaningless dynamics by contrastive and classification losses-based
representation learning and score function-based novelty detection that
accommodate dynamic numbers of the different types of augmented samples. The
proposed two-tower model extracts the representations in terms of time and
frequency, mutually enhancing expressiveness for distinguishing between new and
known activities, even when they share common features. Experiments on four
real-world human activity datasets show that CLAN surpasses the best
performance of existing novelty detection methods, improving by 8.3%, 13.7%,
and 53.3% in AUROC, balanced accuracy, and FPR@TPR0.95 metrics respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyunju Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Dongman Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10289">
<title>Design and development of opto-neural processors for simulation of neural networks trained in image detection for potential implementation in hybrid robotics. (arXiv:2401.10289v1 [cs.ET])</title>
<link>http://arxiv.org/abs/2401.10289</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks have been employed for a wide range of processing
applications like image processing, motor control, object detection and many
others. Living neural networks offer advantages of lower power consumption,
faster processing, and biological realism. Optogenetics offers high spatial and
temporal control over biological neurons and presents potential in training
live neural networks. This work proposes a simulated living neural network
trained indirectly by backpropagating STDP based algorithms using precision
activation by optogenetics achieving accuracy comparable to traditional neural
network training algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shetty_S/0/1/0/all/0/1&quot;&gt;Sanjana Shetty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10290">
<title>Early Prediction of Geomagnetic Storms by Machine Learning Algorithms. (arXiv:2401.10290v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10290</link>
<description rdf:parseType="Literal">&lt;p&gt;Geomagnetic storms (GS) occur when solar winds disrupt Earth&apos;s magnetosphere.
GS can cause severe damages to satellites, power grids, and communication
infrastructures. Estimate of direct economic impacts of a large scale GS
exceeds $40 billion a day in the US. Early prediction is critical in preventing
and minimizing the hazards. However, current methods either predict several
hours ahead but fail to identify all types of GS, or make predictions within
short time, e.g., one hour ahead of the occurrence. This work aims to predict
all types of geomagnetic storms reliably and as early as possible using big
data and machine learning algorithms. By fusing big data collected from
multiple ground stations in the world on different aspects of solar
measurements and using Random Forests regression with feature selection and
downsampling on minor geomagnetic storm instances (which carry majority of the
data), we are able to achieve an accuracy of 82.55% on data collected in 2021
when making early predictions three hours in advance. Given that important
predictive features such as historic Kp indices are measured every 3 hours and
their importance decay quickly with the amount of time in advance, an early
prediction of 3 hours ahead of time is believed to be close to the practical
limit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_I/0/1/0/all/0/1&quot;&gt;Iris Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10293">
<title>Symmetry breaking in geometric quantum machine learning in the presence of noise. (arXiv:2401.10293v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2401.10293</link>
<description rdf:parseType="Literal">&lt;p&gt;Geometric quantum machine learning based on equivariant quantum neural
networks (EQNN) recently appeared as a promising direction in quantum machine
learning. Despite the encouraging progress, the studies are still limited to
theory, and the role of hardware noise in EQNN training has never been
explored. This work studies the behavior of EQNN models in the presence of
noise. We show that certain EQNN models can preserve equivariance under Pauli
channels, while this is not possible under the amplitude damping channel. We
claim that the symmetry breaking grows linearly in the number of layers and
noise strength. We support our claims with numerical data from simulations as
well as hardware up to 64 qubits. Furthermore, we provide strategies to enhance
the symmetry protection of EQNN models in the presence of noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tuysuz_C/0/1/0/all/0/1&quot;&gt;Cenk T&amp;#xfc;ys&amp;#xfc;z&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chang_S/0/1/0/all/0/1&quot;&gt;Su Yeon Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Demidik_M/0/1/0/all/0/1&quot;&gt;Maria Demidik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jansen_K/0/1/0/all/0/1&quot;&gt;Karl Jansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Vallecorsa_S/0/1/0/all/0/1&quot;&gt;Sofia Vallecorsa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Grossi_M/0/1/0/all/0/1&quot;&gt;Michele Grossi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10294">
<title>Tight Group-Level DP Guarantees for DP-SGD with Sampling via Mixture of Gaussians Mechanisms. (arXiv:2401.10294v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.10294</link>
<description rdf:parseType="Literal">&lt;p&gt;We give a procedure for computing group-level $(\epsilon, \delta)$-DP
guarantees for DP-SGD, when using Poisson sampling or fixed batch size
sampling. Up to discretization errors in the implementation, the DP guarantees
computed by this procedure are tight (assuming we release every intermediate
iterate).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganesh_A/0/1/0/all/0/1&quot;&gt;Arun Ganesh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10297">
<title>Learning Non-myopic Power Allocation in Constrained Scenarios. (arXiv:2401.10297v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10297</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a learning-based framework for efficient power allocation in ad
hoc interference networks under episodic constraints. The problem of optimal
power allocation -- for maximizing a given network utility metric -- under
instantaneous constraints has recently gained significant popularity. Several
learnable algorithms have been proposed to obtain fast, effective, and
near-optimal performance. However, a more realistic scenario arises when the
utility metric has to be optimized for an entire episode under time-coupled
constraints. In this case, the instantaneous power needs to be regulated so
that the given utility can be optimized over an entire sequence of wireless
network realizations while satisfying the constraint at all times. Solving each
instance independently will be myopic as the long-term constraint cannot
modulate such a solution. Instead, we frame this as a constrained and
sequential decision-making problem, and employ an actor-critic algorithm to
obtain the constraint-aware power allocation at each step. We present
experimental analyses to illustrate the effectiveness of our method in terms of
superior episodic network-utility performance and its efficiency in terms of
time and computational complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chowdhury_A/0/1/0/all/0/1&quot;&gt;Arindam Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Paternain_S/0/1/0/all/0/1&quot;&gt;Santiago Paternain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Verma_G/0/1/0/all/0/1&quot;&gt;Gunjan Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Swami_A/0/1/0/all/0/1&quot;&gt;Ananthram Swami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Segarra_S/0/1/0/all/0/1&quot;&gt;Santiago Segarra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10298">
<title>Machine learning approach to detect dynamical states from recurrence measures. (arXiv:2401.10298v1 [physics.data-an])</title>
<link>http://arxiv.org/abs/2401.10298</link>
<description rdf:parseType="Literal">&lt;p&gt;We integrate machine learning approaches with nonlinear time series analysis,
specifically utilizing recurrence measures to classify various dynamical states
emerging from time series. We implement three machine learning algorithms
Logistic Regression, Random Forest, and Support Vector Machine for this study.
The input features are derived from the recurrence quantification of nonlinear
time series and characteristic measures of the corresponding recurrence
networks. For training and testing we generate synthetic data from standard
nonlinear dynamical systems and evaluate the efficiency and performance of the
machine learning algorithms in classifying time series into periodic, chaotic,
hyper-chaotic, or noisy categories. Additionally, we explore the significance
of input features in the classification scheme and find that the features
quantifying the density of recurrence points are the most relevant.
Furthermore, we illustrate how the trained algorithms can successfully predict
the dynamical states of two variable stars, SX Her and AC Her from the data of
their light curves.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Thakur_D/0/1/0/all/0/1&quot;&gt;Dheeraja Thakur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mohan_A/0/1/0/all/0/1&quot;&gt;Athul Mohan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ambika_G/0/1/0/all/0/1&quot;&gt;G. Ambika&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Meena_C/0/1/0/all/0/1&quot;&gt;Chandrakala Meena&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10299">
<title>An attempt to generate new bridge types from latent space of generative flow. (arXiv:2401.10299v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10299</link>
<description rdf:parseType="Literal">&lt;p&gt;Through examples of coordinate and probability transformation between
different distributions, the basic principle of normalizing flow is introduced
in a simple and concise manner. From the perspective of the distribution of
random variable function, the essence of probability transformation is
explained, and the scaling factor Jacobian determinant of probability
transformation is introduced. Treating the dataset as a sample from the
population, obtaining normalizing flow is essentially through sampling surveys
to statistically infer the numerical features of the population, and then the
loss function is established by using the maximum likelihood estimation method.
This article introduces how normalizing flow cleverly solves the two major
application challenges of high-dimensional matrix determinant calculation and
neural network reversible transformation. Using symmetric structured image
dataset of three-span beam bridge, arch bridge, cable-stayed bridge and
suspension bridge, constructing and training normalizing flow based on the Glow
API in the TensorFlow Probability library. The model can smoothly transform the
complex distribution of the bridge dataset into a standard normal distribution,
and from the obtained latent space sampling, it can generate new bridge types
that are different from the training dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongjun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10300">
<title>A Hierarchical Framework with Spatio-Temporal Consistency Learning for Emergence Detection in Complex Adaptive Systems. (arXiv:2401.10300v1 [cs.MA])</title>
<link>http://arxiv.org/abs/2401.10300</link>
<description rdf:parseType="Literal">&lt;p&gt;Emergence, a global property of complex adaptive systems (CASs) constituted
by interactive agents, is prevalent in real-world dynamic systems, e.g.,
network-level traffic congestions. Detecting its formation and evaporation
helps to monitor the state of a system, allowing to issue a warning signal for
harmful emergent phenomena. Since there is no centralized controller of CAS,
detecting emergence based on each agent&apos;s local observation is desirable but
challenging. Existing works are unable to capture emergence-related spatial
patterns, and fail to model the nonlinear relationships among agents. This
paper proposes a hierarchical framework with spatio-temporal consistency
learning to solve these two problems by learning the system representation and
agent representations, respectively. Especially, spatio-temporal encoders are
tailored to capture agents&apos; nonlinear relationships and the system&apos;s complex
evolution. Representations of the agents and the system are learned by
preserving the intrinsic spatio-temporal consistency in a self-supervised
manner. Our method achieves more accurate detection than traditional methods
and deep learning methods on three datasets with well-known yet hard-to-detect
emergent behaviors. Notably, our hierarchical framework is generic, which can
employ other deep learning methods for agent-level and system-level detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Siyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1&quot;&gt;Xin Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiahai Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10304">
<title>On the Readiness of Scientific Data for a Fair and Transparent Use in Machine Learning. (arXiv:2401.10304v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10304</link>
<description rdf:parseType="Literal">&lt;p&gt;To ensure the fairness and trustworthiness of machine learning (ML) systems,
recent legislative initiatives and relevant research in the ML community have
pointed out the need to document the data used to train ML models. Besides,
data-sharing practices in many scientific domains have evolved in recent years
for reproducibility purposes. In this sense, the adoption of these practices by
academic institutions has encouraged researchers to publish their data and
technical documentation in peer-reviewed publications such as data papers. In
this study, we analyze how this scientific data documentation meets the needs
of the ML community and regulatory bodies for its use in ML technologies. We
examine a sample of 4041 data papers of different domains, assessing their
completeness and coverage of the requested dimensions, and trends in recent
years, putting special emphasis on the most and least documented dimensions. As
a result, we propose a set of recommendation guidelines for data creators and
scientific data publishers to increase their data&apos;s preparedness for its
transparent and fairer use in ML technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giner_Miguelez_J/0/1/0/all/0/1&quot;&gt;Joan Giner-Miguelez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1&quot;&gt;Abel G&amp;#xf3;mez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cabot_J/0/1/0/all/0/1&quot;&gt;Jordi Cabot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10305">
<title>Personality Trait Inference Via Mobile Phone Sensors: A Machine Learning Approach. (arXiv:2401.10305v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10305</link>
<description rdf:parseType="Literal">&lt;p&gt;This study provides evidence that personality can be reliably predicted from
activity data collected through mobile phone sensors. Employing a set of well
informed indicators calculable from accelerometer records and movement
patterns, we were able to predict users&apos; personality up to a 0.78 F1 score on a
two class problem. Given the fast growing number of data collected from mobile
phones, our novel personality indicators open the door to exciting avenues for
future research in social sciences. Our results reveal distinct behavioral
patterns that proved to be differentially predictive of big five personality
traits. They potentially enable cost effective, questionnaire free
investigation of personality related questions at an unprecedented scale.
Overall, this paper shows how a combination of rich behavioral data obtained
with smartphone sensing and the use of machine learning techniques can help to
advance personality research and can inform both practitioners and researchers
about the different behavioral patterns of personality. These findings have
practical implications for organizations harnessing mobile sensor data for
personality assessment, guiding the refinement of more precise and efficient
prediction models in the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sze_W/0/1/0/all/0/1&quot;&gt;Wun Yung Shaney Sze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Herrero_M/0/1/0/all/0/1&quot;&gt;Maryglen Pearl Herrero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Garriga_R/0/1/0/all/0/1&quot;&gt;Roger Garriga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10306">
<title>Physics-constrained convolutional neural networks for inverse problems in spatiotemporal partial differential equations. (arXiv:2401.10306v1 [physics.flu-dyn])</title>
<link>http://arxiv.org/abs/2401.10306</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a physics-constrained convolutional neural network (PC-CNN) to
solve two types of inverse problems in partial differential equations (PDEs),
which are nonlinear and vary both in space and time. In the first inverse
problem, we are given data that is offset by spatially varying systematic error
(i.e., the bias, also known the epistemic uncertainty). The task is to uncover
from the biased data the true state, which is the solution of the PDE. In the
second inverse problem, we are given sparse information on the solution of a
PDE. The task is to reconstruct the solution in space with high-resolution.
First, we present the PC-CNN, which constrains the PDE with a simple
time-windowing scheme to handle sequential data. Second, we analyse the
performance of the PC-CNN for uncovering solutions from biased data. We analyse
both linear and nonlinear convection-diffusion equations, and the Navier-Stokes
equations, which govern the spatiotemporally chaotic dynamics of turbulent
flows. We find that the PC-CNN correctly recovers the true solution for a
variety of biases, which are parameterised as non-convex functions. Third, we
analyse the performance of the PC-CNN for reconstructing solutions from biased
data for the turbulent flow. We reconstruct the spatiotemporal chaotic solution
on a high-resolution grid from only 2\% of the information contained in it. For
both tasks, we further analyse the Navier-Stokes solutions. We find that the
inferred solutions have a physical spectral energy content, whereas traditional
methods, such as interpolation, do not. This work opens opportunities for
solving inverse problems with partial differential equations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kelshaw_D/0/1/0/all/0/1&quot;&gt;Daniel Kelshaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Magri_L/0/1/0/all/0/1&quot;&gt;Luca Magri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10310">
<title>Mathematical Algorithm Design for Deep Learning under Societal and Judicial Constraints: The Algorithmic Transparency Requirement. (arXiv:2401.10310v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10310</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning still has drawbacks in terms of trustworthiness, which
describes a comprehensible, fair, safe, and reliable method. To mitigate the
potential risk of AI, clear obligations associated to trustworthiness have been
proposed via regulatory guidelines, e.g., in the European AI Act. Therefore, a
central question is to what extent trustworthy deep learning can be realized.
Establishing the described properties constituting trustworthiness requires
that the factors influencing an algorithmic computation can be retraced, i.e.,
the algorithmic implementation is transparent. Motivated by the observation
that the current evolution of deep learning models necessitates a change in
computing technology, we derive a mathematical framework which enables us to
analyze whether a transparent implementation in a computing model is feasible.
We exemplarily apply our trustworthiness framework to analyze deep learning
approaches for inverse problems in digital and analog computing models
represented by Turing and Blum-Shub-Smale Machines, respectively. Based on
previous results, we find that Blum-Shub-Smale Machines have the potential to
establish trustworthy solvers for inverse problems under fairly general
conditions, whereas Turing machines cannot guarantee trustworthiness to the
same degree.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boche_H/0/1/0/all/0/1&quot;&gt;Holger Boche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fono_A/0/1/0/all/0/1&quot;&gt;Adalbert Fono&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1&quot;&gt;Gitta Kutyniok&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10313">
<title>Hacking Predictors Means Hacking Cars: Using Sensitivity Analysis to Identify Trajectory Prediction Vulnerabilities for Autonomous Driving Security. (arXiv:2401.10313v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.10313</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial attacks on learning-based trajectory predictors have already been
demonstrated. However, there are still open questions about the effects of
perturbations on trajectory predictor inputs other than state histories, and
how these attacks impact downstream planning and control. In this paper, we
conduct a sensitivity analysis on two trajectory prediction models,
Trajectron++ and AgentFormer. We observe that between all inputs, almost all of
the perturbation sensitivities for Trajectron++ lie only within the most recent
state history time point, while perturbation sensitivities for AgentFormer are
spread across state histories over time. We additionally demonstrate that,
despite dominant sensitivity on state history perturbations, an undetectable
image map perturbation made with the Fast Gradient Sign Method can induce large
prediction error increases in both models. Even though image maps may
contribute slightly to the prediction output of both models, this result
reveals that rather than being robust to adversarial image perturbations,
trajectory predictors are susceptible to image attacks. Using an
optimization-based planner and example perturbations crafted from sensitivity
results, we show how this vulnerability can cause a vehicle to come to a sudden
stop from moderate driving speeds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gibson_M/0/1/0/all/0/1&quot;&gt;Marsalis Gibson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babazadeh_D/0/1/0/all/0/1&quot;&gt;David Babazadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomlin_C/0/1/0/all/0/1&quot;&gt;Claire Tomlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sastry_S/0/1/0/all/0/1&quot;&gt;Shankar Sastry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10314">
<title>LangProp: A code optimization framework using Language Models applied to driving. (arXiv:2401.10314v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2401.10314</link>
<description rdf:parseType="Literal">&lt;p&gt;LangProp is a framework for iteratively optimizing code generated by large
language models (LLMs) in a supervised/reinforcement learning setting. While
LLMs can generate sensible solutions zero-shot, the solutions are often
sub-optimal. Especially for code generation tasks, it is likely that the
initial code will fail on certain edge cases. LangProp automatically evaluates
the code performance on a dataset of input-output pairs, as well as catches any
exceptions, and feeds the results back to the LLM in the training loop, so that
the LLM can iteratively improve the code it generates. By adopting a metric-
and data-driven training paradigm for this code optimization procedure, one
could easily adapt findings from traditional machine learning techniques such
as imitation learning, DAgger, and reinforcement learning. We demonstrate the
first proof of concept of automated code optimization for autonomous driving in
CARLA, showing that LangProp can generate interpretable and transparent driving
policies that can be verified and improved in a metric- and data-driven way.
Our code will be open-sourced and is available at
https://github.com/shuishida/LangProp.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishida_S/0/1/0/all/0/1&quot;&gt;Shu Ishida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corrado_G/0/1/0/all/0/1&quot;&gt;Gianluca Corrado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fedoseev_G/0/1/0/all/0/1&quot;&gt;George Fedoseev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeo_H/0/1/0/all/0/1&quot;&gt;Hudson Yeo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_L/0/1/0/all/0/1&quot;&gt;Lloyd Russell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shotton_J/0/1/0/all/0/1&quot;&gt;Jamie Shotton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o F. Henriques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1&quot;&gt;Anthony Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10316">
<title>Improving One-class Recommendation with Multi-tasking on Various Preference Intensities. (arXiv:2401.10316v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2401.10316</link>
<description rdf:parseType="Literal">&lt;p&gt;In the one-class recommendation problem, it&apos;s required to make
recommendations basing on users&apos; implicit feedback, which is inferred from
their action and inaction. Existing works obtain representations of users and
items by encoding positive and negative interactions observed from training
data. However, these efforts assume that all positive signals from implicit
feedback reflect a fixed preference intensity, which is not realistic.
Consequently, representations learned with these methods usually fail to
capture informative entity features that reflect various preference
intensities.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a multi-tasking framework taking various preference
intensities of each signal from implicit feedback into consideration.
Representations of entities are required to satisfy the objective of each
subtask simultaneously, making them more robust and generalizable. Furthermore,
we incorporate attentive graph convolutional layers to explore high-order
relationships in the user-item bipartite graph and dynamically capture the
latent tendencies of users toward the items they interact with. Experimental
results show that our method performs better than state-of-the-art methods by a
large margin on three large-scale real-world benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_C/0/1/0/all/0/1&quot;&gt;Chu-Jen Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1&quot;&gt;Hao-Ming Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1&quot;&gt;Pu-Jen Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10334">
<title>DrugAssist: A Large Language Model for Molecule Optimization. (arXiv:2401.10334v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/2401.10334</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the impressive performance of large language models (LLMs) on a
wide range of tasks has attracted an increasing number of attempts to apply
LLMs in drug discovery. However, molecule optimization, a critical task in the
drug discovery pipeline, is currently an area that has seen little involvement
from LLMs. Most of existing approaches focus solely on capturing the underlying
patterns in chemical structures provided by the data, without taking advantage
of expert feedback. These non-interactive approaches overlook the fact that the
drug discovery process is actually one that requires the integration of expert
experience and iterative refinement. To address this gap, we propose
DrugAssist, an interactive molecule optimization model which performs
optimization through human-machine dialogue by leveraging LLM&apos;s strong
interactivity and generalizability. DrugAssist has achieved leading results in
both single and multiple property optimization, simultaneously showcasing
immense potential in transferability and iterative optimization. In addition,
we publicly release a large instruction-based dataset called
MolOpt-Instructions for fine-tuning language models on molecule optimization
tasks. We have made our code and data publicly available at
https://github.com/blazerye/DrugAssist, which we hope to pave the way for
future research in LLMs&apos; application for drug discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ye_G/0/1/0/all/0/1&quot;&gt;Geyan Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Cai_X/0/1/0/all/0/1&quot;&gt;Xibao Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lai_H/0/1/0/all/0/1&quot;&gt;Houtim Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Junhong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Longyue Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zeng_X/0/1/0/all/0/1&quot;&gt;Xiangxiang Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10337">
<title>Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10337</link>
<description rdf:parseType="Literal">&lt;p&gt;Tactics, Techniques and Procedures (TTPs) represent sophisticated attack
patterns in the cybersecurity domain, described encyclopedically in textual
knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP
mapping, is an important and challenging task. Conventional learning approaches
often target the problem in the classical multi-class or multilabel
classification setting. This setting hinders the learning ability of the model
due to a large number of classes (i.e., TTPs), the inevitable skewness of the
label distribution and the complex hierarchical structure of the label space.
We formulate the problem in a different learning paradigm, where the assignment
of a text to a TTP label is decided by the direct semantic similarity between
the two, thus reducing the complexity of competing solely over the large
labeling space. To that end, we propose a neural matching architecture with an
effective sampling-based learn-to-compare mechanism, facilitating the learning
process of the matching model despite constrained resources.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Tu Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srndic_N/0/1/0/all/0/1&quot;&gt;Nedim Srndic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neth_A/0/1/0/all/0/1&quot;&gt;Alexander Neth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10338">
<title>MELODY: Robust Semi-Supervised Hybrid Model for Entity-Level Online Anomaly Detection with Multivariate Time Series. (arXiv:2401.10338v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10338</link>
<description rdf:parseType="Literal">&lt;p&gt;In large IT systems, software deployment is a crucial process in online
services as their code is regularly updated. However, a faulty code change may
degrade the target service&apos;s performance and cause cascading outages in
downstream services. Thus, software deployments should be comprehensively
monitored, and their anomalies should be detected timely. In this paper, we
study the problem of anomaly detection for deployments. We begin by identifying
the challenges unique to this anomaly detection problem, which is at
entity-level (e.g., deployments), relative to the more typical problem of
anomaly detection in multivariate time series (MTS). The unique challenges
include the heterogeneity of deployments, the low latency tolerance, the
ambiguous anomaly definition, and the limited supervision. To address them, we
propose a novel framework, semi-supervised hybrid Model for Entity-Level Online
Detection of anomalY (MELODY). MELODY first transforms the MTS of different
entities to the same feature space by an online feature extractor, then uses a
newly proposed semi-supervised deep one-class model for detecting anomalous
entities. We evaluated MELODY on real data of cloud services with 1.2M+ time
series. The relative F1 score improvement of MELODY over the state-of-the-art
methods ranges from 7.6% to 56.5%. The user evaluation suggests MELODY is
suitable for monitoring deployments in large online systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1&quot;&gt;Jingchao Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guinet_G/0/1/0/all/0/1&quot;&gt;Gauthier Guinet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1&quot;&gt;Peihong Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Callot_L/0/1/0/all/0/1&quot;&gt;Laurent Callot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kan_A/0/1/0/all/0/1&quot;&gt;Andrey Kan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10354">
<title>Towards providing reliable job completion time predictions using PCS. (arXiv:2401.10354v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2401.10354</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we build a case for providing job completion time predictions
to cloud users, similar to the delivery date of a package or arrival time of a
booked ride. Our analysis reveals that providing predictability can come at the
expense of performance and fairness. Existing cloud scheduling systems optimize
for extreme points in the trade-off space, making them either extremely
unpredictable or impractical.
&lt;/p&gt;
&lt;p&gt;To address this challenge, we present PCS, a new scheduling framework that
aims to provide predictability while balancing other traditional objectives.
The key idea behind PCS is to use Weighted-Fair-Queueing (WFQ) and find a
suitable configuration of different WFQ parameters (e.g., class weights) that
meets specific goals for predictability. It uses a simulation-aided search
strategy, to efficiently discover WFQ configurations that lie on the Pareto
front of the trade-off space between these objectives. We implement and
evaluate PCS in the context of DNN job scheduling on GPUs. Our evaluation, on a
small scale GPU testbed and larger-scale simulations, shows that PCS can
provide accurate completion time estimates while marginally compromising on
performance and fairness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faisal_A/0/1/0/all/0/1&quot;&gt;Abdullah Bin Faisal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_N/0/1/0/all/0/1&quot;&gt;Noah Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bashir_H/0/1/0/all/0/1&quot;&gt;Hafiz Mohsin Bashir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamelas_S/0/1/0/all/0/1&quot;&gt;Swaminathan Lamelas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dogar_F/0/1/0/all/0/1&quot;&gt;Fahad R. Dogar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10355">
<title>Intelligent Optimization and Machine Learning Algorithms for Structural Anomaly Detection using Seismic Signals. (arXiv:2401.10355v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10355</link>
<description rdf:parseType="Literal">&lt;p&gt;The lack of anomaly detection methods during mechanized tunnelling can cause
financial loss and deficits in drilling time. On-site excavation requires hard
obstacles to be recognized prior to drilling in order to avoid damaging the
tunnel boring machine and to adjust the propagation velocity. The efficiency of
the structural anomaly detection can be increased with intelligent optimization
techniques and machine learning. In this research, the anomaly in a simple
structure is detected by comparing the experimental measurements of the
structural vibrations with numerical simulations using parameter estimation
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Trapp_M/0/1/0/all/0/1&quot;&gt;Maximilian Trapp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bogoclu_C/0/1/0/all/0/1&quot;&gt;Can Bogoclu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nestorovic_T/0/1/0/all/0/1&quot;&gt;Tamara Nestorovi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Roos_D/0/1/0/all/0/1&quot;&gt;Dirk Roos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10360">
<title>Excuse me, sir? Your language model is leaking (information). (arXiv:2401.10360v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.10360</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a cryptographic method to hide an arbitrary secret payload in
the response of a Large Language Model (LLM). A secret key is required to
extract the payload from the model&apos;s response, and without the key it is
provably impossible to distinguish between the responses of the original LLM
and the LLM that hides a payload. In particular, the quality of generated text
is not affected by the payload. Our approach extends a recent result of Christ,
Gunn and Zamir (2023) who introduced an undetectable watermarking scheme for
LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamir_O/0/1/0/all/0/1&quot;&gt;Or Zamir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10361">
<title>Hierarchical Federated Learning in Multi-hop Cluster-Based VANETs. (arXiv:2401.10361v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10361</link>
<description rdf:parseType="Literal">&lt;p&gt;The usage of federated learning (FL) in Vehicular Ad hoc Networks (VANET) has
garnered significant interest in research due to the advantages of reducing
transmission overhead and protecting user privacy by communicating local
dataset gradients instead of raw data. However, implementing FL in VANETs faces
challenges, including limited communication resources, high vehicle mobility,
and the statistical diversity of data distributions. In order to tackle these
issues, this paper introduces a novel framework for hierarchical federated
learning (HFL) over multi-hop clustering-based VANET. The proposed method
utilizes a weighted combination of the average relative speed and cosine
similarity of FL model parameters as a clustering metric to consider both data
diversity and high vehicle mobility. This metric ensures convergence with
minimum changes in cluster heads while tackling the complexities associated
with non-independent and identically distributed (non-IID) data scenarios.
Additionally, the framework includes a novel mechanism to manage seamless
transitions of cluster heads (CHs), followed by transferring the most recent FL
model parameter to the designated CH. Furthermore, the proposed approach
considers the option of merging CHs, aiming to reduce their count and,
consequently, mitigate associated overhead. Through extensive simulations, the
proposed hierarchical federated learning over clustered VANET has been
demonstrated to improve accuracy and convergence time significantly while
maintaining an acceptable level of packet overhead compared to previously
proposed clustering algorithms and non-clustered VANET.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+HaghighiFard_M/0/1/0/all/0/1&quot;&gt;M. Saeid HaghighiFard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coleri_S/0/1/0/all/0/1&quot;&gt;Sinem Coleri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10364">
<title>Using LLM such as ChatGPT for Designing and Implementing a RISC Processor: Execution,Challenges and Limitations. (arXiv:2401.10364v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10364</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper discusses the feasibility of using Large Language Models LLM for
code generation with a particular application in designing an RISC. The paper
also reviews the associated steps such as parsing, tokenization, encoding,
attention mechanism, sampling the tokens and iterations during code generation.
The generated code for the RISC components is verified through testbenches and
hardware implementation on a FPGA board. Four metric parameters Correct output
on the first iteration, Number of errors embedded in the code, Number of trials
required to achieve the code and Failure to generate the code after three
iterations, are used to compare the efficiency of using LLM in programming. In
all the cases, the generated code had significant errors and human intervention
was always required to fix the bugs. LLM can therefore be used to complement a
programmer code design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hossain_S/0/1/0/all/0/1&quot;&gt;Shadeeb Hossain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gohil_A/0/1/0/all/0/1&quot;&gt;Aayush Gohil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yizhou Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10370">
<title>Deep Generative Modeling for Financial Time Series with Application in VaR: A Comparative Review. (arXiv:2401.10370v1 [q-fin.CP])</title>
<link>http://arxiv.org/abs/2401.10370</link>
<description rdf:parseType="Literal">&lt;p&gt;In the financial services industry, forecasting the risk factor distribution
conditional on the history and the current market environment is the key to
market risk modeling in general and value at risk (VaR) model in particular. As
one of the most widely adopted VaR models in commercial banks, Historical
simulation (HS) uses the empirical distribution of daily returns in a
historical window as the forecast distribution of risk factor returns in the
next day. The objectives for financial time series generation are to generate
synthetic data paths with good variety, and similar distribution and dynamics
to the original historical data. In this paper, we apply multiple existing deep
generative methods (e.g., CGAN, CWGAN, Diffusion, and Signature WGAN) for
conditional time series generation, and propose and test two new methods for
conditional multi-step time series generation, namely Encoder-Decoder CGAN and
Conditional TimeVAE. Furthermore, we introduce a comprehensive framework with a
set of KPIs to measure the quality of the generated time series for financial
modeling. The KPIs cover distribution distance, autocorrelation and
backtesting. All models (HS, parametric and neural networks) are tested on both
historical USD yield curve data and additional data simulated from GARCH and
CIR processes. The study shows that top performing models are HS, GARCH and
CWGAN models. Future research directions in this area are also discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Ericson_L/0/1/0/all/0/1&quot;&gt;Lars Ericson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xuejun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Han_X/0/1/0/all/0/1&quot;&gt;Xusi Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Fu_R/0/1/0/all/0/1&quot;&gt;Rao Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Guo_S/0/1/0/all/0/1&quot;&gt;Steve Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Hu_P/0/1/0/all/0/1&quot;&gt;Ping Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10371">
<title>Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning. (arXiv:2401.10371v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10371</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine unlearning has raised significant interest with the adoption of laws
ensuring the ``right to be forgotten&apos;&apos;. Researchers have provided a
probabilistic notion of approximate unlearning under a similar definition of
Differential Privacy (DP), where privacy is defined as statistical
indistinguishability to retraining from scratch. We propose Langevin
unlearning, an unlearning framework based on noisy gradient descent with
privacy guarantees for approximate unlearning problems. Langevin unlearning
unifies the DP learning process and the privacy-certified unlearning process
with many algorithmic benefits. These include approximate certified unlearning
for non-convex problems, complexity saving compared to retraining, sequential
and batch unlearning for multiple unlearning requests. We verify the
practicality of Langevin unlearning by studying its privacy-utility-complexity
trade-off via experiments on benchmark datasets, and also demonstrate its
superiority against gradient-decent-plus-output-perturbation based approximate
unlearning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1&quot;&gt;Eli Chien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haoyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Ziang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Pan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10373">
<title>Harmonized Spatial and Spectral Learning for Robust and Generalized Medical Image Segmentation. (arXiv:2401.10373v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2401.10373</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has demonstrated remarkable achievements in medical image
segmentation. However, prevailing deep learning models struggle with poor
generalization due to (i) intra-class variations, where the same class appears
differently in different samples, and (ii) inter-class independence, resulting
in difficulties capturing intricate relationships between distinct objects,
leading to higher false negative cases. This paper presents a novel approach
that synergies spatial and spectral representations to enhance
domain-generalized medical image segmentation. We introduce the innovative
Spectral Correlation Coefficient objective to improve the model&apos;s capacity to
capture middle-order features and contextual long-range dependencies. This
objective complements traditional spatial objectives by incorporating valuable
spectral information. Extensive experiments reveal that optimizing this
objective with existing architectures like UNet and TransUNet significantly
enhances generalization, interpretability, and noise robustness, producing more
confident predictions. For instance, in cardiac segmentation, we observe a 0.81
pp and 1.63 pp (pp = percentage point) improvement in DSC over UNet and
TransUNet, respectively. Our interpretability study demonstrates that, in most
tasks, objectives optimized with UNet outperform even TransUNet by introducing
global contextual information alongside local details. These findings
underscore the versatility and effectiveness of our proposed method across
diverse imaging modalities and medical domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gorade_V/0/1/0/all/0/1&quot;&gt;Vandan Gorade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mittal_S/0/1/0/all/0/1&quot;&gt;Sparsh Mittal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jha_D/0/1/0/all/0/1&quot;&gt;Debesh Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Singhal_R/0/1/0/all/0/1&quot;&gt;Rekha Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bagci_U/0/1/0/all/0/1&quot;&gt;Ulas Bagci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10375">
<title>Vulnerabilities of Foundation Model Integrated Federated Learning Under Adversarial Threats. (arXiv:2401.10375v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.10375</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) addresses critical issues in machine learning related
to data privacy and security, yet suffering from data insufficiency and
imbalance under certain circumstances. The emergence of foundation models (FMs)
offers potential solutions to the limitations of existing FL frameworks, e.g.,
by generating synthetic data for model initialization. However, due to the
inherent safety concerns of FMs, integrating FMs into FL could introduce new
risks, which remains largely unexplored. To address this gap, we conduct the
first investigation on the vulnerability of FM integrated FL (FM-FL) under
adversarial threats. Based on a unified framework of FM-FL, we introduce a
novel attack strategy that exploits safety issues of FM to compromise FL client
models. Through extensive experiments with well-known models and benchmark
datasets in both image and text domains, we reveal the high susceptibility of
the FM-FL to this new threat under various FL configurations. Furthermore, we
find that existing FL defense strategies offer limited protection against this
novel attack approach. This research highlights the critical need for enhanced
security measures in FL in the era of FMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chen Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiaqi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10383">
<title>Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis. (arXiv:2401.10383v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10383</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we formulate the multi-agent graph bandit problem as a
multi-agent extension of the graph bandit problem introduced by Zhang,
Johansson, and Li [CISS 57, 1-6 (2023)]. In our formulation, $N$ cooperative
agents travel on a connected graph $G$ with $K$ nodes. Upon arrival at each
node, agents observe a random reward drawn from a node-dependent probability
distribution. The reward of the system is modeled as a weighted sum of the
rewards the agents observe, where the weights capture the decreasing marginal
reward associated with multiple agents sampling the same node at the same time.
We propose an Upper Confidence Bound (UCB)-based learning algorithm,
Multi-G-UCB, and prove that its expected regret over $T$ steps is bounded by
$O(N\log(T)[\sqrt{KT} + DK])$, where $D$ is the diameter of graph $G$. Lastly,
we numerically test our algorithm by comparing it to alternative methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paschalidis_P/0/1/0/all/0/1&quot;&gt;Phevos Paschalidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Runyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1&quot;&gt;Na Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10385">
<title>Approximation of Solution Operators for High-dimensional PDEs. (arXiv:2401.10385v1 [math.NA])</title>
<link>http://arxiv.org/abs/2401.10385</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a finite-dimensional control-based method to approximate solution
operators for evolutional partial differential equations (PDEs), particularly
in high-dimensions. By employing a general reduced-order model, such as a deep
neural network, we connect the evolution of the model parameters with
trajectories in a corresponding function space. Using the computational
technique of neural ordinary differential equation, we learn the control over
the parameter space such that from any initial starting point, the controlled
trajectories closely approximate the solutions to the PDE. Approximation
accuracy is justified for a general class of second-order nonlinear PDEs.
Numerical results are presented for several high-dimensional PDEs, including
real-world applications to solving Hamilton-Jacobi-Bellman equations. These are
demonstrated to show the accuracy and efficiency of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gaby_N/0/1/0/all/0/1&quot;&gt;Nathan Gaby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ye_X/0/1/0/all/0/1&quot;&gt;Xiaojing Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10386">
<title>Noninvasive Acute Compartment Syndrome Diagnosis Using Random Forest Machine Learning. (arXiv:2401.10386v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10386</link>
<description rdf:parseType="Literal">&lt;p&gt;Acute compartment syndrome (ACS) is an orthopedic emergency, caused by
elevated pressure within a muscle compartment, that leads to permanent tissue
damage and eventually death. Diagnosis of ACS relies heavily on
patient-reported symptoms, a method that is clinically unreliable and often
supplemented with invasive intracompartmental pressure measurements. This study
proposes a continuous, objective, noninvasive diagnostic for ACS. The device
detects ACS through a random forest machine learning model that uses pressure
readings from force-sensitive resistors (FSRs) placed on the skin. The final
diagnosis is exported real-time to a web application via Bluetooth. To validate
the diagnostic, a data set containing FSR measurements and the corresponding
simulated intracompartmental pressure was created. The diagnostic achieved an
accuracy, on par to the invasive gold standard, of 97%. The device excelled in
key performance metrics including precision, sensitivity, and F1 score.
Manufactured for 73 USD, our device may be an economic alternative to
needle-based diagnostics. These results demonstrate the potential of
noninvasive ACS diagnostics to meet clinical standards and enhance patient
care.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hweij_Z/0/1/0/all/0/1&quot;&gt;Zaina Abu Hweij&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_F/0/1/0/all/0/1&quot;&gt;Florence Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Sophie Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10393">
<title>Catastrophic Interference is Mitigated in Naturalistic Power-Law Learning Environments. (arXiv:2401.10393v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10393</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks often suffer from catastrophic interference (CI): performance
on previously learned tasks drops off significantly when learning a new task.
This contrasts strongly with humans, who can sequentially learn new tasks
without appreciably forgetting previous tasks. Prior work has explored various
techniques for mitigating CI such as regularization, rehearsal, generative
replay, and distillation methods. The current work takes a different approach,
one guided by cognitive science research showing that in naturalistic
environments, the probability of encountering a task decreases as a power-law
of the time since it was last performed. We argue that a realistic evaluation
of techniques for the mitigation of CI should be performed in simulated
naturalistic learning environments. Thus, we evaluate the extent of mitigation
of CI when training simple rehearsal-based methods in power-law environments
similar to the ones humans face. Our work explores this novel rehearsal-based
approach for a domain-incremental task: learning permutations in the MNIST
task. We compare our rehearsal environment with other baselines to show its
efficacy in promoting continual learning. Additionally, we investigate whether
this environment shows forward facilitation, i.e., faster learning of later
tasks. Next, we explore the robustness of our learning environment to the
number of tasks, model size, and amount of data rehearsed after each task.
Notably, our results show that the performance is comparable or superior to
that of models trained using popular regularization methods and also to
rehearsals in non-power-law environments. The benefits of this training
paradigm include simplicity and the lack of a need for extra neural circuitry.
In addition, because our method is orthogonal to other methods, future research
can combine training in power-law environments with other continual learning
mechanisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gandhi_A/0/1/0/all/0/1&quot;&gt;Atith Gandhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1&quot;&gt;Raj Sanjay Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marupudi_V/0/1/0/all/0/1&quot;&gt;Vijay Marupudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varma_S/0/1/0/all/0/1&quot;&gt;Sashank Varma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10394">
<title>Distribution Consistency based Self-Training for Graph Neural Networks with Sparse Labels. (arXiv:2401.10394v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10394</link>
<description rdf:parseType="Literal">&lt;p&gt;Few-shot node classification poses a significant challenge for Graph Neural
Networks (GNNs) due to insufficient supervision and potential distribution
shifts between labeled and unlabeled nodes. Self-training has emerged as a
widely popular framework to leverage the abundance of unlabeled data, which
expands the training set by assigning pseudo-labels to selected unlabeled
nodes. Efforts have been made to develop various selection strategies based on
confidence, information gain, etc. However, none of these methods takes into
account the distribution shift between the training and testing node sets. The
pseudo-labeling step may amplify this shift and even introduce new ones,
hindering the effectiveness of self-training. Therefore, in this work, we
explore the potential of explicitly bridging the distribution shift between the
expanded training set and test set during self-training. To this end, we
propose a novel Distribution-Consistent Graph Self-Training (DC-GST) framework
to identify pseudo-labeled nodes that are both informative and capable of
redeeming the distribution discrepancy and formulate it as a differentiable
optimization task. A distribution-shift-aware edge predictor is further adopted
to augment the graph and increase the model&apos;s generalizability in assigning
pseudo labels. We evaluate our proposed method on four publicly available
benchmark datasets and extensive experiments demonstrate that our framework
consistently outperforms state-of-the-art baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fali Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tianxiang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Suhang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10396">
<title>Deep Dict: Deep Learning-based Lossy Time Series Compressor for IoT Data. (arXiv:2401.10396v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10396</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Deep Dict, a deep learning-based lossy time series compressor
designed to achieve a high compression ratio while maintaining decompression
error within a predefined range. Deep Dict incorporates two essential
components: the Bernoulli transformer autoencoder (BTAE) and a distortion
constraint. BTAE extracts Bernoulli representations from time series data,
reducing the size of the representations compared to conventional autoencoders.
The distortion constraint limits the prediction error of BTAE to the desired
range. Moreover, in order to address the limitations of common regression
losses such as L1/L2, we introduce a novel loss function called quantized
entropy loss (QEL). QEL takes into account the specific characteristics of the
problem, enhancing robustness to outliers and alleviating optimization
challenges. Our evaluation of Deep Dict across ten diverse time series datasets
from various domains reveals that Deep Dict outperforms state-of-the-art lossy
compressors in terms of compression ratio by a significant margin by up to
53.66%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jinxin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Djukic_P/0/1/0/all/0/1&quot;&gt;Petar Djukic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kulhandjian_M/0/1/0/all/0/1&quot;&gt;Michel Kulhandjian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kantarci_B/0/1/0/all/0/1&quot;&gt;Burak Kantarci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10405">
<title>Differentially Private and Adversarially Robust Machine Learning: An Empirical Evaluation. (arXiv:2401.10405v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10405</link>
<description rdf:parseType="Literal">&lt;p&gt;Malicious adversaries can attack machine learning models to infer sensitive
information or damage the system by launching a series of evasion attacks.
Although various work addresses privacy and security concerns, they focus on
individual defenses, but in practice, models may undergo simultaneous attacks.
This study explores the combination of adversarial training and differentially
private training to defend against simultaneous attacks. While
differentially-private adversarial training, as presented in DP-Adv,
outperforms the other state-of-the-art methods in performance, it lacks formal
privacy guarantees and empirical validation. Thus, in this work, we benchmark
the performance of this technique using a membership inference attack and
empirically show that the resulting approach is as private as non-robust
private models. This work also highlights the need to explore privacy
guarantees in dynamic training paradigms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakkar_J/0/1/0/all/0/1&quot;&gt;Janvi Thakkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zizzo_G/0/1/0/all/0/1&quot;&gt;Giulio Zizzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maffeis_S/0/1/0/all/0/1&quot;&gt;Sergio Maffeis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10419">
<title>M3BUNet: Mobile Mean Max UNet for Pancreas Segmentation on CT-Scans. (arXiv:2401.10419v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2401.10419</link>
<description rdf:parseType="Literal">&lt;p&gt;Segmenting organs in CT scan images is a necessary process for multiple
downstream medical image analysis tasks. Currently, manual CT scan segmentation
by radiologists is prevalent, especially for organs like the pancreas, which
requires a high level of domain expertise for reliable segmentation due to
factors like small organ size, occlusion, and varying shapes. When resorting to
automated pancreas segmentation, these factors translate to limited reliable
labeled data to train effective segmentation models. Consequently, the
performance of contemporary pancreas segmentation models is still not within
acceptable ranges. To improve that, we propose M3BUNet, a fusion of MobileNet
and U-Net neural networks, equipped with a novel Mean-Max (MM) attention that
operates in two stages to gradually segment pancreas CT images from coarse to
fine with mask guidance for object detection. This approach empowers the
network to surpass segmentation performance achieved by similar network
architectures and achieve results that are on par with complex state-of-the-art
methods, all while maintaining a low parameter count. Additionally, we
introduce external contour segmentation as a preprocessing step for the coarse
stage to assist in the segmentation process through image standardization. For
the fine segmentation stage, we found that applying a wavelet decomposition
filter to create multi-input images enhances pancreas segmentation performance.
We extensively evaluate our approach on the widely known NIH pancreas dataset
and MSD pancreas dataset. Our approach demonstrates a considerable performance
improvement, achieving an average Dice Similarity Coefficient (DSC) value of up
to 89.53% and an Intersection Over Union (IOU) score of up to 81.16 for the NIH
pancreas dataset, and 88.60% DSC and 79.90% IOU for the MSD Pancreas dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+juwita_J/0/1/0/all/0/1&quot;&gt;Juwita juwita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hassan_G/0/1/0/all/0/1&quot;&gt;Ghulam Mubashar Hassan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Akhtar_N/0/1/0/all/0/1&quot;&gt;Naveed Akhtar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Datta_A/0/1/0/all/0/1&quot;&gt;Amitava Datta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10432">
<title>A2Q+: Improving Accumulator-Aware Weight Quantization. (arXiv:2401.10432v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10432</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantization techniques commonly reduce the inference costs of neural
networks by restricting the precision of weights and activations. Recent
studies show that also reducing the precision of the accumulator can further
improve hardware efficiency at the risk of numerical overflow, which introduces
arithmetic errors that can degrade model accuracy. To avoid numerical overflow
while maintaining accuracy, recent work proposed accumulator-aware quantization
(A2Q), a quantization-aware training method that constrains model weights
during training to safely use a target accumulator bit width during inference.
Although this shows promise, we demonstrate that A2Q relies on an overly
restrictive constraint and a sub-optimal weight initialization strategy that
each introduce superfluous quantization error. To address these shortcomings,
we introduce: (1) an improved bound that alleviates accumulator constraints
without compromising overflow avoidance; and (2) a new strategy for
initializing quantized weights from pre-trained floating-point checkpoints. We
combine these contributions with weight normalization to introduce A2Q+. We
support our analysis with experiments that show A2Q+ significantly improves the
trade-off between accumulator bit width and model accuracy and characterize new
trade-offs that arise as a consequence of accumulator constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colbert_I/0/1/0/all/0/1&quot;&gt;Ian Colbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pappalardo_A/0/1/0/all/0/1&quot;&gt;Alessandro Pappalardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petri_Koenig_J/0/1/0/all/0/1&quot;&gt;Jakoba Petri-Koenig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Umuroglu_Y/0/1/0/all/0/1&quot;&gt;Yaman Umuroglu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10442">
<title>Path Choice Matters for Clear Attribution in Path Methods. (arXiv:2401.10442v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10442</link>
<description rdf:parseType="Literal">&lt;p&gt;Rigorousness and clarity are both essential for interpretations of DNNs to
engender human trust. Path methods are commonly employed to generate rigorous
attributions that satisfy three axioms. However, the meaning of attributions
remains ambiguous due to distinct path choices. To address the ambiguity, we
introduce \textbf{Concentration Principle}, which centrally allocates high
attributions to indispensable features, thereby endowing aesthetic and
sparsity. We then present \textbf{SAMP}, a model-agnostic interpreter, which
efficiently searches the near-optimal path from a pre-defined set of
manipulation paths. Moreover, we propose the infinitesimal constraint (IC) and
momentum strategy (MS) to improve the rigorousness and optimality.
Visualizations show that SAMP can precisely reveal DNNs by pinpointing salient
image pixels. We also perform quantitative experiments and observe that our
method significantly outperforms the counterparts. Code:
https://github.com/zbr17/SAMP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Borui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1&quot;&gt;Wenzhao Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jie Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiwen Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10446">
<title>Large Language Models are Efficient Learners of Noise-Robust Speech Recognition. (arXiv:2401.10446v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.10446</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in large language models (LLMs) have promoted generative
error correction (GER) for automatic speech recognition (ASR), which leverages
the rich linguistic knowledge and powerful reasoning ability of LLMs to improve
recognition results. The latest work proposes a GER benchmark with HyPoradise
dataset to learn the mapping from ASR N-best hypotheses to ground-truth
transcription by efficient LLM finetuning, which shows great effectiveness but
lacks specificity on noise-robust ASR. In this work, we extend the benchmark to
noisy conditions and investigate if we can teach LLMs to perform denoising for
GER just like what robust ASR do}, where one solution is introducing noise
information as a conditioner into LLM. However, directly incorporating noise
embeddings from audio encoder could harm the LLM tuning due to cross-modality
gap. To this end, we propose to extract a language-space noise embedding from
the N-best list to represent the noise conditions of source speech, which can
promote the denoising process in GER. Furthermore, in order to enhance its
representation ability of audio noise, we design a knowledge distillation (KD)
approach via mutual information estimation to distill the real noise
information in audio embeddings to our language embedding. Experiments on
various latest LLMs demonstrate our approach achieves a new breakthrough with
up to 53.9% correction improvement in terms of word error rate while with
limited training data. Analysis shows that our language-space noise embedding
can well represent the noise conditions of source speech, under which
off-the-shelf LLMs show strong ability of language-space denoising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yuchen Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chao-Han Huck Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ruizhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pin-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chng_E/0/1/0/all/0/1&quot;&gt;EnSiong Chng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10447">
<title>Investigating Training Strategies and Model Robustness of Low-Rank Adaptation for Language Modeling in Speech Recognition. (arXiv:2401.10447v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.10447</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of low-rank adaptation (LoRA) with frozen pretrained language models
(PLMs) has become increasing popular as a mainstream, resource-efficient
modeling approach for memory-constrained hardware. In this study, we first
explore how to enhance model performance by introducing various LoRA training
strategies, achieving relative word error rate reductions of 3.50\% on the
public Librispeech dataset and of 3.67\% on an internal dataset in the
messaging domain. To further characterize the stability of LoRA-based
second-pass speech recognition models, we examine robustness against input
perturbations. These perturbations are rooted in homophone replacements and a
novel metric called N-best Perturbation-based Rescoring Robustness (NPRR), both
designed to measure the relative degradation in the performance of rescoring
models. Our experimental results indicate that while advanced variants of LoRA,
such as dynamic rank-allocated LoRA, lead to performance degradation in
$1$-best perturbation, they alleviate the degradation in $N$-best perturbation.
This finding is in comparison to fully-tuned models and vanilla LoRA tuning
baselines, suggesting that a comprehensive selection is needed when using
LoRA-based adaptation for compute-cost savings and robust language modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chao-Han Huck Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dinh_T/0/1/0/all/0/1&quot;&gt;Tuan Dinh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_S/0/1/0/all/0/1&quot;&gt;Sungho Ryu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolehmainen_J/0/1/0/all/0/1&quot;&gt;Jari Kolehmainen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1&quot;&gt;Roger Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filimonov_D/0/1/0/all/0/1&quot;&gt;Denis Filimonov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shivakumar_P/0/1/0/all/0/1&quot;&gt;Prashanth G. Shivakumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gandhe_A/0/1/0/all/0/1&quot;&gt;Ankur Gandhe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastow_A/0/1/0/all/0/1&quot;&gt;Ariya Rastow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jia Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bulyko_I/0/1/0/all/0/1&quot;&gt;Ivan Bulyko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1&quot;&gt;Andreas Stolcke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10451">
<title>Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian Optimization Approach. (arXiv:2401.10451v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2401.10451</link>
<description rdf:parseType="Literal">&lt;p&gt;Solving large-scale capacity expansion problems (CEPs) is central to
cost-effective decarbonization of regional-scale energy systems. To ensure the
intended outcomes of CEPs, modeling uncertainty due to weather-dependent
variable renewable energy (VRE) supply and energy demand becomes crucially
important. However, the resulting stochastic optimization models are often less
computationally tractable than their deterministic counterparts. Here, we
propose a learning-assisted approximate solution method to tractably solve
two-stage stochastic CEPs. Our method identifies low-cost planning decisions by
constructing and solving a sequence of tractable temporally aggregated
surrogate problems. We adopt a Bayesian optimization approach to searching the
space of time series aggregation hyperparameters and compute approximate
solutions that minimize costs on a validation set of supply-demand projections.
Importantly, we evaluate solved planning outcomes on a held-out set of test
projections. We apply our approach to generation and transmission expansion
planning for a joint power-gas system spanning New England. We show that our
approach yields an estimated cost savings of up to 3.8% in comparison to
benchmark time series aggregation approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Brenner_A/0/1/0/all/0/1&quot;&gt;Aron Brenner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Khorramfar_R/0/1/0/all/0/1&quot;&gt;Rahman Khorramfar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mallapragada_D/0/1/0/all/0/1&quot;&gt;Dharik Mallapragada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Amin_S/0/1/0/all/0/1&quot;&gt;Saurabh Amin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10458">
<title>Contrastive Unlearning: A Contrastive Approach to Machine Unlearning. (arXiv:2401.10458v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10458</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine unlearning aims to eliminate the influence of a subset of training
samples (i.e., unlearning samples) from a trained model. Effectively and
efficiently removing the unlearning samples without negatively impacting the
overall model performance is still challenging. In this paper, we propose a
contrastive unlearning framework, leveraging the concept of representation
learning for more effective unlearning. It removes the influence of unlearning
samples by contrasting their embeddings against the remaining samples so that
they are pushed away from their original classes and pulled toward other
classes. By directly optimizing the representation space, it effectively
removes the influence of unlearning samples while maintaining the
representations learned from the remaining samples. Experiments on a variety of
datasets and models on both class unlearning and sample unlearning showed that
contrastive unlearning achieves the best unlearning effects and efficiency with
the lowest performance loss compared with the state-of-the-art algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hong kyu Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qiuchen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Carl Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1&quot;&gt;Jian Lou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1&quot;&gt;Li Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10460">
<title>Ultra-lightweight Neural Differential DSP Vocoder For High Quality Speech Synthesis. (arXiv:2401.10460v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2401.10460</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural vocoders model the raw audio waveform and synthesize high-quality
audio, but even the highly efficient ones, like MB-MelGAN and LPCNet, fail to
run real-time on a low-end device like a smartglass. A pure digital signal
processing (DSP) based vocoder can be implemented via lightweight fast Fourier
transforms (FFT), and therefore, is a magnitude faster than any neural vocoder.
A DSP vocoder often gets a lower audio quality due to consuming over-smoothed
acoustic model predictions of approximate representations for the vocal tract.
In this paper, we propose an ultra-lightweight differential DSP (DDSP) vocoder
that uses a jointly optimized acoustic model with a DSP vocoder, and learns
without an extracted spectral feature for the vocal tract. The model achieves
audio quality comparable to neural vocoders with a high average MOS of 4.36
while being efficient as a DSP vocoder. Our C++ implementation, without any
hardware-specific optimization, is at 15 MFLOPS, surpasses MB-MelGAN by 340
times in terms of FLOPS, and achieves a vocoder-only RTF of 0.003 and overall
RTF of 0.044 while running single-threaded on a 2GHz Intel Xeon CPU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1&quot;&gt;Prabhav Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koehler_T/0/1/0/all/0/1&quot;&gt;Thilo Koehler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiu_Z/0/1/0/all/0/1&quot;&gt;Zhiping Xiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serai_P/0/1/0/all/0/1&quot;&gt;Prashant Serai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1&quot;&gt;Qing He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10463">
<title>Critical Data Size of Language Models from a Grokking Perspective. (arXiv:2401.10463v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.10463</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the critical data size in language models, a threshold that marks
a fundamental shift from quick memorization to slow generalization. We
formalize the phase transition under the grokking configuration into the Data
Efficiency Hypothesis and identify data insufficiency, sufficiency, and surplus
regimes in language models training dynamics. We develop a grokking
configuration to reproduce grokking on simplistic language models stably by
rescaling initialization and weight decay. We show that generalization occurs
only when language models reach a critical size. We analyze grokking across
sample-wise and model-wise, verifying the proposed data efficiency hypothesis.
Our experiments reveal smoother phase transitions occurring at the critical
dataset size for language datasets. As the model size increases, this critical
point also becomes larger, indicating that larger models require more data. Our
results deepen the understanding of language model training, offering a novel
perspective on the role of data in the learning mechanism of language models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xuekai Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yao Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Bowen Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhouhan Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10467">
<title>Learning Backdoors for Mixed Integer Programs with Contrastive Learning. (arXiv:2401.10467v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2401.10467</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world problems can be efficiently modeled as Mixed Integer Programs
(MIPs) and solved with the Branch-and-Bound method. Prior work has shown the
existence of MIP backdoors, small sets of variables such that prioritizing
branching on them when possible leads to faster running times. However, finding
high-quality backdoors that improve running times remains an open question.
Previous work learns to estimate the relative solver speed of randomly sampled
backdoors through ranking and then decide whether to use it. In this paper, we
utilize the Monte-Carlo tree search method to collect backdoors for training,
rather than relying on random sampling, and adapt a contrastive learning
framework to train a Graph Attention Network model to predict backdoors. Our
method, evaluated on four common MIP problem domains, demonstrates performance
improvements over both Gurobi and previous models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1&quot;&gt;Junyang Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Taoan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1&quot;&gt;Bistra Dilkina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10474">
<title>LDReg: Local Dimensionality Regularized Self-Supervised Learning. (arXiv:2401.10474v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10474</link>
<description rdf:parseType="Literal">&lt;p&gt;Representations learned via self-supervised learning (SSL) can be susceptible
to dimensional collapse, where the learned representation subspace is of
extremely low dimensionality and thus fails to represent the full data
distribution and modalities. Dimensional collapse also known as the
&quot;underfilling&quot; phenomenon is one of the major causes of degraded performance on
downstream tasks. Previous work has investigated the dimensional collapse
problem of SSL at a global level. In this paper, we demonstrate that
representations can span over high dimensional space globally, but collapse
locally. To address this, we propose a method called $\textit{local
dimensionality regularization (LDReg)}$. Our formulation is based on the
derivation of the Fisher-Rao metric to compare and optimize local distance
distributions at an asymptotically small radius for each data point. By
increasing the local intrinsic dimensionality, we demonstrate through a range
of experiments that LDReg improves the representation quality of SSL. The
results also show that LDReg can regularize dimensionality at both local and
global levels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Hanxun Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campello_R/0/1/0/all/0/1&quot;&gt;Ricardo J. G. B. Campello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erfani_S/0/1/0/all/0/1&quot;&gt;Sarah Monazam Erfani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xingjun Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houle_M/0/1/0/all/0/1&quot;&gt;Michael E. Houle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bailey_J/0/1/0/all/0/1&quot;&gt;James Bailey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10478">
<title>Budgeted Online Model Selection and Fine-Tuning via Federated Learning. (arXiv:2401.10478v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10478</link>
<description rdf:parseType="Literal">&lt;p&gt;Online model selection involves selecting a model from a set of candidate
models &apos;on the fly&apos; to perform prediction on a stream of data. The choice of
candidate models henceforth has a crucial impact on the performance. Although
employing a larger set of candidate models naturally leads to more flexibility
in model selection, this may be infeasible in cases where prediction tasks are
performed on edge devices with limited memory. Faced with this challenge, the
present paper proposes an online federated model selection framework where a
group of learners (clients) interacts with a server with sufficient memory such
that the server stores all candidate models. However, each client only chooses
to store a subset of models that can be fit into its memory and performs its
own prediction task using one of the stored models. Furthermore, employing the
proposed algorithm, clients and the server collaborate to fine-tune models to
adapt them to a non-stationary environment. Theoretical analysis proves that
the proposed algorithm enjoys sub-linear regret with respect to the best model
in hindsight. Experiments on real datasets demonstrate the effectiveness of the
proposed algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghari_P/0/1/0/all/0/1&quot;&gt;Pouya M. Ghari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yanning Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10490">
<title>Generalization Error Guaranteed Auto-Encoder-Based Nonlinear Model Reduction for Operator Learning. (arXiv:2401.10490v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10490</link>
<description rdf:parseType="Literal">&lt;p&gt;Many physical processes in science and engineering are naturally represented
by operators between infinite-dimensional function spaces. The problem of
operator learning, in this context, seeks to extract these physical processes
from empirical data, which is challenging due to the infinite or high
dimensionality of data. An integral component in addressing this challenge is
model reduction, which reduces both the data dimensionality and problem size.
In this paper, we utilize low-dimensional nonlinear structures in model
reduction by investigating Auto-Encoder-based Neural Network (AENet). AENet
first learns the latent variables of the input data and then learns the
transformation from these latent variables to corresponding output data. Our
numerical experiments validate the ability of AENet to accurately learn the
solution operator of nonlinear partial differential equations. Furthermore, we
establish a mathematical and statistical estimation theory that analyzes the
generalization error of AENet. Our theoretical framework shows that the sample
complexity of training AENet is intricately tied to the intrinsic dimension of
the modeled process, while also demonstrating the remarkable resilience of
AENet to noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahal_B/0/1/0/all/0/1&quot;&gt;Biraj Dahal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_R/0/1/0/all/0/1&quot;&gt;Rongjie Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1&quot;&gt;Wenjing Liao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10495">
<title>Causal Layering via Conditional Entropy. (arXiv:2401.10495v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10495</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal discovery aims to recover information about an unobserved causal graph
from the observable data it generates. Layerings are orderings of the variables
which place causes before effects. In this paper, we provide ways to recover
layerings of a graph by accessing the data via a conditional entropy oracle,
when distributions are discrete. Our algorithms work by repeatedly removing
sources or sinks from the graph. Under appropriate assumptions and
conditioning, we can separate the sources or sinks from the remainder of the
nodes by comparing their conditional entropy to the unconditional entropy of
their noise. Our algorithms are provably correct and run in worst-case
quadratic time. The main assumptions are faithfulness and injective noise, and
either known noise entropies or weakly monotonically increasing noise entropies
along directed paths. In addition, we require one of either a very mild
extension of faithfulness, or strictly monotonically increasing noise
entropies, or expanding noise injectivity to include an additional single
argument in the structural functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feigenbaum_I/0/1/0/all/0/1&quot;&gt;Itai Feigenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1&quot;&gt;Devansh Arpit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinecke_S/0/1/0/all/0/1&quot;&gt;Shelby Heinecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niebles_J/0/1/0/all/0/1&quot;&gt;Juan Carlos Niebles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1&quot;&gt;Weiran Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10510">
<title>A match made in consistency heaven: when large language models meet evolutionary algorithms. (arXiv:2401.10510v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2401.10510</link>
<description rdf:parseType="Literal">&lt;p&gt;Pre-trained large language models (LLMs) have powerful capabilities for
generating creative natural text. Evolutionary algorithms (EAs) can discover
diverse solutions to complex real-world problems. Motivated by the common
collective and directionality of text sequence generation and evolution, this
paper illustrates the strong consistency of LLMs and EAs, which includes
multiple one-to-one key characteristics: token embedding and genotype-phenotype
mapping, position encoding and fitness shaping, position embedding and
selection, attention and crossover, feed-forward neural network and mutation,
model training and parameter update, and multi-task learning and
multi-objective optimization. Based on this consistency perspective, existing
coupling studies are analyzed, including evolutionary fine-tuning and
LLM-enhanced EAs. Leveraging these insights, we outline a fundamental roadmap
for future research in coupling LLMs and EAs, while highlighting key challenges
along the way. The consistency not only reveals the evolution mechanism behind
LLMs but also facilitates the development of evolved artificial agents that
approach or surpass biological organisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1&quot;&gt;Wang Chao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jiaxuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1&quot;&gt;Licheng Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lingling Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Fang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Shuyuan Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10516">
<title>Episodic Reinforcement Learning with Expanded State-reward Space. (arXiv:2401.10516v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10516</link>
<description rdf:parseType="Literal">&lt;p&gt;Empowered by deep neural networks, deep reinforcement learning (DRL) has
demonstrated tremendous empirical successes in various domains, including
games, health care, and autonomous driving. Despite these advancements, DRL is
still identified as data-inefficient as effective policies demand vast numbers
of environmental samples. Recently, episodic control (EC)-based model-free DRL
methods enable sample efficiency by recalling past experiences from episodic
memory. However, existing EC-based methods suffer from the limitation of
potential misalignment between the state and reward spaces for neglecting the
utilization of (past) retrieval states with extensive information, which
probably causes inaccurate value estimation and degraded policy performance. To
tackle this issue, we introduce an efficient EC-based DRL framework with
expanded state-reward space, where the expanded states used as the input and
the expanded rewards used in the training both contain historical and current
information. To be specific, we reuse the historical states retrieved by EC as
part of the input states and integrate the retrieved MC-returns into the
immediate reward in each interactive transition. As a result, our method is
able to simultaneously achieve the full utilization of retrieval information
and the better evaluation of state values by a Temporal Difference (TD) loss.
Empirical results on challenging Box2d and Mujoco tasks demonstrate the
superiority of our method over a recent sibling method and common baselines.
Further, we also verify our method&apos;s effectiveness in alleviating Q-value
overestimation by additional experiments of Q-value comparison.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1&quot;&gt;Dayang Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yaru Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yunlong Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10518">
<title>Spatial-temporal Forecasting for Regions without Observations. (arXiv:2401.10518v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10518</link>
<description rdf:parseType="Literal">&lt;p&gt;Spatial-temporal forecasting plays an important role in many real-world
applications, such as traffic forecasting, air pollutant forecasting,
crowd-flow forecasting, and so on. State-of-the-art spatial-temporal
forecasting models take data-driven approaches and rely heavily on data
availability. Such models suffer from accuracy issues when data is incomplete,
which is common in reality due to the heavy costs of deploying and maintaining
sensors for data collection. A few recent studies attempted to address the
issue of incomplete data. They typically assume some data availability in a
region of interest either for a short period or at a few locations. In this
paper, we further study spatial-temporal forecasting for a region of interest
without any historical observations, to address scenarios such as unbalanced
region development, progressive deployment of sensors or lack of open data. We
propose a model named STSM for the task. The model takes a contrastive
learning-based approach to learn spatial-temporal patterns from adjacent
regions that have recorded data. Our key insight is to learn from the locations
that resemble those in the region of interest, and we propose a selective
masking strategy to enable the learning. As a result, our model outperforms
adapted state-of-the-art models, reducing errors consistently over both traffic
and air pollutant forecasting tasks. The source code is available at
https://github.com/suzy0223/STSM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1&quot;&gt;Xinyu Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1&quot;&gt;Jianzhong Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanin_E/0/1/0/all/0/1&quot;&gt;Egemen Tanin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yanchuan Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarvi_M/0/1/0/all/0/1&quot;&gt;Majid Sarvi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10522">
<title>FARe: Fault-Aware GNN Training on ReRAM-based PIM Accelerators. (arXiv:2401.10522v1 [cs.AR])</title>
<link>http://arxiv.org/abs/2401.10522</link>
<description rdf:parseType="Literal">&lt;p&gt;Resistive random-access memory (ReRAM)-based processing-in-memory (PIM)
architecture is an attractive solution for training Graph Neural Networks
(GNNs) on edge platforms. However, the immature fabrication process and limited
write endurance of ReRAMs make them prone to hardware faults, thereby limiting
their widespread adoption for GNN training. Further, the existing
fault-tolerant solutions prove inadequate for effectively training GNNs in the
presence of faults. In this paper, we propose a fault-aware framework referred
to as FARe that mitigates the effect of faults during GNN training. FARe
outperforms existing approaches in terms of both accuracy and timing overhead.
Experimental results demonstrate that FARe framework can restore GNN test
accuracy by 47.6% on faulty ReRAM hardware with a ~1% timing overhead compared
to the fault-free counterpart.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhingra_P/0/1/0/all/0/1&quot;&gt;Pratyush Dhingra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ogbogu_C/0/1/0/all/0/1&quot;&gt;Chukwufumnanya Ogbogu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joardar_B/0/1/0/all/0/1&quot;&gt;Biresh Kumar Joardar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doppa_J/0/1/0/all/0/1&quot;&gt;Janardhan Rao Doppa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalyanaraman_A/0/1/0/all/0/1&quot;&gt;Ananth Kalyanaraman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pande_P/0/1/0/all/0/1&quot;&gt;Partha Pratim Pande&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10529">
<title>Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences. (arXiv:2401.10529v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10529</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal Large Language Models (MLLMs) have demonstrated proficiency in
handling a variety of visual-language tasks. However, current MLLM benchmarks
are predominantly designed to evaluate reasoning based on static information
about a single image, and the ability of modern MLLMs to extrapolate from image
sequences, which is essential for understanding our ever-changing world, has
been less investigated. To address this challenge, this paper introduces
Mementos, a new benchmark designed to assess MLLMs&apos; sequential image reasoning
abilities. Mementos features 4,761 diverse image sequences with varying
lengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning
performance. Through a careful evaluation of nine recent MLLMs on Mementos,
including GPT-4V and Gemini, we find that they struggle to accurately describe
dynamic information about given image sequences, often leading to
hallucinations/misrepresentations of objects and their corresponding behaviors.
Our quantitative analysis and case studies identify three key factors impacting
MLLMs&apos; sequential image reasoning: the correlation between object and
behavioral hallucinations, the influence of cooccurring behaviors, and the
compounding impact of behavioral hallucinations. Our dataset is available at
https://github.com/umd-huang-lab/Mementos.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiyao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuhang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1&quot;&gt;Hongjin Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yuancheng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1&quot;&gt;Feihong He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Jaehong Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1&quot;&gt;Taixi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertasius_G/0/1/0/all/0/1&quot;&gt;Gedas Bertasius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1&quot;&gt;Huaxiu Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Furong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10535">
<title>The &quot;Colonial Impulse&quot; of Natural Language Processing: An Audit of Bengali Sentiment Analysis Tools and Their Identity-based Biases. (arXiv:2401.10535v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.10535</link>
<description rdf:parseType="Literal">&lt;p&gt;While colonization has sociohistorically impacted people&apos;s identities across
various dimensions, those colonial values and biases continue to be perpetuated
by sociotechnical systems. One category of sociotechnical systems--sentiment
analysis tools--can also perpetuate colonial values and bias, yet less
attention has been paid to how such tools may be complicit in perpetuating
coloniality, although they are often used to guide various practices (e.g.,
content moderation). In this paper, we explore potential bias in sentiment
analysis tools in the context of Bengali communities that have experienced and
continue to experience the impacts of colonialism. Drawing on identity
categories most impacted by colonialism amongst local Bengali communities, we
focused our analytic attention on gender, religion, and nationality. We
conducted an algorithmic audit of all sentiment analysis tools for Bengali,
available on the Python package index (PyPI) and GitHub. Despite similar
semantic content and structure, our analyses showed that in addition to
inconsistencies in output from different tools, Bengali sentiment analysis
tools exhibit bias between different identity categories and respond
differently to different ways of identity expression. Connecting our findings
with colonially shaped sociocultural structures of Bengali communities, we
discuss the implications of downstream bias of sentiment analysis tools.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1&quot;&gt;Dipto Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guha_S/0/1/0/all/0/1&quot;&gt;Shion Guha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brubaker_J/0/1/0/all/0/1&quot;&gt;Jed Brubaker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Semaan_B/0/1/0/all/0/1&quot;&gt;Bryan Semaan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10541">
<title>I-SplitEE: Image classification in Split Computing DNNs with Early Exits. (arXiv:2401.10541v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10541</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent advances in Deep Neural Networks (DNNs) stem from their
exceptional performance across various domains. However, their inherent large
size hinders deploying these networks on resource-constrained devices like
edge, mobile, and IoT platforms. Strategies have emerged, from partial cloud
computation offloading (split computing) to integrating early exits within DNN
layers. Our work presents an innovative unified approach merging early exits
and split computing. We determine the &apos;splitting layer&apos;, the optimal depth in
the DNN for edge device computations, and whether to infer on edge device or be
offloaded to the cloud for inference considering accuracy, computational
efficiency, and communication costs. Also, Image classification faces diverse
environmental distortions, influenced by factors like time of day, lighting,
and weather. To adapt to these distortions, we introduce I-SplitEE, an online
unsupervised algorithm ideal for scenarios lacking ground truths and with
sequential data. Experimental validation using Caltech-256 and Cifar-10
datasets subjected to varied distortions showcases I-SplitEE&apos;s ability to
reduce costs by a minimum of 55% with marginal performance degradation of at
most 5%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajpai_D/0/1/0/all/0/1&quot;&gt;Divya Jyoti Bajpai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaiswal_A/0/1/0/all/0/1&quot;&gt;Aastha Jaiswal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanawal_M/0/1/0/all/0/1&quot;&gt;Manjesh Kumar Hanawal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10547">
<title>PhoGAD: Graph-based Anomaly Behavior Detection with Persistent Homology Optimization. (arXiv:2401.10547v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10547</link>
<description rdf:parseType="Literal">&lt;p&gt;A multitude of toxic online behaviors, ranging from network attacks to
anonymous traffic and spam, have severely disrupted the smooth operation of
networks. Due to the inherent sender-receiver nature of network behaviors,
graph-based frameworks are commonly used for detecting anomalous behaviors.
However, in real-world scenarios, the boundary between normal and anomalous
behaviors tends to be ambiguous. The local heterophily of graphs interferes
with the detection, and existing methods based on nodes or edges introduce
unwanted noise into representation results, thereby impacting the effectiveness
of detection. To address these issues, we propose PhoGAD, a graph-based anomaly
detection framework. PhoGAD leverages persistent homology optimization to
clarify behavioral boundaries. Building upon this, the weights of adjacent
edges are designed to mitigate the effects of local heterophily. Subsequently,
to tackle the noise problem, we conduct a formal analysis and propose a
disentangled representation-based explicit embedding method, ultimately
achieving anomaly behavior detection. Experiments on intrusion, traffic, and
spam datasets verify that PhoGAD has surpassed the performance of
state-of-the-art (SOTA) frameworks in detection efficacy. Notably, PhoGAD
demonstrates robust detection even with diminished anomaly proportions,
highlighting its applicability to real-world scenarios. The analysis of
persistent homology demonstrates its effectiveness in capturing the topological
structure formed by normal edge features. Additionally, ablation experiments
validate the effectiveness of the innovative mechanisms integrated within
PhoGAD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1&quot;&gt;Ziqi Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Haoyi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianxin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10549">
<title>Unified View Imputation and Feature Selection Learning for Incomplete Multi-view Data. (arXiv:2401.10549v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10549</link>
<description rdf:parseType="Literal">&lt;p&gt;Although multi-view unsupervised feature selection (MUFS) is an effective
technology for reducing dimensionality in machine learning, existing methods
cannot directly deal with incomplete multi-view data where some samples are
missing in certain views. These methods should first apply predetermined values
to impute missing data, then perform feature selection on the complete dataset.
Separating imputation and feature selection processes fails to capitalize on
the potential synergy where local structural information gleaned from feature
selection could guide the imputation, thereby improving the feature selection
performance in turn. Additionally, previous methods only focus on leveraging
samples&apos; local structure information, while ignoring the intrinsic locality of
the feature space. To tackle these problems, a novel MUFS method, called
UNified view Imputation and Feature selectIon lEaRning (UNIFIER), is proposed.
UNIFIER explores the local structure of multi-view data by adaptively learning
similarity-induced graphs from both the sample and feature spaces. Then,
UNIFIER dynamically recovers the missing views, guided by the sample and
feature similarity graphs during the feature selection procedure. Furthermore,
the half-quadratic minimization technique is used to automatically weight
different instances, alleviating the impact of outliers and unreliable restored
data. Comprehensive experimental results demonstrate that UNIFIER outperforms
other state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yanyong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zongxin Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tianrui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_F/0/1/0/all/0/1&quot;&gt;Fengmao Lv&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10559">
<title>OrchMoE: Efficient Multi-Adapter Learning with Task-Skill Synergy. (arXiv:2401.10559v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10559</link>
<description rdf:parseType="Literal">&lt;p&gt;We advance the field of Parameter-Efficient Fine-Tuning (PEFT) with our novel
multi-adapter method, OrchMoE, which capitalizes on modular skill architecture
for enhanced forward transfer in neural networks. Unlike prior models that
depend on explicit task identification inputs, OrchMoE automatically discerns
task categories, streamlining the learning process. This is achieved through an
integrated mechanism comprising an Automatic Task Classification module and a
Task-Skill Allocation module, which collectively deduce task-specific
classifications and tailor skill allocation matrices. Our extensive evaluations
on the &apos;Super Natural Instructions&apos; dataset, featuring 1,600 diverse
instructional tasks, indicate that OrchMoE substantially outperforms comparable
multi-adapter baselines in terms of both performance and sample utilization
efficiency, all while operating within the same parameter constraints. These
findings suggest that OrchMoE offers a significant leap forward in multi-task
learning efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haowen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_K/0/1/0/all/0/1&quot;&gt;Kaixiang Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1&quot;&gt;Cong Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jinjie Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10566">
<title>Robust Multi-Modal Density Estimation. (arXiv:2401.10566v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10566</link>
<description rdf:parseType="Literal">&lt;p&gt;Development of multi-modal, probabilistic prediction models has lead to a
need for comprehensive evaluation metrics. While several metrics can
characterize the accuracy of machine-learned models (e.g., negative
log-likelihood, Jensen-Shannon divergence), these metrics typically operate on
probability densities. Applying them to purely sample-based prediction models
thus requires that the underlying density function is estimated. However,
common methods such as kernel density estimation (KDE) have been demonstrated
to lack robustness, while more complex methods have not been evaluated in
multi-modal estimation problems. In this paper, we present ROME (RObust
Multi-modal density Estimator), a non-parametric approach for density
estimation which addresses the challenge of estimating multi-modal, non-normal,
and highly correlated distributions. ROME utilizes clustering to segment a
multi-modal set of samples into multiple uni-modal ones and then combines
simple KDE estimates obtained for individual clusters in a single multi-modal
estimate. We compared our approach to state-of-the-art methods for density
estimation as well as ablations of ROME, showing that it not only outperforms
established methods but is also more robust to a variety of distributions. Our
results demonstrate that ROME can overcome the issues of over-fitting and
over-smoothing exhibited by other estimators, promising a more robust
evaluation of probabilistic machine learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meszaros_A/0/1/0/all/0/1&quot;&gt;Anna M&amp;#xe9;sz&amp;#xe1;ros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schumann_J/0/1/0/all/0/1&quot;&gt;Julian F. Schumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alonso_Mora_J/0/1/0/all/0/1&quot;&gt;Javier Alonso-Mora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zgonnikov_A/0/1/0/all/0/1&quot;&gt;Arkady Zgonnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kober_J/0/1/0/all/0/1&quot;&gt;Jens Kober&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10586">
<title>PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks. (arXiv:2401.10586v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.10586</link>
<description rdf:parseType="Literal">&lt;p&gt;Black-box query-based attacks constitute significant threats to Machine
Learning as a Service (MLaaS) systems since they can generate adversarial
examples without accessing the target model&apos;s architecture and parameters.
Traditional defense mechanisms, such as adversarial training, gradient masking,
and input transformations, either impose substantial computational costs or
compromise the test accuracy of non-adversarial inputs. To address these
challenges, we propose an efficient defense mechanism, PuriDefense, that
employs random patch-wise purifications with an ensemble of lightweight
purification models at a low level of inference cost. These models leverage the
local implicit function and rebuild the natural image manifold. Our theoretical
analysis suggests that this approach slows down the convergence of query-based
attacks by incorporating randomness into purifications. Extensive experiments
on CIFAR-10 and ImageNet validate the effectiveness of our proposed
purifier-based defense mechanism, demonstrating significant improvements in
robustness against query-based attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1&quot;&gt;Ping Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qingchuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qingfu Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10590">
<title>Adversarially Robust Signed Graph Contrastive Learning from Balance Augmentation. (arXiv:2401.10590v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10590</link>
<description rdf:parseType="Literal">&lt;p&gt;Signed graphs consist of edges and signs, which can be separated into
structural information and balance-related information, respectively. Existing
signed graph neural networks (SGNNs) typically rely on balance-related
information to generate embeddings. Nevertheless, the emergence of recent
adversarial attacks has had a detrimental impact on the balance-related
information. Similar to how structure learning can restore unsigned graphs,
balance learning can be applied to signed graphs by improving the balance
degree of the poisoned graph. However, this approach encounters the challenge
&quot;Irreversibility of Balance-related Information&quot; - while the balance degree
improves, the restored edges may not be the ones originally affected by
attacks, resulting in poor defense effectiveness. To address this challenge, we
propose a robust SGNN framework called Balance Augmented-Signed Graph
Contrastive Learning (BA-SGCL), which combines Graph Contrastive Learning
principles with balance augmentation techniques. Experimental results
demonstrate that BA-SGCL not only enhances robustness against existing
adversarial attacks but also achieves superior performance on link sign
prediction task across various datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jialong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ai_X/0/1/0/all/0/1&quot;&gt;Xing Ai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1&quot;&gt;Yuni Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1&quot;&gt;Kai Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10603">
<title>ZnTrack -- Data as Code. (arXiv:2401.10603v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2401.10603</link>
<description rdf:parseType="Literal">&lt;p&gt;The past decade has seen tremendous breakthroughs in computation and there is
no indication that this will slow any time soon. Machine learning, large-scale
computing resources, and increased industry focus have resulted in rising
investments in computer-driven solutions for data management, simulations, and
model generation. However, with this growth in computation has come an even
larger expansion of data and with it, complexity in data storage, sharing, and
tracking. In this work, we introduce ZnTrack, a Python-driven data versioning
tool. ZnTrack builds upon established version control systems to provide a
user-friendly and easy-to-use interface for tracking parameters in experiments,
designing workflows, and storing and sharing data. From this ability to reduce
large datasets to a simple Python script emerges the concept of Data as Code, a
core component of the work presented here and an undoubtedly important concept
as the age of computation continues to evolve. ZnTrack offers an open-source,
FAIR data compatible Python package to enable users to harness these concepts
of the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zills_F/0/1/0/all/0/1&quot;&gt;Fabian Zills&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schafer_M/0/1/0/all/0/1&quot;&gt;Moritz Sch&amp;#xe4;fer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tovey_S/0/1/0/all/0/1&quot;&gt;Samuel Tovey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kastner_J/0/1/0/all/0/1&quot;&gt;Johannes K&amp;#xe4;stner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holm_C/0/1/0/all/0/1&quot;&gt;Christian Holm&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10620">
<title>Polytopic Autoencoders with Smooth Clustering for Reduced-order Modelling of Flows. (arXiv:2401.10620v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10620</link>
<description rdf:parseType="Literal">&lt;p&gt;With the advancement of neural networks, there has been a notable increase,
both in terms of quantity and variety, in research publications concerning the
application of autoencoders to reduced-order models. We propose a polytopic
autoencoder architecture that includes a lightweight nonlinear encoder, a
convex combination decoder, and a smooth clustering network. Supported by
several proofs, the model architecture ensures that all reconstructed states
lie within a polytope, accompanied by a metric indicating the quality of the
constructed polytopes, referred to as polytope error. Additionally, it offers a
minimal number of convex coordinates for polytopic linear-parameter varying
systems while achieving acceptable reconstruction errors compared to proper
orthogonal decomposition (POD). To validate our proposed model, we conduct
simulations involving two flow scenarios with the incompressible Navier-Stokes
equation. Numerical results demonstrate the guaranteed properties of the model,
low reconstruction errors compared to POD, and the improvement in error using a
clustering network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heiland_J/0/1/0/all/0/1&quot;&gt;Jan Heiland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yongho Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10632">
<title>Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization Approach. (arXiv:2401.10632v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10632</link>
<description rdf:parseType="Literal">&lt;p&gt;Fair machine learning aims to prevent discrimination against individuals or
sub-populations based on sensitive attributes such as gender and race. In
recent years, causal inference methods have been increasingly used in fair
machine learning to measure unfairness by causal effects. However, current
methods assume that the true causal graph is given, which is often not true in
real-world applications. To address this limitation, this paper proposes a
framework for achieving causal fairness based on the notion of interventions
when the true causal graph is partially known. The proposed approach involves
modeling fair prediction using a Partially Directed Acyclic Graph (PDAG),
specifically, a class of causal DAGs that can be learned from observational
data combined with domain knowledge. The PDAG is used to measure causal
fairness, and a constrained optimization problem is formulated to balance
between fairness and accuracy. Results on both simulated and real-world
datasets demonstrate the effectiveness of this method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_A/0/1/0/all/0/1&quot;&gt;Aoqi Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yiqing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1&quot;&gt;Susan Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1&quot;&gt;Mingming Gong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10637">
<title>Towards Universal Unsupervised Anomaly Detection in Medical Imaging. (arXiv:2401.10637v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2401.10637</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing complexity of medical imaging data underscores the need for
advanced anomaly detection methods to automatically identify diverse
pathologies. Current methods face challenges in capturing the broad spectrum of
anomalies, often limiting their use to specific lesion types in brain scans. To
address this challenge, we introduce a novel unsupervised approach, termed
\textit{Reversed Auto-Encoders (RA)}, designed to create realistic
pseudo-healthy reconstructions that enable the detection of a wider range of
pathologies. We evaluate the proposed method across various imaging modalities,
including magnetic resonance imaging (MRI) of the brain, pediatric wrist X-ray,
and chest X-ray, and demonstrate superior performance in detecting anomalies
compared to existing state-of-the-art methods. Our unsupervised anomaly
detection approach may enhance diagnostic accuracy in medical imaging by
identifying a broader range of unknown pathologies. Our code is publicly
available at: \url{https://github.com/ci-ber/RA}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bercea_C/0/1/0/all/0/1&quot;&gt;Cosmin I. Bercea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wiestler_B/0/1/0/all/0/1&quot;&gt;Benedikt Wiestler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1&quot;&gt;Daniel Rueckert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Schnabel_J/0/1/0/all/0/1&quot;&gt;Julia A. Schnabel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10643">
<title>A Comprehensive Survey on Deep-Learning-based Vehicle Re-Identification: Models, Data Sets and Challenges. (arXiv:2401.10643v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10643</link>
<description rdf:parseType="Literal">&lt;p&gt;Vehicle re-identification (ReID) endeavors to associate vehicle images
collected from a distributed network of cameras spanning diverse traffic
environments. This task assumes paramount importance within the spectrum of
vehicle-centric technologies, playing a pivotal role in deploying Intelligent
Transportation Systems (ITS) and advancing smart city initiatives. Rapid
advancements in deep learning have significantly propelled the evolution of
vehicle ReID technologies in recent years. Consequently, undertaking a
comprehensive survey of methodologies centered on deep learning for vehicle
re-identification has become imperative and inescapable. This paper extensively
explores deep learning techniques applied to vehicle ReID. It outlines the
categorization of these methods, encompassing supervised and unsupervised
approaches, delves into existing research within these categories, introduces
datasets and evaluation criteria, and delineates forthcoming challenges and
potential research directions. This comprehensive assessment examines the
landscape of deep learning in vehicle ReID and establishes a foundation and
starting point for future works. It aims to serve as a complete reference by
highlighting challenges and emerging trends, fostering advancements and
applications in vehicle ReID utilizing deep learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amiri_A/0/1/0/all/0/1&quot;&gt;Ali Amiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaya_A/0/1/0/all/0/1&quot;&gt;Aydin Kaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keceli_A/0/1/0/all/0/1&quot;&gt;Ali Seydi Keceli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10646">
<title>Empowering HWNs with Efficient Data Labeling: A Clustered Federated Semi-Supervised Learning Approach. (arXiv:2401.10646v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2401.10646</link>
<description rdf:parseType="Literal">&lt;p&gt;Clustered Federated Multitask Learning (CFL) has gained considerable
attention as an effective strategy for overcoming statistical challenges,
particularly when dealing with non independent and identically distributed (non
IID) data across multiple users. However, much of the existing research on CFL
operates under the unrealistic premise that devices have access to accurate
ground truth labels. This assumption becomes especially problematic in
hierarchical wireless networks (HWNs), where edge networks contain a large
amount of unlabeled data, resulting in slower convergence rates and increased
processing times, particularly when dealing with two layers of model
aggregation. To address these issues, we introduce a novel framework, Clustered
Federated Semi-Supervised Learning (CFSL), designed for more realistic HWN
scenarios. Our approach leverages a best-performing specialized model
algorithm, wherein each device is assigned a specialized model that is highly
adept at generating accurate pseudo-labels for unlabeled data, even when the
data stems from diverse environments. We validate the efficacy of CFSL through
extensive experiments, comparing it with existing methods highlighted in recent
literature. Our numerical results demonstrate that CFSL significantly improves
upon key metrics such as testing accuracy, labeling accuracy, and labeling
latency under varying proportions of labeled and unlabeled data while also
accommodating the non-IID nature of the data and the unique characteristics of
wireless edge networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamood_M/0/1/0/all/0/1&quot;&gt;Moqbel Hamood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albaseer_A/0/1/0/all/0/1&quot;&gt;Abdullatif Albaseer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdallah_M/0/1/0/all/0/1&quot;&gt;Mohamed Abdallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Fuqaha_A/0/1/0/all/0/1&quot;&gt;Ala Al-Fuqaha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10648">
<title>Area Modeling using Stay Information for Large-Scale Users and Analysis for Influence of COVID-19. (arXiv:2401.10648v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10648</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding how people use area in a city can be a valuable information in
a wide range of fields, from marketing to urban planning. Area usage is subject
to change over time due to various events including seasonal shifts and
pandemics. Before the spread of smartphones, this data had been collected
through questionnaire survey. However, this is not a sustainable approach in
terms of time to results and cost. There are many existing studies on area
modeling, which characterize an area with some kind of information, using Point
of Interest (POI) or inter-area movement data. However, since POI is data that
is statically tied to space, and inter-area movement data ignores the behavior
of people within an area, existing methods are not sufficient in terms of
capturing area usage changes. In this paper, we propose a novel area modeling
method named Area2Vec, inspired by Word2Vec, which models areas based on
people&apos;s location data. This method is based on the discovery that it is
possible to characterize an area based on its usage by using people&apos;s stay
information in the area. And it is a novel method that can reflect the
dynamically changing people&apos;s behavior in an area in the modeling results. We
validated Area2vec by performing a functional classification of areas in a
district of Japan. The results show that Area2Vec can be usable in general area
analysis. We also investigated area usage changes due to COVID-19 in two
districts in Japan. We could find that COVID-19 made people refrain from
unnecessary going out, such as visiting entertainment areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shoji_K/0/1/0/all/0/1&quot;&gt;Kazuyuki Shoji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aoki_S/0/1/0/all/0/1&quot;&gt;Shunsuke Aoki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yonezawa_T/0/1/0/all/0/1&quot;&gt;Takuro Yonezawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawaguchi_N/0/1/0/all/0/1&quot;&gt;Nobuo Kawaguchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10652">
<title>AutoChunk: Automated Activation Chunk for Memory-Efficient Long Sequence Inference. (arXiv:2401.10652v1 [cs.PF])</title>
<link>http://arxiv.org/abs/2401.10652</link>
<description rdf:parseType="Literal">&lt;p&gt;Large deep learning models have achieved impressive performance across a
range of applications. However, their large memory requirements, including
parameter memory and activation memory, have become a significant challenge for
their practical serving. While existing methods mainly address parameter
memory, the importance of activation memory has been overlooked. Especially for
long input sequences, activation memory is expected to experience a significant
exponential growth as the length of sequences increases. In this approach, we
propose AutoChunk, an automatic and adaptive compiler system that efficiently
reduces activation memory for long sequence inference by chunk strategies. The
proposed system generates chunk plans by optimizing through multiple stages. In
each stage, the chunk search pass explores all possible chunk candidates and
the chunk selection pass identifies the optimal one. At runtime, AutoChunk
employs code generation to automatically apply chunk strategies. The
experiments demonstrate that AutoChunk can reduce over 80\% of activation
memory while maintaining speed loss within 10%, extend max sequence length by
3.2x to 11.7x, and outperform state-of-the-art methods by a large margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xuanlei Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Shenggan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1&quot;&gt;Guangyang Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1&quot;&gt;Jiarui Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Haotian Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_B/0/1/0/all/0/1&quot;&gt;Bin Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Ziming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1&quot;&gt;Yang You&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10653">
<title>Attentive Fusion: A Transformer-based Approach to Multimodal Hate Speech Detection. (arXiv:2401.10653v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.10653</link>
<description rdf:parseType="Literal">&lt;p&gt;With the recent surge and exponential growth of social media usage,
scrutinizing social media content for the presence of any hateful content is of
utmost importance. Researchers have been diligently working since the past
decade on distinguishing between content that promotes hatred and content that
does not. Traditionally, the main focus has been on analyzing textual content.
However, recent research attempts have also commenced into the identification
of audio-based content. Nevertheless, studies have shown that relying solely on
audio or text-based content may be ineffective, as recent upsurge indicates
that individuals often employ sarcasm in their speech and writing. To overcome
these challenges, we present an approach to identify whether a speech promotes
hate or not utilizing both audio and textual representations. Our methodology
is based on the Transformer framework that incorporates both audio and text
sampling, accompanied by our very own layer called &quot;Attentive Fusion&quot;. The
results of our study surpassed previous state-of-the-art techniques, achieving
an impressive macro F1 score of 0.927 on the Test Set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandal_A/0/1/0/all/0/1&quot;&gt;Atanu Mandal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_G/0/1/0/all/0/1&quot;&gt;Gargi Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barman_A/0/1/0/all/0/1&quot;&gt;Amit Barman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutta_I/0/1/0/all/0/1&quot;&gt;Indranil Dutta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naskar_S/0/1/0/all/0/1&quot;&gt;Sudip Kumar Naskar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10657">
<title>FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks. (arXiv:2401.10657v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10657</link>
<description rdf:parseType="Literal">&lt;p&gt;With the steady rise of the use of AI in bio-technical applications and the
widespread adoption of genomics sequencing, an increasing amount of AI-based
algorithms and tools is entering the research and production stage affecting
critical decision-making streams like drug discovery and clinical outcomes.
This paper demonstrates the vulnerability of AI models often utilized
downstream tasks on recognized public genomics datasets. We undermine model
robustness by deploying an attack that focuses on input transformation while
mimicking the real data and confusing the model decision-making, ultimately
yielding a pronounced deterioration in model performance. Further, we enhance
our approach by generating poisoned data using a variational autoencoder-based
model. Our empirical findings unequivocally demonstrate a decline in model
performance, underscored by diminished accuracy and an upswing in false
positives and false negatives. Furthermore, we analyze the resulting
adversarial samples via spectral analysis yielding conclusions for
countermeasures against such attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skovorodnikov_H/0/1/0/all/0/1&quot;&gt;Heorhii Skovorodnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alkhzaimi_H/0/1/0/all/0/1&quot;&gt;Hoda Alkhzaimi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10674">
<title>Deep Learning-based Embedded Intrusion Detection System for Automotive CAN. (arXiv:2401.10674v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.10674</link>
<description rdf:parseType="Literal">&lt;p&gt;Rising complexity of in-vehicle electronics is enabling new capabilities like
autonomous driving and active safety. However, rising automation also increases
risk of security threats which is compounded by lack of in-built security
measures in legacy networks like CAN, allowing attackers to observe, tamper and
modify information shared over such broadcast networks. Various intrusion
detection approaches have been proposed to detect and tackle such threats, with
machine learning models proving highly effective. However, deploying machine
learning models will require high processing power through high-end processors
or GPUs to perform them close to line rate. In this paper, we propose a hybrid
FPGA-based ECU approach that can transparently integrate IDS functionality
through a dedicated off-the-shelf hardware accelerator that implements a
deep-CNN intrusion detection model. Our results show that the proposed approach
provides an average accuracy of over 99% across multiple attack datasets with
0.64% false detection rates while consuming 94% less energy and achieving 51.8%
reduction in per-message processing latency when compared to IDS
implementations on GPUs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khandelwal_S/0/1/0/all/0/1&quot;&gt;Shashwat Khandelwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wadhwa_E/0/1/0/all/0/1&quot;&gt;Eashan Wadhwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shanker_S/0/1/0/all/0/1&quot;&gt;Shreejith Shanker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10685">
<title>Towards End-to-End GPS Localization with Neural Pseudorange Correction. (arXiv:2401.10685v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10685</link>
<description rdf:parseType="Literal">&lt;p&gt;Pseudorange errors are the root cause of localization inaccuracy in GPS.
Previous data-driven methods regress and eliminate pseudorange errors using
handcrafted intermediate labels. Unlike them, we propose an end-to-end GPS
localization framework, E2E-PrNet, to train a neural network for pseudorange
correction (PrNet) directly using the final task loss calculated with the
ground truth of GPS receiver states. The gradients of the loss with respect to
learnable parameters are backpropagated through a differentiable nonlinear
least squares optimizer to PrNet. The feasibility is verified with GPS data
collected by Android phones, showing that E2E-PrNet outperforms the
state-of-the-art end-to-end GPS localization methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_X/0/1/0/all/0/1&quot;&gt;Xu Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_K/0/1/0/all/0/1&quot;&gt;KV Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haochen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_K/0/1/0/all/0/1&quot;&gt;Kun Cao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10686">
<title>Manipulating Sparse Double Descent. (arXiv:2401.10686v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10686</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates the double descent phenomenon in two-layer neural
networks, focusing on the role of L1 regularization and representation
dimensions. It explores an alternative double descent phenomenon, named sparse
double descent. The study emphasizes the complex relationship between model
complexity, sparsity, and generalization, and suggests further research into
more diverse models and datasets. The findings contribute to a deeper
understanding of neural network training and optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Ya Shi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10689">
<title>A Lightweight Multi-Attack CAN Intrusion Detection System on Hybrid FPGAs. (arXiv:2401.10689v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.10689</link>
<description rdf:parseType="Literal">&lt;p&gt;Rising connectivity in vehicles is enabling new capabilities like connected
autonomous driving and advanced driver assistance systems (ADAS) for improving
the safety and reliability of next-generation vehicles. This increased access
to in-vehicle functions compromises critical capabilities that use legacy
invehicle networks like Controller Area Network (CAN), which has no inherent
security or authentication mechanism. Intrusion detection and mitigation
approaches, particularly using machine learning models, have shown promising
results in detecting multiple attack vectors in CAN through their ability to
generalise to new vectors. However, most deployments require dedicated
computing units like GPUs to perform line-rate detection, consuming much higher
power. In this paper, we present a lightweight multi-attack quantised machine
learning model that is deployed using Xilinx&apos;s Deep Learning Processing Unit IP
on a Zynq Ultrascale+ (XCZU3EG) FPGA, which is trained and validated using the
public CAN Intrusion Detection dataset. The quantised model detects denial of
service and fuzzing attacks with an accuracy of above 99 % and a false positive
rate of 0.07%, which are comparable to the state-of-the-art techniques in the
literature. The Intrusion Detection System (IDS) execution consumes just 2.0 W
with software tasks running on the ECU and achieves a 25 % reduction in
per-message processing latency over the state-of-the-art implementations. This
deployment allows the ECU function to coexist with the IDS with minimal changes
to the tasks, making it ideal for real-time IDS in in-vehicle systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khandelwal_S/0/1/0/all/0/1&quot;&gt;Shashwat Khandelwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shanker_S/0/1/0/all/0/1&quot;&gt;Shreejith Shanker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10690">
<title>Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models. (arXiv:2401.10690v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10690</link>
<description rdf:parseType="Literal">&lt;p&gt;Dyadic regression models, which predict real-valued outcomes for pairs of
entities, are fundamental in many domains (e.g. predicting the rating of a user
to a product in Recommender Systems) and promising and under exploration in
many others (e.g. approximating the adequate dosage of a drug for a patient in
personalized pharmacology). In this work, we demonstrate that non-uniformity in
the observed value distributions of individual entities leads to severely
biased predictions in state-of-the-art models, skewing predictions towards the
average of observed past values for the entity and providing worse-than-random
predictive power in eccentric yet equally important cases. We show that the
usage of global error metrics like Root Mean Squared Error (RMSE) and Mean
Absolute Error (MAE) is insufficient to capture this phenomenon, which we name
eccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as
a new complementary metric that can quantify it in all studied models and
datasets. We also prove the adequateness of EAUC by using naive de-biasing
corrections to demonstrate that a lower model bias correlates with a lower EAUC
and vice-versa. This work contributes a bias-aware evaluation of dyadic
regression models to avoid potential unfairness and risks in critical
real-world applications of such systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paz_Ruza_J/0/1/0/all/0/1&quot;&gt;Jorge Paz-Ruza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alonso_Betanzos_A/0/1/0/all/0/1&quot;&gt;Amparo Alonso-Betanzos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guijarro_Berdinas_B/0/1/0/all/0/1&quot;&gt;Bertha Guijarro-Berdi&amp;#xf1;as&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cancela_B/0/1/0/all/0/1&quot;&gt;Brais Cancela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eiras_Franco_C/0/1/0/all/0/1&quot;&gt;Carlos Eiras-Franco&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10700">
<title>Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model. (arXiv:2401.10700v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10700</link>
<description rdf:parseType="Literal">&lt;p&gt;Safe offline RL is a promising way to bypass risky online interactions
towards safe policy learning. Most existing methods only enforce soft
constraints, i.e., constraining safety violations in expectation below
thresholds predetermined. This can lead to potentially unsafe outcomes, thus
unacceptable in safety-critical scenarios. An alternative is to enforce the
hard constraint of zero violation. However, this can be challenging in offline
setting, as it needs to strike the right balance among three highly intricate
and correlated aspects: safety constraint satisfaction, reward maximization,
and behavior regularization imposed by offline datasets. Interestingly, we
discover that via reachability analysis of safe-control theory, the hard safety
constraint can be equivalently translated to identifying the largest feasible
region given the offline dataset. This seamlessly converts the original trilogy
problem to a feasibility-dependent objective, i.e., maximizing reward value
within the feasible region while minimizing safety risks in the infeasible
region. Inspired by these, we propose FISOR (FeasIbility-guided Safe Offline
RL), which allows safety constraint adherence, reward maximization, and offline
policy learning to be realized via three decoupled processes, while offering
strong safety performance and stability. In FISOR, the optimal policy for the
translated optimization problem can be derived in a special form of weighted
behavior cloning. Thus, we propose a novel energy-guided diffusion model that
does not require training a complicated time-dependent classifier to extract
the policy, greatly simplifying the training. We compare FISOR against
baselines on DSRL benchmark for safe offline RL. Evaluation results show that
FISOR is the only method that can guarantee safety satisfaction in all tasks,
while achieving top returns in most tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yinan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianxiong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1&quot;&gt;Dongjie Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yujie Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shengbo Eben Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1&quot;&gt;Xianyuan Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingjing Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10710">
<title>Classification with neural networks with quadratic decision functions. (arXiv:2401.10710v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10710</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network with quadratic decision functions have been introduced as
alternatives to standard neural networks with affine linear one. They are
advantageous when the objects to be identified are of compact basic geometries
like circles, ellipsis etc. In this paper we investigate the use of such ansatz
functions for classification. In particular we test and compare the algorithm
on the MNIST dataset for classification of handwritten digits and for
classification of subspecies. We also show, that the implementation can be
based on the neural network structure in the software Tensorflow and Keras,
respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frischauf_L/0/1/0/all/0/1&quot;&gt;Leon Frischauf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scherzer_O/0/1/0/all/0/1&quot;&gt;Otmar Scherzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1&quot;&gt;Cong Shi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10721">
<title>Generative Model for Constructing Reaction Path from Initial to Final States. (arXiv:2401.10721v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/2401.10721</link>
<description rdf:parseType="Literal">&lt;p&gt;Mapping out reaction pathways and their corresponding activation barriers is
a significant aspect of molecular simulation. Given their inherent complexity
and nonlinearity, even generating a initial guess of these paths remains a
challenging problem. Presented in this paper is an innovative approach that
utilizes neural networks to generate initial guess for these reaction pathways.
The proposed method is initiated by inputting the coordinates of the initial
state, followed by progressive alterations to its structure. This iterative
process culminates in the generation of the approximate representation of the
reaction path and the coordinates of the final state. The application of this
method extends to complex reaction pathways illustrated by organic reactions.
Training was executed on the Transition1x dataset, an organic reaction pathway
dataset. The results revealed generation of reactions that bore substantial
similarities with the corresponding test data. The method&apos;s flexibility allows
for reactions to be generated either to conform to predetermined conditions or
in a randomized manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hayashi_A/0/1/0/all/0/1&quot;&gt;Akihide Hayashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Takamoto_S/0/1/0/all/0/1&quot;&gt;So Takamoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Ju Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Okanohara_D/0/1/0/all/0/1&quot;&gt;Daisuke Okanohara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10724">
<title>Real-Time Zero-Day Intrusion Detection System for Automotive Controller Area Network on FPGAs. (arXiv:2401.10724v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.10724</link>
<description rdf:parseType="Literal">&lt;p&gt;Increasing automation in vehicles enabled by increased connectivity to the
outside world has exposed vulnerabilities in previously siloed automotive
networks like controller area networks (CAN). Attributes of CAN such as
broadcast-based communication among electronic control units (ECUs) that
lowered deployment costs are now being exploited to carry out active injection
attacks like denial of service (DoS), fuzzing, and spoofing attacks. Research
literature has proposed multiple supervised machine learning models deployed as
Intrusion detection systems (IDSs) to detect such malicious activity; however,
these are largely limited to identifying previously known attack vectors. With
the ever-increasing complexity of active injection attacks, detecting zero-day
(novel) attacks in these networks in real-time (to prevent propagation) becomes
a problem of particular interest. This paper presents an
unsupervised-learning-based convolutional autoencoder architecture for
detecting zero-day attacks, which is trained only on benign (attack-free) CAN
messages. We quantise the model using Vitis-AI tools from AMD/Xilinx targeting
a resource-constrained Zynq Ultrascale platform as our IDS-ECU system for
integration. The proposed model successfully achieves equal or higher
classification accuracy (&amp;gt; 99.5%) on unseen DoS, fuzzing, and spoofing attacks
from a publicly available attack dataset when compared to the state-of-the-art
unsupervised learning-based IDSs. Additionally, by cleverly overlapping IDS
operation on a window of CAN messages with the reception, the model is able to
meet line-rate detection (0.43 ms per window) of high-speed CAN, which when
coupled with the low energy consumption per inference, makes this architecture
ideally suited for detecting zero-day attacks on critical CAN networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khandelwal_S/0/1/0/all/0/1&quot;&gt;Shashwat Khandelwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shanker_S/0/1/0/all/0/1&quot;&gt;Shreejith Shanker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10726">
<title>Empowering Aggregators with Practical Data-Driven Tools: Harnessing Aggregated and Disaggregated Flexibility for Demand Response. (arXiv:2401.10726v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2401.10726</link>
<description rdf:parseType="Literal">&lt;p&gt;This study explores the crucial interplay between aggregators and building
occupants in activating flexibility through Demand Response (DR) programs, with
a keen focus on achieving robust decarbonization and fortifying the resilience
of the energy system amidst the uncertainties presented by Renewable Energy
Sources (RES). Firstly, it introduces a methodology of optimizing aggregated
flexibility provision strategies in environments with limited data, utilizing
Discrete Fourier Transformation (DFT) and clustering techniques to identify
building occupant&apos;s activity patterns. Secondly, the study assesses the
disaggregated flexibility provision of Heating Ventilation and Air Conditioning
(HVAC) systems during DR events, employing machine learning and optimization
techniques for precise, device-level analysis. The first approach offers a
non-intrusive pathway for aggregators to provide flexibility services in
environments of a single smart meter for the whole building&apos;s consumption,
while the second approach carefully considers building occupants&apos; thermal
comfort profiles, while maximizing flexibility in case of existence of
dedicated smart meters to the HVAC systems. Through the application of
data-driven techniques and encompassing case studies from both industrial and
residential buildings, this paper not only unveils pivotal opportunities for
aggregators in the balancing and emerging flexibility markets but also
successfully develops end-to-end practical tools for aggregators. Furthermore,
the efficacy of this tool is validated through detailed case studies,
substantiating its operational capability and contributing to the evolution of
a resilient and efficient energy system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mylonas_C/0/1/0/all/0/1&quot;&gt;Costas Mylonas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Boric_D/0/1/0/all/0/1&quot;&gt;Donata Boric&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Maric_L/0/1/0/all/0/1&quot;&gt;Leila Luttenberger Maric&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tsitsanis_A/0/1/0/all/0/1&quot;&gt;Alexandros Tsitsanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Petrianou_E/0/1/0/all/0/1&quot;&gt;Eleftheria Petrianou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Foti_M/0/1/0/all/0/1&quot;&gt;Magda Foti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10745">
<title>Ethical Artificial Intelligence Principles and Guidelines for the Governance and Utilization of Highly Advanced Large Language Models. (arXiv:2401.10745v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2401.10745</link>
<description rdf:parseType="Literal">&lt;p&gt;Given the success of ChatGPT, LaMDA and other large language models (LLMs),
there has been an increase in development and usage of LLMs within the
technology sector and other sectors. While the level in which LLMs has not
reached a level where it has surpassed human intelligence, there will be a time
when it will. Such LLMs can be referred to as advanced LLMs. Currently, there
are limited usage of ethical artificial intelligence (AI) principles and
guidelines addressing advanced LLMs due to the fact that we have not reached
that point yet. However, this is a problem as once we do reach that point, we
will not be adequately prepared to deal with the aftermath of it in an ethical
and optimal way, which will lead to undesired and unexpected consequences. This
paper addresses this issue by discussing what ethical AI principles and
guidelines can be used to address highly advanced LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hossain_S/0/1/0/all/0/1&quot;&gt;Soaad Hossain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1&quot;&gt;Syed Ishtiaque Ahmed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10746">
<title>A Systematic Evaluation of Euclidean Alignment with Deep Learning for EEG Decoding. (arXiv:2401.10746v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.10746</link>
<description rdf:parseType="Literal">&lt;p&gt;Electroencephalography (EEG) signals are frequently used for various
Brain-Computer Interface (BCI) tasks. While Deep Learning (DL) techniques have
shown promising results, they are hindered by the substantial data
requirements. By leveraging data from multiple subjects, transfer learning
enables more effective training of DL models. A technique that is gaining
popularity is Euclidean Alignment (EA) due to its ease of use, low
computational complexity, and compatibility with Deep Learning models. However,
few studies evaluate its impact on the training performance of shared and
individual DL models. In this work, we systematically evaluate the effect of EA
combined with DL for decoding BCI signals. We used EA to train shared models
with data from multiple subjects and evaluated its transferability to new
subjects. Our experimental results show that it improves decoding in the target
subject by 4.33% and decreases convergence time by more than 70%. We also
trained individual models for each subject to use as a majority-voting ensemble
classifier. In this scenario, using EA improved the 3-model ensemble accuracy
by 3.7%. However, when compared to the shared model with EA, the ensemble
accuracy was 3.62% lower.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Junqueira_B/0/1/0/all/0/1&quot;&gt;Bruna Junqueira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Aristimunha_B/0/1/0/all/0/1&quot;&gt;Bruno Aristimunha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chevallier_S/0/1/0/all/0/1&quot;&gt;Sylvain Chevallier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Camargo_R/0/1/0/all/0/1&quot;&gt;Raphael Y. de Camargo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10747">
<title>Multimodal Sentiment Analysis with Missing Modality: A Knowledge-Transfer Approach. (arXiv:2401.10747v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2401.10747</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal sentiment analysis aims to identify the emotions expressed by
individuals through visual, language, and acoustic cues. However, most of the
existing research efforts assume that all modalities are available during both
training and testing, making their algorithms susceptible to the missing
modality scenario. In this paper, we propose a novel knowledge-transfer network
to translate between different modalities to reconstruct the missing audio
modalities. Moreover, we develop a cross-modality attention mechanism to retain
the maximal information of the reconstructed and observed modalities for
sentiment prediction. Extensive experiments on three publicly available
datasets demonstrate significant improvements over baselines and achieve
comparable results to the previous methods with complete multi-modality
supervision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weide Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1&quot;&gt;Huijing Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_F/0/1/0/all/0/1&quot;&gt;Fengmao Lv&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10748">
<title>Fast gradient-free activation maximization for neurons in spiking neural networks. (arXiv:2401.10748v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2401.10748</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks (NNs), both living and artificial, work due to being complex
systems of neurons, each having its own specialization. Revealing these
specializations is important for understanding NNs inner working mechanisms.
The only way to do this for a living system, the neural response of which to a
stimulus is not a known (let alone differentiable) function is to build a
feedback loop of exposing it to stimuli, the properties of which can be
iteratively varied aiming in the direction of maximal response. To test such a
loop on a living network, one should first learn how to run it quickly and
efficiently, reaching most effective stimuli (ones that maximize certain
neurons activation) in least possible number of iterations. We present a
framework with an effective design of such a loop, successfully testing it on
an artificial spiking neural network (SNN, a model that mimics the behaviour of
NNs in living brains). Our optimization method used for activation maximization
(AM) was based on low-rank tensor decomposition (Tensor Train, TT) of the
activation function&apos;s discretization over its domain the latent parameter space
of stimuli (CIFAR10-size color images, generated by either VQ-VAE or SN-GAN
from their latent description vectors, fed to the SNN). To our knowledge, the
present work is the first attempt to perform effective AM for SNNs. The source
code of our framework, MANGO (for Maximization of neural Activation via
Non-Gradient Optimization) is available on GitHub.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pospelov_N/0/1/0/all/0/1&quot;&gt;Nikita Pospelov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chertkov_A/0/1/0/all/0/1&quot;&gt;Andrei Chertkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beketov_M/0/1/0/all/0/1&quot;&gt;Maxim Beketov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1&quot;&gt;Ivan Oseledets&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anokhin_K/0/1/0/all/0/1&quot;&gt;Konstantin Anokhin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10749">
<title>ReliCD: A Reliable Cognitive Diagnosis Framework with Confidence Awareness. (arXiv:2401.10749v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2401.10749</link>
<description rdf:parseType="Literal">&lt;p&gt;During the past few decades, cognitive diagnostics modeling has attracted
increasing attention in computational education communities, which is capable
of quantifying the learning status and knowledge mastery levels of students.
Indeed, the recent advances in neural networks have greatly enhanced the
performance of traditional cognitive diagnosis models through learning the deep
representations of students and exercises. Nevertheless, existing approaches
often suffer from the issue of overconfidence in predicting students&apos; mastery
levels, which is primarily caused by the unavoidable noise and sparsity in
realistic student-exercise interaction data, severely hindering the educational
application of diagnostic feedback. To address this, in this paper, we propose
a novel Reliable Cognitive Diagnosis(ReliCD) framework, which can quantify the
confidence of the diagnosis feedback and is flexible for different cognitive
diagnostic functions. Specifically, we first propose a Bayesian method to
explicitly estimate the state uncertainty of different knowledge concepts for
students, which enables the confidence quantification of diagnostic feedback.
In particular, to account for potential differences, we suggest modeling
individual prior distributions for the latent variables of different ability
concepts using a pre-trained model. Additionally, we introduce a logical
hypothesis for ranking confidence levels. Along this line, we design a novel
calibration loss to optimize the confidence parameters by modeling the process
of student performance prediction. Finally, extensive experiments on four
real-world datasets clearly demonstrate the effectiveness of our ReliCD
framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yunfei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1&quot;&gt;Chuan Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1&quot;&gt;Dazhong Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1&quot;&gt;Haiping Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Le Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xingyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hengshu Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10753">
<title>BoolGebra: Attributed Graph-learning for Boolean Algebraic Manipulation. (arXiv:2401.10753v1 [cs.AR])</title>
<link>http://arxiv.org/abs/2401.10753</link>
<description rdf:parseType="Literal">&lt;p&gt;Boolean algebraic manipulation is at the core of logic synthesis in
Electronic Design Automation (EDA) design flow. Existing methods struggle to
fully exploit optimization opportunities, and often suffer from an explosive
search space and limited scalability efficiency. This work presents BoolGebra,
a novel attributed graph-learning approach for Boolean algebraic manipulation
that aims to improve fundamental logic synthesis. BoolGebra incorporates Graph
Neural Networks (GNNs) and takes initial feature embeddings from both
structural and functional information as inputs. A fully connected neural
network is employed as the predictor for direct optimization result
predictions, significantly reducing the search space and efficiently locating
the optimization space. The experiments involve training the BoolGebra model
w.r.t design-specific and cross-design inferences using the trained model,
where BoolGebra demonstrates generalizability for cross-design inference and
its potential to scale from small, simple training datasets to large, complex
inference datasets. Finally, BoolGebra is integrated with existing synthesis
tool ABC to perform end-to-end logic minimization evaluation w.r.t SOTA
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingjie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agnesina_A/0/1/0/all/0/1&quot;&gt;Anthony Agnesina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yanqing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1&quot;&gt;Haoxing Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Cunxi Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10754">
<title>Data Augmentation for Traffic Classification. (arXiv:2401.10754v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10754</link>
<description rdf:parseType="Literal">&lt;p&gt;Data Augmentation (DA) -- enriching training data by adding synthetic samples
-- is a technique widely adopted in Computer Vision (CV) and Natural Language
Processing (NLP) tasks to improve models performance. Yet, DA has struggled to
gain traction in networking contexts, particularly in Traffic Classification
(TC) tasks. In this work, we fulfill this gap by benchmarking 18 augmentation
functions applied to 3 TC datasets using packet time series as input
representation and considering a variety of training conditions. Our results
show that (i) DA can reap benefits previously unexplored with (ii)
augmentations acting on time series sequence order and masking being a better
suit for TC and (iii) simple latent space analysis can provide hints about why
augmentations have positive or negative effects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finamore_A/0/1/0/all/0/1&quot;&gt;Alessandro Finamore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michiardi_P/0/1/0/all/0/1&quot;&gt;Pietro Michiardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallo_M/0/1/0/all/0/1&quot;&gt;Massimo Gallo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossi_D/0/1/0/all/0/1&quot;&gt;Dario Rossi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10765">
<title>Starlit: Privacy-Preserving Federated Learning to Enhance Financial Fraud Detection. (arXiv:2401.10765v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10765</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) is a data-minimization approach enabling
collaborative model training across diverse clients with local data, avoiding
direct data exchange. However, state-of-the-art FL solutions to identify
fraudulent financial transactions exhibit a subset of the following
limitations. They (1) lack a formal security definition and proof, (2) assume
prior freezing of suspicious customers&apos; accounts by financial institutions
(limiting the solutions&apos; adoption), (3) scale poorly, involving either $O(n^2)$
computationally expensive modular exponentiation (where $n$ is the total number
of financial institutions) or highly inefficient fully homomorphic encryption,
(4) assume the parties have already completed the identity alignment phase,
hence excluding it from the implementation, performance evaluation, and
security analysis, and (5) struggle to resist clients&apos; dropouts. This work
introduces Starlit, a novel scalable privacy-preserving FL mechanism that
overcomes these limitations. It has various applications, such as enhancing
financial fraud detection, mitigating terrorism, and enhancing digital health.
We implemented Starlit and conducted a thorough performance analysis using
synthetic data from a key player in global financial transactions. The
evaluation indicates Starlit&apos;s scalability, efficiency, and accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abadi_A/0/1/0/all/0/1&quot;&gt;Aydin Abadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doyle_B/0/1/0/all/0/1&quot;&gt;Bradley Doyle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gini_F/0/1/0/all/0/1&quot;&gt;Francesco Gini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guinamard_K/0/1/0/all/0/1&quot;&gt;Kieron Guinamard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murakonda_S/0/1/0/all/0/1&quot;&gt;Sasi Kumar Murakonda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liddell_J/0/1/0/all/0/1&quot;&gt;Jack Liddell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mellor_P/0/1/0/all/0/1&quot;&gt;Paul Mellor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murdoch_S/0/1/0/all/0/1&quot;&gt;Steven J. Murdoch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naseri_M/0/1/0/all/0/1&quot;&gt;Mohammad Naseri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Page_H/0/1/0/all/0/1&quot;&gt;Hector Page&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Theodorakopoulos_G/0/1/0/all/0/1&quot;&gt;George Theodorakopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weller_S/0/1/0/all/0/1&quot;&gt;Suzanne Weller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10774">
<title>Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads. (arXiv:2401.10774v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10774</link>
<description rdf:parseType="Literal">&lt;p&gt;The inference process in Large Language Models (LLMs) is often limited due to
the absence of parallelism in the auto-regressive decoding process, resulting
in most operations being restricted by the memory bandwidth of accelerators.
While methods such as speculative decoding have been suggested to address this
issue, their implementation is impeded by the challenges associated with
acquiring and maintaining a separate draft model. In this paper, we present
Medusa, an efficient method that augments LLM inference by adding extra
decoding heads to predict multiple subsequent tokens in parallel. Using a
tree-based attention mechanism, Medusa constructs multiple candidate
continuations and verifies them simultaneously in each decoding step. By
leveraging parallel processing, Medusa introduces only minimal overhead in
terms of single-step latency while substantially reducing the number of
decoding steps required.
&lt;/p&gt;
&lt;p&gt;We present two levels of fine-tuning procedures for Medusa to meet the needs
of different use cases: Medusa-1: Medusa is directly fine-tuned on top of a
frozen backbone LLM, enabling lossless inference acceleration. Medusa-2: Medusa
is fine-tuned together with the backbone LLM, enabling better prediction
accuracy of Medusa heads and higher speedup but needing a special training
recipe that preserves the backbone model&apos;s capabilities.
&lt;/p&gt;
&lt;p&gt;Moreover, we propose several extensions that improve or expand the utility of
Medusa, including a self-distillation to handle situations where no training
data is available and a typical acceptance scheme to boost the acceptance rate
while maintaining generation quality. We evaluate Medusa on models of various
sizes and training procedures. Our experiments demonstrate that Medusa-1 can
achieve over 2.2x speedup without compromising generation quality, while
Medusa-2 further improves the speedup to 2.3-3.6x.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1&quot;&gt;Tianle Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuhong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_Z/0/1/0/all/0/1&quot;&gt;Zhengyang Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1&quot;&gt;Hongwu Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason D. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Deming Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dao_T/0/1/0/all/0/1&quot;&gt;Tri Dao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10790">
<title>Measuring the Impact of Scene Level Objects on Object Detection: Towards Quantitative Explanations of Detection Decisions. (arXiv:2401.10790v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10790</link>
<description rdf:parseType="Literal">&lt;p&gt;Although accuracy and other common metrics can provide a useful window into
the performance of an object detection model, they lack a deeper view of the
model&apos;s decision process. Regardless of the quality of the training data and
process, the features that an object detection model learns cannot be
guaranteed. A model may learn a relationship between certain background
context, i.e., scene level objects, and the presence of the labeled classes.
Furthermore, standard performance verification and metrics would not identify
this phenomenon. This paper presents a new black box explainability method for
additional verification of object detection models by finding the impact of
scene level objects on the identification of the objects within the image. By
comparing the accuracies of a model on test data with and without certain scene
level objects, the contributions of these objects to the model&apos;s performance
becomes clearer. The experiment presented here will assess the impact of
buildings and people in image context on the detection of emergency road
vehicles by a fine-tuned YOLOv8 model. A large increase in accuracy in the
presence of a scene level object will indicate the model&apos;s reliance on that
object to make its detections. The results of this research lead to providing a
quantitative explanation of the object detection model&apos;s decision process,
enabling a deeper understanding of the model&apos;s performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haar_L/0/1/0/all/0/1&quot;&gt;Lynn Vonder Haar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elvira_T/0/1/0/all/0/1&quot;&gt;Timothy Elvira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Newcomb_L/0/1/0/all/0/1&quot;&gt;Luke Newcomb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ochoa_O/0/1/0/all/0/1&quot;&gt;Omar Ochoa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10791">
<title>Early alignment in two-layer networks training is a two-edged sword. (arXiv:2401.10791v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10791</link>
<description rdf:parseType="Literal">&lt;p&gt;Training neural networks with first order optimisation methods is at the core
of the empirical success of deep learning. The scale of initialisation is a
crucial factor, as small initialisations are generally associated to a feature
learning regime, for which gradient descent is implicitly biased towards simple
solutions. This work provides a general and quantitative description of the
early alignment phase, originally introduced by Maennel et al. (2018) . For
small initialisation and one hidden ReLU layer networks, the early stage of the
training dynamics leads to an alignment of the neurons towards key directions.
This alignment induces a sparse representation of the network, which is
directly related to the implicit bias of gradient flow at convergence. This
sparsity inducing alignment however comes at the expense of difficulties in
minimising the training objective: we also provide a simple data example for
which overparameterised networks fail to converge towards global minima and
only converge to a spurious stationary point instead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boursier_E/0/1/0/all/0/1&quot;&gt;Etienne Boursier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1&quot;&gt;Nicolas Flammarion&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10794">
<title>Deep Reinforcement Learning Empowered Activity-Aware Dynamic Health Monitoring Systems. (arXiv:2401.10794v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10794</link>
<description rdf:parseType="Literal">&lt;p&gt;In smart healthcare, health monitoring utilizes diverse tools and
technologies to analyze patients&apos; real-time biosignal data, enabling immediate
actions and interventions. Existing monitoring approaches were designed on the
premise that medical devices track several health metrics concurrently,
tailored to their designated functional scope. This means that they report all
relevant health values within that scope, which can result in excess resource
use and the gathering of extraneous data due to monitoring irrelevant health
metrics. In this context, we propose Dynamic Activity-Aware Health Monitoring
strategy (DActAHM) for striking a balance between optimal monitoring
performance and cost efficiency, a novel framework based on Deep Reinforcement
Learning (DRL) and SlowFast Model to ensure precise monitoring based on users&apos;
activities. Specifically, with the SlowFast Model, DActAHM efficiently
identifies individual activities and captures these results for enhanced
processing. Subsequently, DActAHM refines health metric monitoring in response
to the identified activity by incorporating a DRL framework. Extensive
experiments comparing DActAHM against three state-of-the-art approaches
demonstrate it achieves 27.3% higher gain than the best-performing baseline
that fixes monitoring actions over timeline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1&quot;&gt;Ziqiaing Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yulan Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1&quot;&gt;Yue Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zehui Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1&quot;&gt;Dusit Niyato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10799">
<title>Novel Representation Learning Technique using Graphs for Performance Analytics. (arXiv:2401.10799v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10799</link>
<description rdf:parseType="Literal">&lt;p&gt;The performance analytics domain in High Performance Computing (HPC) uses
tabular data to solve regression problems, such as predicting the execution
time. Existing Machine Learning (ML) techniques leverage the correlations among
features given tabular datasets, not leveraging the relationships between
samples directly. Moreover, since high-quality embeddings from raw features
improve the fidelity of the downstream predictive models, existing methods rely
on extensive feature engineering and pre-processing steps, costing time and
manual effort. To fill these two gaps, we propose a novel idea of transforming
tabular performance data into graphs to leverage the advancement of Graph
Neural Network-based (GNN) techniques in capturing complex relationships
between features and samples. In contrast to other ML application domains, such
as social networks, the graph is not given; instead, we need to build it. To
address this gap, we propose graph-building methods where nodes represent
samples, and the edges are automatically inferred iteratively based on the
similarity between the features in the samples. We evaluate the effectiveness
of the generated embeddings from GNNs based on how well they make even a simple
feed-forward neural network perform for regression tasks compared to other
state-of-the-art representation learning techniques. Our evaluation
demonstrates that even with up to 25% random missing values for each dataset,
our method outperforms commonly used graph and Deep Neural Network (DNN)-based
approaches and achieves up to 61.67% &amp;amp; 78.56% improvement in MSE loss over the
DNN baseline respectively for HPC dataset and Machine Learning Datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramadan_T/0/1/0/all/0/1&quot;&gt;Tarek Ramadan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lahiry_A/0/1/0/all/0/1&quot;&gt;Ankur Lahiry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1&quot;&gt;Tanzima Z. Islam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10800">
<title>Estimation of AMOC transition probabilities using a machine learning based rare-event algorithm. (arXiv:2401.10800v1 [physics.ao-ph])</title>
<link>http://arxiv.org/abs/2401.10800</link>
<description rdf:parseType="Literal">&lt;p&gt;The Atlantic Meridional Overturning Circulation (AMOC) is an important
component of the global climate, known to be a tipping element, as it could
collapse under global warming. The main objective of this study is to compute
the probability that the AMOC collapses within a specified time window, using a
rare-event algorithm called Trajectory-Adaptive Multilevel Splitting (TAMS).
However, the efficiency and accuracy of TAMS depend on the choice of the score
function. Although the definition of the optimal score function, called
``committor function&quot; is known, it is impossible in general to compute it a
priori. Here, we combine TAMS with a Next-Generation Reservoir Computing
technique that estimates the committor function from the data generated by the
rare-event algorithm. We test this technique in a stochastic box model of the
AMOC for which two types of transition exist, the so-called F(ast)-transitions
and S(low)-transitions. Results for the F-transtions compare favorably with
those in the literature where a physically-informed score function was used. We
show that coupling a rare-event algorithm with machine learning allows for a
correct estimation of transition probabilities, transition times, and even
transition paths for a wide range of model parameters. We then extend these
results to the more difficult problem of S-transitions in the same model. In
both cases of F- and S-transitions, we also show how the Next-Generation
Reservoir Computing technique can be interpreted to retrieve an analytical
estimate of the committor function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Jacques_Dumas_V/0/1/0/all/0/1&quot;&gt;Val&amp;#xe9;rian Jacques-Dumas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Westen_R/0/1/0/all/0/1&quot;&gt;Ren&amp;#xe9; M. van Westen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Dijkstra_H/0/1/0/all/0/1&quot;&gt;Henk A. Dijkstra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10805">
<title>Learning to Visually Connect Actions and their Effects. (arXiv:2401.10805v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10805</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we introduce the novel concept of visually Connecting Actions
and Their Effects (CATE) in video understanding. CATE can have applications in
areas like task planning and learning from demonstration. We propose different
CATE-based task formulations, such as action selection and action
specification, where video understanding models connect actions and effects at
semantic and fine-grained levels. We observe that different formulations
produce representations capturing intuitive action properties. We also design
various baseline models for action selection and action specification. Despite
the intuitive nature of the task, we observe that models struggle, and humans
outperform them by a large margin. The study aims to establish a foundation for
future efforts, showcasing the flexibility and versatility of connecting
actions and effects in video understanding, with the hope of inspiring advanced
formulations and models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peh_E/0/1/0/all/0/1&quot;&gt;Eric Peh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parmar_P/0/1/0/all/0/1&quot;&gt;Paritosh Parmar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernando_B/0/1/0/all/0/1&quot;&gt;Basura Fernando&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10809">
<title>Neglected Hessian component explains mysteries in Sharpness regularization. (arXiv:2401.10809v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10809</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown that methods like SAM which either explicitly or
implicitly penalize second order information can improve generalization in deep
learning. Seemingly similar methods like weight noise and gradient penalties
often fail to provide such benefits. We show that these differences can be
explained by the structure of the Hessian of the loss. First, we show that a
common decomposition of the Hessian can be quantitatively interpreted as
separating the feature exploitation from feature exploration. The feature
exploration, which can be described by the Nonlinear Modeling Error matrix
(NME), is commonly neglected in the literature since it vanishes at
interpolation. Our work shows that the NME is in fact important as it can
explain why gradient penalties are sensitive to the choice of activation
function. Using this insight we design interventions to improve performance. We
also provide evidence that challenges the long held equivalence of weight noise
and gradient penalties. This equivalence relies on the assumption that the NME
can be ignored, which we find does not hold for modern networks since they
involve significant feature learning. We find that regularizing feature
exploitation but not feature exploration yields performance similar to gradient
penalties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dauphin_Y/0/1/0/all/0/1&quot;&gt;Yann N. Dauphin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwala_A/0/1/0/all/0/1&quot;&gt;Atish Agarwala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mobahi_H/0/1/0/all/0/1&quot;&gt;Hossein Mobahi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10811">
<title>Simulation Based Bayesian Optimization. (arXiv:2401.10811v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2401.10811</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian Optimization (BO) is a powerful method for optimizing black-box
functions by combining prior knowledge with ongoing function evaluations. BO
constructs a probabilistic surrogate model of the objective function given the
covariates, which is in turn used to inform the selection of future evaluation
points through an acquisition function. For smooth continuous search spaces,
Gaussian Processes (GPs) are commonly used as the surrogate model as they offer
analytical access to posterior predictive distributions, thus facilitating the
computation and optimization of acquisition functions. However, in complex
scenarios involving optimizations over categorical or mixed covariate spaces,
GPs may not be ideal.
&lt;/p&gt;
&lt;p&gt;This paper introduces Simulation Based Bayesian Optimization (SBBO) as a
novel approach to optimizing acquisition functions that only requires
\emph{sampling-based} access to posterior predictive distributions. SBBO allows
the use of surrogate probabilistic models tailored for combinatorial spaces
with discrete variables. Any Bayesian model in which posterior inference is
carried out through Markov chain Monte Carlo can be selected as the surrogate
model in SBBO. In applications involving combinatorial optimization, we
demonstrate empirically the effectiveness of SBBO method using various choices
of surrogate models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Naveiro_R/0/1/0/all/0/1&quot;&gt;Roi Naveiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tang_B/0/1/0/all/0/1&quot;&gt;Becky Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10816">
<title>Co-Pilot for Health: Personalized Algorithmic AI Nudging to Improve Health Outcomes. (arXiv:2401.10816v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2401.10816</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to shape health behaviors of large populations automatically,
across wearable types and disease conditions at scale has tremendous potential
to improve global health outcomes. We designed and implemented an AI driven
platform for digital algorithmic nudging, enabled by a Graph-Neural Network
(GNN) based Recommendation System, and granular health behavior data from
wearable fitness devices. Here we describe the efficacy results of this
platform with its capabilities of personalized and contextual nudging to
$n=84,764$ individuals over a 12-week period in Singapore. We statistically
validated that participants in the target group who received such AI optimized
daily nudges increased daily physical activity like step count by 6.17% ($p =
3.09\times10^{-4}$) and weekly minutes of Moderate to Vigorous Physical
Activity (MVPA) by 7.61% ($p = 1.16\times10^{-2}$), compared to matched
participants in control group who did not receive any nudges. Further, such
nudges were very well received, with a 13.1% of nudges sent being opened (open
rate), and 11.7% of the opened nudges rated useful compared to 1.9% rated as
not useful thereby demonstrating significant improvement in population level
engagement metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiam_J/0/1/0/all/0/1&quot;&gt;Jodi Chiam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_A/0/1/0/all/0/1&quot;&gt;Aloysius Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nott_C/0/1/0/all/0/1&quot;&gt;Cheryl Nott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mark_N/0/1/0/all/0/1&quot;&gt;Nicholas Mark&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teredesai_A/0/1/0/all/0/1&quot;&gt;Ankur Teredesai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shinde_S/0/1/0/all/0/1&quot;&gt;Sunil Shinde&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10819">
<title>Optimisation in Neurosymbolic Learning Systems. (arXiv:2401.10819v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2401.10819</link>
<description rdf:parseType="Literal">&lt;p&gt;Neurosymbolic AI aims to integrate deep learning with symbolic AI. This
integration has many promises, such as decreasing the amount of data required
to train a neural network, improving the explainability and interpretability of
answers given by models and verifying the correctness of trained systems. We
study neurosymbolic learning, where we have both data and background knowledge
expressed using symbolic languages. How do we connect the symbolic and neural
components to communicate this knowledge? One option is fuzzy reasoning, which
studies degrees of truth. For example, being tall is not a binary concept.
Instead, probabilistic reasoning studies the probability that something is true
or will happen. Our first research question studies how different forms of
fuzzy reasoning combine with learning. We find surprising results like a
connection to the Raven paradox stating we confirm &quot;ravens are black&quot; when we
observe a green apple. In this study, we did not use the background knowledge
when we deployed our models after training. In our second research question, we
studied how to use background knowledge in deployed models. We developed a new
neural network layer based on fuzzy reasoning. Probabilistic reasoning is a
natural fit for neural networks, which we usually train to be probabilistic.
However, they are expensive to compute and do not scale well to large tasks. In
our third research question, we study how to connect probabilistic reasoning
with neural networks by sampling to estimate averages, while in the final
research question, we study scaling probabilistic neurosymbolic learning to
much larger problems than before. Our insight is to train a neural network with
synthetic data to predict the result of probabilistic reasoning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krieken_E/0/1/0/all/0/1&quot;&gt;Emile van Krieken&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10825">
<title>A survey on recent advances in named entity recognition. (arXiv:2401.10825v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.10825</link>
<description rdf:parseType="Literal">&lt;p&gt;Named Entity Recognition seeks to extract substrings within a text that name
real-world objects and to determine their type (for example, whether they refer
to persons or organizations). In this survey, we first present an overview of
recent popular approaches, but we also look at graph- and transformer- based
methods including Large Language Models (LLMs) that have not had much coverage
in other surveys. Second, we focus on methods designed for datasets with scarce
annotations. Third, we evaluate the performance of the main NER implementations
on a variety of datasets with differing characteristics (as regards their
domain, their size, and their number of classes). We thus provide a deep
comparison of algorithms that are never considered together. Our experiments
shed some light on how the characteristics of datasets affect the behavior of
the methods that we compare.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keraghel_I/0/1/0/all/0/1&quot;&gt;Imed Keraghel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morbieu_S/0/1/0/all/0/1&quot;&gt;Stanislas Morbieu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nadif_M/0/1/0/all/0/1&quot;&gt;Mohamed Nadif&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10831">
<title>Understanding Video Transformers via Universal Concept Discovery. (arXiv:2401.10831v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10831</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of concept-based interpretability of
transformer representations for videos. Concretely, we seek to explain the
decision-making process of video transformers based on high-level,
spatiotemporal concepts that are automatically discovered. Prior research on
concept-based interpretability has concentrated solely on image-level tasks.
Comparatively, video models deal with the added temporal dimension, increasing
complexity and posing challenges in identifying dynamic concepts over time. In
this work, we systematically address these challenges by introducing the first
Video Transformer Concept Discovery (VTCD) algorithm. To this end, we propose
an efficient approach for unsupervised identification of units of video
transformer representations - concepts, and ranking their importance to the
output of a model. The resulting concepts are highly interpretable, revealing
spatio-temporal reasoning mechanisms and object-centric representations in
unstructured video models. Performing this analysis jointly over a diverse set
of supervised and self-supervised representations, we discover that some of
these mechanism are universal in video transformers. Finally, we demonstrate
that VTCDcan be used to improve model performance for fine-grained tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kowal_M/0/1/0/all/0/1&quot;&gt;Matthew Kowal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dave_A/0/1/0/all/0/1&quot;&gt;Achal Dave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ambrus_R/0/1/0/all/0/1&quot;&gt;Rares Ambrus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1&quot;&gt;Adrien Gaidon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Derpanis_K/0/1/0/all/0/1&quot;&gt;Konstantinos G. Derpanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tokmakov_P/0/1/0/all/0/1&quot;&gt;Pavel Tokmakov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10839">
<title>Holonic Learning: A Flexible Agent-based Distributed Machine Learning Framework. (arXiv:2401.10839v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2401.10839</link>
<description rdf:parseType="Literal">&lt;p&gt;Ever-increasing ubiquity of data and computational resources in the last
decade have propelled a notable transition in the machine learning paradigm
towards more distributed approaches. Such a transition seeks to not only tackle
the scalability and resource distribution challenges but also to address
pressing privacy and security concerns. To contribute to the ongoing discourse,
this paper introduces Holonic Learning (HoL), a collaborative and
privacy-focused learning framework designed for training deep learning models.
By leveraging holonic concepts, the HoL framework establishes a structured
self-similar hierarchy in the learning process, enabling more nuanced control
over collaborations through the individual model aggregation approach of each
holon, along with their intra-holon commitment and communication patterns. HoL,
in its general form, provides extensive design and flexibility potentials. For
empirical analysis and to demonstrate its effectiveness, this paper implements
HoloAvg, a special variant of HoL that employs weighted averaging for model
aggregation across all holons. The convergence of the proposed method is
validated through experiments on both IID and Non-IID settings of the standard
MNISt dataset. Furthermore, the performance behaviors of HoL are investigated
under various holarchical designs and data distribution scenarios. The
presented results affirm HoL&apos;s prowess in delivering competitive performance
particularly, in the context of the Non-IID data distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esmaeili_A/0/1/0/all/0/1&quot;&gt;Ahmad Esmaeili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghorrati_Z/0/1/0/all/0/1&quot;&gt;Zahra Ghorrati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matson_E/0/1/0/all/0/1&quot;&gt;Eric T. Matson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10840">
<title>Symbolic Cognitive Diagnosis via Hybrid Optimization for Intelligent Education Systems. (arXiv:2401.10840v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2401.10840</link>
<description rdf:parseType="Literal">&lt;p&gt;Cognitive diagnosis assessment is a fundamental and crucial task for student
learning. It models the student-exercise interaction, and discovers the
students&apos; proficiency levels on each knowledge attribute. In real-world
intelligent education systems, generalization and interpretability of cognitive
diagnosis methods are of equal importance. However, most existing methods can
hardly make the best of both worlds due to the complicated student-exercise
interaction. To this end, this paper proposes a symbolic cognitive
diagnosis~(SCD) framework to simultaneously enhance generalization and
interpretability. The SCD framework incorporates the symbolic tree to
explicably represent the complicated student-exercise interaction function, and
utilizes gradient-based optimization methods to effectively learn the student
and exercise parameters. Meanwhile, the accompanying challenge is that we need
to tunnel the discrete symbolic representation and continuous parameter
optimization. To address this challenge, we propose to hybridly optimize the
representation and parameters in an alternating manner. To fulfill SCD, it
alternately learns the symbolic tree by derivative-free genetic programming and
learns the student and exercise parameters via gradient-based Adam. The
extensive experimental results on various real-world datasets show the
superiority of SCD on both generalization and interpretability. The ablation
study verifies the efficacy of each ingredient in SCD, and the case study
explicitly showcases how the interpretable ability of SCD works.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Junhao Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1&quot;&gt;Hong Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Aimin Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10841">
<title>Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media. (arXiv:2401.10841v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.10841</link>
<description rdf:parseType="Literal">&lt;p&gt;Online hate speech proliferation has created a difficult problem for social
media platforms. A particular challenge relates to the use of coded language by
groups interested in both creating a sense of belonging for its users and
evading detection. Coded language evolves quickly and its use varies over time.
This paper proposes a methodology for detecting emerging coded hate-laden
terminology. The methodology is tested in the context of online antisemitic
discourse. The approach considers posts scraped from social media platforms,
often used by extremist users. The posts are scraped using seed expressions
related to previously known discourse of hatred towards Jews. The method begins
by identifying the expressions most representative of each post and calculating
their frequency in the whole corpus. It filters out grammatically incoherent
expressions as well as previously encountered ones so as to focus on emergent
well-formed terminology. This is followed by an assessment of semantic
similarity to known antisemitic terminology using a fine-tuned large language
model, and subsequent filtering out of the expressions that are too distant
from known expressions of hatred. Emergent antisemitic expressions containing
terms clearly relating to Jewish topics are then removed to return only coded
expressions of hatred.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kikkisetti_D/0/1/0/all/0/1&quot;&gt;Dhanush Kikkisetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mustafa_R/0/1/0/all/0/1&quot;&gt;Raza Ul Mustafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melillo_W/0/1/0/all/0/1&quot;&gt;Wendy Melillo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corizzo_R/0/1/0/all/0/1&quot;&gt;Roberto Corizzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boukouvalas_Z/0/1/0/all/0/1&quot;&gt;Zois Boukouvalas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gill_J/0/1/0/all/0/1&quot;&gt;Jeff Gill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Japkowicz_N/0/1/0/all/0/1&quot;&gt;Nathalie Japkowicz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10843">
<title>Training a General Spiking Neural Network with Improved Efficiency and Minimum Latency. (arXiv:2401.10843v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2401.10843</link>
<description rdf:parseType="Literal">&lt;p&gt;Spiking Neural Networks (SNNs) that operate in an event-driven manner and
employ binary spike representation have recently emerged as promising
candidates for energy-efficient computing. However, a cost bottleneck arises in
obtaining high-performance SNNs: training a SNN model requires a large number
of time steps in addition to the usual learning iterations, hence this limits
their energy efficiency. This paper proposes a general training framework that
enhances feature learning and activation efficiency within a limited time step,
providing a new solution for more energy-efficient SNNs. Our framework allows
SNN neurons to learn robust spike feature from different receptive fields and
update neuron states by utilizing both current stimuli and recurrence
information transmitted from other neurons. This setting continuously
complements information within a single time step. Additionally, we propose a
projection function to merge these two stimuli to smoothly optimize neuron
weights (spike firing threshold and activation). We evaluate the proposal for
both convolution and recurrent models. Our experimental results indicate
state-of-the-art visual classification tasks, including CIFAR10, CIFAR100, and
TinyImageNet.Our framework achieves 72.41% and 72.31% top-1 accuracy with only
1 time step on CIFAR100 for CNNs and RNNs, respectively. Our method reduces 10x
and 3x joule energy than a standard ANN and SNN, respectively, on CIFAR10,
without additional time steps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yunpeng Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Man Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Renyuan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10844">
<title>Neural Population Decoding and Imbalanced Multi-Omic Datasets For Cancer Subtype Diagnosis. (arXiv:2401.10844v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2401.10844</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent strides in the field of neural computation has seen the adoption of
Winner Take All (WTA) circuits to facilitate the unification of hierarchical
Bayesian inference and spiking neural networks as a neurobiologically plausible
model of information processing. Current research commonly validates the
performance of these networks via classification tasks, particularly of the
MNIST dataset. However, researchers have not yet reached consensus about how
best to translate the stochastic responses from these networks into discrete
decisions, a process known as population decoding. Despite being an often
underexamined part of SNNs, in this work we show that population decoding has a
significanct impact on the classification performance of WTA networks. For this
purpose, we apply a WTA network to the problem of cancer subtype diagnosis from
multi omic data, using datasets from The Cancer Genome Atlas (TCGA). In doing
so we utilise a novel implementation of gene similarity networks, a feature
encoding technique based on Kohoens self organising map algorithm. We further
show that the impact of selecting certain population decoding methods is
amplified when facing imbalanced datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kent_C/0/1/0/all/0/1&quot;&gt;Charles Theodore Kent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagheriye_L/0/1/0/all/0/1&quot;&gt;Leila Bagheriye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwisthout_J/0/1/0/all/0/1&quot;&gt;Johan Kwisthout&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10859">
<title>Ensembler: Combating model inversion attacks using model ensemble during collaborative inference. (arXiv:2401.10859v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.10859</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models have exhibited remarkable performance across various
domains. Nevertheless, the burgeoning model sizes compel edge devices to
offload a significant portion of the inference process to the cloud. While this
practice offers numerous advantages, it also raises critical concerns regarding
user data privacy. In scenarios where the cloud server&apos;s trustworthiness is in
question, the need for a practical and adaptable method to safeguard data
privacy becomes imperative. In this paper, we introduce Ensembler, an
extensible framework designed to substantially increase the difficulty of
conducting model inversion attacks for adversarial parties. Ensembler leverages
model ensembling on the adversarial server, running in parallel with existing
approaches that introduce perturbations to sensitive data during colloborative
inference. Our experiments demonstrate that when combined with even basic
Gaussian noise, Ensembler can effectively shield images from reconstruction
attacks, achieving recognition levels that fall below human performance in some
strict settings, significantly outperforming baseline methods lacking the
Ensembler framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Dancheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1&quot;&gt;Jinjun Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10862">
<title>Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning. (arXiv:2401.10862v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.10862</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) are vulnerable to `Jailbreaking&apos; prompts, a type
of attack that can coax these models into generating harmful and illegal
content. In this paper, we show that pruning up to 20% of LLM parameters
markedly increases their resistance to such attacks without additional training
and without sacrificing their performance in standard benchmarks. Intriguingly,
we discovered that the enhanced safety observed post-pruning correlates to the
initial safety training level of the model, hinting that the effect of pruning
could be more general and may hold for other LLM behaviors beyond safety.
Additionally, we introduce a curated dataset of 225 harmful tasks across five
categories, inserted into ten different Jailbreaking prompts, showing that
pruning aids LLMs in concentrating attention on task-relevant tokens in
jailbreaking prompts. Lastly, our experiments reveal that the prominent chat
models, such as LLaMA-2 Chat, Vicuna, and Mistral Instruct exhibit high
susceptibility to jailbreaking attacks, with some categories achieving nearly
70-100% success rate. These insights underline the potential of pruning as a
generalizable approach for improving LLM safety, reliability, and potentially
other desired behaviors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1&quot;&gt;Adib Hasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rugina_I/0/1/0/all/0/1&quot;&gt;Ileana Rugina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1&quot;&gt;Alex Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10874">
<title>Applications of flow models to the generation of correlated lattice QCD ensembles. (arXiv:2401.10874v1 [hep-lat])</title>
<link>http://arxiv.org/abs/2401.10874</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine-learned normalizing flows can be used in the context of lattice
quantum field theory to generate statistically correlated ensembles of lattice
gauge fields at different action parameters. This work demonstrates how these
correlations can be exploited for variance reduction in the computation of
observables. Three different proof-of-concept applications are demonstrated
using a novel residual flow architecture: continuum limits of gauge theories,
the mass dependence of QCD observables, and hadronic matrix elements based on
the Feynman-Hellmann approach. In all three cases, it is shown that statistical
uncertainties are significantly reduced when machine-learned flows are
incorporated as compared with the same calculations performed with uncorrelated
ensembles or direct reweighting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Abbott_R/0/1/0/all/0/1&quot;&gt;Ryan Abbott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Botev_A/0/1/0/all/0/1&quot;&gt;Aleksandar Botev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Boyda_D/0/1/0/all/0/1&quot;&gt;Denis Boyda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Hackett_D/0/1/0/all/0/1&quot;&gt;Daniel C. Hackett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Kanwar_G/0/1/0/all/0/1&quot;&gt;Gurtej Kanwar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Racaniere_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Racani&amp;#xe8;re&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo J. Rezende&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Romero_Lopez_F/0/1/0/all/0/1&quot;&gt;Fernando Romero-L&amp;#xf3;pez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Shanahan_P/0/1/0/all/0/1&quot;&gt;Phiala E. Shanahan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-lat/1/au:+Urban_J/0/1/0/all/0/1&quot;&gt;Julian M. Urban&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10886">
<title>SCENES: Subpixel Correspondence Estimation With Epipolar Supervision. (arXiv:2401.10886v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.10886</link>
<description rdf:parseType="Literal">&lt;p&gt;Extracting point correspondences from two or more views of a scene is a
fundamental computer vision problem with particular importance for relative
camera pose estimation and structure-from-motion. Existing local feature
matching approaches, trained with correspondence supervision on large-scale
datasets, obtain highly-accurate matches on the test sets. However, they do not
generalise well to new datasets with different characteristics to those they
were trained on, unlike classic feature extractors. Instead, they require
finetuning, which assumes that ground-truth correspondences or ground-truth
camera poses and 3D structure are available. We relax this assumption by
removing the requirement of 3D structure, e.g., depth maps or point clouds, and
only require camera pose information, which can be obtained from odometry. We
do so by replacing correspondence losses with epipolar losses, which encourage
putative matches to lie on the associated epipolar line. While weaker than
correspondence supervision, we observe that this cue is sufficient for
finetuning existing models on new data. We then further relax the assumption of
known camera poses by using pose estimates in a novel bootstrapping approach.
We evaluate on highly challenging datasets, including an indoor drone dataset
and an outdoor smartphone camera dataset, and obtain state-of-the-art results
without strong supervision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kloepfer_D/0/1/0/all/0/1&quot;&gt;Dominik A. Kloepfer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o F. Henriques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1&quot;&gt;Dylan Campbell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.01243">
<title>Efficient Attention: Attention with Linear Complexities. (arXiv:1812.01243v10 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.01243</link>
<description rdf:parseType="Literal">&lt;p&gt;Dot-product attention has wide applications in computer vision and natural
language processing. However, its memory and computational costs grow
quadratically with the input size. Such growth prohibits its application on
high-resolution inputs. To remedy this drawback, this paper proposes a novel
efficient attention mechanism equivalent to dot-product attention but with
substantially less memory and computational costs. Its resource efficiency
allows more widespread and flexible integration of attention modules into a
network, which leads to better accuracies. Empirical evaluations demonstrated
the effectiveness of its advantages. Efficient attention modules brought
significant performance boosts to object detectors and instance segmenters on
MS-COCO 2017. Further, the resource efficiency democratizes attention to
complex models, where high costs prohibit the use of dot-product attention. As
an exemplar, a model with efficient attention achieved state-of-the-art
accuracies for stereo depth estimation on the Scene Flow dataset. Code is
available at https://github.com/cmsflash/efficient-attention.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mingyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Haiyu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1&quot;&gt;Shuai Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongsheng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.06826">
<title>Few-shot Quality-Diversity Optimization. (arXiv:2109.06826v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2109.06826</link>
<description rdf:parseType="Literal">&lt;p&gt;In the past few years, a considerable amount of research has been dedicated
to the exploitation of previous learning experiences and the design of Few-shot
and Meta Learning approaches, in problem domains ranging from Computer Vision
to Reinforcement Learning based control. A notable exception, where to the best
of our knowledge, little to no effort has been made in this direction is
Quality-Diversity (QD) optimization. QD methods have been shown to be effective
tools in dealing with deceptive minima and sparse rewards in Reinforcement
Learning. However, they remain costly due to their reliance on inherently
sample inefficient evolutionary processes. We show that, given examples from a
task distribution, information about the paths taken by optimization in
parameter space can be leveraged to build a prior population, which when used
to initialize QD methods in unseen environments, allows for few-shot
adaptation. Our proposed method does not require backpropagation. It is simple
to implement and scale, and furthermore, it is agnostic to the underlying
models that are being trained. Experiments carried in both sparse and dense
reward settings using robotic manipulation and navigation benchmarks show that
it considerably reduces the number of generations that are required for QD
optimization in these environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salehi_A/0/1/0/all/0/1&quot;&gt;Achkan Salehi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coninx_A/0/1/0/all/0/1&quot;&gt;Alexandre Coninx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doncieux_S/0/1/0/all/0/1&quot;&gt;Stephane Doncieux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.10891">
<title>Active Restoration of Lost Audio Signals Using Machine Learning and Latent Information. (arXiv:2111.10891v4 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2111.10891</link>
<description rdf:parseType="Literal">&lt;p&gt;Digital audio signal reconstruction of a lost or corrupt segment using deep
learning algorithms has been explored intensively in recent years.
Nevertheless, prior traditional methods with linear interpolation, phase coding
and tone insertion techniques are still in vogue. However, we found no research
work on reconstructing audio signals with the fusion of dithering,
steganography, and machine learning regressors. Therefore, this paper proposes
the combination of steganography, halftoning (dithering), and state-of-the-art
shallow and deep learning methods. The results (including comparing the SPAIN,
Autoregressive, deep learning-based, graph-based, and other methods) are
evaluated with three different metrics. The observations from the results show
that the proposed solution is effective and can enhance the reconstruction of
audio signals performed by the side information (e.g., Latent representation)
steganography provides. Moreover, this paper proposes a novel framework for
reconstruction from heavily compressed embedded audio data using halftoning
(i.e., dithering) and machine learning, which we termed the HCR (halftone-based
compression and reconstruction). This work may trigger interest in optimising
this approach and/or transferring it to different domains (i.e., image
reconstruction). Compared to existing methods, we show improvement in the
inpainting performance in terms of signal-to-noise ratio (SNR), the objective
difference grade (ODG) and Hansen&apos;s audio quality metric. In particular, our
proposed framework outperformed the learning-based methods (D2WGAN and SG) and
the traditional statistical algorithms (e.g., SPAIN, TDC, WCP).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cheddad_Z/0/1/0/all/0/1&quot;&gt;Zohra Adila Cheddad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cheddad_A/0/1/0/all/0/1&quot;&gt;Abbas Cheddad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.05158">
<title>Towards Quantum Graph Neural Networks: An Ego-Graph Learning Approach. (arXiv:2201.05158v3 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2201.05158</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum machine learning is a fast-emerging field that aims to tackle machine
learning using quantum algorithms and quantum computing. Due to the lack of
physical qubits and an effective means to map real-world data from Euclidean
space to Hilbert space, most of these methods focus on quantum analogies or
process simulations rather than devising concrete architectures based on
qubits. In this paper, we propose a novel hybrid quantum-classical algorithm
for graph-structured data, which we refer to as the Ego-graph based Quantum
Graph Neural Network (egoQGNN). egoQGNN implements the GNN theoretical
framework using the tensor product and unity matrix representation, which
greatly reduces the number of model parameters required. When controlled by a
classical computer, egoQGNN can accommodate arbitrarily sized graphs by
processing ego-graphs from the input graph using a modestly-sized quantum
device. The architecture is based on a novel mapping from real-world data to
Hilbert space. This mapping maintains the distance relations present in the
data and reduces information loss. Experimental results show that the proposed
method outperforms competitive state-of-the-art models with only 1.68\%
parameters compared to those models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ai_X/0/1/0/all/0/1&quot;&gt;Xing Ai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhihong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Luzhe Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Junchi Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hancock_E/0/1/0/all/0/1&quot;&gt;Edwin Hancock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2203.16031">
<title>How Deep is Your Art: An Experimental Study on the Limits of Artistic Understanding in a Single-Task, Single-Modality Neural Network. (arXiv:2203.16031v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2203.16031</link>
<description rdf:parseType="Literal">&lt;p&gt;Computational modeling of artwork meaning is complex and difficult. This is
because art interpretation is multidimensional and highly subjective. This
paper experimentally investigated the degree to which a state-of-the-art Deep
Convolutional Neural Network (DCNN), a popular Machine Learning approach, can
correctly distinguish modern conceptual art work into the galleries devised by
art curators. Two hypotheses were proposed to state that the DCNN model uses
Exhibited Properties for classification, like shape and color, but not
Non-Exhibited Properties, such as historical context and artist intention. The
two hypotheses were experimentally validated using a methodology designed for
this purpose. VGG-11 DCNN pre-trained on ImageNet dataset and discriminatively
fine-tuned was trained on handcrafted datasets designed from real-world
conceptual photography galleries. Experimental results supported the two
hypotheses showing that the DCNN model ignores Non-Exhibited Properties and
uses only Exhibited Properties for artwork classification. This work points to
current DCNN limitations, which should be addressed by future DNN models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zahedi_M/0/1/0/all/0/1&quot;&gt;Mahan Agha Zahedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gholamrezaei_N/0/1/0/all/0/1&quot;&gt;Niloofar Gholamrezaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doboli_A/0/1/0/all/0/1&quot;&gt;Alex Doboli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.05359">
<title>Exploring Local Explanations of Nonlinear Models Using Animated Linear Projections. (arXiv:2205.05359v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2205.05359</link>
<description rdf:parseType="Literal">&lt;p&gt;The increased predictive power of machine learning models comes at the cost
of increased complexity and loss of interpretability, particularly in
comparison to parametric statistical models. This trade-off has led to the
emergence of eXplainable AI (XAI) which provides methods, such as local
explanations (LEs) and local variable attributions (LVAs), to shed light on how
a model use predictors to arrive at a prediction. These provide a point
estimate of the linear variable importance in the vicinity of a single
observation. However, LVAs tend not to effectively handle association between
predictors. To understand how the interaction between predictors affects the
variable importance estimate, we can convert LVAs into linear projections and
use the radial tour. This is also useful for learning how a model has made a
mistake, or the effect of outliers, or the clustering of observations. The
approach is illustrated with examples from categorical (penguin species,
chocolate types) and quantitative (soccer/football salaries, house prices)
response models. The methods are implemented in the R package cheem, available
on CRAN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Spyrison_N/0/1/0/all/0/1&quot;&gt;Nicholas Spyrison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cook_D/0/1/0/all/0/1&quot;&gt;Dianne Cook&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Biecek_P/0/1/0/all/0/1&quot;&gt;Przemyslaw Biecek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.14102">
<title>Group-level Brain Decoding with Deep Learning. (arXiv:2205.14102v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.14102</link>
<description rdf:parseType="Literal">&lt;p&gt;Decoding brain imaging data are gaining popularity, with applications in
brain-computer interfaces and the study of neural representations. Decoding is
typicallysubject-specific and does not generalise well over subjects, due to
high amounts ofbetween subject variability. Techniques that overcome this will
not only providericher neuroscientific insights but also make it possible for
group-level models to out-perform subject-specific models. Here, we propose a
method that uses subjectembedding, analogous to word embedding in natural
language processing, to learnand exploit the structure in between-subject
variability as part of a decoding model,our adaptation of the WaveNet
architecture for classification. We apply this to mag-netoencephalography data,
where 15 subjects viewed 118 different images, with30 examples per image; to
classify images using the entire 1 s window followingimage presentation. We
show that the combination of deep learning and subjectembedding is crucial to
closing the performance gap between subject- and group-level decoding models.
Importantly, group models outperform subject models onlow-accuracy subjects
(although slightly impair high-accuracy subjects) and can behelpful for
initialising subject models. While we have not generally found
group-levelmodels to perform better than subject-level models, the performance
of groupmodelling is expected to be even higher with bigger datasets. In order
to providephysiological interpretation at the group level, we make use of
permutation featureimportance. This provides insights into the spatiotemporal
and spectral informationencoded in the models. All code is available on GitHub
(https://github.com/ricsinaruto/MEG-group-decode).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Csaky_R/0/1/0/all/0/1&quot;&gt;Richard Csaky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Es_M/0/1/0/all/0/1&quot;&gt;Mats Van Es&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_O/0/1/0/all/0/1&quot;&gt;Oiwi Parker Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woolrich_M/0/1/0/all/0/1&quot;&gt;Mark Woolrich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.01409">
<title>Hybrid Parameter Search and Dynamic Model Selection for Mixed-Variable Bayesian Optimization. (arXiv:2206.01409v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.01409</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new type of hybrid model for Bayesian optimization (BO)
adept at managing mixed variables, encompassing both quantitative (continuous
and integer) and qualitative (categorical) types. Our proposed new hybrid
models (named hybridM) merge the Monte Carlo Tree Search structure (MCTS) for
categorical variables with Gaussian Processes (GP) for continuous ones. hybridM
leverages the upper confidence bound tree search (UCTS) for MCTS strategy,
showcasing the tree architecture&apos;s integration into Bayesian optimization. Our
innovations, including dynamic online kernel selection in the surrogate
modeling phase and a unique UCTS search strategy, position our hybrid models as
an advancement in mixed-variable surrogate models. Numerical experiments
underscore the superiority of hybrid models, highlighting their potential in
Bayesian optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Hengrui Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1&quot;&gt;Younghyun Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demmel_J/0/1/0/all/0/1&quot;&gt;James W. Demmel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoye S. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.07626">
<title>Algorithmic Assistance with Recommendation-Dependent Preferences. (arXiv:2208.07626v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2208.07626</link>
<description rdf:parseType="Literal">&lt;p&gt;When an algorithm provides risk assessments, we typically think of them as
helpful inputs to human decisions, such as when risk scores are presented to
judges or doctors. However, a decision-maker may not only react to the
information provided by the algorithm. The decision-maker may also view the
algorithmic recommendation as a default action, making it costly for them to
deviate, such as when a judge is reluctant to overrule a high-risk assessment
for a defendant or a doctor fears the consequences of deviating from
recommended procedures. To address such unintended consequences of algorithmic
assistance, we propose a principal-agent model of joint human-machine
decision-making. Within this model, we consider the effect and design of
algorithmic recommendations when they affect choices not just by shifting
beliefs, but also by altering preferences. We motivate this assumption from
institutional factors, such as a desire to avoid audits, as well as from
well-established models in behavioral science that predict loss aversion
relative to a reference point, which here is set by the algorithm. We show that
recommendation-dependent preferences create inefficiencies where the
decision-maker is overly responsive to the recommendation. As a potential
remedy, we discuss algorithms that strategically withhold recommendations, and
show how they can improve the quality of final decisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McLaughlin_B/0/1/0/all/0/1&quot;&gt;Bryce McLaughlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spiess_J/0/1/0/all/0/1&quot;&gt;Jann Spiess&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.02672">
<title>A Novel Maximum-Entropy-Driven Technique for Low-Rank Orthogonal Nonnegative Matrix Factorization with $\ell_0$-Norm sparsity Constraint. (arXiv:2210.02672v3 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2210.02672</link>
<description rdf:parseType="Literal">&lt;p&gt;In data-driven control and machine learning, a common requirement involves
breaking down large matrices into smaller, low-rank factors that possess
specific levels of sparsity. This paper introduces an innovative solution to
the orthogonal nonnegative matrix factorization (ONMF) problem. The objective
is to approximate input data by using two low-rank nonnegative matrices,
adhering to both orthogonality and $\ell_0$-norm sparsity constraints. the
proposed maximum-entropy-principle based framework ensures orthogonality and
sparsity of features or the mixing matrix, while maintaining nonnegativity in
both. Additionally, the methodology offers a quantitative determination of the
``true&apos;&apos; number of underlying features, a crucial hyperparameter for ONMF.
Experimental evaluation on synthetic and a standard datasets highlights the
method&apos;s superiority in terms of sparsity, orthogonality, and computational
speed compared to existing approaches. Notably, the proposed method achieves
comparable or improved reconstruction errors in line with the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basiri_S/0/1/0/all/0/1&quot;&gt;Salar Basiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salapaka_S/0/1/0/all/0/1&quot;&gt;Srinivasa Salapaka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.13350">
<title>Choreographer: Learning and Adapting Skills in Imagination. (arXiv:2211.13350v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2211.13350</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised skill learning aims to learn a rich repertoire of behaviors
without external supervision, providing artificial agents with the ability to
control and influence the environment. However, without appropriate knowledge
and exploration, skills may provide control only over a restricted area of the
environment, limiting their applicability. Furthermore, it is unclear how to
leverage the learned skill behaviors for adapting to downstream tasks in a
data-efficient manner. We present Choreographer, a model-based agent that
exploits its world model to learn and adapt skills in imagination. Our method
decouples the exploration and skill learning processes, being able to discover
skills in the latent state space of the model. During adaptation, the agent
uses a meta-controller to evaluate and adapt the learned skills efficiently by
deploying them in parallel in imagination. Choreographer is able to learn
skills both from offline data, and by collecting data simultaneously with an
exploration policy. The skills can be used to effectively adapt to downstream
tasks, as we show in the URL benchmark, where we outperform previous approaches
from both pixels and states inputs. The learned skills also explore the
environment thoroughly, finding sparse rewards more frequently, as shown in
goal-reaching tasks from the DMC Suite and Meta-World. Website and code:
https://skillchoreographer.github.io/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazzaglia_P/0/1/0/all/0/1&quot;&gt;Pietro Mazzaglia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verbelen_T/0/1/0/all/0/1&quot;&gt;Tim Verbelen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhoedt_B/0/1/0/all/0/1&quot;&gt;Bart Dhoedt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_A/0/1/0/all/0/1&quot;&gt;Alexandre Lacoste&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajeswar_S/0/1/0/all/0/1&quot;&gt;Sai Rajeswar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.00219">
<title>Are you using test log-likelihood correctly?. (arXiv:2212.00219v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2212.00219</link>
<description rdf:parseType="Literal">&lt;p&gt;Test log-likelihood is commonly used to compare different models of the same
data or different approximate inference algorithms for fitting the same
probabilistic model. We present simple examples demonstrating how comparisons
based on test log-likelihood can contradict comparisons according to other
objectives. Specifically, our examples show that (i) approximate Bayesian
inference algorithms that attain higher test log-likelihoods need not also
yield more accurate posterior approximations and (ii) conclusions about
forecast accuracy based on test log-likelihood comparisons may not agree with
conclusions based on root mean squared error.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deshpande_S/0/1/0/all/0/1&quot;&gt;Sameer K. Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Soumya Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Tin D. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Broderick_T/0/1/0/all/0/1&quot;&gt;Tamara Broderick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.01521">
<title>Distribution Fitting for Combating Mode Collapse in Generative Adversarial Networks. (arXiv:2212.01521v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.01521</link>
<description rdf:parseType="Literal">&lt;p&gt;Mode collapse is a significant unsolved issue of generative adversarial
networks. In this work, we examine the causes of mode collapse from a novel
perspective. Due to the nonuniform sampling in the training process, some
sub-distributions may be missed when sampling data. As a result, even when the
generated distribution differs from the real one, the GAN objective can still
achieve the minimum. To address the issue, we propose a global distribution
fitting (GDF) method with a penalty term to confine the generated data
distribution. When the generated distribution differs from the real one, GDF
will make the objective harder to reach the minimal value, while the original
global minimum is not changed. To deal with the circumstance when the overall
real data is unreachable, we also propose a local distribution fitting (LDF)
method. Experiments on several benchmarks demonstrate the effectiveness and
competitive performance of GDF and LDF.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1&quot;&gt;Yanxiang Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_G/0/1/0/all/0/1&quot;&gt;Guozhen Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zheng Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1&quot;&gt;Mei Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.09726">
<title>Improving Faithfulness of Abstractive Summarization by Controlling Confounding Effect of Irrelevant Sentences. (arXiv:2212.09726v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2212.09726</link>
<description rdf:parseType="Literal">&lt;p&gt;Lack of factual correctness is an issue that still plagues state-of-the-art
summarization systems despite their impressive progress on generating seemingly
fluent summaries. In this paper, we show that factual inconsistency can be
caused by irrelevant parts of the input text, which act as confounders. To that
end, we leverage information-theoretic measures of causal effects to quantify
the amount of confounding and precisely quantify how they affect the
summarization performance. Based on insights derived from our theoretical
results, we design a simple multi-task model to control such confounding by
leveraging human-annotated relevant sentences when available. Crucially, we
give a principled characterization of data distributions where such confounding
can be large thereby necessitating the use of human annotated relevant
sentences to generate factual summaries. Our approach improves faithfulness
scores by 20\% over strong baselines on AnswerSumm
\citep{fabbri2021answersumm}, a conversation summarization dataset where lack
of faithfulness is a significant issue due to the subjective nature of the
task. Our best method achieves the highest faithfulness score while also
achieving state-of-the-art results on standard metrics like ROUGE and METEOR.
We corroborate these improvements through human evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghoshal_A/0/1/0/all/0/1&quot;&gt;Asish Ghoshal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Einolghozati_A/0/1/0/all/0/1&quot;&gt;Arash Einolghozati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arun_A/0/1/0/all/0/1&quot;&gt;Ankit Arun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haoran Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1&quot;&gt;Lili Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gor_V/0/1/0/all/0/1&quot;&gt;Vera Gor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1&quot;&gt;Yashar Mehdad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yih_S/0/1/0/all/0/1&quot;&gt;Scott Wen-tau Yih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1&quot;&gt;Asli Celikyilmaz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.06120">
<title>Knowledge from Large-Scale Protein Contact Prediction Models Can Be Transferred to the Data-Scarce RNA Contact Prediction Task. (arXiv:2302.06120v3 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2302.06120</link>
<description rdf:parseType="Literal">&lt;p&gt;RNA, whose functionality is largely determined by its structure, plays an
important role in many biological activities. The prediction of pairwise
structural proximity between each nucleotide of an RNA sequence can
characterize the structural information of the RNA. Historically, this problem
has been tackled by machine learning models using expert-engineered features
and trained on scarce labeled datasets. Here, we find that the knowledge
learned by a protein-coevolution Transformer-based deep neural network can be
transferred to the RNA contact prediction task. As protein datasets are orders
of magnitude larger than those for RNA contact prediction, our findings and the
subsequent framework greatly reduce the data scarcity bottleneck. Experiments
confirm that RNA contact prediction through transfer learning using a publicly
available protein model is greatly improved. Our findings indicate that the
learned structural patterns of proteins can be transferred to RNAs, opening up
potential new avenues for research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Jian_Y/0/1/0/all/0/1&quot;&gt;Yiren Jian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gao_C/0/1/0/all/0/1&quot;&gt;Chongyang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zeng_C/0/1/0/all/0/1&quot;&gt;Chen Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yunjie Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Vosoughi_S/0/1/0/all/0/1&quot;&gt;Soroush Vosoughi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.13854">
<title>A Deep Neural Network Based Reverse Radio Spectrogram Search Algorithm. (arXiv:2302.13854v2 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2302.13854</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern radio astronomy instruments generate vast amounts of data, and the
increasingly challenging radio frequency interference (RFI) environment
necessitates ever-more sophisticated RFI rejection algorithms. The &quot;needle in a
haystack&quot; nature of searches for transients and technosignatures requires us to
develop methods that can determine whether a signal of interest has unique
properties, or is a part of some larger set of pernicious RFI. In the past,
this vetting has required onerous manual inspection of very large numbers of
signals. In this paper we present a fast and modular deep learning algorithm to
search for lookalike signals of interest in radio spectrogram data. First, we
trained a B-Variational Autoencoder on signals returned by an energy detection
algorithm. We then adapted a positional embedding layer from classical
Transformer architecture to a embed additional metadata, which we demonstrate
using a frequency-based embedding. Next we used the encoder component of the
B-Variational Autoencoder to extract features from small (~ 715,Hz, with a
resolution of 2.79Hz per frequency bin) windows in the radio spectrogram. We
used our algorithm to conduct a search for a given query (encoded signal of
interest) on a set of signals (encoded features of searched items) to produce
the top candidates with similar features. We successfully demonstrate that the
algorithm retrieves signals with similar appearance, given only the original
radio spectrogram data. This algorithm can be used to improve the efficiency of
vetting signals of interest in technosignature searches, but could also be
applied to a wider variety of searches for &quot;lookalike&quot; signals in large
astronomical datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ma_P/0/1/0/all/0/1&quot;&gt;Peter Xiangyuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Croft_S/0/1/0/all/0/1&quot;&gt;Steve Croft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lintott_C/0/1/0/all/0/1&quot;&gt;Chris Lintott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Siemion_A/0/1/0/all/0/1&quot;&gt;Andrew P. V. Siemion&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.02506">
<title>Prismer: A Vision-Language Model with Multi-Task Experts. (arXiv:2303.02506v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.02506</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent vision-language models have shown impressive multi-modal generation
capabilities. However, typically they require training huge models on massive
datasets. As a more scalable alternative, we introduce Prismer, a data- and
parameter-efficient vision-language model that leverages an ensemble of
task-specific experts. Prismer only requires training of a small number of
components, with the majority of network weights inherited from multiple
readily-available, pre-trained experts, and kept frozen during training. By
leveraging experts from a wide range of domains, we show Prismer can
efficiently pool this expert knowledge and adapt it to various vision-language
reasoning tasks. In our experiments, we show that Prismer achieves fine-tuned
and few-shot learning performance which is competitive with current
state-of-the-arts, whilst requiring up to two orders of magnitude less training
data. Code is available at https://github.com/NVlabs/prismer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shikun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Linxi Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1&quot;&gt;Edward Johns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhiding Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1&quot;&gt;Chaowei Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.02901">
<title>$\alpha$-divergence Improves the Entropy Production Estimation via Machine Learning. (arXiv:2303.02901v2 [cond-mat.stat-mech] UPDATED)</title>
<link>http://arxiv.org/abs/2303.02901</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have seen a surge of interest in the algorithmic estimation of
stochastic entropy production (EP) from trajectory data via machine learning. A
crucial element of such algorithms is the identification of a loss function
whose minimization guarantees the accurate EP estimation. In this study, we
show that there exists a host of loss functions, namely those implementing a
variational representation of the $\alpha$-divergence, which can be used for
the EP estimation. By fixing $\alpha$ to a value between $-1$ and $0$, the
$\alpha$-NEEP (Neural Estimator for Entropy Production) exhibits a much more
robust performance against strong nonequilibrium driving or slow dynamics,
which adversely affects the existing method based on the Kullback-Leibler
divergence ($\alpha = 0$). In particular, the choice of $\alpha = -0.5$ tends
to yield the optimal results. To corroborate our findings, we present an
exactly solvable simplification of the EP estimation problem, whose loss
function landscape and stochastic properties give deeper intuition into the
robustness of the $\alpha$-NEEP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Kwon_E/0/1/0/all/0/1&quot;&gt;Euijoon Kwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Baek_Y/0/1/0/all/0/1&quot;&gt;Yongjoo Baek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.03183">
<title>Utilizing synthetic training data for the supervised classification of rat ultrasonic vocalizations. (arXiv:2303.03183v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2303.03183</link>
<description rdf:parseType="Literal">&lt;p&gt;Murine rodents generate ultrasonic vocalizations (USVs) with frequencies that
extend to around 120kHz. These calls are important in social behaviour, and so
their analysis can provide insights into the function of vocal communication,
and its dysfunction. The manual identification of USVs, and subsequent
classification into different subcategories is time consuming. Although machine
learning approaches for identification and classification can lead to enormous
efficiency gains, the time and effort required to generate training data can be
high, and the accuracy of current approaches can be problematic. Here we
compare the detection and classification performance of a trained human against
two convolutional neural networks (CNNs), DeepSqueak and VocalMat, on audio
containing rat USVs. Furthermore, we test the effect of inserting synthetic
USVs into the training data of the VocalMat CNN as a means of reducing the
workload associated with generating a training set. Our results indicate that
VocalMat outperformed the DeepSqueak CNN on measures of call identification,
and classification. Additionally, we found that the augmentation of training
data with synthetic images resulted in a further improvement in accuracy, such
that it was sufficiently close to human performance to allow for the use of
this software in laboratory conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scott_K/0/1/0/all/0/1&quot;&gt;K. Jack Scott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Speers_L/0/1/0/all/0/1&quot;&gt;Lucinda J. Speers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilkey_D/0/1/0/all/0/1&quot;&gt;David K. Bilkey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.15954">
<title>TraffNet: Learning Causality of Traffic Generation for What-if Prediction. (arXiv:2303.15954v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.15954</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time what-if traffic prediction is crucial for decision making in
intelligent traffic management and control. Although current deep learning
methods demonstrate significant advantages in traffic prediction, they are
powerless in what-if traffic prediction due to their nature of
correlation-based. Here, we present a simple deep learning framework called
TraffNet that learns the mechanisms of traffic generation for what-if
prediction from vehicle trajectory data. First, we use a heterogeneous graph to
represent the road network, allowing the model to incorporate causal features
of traffic flows, such as Origin-Destination (OD) demands and routes. Next, we
propose a method for learning segment representations, which involves modeling
the process of assigning OD demands onto the road network. The learned segment
representations effectively encapsulate the intricate causes of traffic
generation, facilitating downstream what-if traffic prediction. Finally, we
conduct experiments on synthetic datasets to evaluate the effectiveness of
TraffNet. The code and datasets of TraffNet is available at
https://github.com/mayunyi-1999/TraffNet_code.git.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Ming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1&quot;&gt;Qiang Ai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ruimin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yunyi Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1&quot;&gt;Geqi Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1&quot;&gt;Xiangfu Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Haibo Jin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.17046">
<title>Have it your way: Individualized Privacy Assignment for DP-SGD. (arXiv:2303.17046v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.17046</link>
<description rdf:parseType="Literal">&lt;p&gt;When training a machine learning model with differential privacy, one sets a
privacy budget. This budget represents a maximal privacy violation that any
user is willing to face by contributing their data to the training set. We
argue that this approach is limited because different users may have different
privacy expectations. Thus, setting a uniform privacy budget across all points
may be overly conservative for some users or, conversely, not sufficiently
protective for others. In this paper, we capture these preferences through
individualized privacy budgets. To demonstrate their practicality, we introduce
a variant of Differentially Private Stochastic Gradient Descent (DP-SGD) which
supports such individualized budgets. DP-SGD is the canonical approach to
training models with differential privacy. We modify its data sampling and
gradient noising mechanisms to arrive at our approach, which we call
Individualized DP-SGD (IDP-SGD). Because IDP-SGD provides privacy guarantees
tailored to the preferences of individual users and their data points, we find
it empirically improves privacy-utility trade-offs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boenisch_F/0/1/0/all/0/1&quot;&gt;Franziska Boenisch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muhl_C/0/1/0/all/0/1&quot;&gt;Christopher M&amp;#xfc;hl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dziedzic_A/0/1/0/all/0/1&quot;&gt;Adam Dziedzic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rinberg_R/0/1/0/all/0/1&quot;&gt;Roy Rinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1&quot;&gt;Nicolas Papernot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.11171">
<title>Granular-ball computing: an efficient, robust, and interpretable adaptive multi-granularity representation and computation method. (arXiv:2304.11171v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.11171</link>
<description rdf:parseType="Literal">&lt;p&gt;Human cognition operates on a &quot;Global-first&quot; cognitive mechanism,
prioritizing information processing based on coarse-grained details. This
mechanism inherently possesses an adaptive multi-granularity description
capacity, resulting in computational traits such as efficiency, robustness, and
interpretability. The analysis pattern reliance on the finest granularity and
single-granularity makes most existing computational methods less efficient,
robust, and interpretable, which is an important reason for the current lack of
interpretability in neural networks. Multi-granularity granular-ball computing
employs granular-balls of varying sizes to daptively represent and envelop the
sample space, facilitating learning based on these granular-balls. Given that
the number of coarse-grained &quot;granular-balls&quot; is fewer than sample points,
granular-ball computing proves more efficient. Moreover, the inherent
coarse-grained nature of granular-balls reduces susceptibility to fine-grained
sample disturbances, enhancing robustness. The multi-granularity construct of
granular-balls generates topological structures and coarse-grained
descriptions, naturally augmenting interpretability. Granular-ball computing
has successfully ventured into diverse AI domains, fostering the development of
innovative theoretical methods, including granular-ball classifiers, clustering
techniques, neural networks, rough sets, and evolutionary computing. This has
notably ameliorated the efficiency, noise robustness, and interpretability of
traditional methods. Overall, granular-ball computing is a rare and innovative
theoretical approach in AI that can adaptively and simultaneously enhance
efficiency, robustness, and interpretability. This article delves into the main
application landscapes for granular-ball computing, aiming to equip future
researchers with references and insights to refine and expand this promising
theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1&quot;&gt;Shuyin Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Guoyin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1&quot;&gt;Xinbo Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Lian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.03077">
<title>Explaining dark matter halo density profiles with neural networks. (arXiv:2305.03077v2 [astro-ph.CO] UPDATED)</title>
<link>http://arxiv.org/abs/2305.03077</link>
<description rdf:parseType="Literal">&lt;p&gt;We use explainable neural networks to connect the evolutionary history of
dark matter halos with their density profiles. The network captures independent
factors of variation in the density profiles within a low-dimensional
representation, which we physically interpret using mutual information. Without
any prior knowledge of the halos&apos; evolution, the network recovers the known
relation between the early time assembly and the inner profile, and discovers
that the profile beyond the virial radius is described by a single parameter
capturing the most recent mass accretion rate. The results illustrate the
potential for machine-assisted scientific discovery in complicated
astrophysical datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Lucie_Smith_L/0/1/0/all/0/1&quot;&gt;Luisa Lucie-Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Peiris_H/0/1/0/all/0/1&quot;&gt;Hiranya V. Peiris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Pontzen_A/0/1/0/all/0/1&quot;&gt;Andrew Pontzen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14402">
<title>Enhancing Speech Emotion Recognition Through Differentiable Architecture Search. (arXiv:2305.14402v3 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14402</link>
<description rdf:parseType="Literal">&lt;p&gt;Speech Emotion Recognition (SER) is a critical enabler of emotion-aware
communication in human-computer interactions. Recent advancements in Deep
Learning (DL) have substantially enhanced the performance of SER models through
increased model complexity. However, designing optimal DL architectures
requires prior experience and experimental evaluations. Encouragingly, Neural
Architecture Search (NAS) offers a promising avenue to determine an optimal DL
model automatically. In particular, Differentiable Architecture Search (DARTS)
is an efficient method of using NAS to search for optimised models. This paper
proposes a DARTS-optimised joint CNN and LSTM architecture, to improve SER
performance, where the literature informs the selection of CNN and LSTM
coupling to offer improved performance. While DARTS has previously been applied
to CNN and LSTM combinations, our approach introduces a novel mechanism,
particularly in selecting CNN operations using DARTS. In contrast to previous
studies, we refrain from imposing constraints on the order of the layers for
the CNN within the DARTS cell; instead, we allow DARTS to determine the optimal
layer order autonomously. Experimenting with the IEMOCAP and MSP-IMPROV
datasets, we demonstrate that our proposed methodology achieves significantly
higher SER accuracy than hand-engineering the CNN-LSTM configuration. It also
outperforms the best-reported SER results achieved using DARTS on CNN-LSTM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajapakshe_T/0/1/0/all/0/1&quot;&gt;Thejan Rajapakshe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rana_R/0/1/0/all/0/1&quot;&gt;Rajib Rana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifa_S/0/1/0/all/0/1&quot;&gt;Sara Khalifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sisman_B/0/1/0/all/0/1&quot;&gt;Berrak Sisman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn Schuller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.00119">
<title>Optimal Sets and Solution Paths of ReLU Networks. (arXiv:2306.00119v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.00119</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop an analytical framework to characterize the set of optimal ReLU
neural networks by reformulating the non-convex training problem as a convex
program. We show that the global optima of the convex parameterization are
given by a polyhedral set and then extend this characterization to the optimal
set of the non-convex training objective. Since all stationary points of the
ReLU training problem can be represented as optima of sub-sampled convex
programs, our work provides a general expression for all critical points of the
non-convex objective. We then leverage our results to provide an optimal
pruning algorithm for computing minimal networks, establish conditions for the
regularization path of ReLU networks to be continuous, and develop sensitivity
results for minimal ReLU networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishkin_A/0/1/0/all/0/1&quot;&gt;Aaron Mishkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1&quot;&gt;Mert Pilanci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.10822">
<title>Interpreting Deep Neural Networks with the Package innsight. (arXiv:2306.10822v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.10822</link>
<description rdf:parseType="Literal">&lt;p&gt;The R package innsight offers a general toolbox for revealing variable-wise
interpretations of deep neural networks&apos; predictions with so-called feature
attribution methods. Aside from the unified and user-friendly framework, the
package stands out in three ways: It is generally the first R package
implementing feature attribution methods for neural networks. Secondly, it
operates independently of the deep learning library allowing the interpretation
of models from any R package, including keras, torch, neuralnet, and even
custom models. Despite its flexibility, innsight benefits internally from the
torch package&apos;s fast and efficient array calculations, which builds on LibTorch
$-$ PyTorch&apos;s C++ backend $-$ without a Python dependency. Finally, it offers a
variety of visualization tools for tabular, signal, image data or a combination
of these. Additionally, the plots can be rendered interactively using the
plotly package.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Koenen_N/0/1/0/all/0/1&quot;&gt;Niklas Koenen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wright_M/0/1/0/all/0/1&quot;&gt;Marvin N. Wright&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.17248">
<title>TemperatureGAN: Generative Modeling of Regional Atmospheric Temperatures. (arXiv:2306.17248v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.17248</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic generators are useful for estimating climate impacts on various
sectors. Projecting climate risk in various sectors, e.g. energy systems,
requires generators that are accurate (statistical resemblance to
ground-truth), reliable (do not produce erroneous examples), and efficient.
Leveraging data from the North American Land Data Assimilation System, we
introduce TemperatureGAN, a Generative Adversarial Network conditioned on
months, locations, and time periods, to generate 2m above ground atmospheric
temperatures at an hourly resolution. We propose evaluation methods and metrics
to measure the quality of generated samples. We show that TemperatureGAN
produces high-fidelity examples with good spatial representation and temporal
dynamics consistent with known diurnal cycles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balogun_E/0/1/0/all/0/1&quot;&gt;Emmanuel Balogun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajagopal_R/0/1/0/all/0/1&quot;&gt;Ram Rajagopal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumdar_A/0/1/0/all/0/1&quot;&gt;Arun Majumdar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.12871">
<title>IPA: Inference Pipeline Adaptation to Achieve High Accuracy and Cost-Efficiency. (arXiv:2308.12871v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2308.12871</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficiently optimizing multi-model inference pipelines for fast, accurate,
and cost-effective inference is a crucial challenge in machine learning
production systems, given their tight end-to-end latency requirements. To
simplify the exploration of the vast and intricate trade-off space of latency,
accuracy, and cost in inference pipelines, providers frequently opt to consider
one of them. However, the challenge lies in reconciling latency, accuracy, and
cost trade-offs. To address this challenge and propose a solution to
efficiently manage model variants in inference pipelines, we present IPA, an
online deep learning Inference Pipeline Adaptation system that efficiently
leverages model variants for each deep learning task. Model variants are
different versions of pre-trained models for the same deep learning task with
variations in resource requirements, latency, and accuracy. IPA dynamically
configures batch size, replication, and model variants to optimize accuracy,
minimize costs, and meet user-defined latency Service Level Agreements (SLAs)
using Integer Programming. It supports multi-objective settings for achieving
different trade-offs between accuracy and cost objectives while remaining
adaptable to varying workloads and dynamic traffic patterns. Navigating a wider
variety of configurations allows \namex{} to achieve better trade-offs between
cost and accuracy objectives compared to existing methods. Extensive
experiments in a Kubernetes implementation with five real-world inference
pipelines demonstrate that IPA improves end-to-end accuracy by up to 21% with a
minimal cost increase. The code and data for replications are available at
https://github.com/reconfigurable-ml-pipeline/ipa.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghafouri_S/0/1/0/all/0/1&quot;&gt;Saeid Ghafouri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razavi_K/0/1/0/all/0/1&quot;&gt;Kamran Razavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salmani_M/0/1/0/all/0/1&quot;&gt;Mehran Salmani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanaee_A/0/1/0/all/0/1&quot;&gt;Alireza Sanaee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lorido_Botran_T/0/1/0/all/0/1&quot;&gt;Tania Lorido-Botran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doyle_J/0/1/0/all/0/1&quot;&gt;Joseph Doyle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamshidi_P/0/1/0/all/0/1&quot;&gt;Pooyan Jamshidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.04452">
<title>Postprocessing of Ensemble Weather Forecasts Using Permutation-invariant Neural Networks. (arXiv:2309.04452v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2309.04452</link>
<description rdf:parseType="Literal">&lt;p&gt;Statistical postprocessing is used to translate ensembles of raw numerical
weather forecasts into reliable probabilistic forecast distributions. In this
study, we examine the use of permutation-invariant neural networks for this
task. In contrast to previous approaches, which often operate on ensemble
summary statistics and dismiss details of the ensemble distribution, we propose
networks that treat forecast ensembles as a set of unordered member forecasts
and learn link functions that are by design invariant to permutations of the
member ordering. We evaluate the quality of the obtained forecast distributions
in terms of calibration and sharpness and compare the models against classical
and neural network-based benchmark methods. In case studies addressing the
postprocessing of surface temperature and wind gust forecasts, we demonstrate
state-of-the-art prediction quality. To deepen the understanding of the learned
inference process, we further propose a permutation-based importance analysis
for ensemble-valued predictors, which highlights specific aspects of the
ensemble forecast that are considered important by the trained postprocessing
models. Our results suggest that most of the relevant information is contained
in a few ensemble-internal degrees of freedom, which may impact the design of
future ensemble forecasting and postprocessing systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hohlein_K/0/1/0/all/0/1&quot;&gt;Kevin H&amp;#xf6;hlein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schulz_B/0/1/0/all/0/1&quot;&gt;Benedikt Schulz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Westermann_R/0/1/0/all/0/1&quot;&gt;R&amp;#xfc;diger Westermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lerch_S/0/1/0/all/0/1&quot;&gt;Sebastian Lerch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.07988">
<title>Folding Attention: Memory and Power Optimization for On-Device Transformer-based Streaming Speech Recognition. (arXiv:2309.07988v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.07988</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer-based models excel in speech recognition. Existing efforts to
optimize Transformer inference, typically for long-context applications, center
on simplifying attention score calculations. However, streaming speech
recognition models usually process a limited number of tokens each time, making
attention score calculation less of a bottleneck. Instead, the bottleneck lies
in the linear projection layers of multi-head attention and feedforward
networks, constituting a substantial portion of the model size and contributing
significantly to computation, memory, and power usage.
&lt;/p&gt;
&lt;p&gt;To address this bottleneck, we propose folding attention, a technique
targeting these linear layers, significantly reducing model size and improving
memory and power efficiency. Experiments on on-device Transformer-based
streaming speech recognition models show that folding attention reduces model
size (and corresponding memory consumption) by up to 24% and power consumption
by up to 23%, all without compromising model accuracy or computation overhead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1&quot;&gt;Liangzhen Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shangguan_Y/0/1/0/all/0/1&quot;&gt;Yuan Shangguan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iandola_F/0/1/0/all/0/1&quot;&gt;Forrest N. Iandola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1&quot;&gt;Zhaoheng Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1&quot;&gt;Ernie Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yangyang Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1&quot;&gt;Vikas Chandra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11623">
<title>Leveraging Negative Signals with Self-Attention for Sequential Music Recommendation. (arXiv:2309.11623v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2309.11623</link>
<description rdf:parseType="Literal">&lt;p&gt;Music streaming services heavily rely on their recommendation engines to
continuously provide content to their consumers. Sequential recommendation
consequently has seen considerable attention in current literature, where state
of the art approaches focus on self-attentive models leveraging contextual
information such as long and short-term user history and item features;
however, most of these studies focus on long-form content domains (retail,
movie, etc.) rather than short-form, such as music. Additionally, many do not
explore incorporating negative session-level feedback during training. In this
study, we investigate the use of transformer-based self-attentive architectures
to learn implicit session-level information for sequential music
recommendation. We additionally propose a contrastive learning task to
incorporate negative feedback (e.g skipped tracks) to promote positive hits and
penalize negative hits. This task is formulated as a simple loss term that can
be incorporated into a variety of deep learning architectures for sequential
recommendation. Our experiments show that this results in consistent
performance gains over the baseline architectures ignoring negative user
feedback.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seshadri_P/0/1/0/all/0/1&quot;&gt;Pavan Seshadri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knees_P/0/1/0/all/0/1&quot;&gt;Peter Knees&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.14393">
<title>LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models. (arXiv:2309.14393v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.14393</link>
<description rdf:parseType="Literal">&lt;p&gt;The carbon footprint associated with large language models (LLMs) is a
significant concern, encompassing emissions from their training, inference,
experimentation, and storage processes, including operational and embodied
carbon emissions. An essential aspect is accurately estimating the carbon
impact of emerging LLMs even before their training, which heavily relies on GPU
usage. Existing studies have reported the carbon footprint of LLM training, but
only one tool, mlco2, can predict the carbon footprint of new neural networks
prior to physical training. However, mlco2 has several serious limitations. It
cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs,
disregards critical architectural parameters, focuses solely on GPUs, and
cannot model embodied carbon footprints. Addressing these gaps, we introduce
\textit{\carb}, an end-to-end carbon footprint projection model designed for
both dense and MoE LLMs. Compared to mlco2, \carb~significantly enhances the
accuracy of carbon footprint estimations for various LLMs. The source code is
released at \url{https://github.com/SotaroKaneda/MLCarbon}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faiz_A/0/1/0/all/0/1&quot;&gt;Ahmad Faiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaneda_S/0/1/0/all/0/1&quot;&gt;Sotaro Kaneda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruhan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osi_R/0/1/0/all/0/1&quot;&gt;Rita Osi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1&quot;&gt;Prateek Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1&quot;&gt;Fan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1&quot;&gt;Lei Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01202">
<title>Unified Uncertainty Calibration. (arXiv:2310.01202v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2310.01202</link>
<description rdf:parseType="Literal">&lt;p&gt;To build robust, fair, and safe AI systems, we would like our classifiers to
say ``I don&apos;t know&apos;&apos; when facing test examples that are difficult or fall
outside of the training classes.The ubiquitous strategy to predict under
uncertainty is the simplistic \emph{reject-or-classify} rule: abstain from
prediction if epistemic uncertainty is high, classify otherwise.Unfortunately,
this recipe does not allow different sources of uncertainty to communicate with
each other, produces miscalibrated predictions, and it does not allow to
correct for misspecifications in our uncertainty estimates. To address these
three issues, we introduce \emph{unified uncertainty calibration (U2C)}, a
holistic framework to combine aleatoric and epistemic uncertainties. U2C
enables a clean learning-theoretical analysis of uncertainty estimation, and
outperforms reject-or-classify across a variety of ImageNet benchmarks. Our
code is available at:
https://github.com/facebookresearch/UnifiedUncertaintyCalibration
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chaudhuri_K/0/1/0/all/0/1&quot;&gt;Kamalika Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lopez_Paz_D/0/1/0/all/0/1&quot;&gt;David Lopez-Paz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03298">
<title>A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling. (arXiv:2310.03298v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03298</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-fidelity (MF) methods are gaining popularity for enhancing surrogate
modeling and design optimization by incorporating data from various
low-fidelity (LF) models. While most existing MF methods assume a fixed
dataset, adaptive sampling methods that dynamically allocate resources among
fidelity models can achieve higher efficiency in the exploring and exploiting
the design space. However, most existing MF methods rely on the hierarchical
assumption of fidelity levels or fail to capture the intercorrelation between
multiple fidelity levels and utilize it to quantify the value of the future
samples and navigate the adaptive sampling. To address this hurdle, we propose
a framework hinged on a latent embedding for different fidelity models and the
associated pre-posterior analysis to explicitly utilize their correlation for
adaptive sampling. In this framework, each infill sampling iteration includes
two steps: We first identify the location of interest with the greatest
potential improvement using the high-fidelity (HF) model, then we search for
the next sample across all fidelity levels that maximize the improvement per
unit cost at the location identified in the first step. This is made possible
by a single Latent Variable Gaussian Process (LVGP) model that maps different
fidelity models into an interpretable latent space to capture their
correlations without assuming hierarchical fidelity levels. The LVGP enables us
to assess how LF sampling candidates will affect HF response with pre-posterior
analysis and determine the next sample with the best benefit-to-cost ratio.
Through test cases, we demonstrate that the proposed method outperforms the
benchmark methods in both MF global fitting (GF) and Bayesian Optimization (BO)
problems in convergence rate and robustness. Moreover, the method offers the
flexibility to switch between GF and BO by simply changing the acquisition
function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yi-Ping Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Comlek_Y/0/1/0/all/0/1&quot;&gt;Yigitcan Comlek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03320">
<title>BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs. (arXiv:2310.03320v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03320</link>
<description rdf:parseType="Literal">&lt;p&gt;Foundation models (FMs) are able to leverage large volumes of unlabeled data
to demonstrate superior performance across a wide range of tasks. However, FMs
developed for biomedical domains have largely remained unimodal, i.e.,
independently trained and used for tasks on protein sequences alone, small
molecule structures alone, or clinical data alone. To overcome this limitation
of biomedical FMs, we present BioBridge, a novel parameter-efficient learning
framework, to bridge independently trained unimodal FMs to establish multimodal
behavior. BioBridge achieves it by utilizing Knowledge Graphs (KG) to learn
transformations between one unimodal FM and another without fine-tuning any
underlying unimodal FMs. Our empirical results demonstrate that BioBridge can
beat the best baseline KG embedding methods (on average by around 76.3%) in
cross-modal retrieval tasks. We also identify BioBridge demonstrates
out-of-domain generalization ability by extrapolating to unseen modalities or
relations. Additionally, we also show that BioBridge presents itself as a
general purpose retriever that can aid biomedical multimodal question answering
as well as enhance the guided generation of novel drugs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zifeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zichen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1&quot;&gt;Balasubramaniam Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ioannidis_V/0/1/0/all/0/1&quot;&gt;Vassilis N. Ioannidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rangwala_H/0/1/0/all/0/1&quot;&gt;Huzefa Rangwala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anubhai_R/0/1/0/all/0/1&quot;&gt;Rishita Anubhai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04965">
<title>MULTISCRIPT: Multimodal Script Learning for Supporting Open Domain Everyday Tasks. (arXiv:2310.04965v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.04965</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatically generating scripts (i.e. sequences of key steps described in
text) from video demonstrations and reasoning about the subsequent steps are
crucial to the modern AI virtual assistants to guide humans to complete
everyday tasks, especially unfamiliar ones. However, current methods for
generative script learning rely heavily on well-structured preceding steps
described in text and/or images or are limited to a certain domain, resulting
in a disparity with real-world user scenarios. To address these limitations, we
present a new benchmark challenge -- MultiScript, with two new tasks on
task-oriented multimodal script learning: (1) multimodal script generation, and
(2) subsequent step prediction. For both tasks, the input consists of a target
task name and a video illustrating what has been done to complete the target
task, and the expected output is (1) a sequence of structured step descriptions
in text based on the demonstration video, and (2) a single text description for
the subsequent step, respectively. Built from WikiHow, MultiScript covers
multimodal scripts in videos and text descriptions for over 6,655 human
everyday tasks across 19 diverse domains. To establish baseline performance on
MultiScript, we propose two knowledge-guided multimodal generative frameworks
that incorporate the task-related knowledge prompted from large language models
such as Vicuna. Experimental results show that our proposed approaches
significantly improve over the competitive baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1&quot;&gt;Jingyuan Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Minqian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Ying Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhiyang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lifu Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.05492">
<title>How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition. (arXiv:2310.05492v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.05492</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) with enormous pre-training tokens and parameters
emerge diverse abilities, including math reasoning, code generation, and
instruction following. These abilities are further enhanced by supervised
fine-tuning (SFT). While the open-source community has explored ad-hoc SFT for
enhancing individual capabilities, proprietary LLMs exhibit versatility across
various skills. Therefore, understanding the facilitation of multiple abilities
via SFT is paramount. In this study, we specifically focuses on the interplay
of data composition between mathematical reasoning, code generation, and
general human-aligning abilities during SFT. We propose four intriguing
research questions to explore the association between model performance and
various factors including data amount, composition ratio, model size and SFT
strategies. Our experiments reveal that distinct capabilities scale differently
and larger models generally show superior performance with same amount of data.
Mathematical reasoning and code generation consistently improve with increasing
data amount, whereas general abilities plateau after roughly a thousand
samples. Moreover, we observe data composition appears to enhance various
abilities under limited data conditions, yet can lead to performance conflicts
when data is plentiful. Our findings also suggest the amount of composition
data influences performance more than the composition ratio. In analysis of SFT
strategies, we find that sequentially learning multiple skills risks
catastrophic forgetting. Our proposed Dual-stage Mixed Fine-tuning (DMT)
strategy offers a promising solution to learn multiple abilities with different
scaling patterns.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1&quot;&gt;Guanting Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1&quot;&gt;Hongyi Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1&quot;&gt;Keming Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chengpeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1&quot;&gt;Mingfeng Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Dayiheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1&quot;&gt;Zheng Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1&quot;&gt;Chang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jingren Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.12955">
<title>Towards Robust Offline Reinforcement Learning under Diverse Data Corruption. (arXiv:2310.12955v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.12955</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline reinforcement learning (RL) presents a promising approach for
learning reinforced policies from offline datasets without the need for costly
or unsafe interactions with the environment. However, datasets collected by
humans in real-world environments are often noisy and may even be maliciously
corrupted, which can significantly degrade the performance of offline RL. In
this work, we first investigate the performance of current offline RL
algorithms under comprehensive data corruption, including states, actions,
rewards, and dynamics. Our extensive experiments reveal that implicit
Q-learning (IQL) demonstrates remarkable resilience to data corruption among
various offline RL algorithms. Furthermore, we conduct both empirical and
theoretical analyses to understand IQL&apos;s robust performance, identifying its
supervised policy learning scheme as the key factor. Despite its relative
robustness, IQL still suffers from heavy-tail targets of Q functions under
dynamics corruption. To tackle this challenge, we draw inspiration from robust
statistics to employ the Huber loss to handle the heavy-tailedness and utilize
quantile estimators to balance penalization for corrupted data and learning
stability. By incorporating these simple yet effective modifications into IQL,
we propose a more robust offline RL approach named Robust IQL (RIQL). Extensive
experiments demonstrate that RIQL exhibits highly robust performance when
subjected to diverse data corruption scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Rui Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1&quot;&gt;Han Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiawei Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Amy Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chongjie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1&quot;&gt;Lei Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13384">
<title>Salted Inference: Enhancing Privacy while Maintaining Efficiency of Split Inference in Mobile Computing. (arXiv:2310.13384v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13384</link>
<description rdf:parseType="Literal">&lt;p&gt;In split inference, a deep neural network (DNN) is partitioned to run the
early part of the DNN at the edge and the later part of the DNN in the cloud.
This meets two key requirements for on-device machine learning: input privacy
and computation efficiency. Still, an open question in split inference is
output privacy, given that the outputs of the DNN are observable in the cloud.
While encrypted computing can protect output privacy too, homomorphic
encryption requires substantial computation and communication resources from
both edge and cloud devices. In this paper, we introduce Salted DNNs: a novel
approach that enables clients at the edge, who run the early part of the DNN,
to control the semantic interpretation of the DNN&apos;s outputs at inference time.
Our proposed Salted DNNs maintain classification accuracy and computation
efficiency very close to the standard DNN counterparts. Experimental
evaluations conducted on both images and wearable sensor data demonstrate that
Salted DNNs attain classification accuracy very close to standard DNNs,
particularly when the Salted Layer is positioned within the early part to meet
the requirements of split inference. Our approach is general and can be applied
to various types of DNNs. As a benchmark for future studies, we open-source our
code.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malekzadeh_M/0/1/0/all/0/1&quot;&gt;Mohammad Malekzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawsar_F/0/1/0/all/0/1&quot;&gt;Fahim Kawsar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.03976">
<title>A Foundation Graph Model. (arXiv:2311.03976v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.03976</link>
<description rdf:parseType="Literal">&lt;p&gt;The principal benefit of unsupervised graph representation learning is that a
pre-trained model can be fine-tuned where data or labels are scarce. Existing
approaches are domain specific, maintaining consistent node and edge attributes
across the pre-training and target datasets. This precludes transfer to other
domains. A model capable of positive transfer on arbitrary tasks and domains
would represent the first foundation graph model.
&lt;/p&gt;
&lt;p&gt;In this work we use adversarial contrastive learning to present FoToM, a
graph pre-training method based on node and edge feature exclusion. We use
FoToM to pre-train models over multiple graph domains, producing the first
foundation graph models. We demonstrate positive transfer on evaluation
datasets from multiple domains, including domains not present in pre-training
data. On all datasets performance is at worst on-par and on 76% significantly
better than a supervised baseline ($P \leq 0.01$), with an 8 to 40% reduction
in error at 95% confidence. Contrary to other research, pre-training on a
dataset with the target domain excluded leads us to better performance than
pre-training on a dataset from only the target domain. The multi-domain model
at worst, matches, and on 56% of tasks, significantly outperforms single-domain
($P \leq 0.01$). These results include when node labels are used in evaluation,
where performance is consistently superior to single-domain or non-pre-trained
models. Notably, FoToM benefits scenarios in both large or scarce data regimes
for the target domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davies_A/0/1/0/all/0/1&quot;&gt;Alex O. Davies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Green_R/0/1/0/all/0/1&quot;&gt;Riku W. Green&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ajmeri_N/0/1/0/all/0/1&quot;&gt;Nirav S. Ajmeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filho_T/0/1/0/all/0/1&quot;&gt;Telmo M. Silva Filho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.07202">
<title>Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model Predictive Control. (arXiv:2311.07202v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.07202</link>
<description rdf:parseType="Literal">&lt;p&gt;Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive
Control (MPC) successfully attains globally optimal solutions by upholding
convexity within the MPC framework. However, current ICNN architectures
encounter the issue of vanishing/exploding gradients, which limits their
ability to serve as deep neural networks for complex tasks. Additionally, the
current neural network-based MPC, including conventional neural network-based
MPC and ICNN-based MPC, faces slower convergence speed when compared to MPC
based on first-principles models. In this study, we leverage the principles of
ICNNs to propose a novel Input Convex LSTM for Lyapunov-based MPC, with the
specific goal of reducing convergence time and mitigating the
vanishing/exploding gradient problem while ensuring closed-loop stability. From
a simulation study of a nonlinear chemical reactor, we observed a mitigation of
vanishing/exploding gradient problem and a reduction in convergence time, with
a percentage decrease of 46.7%, 31.3%, and 20.2% compared to baseline plain
RNN, plain LSTM, and Input Convex Recurrent Neural Networks, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zihao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhe Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.11809">
<title>LogLead -- Fast and Integrated Log Loader, Enhancer, and Anomaly Detector. (arXiv:2311.11809v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2311.11809</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces LogLead, a tool designed for efficient log analysis
benchmarking. LogLead combines three essential steps in log processing:
loading, enhancing, and anomaly detection. The tool leverages Polars, a
high-speed DataFrame library. We currently have Loaders for eight systems that
are publicly available (HDFS, Hadoop, BGL, Thunderbird, Spirit, Liberty,
TrainTicket, and GC Webshop). We have multiple enhancers with three parsers
(Drain, Spell, LenMa), Bert embedding creation and other log representation
techniques like bag-of-words. LogLead integrates to five supervised and four
unsupervised machine learning algorithms for anomaly detection from SKLearn. By
integrating diverse datasets, log representation methods and anomaly detectors,
LogLead facilitates comprehensive benchmarking in log analysis research. We
show that log loading from raw file to dataframe is over 10x faster with
LogLead compared to past solutions. We demonstrate roughly 2x improvement in
Drain parsing speed by off-loading log message normalization to LogLead. Our
brief benchmarking on HDFS indicates that log representations extending beyond
the bag-of-words approach offer limited additional benefits. Tool URL:
https://github.com/EvoTestOps/LogLead
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mantyla_M/0/1/0/all/0/1&quot;&gt;Mika M&amp;#xe4;ntyl&amp;#xe4;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuqing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nyyssola_J/0/1/0/all/0/1&quot;&gt;Jesse Nyyss&amp;#xf6;l&amp;#xe4;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.12399">
<title>A Survey of Graph Meets Large Language Model: Progress and Future Directions. (arXiv:2311.12399v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.12399</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph plays a significant role in representing and analyzing complex
relationships in real-world applications such as citation networks, social
networks, and biological data. Recently, Large Language Models (LLMs), which
have achieved tremendous success in various domains, have also been leveraged
in graph-related tasks to surpass traditional Graph Neural Networks (GNNs)
based methods and yield state-of-the-art performance. In this survey, we first
present a comprehensive review and analysis of existing methods that integrate
LLMs with graphs. First of all, we propose a new taxonomy, which organizes
existing methods into three categories based on the role (i.e., enhancer,
predictor, and alignment component) played by LLMs in graph-related tasks. Then
we systematically survey the representative methods along the three categories
of the taxonomy. Finally, we discuss the remaining limitations of existing
studies and highlight promising avenues for future research. The relevant
papers are summarized and will be consistently updated at:
https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuhan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhixun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Peisong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xiangguo Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1&quot;&gt;Hong Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jeffrey Xu Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.15497">
<title>Adaptive Image Registration: A Hybrid Approach Integrating Deep Learning and Optimization Functions for Enhanced Precision. (arXiv:2311.15497v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2311.15497</link>
<description rdf:parseType="Literal">&lt;p&gt;Image registration has traditionally been done using two distinct approaches:
learning based methods, relying on robust deep neural networks, and
optimization-based methods, applying complex mathematical transformations to
warp images accordingly. Of course, both paradigms offer advantages and
disadvantages, and, in this work, we seek to combine their respective strengths
into a single streamlined framework, using the outputs of the learning based
method as initial parameters for optimization while prioritizing computational
power for the image pairs that offer the greatest loss. Our investigations
showed improvements of up to 1.6% in test data, while maintaining the same
inference time, and a substantial 1.0% points performance gain in deformation
field smoothness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Araujo_G/0/1/0/all/0/1&quot;&gt;Gabriel De Araujo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Shanlin Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xiaohui Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.18426">
<title>Convergence Analysis of Fractional Gradient Descent. (arXiv:2311.18426v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2311.18426</link>
<description rdf:parseType="Literal">&lt;p&gt;Fractional derivatives are a well-studied generalization of integer order
derivatives. Naturally, for optimization, it is of interest to understand the
convergence properties of gradient descent using fractional derivatives.
Convergence analysis of fractional gradient descent is currently limited both
in the methods analyzed and the settings analyzed. This paper aims to fill in
these gaps by analyzing variations of fractional gradient descent in smooth and
convex, smooth and strongly convex, and smooth and non-convex settings. First,
novel bounds will be established bridging fractional and integer derivatives.
Then, these bounds will be applied to the aforementioned settings to prove
linear convergence for smooth and strongly convex functions and $O(1/T)$
convergence for smooth and convex functions. Additionally, we prove $O(1/T)$
convergence for smooth and non-convex functions using an extended notion of
smoothness - H\&quot;older smoothness - that is more natural for fractional
derivatives. Finally, empirical results will be presented on the potential
speed up of fractional gradient descent over standard gradient descent as well
as the challenges of predicting which will be faster in general.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Aggarwal_A/0/1/0/all/0/1&quot;&gt;Ashwani Aggarwal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.00067">
<title>Predicting breast cancer with AI for individual risk-adjusted MRI screening and early detection. (arXiv:2312.00067v2 [physics.med-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2312.00067</link>
<description rdf:parseType="Literal">&lt;p&gt;Women with an increased life-time risk of breast cancer undergo supplemental
annual screening MRI. We propose to predict the risk of developing breast
cancer within one year based on the current MRI, with the objective of reducing
screening burden and facilitating early detection. An AI algorithm was
developed on 53,858 breasts from 12,694 patients who underwent screening or
diagnostic MRI and accrued over 12 years, with 2,331 confirmed cancers. A first
U-Net was trained to segment lesions and identify regions of concern. A second
convolutional network was trained to detect malignant cancer using features
extracted by the U-Net. This network was then fine-tuned to estimate the risk
of developing cancer within a year in cases that radiologists considered normal
or likely benign. Risk predictions from this AI were evaluated with a
retrospective analysis of 9,183 breasts from a high-risk screening cohort,
which were not used for training. Statistical analysis focused on the tradeoff
between number of omitted exams versus negative predictive value, and number of
potential early detections versus positive predictive value. The AI algorithm
identified regions of concern that coincided with future tumors in 52% of
screen-detected cancers. Upon directed review, a radiologist found that 71.3%
of cancers had a visible correlate on the MRI prior to diagnosis, 65% of these
correlates were identified by the AI model. Reevaluating these regions in 10%
of all cases with higher AI-predicted risk could have resulted in up to 33%
early detections by a radiologist. Additionally, screening burden could have
been reduced in 16% of lower-risk cases by recommending a later follow-up
without compromising current interval cancer rate. With increasing datasets and
improving image quality we expect this new AI-aided, adaptive screening to
meaningfully reduce screening burden and improve early detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hirsch_L/0/1/0/all/0/1&quot;&gt;Lukas Hirsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Makse_H/0/1/0/all/0/1&quot;&gt;Hernan A. Makse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Martinez_D/0/1/0/all/0/1&quot;&gt;Danny F. Martinez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hughes_M/0/1/0/all/0/1&quot;&gt;Mary Hughes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Eskreis_Winkler_S/0/1/0/all/0/1&quot;&gt;Sarah Eskreis-Winkler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Pinker_K/0/1/0/all/0/1&quot;&gt;Katja Pinker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Morris_E/0/1/0/all/0/1&quot;&gt;Elizabeth Morris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Parra_L/0/1/0/all/0/1&quot;&gt;Lucas C. Parra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Sutton_E/0/1/0/all/0/1&quot;&gt;Elizabeth J. Sutton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.01185">
<title>A ripple in time: a discontinuity in American history. (arXiv:2312.01185v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.01185</link>
<description rdf:parseType="Literal">&lt;p&gt;In this note we use the State of the Union Address (SOTU) dataset from Kaggle
to make some surprising (and some not so surprising) observations pertaining to
the general timeline of American history, and the character and nature of the
addresses themselves. Our main approach is using vector embeddings, such as
BERT (DistilBERT) and GPT-2.
&lt;/p&gt;
&lt;p&gt;While it is widely believed that BERT (and its variations) is most suitable
for NLP classification tasks, we find out that GPT-2 in conjunction with
nonlinear dimension reduction methods such as UMAP provide better separation
and stronger clustering. This makes GPT-2 + UMAP an interesting alternative. In
our case, no model fine-tuning is required, and the pre-trained out-of-the-box
GPT-2 model is enough.
&lt;/p&gt;
&lt;p&gt;We also used a fine-tuned DistilBERT model for classification detecting which
President delivered which address, with very good results (accuracy 93\% - 95\%
depending on the run). An analogous task was performed to determine the year of
writing, and we were able to pin it down to about 4 years (which is a single
presidential term).
&lt;/p&gt;
&lt;p&gt;It is worth noting that SOTU addresses provide relatively small writing
samples (with about 8000 words on average, and varying widely from under 2000
words to more than 20000), and that the amount of authors is relatively large
(we used SOTU addresses of 42 US presidents). This shows that the techniques
employed turn out to be rather efficient, while all the computations described
in this note can be performed using a single GPU instance of Google Colab.
&lt;/p&gt;
&lt;p&gt;The accompanying code is available on GitHub.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolpakov_A/0/1/0/all/0/1&quot;&gt;Alexander Kolpakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rivin_I/0/1/0/all/0/1&quot;&gt;Igor Rivin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05225">
<title>Neural Spectral Methods: Self-supervised learning in the spectral domain. (arXiv:2312.05225v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.05225</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Neural Spectral Methods, a technique to solve parametric Partial
Differential Equations (PDEs), grounded in classical spectral methods. Our
method uses orthogonal bases to learn PDE solutions as mappings between
spectral coefficients. In contrast to current machine learning approaches which
enforce PDE constraints by minimizing the numerical quadrature of the residuals
in the spatiotemporal domain, we leverage Parseval&apos;s identity and introduce a
new training strategy through a \textit{spectral loss}. Our spectral loss
enables more efficient differentiation through the neural network, and
substantially reduces training complexity. At inference time, the computational
cost of our method remains constant, regardless of the spatiotemporal
resolution of the domain. Our experimental results demonstrate that our method
significantly outperforms previous machine learning approaches in terms of
speed and accuracy by one to two orders of magnitude on multiple different
problems. When compared to numerical solvers of the same accuracy, our method
demonstrates a $10\times$ increase in performance speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yiheng Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalapathi_N/0/1/0/all/0/1&quot;&gt;Nithin Chalapathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnapriyan_A/0/1/0/all/0/1&quot;&gt;Aditi Krishnapriyan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08010">
<title>EZ-CLIP: Efficient Zeroshot Video Action Recognition. (arXiv:2312.08010v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2312.08010</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advancements in large-scale pre-training of visual-language models on
paired image-text data have demonstrated impressive generalization capabilities
for zero-shot tasks. Building on this success, efforts have been made to adapt
these image-based visual-language models, such as CLIP, for videos extending
their zero-shot capabilities to the video domain. While these adaptations have
shown promising results, they come at a significant computational cost and
struggle with effectively modeling the crucial temporal aspects inherent to the
video domain. In this study, we present EZ-CLIP, a simple and efficient
adaptation of CLIP that addresses these challenges. EZ-CLIP leverages temporal
visual prompting for seamless temporal adaptation, requiring no fundamental
alterations to the core CLIP architecture while preserving its remarkable
generalization abilities. Moreover, we introduce a novel learning objective
that guides the temporal visual prompts to focus on capturing motion, thereby
enhancing its learning capabilities from video data. We conducted extensive
experiments on five different benchmark datasets, thoroughly evaluating EZ-CLIP
for zero-shot learning and base-to-novel video action recognition, and also
demonstrating its potential for few-shot generalization.Impressively, with a
mere 5.2 million learnable parameters (as opposed to the 71.1 million in the
prior best model), EZ-CLIP can be efficiently trained on a single GPU,
outperforming existing approaches in several evaluations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmad_S/0/1/0/all/0/1&quot;&gt;Shahzad Ahmad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chanda_S/0/1/0/all/0/1&quot;&gt;Sukalpa Chanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rawat_Y/0/1/0/all/0/1&quot;&gt;Yogesh S Rawat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09234">
<title>Let&apos;s do the time-warp-attend: Learning topological invariants of dynamical systems. (arXiv:2312.09234v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.09234</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamical systems across the sciences, from electrical circuits to ecological
networks, undergo qualitative and often catastrophic changes in behavior,
called bifurcations, when their underlying parameters cross a threshold.
Existing methods predict oncoming catastrophes in individual systems but are
primarily time-series-based and struggle both to categorize qualitative
dynamical regimes across diverse systems and to generalize to real data. To
address this challenge, we propose a data-driven, physically-informed
deep-learning framework for classifying dynamical regimes and characterizing
bifurcation boundaries based on the extraction of topologically invariant
features. We focus on the paradigmatic case of the supercritical Hopf
bifurcation, which is used to model periodic dynamics across a wide range of
applications. Our convolutional attention method is trained with data
augmentations that encourage the learning of topological invariants which can
be used to detect bifurcation boundaries in unseen systems and to design models
of biological systems like oscillatory gene regulatory networks. We further
demonstrate our method&apos;s use in analyzing real data by recovering distinct
proliferation and differentiation dynamics along pancreatic endocrinogenesis
trajectory in gene expression space based on single-cell data. Our method
provides valuable insights into the qualitative, long-term behavior of a wide
range of dynamical systems, and can detect bifurcations or catastrophic
transitions in large-scale physical and biological systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moriel_N/0/1/0/all/0/1&quot;&gt;Noa Moriel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ricci_M/0/1/0/all/0/1&quot;&gt;Matthew Ricci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nitzan_M/0/1/0/all/0/1&quot;&gt;Mor Nitzan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10401">
<title>Rethinking Dimensional Rationale in Graph Contrastive Learning from Causal Perspective. (arXiv:2312.10401v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.10401</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph contrastive learning is a general learning paradigm excelling at
capturing invariant information from diverse perturbations in graphs. Recent
works focus on exploring the structural rationale from graphs, thereby
increasing the discriminability of the invariant information. However, such
methods may incur in the mis-learning of graph models towards the
interpretability of graphs, and thus the learned noisy and task-agnostic
information interferes with the prediction of graphs. To this end, with the
purpose of exploring the intrinsic rationale of graphs, we accordingly propose
to capture the dimensional rationale from graphs, which has not received
sufficient attention in the literature. The conducted exploratory experiments
attest to the feasibility of the aforementioned roadmap. To elucidate the
innate mechanism behind the performance improvement arising from the
dimensional rationale, we rethink the dimensional rationale in graph
contrastive learning from a causal perspective and further formalize the
causality among the variables in the pre-training stage to build the
corresponding structural causal model. On the basis of the understanding of the
structural causal model, we propose the dimensional rationale-aware graph
contrastive learning approach, which introduces a learnable dimensional
rationale acquiring network and a redundancy reduction constraint. The
learnable dimensional rationale acquiring network is updated by leveraging a
bi-level meta-learning technique, and the redundancy reduction constraint
disentangles the redundant features through a decorrelation process during
learning. Empirically, compared with state-of-the-art methods, our method can
yield significant performance boosts on various benchmarks with respect to
discriminability and transferability. The code implementation of our method is
available at https://github.com/ByronJi/DRGCL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_Q/0/1/0/all/0/1&quot;&gt;Qirui Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiangmeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jie Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Rui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Changwen Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1&quot;&gt;Fanjiang Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.13110">
<title>Pre-training of Molecular GNNs via Conditional Boltzmann Generator. (arXiv:2312.13110v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.13110</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning representations of molecular structures using deep learning is a
fundamental problem in molecular property prediction tasks. Molecules
inherently exist in the real world as three-dimensional structures;
furthermore, they are not static but in continuous motion in the 3D Euclidean
space, forming a potential energy surface. Therefore, it is desirable to
generate multiple conformations in advance and extract molecular
representations using a 4D-QSAR model that incorporates multiple conformations.
However, this approach is impractical for drug and material discovery tasks
because of the computational cost of obtaining multiple conformations. To
address this issue, we propose a pre-training method for molecular GNNs using
an existing dataset of molecular conformations to generate a latent vector
universal to multiple conformations from a 2D molecular graph. Our method,
called Boltzmann GNN, is formulated by maximizing the conditional marginal
likelihood of a conditional generative model for conformations generation. We
show that our model has a better prediction performance for molecular
properties than existing pre-training methods using molecular graphs and
three-dimensional molecular structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koge_D/0/1/0/all/0/1&quot;&gt;Daiki Koge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ono_N/0/1/0/all/0/1&quot;&gt;Naoaki Ono&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanaya_S/0/1/0/all/0/1&quot;&gt;Shigehiko Kanaya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.13486">
<title>Meta-Learning with Versatile Loss Geometries for Fast Adaptation Using Mirror Descent. (arXiv:2312.13486v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.13486</link>
<description rdf:parseType="Literal">&lt;p&gt;Utilizing task-invariant prior knowledge extracted from related tasks,
meta-learning is a principled framework that empowers learning a new task
especially when data records are limited. A fundamental challenge in
meta-learning is how to quickly &quot;adapt&quot; the extracted prior in order to train a
task-specific model within a few optimization steps. Existing approaches deal
with this challenge using a preconditioner that enhances convergence of the
per-task training process. Though effective in representing locally a quadratic
training loss, these simple linear preconditioners can hardly capture complex
loss geometries. The present contribution addresses this limitation by learning
a nonlinear mirror map, which induces a versatile distance metric to enable
capturing and optimizing a wide range of loss geometries, hence facilitating
the per-task training. Numerical tests on few-shot learning datasets
demonstrate the superior expressiveness and convergence of the advocated
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yilang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bingcong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giannakis_G/0/1/0/all/0/1&quot;&gt;Georgios B. Giannakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.15591">
<title>Privacy-Preserving Neural Graph Databases. (arXiv:2312.15591v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/2312.15591</link>
<description rdf:parseType="Literal">&lt;p&gt;In the era of big data and rapidly evolving information systems, efficient
and accurate data retrieval has become increasingly crucial. Neural graph
databases (NGDBs) have emerged as a powerful paradigm that combines the
strengths of graph databases (graph DBs) and neural networks to enable
efficient storage, retrieval, and analysis of graph-structured data. The usage
of neural embedding storage and complex neural logical query answering provides
NGDBs with generalization ability. When the graph is incomplete, by extracting
latent patterns and representations, neural graph databases can fill gaps in
the graph structure, revealing hidden relationships and enabling accurate query
answering. Nevertheless, this capability comes with inherent trade-offs, as it
introduces additional privacy risks to the database. Malicious attackers can
infer more sensitive information in the database using well-designed
combinatorial queries, such as by comparing the answer sets of where Turing
Award winners born before 1950 and after 1940 lived, the living places of
Turing Award winner Hinton are probably exposed, although the living places may
have been deleted in the training due to the privacy concerns. In this work,
inspired by the privacy protection in graph embeddings, we propose a
privacy-preserving neural graph database (P-NGDB) to alleviate the risks of
privacy leakage in NGDBs. We introduce adversarial training techniques in the
training stage to force the NGDBs to generate indistinguishable answers when
queried with private information, enhancing the difficulty of inferring
sensitive information through combinations of multiple innocuous queries.
Extensive experiment results on three datasets show that P-NGDB can effectively
protect private information in the graph database while delivering high-quality
public answers responses to queries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1&quot;&gt;Qi Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haoran Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1&quot;&gt;Jiaxin Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yangqiu Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00110">
<title>Diffusion Model with Perceptual Loss. (arXiv:2401.00110v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2401.00110</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models trained with mean squared error loss tend to generate
unrealistic samples. Current state-of-the-art models rely on classifier-free
guidance to improve sample quality, yet its surprising effectiveness is not
fully understood. In this paper, we show that the effectiveness of
classifier-free guidance partly originates from it being a form of implicit
perceptual guidance. As a result, we can directly incorporate perceptual loss
in diffusion training to improve sample quality. Since the score matching
objective used in diffusion training strongly resembles the denoising
autoencoder objective used in unsupervised training of perceptual networks, the
diffusion model itself is a perceptual network and can be used to generate
meaningful perceptual loss. We propose a novel self-perceptual objective that
results in diffusion models capable of generating more realistic samples. For
conditional generation, our method only improves sample quality without
entanglement with the conditional input and therefore does not sacrifice sample
diversity. Our method can also improve sample quality for unconditional
generation, which was not possible with classifier-free guidance before.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Shanchuan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xiao Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.04336">
<title>Deep Efficient Private Neighbor Generation for Subgraph Federated Learning. (arXiv:2401.04336v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2401.04336</link>
<description rdf:parseType="Literal">&lt;p&gt;Behemoth graphs are often fragmented and separately stored by multiple data
owners as distributed subgraphs in many realistic applications. Without harming
data privacy, it is natural to consider the subgraph federated learning
(subgraph FL) scenario, where each local client holds a subgraph of the entire
global graph, to obtain globally generalized graph mining models. To overcome
the unique challenge of incomplete information propagation on local subgraphs
due to missing cross-subgraph neighbors, previous works resort to the
augmentation of local neighborhoods through the joint FL of missing neighbor
generators and GNNs. Yet their technical designs have profound limitations
regarding the utility, efficiency, and privacy goals of FL. In this work, we
propose FedDEP to comprehensively tackle these challenges in subgraph FL.
FedDEP consists of a series of novel technical designs: (1) Deep neighbor
generation through leveraging the GNN embeddings of potential missing
neighbors; (2) Efficient pseudo-FL for neighbor generation through embedding
prototyping; and (3) Privacy protection through noise-less
edge-local-differential-privacy. We analyze the correctness and efficiency of
FedDEP, and provide theoretical guarantees on its privacy. Empirical results on
four real-world datasets justify the clear benefits of proposed techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Ke Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Lichao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1&quot;&gt;Bolin Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yiu_S/0/1/0/all/0/1&quot;&gt;Siu Ming Yiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Carl Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.07494">
<title>Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering Tasks. (arXiv:2401.07494v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2401.07494</link>
<description rdf:parseType="Literal">&lt;p&gt;Computational efficiency and adversarial robustness are critical factors in
real-world engineering applications. Yet, conventional neural networks often
fall short in addressing both simultaneously, or even separately. Drawing
insights from natural physical systems and existing literature, it is known
that an input convex architecture enhances computational efficiency, while a
Lipschitz-constrained architecture bolsters adversarial robustness. By
leveraging the strengths of convexity and Lipschitz continuity, we develop a
novel network architecture, termed Input Convex Lipschitz Recurrent Neural
Networks. This model outperforms existing recurrent units across a spectrum of
engineering tasks in terms of computational efficiency and adversarial
robustness. These tasks encompass a benchmark MNIST image classification,
real-world solar irradiance prediction for Solar PV system planning at LHT
Holdings in Singapore, and real-time Model Predictive Control optimization for
a chemical reactor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zihao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pravin_P/0/1/0/all/0/1&quot;&gt;P S Pravin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhe Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.07961">
<title>Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\&quot;odinger Bridge and Reaction-Diffusion PDEs. (arXiv:2401.07961v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2401.07961</link>
<description rdf:parseType="Literal">&lt;p&gt;Lambert&apos;s problem concerns with transferring a spacecraft from a given
initial to a given terminal position within prescribed flight time via velocity
control subject to a gravitational force field. We consider a probabilistic
variant of the Lambert problem where the knowledge of the endpoint constraints
in position vectors are replaced by the knowledge of their respective joint
probability density functions. We show that the Lambert problem with endpoint
joint probability density constraints is a generalized optimal mass transport
(OMT) problem, thereby connecting this classical astrodynamics problem with a
burgeoning area of research in modern stochastic control and stochastic machine
learning. This newfound connection allows us to rigorously establish the
existence and uniqueness of solution for the probabilistic Lambert problem. The
same connection also helps to numerically solve the probabilistic Lambert
problem via diffusion regularization, i.e., by leveraging further connection of
the OMT with the Schr\&quot;odinger bridge problem (SBP). This also shows that the
probabilistic Lambert problem with additive dynamic process noise is in fact a
generalized SBP, and can be solved numerically using the so-called
Schr\&quot;odinger factors, as we do in this work. We explain how the resulting
analysis leads to solving a boundary-coupled system of reaction-diffusion PDEs
where the nonlinear gravitational potential appears as the reaction rate. We
propose novel algorithms for the same, and present illustrative numerical
results. Our analysis and the algorithmic framework are nonparametric, i.e., we
make neither statistical (e.g., Gaussian, first few moments, mixture or
exponential family, finite dimensionality of the sufficient statistic) nor
dynamical (e.g., Taylor series) approximations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Teter_A/0/1/0/all/0/1&quot;&gt;Alexis M.H. Teter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nodozi_I/0/1/0/all/0/1&quot;&gt;Iman Nodozi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Halder_A/0/1/0/all/0/1&quot;&gt;Abhishek Halder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.08169">
<title>Statistical Test for Attention Map in Vision Transformer. (arXiv:2401.08169v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2401.08169</link>
<description rdf:parseType="Literal">&lt;p&gt;The Vision Transformer (ViT) demonstrates exceptional performance in various
computer vision tasks. Attention is crucial for ViT to capture complex
wide-ranging relationships among image patches, allowing the model to weigh the
importance of image patches and aiding our understanding of the decision-making
process. However, when utilizing the attention of ViT as evidence in
high-stakes decision-making tasks such as medical diagnostics, a challenge
arises due to the potential of attention mechanisms erroneously focusing on
irrelevant regions. In this study, we propose a statistical test for ViT&apos;s
attentions, enabling us to use the attentions as reliable quantitative evidence
indicators for ViT&apos;s decision-making with a rigorously controlled error rate.
Using the framework called selective inference, we quantify the statistical
significance of attentions in the form of p-values, which enables the
theoretically grounded quantification of the false positive detection
probability of attentions. We demonstrate the validity and the effectiveness of
the proposed method through numerical experiments and applications to brain
image diagnoses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shiraishi_T/0/1/0/all/0/1&quot;&gt;Tomohiro Shiraishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miwa_D/0/1/0/all/0/1&quot;&gt;Daiki Miwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Katsuoka_T/0/1/0/all/0/1&quot;&gt;Teruyuki Katsuoka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duy_V/0/1/0/all/0/1&quot;&gt;Vo Nguyen Le Duy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Taji_K/0/1/0/all/0/1&quot;&gt;Kouichi Taji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1&quot;&gt;Ichiro Takeuchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.08216">
<title>Towards Efficient and Certified Recovery from Poisoning Attacks in Federated Learning. (arXiv:2401.08216v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2401.08216</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is vulnerable to poisoning attacks, where malicious
clients manipulate their updates to affect the global model. Although various
methods exist for detecting those clients in FL, identifying malicious clients
requires sufficient model updates, and hence by the time malicious clients are
detected, FL models have been already poisoned. Thus, a method is needed to
recover an accurate global model after malicious clients are identified.
Current recovery methods rely on (i) all historical information from
participating FL clients and (ii) the initial model unaffected by the malicious
clients, leading to a high demand for storage and computational resources. In
this paper, we show that highly effective recovery can still be achieved based
on (i) selective historical information rather than all historical information
and (ii) a historical model that has not been significantly affected by
malicious clients rather than the initial model. In this scenario, while
maintaining comparable recovery performance, we can accelerate the recovery
speed and decrease memory consumption. Following this concept, we introduce
Crab, an efficient and certified recovery method, which relies on selective
information storage and adaptive model rollback. Theoretically, we demonstrate
that the difference between the global model recovered by Crab and the one
recovered by train-from-scratch can be bounded under certain assumptions. Our
empirical evaluation, conducted across three datasets over multiple machine
learning models, and a variety of untargeted and targeted poisoning attacks
reveals that Crab is both accurate and efficient, and consistently outperforms
previous approaches in terms of both recovery speed and memory consumption.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yu Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Jiyuan Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Ziyao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1&quot;&gt;Chee Wei Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1&quot;&gt;Kwok-Yan Lam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.08897">
<title>CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder. (arXiv:2401.08897v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2401.08897</link>
<description rdf:parseType="Literal">&lt;p&gt;Symmetries of input and latent vectors have provided valuable insights for
disentanglement learning in VAEs.However, only a few works were proposed as an
unsupervised method, and even these works require known factor information in
training data. We propose a novel method, Composite Factor-Aligned Symmetry
Learning (CFASL), which is integrated into VAEs for learning symmetry-based
disentanglement in unsupervised learning without any knowledge of the dataset
factor information.CFASL incorporates three novel features for learning
symmetry-based disentanglement: 1) Injecting inductive bias to align latent
vector dimensions to factor-aligned symmetries within an explicit learnable
symmetry codebook 2) Learning a composite symmetry to express unknown factors
change between two random samples by learning factor-aligned symmetries within
the codebook 3) Inducing group equivariant encoder and decoder in training VAEs
with the two conditions. In addition, we propose an extended evaluation metric
for multi-factor changes in comparison to disentanglement evaluation in VAEs.
In quantitative and in-depth qualitative analysis, CFASL demonstrates a
significant improvement of disentanglement in single-factor change, and
multi-factor change conditions compared to state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1&quot;&gt;Hee-Jun Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1&quot;&gt;Jaehyoung Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kangil Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.09691">
<title>Imitation Learning Inputting Image Feature to Each Layer of Neural Network. (arXiv:2401.09691v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2401.09691</link>
<description rdf:parseType="Literal">&lt;p&gt;Imitation learning enables robots to learn and replicate human behavior from
training data. Recent advances in machine learning enable end-to-end learning
approaches that directly process high-dimensional observation data, such as
images. However, these approaches face a critical challenge when processing
data from multiple modalities, inadvertently ignoring data with a lower
correlation to the desired output, especially when using short sampling
periods. This paper presents a useful method to address this challenge, which
amplifies the influence of data with a relatively low correlation to the output
by inputting the data into each neural network layer. The proposed approach
effectively incorporates diverse data sources into the learning process.
Through experiments using a simple pick-and-place operation with raw images and
joint information as input, significant improvements in success rates are
demonstrated even when dealing with data from short sampling periods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamane_K/0/1/0/all/0/1&quot;&gt;Koki Yamane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sakaino_S/0/1/0/all/0/1&quot;&gt;Sho Sakaino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsuji_T/0/1/0/all/0/1&quot;&gt;Toshiaki Tsuji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.09796">
<title>A Fast, Performant, Secure Distributed Training Framework For Large Language Model. (arXiv:2401.09796v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2401.09796</link>
<description rdf:parseType="Literal">&lt;p&gt;The distributed (federated) LLM is an important method for co-training the
domain-specific LLM using siloed data. However, maliciously stealing model
parameters and data from the server or client side has become an urgent problem
to be solved. In this paper, we propose a secure distributed LLM based on model
slicing. In this case, we deploy the Trusted Execution Environment (TEE) on
both the client and server side, and put the fine-tuned structure (LoRA or
embedding of P-tuning v2) into the TEE. Then, secure communication is executed
in the TEE and general environments through lightweight encryption. In order to
further reduce the equipment cost as well as increase the model performance and
accuracy, we propose a split fine-tuning scheme. In particular, we split the
LLM by layers and place the latter layers in a server-side TEE (the client does
not need a TEE). We then combine the proposed Sparsification Parameter
Fine-tuning (SPF) with the LoRA part to improve the accuracy of the downstream
task. Numerous experiments have shown that our method guarantees accuracy while
maintaining security.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yinggui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_A/0/1/0/all/0/1&quot;&gt;Anda Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Aihui Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chaofan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.09902">
<title>Interplay between depth and width for interpolation in neural ODEs. (arXiv:2401.09902v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2401.09902</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural ordinary differential equations (neural ODEs) have emerged as a
natural tool for supervised learning from a control perspective, yet a complete
understanding of their optimal architecture remains elusive. In this work, we
examine the interplay between their width $p$ and number of layer transitions
$L$ (effectively the depth $L+1$). Specifically, we assess the model
expressivity in terms of its capacity to interpolate either a finite dataset
$D$ comprising $N$ pairs of points or two probability measures in
$\mathbb{R}^d$ within a Wasserstein error margin $\varepsilon&amp;gt;0$. Our findings
reveal a balancing trade-off between $p$ and $L$, with $L$ scaling as
$O(1+N/p)$ for dataset interpolation, and
$L=O\left(1+(p\varepsilon^d)^{-1}\right)$ for measure interpolation.
&lt;/p&gt;
&lt;p&gt;In the autonomous case, where $L=0$, a separate study is required, which we
undertake focusing on dataset interpolation. We address the relaxed problem of
$\varepsilon$-approximate controllability and establish an error decay of
$\varepsilon\sim O(\log(p)p^{-1/d})$. This decay rate is a consequence of
applying a universal approximation theorem to a custom-built Lipschitz vector
field that interpolates $D$. In the high-dimensional setting, we further
demonstrate that $p=O(N)$ neurons are likely sufficient to achieve exact
control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Alvarez_Lopez_A/0/1/0/all/0/1&quot;&gt;Antonio &amp;#xc1;lvarez-L&amp;#xf3;pez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Slimane_A/0/1/0/all/0/1&quot;&gt;Arselane Hadj Slimane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zuazua_E/0/1/0/all/0/1&quot;&gt;Enrique Zuazua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.10191">
<title>Divide and not forget: Ensemble of selectively trained experts in Continual Learning. (arXiv:2401.10191v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2401.10191</link>
<description rdf:parseType="Literal">&lt;p&gt;Class-incremental learning is becoming more popular as it helps models widen
their applicability while not forgetting what they already know. A trend in
this area is to use a mixture-of-expert technique, where different models work
together to solve the task. However, the experts are usually trained all at
once using whole task data, which makes them all prone to forgetting and
increasing computational burden. To address this limitation, we introduce a
novel approach named SEED. SEED selects only one, the most optimal expert for a
considered task, and uses data from this task to fine-tune only this expert.
For this purpose, each expert represents each class with a Gaussian
distribution, and the optimal expert is selected based on the similarity of
those distributions. Consequently, SEED increases diversity and heterogeneity
within the experts while maintaining the high stability of this ensemble
method. The extensive experiments demonstrate that SEED achieves
state-of-the-art performance in exemplar-free settings across various
scenarios, showing the potential of expert diversification through data in
continual learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rypesc_G/0/1/0/all/0/1&quot;&gt;Grzegorz Rype&amp;#x15b;&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cygert_S/0/1/0/all/0/1&quot;&gt;Sebastian Cygert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_V/0/1/0/all/0/1&quot;&gt;Valeriya Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1&quot;&gt;Tomasz Trzci&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zielinski_B/0/1/0/all/0/1&quot;&gt;Bartosz Zieli&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Twardowski_B/0/1/0/all/0/1&quot;&gt;Bart&amp;#x142;omiej Twardowski&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>