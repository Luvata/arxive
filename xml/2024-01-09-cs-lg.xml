<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2024-01-07T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02429" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02430" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02433" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02437" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02438" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02447" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02450" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02451" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02453" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02456" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02457" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02458" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02465" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02501" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02508" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02511" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02520" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02523" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02524" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02526" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02536" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02544" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02552" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02561" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02566" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02575" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02576" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02586" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02591" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02592" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02602" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02630" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02644" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02650" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02652" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02653" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02656" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02661" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02663" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02665" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02668" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02675" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02682" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02683" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02686" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02687" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02718" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02723" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02734" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02735" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02736" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02739" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02740" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02771" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02773" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02791" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02801" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02810" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02827" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02843" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02847" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02860" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02879" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02889" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02890" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02902" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02903" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02904" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02905" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02914" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02930" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02938" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02940" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02949" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02954" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2104.04987" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.06166" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.06318" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2202.02952" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.04688" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.04988" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.10993" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.12511" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.07866" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.04443" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.06683" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.02725" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.05292" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.03890" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13301" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.02986" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.08109" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12006" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.03756" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.07688" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.07728" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.12075" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.12325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.00201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.05202" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.05305" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.16221" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01282" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09215" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.09441" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.14212" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.17431" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.01878" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04889" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.06942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07910" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08785" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.11514" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.13143" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.14303" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.15960" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00023" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00867" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01100" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01148" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01386" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02106" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00134" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.02329" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2401.02424">
<title>Mapping of Land Use and Land Cover (LULC) using EuroSAT and Transfer Learning. (arXiv:2401.02424v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.02424</link>
<description rdf:parseType="Literal">&lt;p&gt;As the global population continues to expand, the demand for natural
resources increases. Unfortunately, human activities account for 23% of
greenhouse gas emissions. On a positive note, remote sensing technologies have
emerged as a valuable tool in managing our environment. These technologies
allow us to monitor land use, plan urban areas, and drive advancements in areas
such as agriculture, climate change mitigation, disaster recovery, and
environmental monitoring. Recent advances in AI, computer vision, and earth
observation data have enabled unprecedented accuracy in land use mapping. By
using transfer learning and fine-tuning with RGB bands, we achieved an
impressive 99.19% accuracy in land use analysis. Such findings can be used to
inform conservation and urban planning policies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kunwar_S/0/1/0/all/0/1&quot;&gt;Suman Kunwar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferdush_J/0/1/0/all/0/1&quot;&gt;Jannatul Ferdush&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02429">
<title>Brain-Inspired Spiking Neural Networks for Industrial Fault Diagnosis: A Survey, Challenges, and Opportunities. (arXiv:2401.02429v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2401.02429</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent decades, Industrial Fault Diagnosis (IFD) has emerged as a crucial
discipline concerned with detecting and gathering vital information about
industrial equipment&apos;s health condition, thereby facilitating the
identification of failure types and severities. The pursuit of precise and
effective fault recognition has garnered substantial attention, culminating in
a focus on automating equipment monitoring to preclude safety accidents and
reduce reliance on human labor. The advent of artificial neural networks (ANNs)
has been instrumental in augmenting intelligent IFD algorithms, particularly in
the context of big data. Despite these advancements, ANNs, being a simplified
biomimetic neural network model, exhibit inherent limitations such as resource
and data dependencies and restricted cognitive capabilities. To address these
limitations, the third-generation Spiking Neural Network (SNN), founded on
principles of Brain-inspired computing, has surfaced as a promising
alternative. The SNN, characterized by its biological neuron dynamics and
spiking information encoding, demonstrates exceptional potential in
representing spatiotemporal features. Consequently, developing SNN-based IFD
models has gained momentum, displaying encouraging performance. Nevertheless,
this field lacks systematic surveys to illustrate the current situation,
challenges, and future directions. Therefore, this paper systematically reviews
the theoretical progress of SNN-based models to answer the question of what SNN
is. Subsequently, it reviews and analyzes existing SNN-based IFD models to
explain why SNN needs to be used and how to use it. More importantly, this
paper systematically answers the challenges, solutions, and opportunities of
SNN in IFD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yan-Fu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gryllias_K/0/1/0/all/0/1&quot;&gt;Konstantinos Gryllias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02430">
<title>Automated Classification of Model Errors on ImageNet. (arXiv:2401.02430v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.02430</link>
<description rdf:parseType="Literal">&lt;p&gt;While the ImageNet dataset has been driving computer vision research over the
past decade, significant label noise and ambiguity have made top-1 accuracy an
insufficient measure of further progress. To address this, new label-sets and
evaluation protocols have been proposed for ImageNet showing that
state-of-the-art models already achieve over 95% accuracy and shifting the
focus on investigating why the remaining errors persist.
&lt;/p&gt;
&lt;p&gt;Recent work in this direction employed a panel of experts to manually
categorize all remaining classification errors for two selected models.
However, this process is time-consuming, prone to inconsistencies, and requires
trained experts, making it unsuitable for regular model evaluation thus
limiting its utility. To overcome these limitations, we propose the first
automated error classification framework, a valuable tool to study how modeling
choices affect error distributions. We use our framework to comprehensively
evaluate the error distribution of over 900 models. Perhaps surprisingly, we
find that across model architectures, scales, and pre-training corpora, top-1
accuracy is a strong predictor for the portion of all error types. In
particular, we observe that the portion of severe errors drops significantly
with top-1 accuracy indicating that, while it underreports a model&apos;s true
performance, it remains a valuable performance metric.
&lt;/p&gt;
&lt;p&gt;We release all our code at
https://github.com/eth-sri/automated-error-analysis .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peychev_M/0/1/0/all/0/1&quot;&gt;Momchil Peychev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1&quot;&gt;Mark Niklas M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1&quot;&gt;Marc Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1&quot;&gt;Martin Vechev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02433">
<title>FedDiff: Diffusion Model Driven Federated Learning for Multi-Modal and Multi-Clients. (arXiv:2401.02433v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.02433</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid development of imaging sensor technology in the field of
remote sensing, multi-modal remote sensing data fusion has emerged as a crucial
research direction for land cover classification tasks. While diffusion models
have made great progress in generative models and image classification tasks,
existing models primarily focus on single-modality and single-client control,
that is, the diffusion process is driven by a single modal in a single
computing node. To facilitate the secure fusion of heterogeneous data from
clients, it is necessary to enable distributed multi-modal control, such as
merging the hyperspectral data of organization A and the LiDAR data of
organization B privately on each base station client. In this study, we propose
a multi-modal collaborative diffusion federated learning framework called
FedDiff. Our framework establishes a dual-branch diffusion model feature
extraction setup, where the two modal data are inputted into separate branches
of the encoder. Our key insight is that diffusion models driven by different
modalities are inherently complementary in terms of potential denoising steps
on which bilateral connections can be built. Considering the challenge of
private and efficient communication between multiple clients, we embed the
diffusion model into the federated learning communication structure, and
introduce a lightweight communication module. Qualitative and quantitative
experiments validate the superiority of our framework in terms of image quality
and conditional consistency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;DaiXun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1&quot;&gt;Weiying Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;ZiXuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;YiBing Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yunsong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1&quot;&gt;Leyuan Fang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02437">
<title>Randomly Weighted Neuromodulation in Neural Networks Facilitates Learning of Manifolds Common Across Tasks. (arXiv:2401.02437v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2401.02437</link>
<description rdf:parseType="Literal">&lt;p&gt;Geometric Sensitive Hashing functions, a family of Local Sensitive Hashing
functions, are neural network models that learn class-specific manifold
geometry in supervised learning. However, given a set of supervised learning
tasks, understanding the manifold geometries that can represent each task and
the kinds of relationships between the tasks based on them has received little
attention. We explore a formalization of this question by considering a
generative process where each task is associated with a high-dimensional
manifold, which can be done in brain-like models with neuromodulatory systems.
Following this formulation, we define \emph{Task-specific Geometric Sensitive
Hashing~(T-GSH)} and show that a randomly weighted neural network with a
neuromodulation system can realize this function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1&quot;&gt;Jinyung Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavlic_T/0/1/0/all/0/1&quot;&gt;Theodore P. Pavlic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02438">
<title>Sensor Placement for Learning in Flow Networks. (arXiv:2401.02438v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.02438</link>
<description rdf:parseType="Literal">&lt;p&gt;Large infrastructure networks (e.g. for transportation and power
distribution) require constant monitoring for failures, congestion, and other
adversarial events. However, assigning a sensor to every link in the network is
often infeasible due to placement and maintenance costs. Instead, sensors can
be placed only on a few key links, and machine learning algorithms can be
leveraged for the inference of missing measurements (e.g. traffic counts, power
flows) across the network. This paper investigates the sensor placement problem
for networks. We first formalize the problem under a flow conservation
assumption and show that it is NP-hard to place a fixed set of sensors
optimally. Next, we propose an efficient and adaptive greedy heuristic for
sensor placement that scales to large networks. Our experiments, using datasets
from real-world application domains, show that the proposed approach enables
more accurate inference than existing alternatives from the literature. We
demonstrate that considering even imperfect or incomplete ground-truth
estimates can vastly improve the prediction error, especially when a small
number of sensors is available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Burudgunte_A/0/1/0/all/0/1&quot;&gt;Arnav Burudgunte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Silva_A/0/1/0/all/0/1&quot;&gt;Arlei Silva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02447">
<title>User authentication system based on human exhaled breath physics. (arXiv:2401.02447v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.02447</link>
<description rdf:parseType="Literal">&lt;p&gt;This work, in a pioneering approach, attempts to build a biometric system
that works purely based on the fluid mechanics governing exhaled breath. We
test the hypothesis that the structure of turbulence in exhaled human breath
can be exploited to build biometric algorithms. This work relies on the idea
that the extrathoracic airway is unique for every individual, making the
exhaled breath a biomarker. Methods including classical multi-dimensional
hypothesis testing approach and machine learning models are employed in
building user authentication algorithms, namely user confirmation and user
identification. A user confirmation algorithm tries to verify whether a user is
the person they claim to be. A user identification algorithm tries to identify
a user&apos;s identity with no prior information available. A dataset of exhaled
breath time series samples from 94 human subjects was used to evaluate the
performance of these algorithms. The user confirmation algorithms performed
exceedingly well for the given dataset with over $97\%$ true confirmation rate.
The machine learning based algorithm achieved a good true confirmation rate,
reiterating our understanding of why machine learning based algorithms
typically outperform classical hypothesis test based algorithms. The user
identification algorithm performs reasonably well with the provided dataset
with over $50\%$ of the users identified as being within two possible suspects.
We show surprisingly unique turbulent signatures in the exhaled breath that
have not been discovered before. In addition to discussions on a novel
biometric system, we make arguments to utilise this idea as a tool to gain
insights into the morphometric variation of extrathoracic airway across
individuals. Such tools are expected to have future potential in the area of
personalised medicines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karunanethy_M/0/1/0/all/0/1&quot;&gt;Mukesh Karunanethy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathi_R/0/1/0/all/0/1&quot;&gt;Rahul Tripathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panchagnula_M/0/1/0/all/0/1&quot;&gt;Mahesh V Panchagnula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rengaswamy_R/0/1/0/all/0/1&quot;&gt;Raghunathan Rengaswamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02450">
<title>Locally Differentially Private Embedding Models in Distributed Fraud Prevention Systems. (arXiv:2401.02450v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.02450</link>
<description rdf:parseType="Literal">&lt;p&gt;Global financial crime activity is driving demand for machine learning
solutions in fraud prevention. However, prevention systems are commonly
serviced to financial institutions in isolation, and few provisions exist for
data sharing due to fears of unintentional leaks and adversarial attacks.
Collaborative learning advances in finance are rare, and it is hard to find
real-world insights derived from privacy-preserving data processing systems. In
this paper, we present a collaborative deep learning framework for fraud
prevention, designed from a privacy standpoint, and awarded at the recent PETs
Prize Challenges. We leverage latent embedded representations of varied-length
transaction sequences, along with local differential privacy, in order to
construct a data release mechanism which can securely inform externally hosted
fraud and anomaly detection models. We assess our contribution on two
distributed data sets donated by large payment networks, and demonstrate
robustness to popular inference-time attacks, along with utility-privacy
trade-offs analogous to published work in alternative application domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_I/0/1/0/all/0/1&quot;&gt;Iker Perez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1&quot;&gt;Jason Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skalski_P/0/1/0/all/0/1&quot;&gt;Piotr Skalski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burrell_S/0/1/0/all/0/1&quot;&gt;Stuart Burrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mortier_R/0/1/0/all/0/1&quot;&gt;Richard Mortier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McAuley_D/0/1/0/all/0/1&quot;&gt;Derek McAuley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_D/0/1/0/all/0/1&quot;&gt;David Sutton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02451">
<title>Automation of Smart Homes with Multiple Rule Sources. (arXiv:2401.02451v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.02451</link>
<description rdf:parseType="Literal">&lt;p&gt;Using rules for home automation presents several challenges, especially when
considering multiple stakeholders in addition to residents, such as homeowners,
local authorities, energy suppliers, and system providers, who will wish to
contribute rules to safeguard their interests. Managing rules from various
sources requires a structured procedure, a relevant policy, and a designated
authority to ensure authorized and correct contributions and address potential
conflicts. In addition, the smart home rule language needs to express
conditions and decisions at a high level of abstraction without specifying
implementation details such as interfaces, access protocols, and room layout.
Decoupling high-level decisions from these details supports the transferability
and adaptability of rules to similar homes. This separation also has important
implications for structuring the smart home system and the security
architecture. Our proposed approach and system implementation introduce a rule
management process, a rule administrator, and a domain-specific rule language
to address these challenges. In addition, the system provides a learning
process that observes residents, detects behavior patterns, and derives rules
which are then presented as recommendations to the system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eran_K/0/1/0/all/0/1&quot;&gt;Kaufman Eran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoffner_Y/0/1/0/all/0/1&quot;&gt;Yigal Hoffner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02453">
<title>Adaptive Differential Privacy in Federated Learning: A Priority-Based Approach. (arXiv:2401.02453v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.02453</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) as one of the novel branches of distributed machine
learning (ML), develops global models through a private procedure without
direct access to local datasets. However, access to model updates (e.g.
gradient updates in deep neural networks) transferred between clients and
servers can reveal sensitive information to adversaries. Differential privacy
(DP) offers a framework that gives a privacy guarantee by adding certain
amounts of noise to parameters. This approach, although being effective in
terms of privacy, adversely affects model performance due to noise involvement.
Hence, it is always needed to find a balance between noise injection and the
sacrificed accuracy. To address this challenge, we propose adaptive noise
addition in FL which decides the value of injected noise based on features&apos;
relative importance. Here, we first propose two effective methods for
prioritizing features in deep neural network models and then perturb models&apos;
weights based on this information. Specifically, we try to figure out whether
the idea of adding more noise to less important parameters and less noise to
more important parameters can effectively save the model accuracy while
preserving privacy. Our experiments confirm this statement under some
conditions. The amount of noise injected, the proportion of parameters
involved, and the number of global iterations can significantly change the
output. While a careful choice of parameters by considering the properties of
datasets can improve privacy without intense loss of accuracy, a bad choice can
make the model performance worse.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talaei_M/0/1/0/all/0/1&quot;&gt;Mahtab Talaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izadi_I/0/1/0/all/0/1&quot;&gt;Iman Izadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02456">
<title>A comprehensive survey of research towards AI-enabled unmanned aerial systems in pre-, active-, and post-wildfire management. (arXiv:2401.02456v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02456</link>
<description rdf:parseType="Literal">&lt;p&gt;Wildfires have emerged as one of the most destructive natural disasters
worldwide, causing catastrophic losses in both human lives and forest wildlife.
Recently, the use of Artificial Intelligence (AI) in wildfires, propelled by
the integration of Unmanned Aerial Vehicles (UAVs) and deep learning models,
has created an unprecedented momentum to implement and develop more effective
wildfire management. Although some of the existing survey papers have explored
various learning-based approaches, a comprehensive review emphasizing the
application of AI-enabled UAV systems and their subsequent impact on
multi-stage wildfire management is notably lacking. This survey aims to bridge
these gaps by offering a systematic review of the recent state-of-the-art
technologies, highlighting the advancements of UAV systems and AI models from
pre-fire, through the active-fire stage, to post-fire management. To this aim,
we provide an extensive analysis of the existing remote sensing systems with a
particular focus on the UAV advancements, device specifications, and sensor
technologies relevant to wildfire management. We also examine the pre-fire and
post-fire management approaches, including fuel monitoring, prevention
strategies, as well as evacuation planning, damage assessment, and operation
strategies. Additionally, we review and summarize a wide range of computer
vision techniques in active-fire management, with an emphasis on Machine
Learning (ML), Reinforcement Learning (RL), and Deep Learning (DL) algorithms
for wildfire classification, segmentation, detection, and monitoring tasks.
Ultimately, we underscore the substantial advancement in wildfire modeling
through the integration of cutting-edge AI techniques and UAV-based data,
providing novel insights and enhanced predictive capabilities to understand
dynamic wildfire behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boroujeni_S/0/1/0/all/0/1&quot;&gt;Sayed Pedram Haeri Boroujeni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razi_A/0/1/0/all/0/1&quot;&gt;Abolfazl Razi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoshdel_S/0/1/0/all/0/1&quot;&gt;Sahand Khoshdel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Afghah_F/0/1/0/all/0/1&quot;&gt;Fatemeh Afghah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coen_J/0/1/0/all/0/1&quot;&gt;Janice L. Coen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ONeill_L/0/1/0/all/0/1&quot;&gt;Leo ONeill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fule_P/0/1/0/all/0/1&quot;&gt;Peter Z. Fule&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watts_A/0/1/0/all/0/1&quot;&gt;Adam Watts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kokolakis_N/0/1/0/all/0/1&quot;&gt;Nick-Marios T. Kokolakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vamvoudakis_K/0/1/0/all/0/1&quot;&gt;Kyriakos G. Vamvoudakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02457">
<title>eCIL-MU: Embedding based Class Incremental Learning and Machine Unlearning. (arXiv:2401.02457v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02457</link>
<description rdf:parseType="Literal">&lt;p&gt;New categories may be introduced over time, or existing categories may need
to be reclassified. Class incremental learning (CIL) is employed for the
gradual acquisition of knowledge about new categories while preserving
information about previously learned ones in such dynamic environments. It
might also be necessary to also eliminate the influence of related categories
on the model to adapt to reclassification. We thus introduce class-level
machine unlearning (MU) within CIL. Typically, MU methods tend to be
time-consuming and can potentially harm the model&apos;s performance. A continuous
stream of unlearning requests could lead to catastrophic forgetting. To address
these issues, we propose a non-destructive eCIL-MU framework based on embedding
techniques to map data into vectors and then be stored in vector databases. Our
approach exploits the overlap between CIL and MU tasks for acceleration.
Experiments demonstrate the capability of achieving unlearning effectiveness
and orders of magnitude (upto $\sim 278\times$) of acceleration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1&quot;&gt;Zhuo Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kenli Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Datta_A/0/1/0/all/0/1&quot;&gt;Anwitaman Datta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02458">
<title>Data-Centric Foundation Models in Computational Healthcare: A Survey. (arXiv:2401.02458v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02458</link>
<description rdf:parseType="Literal">&lt;p&gt;The advent of foundation models (FMs) as an emerging suite of AI techniques
has struck a wave of opportunities in computational healthcare. The interactive
nature of these models, guided by pre-training data and human instructions, has
ignited a data-centric AI paradigm that emphasizes better data
characterization, quality, and scale. In healthcare AI, obtaining and
processing high-quality clinical data records has been a longstanding
challenge, ranging from data quantity, annotation, patient privacy, and ethics.
In this survey, we investigate a wide range of data-centric approaches in the
FM era (from model pre-training to inference) towards improving the healthcare
workflow. We discuss key perspectives in AI security, assessment, and alignment
with human values. Finally, we offer a promising outlook of FM-based analytics
to enhance the performance of patient outcome and clinical workflow in the
evolving landscape of healthcare and medicine. We provide an up-to-date list of
healthcare-related foundation models and datasets at
https://github.com/Yunkun-Zhang/Data-Centric-FM-Healthcare .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yunkun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jin Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1&quot;&gt;Zheling Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1&quot;&gt;Lingfeng Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1&quot;&gt;Kexin Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Mu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shaoting Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dequan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02465">
<title>Interpretable Time Series Models for Wastewater Modeling in Combined Sewer Overflows. (arXiv:2401.02465v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02465</link>
<description rdf:parseType="Literal">&lt;p&gt;Climate change poses increasingly complex challenges to our society. Extreme
weather events such as floods, wild fires or droughts are becoming more
frequent, spontaneous and difficult to foresee or counteract. In this work we
specifically address the problem of sewage water polluting surface water bodies
after spilling over from rain tanks as a consequence of heavy rain events. We
investigate to what extent state-of-the-art interpretable time series models
can help predict such critical water level points, so that the excess can
promptly be redistributed across the sewage network. Our results indicate that
modern time series models can contribute to better waste water management and
prevention of environmental pollution from sewer systems. All the code and
experiments can be found in our repository:
https://github.com/TeodorChiaburu/RIWWER_TimeSeries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiaburu_T/0/1/0/all/0/1&quot;&gt;Teodor Chiaburu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biessmann_F/0/1/0/all/0/1&quot;&gt;Felix Biessmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02501">
<title>The cell signaling structure function. (arXiv:2401.02501v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.02501</link>
<description rdf:parseType="Literal">&lt;p&gt;Live cell microscopy captures 5-D $(x,y,z,channel,time)$ movies that display
patterns of cellular motion and signaling dynamics. We present here an approach
to finding spatiotemporal patterns of cell signaling dynamics in 5-D live cell
microscopy movies unique in requiring no \emph{a priori} knowledge of expected
pattern dynamics, and no training data. The proposed cell signaling structure
function (SSF) is a Kolmogorov structure function that optimally measures cell
signaling state as nuclear intensity w.r.t. surrounding cytoplasm, a
significant improvement compared to the current state-of-the-art cytonuclear
ratio. SSF kymographs store at each spatiotemporal cell centroid the SSF value,
or a functional output such as velocity. Patterns of similarity are identified
via the metric normalized compression distance (NCD). The NCD is a reproducing
kernel for a Hilbert space that represents the input SSF kymographs as points
in a low dimensional embedding that optimally captures the pattern similarity
identified by the NCD throughout the space. The only parameter is the expected
cell radii ($\mu m$). A new formulation of the cluster structure function
optimally estimates how meaningful an embedding from the RKHS representation.
Results are presented quantifying the impact of ERK and AKT signaling between
different oncogenic mutations, and by the relation between ERK signaling and
cellular velocity patterns for movies of 2-D monolayers of human breast
epithelial (MCF10A) cells, 3-D MCF10A spheroids under optogenetic manipulation
of ERK, and human induced pluripotent stem cells .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aho_L/0/1/0/all/0/1&quot;&gt;Layton Aho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Winter_M/0/1/0/all/0/1&quot;&gt;Mark Winter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DeCarlo_M/0/1/0/all/0/1&quot;&gt;Marc DeCarlo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frismantiene_A/0/1/0/all/0/1&quot;&gt;Agne Frismantiene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blum_Y/0/1/0/all/0/1&quot;&gt;Yannick Blum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagliardi_P/0/1/0/all/0/1&quot;&gt;Paolo Armando Gagliardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pertz_O/0/1/0/all/0/1&quot;&gt;Olivier Pertz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1&quot;&gt;Andrew R. Cohen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02508">
<title>Towards an Adaptable and Generalizable Optimization Engine in Decision and Control: A Meta Reinforcement Learning Approach. (arXiv:2401.02508v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02508</link>
<description rdf:parseType="Literal">&lt;p&gt;Sampling-based model predictive control (MPC) has found significant success
in optimal control problems with non-smooth system dynamics and cost function.
Many machine learning-based works proposed to improve MPC by a) learning or
fine-tuning the dynamics/ cost function, or b) learning to optimize for the
update of the MPC controllers. For the latter, imitation learning-based
optimizers are trained to update the MPC controller by mimicking the expert
demonstrations, which, however, are expensive or even unavailable. More
significantly, many sequential decision-making problems are in non-stationary
environments, requiring that an optimizer should be adaptable and generalizable
to update the MPC controller for solving different tasks. To address those
issues, we propose to learn an optimizer based on meta-reinforcement learning
(RL) to update the controllers. This optimizer does not need expert
demonstration and can enable fast adaptation (e.g., few-shots) when it is
deployed in unseen control tasks. Experimental results validate the
effectiveness of the learned optimizer regarding fast adaptation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Sungwook Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_C/0/1/0/all/0/1&quot;&gt;Chaoying Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_R/0/1/0/all/0/1&quot;&gt;Ran Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1&quot;&gt;Chuangchuang Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02511">
<title>Gain Scheduling with a Neural Operator for a Transport PDE with Nonlinear Recirculation. (arXiv:2401.02511v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2401.02511</link>
<description rdf:parseType="Literal">&lt;p&gt;To stabilize PDE models, control laws require space-dependent functional
gains mapped by nonlinear operators from the PDE functional coefficients. When
a PDE is nonlinear and its &quot;pseudo-coefficient&quot; functions are state-dependent,
a gain-scheduling (GS) nonlinear design is the simplest approach to the design
of nonlinear feedback. The GS version of PDE backstepping employs gains
obtained by solving a PDE at each value of the state. Performing such PDE
computations in real time may be prohibitive. The recently introduced neural
operators (NO) can be trained to produce the gain functions, rapidly in real
time, for each state value, without requiring a PDE solution. In this paper we
introduce NOs for GS-PDE backstepping. GS controllers act on the premise that
the state change is slow and, as a result, guarantee only local stability, even
for ODEs. We establish local stabilization of hyperbolic PDEs with nonlinear
recirculation using both a &quot;full-kernel&quot; approach and the &quot;gain-only&quot; approach
to gain operator approximation. Numerical simulations illustrate stabilization
and demonstrate speedup by three orders of magnitude over traditional PDE
gain-scheduling. Code (Github) for the numerical implementation is published to
enable exploration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lamarque_M/0/1/0/all/0/1&quot;&gt;Maxence Lamarque&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bhan_L/0/1/0/all/0/1&quot;&gt;Luke Bhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Vazquez_R/0/1/0/all/0/1&quot;&gt;Rafael Vazquez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Krstic_M/0/1/0/all/0/1&quot;&gt;Miroslav Krstic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02520">
<title>Structured Matrix Learning under Arbitrary Entrywise Dependence and Estimation of Markov Transition Kernel. (arXiv:2401.02520v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2401.02520</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of structured matrix estimation has been studied mostly under
strong noise dependence assumptions. This paper considers a general framework
of noisy low-rank-plus-sparse matrix recovery, where the noise matrix may come
from any joint distribution with arbitrary dependence across entries. We
propose an incoherent-constrained least-square estimator and prove its
tightness both in the sense of deterministic lower bound and matching minimax
risks under various noise distributions. To attain this, we establish a novel
result asserting that the difference between two arbitrary low-rank incoherent
matrices must spread energy out across its entries, in other words cannot be
too sparse, which sheds light on the structure of incoherent low-rank matrices
and may be of independent interest. We then showcase the applications of our
framework to several important statistical machine learning problems. In the
problem of estimating a structured Markov transition kernel, the proposed
method achieves the minimax optimality and the result can be extended to
estimating the conditional mean operator, a crucial component in reinforcement
learning. The applications to multitask regression and structured covariance
estimation are also presented. We propose an alternating minimization algorithm
to approximately solve the potentially hard optimization problem. Numerical
results corroborate the effectiveness of our method which typically converges
in a few steps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chai_J/0/1/0/all/0/1&quot;&gt;Jinhang Chai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_J/0/1/0/all/0/1&quot;&gt;Jianqing Fan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02523">
<title>Image-based Deep Learning for Smart Digital Twins: a Review. (arXiv:2401.02523v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.02523</link>
<description rdf:parseType="Literal">&lt;p&gt;Smart Digital twins (SDTs) are being increasingly used to virtually replicate
and predict the behaviors of complex physical systems through continual data
assimilation enabling the optimization of the performance of these systems by
controlling the actions of systems. Recently, deep learning (DL) models have
significantly enhanced the capabilities of SDTs, particularly for tasks such as
predictive maintenance, anomaly detection, and optimization. In many domains,
including medicine, engineering, and education, SDTs use image data
(image-based SDTs) to observe and learn system behaviors and control their
behaviors. This paper focuses on various approaches and associated challenges
in developing image-based SDTs by continually assimilating image data from
physical systems. The paper also discusses the challenges involved in designing
and implementing DL models for SDTs, including data acquisition, processing,
and interpretation. In addition, insights into the future directions and
opportunities for developing new image-based DL approaches to develop robust
SDTs are provided. This includes the potential for using generative models for
data augmentation, developing multi-modal DL models, and exploring the
integration of DL with other technologies, including 5G, edge computing, and
IoT. In this paper, we describe the image-based SDTs, which enable broader
adoption of the digital twin DT paradigms across a broad spectrum of areas and
the development of new methods to improve the abilities of SDTs in replicating,
predicting, and optimizing the behavior of complex systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1&quot;&gt;Md Ruman Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramaniam_M/0/1/0/all/0/1&quot;&gt;Mahadevan Subramaniam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1&quot;&gt;Pei-Chi Huang&lt;/a&gt; (Department of Computer Science, University of Nebraska at Omaha, Omaha, NE, USA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02524">
<title>Comprehensive Exploration of Synthetic Data Generation: A Survey. (arXiv:2401.02524v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02524</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed a surge in the popularity of Machine Learning
(ML), applied across diverse domains. However, progress is impeded by the
scarcity of training data due to expensive acquisition and privacy legislation.
Synthetic data emerges as a solution, but the abundance of released models and
limited overview literature pose challenges for decision-making. This work
surveys 417 Synthetic Data Generation (SDG) models over the last decade,
providing a comprehensive overview of model types, functionality, and
improvements. Common attributes are identified, leading to a classification and
trend analysis. The findings reveal increased model performance and complexity,
with neural network-based approaches prevailing, except for privacy-preserving
data generation. Computer vision dominates, with GANs as primary generative
models, while diffusion models, transformers, and RNNs compete. Implications
from our performance evaluation highlight the scarcity of common metrics and
datasets, making comparisons challenging. Additionally, the neglect of training
and computational costs in literature necessitates attention in future
research. This work serves as a guide for SDG model selection and identifies
crucial areas for future exploration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bauer_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trapp_S/0/1/0/all/0/1&quot;&gt;Simon Trapp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stenger_M/0/1/0/all/0/1&quot;&gt;Michael Stenger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leppich_R/0/1/0/all/0/1&quot;&gt;Robert Leppich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kounev_S/0/1/0/all/0/1&quot;&gt;Samuel Kounev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leznik_M/0/1/0/all/0/1&quot;&gt;Mark Leznik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chard_K/0/1/0/all/0/1&quot;&gt;Kyle Chard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1&quot;&gt;Ian Foster&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02526">
<title>Branched Variational Autoencoder Classifiers. (arXiv:2401.02526v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02526</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a modified variational autoencoder (VAEs) that contains
an additional neural network branch. The resulting branched VAE (BVAE)
contributes a classification component based on the class labels to the total
loss and therefore imparts categorical information to the latent
representation. As a result, the latent space distributions of the input
classes are separated and ordered, thereby enhancing the classification
accuracy. The degree of improvement is quantified by numerical calculations
employing the benchmark MNIST dataset for both unrotated and rotated digits.
The proposed technique is then compared to and then incorporated into a VAE
with fixed output distributions. This procedure is found to yield improved
performance for a wide range of output distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salah_A/0/1/0/all/0/1&quot;&gt;Ahmed Salah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yevick_D/0/1/0/all/0/1&quot;&gt;David Yevick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02536">
<title>Novel End-to-End Production-Ready Machine Learning Flow for Nanolithography Modeling and Correction. (arXiv:2401.02536v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02536</link>
<description rdf:parseType="Literal">&lt;p&gt;Optical lithography is the main enabler to semiconductor manufacturing. It
requires extensive processing to perform the Resolution Enhancement Techniques
(RETs) required to transfer the design data to a working Integrated Circuits
(ICs). The processing power and computational runtime for RETs tasks is ever
increasing due to the continuous reduction of the feature size and the
expansion of the chip area. State-of-the-art research sought Machine Learning
(ML) technologies to reduce runtime and computational power, however they are
still not used in production yet. In this study, we analyze the reasons holding
back ML computational lithography from being production ready and present a
novel highly scalable end-to-end flow that enables production ready ML-RET
correction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habib_M/0/1/0/all/0/1&quot;&gt;Mohamed S. E. Habib&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fahmy_H/0/1/0/all/0/1&quot;&gt;Hossam A. H. Fahmy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abu_ElYazeed_M/0/1/0/all/0/1&quot;&gt;Mohamed F. Abu-ElYazeed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02544">
<title>Hyperparameter Estimation for Sparse Bayesian Learning Models. (arXiv:2401.02544v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02544</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse Bayesian Learning (SBL) models are extensively used in signal
processing and machine learning for promoting sparsity through hierarchical
priors. The hyperparameters in SBL models are crucial for the model&apos;s
performance, but they are often difficult to estimate due to the non-convexity
and the high-dimensionality of the associated objective function. This paper
presents a comprehensive framework for hyperparameter estimation in SBL models,
encompassing well-known algorithms such as the expectation-maximization (EM),
MacKay, and convex bounding (CB) algorithms. These algorithms are cohesively
interpreted within an alternating minimization and linearization (AML)
paradigm, distinguished by their unique linearized surrogate functions.
Additionally, a novel algorithm within the AML framework is introduced, showing
enhanced efficiency, especially under low signal noise ratios. This is further
improved by a new alternating minimization and quadratic approximation (AMQ)
paradigm, which includes a proximal regularization term. The paper
substantiates these advancements with thorough convergence analysis and
numerical experiments, demonstrating the algorithm&apos;s effectiveness in various
noise conditions and signal-to-noise ratios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Feng Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1&quot;&gt;Lixin Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1&quot;&gt;Guohui Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02552">
<title>Long-term Fairness For Real-time Decision Making: A Constrained Online Optimization Approach. (arXiv:2401.02552v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02552</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning (ML) has demonstrated remarkable capabilities across many
real-world systems, from predictive modeling to intelligent automation.
However, the widespread integration of machine learning also makes it necessary
to ensure machine learning-driven decision-making systems do not violate
ethical principles and values of society in which they operate. As ML-driven
decisions proliferate, particularly in cases involving sensitive attributes
such as gender, race, and age, to name a few, the need for equity and
impartiality has emerged as a fundamental concern. In situations demanding
real-time decision-making, fairness objectives become more nuanced and complex:
instantaneous fairness to ensure equity in every time slot, and long-term
fairness to ensure fairness over a period of time. There is a growing awareness
that real-world systems that operate over long periods and require fairness
over different timelines. However, existing approaches mainly address dynamic
costs with time-invariant fairness constraints, often disregarding the
challenges posed by time-varying fairness constraints. To bridge this gap, this
work introduces a framework for ensuring long-term fairness within dynamic
decision-making systems characterized by time-varying fairness constraints. We
formulate the decision problem with fairness constraints over a period as a
constrained online optimization problem. A novel online algorithm, named
LoTFair, is presented that solves the problem &apos;on the fly&apos;. We prove that
LoTFair can make overall fairness violations negligible while maintaining the
performance over the long run.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_R/0/1/0/all/0/1&quot;&gt;Ruijie Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muthirayan_D/0/1/0/all/0/1&quot;&gt;Deepan Muthirayan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khargonekar_P/0/1/0/all/0/1&quot;&gt;Pramod P. Khargonekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yanning Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02561">
<title>MeTA: Multi-source Test Time Adaptation. (arXiv:2401.02561v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02561</link>
<description rdf:parseType="Literal">&lt;p&gt;Test time adaptation is the process of adapting, in an unsupervised manner, a
pre-trained source model to each incoming batch of the test data (i.e., without
requiring a substantial portion of the test data to be available, as in
traditional domain adaptation) and without access to the source data. Since it
works with each batch of test data, it is well-suited for dynamic environments
where decisions need to be made as the data is streaming in. Current test time
adaptation methods are primarily focused on a single source model. We propose
the first completely unsupervised Multi-source Test Time Adaptation (MeTA)
framework that handles multiple source models and optimally combines them to
adapt to the test data. MeTA has two distinguishing features. First, it
efficiently obtains the optimal combination weights to combine the source
models to adapt to the test data distribution. Second, it identifies which of
the source model parameters to update so that only the model which is most
correlated to the target data is adapted, leaving the less correlated ones
untouched; this mitigates the issue of &quot;forgetting&quot; the source model parameters
by focusing only on the source model that exhibits the strongest correlation
with the test batch distribution. Experiments on diverse datasets demonstrate
that the combination of multiple source models does at least as well as the
best source (with hindsight knowledge), and performance does not degrade as the
test data distribution changes over time (robust to forgetting).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1&quot;&gt;Sk Miraj Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niloy_F/0/1/0/all/0/1&quot;&gt;Fahim Faisal Niloy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raychaudhuri_D/0/1/0/all/0/1&quot;&gt;Dripta S. Raychaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_Chowdhury_A/0/1/0/all/0/1&quot;&gt;Amit K. Roy-Chowdhury&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02566">
<title>Siamese Residual Neural Network for Musical Shape Evaluation in Piano Performance Assessment. (arXiv:2401.02566v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2401.02566</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding and identifying musical shape plays an important role in music
education and performance assessment. To simplify the otherwise time- and
cost-intensive musical shape evaluation, in this paper we explore how
artificial intelligence (AI) driven models can be applied. Considering musical
shape evaluation as a classification problem, a light-weight Siamese residual
neural network (S-ResNN) is proposed to automatically identify musical shapes.
To assess the proposed approach in the context of piano musical shape
evaluation, we have generated a new dataset, containing 4116 music pieces
derived by 147 piano preparatory exercises and performed in 28 categories of
musical shapes. The experimental results show that the S-ResNN significantly
outperforms a number of benchmark methods in terms of the precision, recall and
F1 score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoquan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weiss_S/0/1/0/all/0/1&quot;&gt;Stephan Weiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1&quot;&gt;Yijun Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yinhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1&quot;&gt;Jinchang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soraghan_J/0/1/0/all/0/1&quot;&gt;John Soraghan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1&quot;&gt;Ming Gong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02575">
<title>Large Language Models for Social Networks: Applications, Challenges, and Solutions. (arXiv:2401.02575v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2401.02575</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) are transforming the way people generate,
explore, and engage with content. We study how we can develop LLM applications
for online social networks. Despite LLMs&apos; successes in other domains, it is
challenging to develop LLM-based products for social networks for numerous
reasons, and it has been relatively under-reported in the research community.
We categorize LLM applications for social networks into three categories. First
is knowledge tasks where users want to find new knowledge and information, such
as search and question-answering. Second is entertainment tasks where users
want to consume interesting content, such as getting entertaining notification
content. Third is foundational tasks that need to be done to moderate and
operate the social networks, such as content annotation and LLM monitoring. For
each task, we share the challenges we found, solutions we developed, and
lessons we learned. To the best of our knowledge, this is the first
comprehensive paper about developing LLM applications for social networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1&quot;&gt;Jingying Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1&quot;&gt;Richard Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_W/0/1/0/all/0/1&quot;&gt;Waleed Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1&quot;&gt;Langxuan Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babic_B/0/1/0/all/0/1&quot;&gt;Bojan Babic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shacham_D/0/1/0/all/0/1&quot;&gt;Danny Shacham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1&quot;&gt;Xiao Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jaewon Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1&quot;&gt;Qi He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02576">
<title>t-DGR: A Trajectory-Based Deep Generative Replay Method for Continual Learning in Decision Making. (arXiv:2401.02576v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02576</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative replay has emerged as a promising approach for continual
learning in decision-making tasks. This approach addresses the problem of
catastrophic forgetting by leveraging the generation of trajectories from
previously encountered tasks to augment the current dataset. However, existing
deep generative replay methods for continual learning rely on autoregressive
models, which suffer from compounding errors in the generated trajectories. In
this paper, we propose a simple, scalable, and non-autoregressive method for
continual learning in decision-making tasks using a generative model that
generates task samples conditioned on the trajectory timestep. We evaluate our
method on Continual World benchmarks and find that our approach achieves
state-of-the-art performance on the average success rate metric among continual
learning methods. Code is available at https://github.com/WilliamYue37/t-DGR .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_W/0/1/0/all/0/1&quot;&gt;William Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1&quot;&gt;Peter Stone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02586">
<title>Federated Learning for distribution skewed data using sample weights. (arXiv:2401.02586v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02586</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the most challenging issues in federated learning is that the data is
often not independent and identically distributed (nonIID). Clients are
expected to contribute the same type of data and drawn from one global
distribution. However, data are often collected in different ways from
different resources. Thus, the data distributions among clients might be
different from the underlying global distribution. This creates a weight
divergence issue and reduces federated learning performance. This work focuses
on improving federated learning performance for skewed data distribution across
clients. The main idea is to adjust the client distribution closer to the
global distribution using sample weights. Thus, the machine learning model
converges faster with higher accuracy. We start from the fundamental concept of
empirical risk minimization and theoretically derive a solution for adjusting
the distribution skewness using sample weights. To determine sample weights, we
implicitly exchange density information by leveraging a neural network-based
density estimation model, MADE. The clients data distribution can then be
adjusted without exposing their raw data. Our experiment results on three
real-world datasets show that the proposed method not only improves federated
learning accuracy but also significantly reduces communication costs compared
to the other experimental methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Hung Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1&quot;&gt;Peiyuan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1&quot;&gt;Morris Chang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02591">
<title>Synthetic Information towards Maximum Posterior Ratio for deep learning on Imbalanced Data. (arXiv:2401.02591v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02591</link>
<description rdf:parseType="Literal">&lt;p&gt;This study examines the impact of class-imbalanced data on deep learning
models and proposes a technique for data balancing by generating synthetic data
for the minority class. Unlike random-based oversampling, our method
prioritizes balancing the informative regions by identifying high entropy
samples. Generating well-placed synthetic data can enhance machine learning
algorithms accuracy and efficiency, whereas poorly-placed ones may lead to
higher misclassification rates. We introduce an algorithm that maximizes the
probability of generating a synthetic sample in the correct region of its class
by optimizing the class posterior ratio. Additionally, to maintain data
topology, synthetic data are generated within each minority sample&apos;s
neighborhood. Our experimental results on forty-one datasets demonstrate the
superior performance of our technique in enhancing deep-learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Hung Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1&quot;&gt;Morris Chang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02592">
<title>Guaranteed Nonconvex Factorization Approach for Tensor Train Recovery. (arXiv:2401.02592v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2401.02592</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we provide the first convergence guarantee for the
factorization approach. Specifically, to avoid the scaling ambiguity and to
facilitate theoretical analysis, we optimize over the so-called left-orthogonal
TT format which enforces orthonormality among most of the factors. To ensure
the orthonormal structure, we utilize the Riemannian gradient descent (RGD) for
optimizing those factors over the Stiefel manifold. We first delve into the TT
factorization problem and establish the local linear convergence of RGD.
Notably, the rate of convergence only experiences a linear decline as the
tensor order increases. We then study the sensing problem that aims to recover
a TT format tensor from linear measurements. Assuming the sensing operator
satisfies the restricted isometry property (RIP), we show that with a proper
initialization, which could be obtained through spectral initialization, RGD
also converges to the ground-truth tensor at a linear rate. Furthermore, we
expand our analysis to encompass scenarios involving Gaussian noise in the
measurements. We prove that RGD can reliably recover the ground truth at a
linear rate, with the recovery error exhibiting only polynomial growth in
relation to the tensor order. We conduct various experiments to validate our
theoretical findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qin_Z/0/1/0/all/0/1&quot;&gt;Zhen Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wakin_M/0/1/0/all/0/1&quot;&gt;Michael B. Wakin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhihui Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02602">
<title>Neural Causal Abstractions. (arXiv:2401.02602v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02602</link>
<description rdf:parseType="Literal">&lt;p&gt;The abilities of humans to understand the world in terms of cause and effect
relationships, as well as to compress information into abstract concepts, are
two hallmark features of human intelligence. These two topics have been studied
in tandem in the literature under the rubric of causal abstractions theory. In
practice, it remains an open problem how to best leverage abstraction theory in
real-world causal inference tasks, where the true mechanisms are unknown and
only limited data is available. In this paper, we develop a new family of
causal abstractions by clustering variables and their domains. This approach
refines and generalizes previous notions of abstractions to better accommodate
individual causal distributions that are spawned by Pearl&apos;s causal hierarchy.
We show that such abstractions are learnable in practical settings through
Neural Causal Models (Xia et al., 2021), enabling the use of the deep learning
toolkit to solve various challenging causal inference tasks -- identification,
estimation, sampling -- at different levels of granularity. Finally, we
integrate these results with representation learning to create more flexible
abstractions, moving these results closer to practical applications. Our
experiments support the theory and illustrate how to scale causal inferences to
high-dimensional settings involving image data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_K/0/1/0/all/0/1&quot;&gt;Kevin Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bareinboim_E/0/1/0/all/0/1&quot;&gt;Elias Bareinboim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02630">
<title>Model-Agnostic Interpretation Framework in Machine Learning: A Comparative Study in NBA Sports. (arXiv:2401.02630v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02630</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of machine learning has seen tremendous progress in recent years,
with deep learning models delivering exceptional performance across a range of
tasks. However, these models often come at the cost of interpretability, as
they operate as opaque &quot;black boxes&quot; that obscure the rationale behind their
decisions. This lack of transparency can limit understanding of the models&apos;
underlying principles and impede their deployment in sensitive domains, such as
healthcare or finance. To address this challenge, our research team has
proposed an innovative framework designed to reconcile the trade-off between
model performance and interpretability. Our approach is centered around modular
operations on high-dimensional data, which enable end-to-end processing while
preserving interpretability. By fusing diverse interpretability techniques and
modularized data processing, our framework sheds light on the decision-making
processes of complex models without compromising their performance. We have
extensively tested our framework and validated its superior efficacy in
achieving a harmonious balance between computational efficiency and
interpretability. Our approach addresses a critical need in contemporary
machine learning applications by providing unprecedented insights into the
inner workings of complex models, fostering trust, transparency, and
accountability in their deployment across diverse domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shun Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02644">
<title>Simple Hierarchical Planning with Diffusion. (arXiv:2401.02644v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02644</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion-based generative methods have proven effective in modeling
trajectories with offline datasets. However, they often face computational
challenges and can falter in generalization, especially in capturing temporal
abstractions for long-horizon tasks. To overcome this, we introduce the
Hierarchical Diffuser, a simple, fast, yet surprisingly effective planning
method combining the advantages of hierarchical and diffusion-based planning.
Our model adopts a &quot;jumpy&quot; planning strategy at the higher level, which allows
it to have a larger receptive field but at a lower computational cost -- a
crucial factor for diffusion-based planning methods, as we have empirically
verified. Additionally, the jumpy sub-goals guide our low-level planner,
facilitating a fine-tuning stage and further improving our approach&apos;s
effectiveness. We conducted empirical evaluations on standard offline
reinforcement learning benchmarks, demonstrating our method&apos;s superior
performance and efficiency in terms of training and planning speed compared to
the non-hierarchical Diffuser as well as other hierarchical planning methods.
Moreover, we explore our model&apos;s generalization capability, particularly on how
our method improves generalization capabilities on compositional
out-of-distribution tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_F/0/1/0/all/0/1&quot;&gt;Fei Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1&quot;&gt;Kenji Kawaguchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gulcehre_C/0/1/0/all/0/1&quot;&gt;Caglar Gulcehre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1&quot;&gt;Sungjin Ahn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02650">
<title>Improving sample efficiency of high dimensional Bayesian optimization with MCMC. (arXiv:2401.02650v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02650</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequential optimization methods are often confronted with the curse of
dimensionality in high-dimensional spaces. Current approaches under the
Gaussian process framework are still burdened by the computational complexity
of tracking Gaussian process posteriors and need to partition the optimization
problem into small regions to ensure exploration or assume an underlying
low-dimensional structure. With the idea of transiting the candidate points
towards more promising positions, we propose a new method based on Markov Chain
Monte Carlo to efficiently sample from an approximated posterior. We provide
theoretical guarantees of its convergence in the Gaussian process Thompson
sampling setting. We also show experimentally that both the Metropolis-Hastings
and the Langevin Dynamics version of our algorithm outperform state-of-the-art
methods in high-dimensional sequential optimization and reinforcement learning
benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_Z/0/1/0/all/0/1&quot;&gt;Zeji Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1&quot;&gt;Yunyue Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Chu Xin Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1&quot;&gt;Kaibo He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1&quot;&gt;Yanan Sui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02652">
<title>Adaptive Discounting of Training Time Attacks. (arXiv:2401.02652v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02652</link>
<description rdf:parseType="Literal">&lt;p&gt;Among the most insidious attacks on Reinforcement Learning (RL) solutions are
training-time attacks (TTAs) that create loopholes and backdoors in the learned
behaviour. Not limited to a simple disruption, constructive TTAs (C-TTAs) are
now available, where the attacker forces a specific, target behaviour upon a
training RL agent (victim). However, even state-of-the-art C-TTAs focus on
target behaviours that could be naturally adopted by the victim if not for a
particular feature of the environment dynamics, which C-TTAs exploit. In this
work, we show that a C-TTA is possible even when the target behaviour is
un-adoptable due to both environment dynamics as well as non-optimality with
respect to the victim objective(s). To find efficient attacks in this context,
we develop a specialised flavour of the DDPG algorithm, which we term
gammaDDPG, that learns this stronger version of C-TTA. gammaDDPG dynamically
alters the attack policy planning horizon based on the victim&apos;s current
behaviour. This improves effort distribution throughout the attack timeline and
reduces the effect of uncertainty the attacker has about the victim. To
demonstrate the features of our method and better relate the results to prior
research, we borrow a 3D grid domain from a state-of-the-art C-TTA for our
experiments. Code is available at &quot;bit.ly/github-rb-gDDPG&quot;.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bector_R/0/1/0/all/0/1&quot;&gt;Ridhima Bector&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aradhya_A/0/1/0/all/0/1&quot;&gt;Abhay Aradhya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quek_C/0/1/0/all/0/1&quot;&gt;Chai Quek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabinovich_Z/0/1/0/all/0/1&quot;&gt;Zinovi Rabinovich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02653">
<title>A Deep Q-Learning based Smart Scheduling of EVs for Demand Response in Smart Grids. (arXiv:2401.02653v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02653</link>
<description rdf:parseType="Literal">&lt;p&gt;Economic and policy factors are driving the continuous increase in the
adoption and usage of electrical vehicles (EVs). However, despite being a
cleaner alternative to combustion engine vehicles, EVs have negative impacts on
the lifespan of microgrid equipment and energy balance due to increased power
demand and the timing of their usage. In our view grid management should
leverage on EVs scheduling flexibility to support local network balancing
through active participation in demand response programs. In this paper, we
propose a model-free solution, leveraging Deep Q-Learning to schedule the
charging and discharging activities of EVs within a microgrid to align with a
target energy profile provided by the distribution system operator. We adapted
the Bellman Equation to assess the value of a state based on specific rewards
for EV scheduling actions and used a neural network to estimate Q-values for
available actions and the epsilon-greedy algorithm to balance exploitation and
exploration to meet the target energy profile. The results are promising
showing that the proposed solution can effectively schedule the EVs charging
and discharging actions to align with the target profile with a Person
coefficient of 0.99, handling effective EVs scheduling situations that involve
dynamicity given by the e-mobility features, relying only on data with no
knowledge of EVs and microgrid dynamics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chifu_V/0/1/0/all/0/1&quot;&gt;Viorica Rozina Chifu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cioara_T/0/1/0/all/0/1&quot;&gt;Tudor Cioara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pop_C/0/1/0/all/0/1&quot;&gt;Cristina Bianca Pop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rusu_H/0/1/0/all/0/1&quot;&gt;Horia Rusu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anghel_I/0/1/0/all/0/1&quot;&gt;Ionut Anghel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02656">
<title>GTA: Guided Transfer of Spatial Attention from Object-Centric Representations. (arXiv:2401.02656v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.02656</link>
<description rdf:parseType="Literal">&lt;p&gt;Utilizing well-trained representations in transfer learning often results in
superior performance and faster convergence compared to training from scratch.
However, even if such good representations are transferred, a model can easily
overfit the limited training dataset and lose the valuable properties of the
transferred representations. This phenomenon is more severe in ViT due to its
low inductive bias. Through experimental analysis using attention maps in ViT,
we observe that the rich representations deteriorate when trained on a small
dataset. Motivated by this finding, we propose a novel and simple
regularization method for ViT called Guided Transfer of spatial Attention
(GTA). Our proposed method regularizes the self-attention maps between the
source and target models. A target model can fully exploit the knowledge
related to object localization properties through this explicit regularization.
Our experimental results show that the proposed GTA consistently improves the
accuracy across five benchmark datasets especially when the number of training
data is small.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1&quot;&gt;SeokHyun Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1&quot;&gt;Jinwoo Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chae_J/0/1/0/all/0/1&quot;&gt;JungWoo Chae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kyungyul Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1&quot;&gt;Sangheum Hwang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02661">
<title>Nurse-in-the-Loop Artificial Intelligence for Precision Management of Type 2 Diabetes in a Clinical Trial Utilizing Transfer-Learned Predictive Digital Twin. (arXiv:2401.02661v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02661</link>
<description rdf:parseType="Literal">&lt;p&gt;Background: Type 2 diabetes (T2D) is a prevalent chronic disease with a
significant risk of serious health complications and negative impacts on the
quality of life. Given the impact of individual characteristics and lifestyle
on the treatment plan and patient outcomes, it is crucial to develop precise
and personalized management strategies. Artificial intelligence (AI) provides
great promise in combining patterns from various data sources with nurses&apos;
expertise to achieve optimal care. Methods: This is a 6-month ancillary study
among T2D patients (n = 20, age = 57 +- 10). Participants were randomly
assigned to an intervention (AI, n=10) group to receive daily AI-generated
individualized feedback or a control group without receiving the daily feedback
(non-AI, n=10) in the last three months. The study developed an online
nurse-in-the-loop predictive control (ONLC) model that utilizes a predictive
digital twin (PDT). The PDT was developed using a transfer-learning-based
Artificial Neural Network. The PDT was trained on participants self-monitoring
data (weight, food logs, physical activity, glucose) from the first three
months, and the online control algorithm applied particle swarm optimization to
identify impactful behavioral changes for maintaining the patient&apos;s glucose and
weight levels for the next three months. The ONLC provided the intervention
group with individualized feedback and recommendations via text messages. The
PDT was re-trained weekly to improve its performance. Findings: The trained
ONLC model achieved &amp;gt;=80% prediction accuracy across all patients while the
model was tuned online. Participants in the intervention group exhibited a
trend of improved daily steps and stable or improved total caloric and total
carb intake as recommended.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faruqui_S/0/1/0/all/0/1&quot;&gt;Syed Hasib Akhter Faruqui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alaeddini_A/0/1/0/all/0/1&quot;&gt;Adel Alaeddini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yan Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shiyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1&quot;&gt;Kumar Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jing Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02663">
<title>A backdoor attack against link prediction tasks with graph neural networks. (arXiv:2401.02663v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02663</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) are a class of deep learning models capable of
processing graph-structured data, and they have demonstrated significant
performance in a variety of real-world applications. Recent studies have found
that GNN models are vulnerable to backdoor attacks. When specific patterns
(called backdoor triggers, e.g., subgraphs, nodes, etc.) appear in the input
data, the backdoor embedded in the GNN models is activated, which misclassifies
the input data into the target class label specified by the attacker, whereas
when there are no backdoor triggers in the input, the backdoor embedded in the
GNN models is not activated, and the models work normally. Backdoor attacks are
highly stealthy and expose GNN models to serious security risks. Currently,
research on backdoor attacks against GNNs mainly focus on tasks such as graph
classification and node classification, and backdoor attacks against link
prediction tasks are rarely studied. In this paper, we propose a backdoor
attack against the link prediction tasks based on GNNs and reveal the existence
of such security vulnerability in GNN models, which make the backdoored GNN
models to incorrectly predict unlinked two nodes as having a link relationship
when a trigger appear. The method uses a single node as the trigger and poison
selected node pairs in the training graph, and then the backdoor will be
embedded in the GNN models through the training process. In the inference
stage, the backdoor in the GNN models can be activated by simply linking the
trigger node to the two end nodes of the unlinked node pairs in the input data,
causing the GNN models to produce incorrect link prediction results for the
target node pairs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1&quot;&gt;Jiazhu Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Haoyu Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02665">
<title>Zero-shot Microclimate Prediction with Deep Learning. (arXiv:2401.02665v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02665</link>
<description rdf:parseType="Literal">&lt;p&gt;Weather station data is a valuable resource for climate prediction, however,
its reliability can be limited in remote locations. To compound the issue,
making local predictions often relies on sensor data that may not be accessible
for a new, previously unmonitored location. In response to these challenges, we
propose a novel zero-shot learning approach designed to forecast various
climate measurements at new and unmonitored locations. Our method surpasses
conventional weather forecasting techniques in predicting microclimate
variables by leveraging knowledge extracted from other geographic locations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deznabi_I/0/1/0/all/0/1&quot;&gt;Iman Deznabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1&quot;&gt;Peeyush Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiterau_M/0/1/0/all/0/1&quot;&gt;Madalina Fiterau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02668">
<title>Towards Integrated Fine-tuning and Inference when Generative AI meets Edge Intelligence. (arXiv:2401.02668v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2401.02668</link>
<description rdf:parseType="Literal">&lt;p&gt;The high-performance generative artificial intelligence (GAI) represents the
latest evolution of computational intelligence, while the blessing of future 6G
networks also makes edge intelligence (EI) full of development potential. The
inevitable encounter between GAI and EI can unleash new opportunities, where
GAI&apos;s pre-training based on massive computing resources and large-scale
unlabeled corpora can provide strong foundational knowledge for EI, while EI
can harness fragmented computing resources to aggregate personalized knowledge
for GAI. However, the natural contradictory features pose significant
challenges to direct knowledge sharing. To address this, in this paper, we
propose the GAI-oriented synthetical network (GaisNet), a collaborative
cloud-edge-end intelligence framework that buffers contradiction leveraging
data-free knowledge relay, where the bidirectional knowledge flow enables GAI&apos;s
virtuous-cycle model fine-tuning and task inference, achieving mutualism
between GAI and EI with seamless fusion and collaborative evolution.
Experimental results demonstrate the effectiveness of the proposed mechanisms.
Finally, we discuss the future challenges and directions in the interplay
between GAI and EI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1&quot;&gt;Ning Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1&quot;&gt;Xuwei Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lianfen Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02675">
<title>LMaaS: Exploring Pricing Strategy of Large Model as a Service for Communication. (arXiv:2401.02675v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2401.02675</link>
<description rdf:parseType="Literal">&lt;p&gt;The next generation of communication is envisioned to be intelligent
communication, that can replace traditional symbolic communication, where
highly condensed semantic information considering both source and channel will
be extracted and transmitted with high efficiency. The recent popular large
models such as GPT4 and the boosting learning techniques lay a solid foundation
for the intelligent communication, and prompt the practical deployment of it in
the near future. Given the characteristics of &quot;training once and widely use&quot; of
those multimodal large language models, we argue that a pay-as-you-go service
mode will be suitable in this context, referred to as Large Model as a Service
(LMaaS). However, the trading and pricing problem is quite complex with
heterogeneous and dynamic customer environments, making the pricing
optimization problem challenging in seeking on-hand solutions. In this paper,
we aim to fill this gap and formulate the LMaaS market trading as a Stackelberg
game with two steps. In the first step, we optimize the seller&apos;s pricing
decision and propose an Iterative Model Pricing (IMP) algorithm that optimizes
the prices of large models iteratively by reasoning customers&apos; future rental
decisions, which is able to achieve a near-optimal pricing solution. In the
second step, we optimize customers&apos; selection decisions by designing a robust
selecting and renting (RSR) algorithm, which is guaranteed to be optimal with
rigorous theoretical proof. Extensive experiments confirm the effectiveness and
robustness of our algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1&quot;&gt;Panlong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yanjie Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fangxin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02682">
<title>Homophily-Related: Adaptive Hybrid Graph Filter for Multi-View Graph Clustering. (arXiv:2401.02682v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02682</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently there is a growing focus on graph data, and multi-view graph
clustering has become a popular area of research interest. Most of the existing
methods are only applicable to homophilous graphs, yet the extensive real-world
graph data can hardly fulfill the homophily assumption, where the connected
nodes tend to belong to the same class. Several studies have pointed out that
the poor performance on heterophilous graphs is actually due to the fact that
conventional graph neural networks (GNNs), which are essentially low-pass
filters, discard information other than the low-frequency information on the
graph. Nevertheless, on certain graphs, particularly heterophilous ones,
neglecting high-frequency information and focusing solely on low-frequency
information impedes the learning of node representations. To break this
limitation, our motivation is to perform graph filtering that is closely
related to the homophily degree of the given graph, with the aim of fully
leveraging both low-frequency and high-frequency signals to learn
distinguishable node embedding. In this work, we propose Adaptive Hybrid Graph
Filter for Multi-View Graph Clustering (AHGFC). Specifically, a graph joint
process and graph joint aggregation matrix are first designed by using the
intrinsic node features and adjacency relationship, which makes the low and
high-frequency signals on the graph more distinguishable. Then we design an
adaptive hybrid graph filter that is related to the homophily degree, which
learns the node embedding based on the graph joint aggregation matrix. After
that, the node embedding of each view is weighted and fused into a consensus
embedding for the downstream task. Experimental results show that our proposed
model performs well on six datasets containing homophilous and heterophilous
graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zichen Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_Y/0/1/0/all/0/1&quot;&gt;Yawen Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1&quot;&gt;Yazhou Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tianyi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jianpeng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_X/0/1/0/all/0/1&quot;&gt;Xiaorong Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Lifang He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02683">
<title>Geometric-Facilitated Denoising Diffusion Model for 3D Molecule Generation. (arXiv:2401.02683v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02683</link>
<description rdf:parseType="Literal">&lt;p&gt;Denoising diffusion models have shown great potential in multiple research
areas. Existing diffusion-based generative methods on de novo 3D molecule
generation face two major challenges. Since majority heavy atoms in molecules
allow connections to multiple atoms through single bonds, solely using
pair-wise distance to model molecule geometries is insufficient. Therefore, the
first one involves proposing an effective neural network as the denoising
kernel that is capable to capture complex multi-body interatomic relationships
and learn high-quality features. Due to the discrete nature of graphs,
mainstream diffusion-based methods for molecules heavily rely on predefined
rules and generate edges in an indirect manner. The second challenge involves
accommodating molecule generation to diffusion and accurately predicting the
existence of bonds. In our research, we view the iterative way of updating
molecule conformations in diffusion process is consistent with molecular
dynamics and introduce a novel molecule generation method named
Geometric-Facilitated Molecular Diffusion (GFMDiff). For the first challenge,
we introduce a Dual-Track Transformer Network (DTN) to fully excevate global
spatial relationships and learn high quality representations which contribute
to accurate predictions of features and geometries. As for the second
challenge, we design Geometric-Facilitated Loss (GFLoss) which intervenes the
formation of bonds during the training period, instead of directly embedding
edges into the latent space. Comprehensive experiments on current benchmarks
demonstrate the superiority of GFMDiff.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Can Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haosen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weigang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_P/0/1/0/all/0/1&quot;&gt;Pengfei Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hongyang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02686">
<title>Beyond Fidelity: Explaining Vulnerability Localization of Learning-based Detectors. (arXiv:2401.02686v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.02686</link>
<description rdf:parseType="Literal">&lt;p&gt;Vulnerability detectors based on deep learning (DL) models have proven their
effectiveness in recent years. However, the shroud of opacity surrounding the
decision-making process of these detectors makes it difficult for security
analysts to comprehend. To address this, various explanation approaches have
been proposed to explain the predictions by highlighting important features,
which have been demonstrated effective in other domains such as computer vision
and natural language processing. Unfortunately, an in-depth evaluation of
vulnerability-critical features, such as fine-grained vulnerability-related
code lines, learned and understood by these explanation approaches remains
lacking. In this study, we first evaluate the performance of ten explanation
approaches for vulnerability detectors based on graph and sequence
representations, measured by two quantitative metrics including fidelity and
vulnerability line coverage rate. Our results show that fidelity alone is not
sufficient for evaluating these approaches, as fidelity incurs significant
fluctuations across different datasets and detectors. We subsequently check the
precision of the vulnerability-related code lines reported by the explanation
approaches, and find poor accuracy in this task among all of them. This can be
attributed to the inefficiency of explainers in selecting important features
and the presence of irrelevant artifacts learned by DL-based detectors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1&quot;&gt;Baijun Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shengming Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Kailong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Meizhen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_G/0/1/0/all/0/1&quot;&gt;Guangdong Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1&quot;&gt;Ruitao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yao Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lei Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haoyu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02687">
<title>PAHD: Perception-Action based Human Decision Making using Explainable Graph Neural Networks on SAR Images. (arXiv:2401.02687v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.02687</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthetic Aperture Radar (SAR) images are commonly utilized in military
applications for automatic target recognition (ATR). Machine learning (ML)
methods, such as Convolutional Neural Networks (CNN) and Graph Neural Networks
(GNN), are frequently used to identify ground-based objects, including battle
tanks, personnel carriers, and missile launchers. Determining the vehicle
class, such as the BRDM2 tank, BMP2 tank, BTR60 tank, and BTR70 tank, is
crucial, as it can help determine whether the target object is an ally or an
enemy. While the ML algorithm provides feedback on the recognized target, the
final decision is left to the commanding officers. Therefore, providing
detailed information alongside the identified target can significantly impact
their actions. This detailed information includes the SAR image features that
contributed to the classification, the classification confidence, and the
probability of the identified object being classified as a different object
type or class. We propose a GNN-based ATR framework that provides the final
classified class and outputs the detailed information mentioned above. This is
the first study to provide a detailed analysis of the classification class,
making final decisions more straightforward. Moreover, our GNN framework
achieves an overall accuracy of 99.2\% when evaluated on the MSTAR dataset,
improving over previous state-of-the-art GNN methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijeratne_S/0/1/0/all/0/1&quot;&gt;Sasindu Wijeratne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bingyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannan_R/0/1/0/all/0/1&quot;&gt;Rajgopal Kannan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prasanna_V/0/1/0/all/0/1&quot;&gt;Viktor Prasanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Busart_C/0/1/0/all/0/1&quot;&gt;Carl Busart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02708">
<title>TripleSurv: Triplet Time-adaptive Coordinate Loss for Survival Analysis. (arXiv:2401.02708v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02708</link>
<description rdf:parseType="Literal">&lt;p&gt;A core challenge in survival analysis is to model the distribution of
censored time-to-event data, where the event of interest may be a death,
failure, or occurrence of a specific event. Previous studies have showed that
ranking and maximum likelihood estimation (MLE)loss functions are widely-used
for survival analysis. However, ranking loss only focus on the ranking of
survival time and does not consider potential effect of samples for exact
survival time values. Furthermore, the MLE is unbounded and easily subject to
outliers (e.g., censored data), which may cause poor performance of modeling.
To handle the complexities of learning process and exploit valuable survival
time values, we propose a time-adaptive coordinate loss function, TripleSurv,
to achieve adaptive adjustments by introducing the differences in the survival
time between sample pairs into the ranking, which can encourage the model to
quantitatively rank relative risk of pairs, ultimately enhancing the accuracy
of predictions. Most importantly, the TripleSurv is proficient in quantifying
the relative risk between samples by ranking ordering of pairs, and consider
the time interval as a trade-off to calibrate the robustness of model over
sample distribution. Our TripleSurv is evaluated on three real-world survival
datasets and a public synthetic dataset. The results show that our method
outperforms the state-of-the-art methods and exhibits good model performance
and robustness on modeling various sophisticated data distributions with
different censor rates. Our code will be available upon acceptance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liwen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1&quot;&gt;Lianzhen Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Fan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1&quot;&gt;Di Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hui_H/0/1/0/all/0/1&quot;&gt;Hui Hui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1&quot;&gt;Jie Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02713">
<title>Graph-level Protein Representation Learning by Structure Knowledge Refinement. (arXiv:2401.02713v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02713</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper focuses on learning representation on the whole graph level in an
unsupervised manner. Learning graph-level representation plays an important
role in a variety of real-world issues such as molecule property prediction,
protein structure feature extraction, and social network analysis. The
mainstream method is utilizing contrastive learning to facilitate graph feature
extraction, known as Graph Contrastive Learning (GCL). GCL, although effective,
suffers from some complications in contrastive learning, such as the effect of
false negative pairs. Moreover, augmentation strategies in GCL are weakly
adaptive to diverse graph datasets. Motivated by these problems, we propose a
novel framework called Structure Knowledge Refinement (SKR) which uses data
structure to determine the probability of whether a pair is positive or
negative. Meanwhile, we propose an augmentation strategy that naturally
preserves the semantic meaning of the original data and is compatible with our
SKR framework. Furthermore, we illustrate the effectiveness of our SKR
framework through intuition and experiments. The experimental results on the
tasks of graph-level classification demonstrate that our SKR framework is
superior to most state-of-the-art baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Ge Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zang_Z/0/1/0/all/0/1&quot;&gt;Zelin Zang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jiangbin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1&quot;&gt;Jun Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Stan Z. Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02718">
<title>Calibration Attack: A Framework For Adversarial Attacks Targeting Calibration. (arXiv:2401.02718v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02718</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new framework of adversarial attacks, named calibration
attacks, in which the attacks are generated and organized to trap victim models
to be miscalibrated without altering their original accuracy, hence seriously
endangering the trustworthiness of the models and any decision-making based on
their confidence scores. Specifically, we identify four novel forms of
calibration attacks: underconfidence attacks, overconfidence attacks, maximum
miscalibration attacks, and random confidence attacks, in both the black-box
and white-box setups. We then test these new attacks on typical victim models
with comprehensive datasets, demonstrating that even with a relatively low
number of queries, the attacks can create significant calibration mistakes. We
further provide detailed analyses to understand different aspects of
calibration attacks. Building on that, we investigate the effectiveness of
widely used adversarial defences and calibration methods against these types of
attacks, which then inspires us to devise two novel defences against such
calibration attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obadinma_S/0/1/0/all/0/1&quot;&gt;Stephen Obadinma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaodan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Hongyu Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02721">
<title>A Cost-Efficient FPGA Implementation of Tiny Transformer Model using Neural ODE. (arXiv:2401.02721v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02721</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer is an emerging neural network model with attention mechanism. It
has been adopted to various tasks and achieved a favorable accuracy compared to
CNNs and RNNs. While the attention mechanism is recognized as a general-purpose
component, many of the Transformer models require a significant number of
parameters compared to the CNN-based ones. To mitigate the computational
complexity, recently, a hybrid approach has been proposed, which uses ResNet as
a backbone architecture and replaces a part of its convolution layers with an
MHSA (Multi-Head Self-Attention) mechanism. In this paper, we significantly
reduce the parameter size of such models by using Neural ODE (Ordinary
Differential Equation) as a backbone architecture instead of ResNet. The
proposed hybrid model reduces the parameter size by 94.6% compared to the
CNN-based ones without degrading the accuracy. We then deploy the proposed
model on a modest-sized FPGA device for edge computing. To further reduce FPGA
resource utilization, we quantize the model following QAT (Quantization Aware
Training) scheme instead of PTQ (Post Training Quantization) to suppress the
accuracy loss. As a result, an extremely lightweight Transformer-based model
can be implemented on resource-limited FPGAs. The weights of the feature
extraction network are stored on-chip to minimize the memory transfer overhead,
allowing faster inference. By eliminating the overhead of memory transfers,
inference can be executed seamlessly, leading to accelerated inference. The
proposed FPGA implementation achieves 12.8x speedup and 9.21x energy efficiency
compared to ARM Cortex-A53 CPU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okubo_I/0/1/0/all/0/1&quot;&gt;Ikumi Okubo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1&quot;&gt;Keisuke Sugiura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsutani_H/0/1/0/all/0/1&quot;&gt;Hiroki Matsutani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02723">
<title>Predicting Traffic Flow with Federated Learning and Graph Neural with Asynchronous Computations Network. (arXiv:2401.02723v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02723</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time traffic flow prediction holds significant importance within the
domain of Intelligent Transportation Systems (ITS). The task of achieving a
balance between prediction precision and computational efficiency presents a
significant challenge. In this article, we present a novel deep-learning method
called Federated Learning and Asynchronous Graph Convolutional Network
(FLAGCN). Our framework incorporates the principles of asynchronous graph
convolutional networks with federated learning to enhance the accuracy and
efficiency of real-time traffic flow prediction. The FLAGCN model employs a
spatial-temporal graph convolution technique to asynchronously address
spatio-temporal dependencies within traffic data effectively. To efficiently
handle the computational requirements associated with this deep learning model,
this study used a graph federated learning technique known as GraphFL. This
approach is designed to facilitate the training process. The experimental
results obtained from conducting tests on two distinct traffic datasets
demonstrate that the utilization of FLAGCN leads to the optimization of both
training and inference durations while maintaining a high level of prediction
accuracy. FLAGCN outperforms existing models with significant improvements by
achieving up to approximately 6.85% reduction in RMSE, 20.45% reduction in
MAPE, compared to the best-performing existing models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yaqub_M/0/1/0/all/0/1&quot;&gt;Muhammad Yaqub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmad_S/0/1/0/all/0/1&quot;&gt;Shahzad Ahmad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manan_M/0/1/0/all/0/1&quot;&gt;Malik Abdul Manan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chuhan_I/0/1/0/all/0/1&quot;&gt;Imran Shabir Chuhan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02734">
<title>FedNS: A Fast Sketching Newton-Type Algorithm for Federated Learning. (arXiv:2401.02734v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02734</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent Newton-type federated learning algorithms have demonstrated linear
convergence with respect to the communication rounds. However, communicating
Hessian matrices is often unfeasible due to their quadratic communication
complexity. In this paper, we introduce a novel approach to tackle this issue
while still achieving fast convergence rates. Our proposed method, named as
Federated Newton Sketch methods (FedNS), approximates the centralized Newton&apos;s
method by communicating the sketched square-root Hessian instead of the exact
Hessian. To enhance communication efficiency, we reduce the sketch size to
match the effective dimension of the Hessian matrix. We provide convergence
analysis based on statistical learning for the federated Newton sketch
approaches. Specifically, our approaches reach super-linear convergence rates
w.r.t. the communication rounds for the first time. We validate the
effectiveness of our algorithms through various experiments, which coincide
with our theoretical findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Haoran Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weiping Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02735">
<title>Shared active subspace for multivariate vector-valued functions. (arXiv:2401.02735v1 [stat.ME])</title>
<link>http://arxiv.org/abs/2401.02735</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes several approaches as baselines to compute a shared
active subspace for multivariate vector-valued functions. The goal is to
minimize the deviation between the function evaluations on the original space
and those on the reconstructed one. This is done either by manipulating the
gradients or the symmetric positive (semi-)definite (SPD) matrices computed
from the gradients of each component function so as to get a single structure
common to all component functions. These approaches can be applied to any data
irrespective of the underlying distribution unlike the existing vector-valued
approach that is constrained to a normal distribution. We test the
effectiveness of these methods on five optimization problems. The experiments
show that, in general, the SPD-level methods are superior to the gradient-level
ones, and are close to the vector-valued approach in the case of a normal
distribution. Interestingly, in most cases it suffices to take the sum of the
SPD matrices to identify the best shared active subspace.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Musayeva_K/0/1/0/all/0/1&quot;&gt;Khadija Musayeva&lt;/a&gt; (CRISAM), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Binois_M/0/1/0/all/0/1&quot;&gt;Mickael Binois&lt;/a&gt; (ACUMES)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02736">
<title>On the numerical reliability of nonsmooth autodiff: a MaxPool case study. (arXiv:2401.02736v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02736</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the reliability of automatic differentiation (AD) for
neural networks involving the nonsmooth MaxPool operation. We investigate the
behavior of AD across different precision levels (16, 32, 64 bits) and
convolutional architectures (LeNet, VGG, and ResNet) on various datasets
(MNIST, CIFAR10, SVHN, and ImageNet). Although AD can be incorrect, recent
research has shown that it coincides with the derivative almost everywhere,
even in the presence of nonsmooth operations (such as MaxPool and ReLU). On the
other hand, in practice, AD operates with floating-point numbers (not real
numbers), and there is, therefore, a need to explore subsets on which AD can be
numerically incorrect. These subsets include a bifurcation zone (where AD is
incorrect over reals) and a compensation zone (where AD is incorrect over
floating-point numbers but correct over reals). Using SGD for the training
process, we study the impact of different choices of the nonsmooth Jacobian for
the MaxPool function on the precision of 16 and 32 bits. These findings suggest
that nonsmooth MaxPool Jacobians with lower norms help maintain stable and
efficient test accuracy, whereas those with higher norms can result in
instability and decreased performance. We also observe that the influence of
MaxPool&apos;s nonsmooth Jacobians on learning can be reduced by using batch
normalization, Adam-like optimizers, or increasing the precision level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boustany_R/0/1/0/all/0/1&quot;&gt;Ryan Boustany&lt;/a&gt; (TSE-R)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02739">
<title>Diffusion Variational Inference: Diffusion Models as Expressive Variational Posteriors. (arXiv:2401.02739v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02739</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose denoising diffusion variational inference (DDVI), an approximate
inference algorithm for latent variable models which relies on diffusion models
as expressive variational posteriors. Our method augments variational
posteriors with auxiliary latents, which yields an expressive class of models
that perform diffusion in latent space by reversing a user-specified noising
process. We fit these models by optimizing a novel lower bound on the marginal
likelihood inspired by the wake-sleep algorithm. Our method is easy to
implement (it fits a regularized extension of the ELBO), is compatible with
black-box variational inference, and outperforms alternative classes of
approximate posteriors based on normalizing flows or adversarial networks. When
applied to deep latent variable models, our method yields the denoising
diffusion VAE (DD-VAE) algorithm. We use this algorithm on a motivating task in
biology -- inferring latent ancestry from human genomes -- outperforming strong
baselines on the Thousand Genomes dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piriyakulkij_T/0/1/0/all/0/1&quot;&gt;Top Piriyakulkij&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yingheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuleshov_V/0/1/0/all/0/1&quot;&gt;Volodymyr Kuleshov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02740">
<title>Fairness-Aware Job Scheduling for Multi-Job Federated Learning. (arXiv:2401.02740v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02740</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) enables multiple data owners (a.k.a. FL clients) to
collaboratively train machine learning models without disclosing sensitive
private data. Existing FL research mostly focuses on the monopoly scenario in
which a single FL server selects a subset of FL clients to update their local
models in each round of training. In practice, there can be multiple FL servers
simultaneously trying to select clients from the same pool. In this paper, we
propose a first-of-its-kind Fairness-aware Federated Job Scheduling (FairFedJS)
approach to bridge this gap. Based on Lyapunov optimization, it ensures fair
allocation of high-demand FL client datasets to FL jobs in need of them, by
jointly considering the current demand and the job payment bids, in order to
prevent prolonged waiting. Extensive experiments comparing FairFedJS against
four state-of-the-art approaches on two datasets demonstrate its significant
advantages. It outperforms the best baseline by 31.9% and 1.0% on average in
terms of scheduling fairness and convergence time, respectively, while
achieving comparable test accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yuxin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Han Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02771">
<title>Powerformer: A Section-adaptive Transformer for Power Flow Adjustment. (arXiv:2401.02771v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02771</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a novel transformer architecture tailored for
learning robust power system state representations, which strives to optimize
power dispatch for the power flow adjustment across different transmission
sections. Specifically, our proposed approach, named Powerformer, develops a
dedicated section-adaptive attention mechanism, separating itself from the
self-attention used in conventional transformers. This mechanism effectively
integrates power system states with transmission section information, which
facilitates the development of robust state representations. Furthermore, by
considering the graph topology of power system and the electrical attributes of
bus nodes, we introduce two customized strategies to further enhance the
expressiveness: graph neural network propagation and multi-factor attention
mechanism. Extensive evaluations are conducted on three power system scenarios,
including the IEEE 118-bus system, a realistic 300-bus system in China, and a
large-scale European system with 9241 buses, where Powerformer demonstrates its
superior performance over several baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kaixuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1&quot;&gt;Wei Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shunyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1&quot;&gt;Yaoquan Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yihe Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qing_Y/0/1/0/all/0/1&quot;&gt;Yunpeng Qing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Quan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jie Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1&quot;&gt;Mingli Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02773">
<title>Tackling Electrode Shift In Gesture Recognition with HD-EMG Electrode Subsets. (arXiv:2401.02773v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02773</link>
<description rdf:parseType="Literal">&lt;p&gt;sEMG pattern recognition algorithms have been explored extensively in
decoding movement intent, yet are known to be vulnerable to changing recording
conditions, exhibiting significant drops in performance across subjects, and
even across sessions. Multi-channel surface EMG, also referred to as
high-density sEMG (HD-sEMG) systems, have been used to improve performance with
the information collected through the use of additional electrodes. However, a
lack of robustness is ever present due to limited datasets and the difficulties
in addressing sources of variability, such as electrode placement. In this
study, we propose training on a collection of input channel subsets and
augmenting our training distribution with data from different electrode
locations, simultaneously targeting electrode shift and reducing input
dimensionality. Our method increases robustness against electrode shift and
results in significantly higher intersession performance across subjects and
classification algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereira_J/0/1/0/all/0/1&quot;&gt;Joao Pereira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalatsis_D/0/1/0/all/0/1&quot;&gt;Dimitrios Chalatsis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hodossy_B/0/1/0/all/0/1&quot;&gt;Balint Hodossy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farina_D/0/1/0/all/0/1&quot;&gt;Dario Farina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02791">
<title>Weakly Semi-supervised Tool Detection in Minimally Invasive Surgery Videos. (arXiv:2401.02791v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.02791</link>
<description rdf:parseType="Literal">&lt;p&gt;Surgical tool detection is essential for analyzing and evaluating minimally
invasive surgery videos. Current approaches are mostly based on supervised
methods that require large, fully instance-level labels (i.e., bounding boxes).
However, large image datasets with instance-level labels are often limited
because of the burden of annotation. Thus, surgical tool detection is important
when providing image-level labels instead of instance-level labels since
image-level annotations are considerably more time-efficient than
instance-level annotations. In this work, we propose to strike a balance
between the extremely costly annotation burden and detection performance. We
further propose a co-occurrence loss, which considers a characteristic that
some tool pairs often co-occur together in an image to leverage image-level
labels. Encapsulating the knowledge of co-occurrence using the co-occurrence
loss helps to overcome the difficulty in classification that originates from
the fact that some tools have similar shapes and textures. Extensive
experiments conducted on the Endovis2018 dataset in various data settings show
the effectiveness of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujii_R/0/1/0/all/0/1&quot;&gt;Ryo Fujii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hachiuma_R/0/1/0/all/0/1&quot;&gt;Ryo Hachiuma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saito_H/0/1/0/all/0/1&quot;&gt;Hideo Saito&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02801">
<title>Credence: Augmenting Datacenter Switch Buffer Sharing with ML Predictions. (arXiv:2401.02801v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2401.02801</link>
<description rdf:parseType="Literal">&lt;p&gt;Packet buffers in datacenter switches are shared across all the switch ports
in order to improve the overall throughput. The trend of shrinking buffer sizes
in datacenter switches makes buffer sharing extremely challenging and a
critical performance issue. Literature suggests that push-out buffer sharing
algorithms have significantly better performance guarantees compared to
drop-tail algorithms. Unfortunately, switches are unable to benefit from these
algorithms due to lack of support for push-out operations in hardware. Our key
observation is that drop-tail buffers can emulate push-out buffers if the
future packet arrivals are known ahead of time. This suggests that augmenting
drop-tail algorithms with predictions about the future arrivals has the
potential to significantly improve performance.
&lt;/p&gt;
&lt;p&gt;This paper is the first research attempt in this direction. We propose
Credence, a drop-tail buffer sharing algorithm augmented with machine-learned
predictions. Credence can unlock the performance only attainable by push-out
algorithms so far. Its performance hinges on the accuracy of predictions.
Specifically, Credence achieves near-optimal performance of the best known
push-out algorithm LQD (Longest Queue Drop) with perfect predictions, but
gracefully degrades to the performance of the simplest drop-tail algorithm
Complete Sharing when the prediction error gets arbitrarily worse. Our
evaluations show that Credence improves throughput by $1.5$x compared to
traditional approaches. In terms of flow completion times, we show that
Credence improves upon the state-of-the-art approaches by up to $95\%$ using
off-the-shelf machine learning techniques that are also practical in today&apos;s
hardware. We believe this work opens several interesting future work
opportunities both in systems and theory that we discuss at the end of this
paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Addanki_V/0/1/0/all/0/1&quot;&gt;Vamsi Addanki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pacut_M/0/1/0/all/0/1&quot;&gt;Maciej Pacut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmid_S/0/1/0/all/0/1&quot;&gt;Stefan Schmid&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02810">
<title>Physics-Informed Neural Networks for High-Frequency and Multi-Scale Problems using Transfer Learning. (arXiv:2401.02810v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02810</link>
<description rdf:parseType="Literal">&lt;p&gt;Physics-informed neural network (PINN) is a data-driven solver for partial
and ordinary differential equations(ODEs/PDEs). It provides a unified framework
to address both forward and inverse problems. However, the complexity of the
objective function often leads to training failures. This issue is particularly
prominent when solving high-frequency and multi-scale problems. We proposed
using transfer learning to boost the robustness and convergence of training
PINN, starting training from low-frequency problems and gradually approaching
high-frequency problems. Through two case studies, we discovered that transfer
learning can effectively train PINN to approximate solutions from low-frequency
problems to high-frequency problems without increasing network parameters.
Furthermore, it requires fewer data points and less training time. We
elaborately described our training strategy, including optimizer selection, and
suggested guidelines for using transfer learning to train neural networks for
solving more complex problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mustajab_A/0/1/0/all/0/1&quot;&gt;Abdul Hannan Mustajab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1&quot;&gt;Hao Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizvi_Z/0/1/0/all/0/1&quot;&gt;Zarghaam Rizvi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wuttke_F/0/1/0/all/0/1&quot;&gt;Frank Wuttke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02827">
<title>Let&apos;s Get It Started: Fostering the Discoverability of New Releases on Deezer. (arXiv:2401.02827v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2401.02827</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents our recent initiatives to foster the discoverability of
new releases on the music streaming service Deezer. After introducing our
search and recommendation features dedicated to new releases, we outline our
shift from editorial to personalized release suggestions using cold start
embeddings and contextual bandits. Backed by online experiments, we discuss the
advantages of this shift in terms of recommendation quality and exposure of new
releases on the service.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Briand_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe9;a Briand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bontempelli_T/0/1/0/all/0/1&quot;&gt;Th&amp;#xe9;o Bontempelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bendada_W/0/1/0/all/0/1&quot;&gt;Walid Bendada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morlon_M/0/1/0/all/0/1&quot;&gt;Mathieu Morlon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigaud_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Rigaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chapus_B/0/1/0/all/0/1&quot;&gt;Benjamin Chapus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouabca_T/0/1/0/all/0/1&quot;&gt;Thomas Bouab&amp;#xe7;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salha_Galvan_G/0/1/0/all/0/1&quot;&gt;Guillaume Salha-Galvan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02843">
<title>Thousands of AI Authors on the Future of AI. (arXiv:2401.02843v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2401.02843</link>
<description rdf:parseType="Literal">&lt;p&gt;In the largest survey of its kind, 2,778 researchers who had published in
top-tier artificial intelligence (AI) venues gave predictions on the pace of AI
progress and the nature and impacts of advanced AI systems The aggregate
forecasts give at least a 50% chance of AI systems achieving several milestones
by 2028, including autonomously constructing a payment processing site from
scratch, creating a song indistinguishable from a new song by a popular
musician, and autonomously downloading and fine-tuning a large language model.
If science continues undisrupted, the chance of unaided machines outperforming
humans in every possible task was estimated at 10% by 2027, and 50% by 2047.
The latter estimate is 13 years earlier than that reached in a similar survey
we conducted only one year earlier [Grace et al., 2022]. However, the chance of
all human occupations becoming fully automatable was forecast to reach 10% by
2037, and 50% as late as 2116 (compared to 2164 in the 2022 survey).
&lt;/p&gt;
&lt;p&gt;Most respondents expressed substantial uncertainty about the long-term value
of AI progress: While 68.3% thought good outcomes from superhuman AI are more
likely than bad, of these net optimists 48% gave at least a 5% chance of
extremely bad outcomes such as human extinction, and 59% of net pessimists gave
5% or more to extremely good outcomes. Between 38% and 51% of respondents gave
at least a 10% chance to advanced AI leading to outcomes as bad as human
extinction. More than half suggested that &quot;substantial&quot; or &quot;extreme&quot; concern is
warranted about six different AI-related scenarios, including misinformation,
authoritarian control, and inequality. There was disagreement about whether
faster or slower AI progress would be better for the future of humanity.
However, there was broad agreement that research aimed at minimizing potential
risks from AI systems ought to be prioritized more.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grace_K/0/1/0/all/0/1&quot;&gt;Katja Grace&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stewart_H/0/1/0/all/0/1&quot;&gt;Harlan Stewart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandkuhler_J/0/1/0/all/0/1&quot;&gt;Julia Fabienne Sandk&amp;#xfc;hler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1&quot;&gt;Stephen Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinstein_Raun_B/0/1/0/all/0/1&quot;&gt;Ben Weinstein-Raun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1&quot;&gt;Jan Brauner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02847">
<title>Generating Non-Stationary Textures using Self-Rectification. (arXiv:2401.02847v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.02847</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the challenge of example-based non-stationary texture
synthesis. We introduce a novel twostep approach wherein users first modify a
reference texture using standard image editing tools, yielding an initial rough
target for the synthesis. Subsequently, our proposed method, termed
&quot;self-rectification&quot;, automatically refines this target into a coherent,
seamless texture, while faithfully preserving the distinct visual
characteristics of the reference exemplar. Our method leverages a pre-trained
diffusion network, and uses self-attention mechanisms, to gradually align the
synthesized texture with the reference, ensuring the retention of the
structures in the provided target. Through experimental validation, our
approach exhibits exceptional proficiency in handling non-stationary textures,
demonstrating significant advancements in texture synthesis when compared to
existing state-of-the-art techniques. Code is available at
https://github.com/xiaorongjun000/Self-Rectification
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1&quot;&gt;Rongjun Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lischinski_D/0/1/0/all/0/1&quot;&gt;Dani Lischinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1&quot;&gt;Daniel Cohen-Or&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Hui Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02860">
<title>Framework for Variable-lag Motif Following Relation Inference In Time Series using Matrix Profile analysis. (arXiv:2401.02860v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02860</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowing who follows whom and what patterns they are following are crucial
steps to understand collective behaviors (e.g. a group of human, a school of
fish, or a stock market). Time series is one of resources that can be used to
get insight regarding following relations. However, the concept of following
patterns or motifs and the solution to find them in time series are not
obvious. In this work, we formalize a concept of following motifs between two
time series and present a framework to infer following patterns between two
time series. The framework utilizes one of efficient and scalable methods to
retrieve motifs from time series called the Matrix Profile Method. We compare
our proposed framework with several baselines. The framework performs better
than baselines in the simulation datasets. In the dataset of sound recording,
the framework is able to retrieve the following motifs within a pair of time
series that two singers sing following each other. In the cryptocurrency
dataset, the framework is capable of capturing the following motifs within a
pair of time series from two digital currencies, which implies that the values
of one currency follow the values of another currency patterns. Our framework
can be utilized in any field of time series to get insight regarding following
patterns between time series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chinpattanakarn_N/0/1/0/all/0/1&quot;&gt;Naaek Chinpattanakarn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amornbunchornvej_C/0/1/0/all/0/1&quot;&gt;Chainarong Amornbunchornvej&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02879">
<title>Efficient Parameter Optimisation for Quantum Kernel Alignment: A Sub-sampling Approach in Variational Training. (arXiv:2401.02879v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2401.02879</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum machine learning with quantum kernels for classification problems is
a growing area of research. Recently, quantum kernel alignment techniques that
parameterise the kernel have been developed, allowing the kernel to be trained
and therefore aligned with a specific dataset. While quantum kernel alignment
is a promising technique, it has been hampered by considerable training costs
because the full kernel matrix must be constructed at every training iteration.
Addressing this challenge, we introduce a novel method that seeks to balance
efficiency and performance. We present a sub-sampling training approach that
uses a subset of the kernel matrix at each training step, thereby reducing the
overall computational cost of the training. In this work, we apply the
sub-sampling method to synthetic datasets and a real-world breast cancer
dataset and demonstrate considerable reductions in the number of circuits
required to train the quantum kernel while maintaining classification accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sahin_M/0/1/0/all/0/1&quot;&gt;M. Emre Sahin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Symons_B/0/1/0/all/0/1&quot;&gt;Benjamin C. B. Symons&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pati_P/0/1/0/all/0/1&quot;&gt;Pushpak Pati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Minhas_F/0/1/0/all/0/1&quot;&gt;Fayyaz Minhas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Millar_D/0/1/0/all/0/1&quot;&gt;Declan Millar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gabrani_M/0/1/0/all/0/1&quot;&gt;Maria Gabrani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Robertus_J/0/1/0/all/0/1&quot;&gt;Jan Lukas Robertus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Mensa_S/0/1/0/all/0/1&quot;&gt;Stefano Mensa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02889">
<title>Energy-Preserving Reduced Operator Inference for Efficient Design and Control. (arXiv:2401.02889v1 [math.NA])</title>
<link>http://arxiv.org/abs/2401.02889</link>
<description rdf:parseType="Literal">&lt;p&gt;Many-query computations, in which a computational model for an engineering
system must be evaluated many times, are crucial in design and control. For
systems governed by partial differential equations (PDEs), typical
high-fidelity numerical models are high-dimensional and too computationally
expensive for the many-query setting. Thus, efficient surrogate models are
required to enable low-cost computations in design and control. This work
presents a physics-preserving reduced model learning approach that targets PDEs
whose quadratic operators preserve energy, such as those arising in governing
equations in many fluids problems. The approach is based on the Operator
Inference method, which fits reduced model operators to state snapshot and time
derivative data in a least-squares sense. However, Operator Inference does not
generally learn a reduced quadratic operator with the energy-preserving
property of the original PDE. Thus, we propose a new energy-preserving Operator
Inference (EP-OpInf) approach, which imposes this structure on the learned
reduced model via constrained optimization. Numerical results using the viscous
Burgers&apos; and Kuramoto-Sivashinksy equation (KSE) demonstrate that EP-OpInf
learns efficient and accurate reduced models that retain this energy-preserving
structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Koike_T/0/1/0/all/0/1&quot;&gt;Tomoki Koike&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Qian_E/0/1/0/all/0/1&quot;&gt;Elizabeth Qian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02890">
<title>Nonlinear functional regression by functional deep neural network with kernel embedding. (arXiv:2401.02890v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2401.02890</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid development of deep learning in various fields of science and
technology, such as speech recognition, image classification, and natural
language processing, recently it is also widely applied in the functional data
analysis (FDA) with some empirical success. However, due to the infinite
dimensional input, we need a powerful dimension reduction method for functional
learning tasks, especially for the nonlinear functional regression. In this
paper, based on the idea of smooth kernel integral transformation, we propose a
functional deep neural network with an efficient and fully data-dependent
dimension reduction method. The architecture of our functional net consists of
a kernel embedding step: an integral transformation with a data-dependent
smooth kernel; a projection step: a dimension reduction by projection with
eigenfunction basis based on the embedding kernel; and finally an expressive
deep ReLU neural network for the prediction. The utilization of smooth kernel
embedding enables our functional net to be discretization invariant, efficient,
and robust to noisy observations, capable of utilizing information in both
input functions and responses data, and have a low requirement on the number of
discrete points for an unimpaired generalization performance. We conduct
theoretical analysis including approximation error and generalization error
analysis, and numerical simulations to verify these advantages of our
functional net.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zhongjie Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_J/0/1/0/all/0/1&quot;&gt;Jun Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Linhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Ding-Xuan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suykens_J/0/1/0/all/0/1&quot;&gt;Johan A.K. Suykens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02902">
<title>State Derivative Normalization for Continuous-Time Deep Neural Networks. (arXiv:2401.02902v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2401.02902</link>
<description rdf:parseType="Literal">&lt;p&gt;The importance of proper data normalization for deep neural networks is well
known. However, in continuous-time state-space model estimation, it has been
observed that improper normalization of either the hidden state or hidden state
derivative of the model estimate, or even of the time interval can lead to
numerical and optimization challenges with deep learning based methods. This
results in a reduced model quality. In this contribution, we show that these
three normalization tasks are inherently coupled. Due to the existence of this
coupling, we propose a solution to all three normalization challenges by
introducing a normalization constant at the state derivative level. We show
that the appropriate choice of the normalization constant is related to the
dynamics of the to-be-identified system and we derive multiple methods of
obtaining an effective normalization constant. We compare and discuss all the
normalization strategies on a benchmark problem based on experimental data from
a cascaded tanks system and compare our results with other methods of the
identification literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Weigand_J/0/1/0/all/0/1&quot;&gt;Jonas Weigand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Beintema_G/0/1/0/all/0/1&quot;&gt;Gerben I. Beintema&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ulmen_J/0/1/0/all/0/1&quot;&gt;Jonas Ulmen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gorges_D/0/1/0/all/0/1&quot;&gt;Daniel G&amp;#xf6;rges&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Toth_R/0/1/0/all/0/1&quot;&gt;Roland T&amp;#xf3;th&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Schoukens_M/0/1/0/all/0/1&quot;&gt;Maarten Schoukens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ruskowski_M/0/1/0/all/0/1&quot;&gt;Martin Ruskowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02903">
<title>Deep Reinforcement Learning for Local Path Following of an Autonomous Formula SAE Vehicle. (arXiv:2401.02903v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2401.02903</link>
<description rdf:parseType="Literal">&lt;p&gt;With the continued introduction of driverless events to Formula:Society of
Automotive Engineers (F:SAE) competitions around the world, teams are
investigating all aspects of the autonomous vehicle stack. This paper presents
the use of Deep Reinforcement Learning (DRL) and Inverse Reinforcement Learning
(IRL) to map locally-observed cone positions to a desired steering angle for
race track following. Two state-of-the-art algorithms not previously tested in
this context: soft actor critic (SAC) and adversarial inverse reinforcement
learning (AIRL), are used to train models in a representative simulation. Three
novel reward functions for use by RL algorithms in an autonomous racing context
are also discussed. Tests performed in simulation and the real world suggest
that both algorithms can successfully train models for local path following.
Suggestions for future work are presented to allow these models to scale to a
full F:SAE vehicle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merton_H/0/1/0/all/0/1&quot;&gt;Harvey Merton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delamore_T/0/1/0/all/0/1&quot;&gt;Thomas Delamore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stol_K/0/1/0/all/0/1&quot;&gt;Karl Stol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_H/0/1/0/all/0/1&quot;&gt;Henry Williams&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02904">
<title>Class-wise Generalization Error: an Information-Theoretic Analysis. (arXiv:2401.02904v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02904</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing generalization theories of supervised learning typically take a
holistic approach and provide bounds for the expected generalization over the
whole data distribution, which implicitly assumes that the model generalizes
similarly for all the classes. In practice, however, there are significant
variations in generalization performance among different classes, which cannot
be captured by the existing generalization bounds. In this work, we tackle this
problem by theoretically studying the class-generalization error, which
quantifies the generalization performance of each individual class. We derive a
novel information-theoretic bound for class-generalization error using the KL
divergence, and we further obtain several tighter bounds using the conditional
mutual information (CMI), which are significantly easier to estimate in
practice. We empirically validate our proposed bounds in different neural
networks and show that they accurately capture the complex class-generalization
error behavior. Moreover, we show that the theoretical tools developed in this
paper can be applied in several applications beyond this context.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laakom_F/0/1/0/all/0/1&quot;&gt;Firas Laakom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bu_Y/0/1/0/all/0/1&quot;&gt;Yuheng Bu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1&quot;&gt;Moncef Gabbouj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02905">
<title>H2G2-Net: A Hierarchical Heterogeneous Graph Generative Network Framework for Discovery of Multi-Modal Physiological Responses. (arXiv:2401.02905v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02905</link>
<description rdf:parseType="Literal">&lt;p&gt;Discovering human cognitive and emotional states using multi-modal
physiological signals draws attention across various research applications.
Physiological responses of the human body are influenced by human cognition and
commonly used to analyze cognitive states. From a network science perspective,
the interactions of these heterogeneous physiological modalities in a graph
structure may provide insightful information to support prediction of cognitive
states. However, there is no clue to derive exact connectivity between
heterogeneous modalities and there exists a hierarchical structure of
sub-modalities. Existing graph neural networks are designed to learn on
non-hierarchical homogeneous graphs with pre-defined graph structures; they
failed to learn from hierarchical, multi-modal physiological data without a
pre-defined graph structure. To this end, we propose a hierarchical
heterogeneous graph generative network (H2G2-Net) that automatically learns a
graph structure without domain knowledge, as well as a powerful representation
on the hierarchical heterogeneous graph in an end-to-end fashion. We validate
the proposed method on the CogPilot dataset that consists of multi-modal
physiological signals. Extensive experiments demonstrate that our proposed
method outperforms the state-of-the-art GNNs by 5%-20% in prediction accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1&quot;&gt;Haidong Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaw_N/0/1/0/all/0/1&quot;&gt;Nathan Gaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yinan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnstone_C/0/1/0/all/0/1&quot;&gt;Chancellor Johnstone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beauchene_C/0/1/0/all/0/1&quot;&gt;Christine Beauchene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuditskaya_S/0/1/0/all/0/1&quot;&gt;Sophia Yuditskaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_H/0/1/0/all/0/1&quot;&gt;Hrishikesh Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chou_C/0/1/0/all/0/1&quot;&gt;Chun-An Chou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02914">
<title>A unified uncertainty-aware exploration: Combining epistemic and aleatory uncertainty. (arXiv:2401.02914v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02914</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploration is a significant challenge in practical reinforcement learning
(RL), and uncertainty-aware exploration that incorporates the quantification of
epistemic and aleatory uncertainty has been recognized as an effective
exploration strategy. However, capturing the combined effect of aleatory and
epistemic uncertainty for decision-making is difficult. Existing works estimate
aleatory and epistemic uncertainty separately and consider the composite
uncertainty as an additive combination of the two. Nevertheless, the additive
formulation leads to excessive risk-taking behavior, causing instability. In
this paper, we propose an algorithm that clarifies the theoretical connection
between aleatory and epistemic uncertainty, unifies aleatory and epistemic
uncertainty estimation, and quantifies the combined effect of both
uncertainties for a risk-sensitive exploration. Our method builds on a novel
extension of distributional RL that estimates a parameterized return
distribution whose parameters are random variables encoding epistemic
uncertainty. Experimental results on tasks with exploration and risk challenges
show that our method outperforms alternative approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malekzadeh_P/0/1/0/all/0/1&quot;&gt;Parvin Malekzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_M/0/1/0/all/0/1&quot;&gt;Ming Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1&quot;&gt;Konstantinos N. Plataniotis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02930">
<title>Dagma-DCE: Interpretable, Non-Parametric Differentiable Causal Discovery. (arXiv:2401.02930v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02930</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Dagma-DCE, an interpretable and model-agnostic scheme for
differentiable causal discovery. Current non- or over-parametric methods in
differentiable causal discovery use opaque proxies of ``independence&apos;&apos; to
justify the inclusion or exclusion of a causal relationship. We show
theoretically and empirically that these proxies may be arbitrarily different
than the actual causal strength. Juxtaposed to existing differentiable causal
discovery algorithms, \textsc{Dagma-DCE} uses an interpretable measure of
causal strength to define weighted adjacency matrices. In a number of simulated
datasets, we show our method achieves state-of-the-art level performance. We
additionally show that \textsc{Dagma-DCE} allows for principled thresholding
and sparsity penalties by domain-experts. The code for our method is available
open-source at https://github.com/DanWaxman/DAGMA-DCE, and can easily be
adapted to arbitrary differentiable models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waxman_D/0/1/0/all/0/1&quot;&gt;Daniel Waxman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Butler_K/0/1/0/all/0/1&quot;&gt;Kurt Butler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Djuric_P/0/1/0/all/0/1&quot;&gt;Petar M. Djuric&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02938">
<title>Fast and Optimal Weight Update for Pruned Large Language Models. (arXiv:2401.02938v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.02938</link>
<description rdf:parseType="Literal">&lt;p&gt;Pruning large language models (LLMs) is a challenging task due to their
enormous size. The primary difficulty is fine-tuning the model after pruning,
which is needed to recover the lost performance caused by dropping weights.
Recent approaches have either ignored fine-tuning entirely, focusing on
efficient pruning criteria, or attempted layer-wise weight updates, preserving
the behavior of each layer. However, even layer-wise weight updates can be
costly for LLMs, and previous works have resorted to various approximations.
&lt;/p&gt;
&lt;p&gt;In our paper, we propose a fast and optimal weight update algorithm for
pruned layers based on the Alternating Direction Method of Multipliers (ADMM).
Coupled with a simple iterative pruning mask selection, our algorithm achieves
state-of-the-art pruning performance across a wide range of LLMs. Code is
available at https://github.com/fmfi-compbio/admm-pruning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boza_V/0/1/0/all/0/1&quot;&gt;Vladim&amp;#xed;r Bo&amp;#x17e;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02940">
<title>Digital-analog quantum learning on Rydberg atom arrays. (arXiv:2401.02940v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2401.02940</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose hybrid digital-analog learning algorithms on Rydberg atom arrays,
combining the potentially practical utility and near-term realizability of
quantum learning with the rapidly scaling architectures of neutral atoms. Our
construction requires only single-qubit operations in the digital setting and
global driving according to the Rydberg Hamiltonian in the analog setting. We
perform a comprehensive numerical study of our algorithm on both classical and
quantum data, given respectively by handwritten digit classification and
unsupervised quantum phase boundary learning. We show in the two representative
problems that digital-analog learning is not only feasible in the near term,
but also requires shorter circuit depths and is more robust to realistic error
models as compared to digital learning schemes. Our results suggest that
digital-analog learning opens a promising path towards improved variational
quantum learning experiments in the near term.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jonathan Z. Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jiao_L/0/1/0/all/0/1&quot;&gt;Lucy Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wolinski_K/0/1/0/all/0/1&quot;&gt;Kristina Wolinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kornjaca_M/0/1/0/all/0/1&quot;&gt;Milan Kornja&amp;#x10d;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Hong-Ye Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cantu_S/0/1/0/all/0/1&quot;&gt;Sergio Cantu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Fangli Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yelin_S/0/1/0/all/0/1&quot;&gt;Susanne F. Yelin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sheng-Tao Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02949">
<title>Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving. (arXiv:2401.02949v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.02949</link>
<description rdf:parseType="Literal">&lt;p&gt;Concepts abound in mathematics and its applications. They vary greatly
between subject areas, and new ones are introduced in each mathematical paper
or application. A formal theory builds a hierarchy of definitions, theorems and
proofs that reference each other. When an AI agent is proving a new theorem,
most of the mathematical concepts and lemmas relevant to that theorem may have
never been seen during training. This is especially true in the Coq proof
assistant, which has a diverse library of Coq projects, each with its own
definitions, lemmas, and even custom tactic procedures used to prove those
lemmas. It is essential for agents to incorporate such new information into
their knowledge base on the fly. We work towards this goal by utilizing a new,
large-scale, graph-based dataset for machine learning in Coq. We leverage a
faithful graph-representation of Coq terms that induces a directed graph of
dependencies between definitions to create a novel graph neural network,
Graph2Tac (G2T), that takes into account not only the current goal, but also
the entire hierarchy of definitions that led to the current goal. G2T is an
online model that is deeply integrated into the users&apos; workflow and can adapt
in real time to new Coq projects and their definitions. It complements well
with other online models that learn in real time from new proof scripts. Our
novel definition embedding task, which is trained to compute representations of
mathematical concepts not seen during training, boosts the performance of the
neural network to rival state-of-the-art k-nearest neighbor predictors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rute_J/0/1/0/all/0/1&quot;&gt;Jason Rute&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olsak_M/0/1/0/all/0/1&quot;&gt;Miroslav Ol&amp;#x161;&amp;#xe1;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blaauwbroek_L/0/1/0/all/0/1&quot;&gt;Lasse Blaauwbroek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Massolo_F/0/1/0/all/0/1&quot;&gt;Fidel Ivan Schaposnik Massolo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piepenbrock_J/0/1/0/all/0/1&quot;&gt;Jelle Piepenbrock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pestun_V/0/1/0/all/0/1&quot;&gt;Vasily Pestun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02950">
<title>The Tactician&apos;s Web of Large-Scale Formal Knowledge. (arXiv:2401.02950v1 [cs.LO])</title>
<link>http://arxiv.org/abs/2401.02950</link>
<description rdf:parseType="Literal">&lt;p&gt;The Tactician&apos;s Web is a platform offering a large web of strongly
interconnected, machine-checked, formal mathematical knowledge conveniently
packaged for machine learning, analytics, and proof engineering. Built on top
of the Coq proof assistant, the platform exports a dataset containing a wide
variety of formal theories, presented as a web of definitions, theorems, proof
terms, tactics, and proof states. Theories are encoded both as a semantic graph
(rendered below) and as human-readable text, each with a unique set of
advantages and disadvantages. Proving agents may interact with Coq through the
same rich data representation and can be automatically benchmarked on a set of
theorems. Tight integration with Coq provides the unique possibility to make
agents available to proof engineers as practical tools.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blaauwbroek_L/0/1/0/all/0/1&quot;&gt;Lasse Blaauwbroek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02954">
<title>DeepSeek LLM: Scaling Open-Source Language Models with Longtermism. (arXiv:2401.02954v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.02954</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid development of open-source large language models (LLMs) has been
truly remarkable. However, the scaling law described in previous literature
presents varying conclusions, which casts a dark cloud over scaling LLMs. We
delve into the study of scaling laws and present our distinctive findings that
facilitate scaling of large scale models in two commonly used open-source
configurations, 7B and 67B. Guided by the scaling laws, we introduce DeepSeek
LLM, a project dedicated to advancing open-source language models with a
long-term perspective. To support the pre-training phase, we have developed a
dataset that currently consists of 2 trillion tokens and is continuously
expanding. We further conduct supervised fine-tuning (SFT) and Direct
Preference Optimization (DPO) on DeepSeek LLM Base models, resulting in the
creation of DeepSeek Chat models. Our evaluation results demonstrate that
DeepSeek LLM 67B surpasses LLaMA-2 70B on various benchmarks, particularly in
the domains of code, mathematics, and reasoning. Furthermore, open-ended
evaluations reveal that DeepSeek LLM 67B Chat exhibits superior performance
compared to GPT-3.5.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DeepSeek-AI/0/1/0/all/0/1&quot;&gt;DeepSeek-AI&lt;/a&gt;: &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bi_X/0/1/0/all/0/1&quot;&gt;Xiao Bi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Deli Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1&quot;&gt;Guanting Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shanhuang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1&quot;&gt;Damai Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1&quot;&gt;Chengqi Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1&quot;&gt;Honghui Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_K/0/1/0/all/0/1&quot;&gt;Kai Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1&quot;&gt;Qiushi Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1&quot;&gt;Zhe Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1&quot;&gt;Huazuo Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1&quot;&gt;Kaige Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wenjun Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_R/0/1/0/all/0/1&quot;&gt;Ruiqi Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_K/0/1/0/all/0/1&quot;&gt;Kang Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1&quot;&gt;Daya Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jianzhong Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_G/0/1/0/all/0/1&quot;&gt;Guangbo Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1&quot;&gt;Zhewen Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Ying He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Wenjie Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1&quot;&gt;Panpan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_E/0/1/0/all/0/1&quot;&gt;Erhang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guowei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiashi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Y.K. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1&quot;&gt;Wenfeng Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1&quot;&gt;Fangyun Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1&quot;&gt;A.X. Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaodong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yiyuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1&quot;&gt;Haoyu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1&quot;&gt;Shanghao Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1&quot;&gt;Fuli Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shirong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_X/0/1/0/all/0/1&quot;&gt;Xiaotao Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_T/0/1/0/all/0/1&quot;&gt;Tian Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piao_Y/0/1/0/all/0/1&quot;&gt;Yishi Piao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1&quot;&gt;Junjie Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1&quot;&gt;Hui Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_T/0/1/0/all/0/1&quot;&gt;Tongzheng Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zehui Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruan_C/0/1/0/all/0/1&quot;&gt;Chong Ruan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sha_Z/0/1/0/all/0/1&quot;&gt;Zhangli Sha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1&quot;&gt;Zhihong Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Junxiao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1&quot;&gt;Xuecheng Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jingxiang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yaofeng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1&quot;&gt;Minghui Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bingxuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Peiyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shiyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yaohui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yongji Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Y. Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xin Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1&quot;&gt;Zhenda Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1&quot;&gt;Ziwei Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1&quot;&gt;Yiliang Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hanwei Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1&quot;&gt;R.X. Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yanhong Xu&lt;/a&gt;, et al. (18 additional authors not shown)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2104.04987">
<title>AutoGL: A Library for Automated Graph Learning. (arXiv:2104.04987v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2104.04987</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed an upsurge in research interests and applications
of machine learning on graphs. However, manually designing the optimal machine
learning algorithms for different graph datasets and tasks is inflexible,
labor-intensive, and requires expert knowledge, limiting its adaptivity and
applicability. Automated machine learning (AutoML) on graphs, aiming to
automatically design the optimal machine learning algorithm for a given graph
dataset and task, has received considerable attention. However, none of the
existing libraries can fully support AutoML on graphs. To fill this gap, we
present Automated Graph Learning (AutoGL), the first dedicated library for
automated machine learning on graphs. AutoGL is open-source, easy to use, and
flexible to be extended. Specifically, we propose a three-layer architecture,
consisting of backends to interface with devices, a complete automated graph
learning pipeline, and supported graph applications. The automated machine
learning pipeline further contains five functional modules: auto feature
engineering, neural architecture search, hyper-parameter optimization, model
training, and auto ensemble, covering the majority of existing AutoML methods
on graphs. For each module, we provide numerous state-of-the-art methods and
flexible base classes and APIs, which allow easy usage and customization. We
further provide experimental results to showcase the usage of our AutoGL
library. We also present AutoGL-light, a lightweight version of AutoGL to
facilitate customizing pipelines and enriching applications, as well as
benchmarks for graph neural architecture search. The codes of AutoGL are
publicly available at https://github.com/THUMNLab/AutoGL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Ziwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1&quot;&gt;Yijian Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zeyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1&quot;&gt;Chaoyu Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1&quot;&gt;Jie Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1&quot;&gt;Heng Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jiyan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haoyang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zixin Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_B/0/1/0/all/0/1&quot;&gt;Beini Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yang Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yipeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wenwu Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.06166">
<title>Game Theory for Adversarial Attacks and Defenses. (arXiv:2110.06166v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.06166</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial attacks can generate adversarial inputs by applying small but
intentionally worst-case perturbations to samples from the dataset, which leads
to even state-of-the-art deep neural networks outputting incorrect answers with
high confidence. Hence, some adversarial defense techniques are developed to
improve the security and robustness of the models and avoid them being
attacked. Gradually, a game-like competition between attackers and defenders
formed, in which both players would attempt to play their best strategies
against each other while maximizing their own payoffs. To solve the game, each
player would choose an optimal strategy against the opponent based on the
prediction of the opponent&apos;s strategy choice. In this work, we are on the
defensive side to apply game-theoretic approaches on defending against attacks.
We use two randomization methods, random initialization and stochastic
activation pruning, to create diversity of networks. Furthermore, we use one
denoising technique, super resolution, to improve models&apos; robustness by
preprocessing images before attacks. Our experimental results indicate that
those three methods can effectively improve the robustness of deep-learning
neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1&quot;&gt;Shorya Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.06318">
<title>Multi-agent Reinforcement Learning for Cooperative Lane Changing of Connected and Autonomous Vehicles in Mixed Traffic. (arXiv:2111.06318v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.06318</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous driving has attracted significant research interests in the past
two decades as it offers many potential benefits, including releasing drivers
from exhausting driving and mitigating traffic congestion, among others.
Despite promising progress, lane-changing remains a great challenge for
autonomous vehicles (AV), especially in mixed and dynamic traffic scenarios.
Recently, reinforcement learning (RL), a powerful data-driven control method,
has been widely explored for lane-changing decision makings in AVs with
encouraging results demonstrated. However, the majority of those studies are
focused on a single-vehicle setting, and lane-changing in the context of
multiple AVs coexisting with human-driven vehicles (HDVs) have received scarce
attention. In this paper, we formulate the lane-changing decision making of
multiple AVs in a mixed-traffic highway environment as a multi-agent
reinforcement learning (MARL) problem, where each AV makes lane-changing
decisions based on the motions of both neighboring AVs and HDVs. Specifically,
a multi-agent advantage actor-critic network (MA2C) is developed with a novel
local reward design and a parameter sharing scheme. In particular, a
multi-objective reward function is proposed to incorporate fuel efficiency,
driving comfort, and safety of autonomous driving. Comprehensive experimental
results, conducted under three different traffic densities and various levels
of human driver aggressiveness, show that our proposed MARL framework
consistently outperforms several state-of-the-art benchmarks in terms of
efficiency, safety and driver comfort.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wei Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Dong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Jun Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhaojian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Huilin Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1&quot;&gt;Wanchen Ge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2202.02952">
<title>Supervision by Denoising for Medical Image Segmentation. (arXiv:2202.02952v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2202.02952</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning-based image reconstruction models, such as those based on the U-Net,
require a large set of labeled images if good generalization is to be
guaranteed. In some imaging domains, however, labeled data with pixel- or
voxel-level label accuracy are scarce due to the cost of acquiring them. This
problem is exacerbated further in domains like medical imaging, where there is
no single ground truth label, resulting in large amounts of repeat variability
in the labels. Therefore, training reconstruction networks to generalize better
by learning from both labeled and unlabeled examples (called semi-supervised
learning) is problem of practical and theoretical interest. However,
traditional semi-supervised learning methods for image reconstruction often
necessitate handcrafting a differentiable regularizer specific to some given
imaging problem, which can be extremely time-consuming. In this work, we
propose &quot;supervision by denoising&quot; (SUD), a framework that enables us to
supervise reconstruction models using their own denoised output as soft labels.
SUD unifies stochastic averaging and spatial denoising techniques under a
spatio-temporal denoising framework and alternates denoising and model weight
update steps in an optimization framework for semi-supervision. As example
applications, we apply SUD to two problems arising from biomedical imaging --
anatomical brain reconstruction (3D) and cortical parcellation (2D) -- to
demonstrate a significant improvement in the image reconstructions over
supervised-only and stochastic averaging baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Young_S/0/1/0/all/0/1&quot;&gt;Sean I. Young&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dalca_A/0/1/0/all/0/1&quot;&gt;Adrian V. Dalca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ferrante_E/0/1/0/all/0/1&quot;&gt;Enzo Ferrante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Golland_P/0/1/0/all/0/1&quot;&gt;Polina Golland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Metzler_C/0/1/0/all/0/1&quot;&gt;Christopher A. Metzler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fischl_B/0/1/0/all/0/1&quot;&gt;Bruce Fischl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Iglesias_J/0/1/0/all/0/1&quot;&gt;Juan Eugenio Iglesias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.04688">
<title>A New Frontier of AI: On-Device AI Training and Personalization. (arXiv:2206.04688v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.04688</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern consumer electronic devices have started executing deep learning-based
intelligence services on devices, not cloud servers, to keep personal data on
devices and to reduce network and cloud costs. We find such a trend as the
opportunity to personalize intelligence services by updating neural networks
with user data without exposing the data out of devices: on-device training.
However, the limited resources of devices incurs significant difficulties. We
propose a light-weight on-device training framework, NNTrainer, which provides
highly memory-efficient neural network training techniques and proactive
swapping based on fine-grained execution order analysis for neural networks.
Moreover, its optimizations do not sacrifice accuracy and are transparent to
training algorithms; thus, prior algorithmic studies may be implemented on top
of NNTrainer. The evaluations show that NNTrainer can reduce memory consumption
down to 1/20 (saving 95%!) and effectively personalizes intelligence services
on devices. NNTrainer is cross-platform and practical open-source software,
which is being deployed to millions of mobile devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1&quot;&gt;Ji Joong Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hyun Suk Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_J/0/1/0/all/0/1&quot;&gt;Jiho Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1&quot;&gt;Donghak Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1&quot;&gt;Seungbaek Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_H/0/1/0/all/0/1&quot;&gt;Hyungjun Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_D/0/1/0/all/0/1&quot;&gt;Donghyeon Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1&quot;&gt;Sungsik Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ham_M/0/1/0/all/0/1&quot;&gt;MyungJoo Ham&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.04988">
<title>Quantum artificial vision for defect detection in manufacturing. (arXiv:2208.04988v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2208.04988</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we consider several algorithms for quantum computer vision
using Noisy Intermediate-Scale Quantum (NISQ) devices, and benchmark them for a
real problem against their classical counterparts. Specifically, we consider
two approaches: a quantum Support Vector Machine (QSVM) on a universal
gate-based quantum computer, and QBoost on a quantum annealer. The quantum
vision systems are benchmarked for an unbalanced dataset of images where the
aim is to detect defects in manufactured car pieces. We see that the quantum
algorithms outperform their classical counterparts in several ways, with QBoost
allowing for larger problems to be analyzed with present-day quantum annealers.
Data preprocessing, including dimensionality reduction and contrast
enhancement, is also discussed, as well as hyperparameter tuning in QBoost. To
the best of our knowledge, this is the first implementation of quantum computer
vision systems for a problem of industrial relevance in a manufacturing
production line.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Guijo_D/0/1/0/all/0/1&quot;&gt;Daniel Guijo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Onofre_V/0/1/0/all/0/1&quot;&gt;Victor Onofre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bimbo_G/0/1/0/all/0/1&quot;&gt;Gianni Del Bimbo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Mugel_S/0/1/0/all/0/1&quot;&gt;Samuel Mugel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Estepa_D/0/1/0/all/0/1&quot;&gt;Daniel Estepa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Carlos_X/0/1/0/all/0/1&quot;&gt;Xabier De Carlos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Adell_A/0/1/0/all/0/1&quot;&gt;Ana Adell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lojo_A/0/1/0/all/0/1&quot;&gt;Aizea Lojo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bilbao_J/0/1/0/all/0/1&quot;&gt;Josu Bilbao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Orus_R/0/1/0/all/0/1&quot;&gt;Roman Orus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.10993">
<title>Application of federated learning techniques for arrhythmia classification using 12-lead ECG signals. (arXiv:2208.10993v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2208.10993</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial Intelligence-based (AI) analysis of large, curated medical
datasets is promising for providing early detection, faster diagnosis, and more
effective treatment using low-power Electrocardiography (ECG) monitoring
devices information. However, accessing sensitive medical data from diverse
sources is highly restricted since improper use, unsafe storage, or data
leakage could violate a person&apos;s privacy. This work uses a Federated Learning
(FL) privacy-preserving methodology to train AI models over heterogeneous sets
of high-definition ECG from 12-lead sensor arrays collected from six
heterogeneous sources. We evaluated the capacity of the resulting models to
achieve equivalent performance compared to state-of-the-art models trained in a
Centralized Learning (CL) fashion. Moreover, we assessed the performance of our
solution over Independent and Identical distributed (IID) and non-IID federated
data. Our methodology involves machine learning techniques based on Deep Neural
Networks and Long-Short-Term Memory models. It has a robust data preprocessing
pipeline with feature engineering, selection, and data balancing techniques.
Our AI models demonstrated comparable performance to models trained using CL,
IID, and non-IID approaches. They showcased advantages in reduced complexity
and faster training time, making them well-suited for cloud-edge architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutierrez_D/0/1/0/all/0/1&quot;&gt;Daniel Mauricio Jimenez Gutierrez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassan_H/0/1/0/all/0/1&quot;&gt;Hafiz Muuhammad Hassan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Landi_L/0/1/0/all/0/1&quot;&gt;Lorella Landi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vitaletti_A/0/1/0/all/0/1&quot;&gt;Andrea Vitaletti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzigiannakis_I/0/1/0/all/0/1&quot;&gt;Ioannis Chatzigiannakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.12511">
<title>Lower Difficulty and Better Robustness: A Bregman Divergence Perspective for Adversarial Training. (arXiv:2208.12511v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2208.12511</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we investigate on improving the adversarial robustness
obtained in adversarial training (AT) via reducing the difficulty of
optimization. To better study this problem, we build a novel Bregman divergence
perspective for AT, in which AT can be viewed as the sliding process of the
training data points on the negative entropy curve. Based on this perspective,
we analyze the learning objectives of two typical AT methods, i.e., PGD-AT and
TRADES, and we find that the optimization process of TRADES is easier than
PGD-AT for that TRADES separates PGD-AT. In addition, we discuss the function
of entropy in TRADES, and we find that models with high entropy can be better
robustness learners. Inspired by the above findings, we propose two methods,
i.e., FAIT and MER, which can both not only reduce the difficulty of
optimization under the 10-step PGD adversaries, but also provide better
robustness. Our work suggests that reducing the difficulty of optimization
under the 10-step PGD adversaries is a promising approach for enhancing the
adversarial robustness in AT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zihui Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1&quot;&gt;Haichang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Bingqian Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xiaoyan Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shudong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.07866">
<title>Efficient Estimation for Longitudinal Networks via Adaptive Merging. (arXiv:2211.07866v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2211.07866</link>
<description rdf:parseType="Literal">&lt;p&gt;Longitudinal network consists of a sequence of temporal edges among multiple
nodes, where the temporal edges are observed in real time. It has become
ubiquitous with the rise of online social platform and e-commerce, but largely
under-investigated in literature. In this paper, we propose an efficient
estimation framework for longitudinal network, leveraging strengths of adaptive
network merging, tensor decomposition and point process. It merges neighboring
sparse networks so as to enlarge the number of observed edges and reduce
estimation variance, whereas the estimation bias introduced by network merging
is controlled by exploiting local temporal structures for adaptive network
neighborhood. A projected gradient descent algorithm is proposed to facilitate
estimation, where the upper bound of the estimation error in each iteration is
established. A thorough analysis is conducted to quantify the asymptotic
behavior of the proposed method, which shows that it can significantly reduce
the estimation error and also provides guideline for network merging under
various scenarios. We further demonstrate the advantage of the proposed method
through extensive numerical experiments on synthetic datasets and a militarized
interstate dispute dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haoran Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junhui Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.04443">
<title>A Distributed Block Chebyshev-Davidson Algorithm for Parallel Spectral Clustering. (arXiv:2212.04443v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.04443</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a distributed Block Chebyshev-Davidson algorithm to solve
large-scale leading eigenvalue problems for spectral analysis in spectral
clustering. First, the efficiency of the Chebyshev-Davidson algorithm relies on
the prior knowledge of the eigenvalue spectrum, which could be expensive to
estimate. This issue can be lessened by the analytic spectrum estimation of the
Laplacian or normalized Laplacian matrices in spectral clustering, making the
proposed algorithm very efficient for spectral clustering. Second, to make the
proposed algorithm capable of analyzing big data, a distributed and parallel
version has been developed with attractive scalability. The speedup by parallel
computing is approximately equivalent to $\sqrt{p}$, where $p$ denotes the
number of processes. {Numerical results will be provided to demonstrate its
efficiency in spectral clustering and scalability advantage over existing
eigensolvers used for spectral clustering in parallel computing environments.}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_Q/0/1/0/all/0/1&quot;&gt;Qiyuan Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haizhao Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.06683">
<title>Surgical Aggregation: Federated Class-Heterogeneous Learning. (arXiv:2301.06683v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2301.06683</link>
<description rdf:parseType="Literal">&lt;p&gt;The release of numerous chest x-ray datasets has spearheaded the development
of deep learning models with expert-level performance. However, they have
limited interoperability due to class-heterogeneity -- a result of inconsistent
labeling schemes and partial annotations. Therefore, it is challenging to
leverage these datasets in aggregate to train models with a complete
representation of abnormalities that may occur within the thorax. In this work,
we propose surgical aggregation, a federated learning framework for aggregating
knowledge from class-heterogeneous datasets and learn a model that can
simultaneously predict the presence of all disease labels present across the
datasets. We evaluate our method using simulated and real-world
class-heterogeneous datasets across both independent and identically
distributed (iid) and non-iid settings. Our results show that surgical
aggregation outperforms current methods, has better generalizability, and is a
crucial first step towards tackling class-heterogeneity in federated learning
to facilitate the development of clinically-useful models using previously
non-interoperable chest x-ray datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_P/0/1/0/all/0/1&quot;&gt;Pranav Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanhere_A/0/1/0/all/0/1&quot;&gt;Adway Kanhere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_P/0/1/0/all/0/1&quot;&gt;Paul H. Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parekh_V/0/1/0/all/0/1&quot;&gt;Vishwa S. Parekh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.02725">
<title>Local Environment Poisoning Attacks on Federated Reinforcement Learning. (arXiv:2303.02725v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.02725</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) has become a popular tool for solving traditional
Reinforcement Learning (RL) tasks. The multi-agent structure addresses the
major concern of data-hungry in traditional RL, while the federated mechanism
protects the data privacy of individual agents. However, the federated
mechanism also exposes the system to poisoning by malicious agents that can
mislead the trained policy. Despite the advantage brought by FL, the
vulnerability of Federated Reinforcement Learning (FRL) has not been
well-studied before. In this work, we propose a general framework to
characterize FRL poisoning as an optimization problem and design a poisoning
protocol that can be applied to policy-based FRL. Our framework can also be
extended to FRL with actor-critic as a local RL algorithm by training a pair of
private and public critics. We provably show that our method can strictly hurt
the global objective. We verify our poisoning effectiveness by conducting
extensive experiments targeting mainstream RL algorithms and over various RL
OpenAI Gym environments covering a wide range of difficulty levels. Within
these experiments, we compare clean and baseline poisoning methods against our
proposed framework. The results show that the proposed framework is successful
in poisoning FRL systems and reducing performance across various environments
and does so more effectively than baseline methods. Our work provides new
insights into the vulnerability of FL in RL training and poses new challenges
for designing robust FRL algorithms
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_E/0/1/0/all/0/1&quot;&gt;Evelyn Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rathi_P/0/1/0/all/0/1&quot;&gt;Praneet Rathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Etesami_S/0/1/0/all/0/1&quot;&gt;S. Rasoul Etesami&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.05292">
<title>MC-ViViT: Multi-branch Classifier-ViViT to detect Mild Cognitive Impairment in older adults using facial videos. (arXiv:2304.05292v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.05292</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep machine learning models including Convolutional Neural Networks (CNN)
have been successful in the detection of Mild Cognitive Impairment (MCI) using
medical images, questionnaires, and videos. This paper proposes a novel
Multi-branch Classifier-Video Vision Transformer (MC-ViViT) model to
distinguish MCI from those with normal cognition by analyzing facial features.
The data comes from the I-CONECT, a behavioral intervention trial aimed at
improving cognitive function by providing frequent video chats. MC-ViViT
extracts spatiotemporal features of videos in one branch and augments
representations by the MC module. The I-CONECT dataset is challenging as the
dataset is imbalanced containing Hard-Easy and Positive-Negative samples, which
impedes the performance of MC-ViViT. We propose a loss function for Hard-Easy
and Positive-Negative Samples (HP Loss) by combining Focal loss and AD-CORRE
loss to address the imbalanced problem. Our experimental results on the
I-CONECT dataset show the great potential of MC-ViViT in predicting MCI with a
high accuracy of 90.63% accuracy on some of the interview videos.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jian Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dodge_H/0/1/0/all/0/1&quot;&gt;Hiroko H. Dodge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahoor_M/0/1/0/all/0/1&quot;&gt;Mohammad H. Mahoor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.03890">
<title>Approximation by non-symmetric networks for cross-domain learning. (arXiv:2305.03890v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.03890</link>
<description rdf:parseType="Literal">&lt;p&gt;For the past 30 years or so, machine learning has stimulated a great deal of
research in the study of approximation capabilities (expressive power) of a
multitude of processes, such as approximation by shallow or deep neural
networks, radial basis function networks, and a variety of kernel based
methods. Motivated by applications such as invariant learning, transfer
learning, and synthetic aperture radar imaging, we initiate in this paper a
general approach to study the approximation capabilities of kernel based
networks using non-symmetric kernels. While singular value decomposition is a
natural instinct to study such kernels, we consider a more general approach to
include the use of a family of kernels, such as generalized translation
networks (which include neural networks and translation invariant kernels as
special cases) and rotated zonal function kernels. Naturally, unlike
traditional kernel based approximation, we cannot require the kernels to be
positive definite. In particular, we obtain estimates on the accuracy of
uniform approximation of functions in a ($L^2$)-Sobolev class by ReLU$^r$
networks when $r$ is not necessarily an integer. Our general results apply to
the approximation of functions with small smoothness compared to the dimension
of the input space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mhaskar_H/0/1/0/all/0/1&quot;&gt;Hrushikesh Mhaskar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13301">
<title>Training Diffusion Models with Reinforcement Learning. (arXiv:2305.13301v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13301</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models are a class of flexible generative models trained with an
approximation to the log-likelihood objective. However, most use cases of
diffusion models are not concerned with likelihoods, but instead with
downstream objectives such as human-perceived image quality or drug
effectiveness. In this paper, we investigate reinforcement learning methods for
directly optimizing diffusion models for such objectives. We describe how
posing denoising as a multi-step decision-making problem enables a class of
policy gradient algorithms, which we refer to as denoising diffusion policy
optimization (DDPO), that are more effective than alternative reward-weighted
likelihood approaches. Empirically, DDPO is able to adapt text-to-image
diffusion models to objectives that are difficult to express via prompting,
such as image compressibility, and those derived from human feedback, such as
aesthetic quality. Finally, we show that DDPO can improve prompt-image
alignment using feedback from a vision-language model without the need for
additional data collection or human annotation. The project&apos;s website can be
found at &lt;a href=&quot;http://rl-diffusion.github.io&quot;&gt;this http URL&lt;/a&gt; .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Black_K/0/1/0/all/0/1&quot;&gt;Kevin Black&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janner_M/0/1/0/all/0/1&quot;&gt;Michael Janner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yilun Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kostrikov_I/0/1/0/all/0/1&quot;&gt;Ilya Kostrikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.02986">
<title>Brain tumor segmentation using synthetic MR images -- A comparison of GANs and diffusion models. (arXiv:2306.02986v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.02986</link>
<description rdf:parseType="Literal">&lt;p&gt;Large annotated datasets are required for training deep learning models, but
in medical imaging data sharing is often complicated due to ethics,
anonymization and data protection legislation. Generative AI models, such as
generative adversarial networks (GANs) and diffusion models, can today produce
very realistic synthetic images, and can potentially facilitate data sharing.
However, in order to share synthetic medical images it must first be
demonstrated that they can be used for training different networks with
acceptable performance. Here, we therefore comprehensively evaluate four GANs
(progressive GAN, StyleGAN 1-3) and a diffusion model for the task of brain
tumor segmentation (using two segmentation networks, U-Net and a Swin
transformer). Our results show that segmentation networks trained on synthetic
images reach Dice scores that are 80% - 90% of Dice scores when training with
real images, but that memorization of the training images can be a problem for
diffusion models if the original dataset is too small. Our conclusion is that
sharing synthetic medical images is a viable option to sharing real images, but
that further work is required. The trained generative models and the generated
synthetic images are shared on AIDA data hub
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Akbar_M/0/1/0/all/0/1&quot;&gt;Muhammad Usman Akbar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Larsson_M/0/1/0/all/0/1&quot;&gt;M&amp;#xe5;ns Larsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Eklund_A/0/1/0/all/0/1&quot;&gt;Anders Eklund&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.08109">
<title>Provable Accelerated Convergence of Nesterov&apos;s Momentum for Deep ReLU Neural Networks. (arXiv:2306.08109v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.08109</link>
<description rdf:parseType="Literal">&lt;p&gt;Current state-of-the-art analyses on the convergence of gradient descent for
training neural networks focus on characterizing properties of the loss
landscape, such as the Polyak-Lojaciewicz (PL) condition and the restricted
strong convexity. While gradient descent converges linearly under such
conditions, it remains an open question whether Nesterov&apos;s momentum enjoys
accelerated convergence under similar settings and assumptions. In this work,
we consider a new class of objective functions, where only a subset of the
parameters satisfies strong convexity, and show Nesterov&apos;s momentum achieves
acceleration in theory for this objective class. We provide two realizations of
the problem class, one of which is deep ReLU networks, which --to the best of
our knowledge--constitutes this work the first that proves accelerated
convergence rate for non-trivial neural network architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_F/0/1/0/all/0/1&quot;&gt;Fangshuo Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12006">
<title>Learning Homogenization for Elliptic Operators. (arXiv:2306.12006v3 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12006</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiscale partial differential equations (PDEs) arise in various
applications, and several schemes have been developed to solve them
efficiently. Homogenization theory is a powerful methodology that eliminates
the small-scale dependence, resulting in simplified equations that are
computationally tractable while accurately predicting the macroscopic response.
In the field of continuum mechanics, homogenization is crucial for deriving
constitutive laws that incorporate microscale physics in order to formulate
balance laws for the macroscopic quantities of interest. However, obtaining
homogenized constitutive laws is often challenging as they do not in general
have an analytic form and can exhibit phenomena not present on the microscale.
In response, data-driven learning of the constitutive law has been proposed as
appropriate for this task. However, a major challenge in data-driven learning
approaches for this problem has remained unexplored: the impact of
discontinuities and corner interfaces in the underlying material. These
discontinuities in the coefficients affect the smoothness of the solutions of
the underlying equations. Given the prevalence of discontinuous materials in
continuum mechanics applications, it is important to address the challenge of
learning in this context; in particular, to develop underpinning theory that
establishes the reliability of data-driven methods in this scientific domain.
The paper addresses this unexplored challenge by investigating the learnability
of homogenized constitutive laws for elliptic operators in the presence of such
complexities. Approximation theory is presented, and numerical experiments are
performed which validate the theory in the context of learning the solution
operator defined by the cell problem arising in homogenization for elliptic
PDEs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bhattacharya_K/0/1/0/all/0/1&quot;&gt;Kaushik Bhattacharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kovachki_N/0/1/0/all/0/1&quot;&gt;Nikola Kovachki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Rajan_A/0/1/0/all/0/1&quot;&gt;Aakila Rajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Stuart_A/0/1/0/all/0/1&quot;&gt;Andrew M. Stuart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Trautner_M/0/1/0/all/0/1&quot;&gt;Margaret Trautner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.03756">
<title>FITS: Modeling Time Series with $10k$ Parameters. (arXiv:2307.03756v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.03756</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce FITS, a lightweight yet powerful model for time
series analysis. Unlike existing models that directly process raw time-domain
data, FITS operates on the principle that time series can be manipulated
through interpolation in the complex frequency domain. By discarding
high-frequency components with negligible impact on time series data, FITS
achieves performance comparable to state-of-the-art models for time series
forecasting and anomaly detection tasks, while having a remarkably compact size
of only approximately $10k$ parameters. Such a lightweight model can be easily
trained and deployed in edge devices, creating opportunities for various
applications. The code is available in: \url{https://github.com/VEWOXIC/FITS}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhijian Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1&quot;&gt;Ailing Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1&quot;&gt;Qiang Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.07688">
<title>Enhancing Network Initialization for Medical AI Models Using Large-Scale, Unlabeled Natural Images. (arXiv:2308.07688v4 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.07688</link>
<description rdf:parseType="Literal">&lt;p&gt;Pre-training datasets, like ImageNet, have become the gold standard in
medical image analysis. However, the emergence of self-supervised learning
(SSL), which leverages unlabeled data to learn robust features, presents an
opportunity to bypass the intensive labeling process. In this study, we
explored if SSL for pre-training on non-medical images can be applied to chest
radiographs and how it compares to supervised pre-training on non-medical
images and on medical images. We utilized a vision transformer and initialized
its weights based on (i) SSL pre-training on natural images (DINOv2), (ii) SL
pre-training on natural images (ImageNet dataset), and (iii) SL pre-training on
chest radiographs from the MIMIC-CXR database. We tested our approach on over
800,000 chest radiographs from six large global datasets, diagnosing more than
20 different imaging findings. Our SSL pre-training on curated images not only
outperformed ImageNet-based pre-training (P&amp;lt;0.001 for all datasets) but, in
certain cases, also exceeded SL on the MIMIC-CXR dataset. Our findings suggest
that selecting the right pre-training strategy, especially with SSL, can be
pivotal for improving artificial intelligence (AI)&apos;s diagnostic accuracy in
medical imaging. By demonstrating the promise of SSL in chest radiograph
analysis, we underline a transformative shift towards more efficient and
accurate AI models in medical imaging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Arasteh_S/0/1/0/all/0/1&quot;&gt;Soroosh Tayebi Arasteh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Misera_L/0/1/0/all/0/1&quot;&gt;Leo Misera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kather_J/0/1/0/all/0/1&quot;&gt;Jakob Nikolas Kather&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Truhn_D/0/1/0/all/0/1&quot;&gt;Daniel Truhn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nebelung_S/0/1/0/all/0/1&quot;&gt;Sven Nebelung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.07728">
<title>Domain-Aware Fine-Tuning: Enhancing Neural Network Adaptability. (arXiv:2308.07728v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.07728</link>
<description rdf:parseType="Literal">&lt;p&gt;Fine-tuning pre-trained neural network models has become a widely adopted
approach across various domains. However, it can lead to the distortion of
pre-trained feature extractors that already possess strong generalization
capabilities. Mitigating feature distortion during adaptation to new target
domains is crucial. Recent studies have shown promising results in handling
feature distortion by aligning the head layer on in-distribution datasets
before performing fine-tuning. Nonetheless, a significant limitation arises
from the treatment of batch normalization layers during fine-tuning, leading to
suboptimal performance. In this paper, we propose Domain-Aware Fine-Tuning
(DAFT), a novel approach that incorporates batch normalization conversion and
the integration of linear probing and fine-tuning. Our batch normalization
conversion method effectively mitigates feature distortion by reducing
modifications to the neural network during fine-tuning. Additionally, we
introduce the integration of linear probing and fine-tuning to optimize the
head layer with gradual adaptation of the feature extractor. By leveraging
batch normalization layers and integrating linear probing and fine-tuning, our
DAFT significantly mitigates feature distortion and achieves improved model
performance on both in-distribution and out-of-distribution datasets. Extensive
experiments demonstrate that our method outperforms other baseline methods,
demonstrating its effectiveness in not only improving performance but also
mitigating feature distortion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_S/0/1/0/all/0/1&quot;&gt;Seokhyeon Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1&quot;&gt;Sunbeom Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jungwoo Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.12075">
<title>Stabilizing RNN Gradients through Pre-training. (arXiv:2308.12075v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.12075</link>
<description rdf:parseType="Literal">&lt;p&gt;Numerous theories of learning propose to prevent the gradient from
exponential growth with depth or time, to stabilize and improve training.
Typically, these analyses are conducted on feed-forward fully-connected neural
networks or simple single-layer recurrent neural networks, given their
mathematical tractability. In contrast, this study demonstrates that
pre-training the network to local stability can be effective whenever the
architectures are too complex for an analytical initialization. Furthermore, we
extend known stability theories to encompass a broader family of deep recurrent
networks, requiring minimal assumptions on data and parameter distribution, a
theory we call the Local Stability Condition (LSC). Our investigation reveals
that the classical Glorot, He, and Orthogonal initialization schemes satisfy
the LSC when applied to feed-forward fully-connected neural networks. However,
analysing deep recurrent networks, we identify a new additive source of
exponential explosion that emerges from counting gradient paths in a
rectangular grid in depth and time. We propose a new approach to mitigate this
issue, that consists on giving a weight of a half to the time and depth
contributions to the gradient, instead of the classical weight of one. Our
empirical results confirm that pre-training both feed-forward and recurrent
networks, for differentiable, neuromorphic and state-space models to fulfill
the LSC, often results in improved final performance. This study contributes to
the field by providing a means to stabilize networks of any complexity. Our
approach can be implemented as an additional step before pre-training on large
augmented datasets, and as an alternative to finding stable initializations
analytically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herranz_Celotti_L/0/1/0/all/0/1&quot;&gt;Luca Herranz-Celotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1&quot;&gt;Jean Rouat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.12325">
<title>Predicting Drug Solubility Using Different Machine Learning Methods -- Linear Regression Model with Extracted Chemical Features vs Graph Convolutional Neural Network. (arXiv:2308.12325v2 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2308.12325</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting the solubility of given molecules remains crucial in the
pharmaceutical industry. In this study, we revisited this extensively studied
topic, leveraging the capabilities of contemporary computing resources. We
employed two machine learning models: a linear regression model and a graph
convolutional neural network (GCNN) model, using various experimental datasets.
Both methods yielded reasonable predictions, with the GCNN model exhibiting the
highest level of performance. However, the present GCNN model has limited
interpretability while the linear regression model allows scientists for a
greater in-depth analysis of the underlying factors through feature importance
analysis, although more human inputs and evaluations on the overall dataset is
required. From the perspective of chemistry, using the linear regression model,
we elucidated the impact of individual atom species and functional groups on
overall solubility, highlighting the significance of comprehending how chemical
structure influences chemical properties in the drug development process. It is
learned that introducing oxygen atoms can increase the solubility of organic
molecules, while almost all other hetero atoms except oxygen and nitrogen tend
to decrease solubility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ho_J/0/1/0/all/0/1&quot;&gt;John Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zhao-Heng Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Colin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Guo_N/0/1/0/all/0/1&quot;&gt;Nicole Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ha_Y/0/1/0/all/0/1&quot;&gt;Yang Ha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.00201">
<title>Subjectivity in Unsupervised Machine Learning Model Selection. (arXiv:2309.00201v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.00201</link>
<description rdf:parseType="Literal">&lt;p&gt;Model selection is a necessary step in unsupervised machine learning. Despite
numerous criteria and metrics, model selection remains subjective. A high
degree of subjectivity may lead to questions about repeatability and
reproducibility of various machine learning studies and doubts about the
robustness of models deployed in the real world. Yet, the impact of modelers&apos;
preferences on model selection outcomes remains largely unexplored. This study
uses the Hidden Markov Model as an example to investigate the subjectivity
involved in model selection. We asked 33 participants and three Large Language
Models (LLMs) to make model selections in three scenarios. Results revealed
variability and inconsistencies in both the participants&apos; and the LLMs&apos;
choices, especially when different criteria and metrics disagree. Sources of
subjectivity include varying opinions on the importance of different criteria
and metrics, differing views on how parsimonious a model should be, and how the
size of a dataset should influence model selection. The results underscore the
importance of developing a more standardized way to document subjective choices
made in model selection processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wanyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cummings_M/0/1/0/all/0/1&quot;&gt;Mary L. Cummings&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.05202">
<title>Graph-Aware Contrasting for Multivariate Time-Series Classification. (arXiv:2309.05202v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.05202</link>
<description rdf:parseType="Literal">&lt;p&gt;Contrastive learning, as a self-supervised learning paradigm, becomes popular
for Multivariate Time-Series (MTS) classification. It ensures the consistency
across different views of unlabeled samples and then learns effective
representations for these samples. Existing contrastive learning methods mainly
focus on achieving temporal consistency with temporal augmentation and
contrasting techniques, aiming to preserve temporal patterns against
perturbations for MTS data. However, they overlook spatial consistency that
requires the stability of individual sensors and their correlations. As MTS
data typically originate from multiple sensors, ensuring spatial consistency
becomes essential for the overall performance of contrastive learning on MTS
data. Thus, we propose Graph-Aware Contrasting for spatial consistency across
MTS data. Specifically, we propose graph augmentations including node and edge
augmentations to preserve the stability of sensors and their correlations,
followed by graph contrasting with both node- and graph-level contrasting to
extract robust sensor- and global-level features. We further introduce
multi-window temporal contrasting to ensure temporal consistency in the data
for each sensor. Extensive experiments demonstrate that our proposed method
achieves state-of-the-art performance on various MTS classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yucheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yuecong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianfei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Min Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoli Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1&quot;&gt;Lihua Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhenghua Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.05305">
<title>Fully-Connected Spatial-Temporal Graph for Multivariate Time-Series Data. (arXiv:2309.05305v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.05305</link>
<description rdf:parseType="Literal">&lt;p&gt;Multivariate Time-Series (MTS) data is crucial in various application fields.
With its sequential and multi-source (multiple sensors) properties, MTS data
inherently exhibits Spatial-Temporal (ST) dependencies, involving temporal
correlations between timestamps and spatial correlations between sensors in
each timestamp. To effectively leverage this information, Graph Neural
Network-based methods (GNNs) have been widely adopted. However, existing
approaches separately capture spatial dependency and temporal dependency and
fail to capture the correlations between Different sEnsors at Different
Timestamps (DEDT). Overlooking such correlations hinders the comprehensive
modelling of ST dependencies within MTS data, thus restricting existing GNNs
from learning effective representations. To address this limitation, we propose
a novel method called Fully-Connected Spatial-Temporal Graph Neural Network
(FC-STGNN), including two key components namely FC graph construction and FC
graph convolution. For graph construction, we design a decay graph to connect
sensors across all timestamps based on their temporal distances, enabling us to
fully model the ST dependencies by considering the correlations between DEDT.
Further, we devise FC graph convolution with a moving-pooling GNN layer to
effectively capture the ST dependencies for learning effective representations.
Extensive experiments show the effectiveness of FC-STGNN on multiple MTS
datasets compared to SOTA methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yucheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yuecong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianfei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Min Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoli Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1&quot;&gt;Lihua Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhenghua Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15325">
<title>Neural Operators for Accelerating Scientific Simulations and Design. (arXiv:2309.15325v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15325</link>
<description rdf:parseType="Literal">&lt;p&gt;Scientific discovery and engineering design are currently limited by the time
and cost of physical experiments, selected mostly through trial-and-error and
intuition that require deep domain expertise. Numerical simulations present an
alternative to physical experiments but are usually infeasible for complex
real-world domains due to the computational requirements of existing numerical
methods. Artificial intelligence (AI) presents a potential paradigm shift by
developing fast data-driven surrogate models. In particular, an AI framework,
known as Neural Operators, presents a principled framework for learning
mappings between functions defined on continuous domains, e.g., spatiotemporal
processes and partial differential equations (PDE). They can extrapolate and
predict solutions at new locations unseen during training, i.e., perform
zero-shot super-resolution. Neural Operators can augment or even replace
existing simulators in many applications, such as computational fluid dynamics,
weather forecasting, and material modeling, while being 4-5 orders of magnitude
faster. Further, Neural Operators can be integrated with physics and other
domain constraints enforced at finer resolutions to obtain high-fidelity
solutions and good generalization. Since Neural Operators are differentiable,
they can directly optimize parameters for inverse design and other inverse
problems. We believe that Neural Operators present a transformative approach to
simulation and design, enabling rapid research and development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1&quot;&gt;Kamyar Azizzadenesheli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kovachki_N/0/1/0/all/0/1&quot;&gt;Nikola Kovachki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zongyi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Schiaffini_M/0/1/0/all/0/1&quot;&gt;Miguel Liu-Schiaffini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1&quot;&gt;Jean Kossaifi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.16221">
<title>Hierarchical Randomized Smoothing. (arXiv:2310.16221v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.16221</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-world data is complex and often consists of objects that can be
decomposed into multiple entities (e.g. images into pixels, graphs into
interconnected nodes). Randomized smoothing is a powerful framework for making
models provably robust against small changes to their inputs - by guaranteeing
robustness of the majority vote when randomly adding noise before
classification. Yet, certifying robustness on such complex data via randomized
smoothing is challenging when adversaries do not arbitrarily perturb entire
objects (e.g. images) but only a subset of their entities (e.g. pixels). As a
solution, we introduce hierarchical randomized smoothing: We partially smooth
objects by adding random noise only on a randomly selected subset of their
entities. By adding noise in a more targeted manner than existing methods we
obtain stronger robustness guarantees while maintaining high accuracy. We
initialize hierarchical smoothing using different noising distributions,
yielding novel robustness certificates for discrete and continuous domains. We
experimentally demonstrate the importance of hierarchical smoothing in image
and node classification, where it yields superior robustness-accuracy
trade-offs. Overall, hierarchical smoothing is an important contribution
towards models that are both - certifiably robust to perturbations and
accurate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholten_Y/0/1/0/all/0/1&quot;&gt;Yan Scholten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuchardt_J/0/1/0/all/0/1&quot;&gt;Jan Schuchardt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bojchevski_A/0/1/0/all/0/1&quot;&gt;Aleksandar Bojchevski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01282">
<title>FlashDecoding++: Faster Large Language Model Inference on GPUs. (arXiv:2311.01282v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.01282</link>
<description rdf:parseType="Literal">&lt;p&gt;As the Large Language Model (LLM) becomes increasingly important in various
domains. However, the following challenges still remain unsolved in
accelerating LLM inference: (1) Synchronized partial softmax update. The
softmax operation requires a synchronized update operation among each partial
softmax result, leading to ~20% overheads for the attention computation in
LLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices
performing GEMM in LLM inference is flat, leading to under-utilized computation
and &amp;gt;50% performance loss after padding zeros in previous designs. (3)
Performance loss due to static dataflow. Kernel performance in LLM depends on
varied input data features, hardware configurations, etc. A single and static
dataflow may lead to a 50.25% performance loss for GEMMs of different shapes in
LLM inference.
&lt;/p&gt;
&lt;p&gt;We present FlashDecoding++, a fast LLM inference engine supporting mainstream
LLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++
creatively proposes: (1) Asynchronized softmax with unified max value.
FlashDecoding++ introduces a unified max value technique for different partial
softmax computations to avoid synchronization. (2) Flat GEMM optimization with
double buffering. FlashDecoding++ points out that flat GEMMs with different
shapes face varied bottlenecks. Then, techniques like double buffering are
introduced. (3) Heuristic dataflow with hardware resource adaptation.
FlashDecoding++ heuristically optimizes dataflow using different hardware
resource considering input dynamics. Due to the versatility of optimizations in
FlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on
both NVIDIA and AMD GPUs compared to Hugging Face implementations.
FlashDecoding++ also achieves an average speedup of 1.37x compared to
state-of-the-art LLM inference engines on mainstream LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1&quot;&gt;Ke Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_G/0/1/0/all/0/1&quot;&gt;Guohao Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiaming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1&quot;&gt;Qiuli Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiuhong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kangdi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yuhan Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09215">
<title>ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy. (arXiv:2311.09215v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2311.09215</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern computer vision offers a great variety of models to practitioners, and
selecting a model from multiple options for specific applications can be
challenging. Conventionally, competing model architectures and training
protocols are compared by their classification accuracy on ImageNet. However,
this single metric does not fully capture performance nuances critical for
specialized tasks. In this work, we conduct an in-depth comparative analysis of
model behaviors beyond ImageNet accuracy, for both ConvNet and Vision
Transformer architectures, each across supervised and CLIP training paradigms.
Although our selected models have similar ImageNet accuracies and compute
requirements, we find that they differ in many other aspects: types of
mistakes, output calibration, transferability, and feature invariance, among
others. This diversity in model characteristics, not captured by traditional
metrics, highlights the need for more nuanced analysis when choosing among
different models. Our code is available at
https://github.com/kirill-vish/Beyond-INet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishniakov_K/0/1/0/all/0/1&quot;&gt;Kirill Vishniakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhuang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.09441">
<title>Exploring the Privacy-Energy Consumption Tradeoff for Split Federated Learning. (arXiv:2311.09441v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.09441</link>
<description rdf:parseType="Literal">&lt;p&gt;Split Federated Learning (SFL) has recently emerged as a promising
distributed learning technology, leveraging the strengths of both federated
learning and split learning. It emphasizes the advantages of rapid convergence
while addressing privacy concerns. As a result, this innovation has received
significant attention from both industry and academia. However, since the model
is split at a specific layer, known as a cut layer, into both client-side and
server-side models for the SFL, the choice of the cut layer in SFL can have a
substantial impact on the energy consumption of clients and their privacy, as
it influences the training burden and the output of the client-side models.
Moreover, the design challenge of determining the cut layer is highly
intricate, primarily due to the inherent heterogeneity in the computing and
networking capabilities of clients. In this article, we provide a comprehensive
overview of the SFL process and conduct a thorough analysis of energy
consumption and privacy. This analysis takes into account the influence of
various system parameters on the cut layer selection strategy. Additionally, we
provide an illustrative example of the cut layer selection, aiming to minimize
the risk of clients from reconstructing the raw data at the server while
sustaining energy consumption within the required energy budget, which involve
trade-offs. Finally, we address open challenges in this field. These directions
represent promising avenues for future research and development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joohyung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seif_M/0/1/0/all/0/1&quot;&gt;Mohamed Seif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1&quot;&gt;Jungchan Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1&quot;&gt;H. Vincent Poor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.14212">
<title>Annotation Sensitivity: Training Data Collection Methods Affect Model Performance. (arXiv:2311.14212v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2311.14212</link>
<description rdf:parseType="Literal">&lt;p&gt;When training data are collected from human annotators, the design of the
annotation instrument, the instructions given to annotators, the
characteristics of the annotators, and their interactions can impact training
data. This study demonstrates that design choices made when creating an
annotation instrument also impact the models trained on the resulting
annotations. We introduce the term annotation sensitivity to refer to the
impact of annotation data collection methods on the annotations themselves and
on downstream model performance and predictions. We collect annotations of hate
speech and offensive language in five experimental conditions of an annotation
instrument, randomly assigning annotators to conditions. We then fine-tune BERT
models on each of the five resulting datasets and evaluate model performance on
a holdout portion of each condition. We find considerable differences between
the conditions for 1) the share of hate speech/offensive language annotations,
2) model performance, 3) model predictions, and 4) model learning curves. Our
results emphasize the crucial role played by the annotation instrument which
has received little attention in the machine learning literature. We call for
additional research into how and why the instrument impacts the annotations to
inform the development of best practices in instrument design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kern_C/0/1/0/all/0/1&quot;&gt;Christoph Kern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Eckman_S/0/1/0/all/0/1&quot;&gt;Stephanie Eckman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Beck_J/0/1/0/all/0/1&quot;&gt;Jacob Beck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chew_R/0/1/0/all/0/1&quot;&gt;Rob Chew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_B/0/1/0/all/0/1&quot;&gt;Bolei Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kreuter_F/0/1/0/all/0/1&quot;&gt;Frauke Kreuter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.17431">
<title>Grounding Foundation Models through Federated Transfer Learning: A General Framework. (arXiv:2311.17431v7 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.17431</link>
<description rdf:parseType="Literal">&lt;p&gt;Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and
powerful emergent abilities have achieved remarkable success in various natural
language processing and computer vision tasks. Grounding FMs by adapting them
to domain-specific tasks or augmenting them with domain-specific knowledge
enables us to exploit the full potential of FMs. However, grounding FMs faces
several challenges, stemming primarily from constrained computing resources,
data privacy, model heterogeneity, and model ownership. Federated Transfer
Learning (FTL), the combination of federated learning and transfer learning,
provides promising solutions to address these challenges. In recent years, the
need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in
both academia and industry. Motivated by the strong growth in FTL-FM research
and the potential impact of FTL-FM on industrial applications, we propose an
FTL-FM framework that formulates problems of grounding FMs in the federated
learning setting, construct a detailed taxonomy based on the FTL-FM framework
to categorize state-of-the-art FTL-FM works, and comprehensively overview
FTL-FM works based on the proposed taxonomy. We also establish correspondences
between FTL-FM and conventional phases of adapting FM so that FM practitioners
can align their research works with FTL-FM. In addition, we overview advanced
efficiency-improving and privacy-preserving techniques because efficiency and
privacy are critical concerns in FTL-FM. Last, we discuss opportunities and
future research directions of FTL-FM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1&quot;&gt;Yan Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1&quot;&gt;Tao Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1&quot;&gt;Hanlin Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaojin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Lixin Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.01878">
<title>HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning. (arXiv:2312.01878v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.01878</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs)
are prominent techniques for homogeneous and heterogeneous graph representation
learning, yet their performance in an end-to-end supervised framework greatly
depends on the availability of task-specific supervision. To reduce the
labeling cost, pre-training on self-supervised pretext tasks has become a
popular paradigm,but there is often a gap between the pre-trained model and
downstream tasks, stemming from the divergence in their objectives. To bridge
the gap, prompt learning has risen as a promising direction especially in
few-shot settings, without the need to fully fine-tune the pre-trained model.
While there has been some early exploration of prompt-based learning on graphs,
they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs
that are prevalent in downstream applications. In this paper, we propose
HGPROMPT, a novel pre-training and prompting framework to unify not only
pre-training and downstream tasks but also homogeneous and heterogeneous graphs
via a dual-template design. Moreover, we propose dual-prompt in HGPROMPT to
assist a downstream task in locating the most relevant prior to bridge the gaps
caused by not only feature variations but also heterogeneity differences across
tasks. Finally, we thoroughly evaluate and analyze HGPROMPT through extensive
experiments on three public datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xingtong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1&quot;&gt;Yuan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zemin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinming Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04889">
<title>KwaiAgents: Generalized Information-seeking Agent System with Large Language Models. (arXiv:2312.04889v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2312.04889</link>
<description rdf:parseType="Literal">&lt;p&gt;Driven by curiosity, humans have continually sought to explore and understand
the world around them, leading to the invention of various tools to satiate
this inquisitiveness. Despite not having the capacity to process and memorize
vast amounts of information in their brains, humans excel in critical thinking,
planning, reflection, and harnessing available tools to interact with and
interpret the world, enabling them to find answers efficiently. The recent
advancements in large language models (LLMs) suggest that machines might also
possess the aforementioned human-like capabilities, allowing them to exhibit
powerful abilities even with a constrained parameter count. In this paper, we
introduce KwaiAgents, a generalized information-seeking agent system based on
LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its
cognitive core, which is capable of understanding a user&apos;s query, behavior
guidelines, and referencing external documents. The agent can also update and
retrieve information from its internal memory, plan and execute actions using a
time-aware search-browse toolkit, and ultimately provide a comprehensive
response. We further investigate the system&apos;s performance when powered by LLMs
less advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework,
designed to ensure even an open-sourced 7B or 13B model performs well among
many agent systems. We exploit both benchmark and human evaluations to
systematically validate these capabilities. Extensive experiments show the
superiority of our agent system compared to other autonomous agents and
highlight the enhanced generalized agent-abilities of our fine-tuned LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1&quot;&gt;Haojie Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhai_Z/0/1/0/all/0/1&quot;&gt;Zepeng Zhai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1&quot;&gt;Hao Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1&quot;&gt;Yaojia Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_R/0/1/0/all/0/1&quot;&gt;Ruiji Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Ming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhongyuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1&quot;&gt;Bing Qin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.06942">
<title>AI Control: Improving Safety Despite Intentional Subversion. (arXiv:2312.06942v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.06942</link>
<description rdf:parseType="Literal">&lt;p&gt;As large language models (LLMs) become more powerful and are deployed more
autonomously, it will be increasingly important to prevent them from causing
harmful outcomes. Researchers have investigated a variety of safety techniques
for this purpose, e.g. using models to review the outputs of other models, or
red-teaming techniques to surface subtle failure modes. However, researchers
have not evaluated whether such techniques still ensure safety if the model is
itself intentionally trying to subvert them. In this paper, we develop and
evaluate pipelines of safety techniques (&quot;protocols&quot;) that are robust to
intentional subversion.
&lt;/p&gt;
&lt;p&gt;We investigate a scenario in which we want to solve a sequence of programming
problems, using access to a powerful but untrusted model (in our case, GPT-4),
access to a less powerful trusted model (in our case, GPT-3.5), and limited
access to high-quality trusted labor. We investigate protocols that aim to
never submit solutions containing backdoors, which we operationalize here as
logical errors that are not caught by test cases.
&lt;/p&gt;
&lt;p&gt;We investigate a range of protocols and test each against strategies that the
untrusted model could use to subvert them. One protocol is what we call trusted
editing. This protocol first asks GPT-4 to write code, and then asks GPT-3.5 to
rate the suspiciousness of that code. If the code is below some suspiciousness
threshold, it is submitted. Otherwise, GPT-3.5 edits the solution to remove
parts that seem suspicious and then submits the edited code. Another protocol
is untrusted monitoring. This protocol asks GPT-4 to write code, and then asks
another instance of GPT-4 whether the code is backdoored, using various
techniques to prevent the GPT-4 instances from colluding. These protocols
improve substantially on simple baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Greenblatt_R/0/1/0/all/0/1&quot;&gt;Ryan Greenblatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlegeris_B/0/1/0/all/0/1&quot;&gt;Buck Shlegeris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sachan_K/0/1/0/all/0/1&quot;&gt;Kshitij Sachan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roger_F/0/1/0/all/0/1&quot;&gt;Fabien Roger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07910">
<title>PromptBench: A Unified Library for Evaluation of Large Language Models. (arXiv:2312.07910v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2312.07910</link>
<description rdf:parseType="Literal">&lt;p&gt;The evaluation of large language models (LLMs) is crucial to assess their
performance and mitigate potential security risks. In this paper, we introduce
PromptBench, a unified library to evaluate LLMs. It consists of several key
components that are easily used and extended by researchers: prompt
construction, prompt engineering, dataset and model loading, adversarial prompt
attack, dynamic evaluation protocols, and analysis tools. PromptBench is
designed to be an open, general, and flexible codebase for research purposes
that can facilitate original study in creating new benchmarks, deploying
downstream applications, and designing new evaluation protocols. The code is
available at: https://github.com/microsoft/promptbench and will be continuously
supported.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1&quot;&gt;Kaijie Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qinlin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08785">
<title>Managing the unknown: a survey on Open Set Recognition and tangential areas. (arXiv:2312.08785v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.08785</link>
<description rdf:parseType="Literal">&lt;p&gt;In real-world scenarios classification models are often required to perform
robustly when predicting samples belonging to classes that have not appeared
during its training stage. Open Set Recognition addresses this issue by
devising models capable of detecting unknown classes from samples arriving
during the testing phase, while maintaining a good level of performance in the
classification of samples belonging to known classes. This review
comprehensively overviews the recent literature related to Open Set
Recognition, identifying common practices, limitations, and connections of this
field with other machine learning research areas, such as continual learning,
out-of-distribution detection, novelty detection, and uncertainty estimation.
Our work also uncovers open problems and suggests several research directions
that may motivate and articulate future efforts towards more safe Artificial
Intelligence methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barcina_Blanco_M/0/1/0/all/0/1&quot;&gt;Marcos Barcina-Blanco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lobo_J/0/1/0/all/0/1&quot;&gt;Jesus L. Lobo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Bringas_P/0/1/0/all/0/1&quot;&gt;Pablo Garcia-Bringas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ser_J/0/1/0/all/0/1&quot;&gt;Javier Del Ser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.11514">
<title>LLM in a flash: Efficient Large Language Model Inference with Limited Memory. (arXiv:2312.11514v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.11514</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) are central to modern natural language
processing, delivering exceptional performance in various tasks. However, their
substantial computational and memory requirements present challenges,
especially for devices with limited DRAM capacity. This paper tackles the
challenge of efficiently running LLMs that exceed the available DRAM capacity
by storing the model parameters in flash memory, but bringing them on demand to
DRAM. Our method involves constructing an inference cost model that takes into
account the characteristics of flash memory, guiding us to optimize in two
critical areas: reducing the volume of data transferred from flash and reading
data in larger, more contiguous chunks. Within this hardware-informed
framework, we introduce two principal techniques. First, &quot;windowing&quot;
strategically reduces data transfer by reusing previously activated neurons,
and second, &quot;row-column bundling&quot;, tailored to the sequential data access
strengths of flash memory, increases the size of data chunks read from flash
memory. These methods collectively enable running models up to twice the size
of the available DRAM, with a 4-5x and 20-25x increase in inference speed
compared to naive loading approaches in CPU and GPU, respectively. Our
integration of sparsity awareness, context-adaptive loading, and a
hardware-oriented design paves the way for effective inference of LLMs on
devices with limited memory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alizadeh_K/0/1/0/all/0/1&quot;&gt;Keivan Alizadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirzadeh_I/0/1/0/all/0/1&quot;&gt;Iman Mirzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belenko_D/0/1/0/all/0/1&quot;&gt;Dmitry Belenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khatamifard_K/0/1/0/all/0/1&quot;&gt;Karen Khatamifard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1&quot;&gt;Minsik Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mundo_C/0/1/0/all/0/1&quot;&gt;Carlo C Del Mundo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1&quot;&gt;Mohammad Rastegari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farajtabar_M/0/1/0/all/0/1&quot;&gt;Mehrdad Farajtabar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.13143">
<title>Underwater Acoustic Signal Recognition Based on Salient Feature. (arXiv:2312.13143v3 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2312.13143</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid advancement of technology, the recognition of underwater
acoustic signals in complex environments has become increasingly crucial.
Currently, mainstream underwater acoustic signal recognition relies primarily
on time-frequency analysis to extract spectral features, finding widespread
applications in the field. However, existing recognition methods heavily depend
on expert systems, facing limitations such as restricted knowledge bases and
challenges in handling complex relationships. These limitations stem from the
complexity and maintenance difficulties associated with rules or inference
engines. Recognizing the potential advantages of deep learning in handling
intricate relationships, this paper proposes a method utilizing neural networks
for underwater acoustic signal recognition. The proposed approach involves
continual learning of features extracted from spectra for the classification of
underwater acoustic signals. Deep learning models can automatically learn
abstract features from data and continually adjust weights during training to
enhance classification performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Minghao Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.14303">
<title>Geo2SigMap: High-Fidelity RF Signal Mapping Using Geographic Databases. (arXiv:2312.14303v2 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2312.14303</link>
<description rdf:parseType="Literal">&lt;p&gt;Radio frequency (RF) signal mapping, which is the process of analyzing and
predicting the RF signal strength and distribution across specific areas, is
crucial for cellular network planning and deployment. Traditional approaches to
RF signal mapping rely on statistical models constructed based on measurement
data, which offer low complexity but often lack accuracy, or ray tracing tools,
which provide enhanced precision for the target area but suffer from increased
computational complexity. Recently, machine learning (ML) has emerged as a
data-driven method for modeling RF signal propagation, which leverages models
trained on synthetic datasets to perform RF signal mapping in &quot;unseen&quot; areas.
&lt;/p&gt;
&lt;p&gt;In this paper, we present Geo2SigMap, an ML-based framework for efficient and
high-fidelity RF signal mapping using geographic databases. First, we develop
an automated framework that seamlessly integrates three open-source tools:
OpenStreetMap (geographic databases), Blender (computer graphics), and Sionna
(ray tracing), enabling the efficient generation of large-scale 3D building
maps and ray tracing models. Second, we propose a cascaded U-Net model, which
is pre-trained on synthetic datasets and employed to generate detailed RF
signal maps, leveraging environmental information and sparse measurement data.
Finally, we evaluate the performance of Geo2SigMap via a real-world measurement
campaign, where three types of user equipment (UE) collect over 45,000 data
points related to cellular information from six LTE cells operating in the
citizens broadband radio service (CBRS) band. Our results show that Geo2SigMap
achieves an average root-mean-square-error (RMSE) of 6.04 dB for predicting the
reference signal received power (RSRP) at the UE, representing an average RMSE
improvement of 3.59 dB compared to existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yiming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zeyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gao_Z/0/1/0/all/0/1&quot;&gt;Zhihui Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tingjun Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.15960">
<title>MoTCoder: Elevating Large Language Models with Modular of Thought for Challenging Programming Tasks. (arXiv:2312.15960v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.15960</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have showcased impressive capabilities in
handling straightforward programming tasks. However, their performance tends to
falter when confronted with more challenging programming problems. We observe
that conventional models often generate solutions as monolithic code blocks,
restricting their effectiveness in tackling intricate questions. To overcome
this limitation, we present Modular-of-Thought Coder (MoTCoder). We introduce a
pioneering framework for MoT instruction tuning, designed to promote the
decomposition of tasks into logical sub-tasks and sub-modules. Our
investigations reveal that, through the cultivation and utilization of
sub-modules, MoTCoder significantly improves both the modularity and
correctness of the generated solutions, leading to substantial relative pass@1
improvements of 12.9% on APPS and 9.43% on CodeContests. Our codes are
available at https://github.com/dvlab-research/MoTCoder.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jingyao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pengguang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1&quot;&gt;Jiaya Jia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00023">
<title>CycleGAN Models for MRI Image Translation. (arXiv:2401.00023v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2401.00023</link>
<description rdf:parseType="Literal">&lt;p&gt;Image-to-image translation has gained popularity in the medical field to
transform images from one domain to another. Medical image synthesis via domain
transformation is advantageous in its ability to augment an image dataset where
images for a given class is limited. From the learning perspective, this
process contributes to data-oriented robustness of the model by inherently
broadening the model&apos;s exposure to more diverse visual data and enabling it to
learn more generalized features. In the case of generating additional
neuroimages, it is advantageous to obtain unidentifiable medical data and
augment smaller annotated datasets. This study proposes the development of a
CycleGAN model for translating neuroimages from one field strength to another
(e.g., 3 Tesla to 1.5). This model was compared to a model based on DCGAN
architecture. CycleGAN was able to generate the synthetic and reconstructed
images with reasonable accuracy. The mapping function from the source (3 Tesla)
to target domain (1.5 Tesla) performed optimally with an average PSNR value of
25.69 $\pm$ 2.49 dB and an MAE value of 2106.27 $\pm$ 1218.37.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Czobit_C/0/1/0/all/0/1&quot;&gt;Cassandra Czobit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Samavi_R/0/1/0/all/0/1&quot;&gt;Reza Samavi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00031">
<title>Self-supervised Pretraining for Decision Foundation Model: Formulation, Pipeline and Challenges. (arXiv:2401.00031v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2401.00031</link>
<description rdf:parseType="Literal">&lt;p&gt;Decision-making is a dynamic process requiring perception, memory, and
reasoning to make choices and find optimal policies. Traditional approaches to
decision-making suffer from sample efficiency and generalization, while
large-scale self-supervised pretraining has enabled fast adaptation with
fine-tuning or few-shot learning in language and vision. We thus argue to
integrate knowledge acquired from generic large-scale self-supervised
pretraining into downstream decision-making problems. We propose
Pretrain-Then-Adapt pipeline and survey recent work on data collection,
pretraining objectives and adaptation strategies for decision-making
pretraining and downstream inference. Finally, we identify critical challenges
and future directions for developing decision foundation model with the help of
generic and flexible self-supervised pretraining.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaoqian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jianbin Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Junge Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00867">
<title>Tensor Networks for Explainable Machine Learning in Cybersecurity. (arXiv:2401.00867v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2401.00867</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we show how tensor networks help in developing explainability
of machine learning algorithms. Specifically, we develop an unsupervised
clustering algorithm based on Matrix Product States (MPS) and apply it in the
context of a real use-case of adversary-generated threat intelligence. Our
investigation proves that MPS rival traditional deep learning models such as
autoencoders and GANs in terms of performance, while providing much richer
model interpretability. Our approach naturally facilitates the extraction of
feature-wise probabilities, Von Neumann Entropy, and mutual information,
offering a compelling narrative for classification of anomalies and fostering
an unprecedented level of transparency and interpretability, something
fundamental to understand the rationale behind artificial intelligence
decisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aizpurua_B/0/1/0/all/0/1&quot;&gt;Borja Aizpurua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orus_R/0/1/0/all/0/1&quot;&gt;Roman Orus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01100">
<title>Scalable manifold learning by uniform landmark sampling and constrained locally linear embedding. (arXiv:2401.01100v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2401.01100</link>
<description rdf:parseType="Literal">&lt;p&gt;As a pivotal approach in machine learning and data science, manifold learning
aims to uncover the intrinsic low-dimensional structure within complex
nonlinear manifolds in high-dimensional space. By exploiting the manifold
hypothesis, various techniques for nonlinear dimension reduction have been
developed to facilitate visualization, classification, clustering, and gaining
key insights. Although existing manifold learning methods have achieved
remarkable successes, they still suffer from extensive distortions incurred in
the global structure, which hinders the understanding of underlying patterns.
Scalability issues also limit their applicability for handling large-scale
data. Here, we propose a scalable manifold learning (scML) method that can
manipulate large-scale and high-dimensional data in an efficient manner. It
starts by seeking a set of landmarks to construct the low-dimensional skeleton
of the entire data, and then incorporates the non-landmarks into the learned
space based on the constrained locally linear embedding (CLLE). We empirically
validated the effectiveness of scML on synthetic datasets and real-world
benchmarks of different types, and applied it to analyze the single-cell
transcriptomics and detect anomalies in electrocardiogram (ECG) signals. scML
scales well with increasing data sizes and embedding dimensions, and exhibits
promising performance in preserving the global structure. The experiments
demonstrate notable robustness in embedding quality as the sample rate
decreases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1&quot;&gt;Dehua Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gui_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Gui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1&quot;&gt;Wenzhang Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Huayi Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01148">
<title>PAC-Bayes-Chernoff bounds for unbounded losses. (arXiv:2401.01148v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2401.01148</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new high-probability PAC-Bayes oracle bound for unbounded
losses. This result can be understood as a PAC-Bayes version of the Chernoff
bound. The proof technique relies on uniformly bounding the tail of certain
random variable based on the Cram\&apos;er transform of the loss. We highlight two
applications of our main result. First, we show that our bound solves the open
problem of optimizing the free parameter on many PAC-Bayes bounds. Finally, we
show that our approach allows working with flexible assumptions on the loss
function, resulting in novel bounds that generalize previous ones and can be
minimized to obtain Gibbs-like posteriors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Casado_I/0/1/0/all/0/1&quot;&gt;Ioar Casado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ortega_L/0/1/0/all/0/1&quot;&gt;Luis A. Ortega&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Masegosa_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s R. Masegosa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perez_A/0/1/0/all/0/1&quot;&gt;Aritz P&amp;#xe9;rez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01386">
<title>Tissue Artifact Segmentation and Severity Analysis for Automated Diagnosis Using Whole Slide Images. (arXiv:2401.01386v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2401.01386</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditionally, pathological analysis and diagnosis are performed by manually
eyeballing glass slide specimens under a microscope by an expert. The whole
slide image is the digital specimen produced from the glass slide. Whole slide
image enabled specimens to be observed on a computer screen and led to
computational pathology where computer vision and artificial intelligence are
utilized for automated analysis and diagnosis. With the current computational
advancement, the entire whole slide image can be analyzed autonomously without
human supervision. However, the analysis could fail or lead to wrong diagnosis
if the whole slide image is affected by tissue artifacts such as tissue fold or
air bubbles depending on the severity. Existing artifact detection methods rely
on experts for severity assessment to eliminate artifact affected regions from
the analysis. This process is time consuming, exhausting and undermines the
goal of automated analysis or removal of artifacts without evaluating their
severity, which could result in the loss of diagnostically important data.
Therefore, it is necessary to detect artifacts and then assess their severity
automatically. In this paper, we propose a system that incorporates severity
evaluation with artifact detection utilizing convolutional neural networks. The
proposed system uses DoubleUNet to segment artifacts and an ensemble network of
six fine tuned convolutional neural network models to determine severity. This
method outperformed current state of the art in accuracy by 9 percent for
artifact segmentation and achieved a strong correlation of 97 percent with the
evaluation of pathologists for severity assessment. The robustness of the
system was demonstrated using our proposed heterogeneous dataset and practical
usability was ensured by integrating it with an automated analysis system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Himel_G/0/1/0/all/0/1&quot;&gt;Galib Muhammad Shahriar Himel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01916">
<title>AstroLLaMA-Chat: Scaling AstroLLaMA with Conversational and Diverse Datasets. (arXiv:2401.01916v2 [astro-ph.IM] UPDATED)</title>
<link>http://arxiv.org/abs/2401.01916</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the potential of enhancing LLM performance in astronomy-focused
question-answering through targeted, continual pre-training. By employing a
compact 7B-parameter LLaMA-2 model and focusing exclusively on a curated set of
astronomy corpora -- comprising abstracts, introductions, and conclusions -- we
achieve notable improvements in specialized topic comprehension. While general
LLMs like GPT-4 excel in broader question-answering scenarios due to superior
reasoning capabilities, our findings suggest that continual pre-training with
limited resources can still enhance model performance on specialized topics.
Additionally, we present an extension of AstroLLaMA: the fine-tuning of the 7B
LLaMA model on a domain-specific conversational dataset, culminating in the
release of the chat-enabled AstroLLaMA for community use. Comprehensive
quantitative benchmarking is currently in progress and will be detailed in an
upcoming full paper. The model, AstroLLaMA-Chat, is now available at
https://huggingface.co/universeTBD, providing the first open-source
conversational AI tool tailored for the astronomy community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Perkowski_E/0/1/0/all/0/1&quot;&gt;Ernest Perkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Pan_R/0/1/0/all/0/1&quot;&gt;Rui Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Tuan Dung Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Ting_Y/0/1/0/all/0/1&quot;&gt;Yuan-Sen Ting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Kruk_S/0/1/0/all/0/1&quot;&gt;Sandor Kruk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+ONeill_C/0/1/0/all/0/1&quot;&gt;Charlie O&amp;#x27;Neill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Jablonska_M/0/1/0/all/0/1&quot;&gt;Maja Jablonska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zechang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Smith_M/0/1/0/all/0/1&quot;&gt;Michael J. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Huiling Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Schawinski_K/0/1/0/all/0/1&quot;&gt;Kevin Schawinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Iyer_K/0/1/0/all/0/1&quot;&gt;Kartheik Iyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+UniverseTBD_I/0/1/0/all/0/1&quot;&gt;Ioana Ciuc&amp;#x103; for UniverseTBD&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02106">
<title>Cadmium Zinc Telluride (CZT) photon counting detector Characterisation for soft tissue imaging. (arXiv:2401.02106v2 [physics.ins-det] UPDATED)</title>
<link>http://arxiv.org/abs/2401.02106</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of photon counting detection technology has resulted in significant
X-ray imaging research interest in recent years. Computed Tomography (CT)
scanners can benefit from photon-counting detectors, which are new technology
with the potential to overcome key limitations of conventional CT detectors.
Researchers are still studying the effectiveness and sensitivity of
semiconductor detector materials in photon counting detectors for detecting
soft tissue contrasts. This study aimed to characterize the performance of the
Cadmium Zinc Telluride photon counting detector in identifying various tissues.
An optimal frame rate per second (FPS) of CZT detector was evaluated by setting
the X-ray tube voltage and current at 25 keV, 35 keV and 0.5 mA, 1.0 mA
respectively by keeping the optimum FPS fixed, the detector energy thresholds
were set in small steps from 15 keV to 35 keV and the Currents were set for
X-ray tubes in ranges of 0.1 mA to 1.0 mA to find the relationship between
voltage and current of the X-ray source and counts per second (CPS). The
samples i.e., fat, liver, muscles, paraffin wax, and contrast media were
stacked at six different thickness levels in a stair-step chamber made from
Plexi-glass. X-ray transmission at six different thicknesses of tissue samples
was also examined for five different energy (regions) thresholds (21 keV, 25
keV, 29 keV, 31 keV, and 45 keV) to determine the effect on count per second
(CPS). In this study, 12 frames per second is found to be the optimum frame
rate per second (FPS) based on the spectral response of an X-ray source and CPS
has a linear relationship with X-ray tube current as well. It was also noted
that A sample&apos;s thickness also affects its X-ray transmission at different
energy thresholds. A high sensitivity and linearity of the detectors make them
suitable for use in both preclinical and medical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hameed_K/0/1/0/all/0/1&quot;&gt;K. Hameed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zainon_R/0/1/0/all/0/1&quot;&gt;Rafidah Zainon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Tamal_M/0/1/0/all/0/1&quot;&gt;Mahbubunnabi Tamal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00134">
<title>Unicron: Economizing Self-Healing LLM Training at Scale. (arXiv:2401.00134v1 [cs.DC] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2401.00134</link>
<description rdf:parseType="Literal">&lt;p&gt;Training large-scale language models is increasingly critical in various
domains, but it is hindered by frequent failures, leading to significant time
and economic costs. Current failure recovery methods in cloud-based settings
inadequately address the diverse and complex scenarios that arise, focusing
narrowly on erasing downtime for individual tasks without considering the
overall cost impact on a cluster. We introduce Unicron, a workload manager
designed for efficient self-healing in large-scale language model training.
Unicron optimizes the training process by minimizing failure-related costs
across multiple concurrent tasks within a cluster. Its key features include
in-band error detection for real-time error identification without extra
overhead, a dynamic cost-aware plan generation mechanism for optimal
reconfiguration, and an efficient transition strategy to reduce downtime during
state changes. Deployed on a 128-GPU distributed cluster, Unicron demonstrates
up to a 1.9x improvement in training efficiency over state-of-the-art methods,
significantly reducing failure recovery costs and enhancing the reliability of
large-scale language model training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1&quot;&gt;Tao He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xue Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhibin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1&quot;&gt;Kun Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jingbo Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wenyuan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jingren Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.02329">
<title>Not all Minorities are Equal: Empty-Class-Aware Distillation for Heterogeneous Federated Learning. (arXiv:2401.02329v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2401.02329</link>
<description rdf:parseType="Literal">&lt;p&gt;Data heterogeneity, characterized by disparities in local data distribution
across clients, poses a significant challenge in federated learning.
Substantial efforts have been devoted to addressing the heterogeneity in local
label distribution. As minority classes suffer from worse accuracy due to
overfitting on local imbalanced data, prior methods often incorporate
class-balanced learning techniques during local training. Despite the improved
mean accuracy across all classes, we observe that empty classes-referring to
categories absent from a client&apos;s data distribution-are still not well
recognized. This paper introduces FedED, a novel approach in heterogeneous
federated learning that integrates both empty-class distillation and logit
suppression simultaneously. Specifically, empty-class distillation leverages
knowledge distillation during local training on each client to retain essential
information related to empty classes from the global model. Moreover, logit
suppression directly penalizes network logits for non-label classes,
effectively addressing misclassifications in minority classes that may be
biased toward majority classes. Extensive experiments validate the efficacy of
FedED, surpassing previous state-of-the-art methods across diverse datasets
with varying degrees of label distribution shift.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1&quot;&gt;Kuangpu Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1&quot;&gt;Yuhe Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jian Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1&quot;&gt;Ran He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zilei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1&quot;&gt;Tieniu Tan&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>