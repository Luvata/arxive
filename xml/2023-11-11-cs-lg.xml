<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-11-09T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04905" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04918" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04927" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04929" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04937" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04938" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04943" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04948" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04951" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04965" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04991" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04996" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05006" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05017" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05019" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05032" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05041" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05042" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05046" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05050" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05054" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05061" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05067" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05071" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05075" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05079" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05081" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05084" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05088" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05092" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05108" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05109" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05116" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05128" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05135" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05139" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05144" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05152" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05160" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05167" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05185" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05203" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05241" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05245" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05256" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05265" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05297" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05303" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05304" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05316" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05317" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05323" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05334" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05346" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05360" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05363" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05398" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05400" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05407" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05417" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05418" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05420" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05421" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05426" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05430" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05435" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05436" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05437" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05440" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05451" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05473" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05477" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05486" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05501" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05511" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05529" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05538" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05539" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05550" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05556" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05557" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05565" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05567" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05573" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05579" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05584" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05587" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05589" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05596" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05598" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05606" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05610" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1912.06708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.02171" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2010.13380" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2012.11258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.13913" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.00906" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2106.08992" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.11886" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.00115" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2110.01736" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2203.16463" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2204.07028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.08913" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.04798" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.00445" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.05954" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.07932" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.09134" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.10962" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.03080" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.09015" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.02982" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.05785" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.09633" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.09734" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.10171" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.12534" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.08688" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.10093" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.10158" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.01353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.02738" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.05828" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.08789" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.00549" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.04234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.07687" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.01588" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.10564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12396" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15001" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.16841" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.01187" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.02913" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04027" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.08013" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.09955" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.11167" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.12929" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.17750" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02064" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.04052" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.04461" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.05439" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06250" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06933" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.07980" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.12943" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.16695" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03811" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05061" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.14991" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.00608" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.01784" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.13016" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.06328" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.06643" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.09949" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.10378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.12421" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.12802" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13121" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.13236" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.14360" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.15767" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.18590" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.19218" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.20190" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.00136" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.01771" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02096" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.03405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.03421" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.03755" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.03764" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.03839" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04252" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04592" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.04661" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2311.04905">
<title>Detecting Relevant Information in High-Volume Chat Logs: Keyphrase Extraction for Grooming and Drug Dealing Forensic Analysis. (arXiv:2311.04905v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.04905</link>
<description rdf:parseType="Literal">&lt;p&gt;The growing use of digital communication platforms has given rise to various
criminal activities, such as grooming and drug dealing, which pose significant
challenges to law enforcement and forensic experts. This paper presents a
supervised keyphrase extraction approach to detect relevant information in
high-volume chat logs involving grooming and drug dealing for forensic
analysis. The proposed method, JointKPE++, builds upon the JointKPE keyphrase
extractor by employing improvements to handle longer texts effectively. We
evaluate JointKPE++ using BERT-based pre-trained models on grooming and drug
dealing datasets, including BERT, RoBERTa, SpanBERT, and BERTimbau. The results
show significant improvements over traditional approaches and demonstrate the
potential for JointKPE++ to aid forensic experts in efficiently detecting
keyphrases related to criminal activities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alves_J/0/1/0/all/0/1&quot;&gt;Jeovane Hon&amp;#xf3;rio Alves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedroso_H/0/1/0/all/0/1&quot;&gt;Hor&amp;#xe1;cio A. C. G. Pedroso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venetikides_R/0/1/0/all/0/1&quot;&gt;Rafael Honorio Venetikides&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koster_J/0/1/0/all/0/1&quot;&gt;Joel E. M. K&amp;#xf6;ster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grochocki_L/0/1/0/all/0/1&quot;&gt;Luiz Rodrigo Grochocki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freitas_C/0/1/0/all/0/1&quot;&gt;Cinthia O. A. Freitas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barddal_J/0/1/0/all/0/1&quot;&gt;Jean Paul Barddal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04916">
<title>Explainable Identification of Hate Speech towards Islam using Graph Neural Networks. (arXiv:2311.04916v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.04916</link>
<description rdf:parseType="Literal">&lt;p&gt;Islamophobic language is a prevalent challenge on online social interaction
platforms. Identifying and eliminating such hatred is a crucial step towards a
future of harmony and peace. This study presents a novel paradigm for
identifying and explaining hate speech towards Islam using graph neural
networks. Utilizing the intrinsic ability of graph neural networks to find,
extract, and use relationships across disparate data points, our model
consistently achieves outstanding performance while offering explanations for
the underlying correlations and causation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wasi_A/0/1/0/all/0/1&quot;&gt;Azmine Toushik Wasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04918">
<title>Low-Resource Named Entity Recognition: Can One-vs-All AUC Maximization Help?. (arXiv:2311.04918v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.04918</link>
<description rdf:parseType="Literal">&lt;p&gt;Named entity recognition (NER), a task that identifies and categorizes named
entities such as persons or organizations from text, is traditionally framed as
a multi-class classification problem. However, this approach often overlooks
the issues of imbalanced label distributions, particularly in low-resource
settings, which is common in certain NER contexts, like biomedical NER
(bioNER). To address these issues, we propose an innovative reformulation of
the multi-class problem as a one-vs-all (OVA) learning problem and introduce a
loss function based on the area under the receiver operating characteristic
curve (AUC). To enhance the efficiency of our OVA-based approach, we propose
two training strategies: one groups labels with similar linguistic
characteristics, and another employs meta-learning. The superiority of our
approach is confirmed by its performance, which surpasses traditional NER
learning in varying NER settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Ngoc Dang Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1&quot;&gt;Wei Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1&quot;&gt;Lan Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1&quot;&gt;Wray Buntine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beare_R/0/1/0/all/0/1&quot;&gt;Richard Beare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Changyou Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04927">
<title>Contextualizing the Limits of Model &amp; Evaluation Dataset Curation on Semantic Similarity Classification Tasks. (arXiv:2311.04927v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.04927</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper demonstrates how the limitations of pre-trained models and open
evaluation datasets factor into assessing the performance of binary semantic
similarity classification tasks. As (1) end-user-facing documentation around
the curation of these datasets and pre-trained model training regimes is often
not easily accessible and (2) given the lower friction and higher demand to
quickly deploy such systems in real-world contexts, our study reinforces prior
work showing performance disparities across datasets, embedding techniques and
distance metrics, while highlighting the importance of understanding how data
is collected, curated and analyzed in semantic similarity classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Theron_D/0/1/0/all/0/1&quot;&gt;Daniel Theron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04929">
<title>An Interdisciplinary Outlook on Large Language Models for Scientific Research. (arXiv:2311.04929v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.04929</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we describe the capabilities and constraints of Large Language
Models (LLMs) within disparate academic disciplines, aiming to delineate their
strengths and limitations with precision. We examine how LLMs augment
scientific inquiry, offering concrete examples such as accelerating literature
review by summarizing vast numbers of publications, enhancing code development
through automated syntax correction, and refining the scientific writing
process. Simultaneously, we articulate the challenges LLMs face, including
their reliance on extensive and sometimes biased datasets, and the potential
ethical dilemmas stemming from their use. Our critical discussion extends to
the varying impacts of LLMs across fields, from the natural sciences, where
they help model complex biological sequences, to the social sciences, where
they can parse large-scale qualitative data. We conclude by offering a nuanced
perspective on how LLMs can be both a boon and a boundary to scientific
progress.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boyko_J/0/1/0/all/0/1&quot;&gt;James Boyko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1&quot;&gt;Joseph Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fox_N/0/1/0/all/0/1&quot;&gt;Nathan Fox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veiga_M/0/1/0/all/0/1&quot;&gt;Maria Han Veiga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jennifer I-Hsiu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Modenesi_B/0/1/0/all/0/1&quot;&gt;Bernardo Modenesi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rauch_A/0/1/0/all/0/1&quot;&gt;Andreas H. Rauch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reid_K/0/1/0/all/0/1&quot;&gt;Kenneth N. Reid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tribedi_S/0/1/0/all/0/1&quot;&gt;Soumi Tribedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Visheratina_A/0/1/0/all/0/1&quot;&gt;Anastasia Visheratina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xin Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04937">
<title>Multimodal Clinical Benchmark for Emergency Care (MC-BEC): A Comprehensive Benchmark for Evaluating Foundation Models in Emergency Medicine. (arXiv:2311.04937v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.04937</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the Multimodal Clinical Benchmark for Emergency Care (MC-BEC), a
comprehensive benchmark for evaluating foundation models in Emergency Medicine
using a dataset of 100K+ continuously monitored Emergency Department visits
from 2020-2022. MC-BEC focuses on clinically relevant prediction tasks at
timescales from minutes to days, including predicting patient decompensation,
disposition, and emergency department (ED) revisit, and includes a standardized
evaluation framework with train-test splits and evaluation metrics. The
multimodal dataset includes a wide range of detailed clinical data, including
triage information, prior diagnoses and medications, continuously measured
vital signs, electrocardiogram and photoplethysmograph waveforms, orders placed
and medications administered throughout the visit, free-text reports of imaging
studies, and information on ED diagnosis, disposition, and subsequent revisits.
We provide performance baselines for each prediction task to enable the
evaluation of multimodal, multitask models. We believe that MC-BEC will
encourage researchers to develop more effective, generalizable, and accessible
foundation models for multimodal clinical data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1&quot;&gt;Emma Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kansal_A/0/1/0/all/0/1&quot;&gt;Aman Kansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Julie Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1&quot;&gt;Boyang Tom Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reisler_J/0/1/0/all/0/1&quot;&gt;Julia Rachel Reisler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;David A Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1&quot;&gt;Pranav Rajpurkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04938">
<title>Improved DDIM Sampling with Moment Matching Gaussian Mixtures. (arXiv:2311.04938v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.04938</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose using a Gaussian Mixture Model (GMM) as reverse transition
operator (kernel) within the Denoising Diffusion Implicit Models (DDIM)
framework, which is one of the most widely used approaches for accelerated
sampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM).
Specifically we match the first and second order central moments of the DDPM
forward marginals by constraining the parameters of the GMM. We see that moment
matching is sufficient to obtain samples with equal or better quality than the
original DDIM with Gaussian kernels. We provide experimental results with
unconditional models trained on CelebAHQ and FFHQ and class-conditional models
trained on ImageNet datasets respectively. Our results suggest that using the
GMM kernel leads to significant improvements in the quality of the generated
samples when the number of sampling steps is small, as measured by FID and IS
metrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a
FID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73
respectively with a Gaussian kernel.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabbur_P/0/1/0/all/0/1&quot;&gt;Prasad Gabbur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04943">
<title>MathNAS: If Blocks Have a Role in Mathematical Architecture Design. (arXiv:2311.04943v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.04943</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Architecture Search (NAS) has emerged as a favoured method for
unearthing effective neural architectures. Recent development of large models
has intensified the demand for faster search speeds and more accurate search
results. However, designing large models by NAS is challenging due to the
dramatical increase of search space and the associated huge performance
evaluation cost. Consider a typical modular search space widely used in NAS, in
which a neural architecture consists of $m$ block nodes and a block node has
$n$ alternative blocks. Facing the space containing $n^m$ candidate networks,
existing NAS methods attempt to find the best one by searching and evaluating
candidate networks directly.Different from the general strategy that takes
architecture search as a whole problem, we propose a novel divide-and-conquer
strategy by making use of the modular nature of the search space.Here, we
introduce MathNAS, a general NAS framework based on mathematical programming.In
MathNAS, the performances of the $m*n$ possible building blocks in the search
space are calculated first, and then the performance of a network is directly
predicted based on the performances of its building blocks. Although estimating
block performances involves network training, just as what happens for network
performance evaluation in existing NAS methods, predicting network performance
is completely training-free and thus extremely fast. In contrast to the $n^m$
candidate networks to evaluate in existing NAS methods, which require training
and a formidable computational burden, there are only $m*n$ possible blocks to
handle in MathNAS. Therefore, our approach effectively reduces the complexity
of network performance evaluation.Our code is available at
https://github.com/wangqinsi1/MathNAS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qinsi_W/0/1/0/all/0/1&quot;&gt;Wang Qinsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jinhan_K/0/1/0/all/0/1&quot;&gt;Ke Jinhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhi_L/0/1/0/all/0/1&quot;&gt;Liang Zhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sihai_Z/0/1/0/all/0/1&quot;&gt;Zhang Sihai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04944">
<title>Edge-assisted U-Shaped Split Federated Learning with Privacy-preserving for Internet of Things. (arXiv:2311.04944v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.04944</link>
<description rdf:parseType="Literal">&lt;p&gt;In the realm of the Internet of Things (IoT), deploying deep learning models
to process data generated or collected by IoT devices is a critical challenge.
However, direct data transmission can cause network congestion and inefficient
execution, given that IoT devices typically lack computation and communication
capabilities. Centralized data processing in data centers is also no longer
feasible due to concerns over data privacy and security. To address these
challenges, we present an innovative Edge-assisted U-Shaped Split Federated
Learning (EUSFL) framework, which harnesses the high-performance capabilities
of edge servers to assist IoT devices in model training and optimization
process. In this framework, we leverage Federated Learning (FL) to enable data
holders to collaboratively train models without sharing their data, thereby
enhancing data privacy protection by transmitting only model parameters.
Additionally, inspired by Split Learning (SL), we split the neural network into
three parts using U-shaped splitting for local training on IoT devices. By
exploiting the greater computation capability of edge servers, our framework
effectively reduces overall training time and allows IoT devices with varying
capabilities to perform training tasks efficiently. Furthermore, we proposed a
novel noise mechanism called LabelDP to ensure that data features and labels
can securely resist reconstruction attacks, eliminating the risk of privacy
leakage. Our theoretical analysis and experimental results demonstrate that
EUSFL can be integrated with various aggregation algorithms, maintaining good
performance across different computing capabilities of IoT devices, and
significantly reducing training time and local computation overhead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Hengliang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zihang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Detian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yang Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shiqiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1&quot;&gt;Siqing You&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04945">
<title>Auto deep learning for bioacoustic signals. (arXiv:2311.04945v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.04945</link>
<description rdf:parseType="Literal">&lt;p&gt;This study investigates the potential of automated deep learning to enhance
the accuracy and efficiency of multi-class classification of bird
vocalizations, compared against traditional manually-designed deep learning
models. Using the Western Mediterranean Wetland Birds dataset, we investigated
the use of AutoKeras, an automated machine learning framework, to automate
neural architecture search and hyperparameter tuning. Comparative analysis
validates our hypothesis that the AutoKeras-derived model consistently
outperforms traditional models like MobileNet, ResNet50 and VGG16. Our approach
and findings underscore the transformative potential of automated deep learning
for advancing bioacoustics research and models. In fact, the automated
techniques eliminate the need for manual feature engineering and model design
while improving performance. This study illuminates best practices in sampling,
evaluation and reporting to enhance reproducibility in this nascent field. All
the code used is available at https:
//github.com/giuliotosato/AutoKeras-bioacustic
&lt;/p&gt;
&lt;p&gt;Keywords: AutoKeras; automated deep learning; audio classification; Wetlands
Bird dataset; comparative analysis; bioacoustics; validation dataset;
multi-class classification; spectrograms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tosato_G/0/1/0/all/0/1&quot;&gt;Giulio Tosato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shehata_A/0/1/0/all/0/1&quot;&gt;Abdelrahman Shehata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janssen_J/0/1/0/all/0/1&quot;&gt;Joshua Janssen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamp_K/0/1/0/all/0/1&quot;&gt;Kees Kamp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jati_P/0/1/0/all/0/1&quot;&gt;Pramatya Jati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stowell_D/0/1/0/all/0/1&quot;&gt;Dan Stowell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04948">
<title>Explained anomaly detection in text reviews: Can subjective scenarios be correctly evaluated?. (arXiv:2311.04948v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.04948</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a pipeline to detect and explain anomalous reviews in
online platforms. The pipeline is made up of three modules and allows the
detection of reviews that do not generate value for users due to either
worthless or malicious composition. The classifications are accompanied by a
normality score and an explanation that justifies the decision made. The
pipeline&apos;s ability to solve the anomaly detection task was evaluated using
different datasets created from a large Amazon database. Additionally, a study
comparing three explainability techniques involving 241 participants was
conducted to assess the explainability module. The study aimed to measure the
impact of explanations on the respondents&apos; ability to reproduce the
classification model and their perceived usefulness. This work can be useful to
automate tasks in review online platforms, such as those for electronic
commerce, and offers inspiration for addressing similar problems in the field
of anomaly detection in textual data. We also consider it interesting to have
carried out a human evaluation of the capacity of different explainability
techniques in a real and infrequent scenario such as the detection of anomalous
reviews, as well as to reflect on whether it is possible to explain tasks as
humanly subjective as this one.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Novoa_Paradela_D/0/1/0/all/0/1&quot;&gt;David Novoa-Paradela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fontenla_Romero_O/0/1/0/all/0/1&quot;&gt;Oscar Fontenla-Romero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guijarro_Berdinas_B/0/1/0/all/0/1&quot;&gt;Bertha Guijarro-Berdi&amp;#xf1;as&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04950">
<title>Lightweight Diffusion Models with Distillation-Based Block Neural Architecture Search. (arXiv:2311.04950v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.04950</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models have recently shown remarkable generation ability, achieving
state-of-the-art performance in many tasks. However, the high computational
cost is still a troubling problem for diffusion models. To tackle this problem,
we propose to automatically remove the structural redundancy in diffusion
models with our proposed Diffusion Distillation-based Block-wise Neural
Architecture Search (DiffNAS). Specifically, given a larger pretrained teacher,
we leverage DiffNAS to search for the smallest architecture which achieves
on-par or even better performance than the teacher. Considering current
diffusion models are based on UNet which naturally has a block-wise structure,
we perform neural architecture search independently in each block, which
largely reduces the search space. Different from previous block-wise NAS
methods, DiffNAS contains a block-wise local search strategy and a retraining
strategy with a joint dynamic loss. Concretely, during the search process, we
block-wisely select the best subnet to avoid the unfairness brought by the
global search strategy used in previous works. When retraining the searched
architecture, we adopt a dynamic joint loss to maintain the consistency between
supernet training and subnet retraining, which also provides informative
objectives for each block and shortens the paths of gradient propagation. We
demonstrate this joint loss can effectively improve model performance. We also
prove the necessity of the dynamic adjustment of this loss. The experiments
show that our method can achieve significant computational reduction,
especially on latent diffusion models with about 50% MACs and Parameter
reduction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Siao Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1&quot;&gt;Chaoyu Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yansong Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+zhu_W/0/1/0/all/0/1&quot;&gt;Wenwu zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04951">
<title>Leveraging Speculative Sampling and KV-Cache Optimizations Together for Generative AI using OpenVINO. (arXiv:2311.04951v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.04951</link>
<description rdf:parseType="Literal">&lt;p&gt;Inference optimizations are critical for improving user experience and
reducing infrastructure costs and power consumption. In this article, we
illustrate a form of dynamic execution known as speculative sampling to reduce
the overall latency of text generation and compare it with standard
autoregressive sampling. This can be used together with model-based
optimizations (e.g. quantization) to provide an optimized solution. Both
sampling methods make use of KV caching. A Jupyter notebook and some sample
executions are provided.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barad_H/0/1/0/all/0/1&quot;&gt;Haim Barad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aidova_E/0/1/0/all/0/1&quot;&gt;Ekaterina Aidova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorbachev_Y/0/1/0/all/0/1&quot;&gt;Yury Gorbachev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04965">
<title>Expressibility-induced Concentration of Quantum Neural Tangent Kernels. (arXiv:2311.04965v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2311.04965</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum tangent kernel methods provide an efficient approach to analyzing the
performance of quantum machine learning models in the infinite-width limit,
which is of crucial importance in designing appropriate circuit architectures
for certain learning tasks. Recently, they have been adapted to describe the
convergence rate of training errors in quantum neural networks in an analytical
manner. Here, we study the connections between the trainability and
expressibility of quantum tangent kernel models. In particular, for global loss
functions, we rigorously prove that high expressibility of both the global and
local quantum encodings can lead to exponential concentration of quantum
tangent kernel values to zero. Whereas for local loss functions, such issue of
exponential concentration persists owing to the high expressibility, but can be
partially mitigated. We further carry out extensive numerical simulations to
support our analytical theories. Our discoveries unveil a pivotal
characteristic of quantum neural tangent kernels, offering valuable insights
for the design of wide quantum variational circuit models in practical
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yu_L/0/1/0/all/0/1&quot;&gt;Li-Wei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Weikang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ye_Q/0/1/0/all/0/1&quot;&gt;Qi Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhide Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Han_Z/0/1/0/all/0/1&quot;&gt;Zizhao Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Deng_D/0/1/0/all/0/1&quot;&gt;Dong-Ling Deng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04991">
<title>Effective Restoration of Source Knowledge in Continual Test Time Adaptation. (arXiv:2311.04991v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.04991</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional test-time adaptation (TTA) methods face significant challenges in
adapting to dynamic environments characterized by continuously changing
long-term target distributions. These challenges primarily stem from two
factors: catastrophic forgetting of previously learned valuable source
knowledge and gradual error accumulation caused by miscalibrated pseudo labels.
To address these issues, this paper introduces an unsupervised domain change
detection method that is capable of identifying domain shifts in dynamic
environments and subsequently resets the model parameters to the original
source pre-trained values. By restoring the knowledge from the source, it
effectively corrects the negative consequences arising from the gradual
deterioration of model parameters caused by ongoing shifts in the domain. Our
method involves progressive estimation of global batch-norm statistics specific
to each domain, while keeping track of changes in the statistics triggered by
domain shifts. Importantly, our method is agnostic to the specific adaptation
technique employed and thus, can be incorporated to existing TTA methods to
enhance their performance in dynamic environments. We perform extensive
experiments on benchmark datasets to demonstrate the superior performance of
our method compared to state-of-the-art adaptation methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niloy_F/0/1/0/all/0/1&quot;&gt;Fahim Faisal Niloy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1&quot;&gt;Sk Miraj Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raychaudhuri_D/0/1/0/all/0/1&quot;&gt;Dripta S. Raychaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_Chowdhury_A/0/1/0/all/0/1&quot;&gt;Amit K. Roy-Chowdhury&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04996">
<title>GPU-Accelerated WFST Beam Search Decoder for CTC-based Speech Recognition. (arXiv:2311.04996v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2311.04996</link>
<description rdf:parseType="Literal">&lt;p&gt;While Connectionist Temporal Classification (CTC) models deliver
state-of-the-art accuracy in automated speech recognition (ASR) pipelines,
their performance has been limited by CPU-based beam search decoding. We
introduce a GPU-accelerated Weighted Finite State Transducer (WFST) beam search
decoder compatible with current CTC models. It increases pipeline throughput
and decreases latency, supports streaming inference, and also supports advanced
features like utterance-specific word boosting via on-the-fly composition. We
provide pre-built DLPack-based python bindings for ease of use with
Python-based machine learning frameworks at
https://github.com/nvidia-riva/riva-asrlib-decoder. We evaluated our decoder
for offline and online scenarios, demonstrating that it is the fastest beam
search decoder for CTC models. In the offline scenario it achieves up to 7
times more throughput than the current state-of-the-art CPU decoder and in the
online streaming scenario, it achieves nearly 8 times lower latency, with same
or better word error rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Galvez_D/0/1/0/all/0/1&quot;&gt;Daniel Galvez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kaldewey_T/0/1/0/all/0/1&quot;&gt;Tim Kaldewey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05006">
<title>Familiarity-Based Open-Set Recognition Under Adversarial Attacks. (arXiv:2311.05006v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05006</link>
<description rdf:parseType="Literal">&lt;p&gt;Open-set recognition (OSR), the identification of novel categories, can be a
critical component when deploying classification models in real-world
applications. Recent work has shown that familiarity-based scoring rules such
as the Maximum Softmax Probability (MSP) or the Maximum Logit Score (MLS) are
strong baselines when the closed-set accuracy is high. However, one of the
potential weaknesses of familiarity-based OSR are adversarial attacks. Here, we
present gradient-based adversarial attacks on familiarity scores for both types
of attacks, False Familiarity and False Novelty attacks, and evaluate their
effectiveness in informed and uninformed settings on TinyImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Enevoldsen_P/0/1/0/all/0/1&quot;&gt;Philip Enevoldsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gundersen_C/0/1/0/all/0/1&quot;&gt;Christian Gundersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lang_N/0/1/0/all/0/1&quot;&gt;Nico Lang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1&quot;&gt;Serge Belongie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Igel_C/0/1/0/all/0/1&quot;&gt;Christian Igel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05017">
<title>Joint Sensing and Semantic Communications with Multi-Task Deep Learning. (arXiv:2311.05017v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2311.05017</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the integration of deep learning techniques for joint
sensing and communications, with an extension to semantic communications. The
integrated system comprises a transmitter and receiver operating over a
wireless channel, subject to noise and fading effects. The transmitter employs
a deep neural network, namely an encoder, for joint operations of source
coding, channel coding, and modulation, while the receiver utilizes another
deep neural network, namely a decoder, for joint operations of demodulation,
channel decoding, and source decoding to reconstruct the data samples. The
transmitted signal serves a dual purpose, supporting communication with the
receiver and enabling sensing. When a target is present, the reflected signal
is received, and another deep neural network decoder is utilized for sensing.
This decoder is responsible for detecting the target&apos;s presence and determining
its range. All these deep neural networks, including one encoder and two
decoders, undergo joint training through multi-task learning, considering data
and channel characteristics. This paper extends to incorporate semantic
communications by introducing an additional deep neural network, another
decoder at the receiver, operating as a task classifier. This decoder evaluates
the fidelity of label classification for received signals, enhancing the
integration of semantics within the communication process. The study presents
results based on using the CIFAR-10 as the input data and accounting for
channel effects like Additive White Gaussian Noise (AWGN) and Rayleigh fading.
The results underscore the effectiveness of multi-task deep learning in
achieving high-fidelity joint sensing and semantic communications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagduyu_Y/0/1/0/all/0/1&quot;&gt;Yalin E. Sagduyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erpek_T/0/1/0/all/0/1&quot;&gt;Tugba Erpek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yener_A/0/1/0/all/0/1&quot;&gt;Aylin Yener&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ulukus_S/0/1/0/all/0/1&quot;&gt;Sennur Ulukus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05019">
<title>DEMASQ: Unmasking the ChatGPT Wordsmith. (arXiv:2311.05019v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2311.05019</link>
<description rdf:parseType="Literal">&lt;p&gt;The potential misuse of ChatGPT and other Large Language Models (LLMs) has
raised concerns regarding the dissemination of false information, plagiarism,
academic dishonesty, and fraudulent activities. Consequently, distinguishing
between AI-generated and human-generated content has emerged as an intriguing
research topic. However, current text detection methods lack precision and are
often restricted to specific tasks or domains, making them inadequate for
identifying content generated by ChatGPT. In this paper, we propose an
effective ChatGPT detector named DEMASQ, which accurately identifies
ChatGPT-generated content. Our method addresses two critical factors: (i) the
distinct biases in text composition observed in human- and machine-generated
content and (ii) the alterations made by humans to evade previous detection
methods. DEMASQ is an energy-based detection model that incorporates novel
aspects, such as (i) optimization inspired by the Doppler effect to capture the
interdependence between input text embeddings and output labels, and (ii) the
use of explainable AI techniques to generate diverse perturbations. To evaluate
our detector, we create a benchmark dataset comprising a mixture of prompts
from both ChatGPT and humans, encompassing domains such as medical, open Q&amp;amp;A,
finance, wiki, and Reddit. Our evaluation demonstrates that DEMASQ achieves
high accuracy in identifying content generated by ChatGPT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumari_K/0/1/0/all/0/1&quot;&gt;Kavita Kumari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pegoraro_A/0/1/0/all/0/1&quot;&gt;Alessandro Pegoraro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fereidooni_H/0/1/0/all/0/1&quot;&gt;Hossein Fereidooni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadeghi_A/0/1/0/all/0/1&quot;&gt;Ahmad-Reza Sadeghi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05032">
<title>Transfer learning from a sparsely annotated dataset of 3D medical images. (arXiv:2311.05032v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.05032</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning leverages pre-trained model features from a large dataset
to save time and resources when training new models for various tasks,
potentially enhancing performance. Due to the lack of large datasets in the
medical imaging domain, transfer learning from one medical imaging model to
other medical imaging models has not been widely explored. This study explores
the use of transfer learning to improve the performance of deep convolutional
neural networks for organ segmentation in medical imaging. A base segmentation
model (3D U-Net) was trained on a large and sparsely annotated dataset; its
weights were used for transfer learning on four new down-stream segmentation
tasks for which a fully annotated dataset was available. We analyzed the
training set size&apos;s influence to simulate scarce data. The results showed that
transfer learning from the base model was beneficial when small datasets were
available, providing significant performance improvements; where fine-tuning
the base model is more beneficial than updating all the network weights with
vanilla transfer learning. Transfer learning with fine-tuning increased the
performance by up to 0.129 (+28\%) Dice score than experiments trained from
scratch, and on average 23 experiments increased the performance by 0.029 Dice
score in the new segmentation tasks. The study also showed that cross-modality
transfer learning using CT scans was beneficial. The findings of this study
demonstrate the potential of transfer learning to improve the efficiency of
annotation and increase the accessibility of accurate organ segmentation in
medical imaging, ultimately leading to improved patient care. We made the
network definition and weights publicly available to benefit other users and
researchers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Humpire_Mamani_G/0/1/0/all/0/1&quot;&gt;Gabriel Efrain Humpire-Mamani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jacobs_C/0/1/0/all/0/1&quot;&gt;Colin Jacobs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Prokop_M/0/1/0/all/0/1&quot;&gt;Mathias Prokop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ginneken_B/0/1/0/all/0/1&quot;&gt;Bram van Ginneken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lessmann_N/0/1/0/all/0/1&quot;&gt;Nikolas Lessmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05041">
<title>Active Transfer Learning for Efficient Video-Specific Human Pose Estimation. (arXiv:2311.05041v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05041</link>
<description rdf:parseType="Literal">&lt;p&gt;Human Pose (HP) estimation is actively researched because of its wide range
of applications. However, even estimators pre-trained on large datasets may not
perform satisfactorily due to a domain gap between the training and test data.
To address this issue, we present our approach combining Active Learning (AL)
and Transfer Learning (TL) to adapt HP estimators to individual video domains
efficiently. For efficient learning, our approach quantifies (i) the estimation
uncertainty based on the temporal changes in the estimated heatmaps and (ii)
the unnaturalness in the estimated full-body HPs. These quantified criteria are
then effectively combined with the state-of-the-art representativeness
criterion to select uncertain and diverse samples for efficient HP estimator
learning. Furthermore, we reconsider the existing Active Transfer Learning
(ATL) method to introduce novel ideas related to the retraining methods and
Stopping Criteria (SC). Experimental results demonstrate that our method
enhances learning efficiency and outperforms comparative methods. Our code is
publicly available at: https://github.com/ImIntheMiddle/VATL4Pose-WACV2024
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taketsugu_H/0/1/0/all/0/1&quot;&gt;Hiromu Taketsugu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ukita_N/0/1/0/all/0/1&quot;&gt;Norimichi Ukita&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05042">
<title>Automated Annotation of Scientific Texts for ML-based Keyphrase Extraction and Validation. (arXiv:2311.05042v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2311.05042</link>
<description rdf:parseType="Literal">&lt;p&gt;Advanced omics technologies and facilities generate a wealth of valuable data
daily; however, the data often lacks the essential metadata required for
researchers to find and search them effectively. The lack of metadata poses a
significant challenge in the utilization of these datasets. Machine
learning-based metadata extraction techniques have emerged as a potentially
viable approach to automatically annotating scientific datasets with the
metadata necessary for enabling effective search. Text labeling, usually
performed manually, plays a crucial role in validating machine-extracted
metadata. However, manual labeling is time-consuming; thus, there is an need to
develop automated text labeling techniques in order to accelerate the process
of scientific innovation. This need is particularly urgent in fields such as
environmental genomics and microbiome science, which have historically received
less attention in terms of metadata curation and creation of gold-standard text
mining datasets.
&lt;/p&gt;
&lt;p&gt;In this paper, we present two novel automated text labeling approaches for
the validation of ML-generated metadata for unlabeled texts, with specific
applications in environmental genomics. Our techniques show the potential of
two new ways to leverage existing information about the unlabeled texts and the
scientific domain. The first technique exploits relationships between different
types of data sources related to the same research study, such as publications
and proposals. The second technique takes advantage of domain-specific
controlled vocabularies or ontologies. In this paper, we detail applying these
approaches for ML-generated metadata validation. Our results show that the
proposed label assignment approaches can generate both generic and
highly-specific text labels for the unlabeled texts, with up to 44% of the
labels matching with those suggested by a ML keyword extraction algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amusat_O/0/1/0/all/0/1&quot;&gt;Oluwamayowa O. Amusat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hegde_H/0/1/0/all/0/1&quot;&gt;Harshad Hegde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mungall_C/0/1/0/all/0/1&quot;&gt;Christopher J. Mungall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giannakou_A/0/1/0/all/0/1&quot;&gt;Anna Giannakou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Byers_N/0/1/0/all/0/1&quot;&gt;Neil P. Byers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunter_D/0/1/0/all/0/1&quot;&gt;Dan Gunter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fagnan_K/0/1/0/all/0/1&quot;&gt;Kjiersten Fagnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_L/0/1/0/all/0/1&quot;&gt;Lavanya Ramakrishnan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05046">
<title>On the Consistency of Maximum Likelihood Estimation of Probabilistic Principal Component Analysis. (arXiv:2311.05046v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.05046</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic principal component analysis (PPCA) is currently one of the
most used statistical tools to reduce the ambient dimension of the data. From
multidimensional scaling to the imputation of missing data, PPCA has a broad
spectrum of applications ranging from science and engineering to quantitative
finance.
&lt;/p&gt;
&lt;p&gt;Despite this wide applicability in various fields, hardly any theoretical
guarantees exist to justify the soundness of the maximal likelihood (ML)
solution for this model. In fact, it is well known that the maximum likelihood
estimation (MLE) can only recover the true model parameters up to a rotation.
The main obstruction is posed by the inherent identifiability nature of the
PPCA model resulting from the rotational symmetry of the parameterization. To
resolve this ambiguity, we propose a novel approach using quotient topological
spaces and in particular, we show that the maximum likelihood solution is
consistent in an appropriate quotient Euclidean space. Furthermore, our
consistency results encompass a more general class of estimators beyond the
MLE. Strong consistency of the ML estimate and consequently strong covariance
estimation of the PPCA model have also been established under a compactness
assumption.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Datta_A/0/1/0/all/0/1&quot;&gt;Arghya Datta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chakrabarty_S/0/1/0/all/0/1&quot;&gt;Sayak Chakrabarty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05050">
<title>Quantum Generative Modeling of Sequential Data with Trainable Token Embedding. (arXiv:2311.05050v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05050</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative models are a class of machine learning models that aim to learn
the underlying probability distribution of data. Unlike discriminative models,
generative models focus on capturing the data&apos;s inherent structure, allowing
them to generate new samples that resemble the original data. To fully exploit
the potential of modeling probability distributions using quantum physics, a
quantum-inspired generative model known as the Born machines have shown great
advancements in learning classical and quantum data over matrix product
state(MPS) framework. The Born machines support tractable log-likelihood,
autoregressive and mask sampling, and have shown outstanding performance in
various unsupervised learning tasks. However, much of the current research has
been centered on improving the expressive power of MPS, predominantly embedding
each token directly by a corresponding tensor index. In this study, we
generalize the embedding method into trainable quantum measurement operators
that can be simultaneously honed with MPS. Our study indicated that combined
with trainable embedding, Born machines can exhibit better performance and
learn deeper correlations from the dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1&quot;&gt;Wanda Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miao_L/0/1/0/all/0/1&quot;&gt;Li Miao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1&quot;&gt;Yi-Zhuang You&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05054">
<title>Geometry-Calibrated DRO: Combating Over-Pessimism with Free Energy Implications. (arXiv:2311.05054v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05054</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning algorithms minimizing average risk are susceptible to
distributional shifts. Distributionally Robust Optimization (DRO) addresses
this issue by optimizing the worst-case risk within an uncertainty set.
However, DRO suffers from over-pessimism, leading to low-confidence
predictions, poor parameter estimations as well as poor generalization. In this
work, we conduct a theoretical analysis of a probable root cause of
over-pessimism: excessive focus on noisy samples. To alleviate the impact of
noise, we incorporate data geometry into calibration terms in DRO, resulting in
our novel Geometry-Calibrated DRO (GCDRO) for regression. We establish the
connection between our risk objective and the Helmholtz free energy in
statistical physics, and this free-energy-based risk can extend to standard DRO
methods. Leveraging gradient flow in Wasserstein space, we develop an
approximate minimax optimization algorithm with a bounded error ratio and
elucidate how our approach mitigates noisy sample effects. Comprehensive
experiments confirm GCDRO&apos;s superiority over conventional DRO methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiashuo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiayun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tianyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_H/0/1/0/all/0/1&quot;&gt;Hao Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1&quot;&gt;Peng Cui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05061">
<title>Efficient Compression of Overparameterized Deep Models through Low-Dimensional Learning Dynamics. (arXiv:2311.05061v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05061</link>
<description rdf:parseType="Literal">&lt;p&gt;Overparameterized models have proven to be powerful tools for solving various
machine learning tasks. However, overparameterization often leads to a
substantial increase in computational and memory costs, which in turn requires
extensive resources to train. In this work, we aim to reduce this complexity by
studying the learning dynamics of overparameterized deep networks. By
extensively studying its learning dynamics, we unveil that the weight matrices
of various architectures exhibit a low-dimensional structure. This finding
implies that we can compress the networks by reducing the training to a small
subspace. We take a step in developing a principled approach for compressing
deep networks by studying deep linear models. We demonstrate that the principal
components of deep linear models are fitted incrementally but within a small
subspace, and use these insights to compress deep linear networks by decreasing
the width of its intermediate layers. Remarkably, we observe that with a
particular choice of initialization, the compressed network converges faster
than the original network, consistently yielding smaller recovery errors
throughout all iterations of gradient descent. We substantiate this observation
by developing a theory focused on the deep matrix factorization problem, and by
conducting empirical evaluations on deep matrix sensing. Finally, we
demonstrate how our compressed model can enhance the utility of deep nonlinear
models. Overall, we observe that our compression technique accelerates the
training process by more than 2x, without compromising model quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1&quot;&gt;Soo Min Kwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zekai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dogyoon Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balzano_L/0/1/0/all/0/1&quot;&gt;Laura Balzano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_Q/0/1/0/all/0/1&quot;&gt;Qing Qu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05067">
<title>Accelerating Exploration with Unlabeled Prior Data. (arXiv:2311.05067v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05067</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to solve tasks from a sparse reward signal is a major challenge for
standard reinforcement learning (RL) algorithms. However, in the real world,
agents rarely need to solve sparse reward tasks entirely from scratch. More
often, we might possess prior experience to draw on that provides considerable
guidance about which actions and outcomes are possible in the world, which we
can use to explore more effectively for new tasks. In this work, we study how
prior data without reward labels may be used to guide and accelerate
exploration for an agent solving a new sparse reward task. We propose a simple
approach that learns a reward model from online experience, labels the
unlabeled prior data with optimistic rewards, and then uses it concurrently
alongside the online data for downstream policy and critic optimization. This
general formula leads to rapid exploration in several challenging sparse-reward
domains where tabula rasa exploration is insufficient, including the AntMaze
domain, Adroit hand manipulation domain, and a visual simulated robotic
manipulation domain. Our results highlight the ease of incorporating unlabeled
prior data into existing online RL algorithms, and the (perhaps surprising)
effectiveness of doing so.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qiyang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jason Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1&quot;&gt;Dibya Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Amy Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05071">
<title>On the Behavior of Audio-Visual Fusion Architectures in Identity Verification Tasks. (arXiv:2311.05071v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05071</link>
<description rdf:parseType="Literal">&lt;p&gt;We train an identity verification architecture and evaluate modifications to
the part of the model that combines audio and visual representations, including
in scenarios where one input is missing in either of two examples to be
compared. We report results on the Voxceleb1-E test set that suggest averaging
the output embeddings improves error rate in the full-modality setting and when
a single modality is missing, and makes more complete use of the embedding
space than systems which use shared layers and discuss possible reasons for
this behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Claborne_D/0/1/0/all/0/1&quot;&gt;Daniel Claborne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slyman_E/0/1/0/all/0/1&quot;&gt;Eric Slyman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pazdernik_K/0/1/0/all/0/1&quot;&gt;Karl Pazdernik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05075">
<title>Mental Health Diagnosis in the Digital Age: Harnessing Sentiment Analysis on Social Media Platforms upon Ultra-Sparse Feature Content. (arXiv:2311.05075v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05075</link>
<description rdf:parseType="Literal">&lt;p&gt;Amid growing global mental health concerns, particularly among vulnerable
groups, natural language processing offers a tremendous potential for early
detection and intervention of people&apos;s mental disorders via analyzing their
postings and discussions on social media platforms. However, ultra-sparse
training data, often due to vast vocabularies and low-frequency words, hinders
the analysis accuracy. Multi-labeling and Co-occurrences of symptoms may also
blur the boundaries in distinguishing similar/co-related disorders. To address
these issues, we propose a novel semantic feature preprocessing technique with
a three-folded structure: 1) mitigating the feature sparsity with a weak
classifier, 2) adaptive feature dimension with modulus loops, and 3)
deep-mining and extending features among the contexts. With enhanced semantic
features, we train a machine learning model to predict and classify mental
disorders. We utilize the Reddit Mental Health Dataset 2022 to examine
conditions such as Anxiety, Borderline Personality Disorder (BPD), and
Bipolar-Disorder (BD) and present solutions to the data sparsity challenge,
highlighted by 99.81% non-zero elements. After applying our preprocessing
technique, the feature sparsity decreases to 85.4%. Overall, our methods, when
compared to seven benchmark models, demonstrate significant performance
improvements: 8.0% in accuracy, 0.069 in precision, 0.093 in recall, 0.102 in
F1 score, and 0.059 in AUC. This research provides foundational insights for
mental health prediction and monitoring, providing innovative solutions to
navigate challenges associated with ultra-sparse data feature and intricate
multi-label classification in the domain of mental health analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1&quot;&gt;Haijian Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Ming Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhai_S/0/1/0/all/0/1&quot;&gt;Shengjie Zhai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05079">
<title>Social Media Bot Detection using Dropout-GAN. (arXiv:2311.05079v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05079</link>
<description rdf:parseType="Literal">&lt;p&gt;Bot activity on social media platforms is a pervasive problem, undermining
the credibility of online discourse and potentially leading to cybercrime. We
propose an approach to bot detection using Generative Adversarial Networks
(GAN). We discuss how we overcome the issue of mode collapse by utilizing
multiple discriminators to train against one generator, while decoupling the
discriminator to perform social media bot detection and utilizing the generator
for data augmentation. In terms of classification accuracy, our approach
outperforms the state-of-the-art techniques in this field. We also show how the
generator in the GAN can be used to evade such a classification technique.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1&quot;&gt;Anant Shukla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jurecek_M/0/1/0/all/0/1&quot;&gt;Martin Jurecek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1&quot;&gt;Mark Stamp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05081">
<title>Generalized test utilities for long-tail performance in extreme multi-label classification. (arXiv:2311.05081v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05081</link>
<description rdf:parseType="Literal">&lt;p&gt;Extreme multi-label classification (XMLC) is the task of selecting a small
subset of relevant labels from a very large set of possible labels. As such, it
is characterized by long-tail labels, i.e., most labels have very few positive
instances. With standard performance measures such as precision@k, a classifier
can ignore tail labels and still report good performance. However, it is often
argued that correct predictions in the tail are more interesting or rewarding,
but the community has not yet settled on a metric capturing this intuitive
concept. The existing propensity-scored metrics fall short on this goal by
confounding the problems of long-tail and missing labels. In this paper, we
analyze generalized metrics budgeted &quot;at k&quot; as an alternative solution. To
tackle the challenging problem of optimizing these metrics, we formulate it in
the expected test utility (ETU) framework, which aims at optimizing the
expected performance on a fixed test set. We derive optimal prediction rules
and construct computationally efficient approximations with provable regret
guarantees and robustness against model misspecification. Our algorithm, based
on block coordinate ascent, scales effortlessly to XMLC problems and obtains
promising results in terms of long-tail performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schultheis_E/0/1/0/all/0/1&quot;&gt;Erik Schultheis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wydmuch_M/0/1/0/all/0/1&quot;&gt;Marek Wydmuch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kotlowski_W/0/1/0/all/0/1&quot;&gt;Wojciech Kot&amp;#x142;owski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babbar_R/0/1/0/all/0/1&quot;&gt;Rohit Babbar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dembczynski_K/0/1/0/all/0/1&quot;&gt;Krzysztof Dembczy&amp;#x144;ski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05084">
<title>Signal Temporal Logic-Guided Apprenticeship Learning. (arXiv:2311.05084v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.05084</link>
<description rdf:parseType="Literal">&lt;p&gt;Apprenticeship learning crucially depends on effectively learning rewards,
and hence control policies from user demonstrations. Of particular difficulty
is the setting where the desired task consists of a number of sub-goals with
temporal dependencies. The quality of inferred rewards and hence policies are
typically limited by the quality of demonstrations, and poor inference of these
can lead to undesirable outcomes. In this letter, we show how temporal logic
specifications that describe high level task objectives, are encoded in a graph
to define a temporal-based metric that reasons about behaviors of demonstrators
and the learner agent to improve the quality of inferred rewards and policies.
Through experiments on a diverse set of robot manipulator simulations, we show
how our framework overcomes the drawbacks of prior literature by drastically
improving the number of demonstrations required to learn a control policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puranic_A/0/1/0/all/0/1&quot;&gt;Aniruddh G. Puranic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshmukh_J/0/1/0/all/0/1&quot;&gt;Jyotirmoy V. Deshmukh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolaidis_S/0/1/0/all/0/1&quot;&gt;Stefanos Nikolaidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05088">
<title>Meta-learning of semi-supervised learning from tasks with heterogeneous attribute spaces. (arXiv:2311.05088v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05088</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a meta-learning method for semi-supervised learning that learns
from multiple tasks with heterogeneous attribute spaces. The existing
semi-supervised meta-learning methods assume that all tasks share the same
attribute space, which prevents us from learning with a wide variety of tasks.
With the proposed method, the expected test performance on tasks with a small
amount of labeled data is improved with unlabeled data as well as data in
various tasks, where the attribute spaces are different among tasks. The
proposed method embeds labeled and unlabeled data simultaneously in a
task-specific space using a neural network, and the unlabeled data&apos;s labels are
estimated by adapting classification or regression models in the embedding
space. For the neural network, we develop variable-feature self-attention
layers, which enable us to find embeddings of data with different attribute
spaces with a single neural network by considering interactions among examples,
attributes, and labels. Our experiments on classification and regression
datasets with heterogeneous attribute spaces demonstrate that our proposed
method outperforms the existing meta-learning and semi-supervised learning
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1&quot;&gt;Tomoharu Iwata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumagai_A/0/1/0/all/0/1&quot;&gt;Atsutoshi Kumagai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05092">
<title>GeoFormer: Predicting Human Mobility using Generative Pre-trained Transformer (GPT). (arXiv:2311.05092v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05092</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting human mobility holds significant practical value, with
applications ranging from enhancing disaster risk planning to simulating
epidemic spread. In this paper, we present the GeoFormer, a decoder-only
transformer model adapted from the GPT architecture to forecast human mobility.
Our proposed model is rigorously tested in the context of the HuMob Challenge
2023 -- a competition designed to evaluate the performance of prediction models
on standardized datasets to predict human mobility. The challenge leverages two
datasets encompassing urban-scale data of 25,000 and 100,000 individuals over a
longitudinal period of 75 days. GeoFormer stands out as a top performer in the
competition, securing a place in the top-3 ranking. Its success is underscored
by performing well on both performance metrics chosen for the competition --
the GEO-BLEU and the Dynamic Time Warping (DTW) measures. The performance of
the GeoFormer on the HuMob Challenge 2023 underscores its potential to make
substantial contributions to the field of human mobility prediction, with
far-reaching implications for disaster preparedness, epidemic control, and
beyond.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solatorio_A/0/1/0/all/0/1&quot;&gt;Aivin V. Solatorio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05108">
<title>Personalized Online Federated Learning with Multiple Kernels. (arXiv:2311.05108v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05108</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-kernel learning (MKL) exhibits well-documented performance in online
non-linear function approximation. Federated learning enables a group of
learners (called clients) to train an MKL model on the data distributed among
clients to perform online non-linear function approximation. There are some
challenges in online federated MKL that need to be addressed: i) Communication
efficiency especially when a large number of kernels are considered ii)
Heterogeneous data distribution among clients. The present paper develops an
algorithmic framework to enable clients to communicate with the server to send
their updates with affordable communication cost while clients employ a large
dictionary of kernels. Utilizing random feature (RF) approximation, the present
paper proposes scalable online federated MKL algorithm. We prove that using the
proposed online federated MKL algorithm, each client enjoys sub-linear regret
with respect to the RF approximation of its best kernel in hindsight, which
indicates that the proposed algorithm can effectively deal with heterogeneity
of the data distributed among clients. Experimental results on real datasets
showcase the advantages of the proposed algorithm compared with other online
federated kernel learning ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghari_P/0/1/0/all/0/1&quot;&gt;Pouya M. Ghari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yanning Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05109">
<title>Reducing the Side-Effects of Oscillations in Training of Quantized YOLO Networks. (arXiv:2311.05109v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05109</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantized networks use less computational and memory resources and are
suitable for deployment on edge devices. While quantization-aware training QAT
is the well-studied approach to quantize the networks at low precision, most
research focuses on over-parameterized networks for classification with limited
studies on popular and edge device friendly single-shot object detection and
semantic segmentation methods like YOLO. Moreover, majority of QAT methods rely
on Straight-through Estimator (STE) approximation which suffers from an
oscillation phenomenon resulting in sub-optimal network quantization. In this
paper, we show that it is difficult to achieve extremely low precision (4-bit
and lower) for efficient YOLO models even with SOTA QAT methods due to
oscillation issue and existing methods to overcome this problem are not
effective on these models. To mitigate the effect of oscillation, we first
propose Exponentially Moving Average (EMA) based update to the QAT model.
Further, we propose a simple QAT correction method, namely QC, that takes only
a single epoch of training after standard QAT procedure to correct the error
induced by oscillating weights and activations resulting in a more accurate
quantized model. With extensive evaluation on COCO dataset using various YOLO5
and YOLO7 variants, we show that our correction method improves quantized YOLO
networks consistently on both object detection and segmentation tasks at
low-precision (4-bit and 3-bit).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1&quot;&gt;Kartik Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asthana_A/0/1/0/all/0/1&quot;&gt;Akshay Asthana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05116">
<title>Covering Number of Real Algebraic Varieties: Improved Bound and Applications. (arXiv:2311.05116v1 [math.AG])</title>
<link>http://arxiv.org/abs/2311.05116</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove an upper bound on the covering number of real algebraic varieties,
images of polynomial maps and semialgebraic sets. The bound remarkably improves
the best known bound by Yomdin-Comte, and its proof is much more
straightforward. As a consequence, our result gives a bound on volume of the
tubular neighborhood of a real variety, improving the results by Lotz and
Basu-Lerario. We apply our theory to three main application domains. Firstly,
we derive a near-optimal bound on the covering number of low rank CP tensors.
Secondly, we prove a bound on the sketching dimension for (general) polynomial
optimization problems. Lastly, we deduce generalization error bounds for deep
neural networks with rational or ReLU activations, improving or matching the
best known results in the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yifan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kileel_J/0/1/0/all/0/1&quot;&gt;Joe Kileel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05128">
<title>Exploring and Analyzing Wildland Fire Data Via Machine Learning Techniques. (arXiv:2311.05128v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05128</link>
<description rdf:parseType="Literal">&lt;p&gt;This research project investigated the correlation between a 10 Hz time
series of thermocouple temperatures and turbulent kinetic energy (TKE) computed
from wind speeds collected from a small experimental prescribed burn at the
Silas Little Experimental Forest in New Jersey, USA. The primary objective of
this project was to explore the potential for using thermocouple temperatures
as predictors for estimating the TKE produced by a wildland fire. Machine
learning models, including Deep Neural Networks, Random Forest Regressor,
Gradient Boosting, and Gaussian Process Regressor, are employed to assess the
potential for thermocouple temperature perturbations to predict TKE values.
Data visualization and correlation analyses reveal patterns and relationships
between thermocouple temperatures and TKE, providing insight into the
underlying dynamics. The project achieves high accuracy in predicting TKE by
employing various machine learning models despite a weak correlation between
the predictors and the target variable. The results demonstrate significant
success, particularly from regression models, in accurately estimating the TKE.
The research findings contribute to fire behavior and smoke modeling science,
emphasizing the importance of incorporating machine learning approaches and
identifying complex relationships between fine-scale fire behavior and
turbulence. Accurate TKE estimation using thermocouple temperatures allows for
the refinement of models that can inform decision-making in fire management
strategies, facilitate effective risk mitigation, and optimize fire management
efforts. This project highlights the valuable role of machine learning
techniques in analyzing wildland fire data, showcasing their potential to
advance fire research and management practices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dulal_D/0/1/0/all/0/1&quot;&gt;Dipak Dulal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charney_J/0/1/0/all/0/1&quot;&gt;Joseph J. Charney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallagher_M/0/1/0/all/0/1&quot;&gt;Michael Gallagher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navasca_C/0/1/0/all/0/1&quot;&gt;Carmeliza Navasca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skowronski_N/0/1/0/all/0/1&quot;&gt;Nicholas Skowronski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05135">
<title>Improving Computational Efficiency for Powered Descent Guidance via Transformer-based Tight Constraint Prediction. (arXiv:2311.05135v1 [math.OC])</title>
<link>http://arxiv.org/abs/2311.05135</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we present Transformer-based Powered Descent Guidance (T-PDG),
a scalable algorithm for reducing the computational complexity of the direct
optimization formulation of the spacecraft powered descent guidance problem.
T-PDG uses data from prior runs of trajectory optimization algorithms to train
a transformer neural network, which accurately predicts the relationship
between problem parameters and the globally optimal solution for the powered
descent guidance problem. The solution is encoded as the set of tight
constraints corresponding to the constrained minimum-cost trajectory and the
optimal final time of landing. By leveraging the attention mechanism of
transformer neural networks, large sequences of time series data can be
accurately predicted when given only the spacecraft state and landing site
parameters. When applied to the real problem of Mars powered descent guidance,
T-PDG reduces the time for computing the 3 degree of freedom fuel-optimal
trajectory, when compared to lossless convexification, from an order of 1-8
seconds to less than 500 milliseconds. A safe and optimal solution is
guaranteed by including a feasibility check in T-PDG before returning the final
trajectory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Briden_J/0/1/0/all/0/1&quot;&gt;Julia Briden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gurga_T/0/1/0/all/0/1&quot;&gt;Trey Gurga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Johnson_B/0/1/0/all/0/1&quot;&gt;Breanna Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cauligi_A/0/1/0/all/0/1&quot;&gt;Abhishek Cauligi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Linares_R/0/1/0/all/0/1&quot;&gt;Richard Linares&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05139">
<title>On neural and dimensional collapse in supervised and unsupervised contrastive learning with hard negative sampling. (arXiv:2311.05139v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05139</link>
<description rdf:parseType="Literal">&lt;p&gt;For a widely-studied data model and general loss and sample-hardening
functions we prove that the Supervised Contrastive Learning (SCL), Hard-SCL
(HSCL), and Unsupervised Contrastive Learning (UCL) risks are minimized by
representations that exhibit Neural Collapse (NC), i.e., the class means form
an Equianglular Tight Frame (ETF) and data from the same class are mapped to
the same representation. We also prove that for any representation mapping, the
HSCL and Hard-UCL (HUCL) risks are lower bounded by the corresponding SCL and
UCL risks. Although the optimality of ETF is known for SCL, albeit only for
InfoNCE loss, its optimality for HSCL and UCL under general loss and hardening
functions is novel. Moreover, our proofs are much simpler, compact, and
transparent. We empirically demonstrate, for the first time, that ADAM
optimization of HSCL and HUCL risks with random initialization and suitable
hardness levels can indeed converge to the NC geometry if we incorporate
unit-ball or unit-sphere feature normalization. Without incorporating hard
negatives or feature normalization, however, the representations learned via
ADAM suffer from dimensional collapse (DC) and fail to attain the NC geometry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Ruijie Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thuan Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aeron_S/0/1/0/all/0/1&quot;&gt;Shuchin Aeron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishwar_P/0/1/0/all/0/1&quot;&gt;Prakash Ishwar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05144">
<title>Counter-Empirical Attacking based on Adversarial Reinforcement Learning for Time-Relevant Scoring System. (arXiv:2311.05144v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05144</link>
<description rdf:parseType="Literal">&lt;p&gt;Scoring systems are commonly seen for platforms in the era of big data. From
credit scoring systems in financial services to membership scores in E-commerce
shopping platforms, platform managers use such systems to guide users towards
the encouraged activity pattern, and manage resources more effectively and more
efficiently thereby. To establish such scoring systems, several &quot;empirical
criteria&quot; are firstly determined, followed by dedicated top-down design for
each factor of the score, which usually requires enormous effort to adjust and
tune the scoring function in the new application scenario. What&apos;s worse, many
fresh projects usually have no ground-truth or any experience to evaluate a
reasonable scoring system, making the designing even harder. To reduce the
effort of manual adjustment of the scoring function in every new scoring
system, we innovatively study the scoring system from the preset empirical
criteria without any ground truth, and propose a novel framework to improve the
system from scratch. In this paper, we propose a &quot;counter-empirical attacking&quot;
mechanism that can generate &quot;attacking&quot; behavior traces and try to break the
empirical rules of the scoring system. Then an adversarial &quot;enhancer&quot; is
applied to evaluate the scoring system and find the improvement strategy. By
training the adversarial learning problem, a proper scoring function can be
learned to be robust to the attacking activity traces that are trying to
violate the empirical criteria. Extensive experiments have been conducted on
two scoring systems including a shared computing resource platform and a
financial credit system. The experimental results have validated the
effectiveness of our proposed framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xiangguo Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1&quot;&gt;Hong Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1&quot;&gt;Hang Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_B/0/1/0/all/0/1&quot;&gt;Bo Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_S/0/1/0/all/0/1&quot;&gt;Si Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1&quot;&gt;Qingwei Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05152">
<title>Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual Downstream Tasks. (arXiv:2311.05152v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05152</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the deployment of large-scale pre-trained models in
audio-visual downstream tasks has yielded remarkable outcomes. However, these
models, primarily trained on single-modality unconstrained datasets, still
encounter challenges in feature extraction for multi-modal tasks, leading to
suboptimal performance. This limitation arises due to the introduction of
irrelevant modality-specific information during encoding, which adversely
affects the performance of downstream tasks. To address this challenge, this
paper proposes a novel Dual-Guided Spatial-Channel-Temporal (DG-SCT) attention
mechanism. This mechanism leverages audio and visual modalities as soft prompts
to dynamically adjust the parameters of pre-trained models based on the current
multi-modal input features. Specifically, the DG-SCT module incorporates
trainable cross-modal interaction layers into pre-trained audio-visual
encoders, allowing adaptive extraction of crucial information from the current
modality across spatial, channel, and temporal dimensions, while preserving the
frozen parameters of large-scale pre-trained models. Experimental evaluations
demonstrate that our proposed model achieves state-of-the-art results across
multiple downstream tasks, including AVE, AVVP, AVS, and AVQA. Furthermore, our
model exhibits promising performance in challenging few-shot and zero-shot
scenarios. The source code and pre-trained models are available at
https://github.com/haoyi-duan/DG-SCT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_H/0/1/0/all/0/1&quot;&gt;Haoyi Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1&quot;&gt;Yan Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Mingze Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1&quot;&gt;Li Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jieming Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhou Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05160">
<title>RAPID: Training-free Retrieval-based Log Anomaly Detection with PLM considering Token-level information. (arXiv:2311.05160v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05160</link>
<description rdf:parseType="Literal">&lt;p&gt;As the IT industry advances, system log data becomes increasingly crucial.
Many computer systems rely on log texts for management due to restricted access
to source code. The need for log anomaly detection is growing, especially in
real-world applications, but identifying anomalies in rapidly accumulating logs
remains a challenging task. Traditional deep learning-based anomaly detection
models require dataset-specific training, leading to corresponding delays.
Notably, most methods only focus on sequence-level log information, which makes
the detection of subtle anomalies harder, and often involve inference processes
that are difficult to utilize in real-time. We introduce RAPID, a model that
capitalizes on the inherent features of log data to enable anomaly detection
without training delays, ensuring real-time capability. RAPID treats logs as
natural language, extracting representations using pre-trained language models.
Given that logs can be categorized based on system context, we implement a
retrieval-based technique to contrast test logs with the most similar normal
logs. This strategy not only obviates the need for log-specific training but
also adeptly incorporates token-level information, ensuring refined and robust
detection, particularly for unseen logs. We also propose the core set
technique, which can reduce the computational cost needed for comparison.
Experimental results show that even without training on log data, RAPID
demonstrates competitive performance compared to prior models and achieves the
best performance on certain datasets. Through various research questions, we
verified its capability for real-time detection without delay.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+No_G/0/1/0/all/0/1&quot;&gt;Gunho No&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yukyung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1&quot;&gt;Hyeongwon Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_P/0/1/0/all/0/1&quot;&gt;Pilsung Kang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05167">
<title>Perfecting Liquid-State Theories with Machine Intelligence. (arXiv:2311.05167v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2311.05167</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have seen a significant increase in the use of machine
intelligence for predicting electronic structure, molecular force fields, and
the physicochemical properties of various condensed systems. However,
substantial challenges remain in developing a comprehensive framework capable
of handling a wide range of atomic compositions and thermodynamic conditions.
This perspective discusses potential future developments in liquid-state
theories leveraging on recent advancements of functional machine learning. By
harnessing the strengths of theoretical analysis and machine learning
techniques including surrogate models, dimension reduction and uncertainty
quantification, we envision that liquid-state theories will gain significant
improvements in accuracy, scalability and computational efficiency, enabling
their broader applications across diverse materials and chemical systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jianzhong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gu_M/0/1/0/all/0/1&quot;&gt;Mengyang Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05185">
<title>Mixture of Weak &amp; Strong Experts on Graphs. (arXiv:2311.05185v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05185</link>
<description rdf:parseType="Literal">&lt;p&gt;Realistic graphs contain both rich self-features of nodes and informative
structures of neighborhoods, jointly handled by a GNN in the typical setup. We
propose to decouple the two modalities by mixture of weak and strong experts
(Mowst), where the weak expert is a light-weight Multi-layer Perceptron (MLP),
and the strong expert is an off-the-shelf Graph Neural Network (GNN). To adapt
the experts&apos; collaboration to different target nodes, we propose a &quot;confidence&quot;
mechanism based on the dispersion of the weak expert&apos;s prediction logits. The
strong expert is conditionally activated when either the node&apos;s classification
relies on neighborhood information, or the weak expert has low model quality.
We reveal interesting training dynamics by analyzing the influence of the
confidence function on loss: our training algorithm encourages the
specialization of each expert by effectively generating soft splitting of the
graph. In addition, our &quot;confidence&quot; design imposes a desirable bias toward the
strong expert to benefit from GNN&apos;s better generalization capability. Mowst is
easy to optimize and achieves strong expressive power, with a computation cost
comparable to a single GNN. Empirically, Mowst shows significant accuracy
improvement on 6 standard node classification benchmarks (including both
homophilous and heterophilous graphs).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1&quot;&gt;Hanqing Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1&quot;&gt;Hanjia Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1&quot;&gt;Diyi Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1&quot;&gt;Yinglong Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1&quot;&gt;Jiebo Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05203">
<title>Whisper in Focus: Enhancing Stuttered Speech Classification with Encoder Layer Optimization. (arXiv:2311.05203v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2311.05203</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, advancements in the field of speech processing have led to
cutting-edge deep learning algorithms with immense potential for real-world
applications. The automated identification of stuttered speech is one of such
applications that the researchers are addressing by employing deep learning
techniques. Recently, researchers have utilized Wav2vec2.0, a speech
recognition model to classify disfluency types in stuttered speech. Although
Wav2vec2.0 has shown commendable results, its ability to generalize across all
disfluency types is limited. In addition, since its base model uses 12 encoder
layers, it is considered a resource-intensive model. Our study unravels the
capabilities of Whisper for the classification of disfluency types in stuttered
speech. We have made notable contributions in three pivotal areas: enhancing
the quality of SEP28-k benchmark dataset, exploration of Whisper for
classification, and introducing an efficient encoder layer freezing strategy.
The optimized Whisper model has achieved the average F1-score of 0.81, which
proffers its abilities. This study also unwinds the significance of deeper
encoder layers in the identification of disfluency types, as the results
demonstrate their greater contribution compared to initial layers. This
research represents substantial contributions, shifting the emphasis towards an
efficient solution, thereby thriving towards prospective innovation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ameer_H/0/1/0/all/0/1&quot;&gt;Huma Ameer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Latif_S/0/1/0/all/0/1&quot;&gt;Seemab Latif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Latif_R/0/1/0/all/0/1&quot;&gt;Rabia Latif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhtar_S/0/1/0/all/0/1&quot;&gt;Sana Mukhtar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05241">
<title>When Meta-Learning Meets Online and Continual Learning: A Survey. (arXiv:2311.05241v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05241</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past decade, deep neural networks have demonstrated significant
success using the training scheme that involves mini-batch stochastic gradient
descent on extensive datasets. Expanding upon this accomplishment, there has
been a surge in research exploring the application of neural networks in other
learning scenarios. One notable framework that has garnered significant
attention is meta-learning. Often described as &quot;learning to learn,&quot;
meta-learning is a data-driven approach to optimize the learning algorithm.
Other branches of interest are continual learning and online learning, both of
which involve incrementally updating a model with streaming data. While these
frameworks were initially developed independently, recent works have started
investigating their combinations, proposing novel problem settings and learning
algorithms. However, due to the elevated complexity and lack of unified
terminology, discerning differences between the learning frameworks can be
challenging even for experienced researchers. To facilitate a clear
understanding, this paper provides a comprehensive survey that organizes
various problem settings using consistent terminology and formal descriptions.
By offering an overview of these learning paradigms, our work aims to foster
further advancements in this promising area of research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1&quot;&gt;Jaehyeon Son&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Soochan Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1&quot;&gt;Gunhee Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05245">
<title>Uncertainty Wrapper in the medical domain: Establishing transparent uncertainty quantification for opaque machine learning models in practice. (arXiv:2311.05245v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05245</link>
<description rdf:parseType="Literal">&lt;p&gt;When systems use data-based models that are based on machine learning (ML),
errors in their results cannot be ruled out. This is particularly critical if
it remains unclear to the user how these models arrived at their decisions and
if errors can have safety-relevant consequences, as is often the case in the
medical field. In such cases, the use of dependable methods to quantify the
uncertainty remaining in a result allows the user to make an informed decision
about further usage and draw possible conclusions based on a given result. This
paper demonstrates the applicability and practical utility of the Uncertainty
Wrapper using flow cytometry as an application from the medical field that can
benefit from the use of ML models in conjunction with dependable and
transparent uncertainty quantification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jockel_L/0/1/0/all/0/1&quot;&gt;Lisa J&amp;#xf6;ckel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klas_M/0/1/0/all/0/1&quot;&gt;Michael Kl&amp;#xe4;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popp_G/0/1/0/all/0/1&quot;&gt;Georg Popp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hilger_N/0/1/0/all/0/1&quot;&gt;Nadja Hilger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fricke_S/0/1/0/all/0/1&quot;&gt;Stephan Fricke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05256">
<title>Latent Task-Specific Graph Network Simulators. (arXiv:2311.05256v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05256</link>
<description rdf:parseType="Literal">&lt;p&gt;Simulating dynamic physical interactions is a critical challenge across
multiple scientific domains, with applications ranging from robotics to
material science. For mesh-based simulations, Graph Network Simulators (GNSs)
pose an efficient alternative to traditional physics-based simulators. Their
inherent differentiability and speed make them particularly well-suited for
inverse design problems. Yet, adapting to new tasks from limited available data
is an important aspect for real-world applications that current methods
struggle with. We frame mesh-based simulation as a meta-learning problem and
use a recent Bayesian meta-learning method to improve GNSs adaptability to new
scenarios by leveraging context data and handling uncertainties. Our approach,
latent task-specific graph network simulator, uses non-amortized task posterior
approximations to sample latent descriptions of unknown system properties.
Additionally, we leverage movement primitives for efficient full trajectory
prediction, effectively addressing the issue of accumulating errors encountered
by previous auto-regressive methods. We validate the effectiveness of our
approach through various experiments, performing on par with or better than
established baseline methods. Movement primitives further allow us to
accommodate various types of context data, as demonstrated through the
utilization of point clouds during inference. By combining GNSs with
meta-learning, we bring them closer to real-world applicability, particularly
in scenarios with smaller datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahlinger_P/0/1/0/all/0/1&quot;&gt;Philipp Dahlinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freymuth_N/0/1/0/all/0/1&quot;&gt;Niklas Freymuth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volpp_M/0/1/0/all/0/1&quot;&gt;Michael Volpp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1&quot;&gt;Tai Hoang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1&quot;&gt;Gerhard Neumann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05265">
<title>Don&apos;t Waste a Single Annotation: Improving Single-Label Classifiers Through Soft Labels. (arXiv:2311.05265v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.05265</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we address the limitations of the common data annotation and
training methods for objective single-label classification tasks. Typically,
when annotating such tasks annotators are only asked to provide a single label
for each sample and annotator disagreement is discarded when a final hard label
is decided through majority voting. We challenge this traditional approach,
acknowledging that determining the appropriate label can be difficult due to
the ambiguity and lack of context in the data samples. Rather than discarding
the information from such ambiguous annotations, our soft label method makes
use of them for training. Our findings indicate that additional annotator
information, such as confidence, secondary label and disagreement, can be used
to effectively generate soft labels. Training classifiers with these soft
labels then leads to improved performance and calibration on the hard label
test set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1&quot;&gt;Ben Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yue Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1&quot;&gt;Yida Mu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1&quot;&gt;Carolina Scarton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1&quot;&gt;Kalina Bontcheva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1&quot;&gt;Xingyi Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05297">
<title>Do personality tests generalize to Large Language Models?. (arXiv:2311.05297v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.05297</link>
<description rdf:parseType="Literal">&lt;p&gt;With large language models (LLMs) appearing to behave increasingly human-like
in text-based interactions, it has become popular to attempt to evaluate
various properties of these models using tests originally designed for humans.
While re-using existing tests is a resource-efficient way to evaluate LLMs,
careful adjustments are usually required to ensure that test results are even
valid across human sub-populations. Thus, it is not clear to what extent
different tests&apos; validity generalizes to LLMs. In this work, we provide
evidence that LLMs&apos; responses to personality tests systematically deviate from
typical human responses, implying that these results cannot be interpreted in
the same way as human test results. Concretely, reverse-coded items (e.g. &quot;I am
introverted&quot; vs &quot;I am extraverted&quot;) are often both answered affirmatively by
LLMs. In addition, variation across different prompts designed to &quot;steer&quot; LLMs
to simulate particular personality types does not follow the clear separation
into five independent personality factors from human samples. In light of these
results, we believe it is important to pay more attention to tests&apos; validity
for LLMs before drawing strong conclusions about potentially ill-defined
concepts like LLMs&apos; &quot;personality&quot;.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dorner_F/0/1/0/all/0/1&quot;&gt;Florian E. Dorner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suhr_T/0/1/0/all/0/1&quot;&gt;Tom S&amp;#xfc;hr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samadi_S/0/1/0/all/0/1&quot;&gt;Samira Samadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kelava_A/0/1/0/all/0/1&quot;&gt;Augustin Kelava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05303">
<title>Reliable and Efficient Data Collection in UAV-based IoT Networks. (arXiv:2311.05303v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2311.05303</link>
<description rdf:parseType="Literal">&lt;p&gt;Internet of Things (IoT) involves sensors for monitoring and wireless
networks for efficient communication. However, resource-constrained IoT devices
and limitations in existing wireless technologies hinder its full potential.
Integrating Unmanned Aerial Vehicles (UAVs) into IoT networks can address some
challenges by expanding its&apos; coverage, providing security, and bringing
computing closer to IoT devices. Nevertheless, effective data collection in
UAV-assisted IoT networks is hampered by factors, including dynamic UAV
behavior, environmental variables, connectivity instability, and security
considerations. In this survey, we first explore UAV-based IoT networks,
focusing on communication and networking aspects. Next, we cover various
UAV-based data collection methods their advantages and disadvantages, followed
by a discussion on performance metrics for data collection. As this article
primarily emphasizes reliable and efficient data collection in UAV-assisted IoT
networks, we briefly discuss existing research on data accuracy and
consistency, network connectivity, and data security and privacy to provide
insights into reliable data collection. Additionally, we discuss efficient data
collection strategies in UAV-based IoT networks, covering trajectory and path
planning, collision avoidance, sensor network clustering, data aggregation, UAV
swarm formations, and artificial intelligence for optimization. We also present
two use cases of UAVs as a service for enhancing data collection reliability
and efficiency. Finally, we discuss future challenges in data collection for
UAV-assisted IoT networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_P/0/1/0/all/0/1&quot;&gt;Poorvi Joshi&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalita_A/0/1/0/all/0/1&quot;&gt;Alakesh Kalita&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurusamy_M/0/1/0/all/0/1&quot;&gt;Mohan Gurusamy&lt;/a&gt; (1) ((1) National University of Singapore, (2) Singapore University of Technology and Design)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05304">
<title>Data Valuation and Detections in Federated Learning. (arXiv:2311.05304v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05304</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) enables collaborative model training without sharing
raw data, demanding abundant, high-quality data for optimal model performance.
Fair and efficient data evaluation is a fundamental issue for incentivizing
clients to provide more high-quality data. Meanwhile, it is likely that only a
subset of clients and datasets are relevant for a learning task while the rest
of them may have a negative impact on the model training. This paper introduces
a novel privacy-preserving method for evaluating client contributions and
selecting relevant data samples without a pre-specified training algorithm. Our
proposed approach, FedBary, utilizes Wasserstein distance within the federated
context, offering a new pioneering solution for data valuation, which provides
transparent data evaluation and efficient computation of Wasserstein barycenter
to mitigate reliance on validation data. We conduct extensive empirical
experiments and theoretical analysis, showing the promising research of this
valuation metric.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenqian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1&quot;&gt;Shuran Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fengrui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1&quot;&gt;Yan Pang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05316">
<title>ABIGX: A Unified Framework for eXplainable Fault Detection and Classification. (arXiv:2311.05316v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05316</link>
<description rdf:parseType="Literal">&lt;p&gt;For explainable fault detection and classification (FDC), this paper proposes
a unified framework, ABIGX (Adversarial fault reconstruction-Based Integrated
Gradient eXplanation). ABIGX is derived from the essentials of previous
successful fault diagnosis methods, contribution plots (CP) and
reconstruction-based contribution (RBC). It is the first explanation framework
that provides variable contributions for the general FDC models. The core part
of ABIGX is the adversarial fault reconstruction (AFR) method, which rethinks
the FR from the perspective of adversarial attack and generalizes to fault
classification models with a new fault index. For fault classification, we put
forward a new problem of fault class smearing, which intrinsically hinders the
correct explanation. We prove that ABIGX effectively mitigates this problem and
outperforms the existing gradient-based explanation methods. For fault
detection, we theoretically bridge ABIGX with conventional fault diagnosis
methods by proving that CP and RBC are the linear specifications of ABIGX. The
experiments evaluate the explanations of FDC by quantitative metrics and
intuitive illustrations, the results of which show the general superiority of
ABIGX to other advanced explanation methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuo_Y/0/1/0/all/0/1&quot;&gt;Yue Zhuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1&quot;&gt;Jinchuan Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhihuan Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Ge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05317">
<title>RepQ: Generalizing Quantization-Aware Training for Re-Parametrized Architectures. (arXiv:2311.05317v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05317</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing neural networks are memory-consuming and computationally intensive,
making deploying them challenging in resource-constrained environments.
However, there are various methods to improve their efficiency. Two such
methods are quantization, a well-known approach for network compression, and
re-parametrization, an emerging technique designed to improve model
performance. Although both techniques have been studied individually, there has
been limited research on their simultaneous application. To address this gap,
we propose a novel approach called RepQ, which applies quantization to
re-parametrized networks. Our method is based on the insight that the test
stage weights of an arbitrary re-parametrized layer can be presented as a
differentiable function of trainable parameters. We enable quantization-aware
training by applying quantization on top of this function. RepQ generalizes
well to various re-parametrized models and outperforms the baseline method LSQ
quantization scheme in all experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prutianova_A/0/1/0/all/0/1&quot;&gt;Anastasiia Prutianova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1&quot;&gt;Alexey Zaytsev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chung-Kuei Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fengyu Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koryakovskiy_I/0/1/0/all/0/1&quot;&gt;Ivan Koryakovskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05323">
<title>Spatial Attention-based Distribution Integration Network for Human Pose Estimation. (arXiv:2311.05323v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05323</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, human pose estimation has made significant progress through
the implementation of deep learning techniques. However, these techniques still
face limitations when confronted with challenging scenarios, including
occlusion, diverse appearances, variations in illumination, and overlap. To
cope with such drawbacks, we present the Spatial Attention-based Distribution
Integration Network (SADI-NET) to improve the accuracy of localization in such
situations. Our network consists of three efficient models: the receptive
fortified module (RFM), spatial fusion module (SFM), and distribution learning
module (DLM). Building upon the classic HourglassNet architecture, we replace
the basic block with our proposed RFM. The RFM incorporates a dilated residual
block and attention mechanism to expand receptive fields while enhancing
sensitivity to spatial information. In addition, the SFM incorporates
multi-scale characteristics by employing both global and local attention
mechanisms. Furthermore, the DLM, inspired by residual log-likelihood
estimation (RLE), reconfigures a predicted heatmap using a trainable
distribution weight. For the purpose of determining the efficacy of our model,
we conducted extensive experiments on the MPII and LSP benchmarks.
Particularly, our model obtained a remarkable $92.10\%$ percent accuracy on the
MPII test dataset, demonstrating significant improvements over existing models
and establishing state-of-the-art performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Sihan Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jing Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1&quot;&gt;Xiaoxuan Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaoyue Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qijin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05334">
<title>Real-time Addressee Estimation: Deployment of a Deep-Learning Model on the iCub Robot. (arXiv:2311.05334v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2311.05334</link>
<description rdf:parseType="Literal">&lt;p&gt;Addressee Estimation is the ability to understand to whom a person is
talking, a skill essential for social robots to interact smoothly with humans.
In this sense, it is one of the problems that must be tackled to develop
effective conversational agents in multi-party and unstructured scenarios. As
humans, one of the channels that mainly lead us to such estimation is the
non-verbal behavior of speakers: first of all, their gaze and body pose.
Inspired by human perceptual skills, in the present work, a deep-learning model
for Addressee Estimation relying on these two non-verbal features is designed,
trained, and deployed on an iCub robot. The study presents the procedure of
such implementation and the performance of the model deployed in real-time
human-robot interaction compared to previous tests on the dataset used for the
training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazzola_C/0/1/0/all/0/1&quot;&gt;Carlo Mazzola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rea_F/0/1/0/all/0/1&quot;&gt;Francesco Rea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sciutti_A/0/1/0/all/0/1&quot;&gt;Alessandra Sciutti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05346">
<title>Accelerated Shapley Value Approximation for Data Evaluation. (arXiv:2311.05346v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05346</link>
<description rdf:parseType="Literal">&lt;p&gt;Data valuation has found various applications in machine learning, such as
data filtering, efficient learning and incentives for data sharing. The most
popular current approach to data valuation is the Shapley value. While popular
for its various applications, Shapley value is computationally expensive even
to approximate, as it requires repeated iterations of training models on
different subsets of data. In this paper we show that the Shapley value of data
points can be approximated more efficiently by leveraging the structural
properties of machine learning problems. We derive convergence guarantees on
the accuracy of the approximate Shapley value for different learning settings
including Stochastic Gradient Descent with convex and non-convex loss
functions. Our analysis suggests that in fact models trained on small subsets
are more important in the context of data valuation. Based on this idea, we
describe $\delta$-Shapley -- a strategy of only using small subsets for the
approximation. Experiments show that this approach preserves approximate value
and rank of data, while achieving speedup of up to 9.9x. In pre-trained
networks the approach is found to bring more efficiency in terms of accurate
evaluation using small subsets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watson_L/0/1/0/all/0/1&quot;&gt;Lauren Watson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kujawa_Z/0/1/0/all/0/1&quot;&gt;Zeno Kujawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andreeva_R/0/1/0/all/0/1&quot;&gt;Rayna Andreeva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hao-Tsung Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elahi_T/0/1/0/all/0/1&quot;&gt;Tariq Elahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_R/0/1/0/all/0/1&quot;&gt;Rik Sarkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05360">
<title>Basis functions nonlinear data-enabled predictive control: Consistent and computationally efficient formulations. (arXiv:2311.05360v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2311.05360</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the extension of data-enabled predictive control (DeePC)
to nonlinear systems via general basis functions. Firstly, we formulate a basis
functions DeePC behavioral predictor and we identify necessary and sufficient
conditions for equivalence with a corresponding basis functions multi-step
identified predictor. The derived conditions yield a dynamic regularization
cost function that enables a well-posed (i.e., consistent) basis functions
formulation of nonlinear DeePC. To optimize computational efficiency of basis
functions DeePC we further develop two alternative formulations that use a
simpler, sparse regularization cost function and ridge regression,
respectively. Consistency implications for Koopman DeePC as well as several
methods for constructing the basis functions representation are also indicated.
The effectiveness of the developed consistent basis functions DeePC
formulations is illustrated on a benchmark nonlinear pendulum state-space
model, for both noise free and noisy data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lazar_M/0/1/0/all/0/1&quot;&gt;Mircea Lazar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05363">
<title>Beyond the training set: an intuitive method for detecting distribution shift in model-based optimization. (arXiv:2311.05363v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05363</link>
<description rdf:parseType="Literal">&lt;p&gt;Model-based optimization (MBO) is increasingly applied to design problems in
science and engineering. A common scenario involves using a fixed training set
to train models, with the goal of designing new samples that outperform those
present in the training data. A major challenge in this setting is distribution
shift, where the distributions of training and design samples are different.
While some shift is expected, as the goal is to create better designs, this
change can negatively affect model accuracy and subsequently, design quality.
Despite the widespread nature of this problem, addressing it demands deep
domain knowledge and artful application. To tackle this issue, we propose a
straightforward method for design practitioners that detects distribution
shifts. This method trains a binary classifier using knowledge of the unlabeled
design distribution to separate the training data from the design data. The
classifier&apos;s logit scores are then used as a proxy measure of distribution
shift. We validate our method in a real-world application by running offline
MBO and evaluate the effect of distribution shift on design quality. We find
that the intensity of the shift in the design distribution varies based on the
number of steps taken by the optimization algorithm, and our simple approach
can identify these shifts. This enables users to constrain their search to
regions where the model&apos;s predictions are reliable, thereby increasing the
quality of designs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damani_F/0/1/0/all/0/1&quot;&gt;Farhan Damani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brookes_D/0/1/0/all/0/1&quot;&gt;David H Brookes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sternlieb_T/0/1/0/all/0/1&quot;&gt;Theodore Sternlieb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webster_C/0/1/0/all/0/1&quot;&gt;Cameron Webster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malina_S/0/1/0/all/0/1&quot;&gt;Stephen Malina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jajoo_R/0/1/0/all/0/1&quot;&gt;Rishi Jajoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1&quot;&gt;Kathy Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinai_S/0/1/0/all/0/1&quot;&gt;Sam Sinai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05398">
<title>The Sample Complexity Of ERMs In Stochastic Convex Optimization. (arXiv:2311.05398v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05398</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic convex optimization is one of the most well-studied models for
learning in modern machine learning. Nevertheless, a central fundamental
question in this setup remained unresolved: &quot;How many data points must be
observed so that any empirical risk minimizer (ERM) shows good performance on
the true population?&quot; This question was proposed by Feldman (2016), who proved
that $\Omega(\frac{d}{\epsilon}+\frac{1}{\epsilon^2})$ data points are
necessary (where $d$ is the dimension and $\epsilon&amp;gt;0$ is the accuracy
parameter). Proving an $\omega(\frac{d}{\epsilon}+\frac{1}{\epsilon^2})$ lower
bound was left as an open problem. In this work we show that in fact
$\tilde{O}(\frac{d}{\epsilon}+\frac{1}{\epsilon^2})$ data points are also
sufficient. This settles the question and yields a new separation between ERMs
and uniform convergence. This sample complexity holds for the classical setup
of learning bounded convex Lipschitz functions over the Euclidean unit ball. We
further generalize the result and show that a similar upper bound holds for all
symmetric convex bodies. The general bound is composed of two terms: (i) a term
of the form $\tilde{O}(\frac{d}{\epsilon})$ with an inverse-linear dependence
on the accuracy parameter, and (ii) a term that depends on the statistical
complexity of the class of $\textit{linear}$ functions (captured by the
Rademacher complexity). The proof builds a mechanism for controlling the
behavior of stochastic convex optimization problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carmon_D/0/1/0/all/0/1&quot;&gt;Daniel Carmon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livni_R/0/1/0/all/0/1&quot;&gt;Roi Livni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yehudayoff_A/0/1/0/all/0/1&quot;&gt;Amir Yehudayoff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05400">
<title>SIRE: scale-invariant, rotation-equivariant estimation of artery orientations using graph neural networks. (arXiv:2311.05400v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05400</link>
<description rdf:parseType="Literal">&lt;p&gt;Blood vessel orientation as visualized in 3D medical images is an important
descriptor of its geometry that can be used for centerline extraction and
subsequent segmentation and visualization. Arteries appear at many scales and
levels of tortuosity, and determining their exact orientation is challenging.
Recent works have used 3D convolutional neural networks (CNNs) for this
purpose, but CNNs are sensitive to varying vessel sizes and orientations. We
present SIRE: a scale-invariant, rotation-equivariant estimator for local
vessel orientation. SIRE is modular and can generalise due to symmetry
preservation.
&lt;/p&gt;
&lt;p&gt;SIRE consists of a gauge equivariant mesh CNN (GEM-CNN) operating on multiple
nested spherical meshes with different sizes in parallel. The features on each
mesh are a projection of image intensities within the corresponding sphere.
These features are intrinsic to the sphere and, in combination with the
GEM-CNN, lead to SO(3)-equivariance. Approximate scale invariance is achieved
by weight sharing and use of a symmetric maximum function to combine
multi-scale predictions. Hence, SIRE can be trained with arbitrarily oriented
vessels with varying radii to generalise to vessels with a wide range of
calibres and tortuosity.
&lt;/p&gt;
&lt;p&gt;We demonstrate the efficacy of SIRE using three datasets containing vessels
of varying scales: the vascular model repository (VMR), the ASOCA coronary
artery set, and a set of abdominal aortic aneurysms (AAAs). We embed SIRE in a
centerline tracker which accurately tracks AAAs, regardless of the data SIRE is
trained with. Moreover, SIRE can be used to track coronary arteries, even when
trained only with AAAs.
&lt;/p&gt;
&lt;p&gt;In conclusion, by incorporating SO(3) and scale symmetries, SIRE can
determine the orientations of vessels outside of the training domain, forming a
robust and data-efficient solution to geometric analysis of blood vessels in 3D
medical images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alblas_D/0/1/0/all/0/1&quot;&gt;Dieuwertje Alblas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suk_J/0/1/0/all/0/1&quot;&gt;Julian Suk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brune_C/0/1/0/all/0/1&quot;&gt;Christoph Brune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_K/0/1/0/all/0/1&quot;&gt;Kak Khee Yeung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolterink_J/0/1/0/all/0/1&quot;&gt;Jelmer M. Wolterink&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05407">
<title>Data Distillation for Neural Network Potentials toward Foundational Dataset. (arXiv:2311.05407v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/2311.05407</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning (ML) techniques and atomistic modeling have rapidly
transformed materials design and discovery. Specifically, generative models can
swiftly propose promising materials for targeted applications. However, the
predicted properties of materials through the generative models often do not
match with calculated properties through ab initio calculations. This
discrepancy can arise because the generated coordinates are not fully relaxed,
whereas the many properties are derived from relaxed structures. Neural
network-based potentials (NNPs) can expedite the process by providing relaxed
structures from the initially generated ones. Nevertheless, acquiring data to
train NNPs for this purpose can be extremely challenging as it needs to
encompass previously unknown structures. This study utilized extended ensemble
molecular dynamics (MD) to secure a broad range of liquid- and solid-phase
configurations in one of the metallic systems, nickel. Then, we could
significantly reduce them through active learning without losing much accuracy.
We found that the NNP trained from the distilled data could predict different
energy-minimized closed-pack crystal structures even though those structures
were not explicitly part of the initial data. Furthermore, the data can be
translated to other metallic systems (aluminum and niobium), without repeating
the sampling and distillation processes. Our approach to data acquisition and
distillation has demonstrated the potential to expedite NNP development and
enhance materials design and discovery by integrating generative models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Jung_G/0/1/0/all/0/1&quot;&gt;Gang Seob Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sangkeun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jong Youl Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05417">
<title>Predicting the Position Uncertainty at the Time of Closest Approach with Diffusion Models. (arXiv:2311.05417v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05417</link>
<description rdf:parseType="Literal">&lt;p&gt;The risk of collision between resident space objects has significantly
increased in recent years. As a result, spacecraft collision avoidance
procedures have become an essential part of satellite operations. To ensure
safe and effective space activities, satellite owners and operators rely on
constantly updated estimates of encounters. These estimates include the
uncertainty associated with the position of each object at the expected TCA.
These estimates are crucial in planning risk mitigation measures, such as
collision avoidance manoeuvres. As the TCA approaches, the accuracy of these
estimates improves, as both objects&apos; orbit determination and propagation
procedures are made for increasingly shorter time intervals. However, this
improvement comes at the cost of taking place close to the critical decision
moment. This means that safe avoidance manoeuvres might not be possible or
could incur significant costs. Therefore, knowing the evolution of this
variable in advance can be crucial for operators. This work proposes a machine
learning model based on diffusion models to forecast the position uncertainty
of objects involved in a close encounter, particularly for the secondary object
(usually debris), which tends to be more unpredictable. We compare the
performance of our model with other state-of-the-art solutions and a na\&quot;ive
baseline approach, showing that the proposed solution has the potential to
significantly improve the safety and effectiveness of spacecraft operations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guimaraes_M/0/1/0/all/0/1&quot;&gt;Marta Guimar&amp;#xe3;es&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soares_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe1;udia Soares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manfletti_C/0/1/0/all/0/1&quot;&gt;Chiara Manfletti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05418">
<title>Generalization in medical AI: a perspective on developing scalable models. (arXiv:2311.05418v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05418</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past few years, research has witnessed the advancement of deep
learning models trained on large datasets, some even encompassing millions of
examples. While these impressive performance on their hidden test sets, they
often underperform when assessed on external datasets. Recognizing the critical
role of generalization in medical AI development, many prestigious journals now
require reporting results both on the local hidden test set as well as on
external datasets before considering a study for publication. Effectively, the
field of medical AI has transitioned from the traditional usage of a single
dataset that is split into train and test to a more comprehensive framework
using multiple datasets, some of which are used for model development (source
domain) and others for testing (target domains). However, this new experimental
setting does not necessarily resolve the challenge of generalization. This is
because of the variability encountered in intended use and specificities across
hospital cultures making the idea of universally generalizable systems a myth.
On the other hand, the systematic, and a fortiori recurrent re-calibration, of
models at the individual hospital level, although ideal, may be overoptimistic
given the legal, regulatory and technical challenges that are involved.
Re-calibration using transfer learning may not even be possible in some
instances where reference labels of target domains are not available. In this
perspective we establish a hierarchical three-level scale system reflecting the
generalization level of a medical AI algorithm. This scale better reflects the
diversity of real-world medical scenarios per which target domain data for
re-calibration of models may or not be available and if it is, may or not have
reference labels systematically available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behar_J/0/1/0/all/0/1&quot;&gt;Joachim A. Behar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levy_J/0/1/0/all/0/1&quot;&gt;Jeremy Levy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celi_L/0/1/0/all/0/1&quot;&gt;Leo Anthony Celi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05420">
<title>Counterfactually Fair Representation. (arXiv:2311.05420v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05420</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of machine learning models in high-stake applications (e.g.,
healthcare, lending, college admission) has raised growing concerns due to
potential biases against protected social groups. Various fairness notions and
methods have been proposed to mitigate such biases. In this work, we focus on
Counterfactual Fairness (CF), a fairness notion that is dependent on an
underlying causal graph and first proposed by Kusner \textit{et
al.}~\cite{kusner2017counterfactual}; it requires that the outcome an
individual perceives is the same in the real world as it would be in a
&quot;counterfactual&quot; world, in which the individual belongs to another social
group. Learning fair models satisfying CF can be challenging. It was shown in
\cite{kusner2017counterfactual} that a sufficient condition for satisfying CF
is to \textbf{not} use features that are descendants of sensitive attributes in
the causal graph. This implies a simple method that learns CF models only using
non-descendants of sensitive attributes while eliminating all descendants.
Although several subsequent works proposed methods that use all features for
training CF models, there is no theoretical guarantee that they can satisfy CF.
In contrast, this work proposes a new algorithm that trains models using all
the available features. We theoretically and empirically show that models
trained with this method can satisfy CF\footnote{The code repository for this
work can be found in
\url{https://github.com/osu-srml/CF_Representation_Learning}}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_Z/0/1/0/all/0/1&quot;&gt;Zhiqun Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalili_M/0/1/0/all/0/1&quot;&gt;Mohammad Mahdi Khalili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xueru Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05421">
<title>Diffusion Based Causal Representation Learning. (arXiv:2311.05421v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05421</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal reasoning can be considered a cornerstone of intelligent systems.
Having access to an underlying causal graph comes with the promise of
cause-effect estimation and the identification of efficient and safe
interventions. However, learning causal representations remains a major
challenge, due to the complexity of many real-world systems. Previous works on
causal representation learning have mostly focused on Variational Auto-Encoders
(VAE). These methods only provide representations from a point estimate, and
they are unsuitable to handle high dimensions. To overcome these problems, we
proposed a new Diffusion-based Causal Representation Learning (DCRL) algorithm.
This algorithm uses diffusion-based representations for causal discovery. DCRL
offers access to infinite dimensional latent codes, which encode different
levels of information in the latent code. In a first proof of principle, we
investigate the use of DCRL for causal representation learning. We further
demonstrate experimentally that this approach performs comparably well in
identifying the causal structure and causal variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mamaghan_A/0/1/0/all/0/1&quot;&gt;Amir Mohammad Karimi Mamaghan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dittadi_A/0/1/0/all/0/1&quot;&gt;Andrea Dittadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1&quot;&gt;Stefan Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johansson_K/0/1/0/all/0/1&quot;&gt;Karl Henrik Johansson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quinzan_F/0/1/0/all/0/1&quot;&gt;Francesco Quinzan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05426">
<title>Statistical Learning of Conjunction Data Messages Through a Bayesian Non-Homogeneous Poisson Process. (arXiv:2311.05426v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05426</link>
<description rdf:parseType="Literal">&lt;p&gt;Current approaches for collision avoidance and space traffic management face
many challenges, mainly due to the continuous increase in the number of objects
in orbit and the lack of scalable and automated solutions. To avoid
catastrophic incidents, satellite owners/operators must be aware of their
assets&apos; collision risk to decide whether a collision avoidance manoeuvre needs
to be performed. This process is typically executed through the use of warnings
issued in the form of CDMs which contain information about the event, such as
the expected TCA and the probability of collision. Our previous work presented
a statistical learning model that allowed us to answer two important questions:
(1) Will any new conjunctions be issued in the next specified time interval?
(2) When and with what uncertainty will the next CDM arrive? However, the model
was based on an empirical Bayes homogeneous Poisson process, which assumes that
the arrival rates of CDMs are constant over time. In fact, the rate at which
the CDMs are issued depends on the behaviour of the objects as well as on the
screening process performed by third parties. Thus, in this work, we extend the
previous study and propose a Bayesian non-homogeneous Poisson process
implemented with high precision using a Probabilistic Programming Language to
fully describe the underlying phenomena. We compare the proposed solution with
a baseline model to demonstrate the added value of our approach. The results
show that this problem can be successfully modelled by our Bayesian
non-homogeneous Poisson Process with greater accuracy, contributing to the
development of automated collision avoidance systems and helping operators
react timely but sparingly with satellite manoeuvres.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guimaraes_M/0/1/0/all/0/1&quot;&gt;Marta Guimar&amp;#xe3;es&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soares_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe1;udia Soares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manfletti_C/0/1/0/all/0/1&quot;&gt;Chiara Manfletti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05430">
<title>Taxonomy for Resident Space Objects in LEO: A Deep Learning Approach. (arXiv:2311.05430v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05430</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing number of RSOs has raised concerns about the risk of
collisions and catastrophic incidents for all direct and indirect users of
space. To mitigate this issue, it is essential to have a good understanding of
the various RSOs in orbit and their behaviour. A well-established taxonomy
defining several classes of RSOs is a critical step in achieving this
understanding. This taxonomy helps assign objects to specific categories based
on their main characteristics, leading to better tracking services.
Furthermore, a well-established taxonomy can facilitate research and analysis
processes by providing a common language and framework for better understanding
the factors that influence RSO behaviour in space. These factors, in turn, help
design more efficient and effective strategies for space traffic management.
Our work proposes a new taxonomy for RSOs focusing on the low Earth orbit
regime to enhance space traffic management. In addition, we present a deep
learning-based model that uses an autoencoder architecture to reduce the
features representing the characteristics of the RSOs. The autoencoder
generates a lower-dimensional space representation that is then explored using
techniques such as Uniform Manifold Approximation and Projection to identify
fundamental clusters of RSOs based on their unique characteristics. This
approach captures the complex and non-linear relationships between the features
and the RSOs&apos; classes identified. Our proposed taxonomy and model offer a
significant contribution to the ongoing efforts to mitigate the overall risks
posed by the increasing number of RSOs in orbit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guimaraes_M/0/1/0/all/0/1&quot;&gt;Marta Guimar&amp;#xe3;es&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soares_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe1;udia Soares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manfletti_C/0/1/0/all/0/1&quot;&gt;Chiara Manfletti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05435">
<title>Parkinson&apos;s Disease Detection through Vocal Biomarkers and Advanced Machine Learning Algorithms: A Comprehensive Study. (arXiv:2311.05435v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05435</link>
<description rdf:parseType="Literal">&lt;p&gt;Parkinson&apos;s disease (PD) is a prevalent neurodegenerative disorder known for
its impact on motor neurons, causing symptoms like tremors, stiffness, and gait
difficulties. This study explores the potential of vocal feature alterations in
PD patients as a means of early disease prediction. This research aims to
predict the onset of Parkinson&apos;s disease. Utilizing a variety of advanced
machine-learning algorithms, including XGBoost, LightGBM, Bagging, AdaBoost,
and Support Vector Machine, among others, the study evaluates the predictive
performance of these models using metrics such as accuracy, area under the
curve (AUC), sensitivity, and specificity. The findings of this comprehensive
analysis highlight LightGBM as the most effective model, achieving an
impressive accuracy rate of 96%, alongside a matching AUC of 96%. LightGBM
exhibited a remarkable sensitivity of 100% and specificity of 94.43%,
surpassing other machine learning algorithms in accuracy and AUC scores. Given
the complexities of Parkinson&apos;s disease and its challenges in early diagnosis,
this study underscores the significance of leveraging vocal biomarkers coupled
with advanced machine-learning techniques for precise and timely PD detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sayed_M/0/1/0/all/0/1&quot;&gt;Md Abu Sayed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahamed_S/0/1/0/all/0/1&quot;&gt;Sabbir Ahamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1&quot;&gt;Duc M Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavel_M/0/1/0/all/0/1&quot;&gt;Md Eyasin Ul Islam Pavel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_M/0/1/0/all/0/1&quot;&gt;Malay Sarkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mia_M/0/1/0/all/0/1&quot;&gt;Md Tuhin Mia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05436">
<title>Fair Wasserstein Coresets. (arXiv:2311.05436v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.05436</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent technological advancements have given rise to the ability of
collecting vast amounts of data, that often exceed the capacity of commonly
used machine learning algorithms. Approaches such as coresets and synthetic
data distillation have emerged as frameworks to generate a smaller, yet
representative, set of samples for downstream training. As machine learning is
increasingly applied to decision-making processes, it becomes imperative for
modelers to consider and address biases in the data concerning subgroups
defined by factors like race, gender, or other sensitive attributes. Current
approaches focus on creating fair synthetic representative samples by
optimizing local properties relative to the original samples. These methods,
however, are not guaranteed to positively affect the performance or fairness of
downstream learning processes. In this work, we present Fair Wasserstein
Coresets (FWC), a novel coreset approach which generates fair synthetic
representative samples along with sample-level weights to be used in downstream
learning tasks. FWC aims to minimize the Wasserstein distance between the
original datasets and the weighted synthetic samples while enforcing (an
empirical version of) demographic parity, a prominent criterion for algorithmic
fairness, via a linear constraint. We show that FWC can be thought of as a
constrained version of Lloyd&apos;s algorithm for k-medians or k-means clustering.
Our experiments, conducted on both synthetic and real datasets, demonstrate the
scalability of our approach and highlight the competitive performance of FWC
compared to existing fair clustering approaches, even when attempting to
enhance the fairness of the latter through fair pre-processing techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zikai Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dalmasso_N/0/1/0/all/0/1&quot;&gt;Niccol&amp;#xf2; Dalmasso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Potluru_V/0/1/0/all/0/1&quot;&gt;Vamsi K. Potluru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balch_T/0/1/0/all/0/1&quot;&gt;Tucker Balch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Veloso_M/0/1/0/all/0/1&quot;&gt;Manuela Veloso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05437">
<title>LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents. (arXiv:2311.05437v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05437</link>
<description rdf:parseType="Literal">&lt;p&gt;LLaVA-Plus is a general-purpose multimodal assistant that expands the
capabilities of large multimodal models. It maintains a skill repository of
pre-trained vision and vision-language models and can activate relevant tools
based on users&apos; inputs to fulfill real-world tasks. LLaVA-Plus is trained on
multimodal instruction-following data to acquire the ability to use tools,
covering visual understanding, generation, external knowledge retrieval, and
compositions. Empirical results show that LLaVA-Plus outperforms LLaVA in
existing capabilities and exhibits new ones. It is distinct in that the image
query is directly grounded and actively engaged throughout the entire human-AI
interaction sessions, significantly improving tool use performance and enabling
new scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shilong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1&quot;&gt;Hao Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haotian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Feng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_T/0/1/0/all/0/1&quot;&gt;Tianhe Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1&quot;&gt;Xueyan Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianwei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chunyuan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05440">
<title>A Practical Approach to Novel Class Discovery in Tabular Data. (arXiv:2311.05440v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05440</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of Novel Class Discovery (NCD) consists in extracting knowledge
from a labeled set of known classes to accurately partition an unlabeled set of
novel classes. While NCD has recently received a lot of attention from the
community, it is often solved on computer vision problems and under unrealistic
conditions. In particular, the number of novel classes is usually assumed to be
known in advance, and their labels are sometimes used to tune hyperparameters.
Methods that rely on these assumptions are not applicable in real-world
scenarios. In this work, we focus on solving NCD in tabular data when no prior
knowledge of the novel classes is available. To this end, we propose to tune
the hyperparameters of NCD methods by adapting the $k$-fold cross-validation
process and hiding some of the known classes in each fold. Since we have found
that methods with too many hyperparameters are likely to overfit these hidden
classes, we define a simple deep NCD model. This method is composed of only the
essential elements necessary for the NCD problem and performs impressively well
under realistic conditions. Furthermore, we find that the latent space of this
method can be used to reliably estimate the number of novel classes.
Additionally, we adapt two unsupervised clustering algorithms ($k$-means and
Spectral Clustering) to leverage the knowledge of the known classes. Extensive
experiments are conducted on 7 tabular datasets and demonstrate the
effectiveness of the proposed method and hyperparameter tuning process, and
show that the NCD problem can be solved without relying on knowledge from the
novel classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Troisemaine_C/0/1/0/all/0/1&quot;&gt;Colin Troisemaine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reiffers_Masson_A/0/1/0/all/0/1&quot;&gt;Alexandre Reiffers-Masson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gosselin_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Gosselin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lemaire_V/0/1/0/all/0/1&quot;&gt;Vincent Lemaire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaton_S/0/1/0/all/0/1&quot;&gt;Sandrine Vaton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05451">
<title>All Should Be Equal in the Eyes of Language Models: Counterfactually Aware Fair Text Generation. (arXiv:2311.05451v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.05451</link>
<description rdf:parseType="Literal">&lt;p&gt;Fairness in Language Models (LMs) remains a longstanding challenge, given the
inherent biases in training data that can be perpetuated by models and affect
the downstream tasks. Recent methods employ expensive retraining or attempt
debiasing during inference by constraining model outputs to contrast from a
reference set of biased templates or exemplars. Regardless, they dont address
the primary goal of fairness to maintain equitability across different
demographic groups. In this work, we posit that inferencing LMs to generate
unbiased output for one demographic under a context ensues from being aware of
outputs for other demographics under the same context. To this end, we propose
Counterfactually Aware Fair InferencE (CAFIE), a framework that dynamically
compares the model understanding of diverse demographics to generate more
equitable sentences. We conduct an extensive empirical evaluation using base
LMs of varying sizes and across three diverse datasets and found that CAFIE
outperforms strong baselines. CAFIE produces fairer text and strikes the best
balance between fairness and language modeling capability
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_P/0/1/0/all/0/1&quot;&gt;Pragyan Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Java_A/0/1/0/all/0/1&quot;&gt;Abhinav Java&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jandial_S/0/1/0/all/0/1&quot;&gt;Surgan Jandial&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahid_S/0/1/0/all/0/1&quot;&gt;Simra Shahid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Furniturewala_S/0/1/0/all/0/1&quot;&gt;Shaz Furniturewala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1&quot;&gt;Balaji Krishnamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhatia_S/0/1/0/all/0/1&quot;&gt;Sumit Bhatia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05452">
<title>Transformer-based Model for Oral Epithelial Dysplasia Segmentation. (arXiv:2311.05452v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.05452</link>
<description rdf:parseType="Literal">&lt;p&gt;Oral epithelial dysplasia (OED) is a premalignant histopathological diagnosis
given to lesions of the oral cavity. OED grading is subject to large
inter/intra-rater variability, resulting in the under/over-treatment of
patients. We developed a new Transformer-based pipeline to improve detection
and segmentation of OED in haematoxylin and eosin (H&amp;amp;E) stained whole slide
images (WSIs). Our model was trained on OED cases (n = 260) and controls (n =
105) collected using three different scanners, and validated on test data from
three external centres in the United Kingdom and Brazil (n = 78). Our internal
experiments yield a mean F1-score of 0.81 for OED segmentation, which reduced
slightly to 0.71 on external testing, showing good generalisability, and
gaining state-of-the-art results. This is the first externally validated study
to use Transformers for segmentation in precancerous histology images. Our
publicly available model shows great promise to be the first step of a
fully-integrated pipeline, allowing earlier and more efficient OED diagnosis,
ultimately benefiting patient outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shephard_A/0/1/0/all/0/1&quot;&gt;Adam J Shephard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mahmood_H/0/1/0/all/0/1&quot;&gt;Hanya Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Raza_S/0/1/0/all/0/1&quot;&gt;Shan E Ahmed Raza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Araujo_A/0/1/0/all/0/1&quot;&gt;Anna Luiza Damaceno Araujo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Santos_Silva_A/0/1/0/all/0/1&quot;&gt;Alan Roger Santos-Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lopes_M/0/1/0/all/0/1&quot;&gt;Marcio Ajudarte Lopes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Vargas_P/0/1/0/all/0/1&quot;&gt;Pablo Agustin Vargas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+McCombe_K/0/1/0/all/0/1&quot;&gt;Kris McCombe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Craig_S/0/1/0/all/0/1&quot;&gt;Stephanie Craig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+James_J/0/1/0/all/0/1&quot;&gt;Jacqueline James&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Brooks_J/0/1/0/all/0/1&quot;&gt;Jill Brooks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nankivell_P/0/1/0/all/0/1&quot;&gt;Paul Nankivell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mehanna_H/0/1/0/all/0/1&quot;&gt;Hisham Mehanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Khurram_S/0/1/0/all/0/1&quot;&gt;Syed Ali Khurram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rajpoot_N/0/1/0/all/0/1&quot;&gt;Nasir M Rajpoot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05473">
<title>Do Ensembling and Meta-Learning Improve Outlier Detection in Randomized Controlled Trials?. (arXiv:2311.05473v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05473</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern multi-centre randomized controlled trials (MCRCTs) collect massive
amounts of tabular data, and are monitored intensively for irregularities by
humans. We began by empirically evaluating 6 modern machine learning-based
outlier detection algorithms on the task of identifying irregular data in 838
datasets from 7 real-world MCRCTs with a total of 77,001 patients from over 44
countries. Our results reinforce key findings from prior work in the outlier
detection literature on data from other domains. Existing algorithms often
succeed at identifying irregularities without any supervision, with at least
one algorithm exhibiting positive performance 70.6% of the time. However,
performance across datasets varies substantially with no single algorithm
performing consistently well, motivating new techniques for unsupervised model
selection or other means of aggregating potentially discordant predictions from
multiple candidate models. We propose the Meta-learned Probabilistic Ensemble
(MePE), a simple algorithm for aggregating the predictions of multiple
unsupervised models, and show that it performs favourably compared to recent
meta-learning approaches for outlier detection model selection. While
meta-learning shows promise, small ensembles outperform all forms of
meta-learning on average, a negative result that may guide the application of
current outlier detection approaches in healthcare and other real-world
domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nelson_W/0/1/0/all/0/1&quot;&gt;Walter Nelson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranisau_J/0/1/0/all/0/1&quot;&gt;Jonathan Ranisau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petch_J/0/1/0/all/0/1&quot;&gt;Jeremy Petch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05477">
<title>Using ResNet to Utilize 4-class T2-FLAIR Slice Classification Based on the Cholinergic Pathways Hyperintensities Scale for Pathological Aging. (arXiv:2311.05477v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2311.05477</link>
<description rdf:parseType="Literal">&lt;p&gt;The Cholinergic Pathways Hyperintensities Scale (CHIPS) is a visual rating
scale used to assess the extent of cholinergic white matter hyperintensities in
T2-FLAIR images, serving as an indicator of dementia severity. However, the
manual selection of four specific slices for rating throughout the entire brain
is a time-consuming process. Our goal was to develop a deep learning-based
model capable of automatically identifying the four slices relevant to CHIPS.
To achieve this, we trained a 4-class slice classification model (BSCA) using
the ADNI T2-FLAIR dataset (N=150) with the assistance of ResNet. Subsequently,
we tested the model&apos;s performance on a local dataset (N=30). The results
demonstrated the efficacy of our model, with an accuracy of 99.82% and an
F1-score of 99.83%. This achievement highlights the potential impact of BSCA as
an automatic screening tool, streamlining the selection of four specific
T2-FLAIR slices that encompass white matter landmarks along the cholinergic
pathways. Clinicians can leverage this tool to assess the risk of clinical
dementia development efficiently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tsai_W/0/1/0/all/0/1&quot;&gt;Wei-Chun Kevin Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yi-Chien Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yu_M/0/1/0/all/0/1&quot;&gt;Ming-Chun Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chou_C/0/1/0/all/0/1&quot;&gt;Chia-Ju Chou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yan_S/0/1/0/all/0/1&quot;&gt;Sui-Hing Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Yang-Teng Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yan-Hsiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chiu_Y/0/1/0/all/0/1&quot;&gt;Yen-Ling Chiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chuang_Y/0/1/0/all/0/1&quot;&gt;Yi-Fang Chuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ran-Zan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shih_Y/0/1/0/all/0/1&quot;&gt;Yao-Chia Shih&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05486">
<title>Disease Gene Prioritization With Quantum Walks. (arXiv:2311.05486v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2311.05486</link>
<description rdf:parseType="Literal">&lt;p&gt;Disease gene prioritization assigns scores to genes or proteins according to
their likely relevance for a given disease based on a provided set of seed
genes. Here, we describe a new algorithm for disease gene prioritization based
on continuous-time quantum walks using the adjacency matrix of a
protein-protein interaction (PPI) network. Our algorithm can be seen as a
quantum version of a previous method known as the diffusion kernel, but,
importantly, has higher performance in predicting disease genes, and also
permits the encoding of seed node self-loops into the underlying Hamiltonian,
which offers yet another boost in performance. We demonstrate the success of
our proposed method by comparing it to several well-known gene prioritization
methods on three disease sets, across seven different PPI networks. In order to
compare these methods, we use cross-validation and examine the mean reciprocal
ranks and recall values. We further validate our method by performing an
enrichment analysis of the predicted genes for coronary artery disease. We also
investigate the impact of adding self-loops to the seeds, and argue that they
allow the quantum walker to remain more local to low-degree seed nodes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Saarinen_H/0/1/0/all/0/1&quot;&gt;Harto Saarinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Goldsmith_M/0/1/0/all/0/1&quot;&gt;Mark Goldsmith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Rui-Sheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Loscalzo_J/0/1/0/all/0/1&quot;&gt;Joseph Loscalzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Maniscalco_S/0/1/0/all/0/1&quot;&gt;Sabrina Maniscalco&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05501">
<title>Dirichlet Active Learning. (arXiv:2311.05501v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.05501</link>
<description rdf:parseType="Literal">&lt;p&gt;This work introduces Dirichlet Active Learning (DiAL), a Bayesian-inspired
approach to the design of active learning algorithms. Our framework models
feature-conditional class probabilities as a Dirichlet random field and lends
observational strength between similar features in order to calibrate the
random field. This random field can then be utilized in learning tasks: in
particular, we can use current estimates of mean and variance to conduct
classification and active learning in the context where labeled data is scarce.
We demonstrate the applicability of this model to low-label rate graph learning
by constructing ``propagation operators&apos;&apos; based upon the graph Laplacian, and
offer computational studies demonstrating the method&apos;s competitiveness with the
state of the art. Finally, we provide rigorous guarantees regarding the ability
of this approach to ensure both exploration and exploitation, expressed
respectively in terms of cluster exploration and increased attention to
decision boundaries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miller_K/0/1/0/all/0/1&quot;&gt;Kevin Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Murray_R/0/1/0/all/0/1&quot;&gt;Ryan Murray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05511">
<title>Anytime-Constrained Reinforcement Learning. (arXiv:2311.05511v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05511</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce and study constrained Markov Decision Processes (cMDPs) with
anytime constraints. An anytime constraint requires the agent to never violate
its budget at any point in time, almost surely. Although Markovian policies are
no longer sufficient, we show that there exist optimal deterministic policies
augmented with cumulative costs. In fact, we present a fixed-parameter
tractable reduction from anytime-constrained cMDPs to unconstrained MDPs. Our
reduction yields planning and learning algorithms that are time and
sample-efficient for tabular cMDPs so long as the precision of the costs is
logarithmic in the size of the cMDP. However, we also show that computing
non-trivial approximately optimal policies is NP-hard in general. To circumvent
this bottleneck, we design provable approximation algorithms that efficiently
compute or learn an approximately feasible policy with optimal value so long as
the maximum supported cost is bounded by a polynomial in the cMDP or by the
absolute budget. Given our hardness results, our approximation guarantees are
the best possible in terms of tractability under worst-case analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McMahan_J/0/1/0/all/0/1&quot;&gt;Jeremy McMahan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaojin Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05529">
<title>Information-theoretic generalization bounds for learning from quantum data. (arXiv:2311.05529v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2311.05529</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning tasks play an increasingly prominent role in quantum information and
computation. They range from fundamental problems such as state discrimination
and metrology over the framework of quantum probably approximately correct
(PAC) learning, to the recently proposed shadow variants of state tomography.
However, the many directions of quantum learning theory have so far evolved
separately. We propose a general mathematical formalism for describing quantum
learning by training on classical-quantum data and then testing how well the
learned hypothesis generalizes to new data. In this framework, we prove bounds
on the expected generalization error of a quantum learner in terms of classical
and quantum information-theoretic quantities measuring how strongly the
learner&apos;s hypothesis depends on the specific data seen during training.
&lt;/p&gt;
&lt;p&gt;To achieve this, we use tools from quantum optimal transport and quantum
concentration inequalities to establish non-commutative versions of decoupling
lemmas that underlie recent information-theoretic generalization bounds for
classical machine learning.
&lt;/p&gt;
&lt;p&gt;Our framework encompasses and gives intuitively accessible generalization
bounds for a variety of quantum learning scenarios such as quantum state
discrimination, PAC learning quantum states, quantum parameter estimation, and
quantumly PAC learning classical functions. Thereby, our work lays a foundation
for a unifying quantum information-theoretic perspective on quantum learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1&quot;&gt;Matthias Caro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gur_T/0/1/0/all/0/1&quot;&gt;Tom Gur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rouze_C/0/1/0/all/0/1&quot;&gt;Cambyse Rouz&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Franca_D/0/1/0/all/0/1&quot;&gt;Daniel Stilck Fran&amp;#xe7;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Subramanian_S/0/1/0/all/0/1&quot;&gt;Sathyawageeswar Subramanian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05538">
<title>Embedding Space Interpolation Beyond Mini-Batch, Beyond Pairs and Beyond Examples. (arXiv:2311.05538v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05538</link>
<description rdf:parseType="Literal">&lt;p&gt;Mixup refers to interpolation-based data augmentation, originally motivated
as a way to go beyond empirical risk minimization (ERM). Its extensions mostly
focus on the definition of interpolation and the space (input or feature) where
it takes place, while the augmentation process itself is less studied. In most
methods, the number of generated examples is limited to the mini-batch size and
the number of examples being interpolated is limited to two (pairs), in the
input space.
&lt;/p&gt;
&lt;p&gt;We make progress in this direction by introducing MultiMix, which generates
an arbitrarily large number of interpolated examples beyond the mini-batch size
and interpolates the entire mini-batch in the embedding space. Effectively, we
sample on the entire convex hull of the mini-batch rather than along linear
segments between pairs of examples.
&lt;/p&gt;
&lt;p&gt;On sequence data, we further extend to Dense MultiMix. We densely interpolate
features and target labels at each spatial location and also apply the loss
densely. To mitigate the lack of dense labels, we inherit labels from examples
and weight interpolation factors by attention as a measure of confidence.
&lt;/p&gt;
&lt;p&gt;Overall, we increase the number of loss terms per mini-batch by orders of
magnitude at little additional cost. This is only possible because of
interpolating in the embedding space. We empirically show that our solutions
yield significant improvement over state-of-the-art mixup methods on four
different benchmarks, despite interpolation being only linear. By analyzing the
embedding space, we show that the classes are more tightly clustered and
uniformly spread over the embedding space, thereby explaining the improved
behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkataramanan_S/0/1/0/all/0/1&quot;&gt;Shashanka Venkataramanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kijak_E/0/1/0/all/0/1&quot;&gt;Ewa Kijak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amsaleg_L/0/1/0/all/0/1&quot;&gt;Laurent Amsaleg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1&quot;&gt;Yannis Avrithis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05539">
<title>A Deep Learning Method for Simultaneous Denoising and Missing Wedge Reconstruction in Cryogenic Electron Tomography. (arXiv:2311.05539v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05539</link>
<description rdf:parseType="Literal">&lt;p&gt;Cryogenic electron tomography (cryo-ET) is a technique for imaging biological
samples such as viruses, cells, and proteins in 3D. A microscope collects a
series of 2D projections of the sample, and the goal is to reconstruct the 3D
density of the sample called the tomogram. This is difficult as the 2D
projections have a missing wedge of information and are noisy. Tomograms
reconstructed with conventional methods, such as filtered back-projection,
suffer from the noise, and from artifacts and anisotropic resolution due to the
missing wedge of information. To improve the visual quality and resolution of
such tomograms, we propose a deep-learning approach for simultaneous denoising
and missing wedge reconstruction called DeepDeWedge. DeepDeWedge is based on
fitting a neural network to the 2D projections with a self-supervised loss
inspired by noise2noise-like methods. The algorithm requires no training or
ground truth data. Experiments on synthetic and real cryo-ET data show that
DeepDeWedge achieves competitive performance for deep learning-based denoising
and missing wedge reconstruction of cryo-ET tomograms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiedemann_S/0/1/0/all/0/1&quot;&gt;Simon Wiedemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heckel_R/0/1/0/all/0/1&quot;&gt;Reinhard Heckel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05550">
<title>Towards End-to-End Spoken Grammatical Error Correction. (arXiv:2311.05550v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2311.05550</link>
<description rdf:parseType="Literal">&lt;p&gt;Grammatical feedback is crucial for L2 learners, teachers, and testers.
Spoken grammatical error correction (GEC) aims to supply feedback to L2
learners on their use of grammar when speaking. This process usually relies on
a cascaded pipeline comprising an ASR system, disfluency removal, and GEC, with
the associated concern of propagating errors between these individual modules.
In this paper, we introduce an alternative &quot;end-to-end&quot; approach to spoken GEC,
exploiting a speech recognition foundation model, Whisper. This foundation
model can be used to replace the whole framework or part of it, e.g., ASR and
disfluency removal. These end-to-end approaches are compared to more standard
cascaded approaches on the data obtained from a free-speaking spoken language
assessment test, Linguaskill. Results demonstrate that end-to-end spoken GEC is
possible within this architecture, but the lack of available data limits
current performance compared to a system using large quantities of text-based
GEC data. Conversely, end-to-end disfluency detection and removal, which is
easier for the attention-based Whisper to learn, does outperform cascaded
approaches. Additionally, the paper discusses the challenges of providing
feedback to candidates when using end-to-end systems for spoken GEC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banno_S/0/1/0/all/0/1&quot;&gt;Stefano Bann&amp;#xf2;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1&quot;&gt;Rao Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_M/0/1/0/all/0/1&quot;&gt;Mengjie Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knill_K/0/1/0/all/0/1&quot;&gt;Kate M. Knill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1&quot;&gt;Mark J.F. Gales&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05556">
<title>LCM-LoRA: A Universal Stable-Diffusion Acceleration Module. (arXiv:2311.05556v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05556</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent Consistency Models (LCMs) have achieved impressive performance in
accelerating text-to-image generative tasks, producing high-quality images with
minimal inference steps. LCMs are distilled from pre-trained latent diffusion
models (LDMs), requiring only ~32 A100 GPU training hours. This report further
extends LCMs&apos; potential in two aspects: First, by applying LoRA distillation to
Stable-Diffusion models including SD-V1.5, SSD-1B, and SDXL, we have expanded
LCM&apos;s scope to larger models with significantly less memory consumption,
achieving superior image generation quality. Second, we identify the LoRA
parameters obtained through LCM distillation as a universal Stable-Diffusion
acceleration module, named LCM-LoRA. LCM-LoRA can be directly plugged into
various Stable-Diffusion fine-tuned models or LoRAs without training, thus
representing a universally applicable accelerator for diverse image generation
tasks. Compared with previous numerical PF-ODE solvers such as DDIM,
DPM-Solver, LCM-LoRA can be viewed as a plug-in neural PF-ODE solver that
possesses strong generalization abilities. Project page:
https://github.com/luosiallen/latent-consistency-model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1&quot;&gt;Simian Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1&quot;&gt;Yiqin Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patil_S/0/1/0/all/0/1&quot;&gt;Suraj Patil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_D/0/1/0/all/0/1&quot;&gt;Daniel Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Platen_P/0/1/0/all/0/1&quot;&gt;Patrick von Platen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Passos_A/0/1/0/all/0/1&quot;&gt;Apolin&amp;#xe1;rio Passos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Longbo Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Hang Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05557">
<title>Exploiting Neural-Network Statistics for Low-Power DNN Inference. (arXiv:2311.05557v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05557</link>
<description rdf:parseType="Literal">&lt;p&gt;Specialized compute blocks have been developed for efficient DNN execution.
However, due to the vast amount of data and parameter movements, the
interconnects and on-chip memories form another bottleneck, impairing power and
performance. This work addresses this bottleneck by contributing a low-power
technique for edge-AI inference engines that combines overhead-free coding with
a statistical analysis of the data and parameters of neural networks. Our
approach reduces the interconnect and memory power consumption by up to 80% for
state-of-the-art benchmarks while providing additional power savings for the
compute blocks by up to 39%. These power improvements are achieved with no loss
of accuracy and negligible hardware cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bamberg_L/0/1/0/all/0/1&quot;&gt;Lennart Bamberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Najafi_A/0/1/0/all/0/1&quot;&gt;Ardalan Najafi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Ortiz_A/0/1/0/all/0/1&quot;&gt;Alberto Garcia-Ortiz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05559">
<title>Disentangling Quantum and Classical Contributions in Hybrid Quantum Machine Learning Architectures. (arXiv:2311.05559v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2311.05559</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum computing offers the potential for superior computational
capabilities, particularly for data-intensive tasks. However, the current state
of quantum hardware puts heavy restrictions on input size. To address this,
hybrid transfer learning solutions have been developed, merging pre-trained
classical models, capable of handling extensive inputs, with variational
quantum circuits. Yet, it remains unclear how much each component - classical
and quantum - contributes to the model&apos;s results. We propose a novel hybrid
architecture: instead of utilizing a pre-trained network for compression, we
employ an autoencoder to derive a compressed version of the input data. This
compressed data is then channeled through the encoder part of the autoencoder
to the quantum component. We assess our model&apos;s classification capabilities
against two state-of-the-art hybrid transfer learning architectures, two purely
classical architectures and one quantum architecture. Their accuracy is
compared across four datasets: Banknote Authentication, Breast Cancer
Wisconsin, MNIST digits, and AudioMNIST. Our research suggests that classical
components significantly influence classification in hybrid transfer learning,
a contribution often mistakenly ascribed to the quantum element. The
performance of our model aligns with that of a variational quantum circuit
using amplitude embedding, positioning it as a feasible alternative.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kolle_M/0/1/0/all/0/1&quot;&gt;Michael K&amp;#xf6;lle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Maurer_J/0/1/0/all/0/1&quot;&gt;Jonas Maurer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Altmann_P/0/1/0/all/0/1&quot;&gt;Philipp Altmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sunkel_L/0/1/0/all/0/1&quot;&gt;Leo S&amp;#xfc;nkel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Stein_J/0/1/0/all/0/1&quot;&gt;Jonas Stein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Linnhoff_Popien_C/0/1/0/all/0/1&quot;&gt;Claudia Linnhoff-Popien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05565">
<title>High-Performance Transformers for Table Structure Recognition Need Early Convolutions. (arXiv:2311.05565v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05565</link>
<description rdf:parseType="Literal">&lt;p&gt;Table structure recognition (TSR) aims to convert tabular images into a
machine-readable format, where a visual encoder extracts image features and a
textual decoder generates table-representing tokens. Existing approaches use
classic convolutional neural network (CNN) backbones for the visual encoder and
transformers for the textual decoder. However, this hybrid CNN-Transformer
architecture introduces a complex visual encoder that accounts for nearly half
of the total model parameters, markedly reduces both training and inference
speed, and hinders the potential for self-supervised learning in TSR. In this
work, we design a lightweight visual encoder for TSR without sacrificing
expressive power. We discover that a convolutional stem can match classic CNN
backbone performance, with a much simpler model. The convolutional stem strikes
an optimal balance between two crucial factors for high-performance TSR: a
higher receptive field (RF) ratio and a longer sequence length. This allows it
to &quot;see&quot; an appropriate portion of the table and &quot;store&quot; the complex table
structure within sufficient context length for the subsequent transformer. We
conducted reproducible ablation studies and open-sourced our code at
https://github.com/poloclub/tsr-convstem to enhance transparency, inspire
innovations, and facilitate fair comparisons in our domain as tables are a
promising modality for representation learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1&quot;&gt;ShengYun Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seongmin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaojing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balasubramaniyan_R/0/1/0/all/0/1&quot;&gt;Rajarajeswari Balasubramaniyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1&quot;&gt;Duen Horng Chau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05567">
<title>Exploring Emotion Expression Recognition in Older Adults Interacting with a Virtual Coach. (arXiv:2311.05567v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05567</link>
<description rdf:parseType="Literal">&lt;p&gt;The EMPATHIC project aimed to design an emotionally expressive virtual coach
capable of engaging healthy seniors to improve well-being and promote
independent aging. One of the core aspects of the system is its human sensing
capabilities, allowing for the perception of emotional states to provide a
personalized experience. This paper outlines the development of the emotion
expression recognition module of the virtual coach, encompassing data
collection, annotation design, and a first methodological approach, all
tailored to the project requirements. With the latter, we investigate the role
of various modalities, individually and combined, for discrete emotion
expression recognition in this context: speech from audio, and facial
expressions, gaze, and head dynamics from video. The collected corpus includes
users from Spain, France, and Norway, and was annotated separately for the
audio and video channels with distinct emotional labels, allowing for a
performance comparison across cultures and label types. Results confirm the
informative power of the modalities studied for the emotional categories
considered, with multimodal methods generally outperforming others (around 68%
accuracy with audio labels and 72-74% with video labels). The findings are
expected to contribute to the limited literature on emotion recognition applied
to older adults in conversational human-machine interaction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palmero_C/0/1/0/all/0/1&quot;&gt;Cristina Palmero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+deVelasco_M/0/1/0/all/0/1&quot;&gt;Mikel deVelasco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hmani_M/0/1/0/all/0/1&quot;&gt;Mohamed Amine Hmani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mtibaa_A/0/1/0/all/0/1&quot;&gt;Aymen Mtibaa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Letaifa_L/0/1/0/all/0/1&quot;&gt;Leila Ben Letaifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buch_Cardona_P/0/1/0/all/0/1&quot;&gt;Pau Buch-Cardona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Justo_R/0/1/0/all/0/1&quot;&gt;Raquel Justo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amorese_T/0/1/0/all/0/1&quot;&gt;Terry Amorese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_Fraile_E/0/1/0/all/0/1&quot;&gt;Eduardo Gonz&amp;#xe1;lez-Fraile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_Ruanova_B/0/1/0/all/0/1&quot;&gt;Bego&amp;#xf1;a Fern&amp;#xe1;ndez-Ruanova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenorio_Laranga_J/0/1/0/all/0/1&quot;&gt;Jofre Tenorio-Laranga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johansen_A/0/1/0/all/0/1&quot;&gt;Anna Torp Johansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_M/0/1/0/all/0/1&quot;&gt;Micaela Rodrigues da Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinussen_L/0/1/0/all/0/1&quot;&gt;Liva Jenny Martinussen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korsnes_M/0/1/0/all/0/1&quot;&gt;Maria Stylianou Korsnes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cordasco_G/0/1/0/all/0/1&quot;&gt;Gennaro Cordasco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esposito_A/0/1/0/all/0/1&quot;&gt;Anna Esposito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Yacoubi_M/0/1/0/all/0/1&quot;&gt;Mounim A. El-Yacoubi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petrovska_Delacretaz_D/0/1/0/all/0/1&quot;&gt;Dijana Petrovska-Delacr&amp;#xe9;taz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torres_M/0/1/0/all/0/1&quot;&gt;M. In&amp;#xe9;s Torres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escalera_S/0/1/0/all/0/1&quot;&gt;Sergio Escalera&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05573">
<title>Outlier-Robust Wasserstein DRO. (arXiv:2311.05573v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2311.05573</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributionally robust optimization (DRO) is an effective approach for
data-driven decision-making in the presence of uncertainty. Geometric
uncertainty due to sampling or localized perturbations of data points is
captured by Wasserstein DRO (WDRO), which seeks to learn a model that performs
uniformly well over a Wasserstein ball centered around the observed data
distribution. However, WDRO fails to account for non-geometric perturbations
such as adversarial outliers, which can greatly distort the Wasserstein
distance measurement and impede the learned model. We address this gap by
proposing a novel outlier-robust WDRO framework for decision-making under both
geometric (Wasserstein) perturbations and non-geometric (total variation (TV))
contamination that allows an $\varepsilon$-fraction of data to be arbitrarily
corrupted. We design an uncertainty set using a certain robust Wasserstein ball
that accounts for both perturbation types and derive minimax optimal excess
risk bounds for this procedure that explicitly capture the Wasserstein and TV
risks. We prove a strong duality result that enables tractable convex
reformulations and efficient computation of our outlier-robust WDRO problem.
When the loss function depends only on low-dimensional features of the data, we
eliminate certain dimension dependencies from the risk bounds that are
unavoidable in the general setting. Finally, we present experiments validating
our theory on standard regression and classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nietert_S/0/1/0/all/0/1&quot;&gt;Sloan Nietert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goldfeld_Z/0/1/0/all/0/1&quot;&gt;Ziv Goldfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shafiee_S/0/1/0/all/0/1&quot;&gt;Soroosh Shafiee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05579">
<title>SigScatNet: A Siamese + Scattering based Deep Learning Approach for Signature Forgery Detection and Similarity Assessment. (arXiv:2311.05579v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2311.05579</link>
<description rdf:parseType="Literal">&lt;p&gt;The surge in counterfeit signatures has inflicted widespread inconveniences
and formidable challenges for both individuals and organizations. This
groundbreaking research paper introduces SigScatNet, an innovative solution to
combat this issue by harnessing the potential of a Siamese deep learning
network, bolstered by Scattering wavelets, to detect signature forgery and
assess signature similarity. The Siamese Network empowers us to ascertain the
authenticity of signatures through a comprehensive similarity index, enabling
precise validation and comparison. Remarkably, the integration of Scattering
wavelets endows our model with exceptional efficiency, rendering it light
enough to operate seamlessly on cost-effective hardware systems. To validate
the efficacy of our approach, extensive experimentation was conducted on two
open-sourced datasets: the ICDAR SigComp Dutch dataset and the CEDAR dataset.
The experimental results demonstrate the practicality and resounding success of
our proposed SigScatNet, yielding an unparalleled Equal Error Rate of 3.689%
with the ICDAR SigComp Dutch dataset and an astonishing 0.0578% with the CEDAR
dataset. Through the implementation of SigScatNet, our research spearheads a
new state-of-the-art in signature analysis in terms of EER scores and
computational efficiency, offering an advanced and accessible solution for
detecting forgery and quantifying signature similarities. By employing
cutting-edge Siamese deep learning and Scattering wavelets, we provide a robust
framework that paves the way for secure and efficient signature verification
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chokshi_A/0/1/0/all/0/1&quot;&gt;Anmol Chokshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1&quot;&gt;Vansh Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhope_R/0/1/0/all/0/1&quot;&gt;Rajas Bhope&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhage_S/0/1/0/all/0/1&quot;&gt;Sudhir Dhage&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05584">
<title>Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations. (arXiv:2311.05584v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05584</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have emerged as powerful and general solutions
to many natural language tasks. However, many of the most important
applications of language generation are interactive, where an agent has to talk
to a person to reach a desired outcome. For example, a teacher might try to
understand their student&apos;s current comprehension level to tailor their
instruction accordingly, and a travel agent might ask questions of their
customer to understand their preferences in order to recommend activities they
might enjoy. LLMs trained with supervised fine-tuning or &quot;single-step&quot; RL, as
with standard RLHF, might struggle which tasks that require such goal-directed
behavior, since they are not trained to optimize for overall conversational
outcomes after multiple turns of interaction. In this work, we explore a new
method for adapting LLMs with RL for such goal-directed dialogue. Our key
insight is that, though LLMs might not effectively solve goal-directed dialogue
tasks out of the box, they can provide useful data for solving such tasks by
simulating suboptimal but human-like behaviors. Given a textual description of
a goal-directed dialogue task, we leverage LLMs to sample diverse synthetic
rollouts of hypothetical in-domain human-human interactions. Our algorithm then
utilizes this dataset with offline reinforcement learning to train an
interactive conversational agent that can optimize goal-directed objectives
over multiple turns. In effect, the LLM produces examples of possible
interactions, and RL then processes these examples to learn to perform more
optimal interactions. Empirically, we show that our proposed approach achieves
state-of-the-art performance in various goal-directed dialogue tasks that
include teaching and preference elicitation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1&quot;&gt;Joey Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca Dragan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05587">
<title>Bayesian Methods for Media Mix Modelling with shape and funnel effects. (arXiv:2311.05587v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05587</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, significant progress in generative AI has highlighted the
important role of physics-inspired models that utilize advanced mathematical
concepts based on fundamental physics principles to enhance artificial
intelligence capabilities. Among these models, those based on diffusion
equations have greatly improved image quality. This study aims to explore the
potential uses of Maxwell-Boltzmann equation, which forms the basis of the
kinetic theory of gases, and the Michaelis-Menten model in Marketing Mix
Modelling (MMM) applications. We propose incorporating these equations into
Hierarchical Bayesian models to analyse consumer behaviour in the context of
advertising. These equation sets excel in accurately describing the random
dynamics in complex systems like social interactions and consumer-advertising
interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marin_J/0/1/0/all/0/1&quot;&gt;Javier Marin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05589">
<title>A Coefficient Makes SVRG Effective. (arXiv:2311.05589v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05589</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic Variance Reduced Gradient (SVRG), introduced by Johnson &amp;amp; Zhang
(2013), is a theoretically compelling optimization method. However, as Defazio
&amp;amp; Bottou (2019) highlights, its effectiveness in deep learning is yet to be
proven. In this work, we demonstrate the potential of SVRG in optimizing
real-world neural networks. Our analysis finds that, for deeper networks, the
strength of the variance reduction term in SVRG should be smaller and decrease
as training progresses. Inspired by this, we introduce a multiplicative
coefficient $\alpha$ to control the strength and adjust it through a linear
decay schedule. We name our method $\alpha$-SVRG. Our results show
$\alpha$-SVRG better optimizes neural networks, consistently reducing training
loss compared to both baseline and the standard SVRG across various
architectures and image classification datasets. We hope our findings encourage
further exploration into variance reduction techniques in deep learning. Code
is available at https://github.com/davidyyd/alpha-SVRG.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1&quot;&gt;Yida Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhiqiu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1&quot;&gt;Trevor Darrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhuang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05596">
<title>LLM Augmented Hierarchical Agents. (arXiv:2311.05596v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05596</link>
<description rdf:parseType="Literal">&lt;p&gt;Solving long-horizon, temporally-extended tasks using Reinforcement Learning
(RL) is challenging, compounded by the common practice of learning without
prior knowledge (or tabula rasa learning). Humans can generate and execute
plans with temporally-extended actions and quickly learn to perform new tasks
because we almost never solve problems from scratch. We want autonomous agents
to have this same ability. Recently, LLMs have been shown to encode a
tremendous amount of knowledge about the world and to perform impressive
in-context learning and reasoning. However, using LLMs to solve real world
problems is hard because they are not grounded in the current task. In this
paper we exploit the planning capabilities of LLMs while using RL to provide
learning from the environment, resulting in a hierarchical agent that uses LLMs
to solve long-horizon tasks. Instead of completely relying on LLMs, they guide
a high-level policy, making learning significantly more sample efficient. This
approach is evaluated in simulation environments such as MiniGrid, SkillHack,
and Crafter, and on a real robot arm in block manipulation tasks. We show that
agents trained using our approach outperform other baselines methods and, once
trained, don&apos;t need access to LLMs during deployment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1&quot;&gt;Bharat Prakash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oates_T/0/1/0/all/0/1&quot;&gt;Tim Oates&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohsenin_T/0/1/0/all/0/1&quot;&gt;Tinoosh Mohsenin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05598">
<title>Sorting Out Quantum Monte Carlo. (arXiv:2311.05598v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05598</link>
<description rdf:parseType="Literal">&lt;p&gt;Molecular modeling at the quantum level requires choosing a parameterization
of the wavefunction that both respects the required particle symmetries, and is
scalable to systems of many particles. For the simulation of fermions, valid
parameterizations must be antisymmetric with respect to the exchange of
particles. Typically, antisymmetry is enforced by leveraging the anti-symmetry
of determinants with respect to the exchange of matrix rows, but this involves
computing a full determinant each time the wavefunction is evaluated. Instead,
we introduce a new antisymmetrization layer derived from sorting, the
$\textit{sortlet}$, which scales as $O(N \log N)$ with regards to the number of
particles -- in contrast to $O(N^3)$ for the determinant. We show numerically
that applying this anti-symmeterization layer on top of an attention based
neural-network backbone yields a flexible wavefunction parameterization capable
of reaching chemical accuracy when approximating the ground state of first-row
atoms and small molecules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richter_Powell_J/0/1/0/all/0/1&quot;&gt;Jack Richter-Powell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiede_L/0/1/0/all/0/1&quot;&gt;Luca Thiede&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asparu_Guzik_A/0/1/0/all/0/1&quot;&gt;Al&amp;#xe1;n Asparu-Guzik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1&quot;&gt;David Duvenaud&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05606">
<title>Diffusion-Generative Multi-Fidelity Learning for Physical Simulation. (arXiv:2311.05606v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05606</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-fidelity surrogate learning is important for physical simulation
related applications in that it avoids running numerical solvers from scratch,
which is known to be costly, and it uses multi-fidelity examples for training
and greatly reduces the cost of data collection. Despite the variety of
existing methods, they all build a model to map the input parameters outright
to the solution output. Inspired by the recent breakthrough in generative
models, we take an alternative view and consider the solution output as
generated from random noises. We develop a diffusion-generative multi-fidelity
(DGMF) learning method based on stochastic differential equations (SDE), where
the generation is a continuous denoising process. We propose a conditional
score model to control the solution generation by the input parameters and the
fidelity. By conditioning on additional inputs (temporal or spacial variables),
our model can efficiently learn and predict multi-dimensional solution arrays.
Our method naturally unifies discrete and continuous fidelity modeling. The
advantage of our method in several typical applications shows a promising new
direction for multi-fidelity learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shibo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1&quot;&gt;Shikai Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhe_S/0/1/0/all/0/1&quot;&gt;Shandian Zhe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05610">
<title>Efficient Parallelization Layouts for Large-Scale Distributed Model Training. (arXiv:2311.05610v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2311.05610</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficiently training large language models requires parallelizing across
hundreds of hardware accelerators and invoking various compute and memory
optimizations. When combined, many of these strategies have complex
interactions regarding the final training efficiency. Prior work tackling this
problem did not have access to the latest set of optimizations, such as
FlashAttention or sequence parallelism. In this work, we conduct a
comprehensive ablation study of possible training configurations for large
language models. We distill this large study into several key recommendations
for the most efficient training. For instance, we find that using a micro-batch
size of 1 usually enables the most efficient training layouts. Larger
micro-batch sizes necessitate activation checkpointing or higher degrees of
model parallelism and also lead to larger pipeline bubbles. Our most efficient
configurations enable us to achieve state-of-the-art training efficiency
results over a range of model sizes, most notably a Model FLOPs utilization of
70.5% when training a 13B model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hagemann_J/0/1/0/all/0/1&quot;&gt;Johannes Hagemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinbach_S/0/1/0/all/0/1&quot;&gt;Samuel Weinbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dobler_K/0/1/0/all/0/1&quot;&gt;Konstantin Dobler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schall_M/0/1/0/all/0/1&quot;&gt;Maximilian Schall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melo_G/0/1/0/all/0/1&quot;&gt;Gerard de Melo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1912.06708">
<title>A posteriori Trading-inspired Model-free Time Series Segmentation. (arXiv:1912.06708v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1912.06708</link>
<description rdf:parseType="Literal">&lt;p&gt;Within the context of multivariate time series segmentation this paper
proposes a method inspired by a posteriori optimal trading. After a
normalization step time series are treated channel-wise as surrogate stock
prices that can be traded optimally a posteriori in a virtual portfolio holding
either stock or cash. Linear transaction costs are interpreted as
hyperparameters for noise filtering. Resulting trading signals as well as
resulting trading signals obtained on the reversed time series are used for
unsupervised labeling, before a consensus over channels is reached that
determines segmentation time instants. The method is model-free such that no
model prescriptions for segments are made. Benefits of proposed approach
include simplicity, adaptability to a wide range of different shapes of time
series, and in particular computational efficiency that make it suitable for
big data. Performance is demonstrated on synthetic and real-world data,
including a large-scale dataset comprising a multivariate time series of
dimension 1000 and length 2709. Proposed method is compared to a popular
model-based bottom-up approach fitting piecewise affine models and to a
state-of-the-art model-based top-down approach fitting Gaussian models, and
found to be consistently faster while producing more intuitive results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Plessen_M/0/1/0/all/0/1&quot;&gt;Mogens Graf Plessen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.02171">
<title>Factorized Discriminant Analysis for Genetic Signatures of Neuronal Phenotypes. (arXiv:2010.02171v6 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2010.02171</link>
<description rdf:parseType="Literal">&lt;p&gt;Navigating the complex landscape of single-cell transcriptomic data presents
significant challenges. Central to this challenge is the identification of a
meaningful representation of high-dimensional gene expression patterns that
sheds light on the structural and functional properties of cell types. Pursuing
model interpretability and computational simplicity, we often look for a linear
transformation of the original data that aligns with key phenotypic features of
cells. In response to this need, we introduce factorized linear discriminant
analysis (FLDA), a novel method for linear dimensionality reduction. The crux
of FLDA lies in identifying a linear function of gene expression levels that is
highly correlated with one phenotypic feature while minimizing the influence of
others. To augment this method, we integrate it with a sparsity-based
regularization algorithm. This integration is crucial as it selects a subset of
genes pivotal to a specific phenotypic feature or a combination thereof. To
illustrate the effectiveness of FLDA, we apply it to transcriptomic datasets
from neurons in the Drosophila optic lobe. We demonstrate that FLDA not only
captures the inherent structural patterns aligned with phenotypic features but
also uncovers key genes associated with each phenotype.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Qiao_M/0/1/0/all/0/1&quot;&gt;Mu Qiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2010.13380">
<title>The training accuracy of two-layer neural networks: its estimation and understanding using random datasets. (arXiv:2010.13380v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2010.13380</link>
<description rdf:parseType="Literal">&lt;p&gt;Although the neural network (NN) technique plays an important role in machine
learning, understanding the mechanism of NN models and the transparency of deep
learning still require more basic research. In this study, we propose a novel
theory based on space partitioning to estimate the approximate training
accuracy for two-layer neural networks on random datasets without training.
There appear to be no other studies that have proposed a method to estimate
training accuracy without using input data and/or trained models. Our method
estimates the training accuracy for two-layer fully-connected neural networks
on two-class random datasets using only three arguments: the dimensionality of
inputs (d), the number of inputs (N), and the number of neurons in the hidden
layer (L). We have verified our method using real training accuracies in our
experiments. The results indicate that the method will work for any dimension,
and the proposed theory could extend also to estimate deeper NN models. The
main purpose of this paper is to understand the mechanism of NN models by the
approach of estimating training accuracy but not to analyze their
generalization nor their performance in real-world applications. This study may
provide a starting point for a new way for researchers to make progress on the
difficult problem of understanding deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_S/0/1/0/all/0/1&quot;&gt;Shuyue Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loew_M/0/1/0/all/0/1&quot;&gt;Murray Loew&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2012.11258">
<title>Difference Rewards Policy Gradients. (arXiv:2012.11258v2 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/2012.11258</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy gradient methods have become one of the most popular classes of
algorithms for multi-agent reinforcement learning. A key challenge, however,
that is not addressed by many of these methods is multi-agent credit
assignment: assessing an agent&apos;s contribution to the overall performance, which
is crucial for learning good policies. We propose a novel algorithm called
Dr.Reinforce that explicitly tackles this by combining difference rewards with
policy gradients to allow for learning decentralized policies when the reward
function is known. By differencing the reward function directly, Dr.Reinforce
avoids difficulties associated with learning the Q-function as done by
Counterfactual Multiagent Policy Gradients (COMA), a state-of-the-art
difference rewards method. For applications where the reward function is
unknown, we show the effectiveness of a version of Dr.Reinforce that learns an
additional reward network that is used to estimate the difference rewards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castellini_J/0/1/0/all/0/1&quot;&gt;Jacopo Castellini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devlin_S/0/1/0/all/0/1&quot;&gt;Sam Devlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliehoek_F/0/1/0/all/0/1&quot;&gt;Frans A. Oliehoek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savani_R/0/1/0/all/0/1&quot;&gt;Rahul Savani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.13913">
<title>Simple steps are all you need: Frank-Wolfe and generalized self-concordant functions. (arXiv:2105.13913v7 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2105.13913</link>
<description rdf:parseType="Literal">&lt;p&gt;Generalized self-concordance is a key property present in the objective
function of many important learning problems. We establish the convergence rate
of a simple Frank-Wolfe variant that uses the open-loop step size strategy
$\gamma_t = 2/(t+2)$, obtaining a $\mathcal{O}(1/t)$ convergence rate for this
class of functions in terms of primal gap and Frank-Wolfe gap, where $t$ is the
iteration count. This avoids the use of second-order information or the need to
estimate local smoothness parameters of previous work. We also show improved
convergence rates for various common cases, e.g., when the feasible region
under consideration is uniformly convex or polyhedral.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Carderera_A/0/1/0/all/0/1&quot;&gt;Alejandro Carderera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Besancon_M/0/1/0/all/0/1&quot;&gt;Mathieu Besan&amp;#xe7;on&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pokutta_S/0/1/0/all/0/1&quot;&gt;Sebastian Pokutta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.00906">
<title>Operator Splitting for Learning to Predict Equilibria in Convex Games. (arXiv:2106.00906v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.00906</link>
<description rdf:parseType="Literal">&lt;p&gt;Systems of competing agents can often be modeled as games. Assuming
rationality, the most likely outcomes are given by an equilibrium (e.g. a Nash
equilibrium). In many practical settings, games are influenced by context, i.e.
additional data beyond the control of any agent (e.g. weather for traffic and
fiscal policy for market economies). Often the exact game mechanics are
unknown, yet vast amounts of historical data consisting of (context,
equilibrium) pairs are available, raising the possibility of learning a solver
which predicts the equilibria given only the context. We introduce Nash Fixed
Point Networks (N-FPNs), a class of neural networks that naturally output
equilibria. Crucially, N- FPNs employ a constraint decoupling scheme to handle
complicated agent action sets while avoiding expensive projections.
Empirically, we find N-FPNs are compatible with the recently developed
Jacobian-Free Backpropagation technique for training implicit networks, making
them significantly faster and easier to train than prior models. Our
experiments show N-FPNs are capable of scaling to problems orders of magnitude
larger than existing learned game solvers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McKenzie_D/0/1/0/all/0/1&quot;&gt;Daniel McKenzie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heaton_H/0/1/0/all/0/1&quot;&gt;Howard Heaton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qiuwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fung_S/0/1/0/all/0/1&quot;&gt;Samy Wu Fung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1&quot;&gt;Stanley Osher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1&quot;&gt;Wotao Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2106.08992">
<title>On the approximation capability of GNNs in node classification/regression tasks. (arXiv:2106.08992v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2106.08992</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) are a broad class of connectionist models for
graph processing. Recent studies have shown that GNNs can approximate any
function on graphs, modulo the equivalence relation on graphs defined by the
Weisfeiler--Lehman (WL) test. However, these results suffer from some
limitations, both because they were derived using the Stone--Weierstrass
theorem -- which is existential in nature, -- and because they assume that the
target function to be approximated must be continuous. Furthermore, all current
results are dedicated to graph classification/regression tasks, where the GNN
must produce a single output for the whole graph, while also node
classification/regression problems, in which an output is returned for each
node, are very common. In this paper, we propose an alternative way to
demonstrate the approximation capability of GNNs that overcomes these
limitations. Indeed, we show that GNNs are universal approximators in
probability for node classification/regression tasks, as they can approximate
any measurable function that satisfies the 1--WL equivalence on nodes. The
proposed theoretical framework allows the approximation of generic
discontinuous target functions and also suggests the GNN architecture that can
reach a desired approximation. In addition, we provide a bound on the number of
the GNN layers required to achieve the desired degree of approximation, namely
$2r-1$, where $r$ is the maximum number of nodes for the graphs in the domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DInverno_G/0/1/0/all/0/1&quot;&gt;Giuseppe Alessio D&amp;#x27;Inverno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bianchini_M/0/1/0/all/0/1&quot;&gt;Monica Bianchini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sampoli_M/0/1/0/all/0/1&quot;&gt;Maria Lucia Sampoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scarselli_F/0/1/0/all/0/1&quot;&gt;Franco Scarselli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.11886">
<title>Logspace Reducibility From Secret Leakage Planted Clique. (arXiv:2107.11886v2 [cs.CC] UPDATED)</title>
<link>http://arxiv.org/abs/2107.11886</link>
<description rdf:parseType="Literal">&lt;p&gt;The planted clique problem is well-studied in the context of observing,
explaining, and predicting interesting computational phenomena associated with
statistical problems. When equating computational efficiency with the existence
of polynomial time algorithms, the computational hardness of (some variant of)
the planted clique problem can be used to infer the computational hardness of a
host of other statistical problems.
&lt;/p&gt;
&lt;p&gt;Is this ability to transfer computational hardness from (some variant of) the
planted clique problem to other statistical problems robust to changing our
notion of computational efficiency to space efficiency?
&lt;/p&gt;
&lt;p&gt;We answer this question affirmatively for three different statistical
problems, namely Sparse PCA, submatrix detection, and testing almost k-wise
independence. The key challenge is that space efficient randomized reductions
need to repeatedly access the randomness they use. Known reductions to these
problems are all randomized and need polynomially many random bits to
implement. Since we can not store polynomially many random bits in memory, it
is unclear how to implement these existing reductions space efficiently. There
are two ideas involved in circumventing this issue and implementing known
reductions to these problems space efficiently.
&lt;/p&gt;
&lt;p&gt;1. When solving statistical problems, we can use parts of the input itself as
randomness.
&lt;/p&gt;
&lt;p&gt;2. Secret leakage variants of the planted clique problem with appropriate
secret leakage can be more useful than the standard planted clique problem when
we want to use parts of the input as randomness.
&lt;/p&gt;
&lt;p&gt;(abstract shortened due to arxiv constraints)
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mardia_J/0/1/0/all/0/1&quot;&gt;Jay Mardia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.00115">
<title>Comparing Sequential Forecasters. (arXiv:2110.00115v6 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/2110.00115</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider two forecasters, each making a single prediction for a sequence of
events over time. We ask a relatively basic question: how might we compare
these forecasters, either online or post-hoc, while avoiding unverifiable
assumptions on how the forecasts and outcomes were generated? In this paper, we
present a rigorous answer to this question by designing novel sequential
inference procedures for estimating the time-varying difference in forecast
scores. To do this, we employ confidence sequences (CS), which are sequences of
confidence intervals that can be continuously monitored and are valid at
arbitrary data-dependent stopping times (&quot;anytime-valid&quot;). The widths of our
CSs are adaptive to the underlying variance of the score differences.
Underlying their construction is a game-theoretic statistical framework, in
which we further identify e-processes and p-processes for sequentially testing
a weak null hypothesis -- whether one forecaster outperforms another on average
(rather than always). Our methods do not make distributional assumptions on the
forecasts or outcomes; our main theorems apply to any bounded scores, and we
later provide alternative methods for unbounded scores. We empirically validate
our approaches by comparing real-world baseball and weather forecasters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choe_Y/0/1/0/all/0/1&quot;&gt;Yo Joong Choe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1&quot;&gt;Aaditya Ramdas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2110.01736">
<title>AdjointBackMapV2: Precise Reconstruction of Arbitrary CNN Unit&apos;s Activation via Adjoint Operators. (arXiv:2110.01736v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2110.01736</link>
<description rdf:parseType="Literal">&lt;p&gt;Adjoint operators have been found to be effective in the exploration of CNN&apos;s
inner workings [1]. However, the previous no-bias assumption restricted its
generalization. We overcome the restriction via embedding input images into an
extended normed space that includes bias in all CNN layers as part of the
extended space and propose an adjoint-operator-based algorithm that maps
high-level weights back to the extended input space for reconstructing an
effective hypersurface. Such hypersurface can be computed for an arbitrary unit
in the CNN, and we prove that this reconstructed hypersurface, when multiplied
by the original input (through an inner product), will precisely replicate the
output value of each unit. We show experimental results based on the CIFAR-10
and CIFAR-100 data sets where the proposed approach achieves near 0 activation
value reconstruction error.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_Q/0/1/0/all/0/1&quot;&gt;Qing Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_S/0/1/0/all/0/1&quot;&gt;Siu Wun Cheung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choe_Y/0/1/0/all/0/1&quot;&gt;Yoonsuck Choe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2203.16463">
<title>Perfectly Accurate Membership Inference by a Dishonest Central Server in Federated Learning. (arXiv:2203.16463v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2203.16463</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning is expected to provide strong privacy guarantees, as only
gradients or model parameters but no plain text training data is ever exchanged
either between the clients or between the clients and the central server. In
this paper, we challenge this claim by introducing a simple but still very
effective membership inference attack algorithm, which relies only on a single
training step. In contrast to the popular honest-but-curious model, we
investigate a framework with a dishonest central server. Our strategy is
applicable to models with ReLU activations and uses the properties of this
activation function to achieve perfect accuracy. Empirical evaluation on visual
classification tasks with MNIST, CIFAR10, CIFAR100 and CelebA datasets show
that our method provides perfect accuracy in identifying one sample in a
training set with thousands of samples. Occasional failures of our method lead
us to discover duplicate images in the CIFAR100 and CelebA datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pichler_G/0/1/0/all/0/1&quot;&gt;Georg Pichler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romanelli_M/0/1/0/all/0/1&quot;&gt;Marco Romanelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vega_L/0/1/0/all/0/1&quot;&gt;Leonardo Rey Vega&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1&quot;&gt;Pablo Piantanida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2204.07028">
<title>Exploring the Distributed Knowledge Congruence in Proxy-data-free Federated Distillation. (arXiv:2204.07028v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2204.07028</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is a privacy-preserving machine learning paradigm in
which the server periodically aggregates local model parameters from clients
without assembling their private data.
&lt;/p&gt;
&lt;p&gt;Constrained communication and personalization requirements pose severe
challenges to FL. Federated distillation (FD) is proposed to simultaneously
address the above two problems, which exchanges knowledge between the server
and clients, supporting heterogeneous local models while significantly reducing
communication overhead. However, most existing FD methods require a proxy
dataset, which is often unavailable in reality.
&lt;/p&gt;
&lt;p&gt;A few recent proxy-data-free FD approaches can eliminate the need for
additional public data, but suffer from remarkable discrepancy among local
knowledge due to client-side model heterogeneity, leading to ambiguous
representation on the server and inevitable accuracy degradation.
&lt;/p&gt;
&lt;p&gt;To tackle this issue, we propose a proxy-data-free FD algorithm based on
distributed knowledge congruence (FedDKC). FedDKC leverages well-designed
refinement strategies to narrow local knowledge differences into an acceptable
upper bound, so as to mitigate the negative effects of knowledge incongruence.
&lt;/p&gt;
&lt;p&gt;Specifically, from perspectives of peak probability and Shannon entropy of
local knowledge, we design kernel-based knowledge refinement (KKR) and
searching-based knowledge refinement (SKR) respectively, and theoretically
guarantee that the refined-local knowledge can satisfy an approximately-similar
distribution and be regarded as congruent.
&lt;/p&gt;
&lt;p&gt;Extensive experiments conducted on three common datasets demonstrate that our
proposed FedDKC significantly outperforms the state-of-the-art on various
heterogeneous settings while evidently improving the convergence speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Sheng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Min Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1&quot;&gt;Quyang Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Junbo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zeju Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qingxiang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.08913">
<title>Price Interpretability of Prediction Markets: A Convergence Analysis. (arXiv:2205.08913v2 [q-fin.TR] UPDATED)</title>
<link>http://arxiv.org/abs/2205.08913</link>
<description rdf:parseType="Literal">&lt;p&gt;Prediction markets are long known for prediction accuracy. This study
systematically explores the fundamental properties of prediction markets,
addressing questions about their information aggregation process and the
factors contributing to their remarkable efficacy. We propose a novel
multivariate utility (MU) based mechanism that unifies several existing
automated market-making schemes. Using this mechanism, we establish the
convergence results for markets comprised of risk-averse traders who have
heterogeneous beliefs and repeatedly interact with the market maker. We
demonstrate that the resulting limiting wealth distribution aligns with the
Pareto efficient frontier defined by the utilities of all market participants.
With the help of this result, we establish analytical and numerical results for
the limiting price in different market models. Specifically, we show that the
limiting price converges to the geometric mean of agent beliefs in exponential
utility-based markets. In risk-measure-based markets, we construct a family of
risk measures that satisfy the convergence criteria and prove that the price
can converge to a unique level represented by the weighted power mean of agent
beliefs. In broader markets with Constant Relative Risk Aversion (CRRA)
utilities, we reveal that the limiting price can be characterized by systems of
equations that encapsulate agent beliefs, risk parameters, and wealth. Despite
the potential impact of traders&apos; trading sequences on the limiting price, we
establish a price invariance result for markets with a large trader population.
Using this result, we propose an efficient approximation scheme for the
limiting price.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Yu_D/0/1/0/all/0/1&quot;&gt;Dian Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianjun Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Wu_W/0/1/0/all/0/1&quot;&gt;Weiping Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zizhuo Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.04798">
<title>A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs. (arXiv:2206.04798v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2206.04798</link>
<description rdf:parseType="Literal">&lt;p&gt;Reasoning on large-scale knowledge graphs has been long dominated by
embedding methods. While path-based methods possess the inductive capacity that
embeddings lack, their scalability is limited by the exponential number of
paths. Here we present A*Net, a scalable path-based method for knowledge graph
reasoning. Inspired by the A* algorithm for shortest path problems, our A*Net
learns a priority function to select important nodes and edges at each
iteration, to reduce time and memory footprint for both training and inference.
The ratio of selected nodes and edges can be specified to trade off between
performance and efficiency. Experiments on both transductive and inductive
knowledge graph reasoning benchmarks show that A*Net achieves competitive
performance with existing state-of-the-art path-based methods, while merely
visiting 10% nodes and 10% edges at each iteration. On a million-scale dataset
ogbl-wikikg2, A*Net not only achieves a new state-of-the-art result, but also
converges faster than embedding methods. A*Net is the first path-based method
for knowledge graph reasoning at such scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhaocheng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xinyu Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Galkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xhonneux_S/0/1/0/all/0/1&quot;&gt;Sophie Xhonneux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Ming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gazeau_M/0/1/0/all/0/1&quot;&gt;Maxime Gazeau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jian Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.00445">
<title>Interpreting Embedding Spaces by Conceptualization. (arXiv:2209.00445v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2209.00445</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the main methods for computational interpretation of a text is mapping
it into a vector in some embedding space. Such vectors can then be used for a
variety of textual processing tasks. Recently, most embedding spaces are a
product of training large language models (LLMs). One major drawback of this
type of representation is their incomprehensibility to humans. Understanding
the embedding space is crucial for several important needs, including the need
to debug the embedding method and compare it to alternatives, and the need to
detect biases hidden in the model. In this paper, we present a novel method of
understanding embeddings by transforming a latent embedding space into a
comprehensible conceptual space. We present an algorithm for deriving a
conceptual space with dynamic on-demand granularity. We devise a new evaluation
method, using either human rater or LLM-based raters, to show that the
conceptualized vectors indeed represent the semantics of the original latent
ones. We show the use of our method for various tasks, including comparing the
semantics of alternative models and tracing the layers of the LLM. The code is
available online
https://github.com/adiSimhi/Interpreting-Embedding-Spaces-by-Conceptualization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simhi_A/0/1/0/all/0/1&quot;&gt;Adi Simhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markovitch_S/0/1/0/all/0/1&quot;&gt;Shaul Markovitch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.05954">
<title>Automatically Score Tissue Images Like a Pathologist by Transfer Learning. (arXiv:2209.05954v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.05954</link>
<description rdf:parseType="Literal">&lt;p&gt;Cancer is the second leading cause of death in the world. Diagnosing cancer
early on can save many lives. Pathologists have to look at tissue microarray
(TMA) images manually to identify tumors, which can be time-consuming,
inconsistent and subjective. Existing automatic algorithms either have not
achieved the accuracy level of a pathologist or require substantial human
involvements. A major challenge is that TMA images with different shapes,
sizes, and locations can have the same score. Learning staining patterns in TMA
images requires a huge number of images, which are severely limited due to
privacy and regulation concerns in medical organizations. TMA images from
different cancer types may share certain common characteristics, but combining
them directly harms the accuracy due to heterogeneity in their staining
patterns. Transfer learning is an emerging learning paradigm that allows
borrowing strength from similar problems. However, existing approaches
typically require a large sample from similar learning problems, while TMA
images of different cancer types are often available in small sample size and
further existing algorithms are limited to transfer learning from one similar
problem. We propose a new transfer learning algorithm that could learn from
multiple related problems, where each problem has a small sample and can have a
substantially different distribution from the original one. The proposed
algorithm has made it possible to break the critical accuracy barrier (the 75%
accuracy level of pathologists), with a reported accuracy of 75.9% on breast
cancer TMA images from the Stanford Tissue Microarray Database. It is supported
by recent developments in transfer learning theory and empirical evidence in
clustering technology. This will allow pathologists to confidently adopt
automatic algorithms in recognizing tumors consistently with a higher accuracy
in real time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_I/0/1/0/all/0/1&quot;&gt;Iris Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.07932">
<title>Top-Tuning: a study on transfer learning for an efficient alternative to fine tuning for image classification with fast kernel methods. (arXiv:2209.07932v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.07932</link>
<description rdf:parseType="Literal">&lt;p&gt;The impressive performance of deep learning architectures is associated with
a massive increase in model complexity. Millions of parameters need to be
tuned, with training and inference time scaling accordingly, together with
energy consumption. But is massive fine-tuning always necessary? In this paper,
focusing on image classification, we consider a simple transfer learning
approach exploiting pre-trained convolutional features as input for a
fast-to-train kernel method. We refer to this approach as \textit{top-tuning}
since only the kernel classifier is trained on the target dataset. In our
study, we perform more than 3000 training processes focusing on 32 small to
medium-sized target datasets, a typical situation where transfer learning is
necessary. We show that the top-tuning approach provides comparable accuracy
with respect to fine-tuning, with a training time between one and two orders of
magnitude smaller. These results suggest that top-tuning is an effective
alternative to fine-tuning in small/medium datasets, being especially useful
when training time efficiency and computational resources saving are crucial.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alfano_P/0/1/0/all/0/1&quot;&gt;Paolo Didier Alfano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pastore_V/0/1/0/all/0/1&quot;&gt;Vito Paolo Pastore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosasco_L/0/1/0/all/0/1&quot;&gt;Lorenzo Rosasco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Odone_F/0/1/0/all/0/1&quot;&gt;Francesca Odone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.09134">
<title>Principled Pruning of Bayesian Neural Networks through Variational Free Energy Minimization. (arXiv:2210.09134v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.09134</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian model reduction provides an efficient approach for comparing the
performance of all nested sub-models of a model, without re-evaluating any of
these sub-models. Until now, Bayesian model reduction has been applied mainly
in the computational neuroscience community on simple models. In this paper, we
formulate and apply Bayesian model reduction to perform principled pruning of
Bayesian neural networks, based on variational free energy minimization. Direct
application of Bayesian model reduction, however, gives rise to approximation
errors. Therefore, a novel iterative pruning algorithm is presented to
alleviate the problems arising with naive Bayesian model reduction, as
supported experimentally on the publicly available UCI datasets for different
inference algorithms. This novel parameter pruning scheme solves the
shortcomings of current state-of-the-art pruning methods that are used by the
signal processing community. The proposed approach has a clear stopping
criterion and minimizes the same objective that is used during training. Next
to these benefits, our experiments indicate better model performance in
comparison to state-of-the-art pruning schemes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beckers_J/0/1/0/all/0/1&quot;&gt;Jim Beckers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erp_B/0/1/0/all/0/1&quot;&gt;Bart van Erp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Ziyue Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kondrashov_K/0/1/0/all/0/1&quot;&gt;Kirill Kondrashov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vries_B/0/1/0/all/0/1&quot;&gt;Bert de Vries&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.10962">
<title>Optimization on Manifolds via Graph Gaussian Processes. (arXiv:2210.10962v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2210.10962</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper integrates manifold learning techniques within a \emph{Gaussian
process upper confidence bound} algorithm to optimize an objective function on
a manifold. Our approach is motivated by applications where a full
representation of the manifold is not available and querying the objective is
expensive. We rely on a point cloud of manifold samples to define a graph
Gaussian process surrogate model for the objective. Query points are
sequentially chosen using the posterior distribution of the surrogate model
given all previous queries. We establish regret bounds in terms of the number
of queries and the size of the point cloud. Several numerical examples
complement the theory and illustrate the performance of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hwanwoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sanz_Alonso_D/0/1/0/all/0/1&quot;&gt;Daniel Sanz-Alonso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Ruiyi Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.03080">
<title>Straggler-Resilient Differentially-Private Decentralized Learning. (arXiv:2212.03080v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.03080</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the straggler problem in decentralized learning over a logical
ring while preserving user data privacy. Especially, we extend the recently
proposed framework of differential privacy (DP) amplification by
decentralization by Cyffers and Bellet to include overall training
latency--comprising both computation and communication latency. Analytical
results on both the convergence speed and the DP level are derived for both a
skipping scheme (which ignores the stragglers after a timeout) and a baseline
scheme that waits for each node to finish before the training continues. A
trade-off between overall training latency, accuracy, and privacy,
parameterized by the timeout of the skipping scheme, is identified and
empirically validated for logistic regression on a real-world dataset and for
image classification using the MNIST and CIFAR-10 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yakimenka_Y/0/1/0/all/0/1&quot;&gt;Yauhen Yakimenka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_C/0/1/0/all/0/1&quot;&gt;Chung-Wei Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hsuan-Yin Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosnes_E/0/1/0/all/0/1&quot;&gt;Eirik Rosnes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kliewer_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rg Kliewer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.09015">
<title>GAN-based Tabular Data Generator for Constructing Synopsis in Approximate Query Processing: Challenges and Solutions. (arXiv:2212.09015v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/2212.09015</link>
<description rdf:parseType="Literal">&lt;p&gt;In data-driven systems, data exploration is imperative for making real-time
decisions. However, big data is stored in massive databases that are difficult
to retrieve. Approximate Query Processing (AQP) is a technique for providing
approximate answers to aggregate queries based on a summary of the data
(synopsis) that closely replicates the behavior of the actual data, which can
be useful where an approximate answer to the queries would be acceptable in a
fraction of the real execution time. This study explores the novel utilization
of Generative Adversarial Networks (GANs) in the generation of tabular data
that can be employed in AQP for synopsis construction. We thoroughly
investigate the unique challenges posed by the synopsis construction process,
including maintaining data distribution characteristics, handling bounded
continuous and categorical data, and preserving semantic relationships and then
introduce the advancement of tabular GAN architectures that overcome these
challenges. Furthermore, we propose and validate a suite of statistical metrics
tailored for assessing the reliability of the GAN-generated synopses. Our
findings demonstrate that advanced GAN variations exhibit a promising capacity
to generate high-fidelity synopses, potentially transforming the efficiency and
effectiveness of AQP in data-driven systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fallahian_M/0/1/0/all/0/1&quot;&gt;Mohammadali Fallahian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dorodchi_M/0/1/0/all/0/1&quot;&gt;Mohsen Dorodchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreth_K/0/1/0/all/0/1&quot;&gt;Kyle Kreth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.02982">
<title>Why Batch Normalization Damage Federated Learning on Non-IID Data?. (arXiv:2301.02982v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.02982</link>
<description rdf:parseType="Literal">&lt;p&gt;As a promising distributed learning paradigm, federated learning (FL)
involves training deep neural network (DNN) models at the network edge while
protecting the privacy of the edge clients. To train a large-scale DNN model,
batch normalization (BN) has been regarded as a simple and effective means to
accelerate the training and improve the generalization capability. However,
recent findings indicate that BN can significantly impair the performance of FL
in the presence of non-i.i.d. data. While several FL algorithms have been
proposed to address this issue, their performance still falls significantly
when compared to the centralized scheme. Furthermore, none of them have
provided a theoretical explanation of how the BN damages the FL convergence. In
this paper, we present the first convergence analysis to show that under the
non-i.i.d. data, the mismatch between the local and global statistical
parameters in BN causes the gradient deviation between the local and global
models, which, as a result, slows down and biases the FL convergence. In view
of this, we develop a new FL algorithm that is tailored to BN, called FedTAN,
which is capable of achieving robust FL performance under a variety of data
distributions via iterative layer-wise parameter aggregation. Comprehensive
experimental results demonstrate the superiority of the proposed FedTAN over
existing baselines for training BN-based DNN models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanmeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1&quot;&gt;Qingjiang Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1&quot;&gt;Tsung-Hui Chang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.05785">
<title>Efficient Activation Function Optimization through Surrogate Modeling. (arXiv:2301.05785v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.05785</link>
<description rdf:parseType="Literal">&lt;p&gt;Carefully designed activation functions can improve the performance of neural
networks in many machine learning tasks. However, it is difficult for humans to
construct optimal activation functions, and current activation function search
algorithms are prohibitively expensive. This paper aims to improve the state of
the art through three steps: First, the benchmark datasets Act-Bench-CNN,
Act-Bench-ResNet, and Act-Bench-ViT were created by training convolutional,
residual, and vision transformer architectures from scratch with 2,913
systematically generated activation functions. Second, a characterization of
the benchmark space was developed, leading to a new surrogate-based method for
optimization. More specifically, the spectrum of the Fisher information matrix
associated with the model&apos;s predictive distribution at initialization and the
activation function&apos;s output distribution were found to be highly predictive of
performance. Third, the surrogate was used to discover improved activation
functions in several real-world tasks, with a surprising finding: a sigmoidal
design that outperformed all other activation functions was discovered,
challenging the status quo of always using rectifier nonlinearities in deep
learning. Each of these steps is a contribution in its own right; together they
serve as a practical and theoretical foundation for further research on
activation function optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bingham_G/0/1/0/all/0/1&quot;&gt;Garrett Bingham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1&quot;&gt;Risto Miikkulainen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.09633">
<title>Prediction-Powered Inference. (arXiv:2301.09633v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2301.09633</link>
<description rdf:parseType="Literal">&lt;p&gt;Prediction-powered inference is a framework for performing valid statistical
inference when an experimental dataset is supplemented with predictions from a
machine-learning system. The framework yields simple algorithms for computing
provably valid confidence intervals for quantities such as means, quantiles,
and linear and logistic regression coefficients, without making any assumptions
on the machine-learning algorithm that supplies the predictions. Furthermore,
more accurate predictions translate to smaller confidence intervals.
Prediction-powered inference could enable researchers to draw valid and more
data-efficient conclusions using machine learning. The benefits of
prediction-powered inference are demonstrated with datasets from proteomics,
astronomy, genomics, remote sensing, census analysis, and ecology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Angelopoulos_A/0/1/0/all/0/1&quot;&gt;Anastasios N. Angelopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bates_S/0/1/0/all/0/1&quot;&gt;Stephen Bates&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fannjiang_C/0/1/0/all/0/1&quot;&gt;Clara Fannjiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zrnic_T/0/1/0/all/0/1&quot;&gt;Tijana Zrnic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.09734">
<title>Topological Learning in Multi-Class Data Sets. (arXiv:2301.09734v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.09734</link>
<description rdf:parseType="Literal">&lt;p&gt;We specialize techniques from topological data analysis to the problem of
characterizing the topological complexity (as defined in the body of the paper)
of a multi-class data set. As a by-product, a topological classifier is defined
that uses an open sub-covering of the data set. This sub-covering can be used
to construct a simplicial complex whose topological features (e.g., Betti
numbers) provide information about the classification problem. We use these
topological constructs to study the impact of topological complexity on
learning in feedforward deep neural networks (DNNs). We hypothesize that
topological complexity is negatively correlated with the ability of a fully
connected feedforward deep neural network to learn to classify data correctly.
We evaluate our topological classification algorithm on multiple constructed
and open source data sets. We also validate our hypothesis regarding the
relationship between topological complexity and learning in DNN&apos;s on multiple
data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffin_C/0/1/0/all/0/1&quot;&gt;Christopher Griffin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karn_T/0/1/0/all/0/1&quot;&gt;Trevor Karn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Apple_B/0/1/0/all/0/1&quot;&gt;Benjamin Apple&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.10171">
<title>Spectral Cross-Domain Neural Network with Soft-adaptive Threshold Spectral Enhancement. (arXiv:2301.10171v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.10171</link>
<description rdf:parseType="Literal">&lt;p&gt;Electrocardiography (ECG) signals can be considered as multi-variable
time-series. The state-of-the-art ECG data classification approaches, based on
either feature engineering or deep learning techniques, treat separately
spectral and time domains in machine learning systems. No spectral-time domain
communication mechanism inside the classifier model can be found in current
approaches, leading to difficulties in identifying complex ECG forms. In this
paper, we proposed a novel deep learning model named Spectral Cross-domain
neural network (SCDNN) with a new block called Soft-adaptive threshold spectral
enhancement (SATSE), to simultaneously reveal the key information embedded in
spectral and time domains inside the neural network. More precisely, the
domain-cross information is captured by a general Convolutional neural network
(CNN) backbone, and different information sources are merged by a self-adaptive
mechanism to mine the connection between time and spectral domains. In SATSE,
the knowledge from time and spectral domains is extracted via the Fast Fourier
Transformation (FFT) with soft trainable thresholds in modified Sigmoid
functions. The proposed SCDNN is tested with several classification tasks
implemented on the public ECG databases \textit{PTB-XL} and \textit{MIT-BIH}.
SCDNN outperforms the state-of-the-art approaches with a low computational cost
regarding a variety of metrics in all classification tasks on both databases,
by finding appropriate domains from the infinite spectral mapping. The
convergence of the trainable thresholds in the spectral domain is also
numerically investigated in this paper. The robust performance of SCDNN
provides a new perspective to exploit knowledge across deep learning models
from time and spectral domains. The repository can be found:
https://github.com/DL-WG/SCDNN-TS
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Che Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Sibo Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1&quot;&gt;Weiping Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arcucci_R/0/1/0/all/0/1&quot;&gt;Rossella Arcucci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.12534">
<title>Vicarious Offense and Noise Audit of Offensive Speech Classifiers: Unifying Human and Machine Disagreement on What is Offensive. (arXiv:2301.12534v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2301.12534</link>
<description rdf:parseType="Literal">&lt;p&gt;Offensive speech detection is a key component of content moderation. However,
what is offensive can be highly subjective. This paper investigates how machine
and human moderators disagree on what is offensive when it comes to real-world
social web political discourse. We show that (1) there is extensive
disagreement among the moderators (humans and machines); and (2) human and
large-language-model classifiers are unable to predict how other human raters
will respond, based on their political leanings. For (1), we conduct a noise
audit at an unprecedented scale that combines both machine and human responses.
For (2), we introduce a first-of-its-kind dataset of vicarious offense. Our
noise audit reveals that moderation outcomes vary wildly across different
machine moderators. Our experiments with human moderators suggest that
political leanings combined with sensitive issues affect both first-person and
vicarious offense. The dataset is available through
https://github.com/Homan-Lab/voiced.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weerasooriya_T/0/1/0/all/0/1&quot;&gt;Tharindu Cyril Weerasooriya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1&quot;&gt;Sujan Dutta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1&quot;&gt;Tharindu Ranasinghe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1&quot;&gt;Marcos Zampieri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Homan_C/0/1/0/all/0/1&quot;&gt;Christopher M. Homan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+KhudaBukhsh_A/0/1/0/all/0/1&quot;&gt;Ashiqur R. KhudaBukhsh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.08688">
<title>Efficient Classification of SARS-CoV-2 Spike Sequences Using Federated Learning. (arXiv:2302.08688v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.08688</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a federated learning (FL) approach to train an AI model
for SARS-Cov-2 variant classification. We analyze the SARS-CoV-2 spike
sequences in a distributed way, without data sharing, to detect different
variants of this rapidly mutating coronavirus. Our method maintains the
confidentiality of local data (that could be stored in different locations) yet
allows us to reliably detect and identify different known and unknown variants
of the novel coronavirus SARS-CoV-2. Using the proposed approach, we achieve an
overall accuracy of $93\%$ on the coronavirus variant identification task. We
also provide details regarding how the proposed model follows the main laws of
federated learning, such as Laws of data ownership, data privacy, model
aggregation, and model heterogeneity. Since the proposed model is distributed,
it could scale on ``Big Data&apos;&apos; easily. We plan to use this proof-of-concept to
implement a privacy-preserving pandemic response strategy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chourasia_P/0/1/0/all/0/1&quot;&gt;Prakash Chourasia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murad_T/0/1/0/all/0/1&quot;&gt;Taslim Murad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tayebi_Z/0/1/0/all/0/1&quot;&gt;Zahra Tayebi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1&quot;&gt;Sarwan Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_I/0/1/0/all/0/1&quot;&gt;Imdad Ullah Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patterson_M/0/1/0/all/0/1&quot;&gt;Murray Patterson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.10093">
<title>Progressive Ensemble Distillation: Building Ensembles for Efficient Inference. (arXiv:2302.10093v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.10093</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of progressive ensemble distillation: Given a large,
pretrained teacher model $g$, we seek to decompose the model into smaller,
low-inference cost student models $f_i$, such that progressively evaluating
additional models in this ensemble leads to improved predictions. The resulting
ensemble allows for flexibly tuning accuracy vs. inference cost at runtime,
which is useful for a number of applications in on-device inference. The method
we propose, B-DISTIL , relies on an algorithmic procedure that uses function
composition over intermediate activations to construct expressive ensembles
with similar performance as $g$ , but with smaller student models. We
demonstrate the effectiveness of B-DISTIL by decomposing pretrained models
across standard image, speech, and sensor datasets. We also provide theoretical
guarantees in terms of convergence and generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dennis_D/0/1/0/all/0/1&quot;&gt;Don Kurian Dennis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shetty_A/0/1/0/all/0/1&quot;&gt;Abhishek Shetty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sevekari_A/0/1/0/all/0/1&quot;&gt;Anish Sevekari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koishida_K/0/1/0/all/0/1&quot;&gt;Kazuhito Koishida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1&quot;&gt;Virginia Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.10158">
<title>Sparse PCA Beyond Covariance Thresholding. (arXiv:2302.10158v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.10158</link>
<description rdf:parseType="Literal">&lt;p&gt;In the Wishart model for sparse PCA we are given $n$ samples $Y_1,\ldots,
Y_n$ drawn independently from a $d$-dimensional Gaussian distribution $N({0, Id
+ \beta vv^\top})$, where $\beta &amp;gt; 0$ and $v\in \mathbb{R}^d$ is a $k$-sparse
unit vector, and we wish to recover $v$ (up to sign).
&lt;/p&gt;
&lt;p&gt;We show that if $n \ge \Omega(d)$, then for every $t \ll k$ there exists an
algorithm running in time $n\cdot d^{O(t)}$ that solves this problem as long as
\[ \beta \gtrsim \frac{k}{\sqrt{nt}}\sqrt{\ln({2 + td/k^2})}\,. \] Prior to
this work, the best polynomial time algorithm in the regime $k\approx
\sqrt{d}$, called \emph{Covariance Thresholding} (proposed in [KNV15a] and
analyzed in [DM14]), required $\beta \gtrsim \frac{k}{\sqrt{n}}\sqrt{\ln({2 +
d/k^2})}$. For large enough constant $t$ our algorithm runs in polynomial time
and has better guarantees than Covariance Thresholding. Previously known
algorithms with such guarantees required quasi-polynomial time $d^{O(\log d)}$.
&lt;/p&gt;
&lt;p&gt;In addition, we show that our techniques work with sparse PCA with
adversarial perturbations studied in [dKNS20]. This model generalizes not only
sparse PCA, but also other problems studied in prior works, including the
sparse planted vector problem. As a consequence, we provide polynomial time
algorithms for the sparse planted vector problem that have better guarantees
than the state of the art in some regimes.
&lt;/p&gt;
&lt;p&gt;Our approach also works with the Wigner model for sparse PCA. Moreover, we
show that it is possible to combine our techniques with recent results on
sparse PCA with symmetric heavy-tailed noise [dNNS22]. In particular, in the
regime $k \approx \sqrt{d}$ we get the first polynomial time algorithm that
works with symmetric heavy-tailed noise, while the algorithm from [dNNS22].
requires quasi-polynomial time in these settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Novikov_G/0/1/0/all/0/1&quot;&gt;Gleb Novikov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.01353">
<title>Penalising the biases in norm regularisation enforces sparsity. (arXiv:2303.01353v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2303.01353</link>
<description rdf:parseType="Literal">&lt;p&gt;Controlling the parameters&apos; norm often yields good generalisation when
training neural networks. Beyond simple intuitions, the relation between
regularising parameters&apos; norm and obtained estimators remains theoretically
misunderstood. For one hidden ReLU layer networks with unidimensional data,
this work shows the parameters&apos; norm required to represent a function is given
by the total variation of its second derivative, weighted by a $\sqrt{1+x^2}$
factor. Notably, this weighting factor disappears when the norm of bias terms
is not regularised. The presence of this additional weighting factor is of
utmost significance as it is shown to enforce the uniqueness and sparsity (in
the number of kinks) of the minimal norm interpolator. Conversely, omitting the
bias&apos; norm allows for non-sparse solutions. Penalising the bias terms in the
regularisation, either explicitly or implicitly, thus leads to sparse
estimators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boursier_E/0/1/0/all/0/1&quot;&gt;Etienne Boursier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flammarion_N/0/1/0/all/0/1&quot;&gt;Nicolas Flammarion&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.02738">
<title>Uncoupled and Convergent Learning in Two-Player Zero-Sum Markov Games with Bandit Feedback. (arXiv:2303.02738v2 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/2303.02738</link>
<description rdf:parseType="Literal">&lt;p&gt;We revisit the problem of learning in two-player zero-sum Markov games,
focusing on developing an algorithm that is uncoupled, convergent, and
rational, with non-asymptotic convergence rates. We start from the case of
stateless matrix game with bandit feedback as a warm-up, showing an
$O(t^{-\frac{1}{8}})$ last-iterate convergence rate. To the best of our
knowledge, this is the first result that obtains finite last-iterate
convergence rate given access to only bandit feedback. We extend our result to
the case of irreducible Markov games, providing a last-iterate convergence rate
of $O(t^{-\frac{1}{9+\varepsilon}})$ for any $\varepsilon&amp;gt;0$. Finally, we study
Markov games without any assumptions on the dynamics, and show a path
convergence rate, which is a new notion of convergence we defined, of
$O(t^{-\frac{1}{10}})$. Our algorithm removes the coordination and prior
knowledge requirement of [Wei et al., 2021], which pursued the same goals as us
for irreducible Markov games. Our algorithm is related to [Chen et al., 2021,
Cen et al., 2021] and also builds on the entropy regularization technique.
However, we remove their requirement of communications on the entropy values,
making our algorithm entirely uncoupled.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1&quot;&gt;Yang Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Haipeng Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1&quot;&gt;Chen-Yu Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1&quot;&gt;Weiqiang Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.05828">
<title>Adapting Contrastive Language-Image Pretrained (CLIP) Models for Out-of-Distribution Detection. (arXiv:2303.05828v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.05828</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a comprehensive experimental study on pretrained feature
extractors for visual out-of-distribution (OOD) detection, focusing on adapting
contrastive language-image pretrained (CLIP) models. Without fine-tuning on the
training data, we are able to establish a positive correlation ($R^2\geq0.92$)
between in-distribution classification and unsupervised OOD detection for CLIP
models in $4$ benchmarks. We further propose a new simple and scalable method
called \textit{pseudo-label probing} (PLP) that adapts vision-language models
for OOD detection. Given a set of label names of the training set, PLP trains a
linear layer using the pseudo-labels derived from the text encoder of CLIP. To
test the OOD detection robustness of pretrained models, we develop a novel
feature-based adversarial OOD data manipulation approach to create adversarial
samples. Intriguingly, we show that (i) PLP outperforms the previous
state-of-the-art \citep{ming2022mcm} on all $5$ large-scale benchmarks based on
ImageNet, specifically by an average AUROC gain of 3.4\% using the largest CLIP
model (ViT-G), (ii) we show that linear probing outperforms fine-tuning by
large margins for CLIP architectures (i.e. CLIP ViT-H achieves a mean gain of
7.3\% AUROC on average on all ImageNet-based benchmarks), and (iii)
billion-parameter CLIP models still fail at detecting adversarially manipulated
OOD images. The code and adversarially created datasets will be made publicly
available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adaloglou_N/0/1/0/all/0/1&quot;&gt;Nikolas Adaloglou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michels_F/0/1/0/all/0/1&quot;&gt;Felix Michels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaiser_T/0/1/0/all/0/1&quot;&gt;Tim Kaiser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kollmann_M/0/1/0/all/0/1&quot;&gt;Markus Kollmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.08789">
<title>PLEX: Making the Most of the Available Data for Robotic Manipulation Pretraining. (arXiv:2303.08789v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2303.08789</link>
<description rdf:parseType="Literal">&lt;p&gt;A rich representation is key to general robotic manipulation, but existing
approaches to representation learning require large amounts of multimodal
demonstrations. In this work we propose PLEX, a transformer-based architecture
that learns from a small amount of task-agnostic visuomotor trajectories and a
much larger amount of task-conditioned object manipulation videos -- a type of
data available in quantity. PLEX uses visuomotor trajectories to induce a
latent feature space and to learn task-agnostic manipulation routines, while
diverse video-only demonstrations teach PLEX how to plan in the induced latent
feature space for a wide variety of tasks. Experiments showcase PLEX&apos;s
generalization on Meta-World and SOTA performance in challenging Robosuite
environments. In particular, using relative positional encoding in PLEX&apos;s
transformers greatly helps in low-data regimes of learning from human-collected
demonstrations. The paper&apos;s accompanying code and data are available at
https://microsoft.github.io/PLEX.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_G/0/1/0/all/0/1&quot;&gt;Garrett Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Ching-An Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loynd_R/0/1/0/all/0/1&quot;&gt;Ricky Loynd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frujeri_F/0/1/0/all/0/1&quot;&gt;Felipe Vieira Frujeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vineet_V/0/1/0/all/0/1&quot;&gt;Vibhav Vineet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jalobeanu_M/0/1/0/all/0/1&quot;&gt;Mihai Jalobeanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1&quot;&gt;Andrey Kolobov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.00549">
<title>Variational Denoising for Variational Quantum Eigensolver. (arXiv:2304.00549v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2304.00549</link>
<description rdf:parseType="Literal">&lt;p&gt;The variational quantum eigensolver (VQE) is a hybrid algorithm that has the
potential to provide a quantum advantage in practical chemistry problems that
are currently intractable on classical computers. VQE trains parameterized
quantum circuits using a classical optimizer to approximate the eigenvalues and
eigenstates of a given Hamiltonian. However, VQE faces challenges in
task-specific design and machine-specific architecture, particularly when
running on noisy quantum devices. This can have a negative impact on its
trainability, accuracy, and efficiency, resulting in noisy quantum data. We
propose variational denoising, an unsupervised learning method that employs a
parameterized quantum neural network to improve the solution of VQE by learning
from noisy VQE outputs. Our approach can significantly decrease energy
estimation errors and increase fidelities with ground states compared to noisy
input data for the $\text{H}_2$, LiH, and $\text{BeH}_2$ molecular
Hamiltonians, and the transverse field Ising model. Surprisingly, it only
requires noisy data for training. Variational denoising can be integrated into
quantum hardware, increasing its versatility as an end-to-end quantum
processing for quantum data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tran_Q/0/1/0/all/0/1&quot;&gt;Quoc Hoan Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kikuchi_S/0/1/0/all/0/1&quot;&gt;Shinji Kikuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Oshima_H/0/1/0/all/0/1&quot;&gt;Hirotaka Oshima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.04234">
<title>Variational operator learning: A unified paradigm marrying training neural operators and solving partial differential equations. (arXiv:2304.04234v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.04234</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural operators as novel neural architectures for fast approximating
solution operators of partial differential equations (PDEs), have shown
considerable promise for future scientific computing. However, the mainstream
of training neural operators is still data-driven, which needs an expensive
ground-truth dataset from various sources (e.g., solving PDEs&apos; samples with the
conventional solvers, real-world experiments) in addition to training stage
costs. From a computational perspective, marrying operator learning and
specific domain knowledge to solve PDEs is an essential step in reducing
dataset costs and label-free learning. We propose a novel paradigm that
provides a unified framework of training neural operators and solving PDEs with
the variational form, which we refer to as the variational operator learning
(VOL). Ritz and Galerkin approach with finite element discretization are
developed for VOL to achieve matrix-free approximation of system functional and
residual, then direct minimization and iterative update are proposed as two
optimization strategies for VOL. Various types of experiments based on
reasonable benchmarks about variable heat source, Darcy flow, and variable
stiffness elasticity are conducted to demonstrate the effectiveness of VOL.
With a label-free training set and a 5-label-only shift set, VOL learns
solution operators with its test errors decreasing in a power law with respect
to the amount of unlabeled data. To the best of the authors&apos; knowledge, this is
the first study that integrates the perspectives of the weak form and efficient
iterative methods for solving sparse linear systems into the end-to-end
operator learning task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1&quot;&gt;Tengfei Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Dachuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_P/0/1/0/all/0/1&quot;&gt;Peng Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bo Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.07687">
<title>MLRegTest: A Benchmark for the Machine Learning of Regular Languages. (arXiv:2304.07687v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.07687</link>
<description rdf:parseType="Literal">&lt;p&gt;Evaluating machine learning (ML) systems on their ability to learn known
classifiers allows fine-grained examination of the patterns they can learn,
which builds confidence when they are applied to the learning of unknown
classifiers. This article presents a new benchmark for ML systems on sequence
classification called MLRegTest, which contains training, development, and test
sets from 1,800 regular languages. Different kinds of formal languages
represent different kinds of long-distance dependencies, and correctly
identifying long-distance dependencies in sequences is a known challenge for ML
systems to generalize successfully. MLRegTest organizes its languages according
to their logical complexity (monadic second order, first order, propositional,
or monomial expressions) and the kind of logical literals (string, tier-string,
subsequence, or combinations thereof). The logical complexity and choice of
literal provides a systematic way to understand different kinds of
long-distance dependencies in regular languages, and therefore to understand
the capacities of different ML systems to learn such long-distance
dependencies. Finally, the performance of different neural networks (simple
RNN, LSTM, GRU, transformer) on MLRegTest is examined. The main conclusion is
that their performance depends significantly on the kind of test set, the class
of language, and the neural network architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poel_S/0/1/0/all/0/1&quot;&gt;Sam van der Poel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lambert_D/0/1/0/all/0/1&quot;&gt;Dakotah Lambert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kostyszyn_K/0/1/0/all/0/1&quot;&gt;Kalina Kostyszyn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Tiantian Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_R/0/1/0/all/0/1&quot;&gt;Rahul Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andersen_D/0/1/0/all/0/1&quot;&gt;Derek Andersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chau_J/0/1/0/all/0/1&quot;&gt;Joanne Chau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peterson_E/0/1/0/all/0/1&quot;&gt;Emily Peterson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clair_C/0/1/0/all/0/1&quot;&gt;Cody St. Clair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fodor_P/0/1/0/all/0/1&quot;&gt;Paul Fodor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shibata_C/0/1/0/all/0/1&quot;&gt;Chihiro Shibata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinz_J/0/1/0/all/0/1&quot;&gt;Jeffrey Heinz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.01588">
<title>Revisiting Gradient Clipping: Stochastic bias and tight convergence guarantees. (arXiv:2305.01588v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.01588</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient clipping is a popular modification to standard (stochastic) gradient
descent, at every iteration limiting the gradient norm to a certain value $c
&amp;gt;0$. It is widely used for example for stabilizing the training of deep
learning models (Goodfellow et al., 2016), or for enforcing differential
privacy (Abadi et al., 2016). Despite popularity and simplicity of the clipping
mechanism, its convergence guarantees often require specific values of $c$ and
strong noise assumptions.
&lt;/p&gt;
&lt;p&gt;In this paper, we give convergence guarantees that show precise dependence on
arbitrary clipping thresholds $c$ and show that our guarantees are tight with
both deterministic and stochastic gradients. In particular, we show that (i)
for deterministic gradient descent, the clipping threshold only affects the
higher-order terms of convergence, (ii) in the stochastic setting convergence
to the true optimum cannot be guaranteed under the standard noise assumption,
even under arbitrary small step-sizes. We give matching upper and lower bounds
for convergence of the gradient norm when running clipped SGD, and illustrate
these results with experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koloskova_A/0/1/0/all/0/1&quot;&gt;Anastasia Koloskova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendrikx_H/0/1/0/all/0/1&quot;&gt;Hadrien Hendrikx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1&quot;&gt;Sebastian U. Stich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.10564">
<title>Counterfactually Comparing Abstaining Classifiers. (arXiv:2305.10564v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2305.10564</link>
<description rdf:parseType="Literal">&lt;p&gt;Abstaining classifiers have the option to abstain from making predictions on
inputs that they are unsure about. These classifiers are becoming increasingly
popular in high-stakes decision-making problems, as they can withhold uncertain
predictions to improve their reliability and safety. When evaluating black-box
abstaining classifier(s), however, we lack a principled approach that accounts
for what the classifier would have predicted on its abstentions. These missing
predictions matter when they can eventually be utilized, either directly or as
a backup option in a failure mode. In this paper, we introduce a novel approach
and perspective to the problem of evaluating and comparing abstaining
classifiers by treating abstentions as missing data. Our evaluation approach is
centered around defining the counterfactual score of an abstaining classifier,
defined as the expected performance of the classifier had it not been allowed
to abstain. We specify the conditions under which the counterfactual score is
identifiable: if the abstentions are stochastic, and if the evaluation data is
independent of the training data (ensuring that the predictions are missing at
random), then the score is identifiable. Note that, if abstentions are
deterministic, then the score is unidentifiable because the classifier can
perform arbitrarily poorly on its abstentions. Leveraging tools from
observational causal inference, we then develop nonparametric and doubly robust
methods to efficiently estimate this quantity under identification. Our
approach is examined in both simulated and real data experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choe_Y/0/1/0/all/0/1&quot;&gt;Yo Joong Choe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gangrade_A/0/1/0/all/0/1&quot;&gt;Aditya Gangrade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1&quot;&gt;Aaditya Ramdas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12396">
<title>Joint Feature and Differentiable $ k $-NN Graph Learning using Dirichlet Energy. (arXiv:2305.12396v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12396</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature selection (FS) plays an important role in machine learning, which
extracts important features and accelerates the learning process. In this
paper, we propose a deep FS method that simultaneously conducts feature
selection and differentiable $ k $-NN graph learning based on the Dirichlet
Energy. The Dirichlet Energy identifies important features by measuring their
smoothness on the graph structure, and facilitates the learning of a new graph
that reflects the inherent structure in new feature subspace. We employ Optimal
Transport theory to address the non-differentiability issue of learning $ k
$-NN graphs in neural networks, which theoretically makes our method applicable
to other graph neural networks for dynamic graph learning. Furthermore, the
proposed framework is interpretable, since all modules are designed
algorithmically. We validate the effectiveness of our model with extensive
experiments on both synthetic and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1&quot;&gt;Lei Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Rong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_F/0/1/0/all/0/1&quot;&gt;Feiping Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xuelong Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15001">
<title>Contrastive Training of Complex-Valued Autoencoders for Object Discovery. (arXiv:2305.15001v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15001</link>
<description rdf:parseType="Literal">&lt;p&gt;Current state-of-the-art object-centric models use slots and attention-based
routing for binding. However, this class of models has several conceptual
limitations: the number of slots is hardwired; all slots have equal capacity;
training has high computational cost; there are no object-level relational
factors within slots. Synchrony-based models in principle can address these
limitations by using complex-valued activations which store binding information
in their phase components. However, working examples of such synchrony-based
models have been developed only very recently, and are still limited to toy
grayscale datasets and simultaneous storage of less than three objects in
practice. Here we introduce architectural modifications and a novel contrastive
learning method that greatly improve the state-of-the-art synchrony-based
model. For the first time, we obtain a class of synchrony-based models capable
of discovering objects in an unsupervised manner in multi-object color datasets
and simultaneously representing more than three objects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanic_A/0/1/0/all/0/1&quot;&gt;Aleksandar Stani&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalakrishnan_A/0/1/0/all/0/1&quot;&gt;Anand Gopalakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1&quot;&gt;Kazuki Irie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1&quot;&gt;J&amp;#xfc;rgen Schmidhuber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.16841">
<title>Differentiable Random Partition Models. (arXiv:2305.16841v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.16841</link>
<description rdf:parseType="Literal">&lt;p&gt;Partitioning a set of elements into an unknown number of mutually exclusive
subsets is essential in many machine learning problems. However, assigning
elements, such as samples in a dataset or neurons in a network layer, to an
unknown and discrete number of subsets is inherently non-differentiable,
prohibiting end-to-end gradient-based optimization of parameters. We overcome
this limitation by proposing a novel two-step method for inferring partitions,
which allows its usage in variational inference tasks. This new approach
enables reparameterized gradients with respect to the parameters of the new
random partition model. Our method works by inferring the number of elements
per subset and, second, by filling these subsets in a learned order. We
highlight the versatility of our general-purpose approach on three different
challenging experiments: variational clustering, inference of shared and
independent generative factors under weak supervision, and multitask learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutter_T/0/1/0/all/0/1&quot;&gt;Thomas M. Sutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryser_A/0/1/0/all/0/1&quot;&gt;Alain Ryser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liebeskind_J/0/1/0/all/0/1&quot;&gt;Joram Liebeskind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1&quot;&gt;Julia E. Vogt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.01187">
<title>Training neural operators to preserve invariant measures of chaotic attractors. (arXiv:2306.01187v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.01187</link>
<description rdf:parseType="Literal">&lt;p&gt;Chaotic systems make long-horizon forecasts difficult because small
perturbations in initial conditions cause trajectories to diverge at an
exponential rate. In this setting, neural operators trained to minimize squared
error losses, while capable of accurate short-term forecasts, often fail to
reproduce statistical or structural properties of the dynamics over longer time
horizons and can yield degenerate results. In this paper, we propose an
alternative framework designed to preserve invariant measures of chaotic
attractors that characterize the time-invariant statistical properties of the
dynamics. Specifically, in the multi-environment setting (where each sample
trajectory is governed by slightly different dynamics), we consider two novel
approaches to training with noisy data. First, we propose a loss based on the
optimal transport distance between the observed dynamics and the neural
operator outputs. This approach requires expert knowledge of the underlying
physics to determine what statistical features should be included in the
optimal transport loss. Second, we show that a contrastive learning framework,
which does not require any specialized prior knowledge, can preserve
statistical properties of the dynamics nearly as well as the optimal transport
approach. On a variety of chaotic systems, our method is shown empirically to
preserve invariant measures of chaotic attractors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Ruoxi Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1&quot;&gt;Peter Y. Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orlova_E/0/1/0/all/0/1&quot;&gt;Elena Orlova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Willett_R/0/1/0/all/0/1&quot;&gt;Rebecca Willett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.02913">
<title>Decentralized SGD and Average-direction SAM are Asymptotically Equivalent. (arXiv:2306.02913v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.02913</link>
<description rdf:parseType="Literal">&lt;p&gt;Decentralized stochastic gradient descent (D-SGD) allows collaborative
learning on massive devices simultaneously without the control of a central
server. However, existing theories claim that decentralization invariably
undermines generalization. In this paper, we challenge the conventional belief
and present a completely new perspective for understanding decentralized
learning. We prove that D-SGD implicitly minimizes the loss function of an
average-direction Sharpness-aware minimization (SAM) algorithm under general
non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence
reveals an intrinsic regularization-optimization trade-off and three advantages
of decentralization: (1) there exists a free uncertainty evaluation mechanism
in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient
smoothing effect; and (3) the sharpness regularization effect of D-SGD does not
decrease as total batch size increases, which justifies the potential
generalization benefit of D-SGD over centralized SGD (C-SGD) in large-batch
scenarios. The code is available at
https://github.com/Raiden-Zhu/ICML-2023-DSGD-and-SAM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1&quot;&gt;Tongtian Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1&quot;&gt;Fengxiang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kaixuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1&quot;&gt;Mingli Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04027">
<title>Intervention Generalization: A View from Factor Graph Models. (arXiv:2306.04027v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.04027</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the goals of causal inference is to generalize from past experiments
and observational data to novel conditions. While it is in principle possible
to eventually learn a mapping from a novel experimental condition to an outcome
of interest, provided a sufficient variety of experiments is available in the
training data, coping with a large combinatorial space of possible
interventions is hard. Under a typical sparse experimental design, this mapping
is ill-posed without relying on heavy regularization or prior distributions.
Such assumptions may or may not be reliable, and can be hard to defend or test.
In this paper, we take a close look at how to warrant a leap from past
experiments to novel conditions based on minimal assumptions about the
factorization of the distribution of the manipulated system, communicated in
the well-understood language of factor graph models. A postulated
$\textit{interventional factor model}$ (IFM) may not always be informative, but
it conveniently abstracts away a need for explicitly modeling unmeasured
confounding and feedback mechanisms, leading to directly testable claims. Given
an IFM and datasets from a collection of experimental regimes, we derive
conditions for identifiability of the expected outcomes of new regimes never
observed in these training data. We implement our framework using several
efficient algorithms, and apply them on a range of semi-synthetic experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bravo_Hermsdorff_G/0/1/0/all/0/1&quot;&gt;Gecia Bravo-Hermsdorff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Watson_D/0/1/0/all/0/1&quot;&gt;David S. Watson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jialin Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zeitler_J/0/1/0/all/0/1&quot;&gt;Jakob Zeitler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Silva_R/0/1/0/all/0/1&quot;&gt;Ricardo Silva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.08013">
<title>TopP&amp;R: Robust Support Estimation Approach for Evaluating Fidelity and Diversity in Generative Models. (arXiv:2306.08013v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.08013</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a robust and reliable evaluation metric for generative models by
introducing topological and statistical treatments for rigorous support
estimation. Existing metrics, such as Inception Score (IS), Frechet Inception
Distance (FID), and the variants of Precision and Recall (P&amp;amp;R), heavily rely on
supports that are estimated from sample features. However, the reliability of
their estimation has not been seriously discussed (and overlooked) even though
the quality of the evaluation entirely depends on it. In this paper, we propose
Topological Precision and Recall (TopP&amp;amp;R, pronounced &apos;topper&apos;), which provides
a systematic approach to estimating supports, retaining only topologically and
statistically important features with a certain level of confidence. This not
only makes TopP&amp;amp;R strong for noisy features, but also provides statistical
consistency. Our theoretical and experimental results show that TopP&amp;amp;R is
robust to outliers and non-independent and identically distributed (Non-IID)
perturbations, while accurately capturing the true trend of change in samples.
To the best of our knowledge, this is the first evaluation metric focused on
the robust estimation of the support and provides its statistical consistency
under noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_P/0/1/0/all/0/1&quot;&gt;Pum Jun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_Y/0/1/0/all/0/1&quot;&gt;Yoojin Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jisu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1&quot;&gt;Jaejun Yoo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.09955">
<title>Training shallow ReLU networks on noisy data using hinge loss: when do we overfit and is it benign?. (arXiv:2306.09955v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.09955</link>
<description rdf:parseType="Literal">&lt;p&gt;We study benign overfitting in two-layer ReLU networks trained using gradient
descent and hinge loss on noisy data for binary classification. In particular,
we consider linearly separable data for which a relatively small proportion of
labels are corrupted or flipped. We identify conditions on the margin of the
clean data that give rise to three distinct training outcomes: benign
overfitting, in which zero loss is achieved and with high probability test data
is classified correctly; overfitting, in which zero loss is achieved but test
data is misclassified with probability lower bounded by a constant; and
non-overfitting, in which clean points, but not corrupt points, achieve zero
loss and again with high probability test data is classified correctly. Our
analysis provides a fine-grained description of the dynamics of neurons
throughout training and reveals two distinct phases: in the first phase clean
points achieve close to zero loss, in the second phase clean points oscillate
on the boundary of zero loss while corrupt points either converge towards zero
loss or are eventually zeroed by the network. We prove these results using a
combinatorial approach that involves bounding the number of clean versus
corrupt updates across these phases of training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+George_E/0/1/0/all/0/1&quot;&gt;Erin George&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murray_M/0/1/0/all/0/1&quot;&gt;Michael Murray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swartworth_W/0/1/0/all/0/1&quot;&gt;William Swartworth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Needell_D/0/1/0/all/0/1&quot;&gt;Deanna Needell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.11167">
<title>Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset. (arXiv:2306.11167v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.11167</link>
<description rdf:parseType="Literal">&lt;p&gt;The quest for human imitative AI has been an enduring topic in AI research
since its inception. The technical evolution and emerging capabilities of the
latest cohort of large language models (LLMs) have reinvigorated the subject
beyond academia to the cultural zeitgeist. While recent NLP evaluation
benchmark tasks test some aspects of human-imitative behaviour (e.g.,
BIG-bench&apos;s &apos;human-like behavior&apos; tasks), few, if not none, examine creative
problem solving abilities. Creative problem solving in humans is a well-studied
topic in cognitive neuroscience with standardized tests that predominantly use
the ability to associate (heterogeneous) connections among clue words as a
metric for creativity. Exposure to misleading stimuli - distractors dubbed red
herrings - impede human performance in such tasks via the fixation effect and
Einstellung paradigm. In cognitive neuroscience studies, such fixations are
experimentally induced by pre-exposing participants to orthographically similar
incorrect words to subsequent word-fragments or clues. The popular British quiz
show Only Connect&apos;s Connecting Wall segment essentially mimics Mednick&apos;s Remote
Associates Test (RAT) formulation with built-in, deliberate red herrings, which
makes it an ideal proxy dataset to explore and study fixation effect and
Einstellung paradigm from cognitive neuroscience in LLMs. In this paper we
present the novel Only Connect Wall (OCW) dataset and report results from our
evaluation of selected pre-trained language models and LLMs on creative problem
solving tasks like grouping clue words by heterogeneous connections, and
identifying correct open knowledge domain connections in respective groups. We
synthetically generate two additional datasets: OCW-Randomized, OCW-WordNet to
further analyze our red-herrings hypothesis in language models. The code and
link to the dataset are available at https://github.com/TaatiTeam/OCW.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naeini_S/0/1/0/all/0/1&quot;&gt;Saeid Naeini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saqur_R/0/1/0/all/0/1&quot;&gt;Raeid Saqur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saeidi_M/0/1/0/all/0/1&quot;&gt;Mozhgan Saeidi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giorgi_J/0/1/0/all/0/1&quot;&gt;John Giorgi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taati_B/0/1/0/all/0/1&quot;&gt;Babak Taati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.12929">
<title>Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing. (arXiv:2306.12929v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.12929</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer models have been widely adopted in various domains over the last
years, and especially large language models have advanced the field of AI
significantly. Due to their size, the capability of these networks has
increased tremendously, but this has come at the cost of a significant increase
in necessary compute. Quantization is one of the most effective ways to reduce
the computational time and memory consumption of neural networks. Many studies
have shown, however, that modern transformer models tend to learn strong
outliers in their activations, making them difficult to quantize. To retain
acceptable performance, the existence of these outliers requires activations to
be in higher bitwidth or the use of different numeric formats, extra
fine-tuning, or other workarounds. We show that strong outliers are related to
very specific behavior of attention heads that try to learn a &quot;no-op&quot; or just a
partial update of the residual. To achieve the exact zeros needed in the
attention matrix for a no-update, the input to the softmax is pushed to be
larger and larger during training, causing outliers in other parts of the
network. Based on these observations, we propose two simple (independent)
modifications to the attention mechanism - clipped softmax and gated attention.
We empirically show that models pre-trained using our methods learn
significantly smaller outliers while maintaining and sometimes even improving
the floating-point task performance. This enables us to quantize transformers
to full INT8 quantization of the activations without any additional effort. We
demonstrate the effectiveness of our methods on both language models (BERT,
OPT) and vision transformers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bondarenko_Y/0/1/0/all/0/1&quot;&gt;Yelysei Bondarenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagel_M/0/1/0/all/0/1&quot;&gt;Markus Nagel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blankevoort_T/0/1/0/all/0/1&quot;&gt;Tijmen Blankevoort&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.17750">
<title>TD Convergence: An Optimization Perspective. (arXiv:2306.17750v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.17750</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the convergence behavior of the celebrated temporal-difference (TD)
learning algorithm. By looking at the algorithm through the lens of
optimization, we first argue that TD can be viewed as an iterative optimization
algorithm where the function to be minimized changes per iteration. By
carefully investigating the divergence displayed by TD on a classical counter
example, we identify two forces that determine the convergent or divergent
behavior of the algorithm. We next formalize our discovery in the linear TD
setting with quadratic loss and prove that convergence of TD hinges on the
interplay between these two forces. We extend this optimization perspective to
prove convergence of TD in a much broader setting than just linear
approximation and squared loss. Our results provide a theoretical explanation
for the successful application of TD in reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asadi_K/0/1/0/all/0/1&quot;&gt;Kavosh Asadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabach_S/0/1/0/all/0/1&quot;&gt;Shoham Sabach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottesman_O/0/1/0/all/0/1&quot;&gt;Omer Gottesman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fakoor_R/0/1/0/all/0/1&quot;&gt;Rasool Fakoor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02064">
<title>Facing Off World Model Backbones: RNNs, Transformers, and S4. (arXiv:2307.02064v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02064</link>
<description rdf:parseType="Literal">&lt;p&gt;World models are a fundamental component in model-based reinforcement
learning (MBRL). To perform temporally extended and consistent simulations of
the future in partially observable environments, world models need to possess
long-term memory. However, state-of-the-art MBRL agents, such as Dreamer,
predominantly employ recurrent neural networks (RNNs) as their world model
backbone, which have limited memory capacity. In this paper, we seek to explore
alternative world model backbones for improving long-term memory. In
particular, we investigate the effectiveness of Transformers and Structured
State Space Sequence (S4) models, motivated by their remarkable ability to
capture long-range dependencies in low-dimensional sequences and their
complementary strengths. We propose S4WM, the first world model compatible with
parallelizable SSMs including S4 and its variants. By incorporating latent
variable modeling, S4WM can efficiently generate high-dimensional image
sequences through latent imagination. Furthermore, we extensively compare RNN-,
Transformer-, and S4-based world models across four sets of environments, which
we have tailored to assess crucial memory capabilities of world models,
including long-term imagination, context-dependent recall, reward prediction,
and memory-based reasoning. Our findings demonstrate that S4WM outperforms
Transformer-based world models in terms of long-term memory, while exhibiting
greater efficiency during training and imagination. These results pave the way
for the development of stronger MBRL agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_F/0/1/0/all/0/1&quot;&gt;Fei Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Junyeong Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1&quot;&gt;Sungjin Ahn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.04052">
<title>Learning to Group Auxiliary Datasets for Molecule. (arXiv:2307.04052v2 [q-bio.BM] UPDATED)</title>
<link>http://arxiv.org/abs/2307.04052</link>
<description rdf:parseType="Literal">&lt;p&gt;The limited availability of annotations in small molecule datasets presents a
challenge to machine learning models. To address this, one common strategy is
to collaborate with additional auxiliary datasets. However, having more data
does not always guarantee improvements. Negative transfer can occur when the
knowledge in the target dataset differs or contradicts that of the auxiliary
molecule datasets. In light of this, identifying the auxiliary molecule
datasets that can benefit the target dataset when jointly trained remains a
critical and unresolved problem. Through an empirical analysis, we observe that
combining graph structure similarity and task similarity can serve as a more
reliable indicator for identifying high-affinity auxiliary datasets. Motivated
by this insight, we propose MolGroup, which separates the dataset affinity into
task and structure affinity to predict the potential benefits of each auxiliary
molecule dataset. MolGroup achieves this by utilizing a routing mechanism
optimized through a bi-level optimization framework. Empowered by the meta
gradient, the routing mechanism is optimized toward maximizing the target
dataset&apos;s performance and quantifies the affinity as the gating score. As a
result, MolGroup is capable of predicting the optimal combination of auxiliary
datasets for each target dataset. Our extensive experiments demonstrate the
efficiency and effectiveness of MolGroup, showing an average improvement of
4.41%/3.47% for GIN/Graphormer trained with the group of molecule datasets
selected by MolGroup on 11 target molecule datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Tinglin Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Ziniu Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ying_R/0/1/0/all/0/1&quot;&gt;Rex Ying&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.04461">
<title>Multi-modal Graph Learning over UMLS Knowledge Graphs. (arXiv:2307.04461v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.04461</link>
<description rdf:parseType="Literal">&lt;p&gt;Clinicians are increasingly looking towards machine learning to gain insights
about patient evolutions. We propose a novel approach named Multi-Modal UMLS
Graph Learning (MMUGL) for learning meaningful representations of medical
concepts using graph neural networks over knowledge graphs based on the unified
medical language system. These representations are aggregated to represent
entire patient visits and then fed into a sequence model to perform predictions
at the granularity of multiple hospital visits of a patient. We improve
performance by incorporating prior medical knowledge and considering multiple
modalities. We compare our method to existing architectures proposed to learn
representations at different granularities on the MIMIC-III dataset and show
that our approach outperforms these methods. The results demonstrate the
significance of multi-modal medical concept representations based on prior
medical knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burger_M/0/1/0/all/0/1&quot;&gt;Manuel Burger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1&quot;&gt;Gunnar R&amp;#xe4;tsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuznetsova_R/0/1/0/all/0/1&quot;&gt;Rita Kuznetsova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.05439">
<title>Metropolis Sampling for Constrained Diffusion Models. (arXiv:2307.05439v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.05439</link>
<description rdf:parseType="Literal">&lt;p&gt;Denoising diffusion models have recently emerged as the predominant paradigm
for generative modelling on image domains. In addition, their extension to
Riemannian manifolds has facilitated a range of applications across the natural
sciences. While many of these problems stand to benefit from the ability to
specify arbitrary, domain-informed constraints, this setting is not covered by
the existing (Riemannian) diffusion model methodology. Recent work has
attempted to address this issue by constructing novel noising processes based
on the reflected Brownian motion and logarithmic barrier methods. However, the
associated samplers are either computationally burdensome or only apply to
convex subsets of Euclidean space. In this paper, we introduce an alternative,
simple noising scheme based on Metropolis sampling that affords substantial
gains in computational efficiency and empirical performance compared to the
earlier samplers. Of independent interest, we prove that this new process
corresponds to a valid discretisation of the reflected Brownian motion. We
demonstrate the scalability and flexibility of our approach on a range of
problem settings with convex and non-convex constraints, including applications
from geospatial modelling, robotics and protein design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fishman_N/0/1/0/all/0/1&quot;&gt;Nic Fishman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klarner_L/0/1/0/all/0/1&quot;&gt;Leo Klarner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathieu_E/0/1/0/all/0/1&quot;&gt;Emile Mathieu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutchinson_M/0/1/0/all/0/1&quot;&gt;Michael Hutchinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bortoli_V/0/1/0/all/0/1&quot;&gt;Valentin de Bortoli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06250">
<title>Identifiability Guarantees for Causal Disentanglement from Soft Interventions. (arXiv:2307.06250v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06250</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal disentanglement aims to uncover a representation of data using latent
variables that are interrelated through a causal model. Such a representation
is identifiable if the latent model that explains the data is unique. In this
paper, we focus on the scenario where unpaired observational and interventional
data are available, with each intervention changing the mechanism of a latent
variable. When the causal variables are fully observed, statistically
consistent algorithms have been developed to identify the causal model under
faithfulness assumptions. We here show that identifiability can still be
achieved with unobserved causal variables, given a generalized notion of
faithfulness. Our results guarantee that we can recover the latent causal model
up to an equivalence class and predict the effect of unseen combinations of
interventions, in the limit of infinite data. We implement our causal
disentanglement framework by developing an autoencoding variational Bayes
algorithm and apply it to the problem of predicting combinatorial perturbation
effects in genomics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiaqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Squires_C/0/1/0/all/0/1&quot;&gt;Chandler Squires&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Greenewald_K/0/1/0/all/0/1&quot;&gt;Kristjan Greenewald&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srivastava_A/0/1/0/all/0/1&quot;&gt;Akash Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shanmugam_K/0/1/0/all/0/1&quot;&gt;Karthikeyan Shanmugam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Uhler_C/0/1/0/all/0/1&quot;&gt;Caroline Uhler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06933">
<title>FDAPT: Federated Domain-adaptive Pre-training for Language Models. (arXiv:2307.06933v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06933</link>
<description rdf:parseType="Literal">&lt;p&gt;Foundation models (FMs) have shown prominent success in a wide range of
tasks. Their applicability to specific domain-task pairings relies on the
availability of, both, high-quality data and significant computational
resources. These challenges are not new to the field and, indeed, Federated
Learning (FL) has been shown to be a promising solution in similar setups. This
paper tackles the specific case of Domain-Adaptive Pre-Training (DAPT), a key
step in the application of FMs. We conduct the first comprehensive empirical
study to evaluate the performance of Federated Domain-Adaptive Pre-Training
(FDAPT). We demonstrate that FDAPT can maintain competitive downstream task
performance to the centralized baseline in both IID and non-IID situations.
Finally, we propose a novel algorithm, Frozen Federated Domain-Adaptive
Pre-Training (FFDAPT). FFDAPT improves the computational efficiency by 12.1% on
average and exhibits similar downstream task performance to vanilla FDAPT, with
general performance fluctuations remaining less than 1%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1&quot;&gt;Lekang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svoboda_F/0/1/0/all/0/1&quot;&gt;Filip Svoboda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1&quot;&gt;Nicholas D. Lane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.07980">
<title>Byzantine-Robust Distributed Online Learning: Taming Adversarial Participants in An Adversarial Environment. (arXiv:2307.07980v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.07980</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies distributed online learning under Byzantine attacks. The
performance of an online learning algorithm is often characterized by
(adversarial) regret, which evaluates the quality of one-step-ahead
decision-making when an environment provides adversarial losses, and a
sublinear bound is preferred. But we prove that, even with a class of
state-of-the-art robust aggregation rules, in an adversarial environment and in
the presence of Byzantine participants, distributed online gradient descent can
only achieve a linear adversarial regret bound, which is tight. This is the
inevitable consequence of Byzantine attacks, even though we can control the
constant of the linear adversarial regret to a reasonable level. Interestingly,
when the environment is not fully adversarial so that the losses of the honest
participants are i.i.d. (independent and identically distributed), we show that
sublinear stochastic regret, in contrast to the aforementioned adversarial
regret, is possible. We develop a Byzantine-robust distributed online momentum
algorithm to attain such a sublinear stochastic regret bound. Extensive
numerical experiments corroborate our theoretical analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1&quot;&gt;Xingrong Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhaoxian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_Q/0/1/0/all/0/1&quot;&gt;Qing Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1&quot;&gt;Zhi Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.12943">
<title>Gaussian Cooling and Dikin Walks: The Interior-Point Method for Logconcave Sampling. (arXiv:2307.12943v3 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2307.12943</link>
<description rdf:parseType="Literal">&lt;p&gt;The connections between (convex) optimization and (logconcave) sampling have
been considerably enriched in the past decade with many conceptual and
mathematical analogies. For instance, the Langevin algorithm can be viewed as a
sampling analogue of gradient descent and has condition-number-dependent
guarantees on its performance. In the early 1990s, Nesterov and Nemirovski
developed the Interior-Point Method (IPM) for convex optimization based on
self-concordant barriers, providing efficient algorithms for structured convex
optimization, often faster than the general method. This raises the following
question: can we develop an analogous IPM for structured sampling problems?
&lt;/p&gt;
&lt;p&gt;In 2012, Kannan and Narayanan proposed the Dikin walk for uniformly sampling
polytopes, and an improved analysis was given in 2020 by Laddha-Lee-Vempala.
The Dikin walk uses a local metric defined by a self-concordant barrier for
linear constraints. Here we generalize this approach by developing and adapting
IPM machinery together with the Dikin walk for poly-time sampling algorithms.
Our IPM-based sampling framework provides an efficient warm start and goes
beyond uniform distributions and linear constraints. We illustrate the approach
on important special cases, in particular giving the fastest algorithms to
sample uniform, exponential, or Gaussian distributions on a truncated PSD cone.
The framework is general and can be applied to other sampling algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kook_Y/0/1/0/all/0/1&quot;&gt;Yunbum Kook&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1&quot;&gt;Santosh S. Vempala&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.16695">
<title>A theory of data variability in Neural Network Bayesian inference. (arXiv:2307.16695v2 [cond-mat.dis-nn] UPDATED)</title>
<link>http://arxiv.org/abs/2307.16695</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian inference and kernel methods are well established in machine
learning. The neural network Gaussian process in particular provides a concept
to investigate neural networks in the limit of infinitely wide hidden layers by
using kernel and inference methods. Here we build upon this limit and provide a
field-theoretic formalism which covers the generalization properties of
infinitely wide networks. We systematically compute generalization properties
of linear, non-linear, and deep non-linear networks for kernel matrices with
heterogeneous entries. In contrast to currently employed spectral methods we
derive the generalization properties from the statistical properties of the
input, elucidating the interplay of input dimensionality, size of the training
data set, and variability of the data. We show that data variability leads to a
non-Gaussian action reminiscent of a ($\varphi^3+\varphi^4$)-theory. Using our
formalism on a synthetic task and on MNIST we obtain a homogeneous kernel
matrix approximation for the learning curve as well as corrections due to data
variability which allow the estimation of the generalization properties and
exact results for the bounds of the learning curves in the case of infinitely
many training data points.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Lindner_J/0/1/0/all/0/1&quot;&gt;Javed Lindner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Dahmen_D/0/1/0/all/0/1&quot;&gt;David Dahmen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Kramer_M/0/1/0/all/0/1&quot;&gt;Michael Kr&amp;#xe4;mer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Helias_M/0/1/0/all/0/1&quot;&gt;Moritz Helias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03811">
<title>Non-Convex Bilevel Optimization with Time-Varying Objective Functions. (arXiv:2308.03811v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03811</link>
<description rdf:parseType="Literal">&lt;p&gt;Bilevel optimization has become a powerful tool in a wide variety of machine
learning problems. However, the current nonconvex bilevel optimization
considers an offline dataset and static functions, which may not work well in
emerging online applications with streaming data and time-varying functions. In
this work, we study online bilevel optimization (OBO) where the functions can
be time-varying and the agent continuously updates the decisions with online
streaming data. To deal with the function variations and the unavailability of
the true hypergradients in OBO, we propose a single-loop online bilevel
optimizer with window averaging (SOBOW), which updates the outer-level decision
based on a window average of the most recent hypergradient estimations stored
in the memory. Compared to existing algorithms, SOBOW is computationally
efficient and does not need to know previous functions. To handle the unique
technical difficulties rooted in single-loop update and function variations for
OBO, we develop a novel analytical technique that disentangles the complex
couplings between decision variables, and carefully controls the hypergradient
estimation error. We show that SOBOW can achieve a sublinear bilevel local
regret under mild conditions. Extensive experiments across multiple domains
corroborate the effectiveness of SOBOW.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Sen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sow_D/0/1/0/all/0/1&quot;&gt;Daouda Sow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ji_K/0/1/0/all/0/1&quot;&gt;Kaiyi Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yingbin Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shroff_N/0/1/0/all/0/1&quot;&gt;Ness Shroff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05061">
<title>Fine-Tune Language Models as Multi-Modal Differential Equation Solvers. (arXiv:2308.05061v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.05061</link>
<description rdf:parseType="Literal">&lt;p&gt;In the growing domain of scientific machine learning, in-context operator
learning has shown notable potential in learning operators and solving
differential equations using prompted data, during the inference stage without
weight updates. However, the current model&apos;s overdependence on function data,
may inadvertently overlook the invaluable human insight into the operator. To
address this, we present a transformation of in-context operator learning into
a multi-modal paradigm. In particular, we take inspiration from the recent
success of large language models, and propose using &quot;captions&quot; to integrate
human knowledge about the operator, expressed through natural language
descriptions and equations. Also, we introduce a novel approach to train a
language-model-like architecture, or directly fine-tune existing language
models, for in-context operator learning. We beat the baseline on single-modal
learning tasks, and also demonstrated the effectiveness of multi-modal learning
in enhancing performance and reducing function data requirements. The proposed
method not only significantly improves in-context operator learning, but also
creates a new path for the application of language models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Liu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Siting Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1&quot;&gt;Stanley J. Osher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.14991">
<title>Incorporating Neuro-Inspired Adaptability for Continual Learning in Artificial Intelligence. (arXiv:2308.14991v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.14991</link>
<description rdf:parseType="Literal">&lt;p&gt;Continual learning aims to empower artificial intelligence (AI) with strong
adaptability to the real world. For this purpose, a desirable solution should
properly balance memory stability with learning plasticity, and acquire
sufficient compatibility to capture the observed distributions. Existing
advances mainly focus on preserving memory stability to overcome catastrophic
forgetting, but remain difficult to flexibly accommodate incremental changes as
biological intelligence (BI) does. By modeling a robust Drosophila learning
system that actively regulates forgetting with multiple learning modules, here
we propose a generic approach that appropriately attenuates old memories in
parameter distributions to improve learning plasticity, and accordingly
coordinates a multi-learner architecture to ensure solution compatibility.
Through extensive theoretical and empirical validation, our approach not only
clearly enhances the performance of continual learning, especially over
synaptic regularization methods in task-incremental settings, but also
potentially advances the understanding of neurological adaptive mechanisms,
serving as a novel paradigm to progress AI and BI together.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liyuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xingxing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mingtian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1&quot;&gt;Yi Zhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.00608">
<title>Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair. (arXiv:2309.00608v3 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2309.00608</link>
<description rdf:parseType="Literal">&lt;p&gt;During Automated Program Repair (APR), it can be challenging to synthesize
correct patches for real-world systems in general-purpose programming
languages. Recent Large Language Models (LLMs) have been shown to be helpful
&quot;copilots&quot; in assisting developers with various coding tasks, and have also
been directly applied for patch synthesis. However, most LLMs treat programs as
sequences of tokens, meaning that they are ignorant of the underlying semantics
constraints of the target programming language. This results in plenty of
statically invalid generated patches, impeding the practicality of the
technique. Therefore, we propose Repilot, a general code generation framework
to further copilot the AI &quot;copilots&quot; (i.e., LLMs) by synthesizing more valid
patches during the repair process. Our key insight is that many LLMs produce
outputs autoregressively (i.e., token by token), resembling human writing
programs, which can be significantly boosted and guided through a Completion
Engine. Repilot synergistically synthesizes a candidate patch through the
interaction between an LLM and a Completion Engine, which 1) prunes away
infeasible tokens suggested by the LLM and 2) proactively completes the token
based on the suggestions provided by the Completion Engine. Our evaluation on a
subset of the widely-used Defects4j 1.2 and 2.0 datasets shows that Repilot
outperforms state-of-the-art techniques by fixing 27% and 47% more bugs,
respectively. Moreover, Repilot produces more valid and correct patches than
the base LLM with the same budget. While we focus on leveraging Repilot for APR
in this work, the overall approach is also generalizable to other code
generation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1&quot;&gt;Yuxiang Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1&quot;&gt;Chunqiu Steven Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lingming Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.01784">
<title>ATMS: Algorithmic Trading-Guided Market Simulation. (arXiv:2309.01784v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.01784</link>
<description rdf:parseType="Literal">&lt;p&gt;In many applications involving multi-agent system (MAS), it is imperative to
test an experimental (Exp) autonomous agent in a high-fidelity simulator prior
to its deployment to production, to avoid unexpected losses in the real-world.
Such a simulator acts as the environmental background (BG) agent(s), called
agent-based simulator (ABS), aiming to replicate the complex real MAS. However,
developing realistic ABS remains challenging, mainly due to the sequential and
dynamic nature of such systems. To fill this gap, we propose a metric to
distinguish between real and synthetic multi-agent systems, which is evaluated
through the live interaction between the Exp and BG agents to explicitly
account for the systems&apos; sequential nature. Specifically, we characterize the
system/environment by studying the effect of a sequence of BG agents&apos; responses
to the environment state evolution and take such effects&apos; differences as MAS
distance metric; The effect estimation is cast as a causal inference problem
since the environment evolution is confounded with the previous environment
state. Importantly, we propose the Interactive Agent-Guided Simulation (INTAGS)
framework to build a realistic ABS by optimizing over this novel metric. To
adapt to any environment with interactive sequential decision making agents,
INTAGS formulates the simulator as a stochastic policy in reinforcement
learning. Moreover, INTAGS utilizes the policy gradient update to bypass
differentiating the proposed metric such that it can support non-differentiable
operations of multi-agent environments. Through extensive experiments, we
demonstrate the effectiveness of INTAGS on an equity stock market simulation
example. We show that using INTAGS to calibrate the simulator can generate more
realistic market data compared to the state-of-the-art conditional Wasserstein
Generative Adversarial Network approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1&quot;&gt;Song Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coletta_A/0/1/0/all/0/1&quot;&gt;Andrea Coletta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vyetrenko_S/0/1/0/all/0/1&quot;&gt;Svitlana Vyetrenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balch_T/0/1/0/all/0/1&quot;&gt;Tucker Balch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.13016">
<title>Understanding Deep Gradient Leakage via Inversion Influence Functions. (arXiv:2309.13016v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.13016</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Gradient Leakage (DGL) is a highly effective attack that recovers
private training images from gradient vectors. This attack casts significant
privacy challenges on distributed learning from clients with sensitive data,
where clients are required to share gradients. Defending against such attacks
requires but lacks an understanding of when and how privacy leakage happens,
mostly because of the black-box nature of deep networks. In this paper, we
propose a novel Inversion Influence Function (I$^2$F) that establishes a
closed-form connection between the recovered images and the private gradients
by implicitly solving the DGL problem. Compared to directly solving DGL, I$^2$F
is scalable for analyzing deep networks, requiring only oracle access to
gradients and Jacobian-vector products. We empirically demonstrate that I$^2$F
effectively approximated the DGL generally on different model architectures,
datasets, attack implementations, and noise-based defenses. With this novel
tool, we provide insights into effective gradient perturbation directions, the
unfairness of privacy protection, and privacy-preferred model initialization.
Our codes are provided in
https://github.com/illidanlab/inversion-influence-function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haobo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1&quot;&gt;Junyuan Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yuyang Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahdavi_M/0/1/0/all/0/1&quot;&gt;Mehrdad Mahdavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiayu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.06328">
<title>Antenna Response Consistency Driven Self-supervised Learning for WIFI-based Human Activity Recognition. (arXiv:2310.06328v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.06328</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning (SSL) for WiFi-based human activity recognition
(HAR) holds great promise due to its ability to address the challenge of
insufficient labeled data. However, directly transplanting SSL algorithms,
especially contrastive learning, originally designed for other domains to CSI
data, often fails to achieve the expected performance. We attribute this issue
to the inappropriate alignment criteria, which disrupt the semantic distance
consistency between the feature space and the input space. To address this
challenge, we introduce \textbf{A}ntenna \textbf{R}esponse \textbf{C}onsistency
(ARC) as a solution to define proper alignment criteria. ARC is designed to
retain semantic information from the input space while introducing robustness
to real-world noise. Moreover, we substantiate the effectiveness of ARC through
a comprehensive set of experiments, demonstrating its capability to enhance the
performance of self-supervised learning for WiFi-based HAR by achieving an
increase of over 5\% in accuracy in most cases and achieving a best accuracy of
94.97\%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Ke Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiangtao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1&quot;&gt;Dingchang Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.06643">
<title>Implicit Variational Inference for High-Dimensional Posteriors. (arXiv:2310.06643v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.06643</link>
<description rdf:parseType="Literal">&lt;p&gt;In variational inference, the benefits of Bayesian models rely on accurately
capturing the true posterior distribution. We propose using neural samplers
that specify implicit distributions, which are well-suited for approximating
complex multimodal and correlated posteriors in high-dimensional spaces. Our
approach introduces novel bounds for approximate inference using implicit
distributions by locally linearising the neural sampler. This is distinct from
existing methods that rely on additional discriminator networks and unstable
adversarial objectives. Furthermore, we present a new sampler architecture
that, for the first time, enables implicit distributions over tens of millions
of latent variables, addressing computational concerns by using differentiable
numerical approximations. We empirically show that our method is capable of
recovering correlations across layers in large Bayesian neural networks, a
property that is crucial for a network&apos;s performance but notoriously
challenging to achieve. To the best of our knowledge, no other method has been
shown to accomplish this task for such large models. Through experiments in
downstream tasks, we demonstrate that our expressive posteriors outperform
state-of-the-art uncertainty quantification methods, validating the
effectiveness of our training algorithm and the quality of the learned implicit
approximation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uppal_A/0/1/0/all/0/1&quot;&gt;Anshuk Uppal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stensbo_Smidt_K/0/1/0/all/0/1&quot;&gt;Kristoffer Stensbo-Smidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boomsma_W/0/1/0/all/0/1&quot;&gt;Wouter Boomsma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1&quot;&gt;Jes Frellsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.09949">
<title>Chameleon: a heterogeneous and disaggregated accelerator system for retrieval-augmented language models. (arXiv:2310.09949v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.09949</link>
<description rdf:parseType="Literal">&lt;p&gt;A Retrieval-Augmented Language Model (RALM) augments a generative language
model by retrieving context-specific knowledge from an external database. This
strategy facilitates impressive text generation quality even with smaller
models, thus reducing orders of magnitude of computational demands. However,
RALMs introduce unique system design challenges due to (a) the diverse workload
characteristics between LM inference and retrieval and (b) the various system
requirements and bottlenecks for different RALM configurations such as model
sizes, database sizes, and retrieval frequencies. We propose Chameleon, a
heterogeneous accelerator system that integrates both LM and retrieval
accelerators in a disaggregated architecture. The heterogeneity ensures
efficient acceleration of both LM inference and retrieval, while the
accelerator disaggregation enables the system to independently scale both types
of accelerators to fulfill diverse RALM requirements. Our Chameleon prototype
implements retrieval accelerators on FPGAs and assigns LM inference to GPUs,
with a CPU server orchestrating these accelerators over the network. Compared
to CPU-based and CPU-GPU vector search systems, Chameleon achieves up to 23.72x
speedup and 26.2x energy efficiency. Evaluated on various RALMs, Chameleon
exhibits up to 2.16x reduction in latency and 3.18x speedup in throughput
compared to the hybrid CPU-GPU architecture. These promising results pave the
way for bringing accelerator heterogeneity and disaggregation into future RALM
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1&quot;&gt;Wenqi Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeller_M/0/1/0/all/0/1&quot;&gt;Marco Zeller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waleffe_R/0/1/0/all/0/1&quot;&gt;Roger Waleffe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1&quot;&gt;Torsten Hoefler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alonso_G/0/1/0/all/0/1&quot;&gt;Gustavo Alonso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.10378">
<title>Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models. (arXiv:2310.10378v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.10378</link>
<description rdf:parseType="Literal">&lt;p&gt;Multilingual large-scale Pretrained Language Models (PLMs) have been shown to
store considerable amounts of factual knowledge, but large variations are
observed across languages. With the ultimate goal of ensuring that users with
different language backgrounds obtain consistent feedback from the same model,
we study the cross-lingual consistency (CLC) of factual knowledge in various
multilingual PLMs. To this end, we propose a Ranking-based Consistency (RankC)
metric to evaluate knowledge consistency across languages independently from
accuracy. Using this metric, we conduct an in-depth analysis of the determining
factors for CLC, both at model level and at language-pair level. Among other
results, we find that increasing model size leads to higher factual probing
accuracy in most languages, but does not improve cross-lingual consistency.
Finally, we conduct a case study on CLC when new factual associations are
inserted in the PLMs via model editing. Results on a small sample of facts
inserted in English reveal a clear pattern whereby the new piece of knowledge
transfers only to languages with which English has a high RankC score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1&quot;&gt;Jirui Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_R/0/1/0/all/0/1&quot;&gt;Raquel Fern&amp;#xe1;ndez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bisazza_A/0/1/0/all/0/1&quot;&gt;Arianna Bisazza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.12421">
<title>Detecting and Mitigating Algorithmic Bias in Binary Classification using Causal Modeling. (arXiv:2310.12421v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.12421</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes the use of causal modeling to detect and mitigate
algorithmic bias. We provide a brief description of causal modeling and a
general overview of our approach. We then use the Adult dataset, which is
available for download from the UC Irvine Machine Learning Repository, to
develop (1) a prediction model, which is treated as a black box, and (2) a
causal model for bias mitigation. In this paper, we focus on gender bias and
the problem of binary classification. We show that gender bias in the
prediction model is statistically significant at the 0.05 level. We demonstrate
the effectiveness of the causal model in mitigating gender bias by
cross-validation. Furthermore, we show that the overall classification accuracy
is improved slightly. Our novel approach is intuitive, easy-to-use, and can be
implemented using existing statistical software tools such as &quot;lavaan&quot; in R.
Hence, it enhances explainability and promotes trust.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hui_W/0/1/0/all/0/1&quot;&gt;Wendy Hui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lau_W/0/1/0/all/0/1&quot;&gt;Wai Kwong Lau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.12802">
<title>An effective theory of collective deep learning. (arXiv:2310.12802v2 [physics.soc-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2310.12802</link>
<description rdf:parseType="Literal">&lt;p&gt;Unraveling the emergence of collective learning in systems of coupled
artificial neural networks points to broader implications for machine learning,
neuroscience, and society. Here we introduce a minimal model that condenses
several recent decentralized algorithms by considering a competition between
two terms: the local learning dynamics in the parameters of each neural network
unit, and a diffusive coupling among units that tends to homogenize the
parameters of the ensemble. We derive an effective theory for linear networks
to show that the coarse-grained behavior of our system is equivalent to a
deformed Ginzburg-Landau model with quenched disorder. This framework predicts
depth-dependent disorder-order-disorder phase transitions in the parameters&apos;
solutions that reveal a depth-delayed onset of a collective learning phase and
a low-rank microscopic learning path. We validate the theory in coupled
ensembles of realistic neural networks trained on the MNIST dataset under
privacy constraints. Interestingly, experiments confirm that individual
networks -- trained on private data -- can fully generalize to unseen data
classes when the collective learning phase emerges. Our work establishes the
physics of collective learning and contributes to the mechanistic
interpretability of deep learning in decentralized settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Arola_Fernandez_L/0/1/0/all/0/1&quot;&gt;Llu&amp;#xed;s Arola-Fern&amp;#xe1;ndez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lacasa_L/0/1/0/all/0/1&quot;&gt;Lucas Lacasa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13121">
<title>Understanding Addition in Transformers. (arXiv:2310.13121v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13121</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the inner workings of machine learning models like Transformers
is vital for their safe and ethical use. This paper presents an in-depth
analysis of a one-layer Transformer model trained for n-digit integer addition.
We reveal that the model divides the task into parallel, digit-specific streams
and employs distinct algorithms for different digit positions. Our study also
finds that the model starts calculations late but executes them rapidly. A rare
use case with high loss is identified and explained. Overall, the model&apos;s
algorithm is explained in detail. These findings are validated through rigorous
testing and mathematical modeling, contributing to the broader works in
Mechanistic Interpretability, AI safety, and alignment. Our approach opens the
door for analyzing more complex tasks and multi-layer Transformer models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quirke_P/0/1/0/all/0/1&quot;&gt;Philip Quirke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1&quot;&gt;Fazl Barez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.13236">
<title>An Efficient Federated Learning Framework for Training Semantic Communication System. (arXiv:2310.13236v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.13236</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic communication has emerged as a pillar for the next generation of
communication systems due to its capabilities in alleviating data redundancy.
Most semantic communication systems are built upon advanced deep learning
models whose training performance heavily relies on data availability. Existing
studies often make unrealistic assumptions of a readily accessible data source,
where in practice, data is mainly created on the client side. Due to privacy
and security concerns, the transmission of data is restricted, which is
necessary for conventional centralized training schemes. To address this
challenge, we explore semantic communication in a federated learning (FL)
setting that utilizes client data without leaking privacy. Additionally, we
design our system to tackle the communication overhead by reducing the quantity
of information delivered in each global round. In this way, we can save
significant bandwidth for resource-limited devices and reduce overall network
traffic. Finally, we introduce a mechanism to aggregate the global model from
clients, called FedLol. Extensive simulation results demonstrate the
effectiveness of our proposed technique compared to baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1&quot;&gt;Loc X. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1&quot;&gt;Huy Q. Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tun_Y/0/1/0/all/0/1&quot;&gt;Ye Lin Tun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aung_P/0/1/0/all/0/1&quot;&gt;Pyae Sone Aung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tun_Y/0/1/0/all/0/1&quot;&gt;Yan Kyaw Tun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1&quot;&gt;Zhu Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1&quot;&gt;Choong Seon Hong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.14360">
<title>Is ChatGPT a game changer for geocoding -- a benchmark for geocoding address parsing techniques. (arXiv:2310.14360v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.14360</link>
<description rdf:parseType="Literal">&lt;p&gt;The remarkable success of GPT models across various tasks, including toponymy
recognition motivates us to assess the performance of the GPT-3 model in the
geocoding address parsing task. To ensure that the evaluation more accurately
mirrors performance in real-world scenarios with diverse user input qualities
and resolve the pressing need for a &apos;gold standard&apos; evaluation dataset for
geocoding systems, we introduce a benchmark dataset of low-quality address
descriptions synthesized based on human input patterns mining from actual input
logs of a geocoding system in production. This dataset has 21 different input
errors and variations; contains over 239,000 address records that are uniquely
selected from streets across all U.S. 50 states and D.C.; and consists of three
subsets to be used as training, validation, and testing sets. Building on this,
we train and gauge the performance of the GPT-3 model in extracting address
components, contrasting its performance with transformer-based and LSTM-based
models. The evaluation results indicate that Bidirectional LSTM-CRF model has
achieved the best performance over these transformer-based models and GPT-3
model. Transformer-based models demonstrate very comparable results compared to
the Bidirectional LSTM-CRF model. The GPT-3 model, though trailing in
performance, showcases potential in the address parsing task with few-shot
examples, exhibiting room for improvement with additional fine-tuning. We open
source the code and data of this presented benchmark so that researchers can
utilize it for future model development or extend it to evaluate similar tasks,
such as document geocoding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zhengcong Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Diya Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_D/0/1/0/all/0/1&quot;&gt;Daniel W. Goldberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.15767">
<title>Unpaired MRI Super Resolution with Self-Supervised Contrastive Learning. (arXiv:2310.15767v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.15767</link>
<description rdf:parseType="Literal">&lt;p&gt;High-resolution (HR) magnetic resonance imaging (MRI) is crucial for
enhancing diagnostic accuracy in clinical settings. Nonetheless, the inherent
limitation of MRI resolution restricts its widespread applicability. Deep
learning-based image super-resolution (SR) methods exhibit promise in improving
MRI resolution without additional cost. However, these methods frequently
require a substantial number of HR MRI images for training, which can be
challenging to acquire. In this paper, we propose an unpaired MRI SR approach
that employs self-supervised contrastive learning to enhance SR performance
with limited training data. Our approach leverages both authentic HR images and
synthetically generated SR images to construct positive and negative sample
pairs, thus facilitating the learning of discriminative features. Empirical
results presented in this study underscore significant enhancements in the peak
signal-to-noise ratio and structural similarity index, even when a paucity of
HR images is available. These findings accentuate the potential of our approach
in addressing the challenge of limited training data, thereby contributing to
the advancement of high-resolution MRI in clinical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Quanwei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jianan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiling Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yanni Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Tao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lv_Z/0/1/0/all/0/1&quot;&gt;Zhihan Lv&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.18590">
<title>Using Early Readouts to Mediate Featural Bias in Distillation. (arXiv:2310.18590v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.18590</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep networks tend to learn spurious feature-label correlations in real-world
supervised learning tasks. This vulnerability is aggravated in distillation,
where a student model may have lesser representational capacity than the
corresponding teacher model. Often, knowledge of specific spurious correlations
is used to reweight instances &amp;amp; rebalance the learning process. We propose a
novel early readout mechanism whereby we attempt to predict the label using
representations from earlier network layers. We show that these early readouts
automatically identify problem instances or groups in the form of confident,
incorrect predictions. Leveraging these signals to modulate the distillation
loss on an instance level allows us to substantially improve not only group
fairness measures across benchmark datasets, but also overall accuracy of the
student model. We also provide secondary analyses that bring insight into the
role of feature learning in supervision and distillation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_R/0/1/0/all/0/1&quot;&gt;Rishabh Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sivasubramanian_D/0/1/0/all/0/1&quot;&gt;Durga Sivasubramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mekala_A/0/1/0/all/0/1&quot;&gt;Anmol Mekala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1&quot;&gt;Ganesh Ramakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shenoy_P/0/1/0/all/0/1&quot;&gt;Pradeep Shenoy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.19218">
<title>A Survey of Federated Unlearning: A Taxonomy, Challenges and Future Directions. (arXiv:2310.19218v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.19218</link>
<description rdf:parseType="Literal">&lt;p&gt;With the development of trustworthy Federated Learning (FL), the requirement
of implementing right to be forgotten gives rise to the area of Federated
Unlearning (FU). Comparing to machine unlearning, a major challenge of FU lies
in the decentralized and privacy-preserving nature of FL, in which clients
jointly train a global model without sharing their raw data, making it
substantially more intricate to selectively unlearn specific information. In
that regard, many efforts have been made to tackle the challenges of FU and
have achieved significant progress. In this paper, we present a comprehensive
survey of FU. Specially, we provide the existing algorithms, objectives,
evaluation metrics, and identify some challenges of FU. By reviewing and
comparing some studies, we summarize them into a taxonomy for various schemes,
potential applications and future directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jiaxi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yang Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.20190">
<title>Visible to Thermal image Translation for improving visual task in low light conditions. (arXiv:2310.20190v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.20190</link>
<description rdf:parseType="Literal">&lt;p&gt;Several visual tasks, such as pedestrian detection and image-to-image
translation, are challenging to accomplish in low light using RGB images. Heat
variation of objects in thermal images can be used to overcome this. In this
work, an end-to-end framework, which consists of a generative network and a
detector network, is proposed to translate RGB image into Thermal ones and
compare generated thermal images with real data. We have collected images from
two different locations using the Parrot Anafi Thermal drone. After that, we
created a two-stream network, preprocessed, augmented, the image data, and
trained the generator and discriminator models from scratch. The findings
demonstrate that it is feasible to translate RGB training data to thermal data
using GAN. As a result, thermal data can now be produced more quickly and
affordably, which is useful for security and surveillance applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Md Azim Khan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.00136">
<title>Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data. (arXiv:2311.00136v3 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/2311.00136</link>
<description rdf:parseType="Literal">&lt;p&gt;State-of-the-art systems neuroscience experiments yield large-scale
multimodal data, and these data sets require new tools for analysis. Inspired
by the success of large pretrained models in vision and language domains, we
reframe the analysis of large-scale, cellular-resolution neuronal spiking data
into an autoregressive spatiotemporal generation problem. Neuroformer is a
multimodal, multitask generative pretrained transformer (GPT) model that is
specifically designed to handle the intricacies of data in systems
neuroscience. It scales linearly with feature size, can process an arbitrary
number of modalities, and is adaptable to downstream tasks, such as predicting
behavior. We first trained Neuroformer on simulated datasets, and found that it
both accurately predicted simulated neuronal circuit activity, and also
intrinsically inferred the underlying neural circuit connectivity, including
direction. When pretrained to decode neural responses, the model predicted the
behavior of a mouse with only few-shot fine-tuning, suggesting that the model
begins learning how to do so directly from the neural representations
themselves, without any explicit supervision. We used an ablation study to show
that joint training on neuronal responses and behavior boosted performance,
highlighting the model&apos;s ability to associate behavioral and neural
representations in an unsupervised manner. These findings show that Neuroformer
can analyze neural datasets and their emergent properties, informing the
development of models and hypotheses associated with the brain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Antoniades_A/0/1/0/all/0/1&quot;&gt;Antonis Antoniades&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yiyi Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Canzano_J/0/1/0/all/0/1&quot;&gt;Joseph Canzano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;William Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Smith_S/0/1/0/all/0/1&quot;&gt;Spencer LaVere Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.01771">
<title>Efficient Generalized Low-Rank Tensor Contextual Bandits. (arXiv:2311.01771v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.01771</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we aim to build a novel bandits algorithm that is capable of
fully harnessing the power of multi-dimensional data and the inherent
non-linearity of reward functions to provide high-usable and accountable
decision-making services. To this end, we introduce a generalized low-rank
tensor contextual bandits model in which an action is formed from three feature
vectors, and thus can be represented by a tensor. In this formulation, the
reward is determined through a generalized linear function applied to the inner
product of the action&apos;s feature tensor and a fixed but unknown parameter tensor
with a low tubal rank. To effectively achieve the trade-off between exploration
and exploitation, we introduce a novel algorithm called &quot;Generalized Low-Rank
Tensor Exploration Subspace then Refine&quot; (G-LowTESTR). This algorithm first
collects raw data to explore the intrinsic low-rank tensor subspace information
embedded in the decision-making scenario, and then converts the original
problem into an almost lower-dimensional generalized linear contextual bandits
problem. Rigorous theoretical analysis shows that the regret bound of
G-LowTESTR is superior to those in vectorization and matricization cases. We
conduct a series of simulations and real data experiments to further highlight
the effectiveness of G-LowTESTR, leveraging its ability to capitalize on the
low-rank tensor structure for enhanced learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1&quot;&gt;Qianxin Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yiyang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shaojie Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yao Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02096">
<title>Variational Autoencoders for Noise Reduction in Industrial LLRF Systems. (arXiv:2311.02096v2 [physics.acc-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2311.02096</link>
<description rdf:parseType="Literal">&lt;p&gt;Industrial particle accelerators inherently operate in much dirtier
environments than typical research accelerators. This leads to an increase in
noise both in the RF system and in other electronic systems. Combined with the
fact that industrial accelerators are mass produced, there is less attention
given to optimizing the performance of an individual system. As a result,
industrial systems tend to under perform considering their hardware hardware
capabilities. With the growing demand for accelerators for medical
sterilization, food irradiation, cancer treatment, and imaging, improving the
signal processing of these machines will increase the margin for the deployment
of these systems. Our work is focusing on using machine learning techniques to
reduce the noise of RF signals used for pulse-to-pulse feedback in industrial
accelerators. We will review our algorithms, simulation results, and results
working with measured data. We will then discuss next steps for deployment and
testing on an industrial system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Edelen_J/0/1/0/all/0/1&quot;&gt;J. P. Edelen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Henderson_M/0/1/0/all/0/1&quot;&gt;M. J. Henderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Einstein_Curtis_J/0/1/0/all/0/1&quot;&gt;J. Einstein-Curtis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hall_C/0/1/0/all/0/1&quot;&gt;C. C. Hall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Cruz_J/0/1/0/all/0/1&quot;&gt;J. A. Diaz Cruz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Edelen_A/0/1/0/all/0/1&quot;&gt;A. L. Edelen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.03405">
<title>Communication Efficient and Privacy-Preserving Federated Learning Based on Evolution Strategies. (arXiv:2311.03405v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.03405</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is an emerging paradigm for training deep neural
networks (DNNs) in distributed manners. Current FL approaches all suffer from
high communication overhead and information leakage. In this work, we present a
federated learning algorithm based on evolution strategies (FedES), a
zeroth-order training method. Instead of transmitting model parameters, FedES
only communicates loss values, and thus has very low communication overhead.
Moreover, a third party is unable to estimate gradients without knowing the
pre-shared seed, which protects data privacy. Experimental results demonstrate
FedES can achieve the above benefits while keeping convergence performance the
same as that with back propagation methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_G/0/1/0/all/0/1&quot;&gt;Guangchen Lan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.03421">
<title>Hopfield-Enhanced Deep Neural Networks for Artifact-Resilient Brain State Decoding. (arXiv:2311.03421v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/2311.03421</link>
<description rdf:parseType="Literal">&lt;p&gt;The study of brain states, ranging from highly synchronous to asynchronous
neuronal patterns like the sleep-wake cycle, is fundamental for assessing the
brain&apos;s spatiotemporal dynamics and their close connection to behavior.
However, the development of new techniques to accurately identify them still
remains a challenge, as these are often compromised by the presence of noise,
artifacts, and suboptimal recording quality. In this study, we propose a
two-stage computational framework combining Hopfield Networks for artifact data
preprocessing with Convolutional Neural Networks (CNNs) for classification of
brain states in rat neural recordings under different levels of anesthesia. To
evaluate the robustness of our framework, we deliberately introduced noise
artifacts into the neural recordings. We evaluated our hybrid Hopfield-CNN
pipeline by benchmarking it against two comparative models: a standalone CNN
handling the same noisy inputs, and another CNN trained and tested on
artifact-free data. Performance across various levels of data compression and
noise intensities showed that our framework can effectively mitigate artifacts,
allowing the model to reach parity with the clean-data CNN at lower noise
levels. Although this study mainly benefits small-scale experiments, the
findings highlight the necessity for advanced deep learning and Hopfield
Network models to improve scalability and robustness in diverse real-world
settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Marin_Llobet_A/0/1/0/all/0/1&quot;&gt;Arnau Marin-Llobet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Manasanch_A/0/1/0/all/0/1&quot;&gt;Arnau Manasanch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sanchez_Vives_M/0/1/0/all/0/1&quot;&gt;Maria V. Sanchez-Vives&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.03755">
<title>Multilingual Mathematical Autoformalization. (arXiv:2311.03755v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.03755</link>
<description rdf:parseType="Literal">&lt;p&gt;Autoformalization is the task of translating natural language materials into
machine-verifiable formalisations. Progress in autoformalization research is
hindered by the lack of a sizeable dataset consisting of informal-formal pairs
expressing the same essence. Existing methods tend to circumvent this challenge
by manually curating small corpora or using few-shot learning with large
language models. But these methods suffer from data scarcity and formal
language acquisition difficulty. In this work, we create $\texttt{MMA}$, a
large, flexible, multilingual, and multi-domain dataset of informal-formal
pairs, by using a language model to translate in the reverse direction, that
is, from formal mathematical statements into corresponding informal ones.
Experiments show that language models fine-tuned on $\texttt{MMA}$ produce
$16-18\%$ of statements acceptable with minimal corrections on the
$\texttt{miniF2F}$ and $\texttt{ProofNet}$ benchmarks, up from $0\%$ with the
base model. We demonstrate that fine-tuning on multilingual formal data results
in more capable autoformalization models even when deployed on monolingual
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_A/0/1/0/all/0/1&quot;&gt;Albert Q. Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenda Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamnik_M/0/1/0/all/0/1&quot;&gt;Mateja Jamnik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.03764">
<title>Neuro-GPT: Developing A Foundation Model for EEG. (arXiv:2311.03764v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.03764</link>
<description rdf:parseType="Literal">&lt;p&gt;To handle the scarcity and heterogeneity of electroencephalography (EEG) data
in Brain-Computer Interface (BCI) tasks, and to harness the vast public data,
we propose Neuro-GPT, a foundation model consisting of an EEG encoder and a GPT
model. The foundation model is pre-trained on a large-scale public EEG dataset,
using a self-supervised task which learns how to reconstruct the masked chunk
in EEG. We then fine-tune the foundation model on a Motor Imagery
Classification task where only 9 subjects are available. Experiments
demonstrated that applying foundation model can significantly improve
classification performance compared to the model trained from scratch, which
provides evidence for the advanced generalizability of foundation model and the
ability to address the challenges of data scarcity and heterogeneity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1&quot;&gt;Wenhui Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_W/0/1/0/all/0/1&quot;&gt;Woojae Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tholke_P/0/1/0/all/0/1&quot;&gt;Philipp Th&amp;#xf6;lke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medani_T/0/1/0/all/0/1&quot;&gt;Takfarinas Medani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jerbi_K/0/1/0/all/0/1&quot;&gt;Karim Jerbi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1&quot;&gt;Anand A. Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leahy_R/0/1/0/all/0/1&quot;&gt;Richard M. Leahy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.03839">
<title>Aspects of human memory and Large Language Models. (arXiv:2311.03839v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.03839</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) are huge artificial neural networks which
primarily serve to generate text, but also provide a very sophisticated
probabilistic model of language use. Since generating a semantically consistent
text requires a form of effective memory, we investigate the memory properties
of LLMs and find surprising similarities with key characteristics of human
memory. We argue that the human-like memory properties of the Large Language
Model do not follow automatically from the LLM architecture but are rather
learned from the statistics of the training textual data. These results
strongly suggest that the biological features of human memory leave an imprint
on the way that we structure our textual narratives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janik_R/0/1/0/all/0/1&quot;&gt;Romuald A. Janik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04252">
<title>CNN-Based Structural Damage Detection using Time-Series Sensor Data. (arXiv:2311.04252v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.04252</link>
<description rdf:parseType="Literal">&lt;p&gt;Structural Health Monitoring (SHM) is vital for evaluating structural
condition, aiming to detect damage through sensor data analysis. It aligns with
predictive maintenance in modern industry, minimizing downtime and costs by
addressing potential structural issues. Various machine learning techniques
have been used to extract valuable information from vibration data, often
relying on prior structural knowledge. This research introduces an innovative
approach to structural damage detection, utilizing a new Convolutional Neural
Network (CNN) algorithm. In order to extract deep spatial features from time
series data, CNNs are taught to recognize long-term temporal connections. This
methodology combines spatial and temporal features, enhancing discrimination
capabilities when compared to methods solely reliant on deep spatial features.
Time series data are divided into two categories using the proposed neural
network: undamaged and damaged. To validate its efficacy, the method&apos;s accuracy
was tested using a benchmark dataset derived from a three-floor structure at
Los Alamos National Laboratory (LANL). The outcomes show that the new CNN
algorithm is very accurate in spotting structural degradation in the examined
structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_I/0/1/0/all/0/1&quot;&gt;Ishan Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_I/0/1/0/all/0/1&quot;&gt;Ishan Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadana_A/0/1/0/all/0/1&quot;&gt;Aditya Sadana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhowmik_B/0/1/0/all/0/1&quot;&gt;Basuraj Bhowmik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04592">
<title>On Characterizing the Evolution of Embedding Space of Neural Networks using Algebraic Topology. (arXiv:2311.04592v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.04592</link>
<description rdf:parseType="Literal">&lt;p&gt;We study how the topology of feature embedding space changes as it passes
through the layers of a well-trained deep neural network (DNN) through Betti
numbers. Motivated by existing studies using simplicial complexes on shallow
fully connected networks (FCN), we present an extended analysis using Cubical
homology instead, with a variety of popular deep architectures and real image
datasets. We demonstrate that as depth increases, a topologically complicated
dataset is transformed into a simple one, resulting in Betti numbers attaining
their lowest possible value. The rate of decay in topological complexity (as a
metric) helps quantify the impact of architectural choices on the
generalization ability. Interestingly from a representation learning
perspective, we highlight several invariances such as topological invariance of
(1) an architecture on similar datasets; (2) embedding space of a dataset for
architectures of variable depth; (3) embedding space to input resolution/size,
and (4) data sub-sampling. In order to further demonstrate the link between
expressivity \&amp;amp; the generalization capability of a network, we consider the
task of ranking pre-trained models for downstream classification task (transfer
learning). Compared to existing approaches, the proposed metric has a better
correlation to the actually achievable accuracy via fine-tuning the pre-trained
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1&quot;&gt;Suryaka Suresh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_B/0/1/0/all/0/1&quot;&gt;Bishshoy Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abrol_V/0/1/0/all/0/1&quot;&gt;Vinayak Abrol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sumantra Dutta Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.04661">
<title>Massive Editing for Large Language Models via Meta Learning. (arXiv:2311.04661v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.04661</link>
<description rdf:parseType="Literal">&lt;p&gt;While large language models (LLMs) have enabled learning knowledge from the
pre-training corpora, the acquired knowledge may be fundamentally incorrect or
outdated over time, which necessitates rectifying the knowledge of the language
model (LM) after the training. A promising approach involves employing a
hyper-network to generate parameter shift, whereas existing hyper-networks
suffer from inferior scalability in synchronous editing operation amount. To
mitigate the problem, we propose the MAssive Language Model Editing Network
(MALMEN), which formulates the parameter shift aggregation as the least square
problem, subsequently updating the LM parameters using the normal equation. To
accommodate editing multiple facts simultaneously with limited memory budgets,
we separate the computation on the hyper-network and LM, enabling arbitrary
batch size on both neural networks. Our method is evaluated by editing up to
thousands of facts on LMs with different architectures, i.e., BERT-base, GPT-2,
T5-XL (2.8B), and GPT-J (6B), across various knowledge-intensive NLP tasks,
i.e., closed book fact-checking and question answering. Remarkably, MALMEN is
capable of editing hundreds of times more facts than strong baselines with the
identical hyper-network architecture and outperforms editor specifically
designed for GPT. Our code is available at
https://github.com/ChenmienTan/malmen.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1&quot;&gt;Chenmien Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Ge Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jie Fu&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>