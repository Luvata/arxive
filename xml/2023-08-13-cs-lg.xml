<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-08-10T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05106" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05110" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05115" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05118" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05120" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05122" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05125" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05127" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05129" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05133" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05141" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05166" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05176" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05189" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05194" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05218" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05219" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05232" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05235" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05237" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05239" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05254" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05275" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05281" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05292" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05305" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05309" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05326" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05345" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05362" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05364" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05371" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05374" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05390" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05407" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05411" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05451" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05463" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05471" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05476" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05481" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05483" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05509" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05522" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05525" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05566" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05575" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05600" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05601" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05619" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05621" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05629" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05633" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05646" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05680" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05707" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05711" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05724" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05725" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05731" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05732" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05737" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05739" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05741" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.02495" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2202.09518" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2202.13341" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.07902" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.14408" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.04087" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.13662" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.03942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.04702" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.00790" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.05869" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.10822" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.00453" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.09738" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.14679" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.06024" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.06601" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.07925" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.08902" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.14961" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.05874" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.09797" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.10382" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.12177" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.03829" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.11122" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.11509" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12932" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19170" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.03805" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.06955" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.09807" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.13759" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.16021" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02279" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.07944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.14527" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15644" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.16361" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03152" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03382" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03712" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04704" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05011" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19069" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2308.05106">
<title>Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures. (arXiv:2308.05106v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05106</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents an investigation into machine learning techniques for
violence detection in videos and their adaptation to a federated learning
context. The study includes experiments with spatio-temporal features extracted
from benchmark video datasets, comparison of different methods, and proposal of
a modified version of the &quot;Flow-Gated&quot; architecture called &quot;Diff-Gated.&quot;
Additionally, various machine learning techniques, including super-convergence
and transfer learning, are explored, and a method for adapting centralized
datasets to a federated learning context is developed. The research achieves
better accuracy results compared to state-of-the-art models by training the
best violence detection model in a federated learning context.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quentin_P/0/1/0/all/0/1&quot;&gt;Pajon Quentin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swan_S/0/1/0/all/0/1&quot;&gt;Serre Swan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hugo_W/0/1/0/all/0/1&quot;&gt;Wissocq Hugo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leo_R/0/1/0/all/0/1&quot;&gt;Rabaud L&amp;#xe9;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siba_H/0/1/0/all/0/1&quot;&gt;Haidar Siba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antoun_Y/0/1/0/all/0/1&quot;&gt;Yaacoub Antoun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05110">
<title>Can Attention Be Used to Explain EHR-Based Mortality Prediction Tasks: A Case Study on Hemorrhagic Stroke. (arXiv:2308.05110v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05110</link>
<description rdf:parseType="Literal">&lt;p&gt;Stroke is a significant cause of mortality and morbidity, necessitating early
predictive strategies to minimize risks. Traditional methods for evaluating
patients, such as Acute Physiology and Chronic Health Evaluation (APACHE II,
IV) and Simplified Acute Physiology Score III (SAPS III), have limited accuracy
and interpretability. This paper proposes a novel approach: an interpretable,
attention-based transformer model for early stroke mortality prediction. This
model seeks to address the limitations of previous predictive models, providing
both interpretability (providing clear, understandable explanations of the
model) and fidelity (giving a truthful explanation of the model&apos;s dynamics from
input to output). Furthermore, the study explores and compares fidelity and
interpretability scores using Shapley values and attention-based scores to
improve model explainability. The research objectives include designing an
interpretable attention-based transformer model, evaluating its performance
compared to existing models, and providing feature importance derived from the
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1&quot;&gt;Qizhang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1&quot;&gt;Jiayi Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emdad_F/0/1/0/all/0/1&quot;&gt;Forhan Bin Emdad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanna_K/0/1/0/all/0/1&quot;&gt;Karim Hanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhe He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05115">
<title>PTransIPs: Identification of phosphorylation sites based on protein pretrained language model and Transformer. (arXiv:2308.05115v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/2308.05115</link>
<description rdf:parseType="Literal">&lt;p&gt;Phosphorylation is central to numerous fundamental cellular processes,
influencing the onset and progression of a variety of diseases. Identification
of phosphorylation sites is thus an important step for understanding the
molecular mechanisms of cells and virus infection, which potentially leads to
new therapeutic targets. In this study, we present PTransIPs, a novel deep
learning model for the identification of phosphorylation sites. PTransIPs
treats amino acids in protein sequences as words in natural language,
extracting unique encodings based on the types along with position of amino
acids in the sequence. It also incorporates embeddings from large pre-trained
protein models as additional data inputs. PTransIPS is further trained on a
combination model of convolutional neural network with residual connections and
Transformer model equipped with multi-head attention mechanisms. At last, the
model outputs classification results through a fully connected layer. The
results of independent testing reveal that PTransIPs outperforms existing
state-of-the-art methodologies, achieving AUROCs of 0.9232 and 0.9660 for
identifying phosphorylated S/T and Y sites respectively. In addition, ablation
studies prove that pretrained model embeddings contribute to the performance of
PTransIPs. Furthermore, PTransIPs has interpretable amino acid preference,
visible training process and shows generalizability on other bioactivity
classification tasks. To facilitate usage, our code and data are publicly
accessible at \url{https://github.com/StatXzy7/PTransIPs}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Ziyang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhong_H/0/1/0/all/0/1&quot;&gt;Haitian Zhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05118">
<title>Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries. (arXiv:2308.05118v1 [q-bio.GN])</title>
<link>http://arxiv.org/abs/2308.05118</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper demonstrates the utility of organized numerical representations of
genes in research involving flat string gene formats (i.e., FASTA/FASTQ5).
FASTA/FASTQ files have several current limitations, such as their large file
sizes, slow processing speeds for mapping and alignment, and contextual
dependencies. These challenges significantly hinder investigations and tasks
that involve finding similar sequences. The solution lies in transforming
sequences into an alternative representation that facilitates easier clustering
into similar groups compared to the raw sequences themselves. By assigning a
unique vector embedding to each short sequence, it is possible to more
efficiently cluster and improve upon compression performance for the string
representations of cDNA libraries. Furthermore, through learning alternative
coordinate vector embeddings based on the contexts of codon triplets, we can
demonstrate clustering based on amino acid properties. Finally, using this
sequence embedding method to encode barcodes and cDNA sequences, we can improve
the time complexity of the similarity search by coupling vector embeddings with
an algorithm that determines the proximity of vectors in Euclidean space; this
allows us to perform sequence similarity searches in a quicker and more modular
fashion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Um_D/0/1/0/all/0/1&quot;&gt;Daniel H. Um&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Knowles_D/0/1/0/all/0/1&quot;&gt;David A. Knowles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kaiser_G/0/1/0/all/0/1&quot;&gt;Gail E. Kaiser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05120">
<title>Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation &amp; Control Systems. (arXiv:2308.05120v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05120</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the field of data-driven neural network-based machine
learning (ML) algorithms has grown significantly and spurred research in its
applicability to instrumentation and control systems. While they are promising
in operational contexts, the trustworthiness of such algorithms is not
adequately assessed. Failures of ML-integrated systems are poorly understood;
the lack of comprehensive risk modeling can degrade the trustworthiness of
these systems. In recent reports by the National Institute for Standards and
Technology, trustworthiness in ML is a critical barrier to adoption and will
play a vital role in intelligent systems&apos; safe and accountable operation. Thus,
in this work, we demonstrate a real-time model-agnostic method to evaluate the
relative reliability of ML predictions by incorporating out-of-distribution
detection on the training dataset. It is well documented that ML algorithms
excel at interpolation (or near-interpolation) tasks but significantly degrade
at extrapolation. This occurs when new samples are &quot;far&quot; from training samples.
The method, referred to as the Laplacian distributed decay for reliability
(LADDR), determines the difference between the operational and training
datasets, which is used to calculate a prediction&apos;s relative reliability. LADDR
is demonstrated on a feedforward neural network-based model used to predict
safety significant factors during different loss-of-flow transients. LADDR is
intended as a &quot;data supervisor&quot; and determines the appropriateness of
well-trained ML models in the context of operational conditions. Ultimately,
LADDR illustrates how training data can be used as evidence to support the
trustworthiness of ML predictions when utilized for conventional interpolation
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1&quot;&gt;Edward Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1&quot;&gt;Han Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dinh_N/0/1/0/all/0/1&quot;&gt;Nam Dinh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05122">
<title>Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder. (arXiv:2308.05122v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/2308.05122</link>
<description rdf:parseType="Literal">&lt;p&gt;The multifactorial etiology of autism spectrum disorder (ASD) suggests that
its study would benefit greatly from multimodal approaches that combine data
from widely varying platforms, e.g., neuroimaging, genetics, and clinical
characterization. Prior neuroimaging-genetic analyses often apply naive feature
concatenation approaches in data-driven work or use the findings from one
modality to guide posthoc analysis of another, missing the opportunity to
analyze the paired multimodal data in a truly unified approach. In this paper,
we develop a more integrative model for combining genetic, demographic, and
neuroimaging data. Inspired by the influence of genotype on phenotype, we
propose using an attention-based approach where the genetic data guides
attention to neuroimaging features of importance for model prediction. The
genetic data is derived from copy number variation parameters, while the
neuroimaging data is from functional magnetic resonance imaging. We evaluate
the proposed approach on ASD classification and severity prediction tasks,
using a sex-balanced dataset of 228 ASD and typically developing subjects in a
10-fold cross-validation framework. We demonstrate that our attention-based
model combining genetic information, demographic data, and functional magnetic
resonance imaging results in superior prediction performance compared to other
multimodal approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Dvornek_N/0/1/0/all/0/1&quot;&gt;Nicha C. Dvornek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sullivan_C/0/1/0/all/0/1&quot;&gt;Catherine Sullivan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Duncan_J/0/1/0/all/0/1&quot;&gt;James S. Duncan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abha R. Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05125">
<title>Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network. (arXiv:2308.05125v1 [q-bio.MN])</title>
<link>http://arxiv.org/abs/2308.05125</link>
<description rdf:parseType="Literal">&lt;p&gt;The capacity to identify and analyze protein-protein interactions, along with
their internal modular organization, plays a crucial role in comprehending the
intricate mechanisms underlying biological processes at the molecular level. We
can learn a lot about the structure and dynamics of these interactions by using
network analysis. We can improve our understanding of the biological roots of
disease pathogenesis by recognizing network communities. This knowledge, in
turn, holds significant potential for driving advancements in drug discovery
and facilitating personalized medicine approaches for disease treatment. In
this study, we aimed to uncover the communities within the variant B.1.1.529
(Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and four
widely recognized algorithms: Girvan-Newman, Louvain, Leiden, and Label
Propagation algorithm. Each of these algorithms has established prominence in
the field and offers unique perspectives on identifying communities within
complex networks. We also compare the networks by the global properties,
statistic summary, subgraph count, graphlet and validate by the modulaity. By
employing these approaches, we sought to gain deeper insights into the
structural organization and interconnections present within the Omicron virus
network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Das_M/0/1/0/all/0/1&quot;&gt;Mamata Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+K%2E_S/0/1/0/all/0/1&quot;&gt;Selvakumar K.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Alphonse_P/0/1/0/all/0/1&quot;&gt;P.J.A. Alphonse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05127">
<title>Data-Free Model Extraction Attacks in the Context of Object Detection. (arXiv:2308.05127v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2308.05127</link>
<description rdf:parseType="Literal">&lt;p&gt;A significant number of machine learning models are vulnerable to model
extraction attacks, which focus on stealing the models by using specially
curated queries against the target model. This task is well accomplished by
using part of the training data or a surrogate dataset to train a new model
that mimics a target model in a white-box environment. In pragmatic situations,
however, the target models are trained on private datasets that are
inaccessible to the adversary. The data-free model extraction technique
replaces this problem when it comes to using queries artificially curated by a
generator similar to that used in Generative Adversarial Nets. We propose for
the first time, to the best of our knowledge, an adversary black box attack
extending to a regression problem for predicting bounding box coordinates in
object detection. As part of our study, we found that defining a loss function
and using a novel generator setup is one of the key aspects in extracting the
target model. We find that the proposed model extraction method achieves
significant results by using reasonable queries. The discovery of this object
detection vulnerability will support future prospects for securing such models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_H/0/1/0/all/0/1&quot;&gt;Harshit Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+G_A/0/1/0/all/0/1&quot;&gt;Aravindhan G&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_P/0/1/0/all/0/1&quot;&gt;Pavan Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Govidarajulu_Y/0/1/0/all/0/1&quot;&gt;Yuvaraj Govidarajulu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1&quot;&gt;Manojkumar Parmar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05129">
<title>Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?. (arXiv:2308.05129v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2308.05129</link>
<description rdf:parseType="Literal">&lt;p&gt;While many studies have assessed the fairness of AI algorithms in the medical
field, the causes of differences in prediction performance are often unknown.
This lack of knowledge about the causes of bias hampers the efficacy of bias
mitigation, as evidenced by the fact that simple dataset balancing still often
performs best in reducing performance gaps but is unable to resolve all
performance differences. In this work, we investigate the causes of gender bias
in machine learning-based chest X-ray diagnosis. In particular, we explore the
hypothesis that breast tissue leads to underexposure of the lungs and causes
lower model performance. Methodologically, we propose a new sampling method
which addresses the highly skewed distribution of recordings per patient in two
widely used public datasets, while at the same time reducing the impact of
label errors. Our comprehensive analysis of gender differences across diseases,
datasets, and gender representations in the training set shows that dataset
imbalance is not the sole cause of performance differences. Moreover, relative
group performance differs strongly between datasets, indicating important
dataset-specific factors influencing male/female group performance. Finally, we
investigate the effect of breast tissue more specifically, by cropping out the
breasts from recordings, finding that this does not resolve the observed
performance gaps. In conclusion, our results indicate that dataset-specific
factors, not fundamental physiological differences, are the main drivers of
male--female performance gaps in chest X-ray analyses on widely used NIH and
CheXpert Dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Weng_N/0/1/0/all/0/1&quot;&gt;Nina Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bigdeli_S/0/1/0/all/0/1&quot;&gt;Siavash Bigdeli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Petersen_E/0/1/0/all/0/1&quot;&gt;Eike Petersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Feragen_A/0/1/0/all/0/1&quot;&gt;Aasa Feragen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05133">
<title>Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders. (arXiv:2308.05133v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/2308.05133</link>
<description rdf:parseType="Literal">&lt;p&gt;The primary method for identifying mental disorders automatically has
traditionally involved using binary classifiers. These classifiers are trained
using behavioral data obtained from an interview setup. In this training
process, data from individuals with the specific disorder under consideration
are categorized as the positive class, while data from all other participants
constitute the negative class. In practice, it is widely recognized that
certain mental disorders share similar symptoms, causing the collected
behavioral data to encompass a variety of attributes associated with multiple
disorders. Consequently, attributes linked to the targeted mental disorder
might also be present within the negative class. This data impurity may lead to
sub-optimal training of the classifier for a mental disorder of interest. In
this study, we investigate this hypothesis in the context of major depressive
disorder (MDD) and post-traumatic stress disorder detection (PTSD). The results
show that upon removal of such data impurity, MDD and PTSD detection
performances are significantly improved.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gupta_R/0/1/0/all/0/1&quot;&gt;Rohan Kumar Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sinha_R/0/1/0/all/0/1&quot;&gt;Rohit Sinha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05141">
<title>Sound propagation in realistic interactive 3D scenes with parameterized sources using deep neural operators. (arXiv:2308.05141v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2308.05141</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the challenge of sound propagation simulations in $3$D virtual
rooms with moving sources, which have applications in virtual/augmented
reality, game audio, and spatial computing. Solutions to the wave equation can
describe wave phenomena such as diffraction and interference. However,
simulating them using conventional numerical discretization methods with
hundreds of source and receiver positions is intractable, making stimulating a
sound field with moving sources impractical. To overcome this limitation, we
propose using deep operator networks to approximate linear wave-equation
operators. This enables the rapid prediction of sound propagation in realistic
3D acoustic scenes with moving sources, achieving millisecond-scale
computations. By learning a compact surrogate model, we avoid the offline
calculation and storage of impulse responses for all relevant source/listener
pairs. Our experiments, including various complex scene geometries, show good
agreement with reference solutions, with root mean squared errors ranging from
0.02 Pa to 0.10 Pa. Notably, our method signifies a paradigm shift as no prior
machine learning approach has achieved precise predictions of complete wave
fields within realistic domains. We anticipate that our findings will drive
further exploration of deep neural operator methods, advancing research in
immersive user experiences within virtual environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borrel_Jensen_N/0/1/0/all/0/1&quot;&gt;Nikolas Borrel-Jensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goswami_S/0/1/0/all/0/1&quot;&gt;Somdatta Goswami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engsig_Karup_A/0/1/0/all/0/1&quot;&gt;Allan P. Engsig-Karup&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1&quot;&gt;George Em Karniadakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_C/0/1/0/all/0/1&quot;&gt;Cheol-Ho Jeong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05166">
<title>Deep Learning for Morphological Identification of Extended Radio Galaxies using Weak Labels. (arXiv:2308.05166v1 [astro-ph.IM])</title>
<link>http://arxiv.org/abs/2308.05166</link>
<description rdf:parseType="Literal">&lt;p&gt;The present work discusses the use of a weakly-supervised deep learning
algorithm that reduces the cost of labelling pixel-level masks for complex
radio galaxies with multiple components. The algorithm is trained on weak
class-level labels of radio galaxies to get class activation maps (CAMs). The
CAMs are further refined using an inter-pixel relations network (IRNet) to get
instance segmentation masks over radio galaxies and the positions of their
infrared hosts. We use data from the Australian Square Kilometre Array
Pathfinder (ASKAP) telescope, specifically the Evolutionary Map of the Universe
(EMU) Pilot Survey, which covered a sky area of 270 square degrees with an RMS
sensitivity of 25-35 $\mu$Jy/beam. We demonstrate that weakly-supervised deep
learning algorithms can achieve high accuracy in predicting pixel-level
information, including masks for the extended radio emission encapsulating all
galaxy components and the positions of the infrared host galaxies. We evaluate
the performance of our method using mean Average Precision (mAP) across
multiple classes at a standard intersection over union (IoU) threshold of 0.5.
We show that the model achieves a mAP$_{50}$ of 67.5\% and 76.8\% for radio
masks and infrared host positions, respectively. The network architecture can
be found at the following link: https://github.com/Nikhel1/Gal-CAM
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Gupta_N/0/1/0/all/0/1&quot;&gt;Nikhel Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Hayder_Z/0/1/0/all/0/1&quot;&gt;Zeeshan Hayder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Norris_R/0/1/0/all/0/1&quot;&gt;Ray P. Norris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Huynh_M/0/1/0/all/0/1&quot;&gt;Minh Huynh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Petersson_L/0/1/0/all/0/1&quot;&gt;Lars Petersson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;X. Rosalind Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Andernach_H/0/1/0/all/0/1&quot;&gt;Heinz Andernach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Koribalski_B/0/1/0/all/0/1&quot;&gt;B&amp;#xe4;rbel S. Koribalski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Yew_M/0/1/0/all/0/1&quot;&gt;Miranda Yew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Crawford_E/0/1/0/all/0/1&quot;&gt;Evan J. Crawford&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05176">
<title>Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models. (arXiv:2308.05176v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2308.05176</link>
<description rdf:parseType="Literal">&lt;p&gt;Epilepsy is a prevalent neurological disorder characterized by recurrent and
unpredictable seizures, necessitating accurate prediction for effective
management and patient care. Application of machine learning (ML) on
electroencephalogram (EEG) recordings, along with its ability to provide
valuable insights into brain activity during seizures, is able to make accurate
and robust seizure prediction an indispensable component in relevant studies.
In this research, we present a comprehensive comparative analysis of five
machine learning models - Random Forest (RF), Decision Tree (DT), Extra Trees
(ET), Logistic Regression (LR), and Gradient Boosting (GB) - for the prediction
of epileptic seizures using EEG data. The dataset underwent meticulous
preprocessing, including cleaning, normalization, outlier handling, and
oversampling, ensuring data quality and facilitating accurate model training.
These preprocessing techniques played a crucial role in enhancing the models&apos;
performance. The results of our analysis demonstrate the performance of each
model in terms of accuracy. The LR classifier achieved an accuracy of 56.95%,
while GB and DT both attained 97.17% accuracy. RT achieved a higher accuracy of
98.99%, while the ET model exhibited the best performance with an accuracy of
99.29%. Our findings reveal that the ET model outperformed not only the other
models in the comparative analysis but also surpassed the state-of-the-art
results from previous research. The superior performance of the ET model makes
it a compelling choice for accurate and robust epileptic seizure prediction
using EEG data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Talukder_M/0/1/0/all/0/1&quot;&gt;Md. Simul Hasan Talukder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sulaiman_R/0/1/0/all/0/1&quot;&gt;Rejwan Bin Sulaiman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05189">
<title>Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding. (arXiv:2308.05189v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05189</link>
<description rdf:parseType="Literal">&lt;p&gt;This PhD. Thesis concerns the study and development of hierarchical
representations for spatio-temporal visual attention modeling and understanding
in video sequences. More specifically, we propose two computational models for
visual attention. First, we present a generative probabilistic model for
context-aware visual attention modeling and understanding. Secondly, we develop
a deep network architecture for visual attention modeling, which first
estimates top-down spatio-temporal visual attention, and ultimately serves for
modeling attention in the temporal domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_Torres_M/0/1/0/all/0/1&quot;&gt;Miguel-&amp;#xc1;ngel Fern&amp;#xe1;ndez-Torres&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05194">
<title>Evaluating Pedestrian Trajectory Prediction Methods for the Application in Autonomous Driving. (arXiv:2308.05194v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05194</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, the state of the art in the field of pedestrian trajectory
prediction is evaluated alongside the constant velocity model (CVM) with
respect to its applicability in autonomous vehicles. The evaluation is
conducted on the widely-used ETH/UCY dataset where the Average Displacement
Error (ADE) and the Final Displacement Error (FDE) are reported. To align with
requirements in real-world applications, modifications are made to the input
features of the initially proposed models. An ablation study is conducted to
examine the influence of the observed motion history on the prediction
performance, thereby establishing a better understanding of its impact.
Additionally, the inference time of each model is measured to evaluate the
scalability of each model when confronted with varying amounts of agents. The
results demonstrate that simple models remain competitive when generating
single trajectories, and certain features commonly thought of as useful have
little impact on the overall performance across different architectures. Based
on these findings, recommendations are proposed to guide the future development
of trajectory prediction algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uhlemann_N/0/1/0/all/0/1&quot;&gt;Nico Uhlemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fent_F/0/1/0/all/0/1&quot;&gt;Felix Fent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lienkamp_M/0/1/0/all/0/1&quot;&gt;Markus Lienkamp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05218">
<title>Conformer-based Target-Speaker Automatic Speech Recognition for Single-Channel Audio. (arXiv:2308.05218v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2308.05218</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose CONF-TSASR, a non-autoregressive end-to-end time-frequency domain
architecture for single-channel target-speaker automatic speech recognition
(TS-ASR). The model consists of a TitaNet based speaker embedding module, a
Conformer based masking as well as ASR modules. These modules are jointly
optimized to transcribe a target-speaker, while ignoring speech from other
speakers. For training we use Connectionist Temporal Classification (CTC) loss
and introduce a scale-invariant spectrogram reconstruction loss to encourage
the model better separate the target-speaker&apos;s spectrogram from mixture. We
obtain state-of-the-art target-speaker word error rate (TS-WER) on
WSJ0-2mix-extr (4.2%). Further, we report for the first time TS-WER on
WSJ0-3mix-extr (12.4%), LibriSpeech2Mix (4.2%) and LibriSpeech3Mix (7.6%)
datasets, establishing new benchmarks for TS-ASR. The proposed model will be
open-sourced through NVIDIA NeMo toolkit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puvvada_K/0/1/0/all/0/1&quot;&gt;Krishna C. Puvvada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lavrukhin_V/0/1/0/all/0/1&quot;&gt;Vitaly Lavrukhin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ginsburg_B/0/1/0/all/0/1&quot;&gt;Boris Ginsburg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05219">
<title>Decoding Layer Saliency in Language Transformers. (arXiv:2308.05219v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.05219</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a strategy for identifying textual saliency in
large-scale language models applied to classification tasks. In visual networks
where saliency is more well-studied, saliency is naturally localized through
the convolutional layers of the network; however, the same is not true in
modern transformer-stack networks used to process natural language. We adapt
gradient-based saliency methods for these networks, propose a method for
evaluating the degree of semantic coherence of each layer, and demonstrate
consistent improvement over numerous other methods for textual saliency on
multiple benchmark classification datasets. Our approach requires no additional
training or access to labelled data, and is comparatively very computationally
efficient.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_E/0/1/0/all/0/1&quot;&gt;Elizabeth M. Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castanon_G/0/1/0/all/0/1&quot;&gt;Gregory Castanon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05226">
<title>Training neural networks with end-to-end optical backpropagation. (arXiv:2308.05226v1 [physics.optics])</title>
<link>http://arxiv.org/abs/2308.05226</link>
<description rdf:parseType="Literal">&lt;p&gt;Optics is an exciting route for the next generation of computing hardware for
machine learning, promising several orders of magnitude enhancement in both
computational speed and energy efficiency. However, to reach the full capacity
of an optical neural network it is necessary that the computing not only for
the inference, but also for the training be implemented optically. The primary
algorithm for training a neural network is backpropagation, in which the
calculation is performed in the order opposite to the information flow for
inference. While straightforward in a digital computer, optical implementation
of backpropagation has so far remained elusive, particularly because of the
conflicting requirements for the optical element that implements the nonlinear
activation function. In this work, we address this challenge for the first time
with a surprisingly simple and generic scheme. Saturable absorbers are employed
for the role of the activation units, and the required properties are achieved
through a pump-probe process, in which the forward propagating signal acts as
the pump and backward as the probe. Our approach is adaptable to various analog
platforms, materials, and network structures, and it demonstrates the
possibility of constructing neural networks entirely reliant on analog optical
processes for both training and inference tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Spall_J/0/1/0/all/0/1&quot;&gt;James Spall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xianxin Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lvovsky_A/0/1/0/all/0/1&quot;&gt;A. I. Lvovsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05232">
<title>SegMatch: A semi-supervised learning method for surgical instrument segmentation. (arXiv:2308.05232v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05232</link>
<description rdf:parseType="Literal">&lt;p&gt;Surgical instrument segmentation is recognised as a key enabler to provide
advanced surgical assistance and improve computer assisted interventions. In
this work, we propose SegMatch, a semi supervised learning method to reduce the
need for expensive annotation for laparoscopic and robotic surgical images.
SegMatch builds on FixMatch, a widespread semi supervised classification
pipeline combining consistency regularization and pseudo labelling, and adapts
it for the purpose of segmentation. In our proposed SegMatch, the unlabelled
images are weakly augmented and fed into the segmentation model to generate a
pseudo-label to enforce the unsupervised loss against the output of the model
for the adversarial augmented image on the pixels with a high confidence score.
Our adaptation for segmentation tasks includes carefully considering the
equivariance and invariance properties of the augmentation functions we rely
on. To increase the relevance of our augmentations, we depart from using only
handcrafted augmentations and introduce a trainable adversarial augmentation
strategy. Our algorithm was evaluated on the MICCAI Instrument Segmentation
Challenge datasets Robust-MIS 2019 and EndoVis 2017. Our results demonstrate
that adding unlabelled data for training purposes allows us to surpass the
performance of fully supervised approaches which are limited by the
availability of training data in these challenges. SegMatch also outperforms a
range of state-of-the-art semi-supervised learning semantic segmentation models
in different labelled to unlabelled data ratios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_M/0/1/0/all/0/1&quot;&gt;Meng Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budd_C/0/1/0/all/0/1&quot;&gt;Charlie Budd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Peraza_Herrera_L/0/1/0/all/0/1&quot;&gt;Luis C. Garcia-Peraza-Herrera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dorent_R/0/1/0/all/0/1&quot;&gt;Reuben Dorent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1&quot;&gt;Miaojing Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vercauteren_T/0/1/0/all/0/1&quot;&gt;Tom Vercauteren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05234">
<title>Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving. (arXiv:2308.05234v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05234</link>
<description rdf:parseType="Literal">&lt;p&gt;Environmental perception is a key element of autonomous driving because the
information received from the perception module influences core driving
decisions. An outstanding challenge in real-time perception for autonomous
driving lies in finding the best trade-off between detection quality and
latency. Major constraints on both computation and power have to be taken into
account for real-time perception in autonomous vehicles. Larger object
detection models tend to produce the best results, but are also slower at
runtime. Since the most accurate detectors cannot run in real-time locally, we
investigate the possibility of offloading computation to edge and cloud
platforms, which are less resource-constrained. We create a synthetic dataset
to train object detection models and evaluate different offloading strategies.
Using real hardware and network simulations, we compare different trade-offs
between prediction quality and end-to-end delay. Since sending raw frames over
the network implies additional transmission delays, we also explore the use of
JPEG and H.265 compression at varying qualities and measure their impact on
prediction metrics. We show that models with adequate compression can be run in
real-time on the cloud while outperforming local detection performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hawlader_F/0/1/0/all/0/1&quot;&gt;Faisal Hawlader&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinet_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Robinet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_R/0/1/0/all/0/1&quot;&gt;Rapha&amp;#xeb;l Frank&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05235">
<title>Spatial Gated Multi-Layer Perceptron for Land Use and Land Cover Mapping. (arXiv:2308.05235v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05235</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional Neural Networks (CNNs) are models that are utilized extensively
for the hierarchical extraction of features. Vision transformers (ViTs),
through the use of a self-attention mechanism, have recently achieved superior
modeling of global contextual information compared to CNNs. However, to realize
their image classification strength, ViTs require substantial training
datasets. Where the available training data are limited, current advanced
multi-layer perceptrons (MLPs) can provide viable alternatives to both deep
CNNs and ViTs. In this paper, we developed the SGU-MLP, a learning algorithm
that effectively uses both MLPs and spatial gating units (SGUs) for precise
land use land cover (LULC) mapping. Results illustrated the superiority of the
developed SGU-MLP classification algorithm over several CNN and CNN-ViT-based
models, including HybridSN, ResNet, iFormer, EfficientFormer and CoAtNet. The
proposed SGU-MLP algorithm was tested through three experiments in Houston,
USA, Berlin, Germany and Augsburg, Germany. The SGU-MLP classification model
was found to consistently outperform the benchmark CNN and CNN-ViT-based
algorithms. For example, for the Houston experiment, SGU-MLP significantly
outperformed HybridSN, CoAtNet, Efficientformer, iFormer and ResNet by
approximately 15%, 19%, 20%, 21%, and 25%, respectively, in terms of average
accuracy. The code will be made publicly available at
https://github.com/aj1365/SGUMLP
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamali_A/0/1/0/all/0/1&quot;&gt;Ali Jamali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Swalpa Kumar Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1&quot;&gt;Danfeng Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atkinson_P/0/1/0/all/0/1&quot;&gt;Peter M Atkinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghamisi_P/0/1/0/all/0/1&quot;&gt;Pedram Ghamisi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05237">
<title>Financial Fraud Detection: A Comparative Study of Quantum Machine Learning Models. (arXiv:2308.05237v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2308.05237</link>
<description rdf:parseType="Literal">&lt;p&gt;In this research, a comparative study of four Quantum Machine Learning (QML)
models was conducted for fraud detection in finance. We proved that the Quantum
Support Vector Classifier model achieved the highest performance, with F1
scores of 0.98 for fraud and non-fraud classes. Other models like the
Variational Quantum Classifier, Estimator Quantum Neural Network (QNN), and
Sampler QNN demonstrate promising results, propelling the potential of QML
classification for financial applications. While they exhibit certain
limitations, the insights attained pave the way for future enhancements and
optimisation strategies. However, challenges exist, including the need for more
efficient Quantum algorithms and larger and more complex datasets. The article
provides solutions to overcome current limitations and contributes new insights
to the field of Quantum Machine Learning in fraud detection, with important
implications for its future development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Innan_N/0/1/0/all/0/1&quot;&gt;Nouhaila Innan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Muhammad Al-Zafar Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bennai_M/0/1/0/all/0/1&quot;&gt;Mohamed Bennai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05239">
<title>AI-Enabled Software and System Architecture Frameworks: Focusing on smart Cyber-Physical Systems (CPS). (arXiv:2308.05239v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2308.05239</link>
<description rdf:parseType="Literal">&lt;p&gt;Several architecture frameworks for software, systems, and enterprises have
been proposed in the literature. They identified various stakeholders and
defined architecture viewpoints and views to frame and address stakeholder
concerns. However, the stakeholders with data science and Machine Learning (ML)
related concerns, such as data scientists and data engineers, are yet to be
included in existing architecture frameworks. Therefore, they failed to address
the architecture viewpoints and views responsive to the concerns of the data
science community. In this paper, we address this gap by establishing the
architecture frameworks adapted to meet the requirements of modern applications
and organizations where ML artifacts are both prevalent and crucial. In
particular, we focus on ML-enabled Cyber-Physical Systems (CPSs) and propose
two sets of merit criteria for their efficient development and performance
assessment, namely the criteria for evaluating and benchmarking ML-enabled
CPSs, and the criteria for evaluation and benchmarking of the tools intended to
support users through the modeling and development pipeline. In this study, we
deploy multiple empirical and qualitative research methods based on literature
review and survey instruments including expert interviews and an online
questionnaire. We collect, analyze, and integrate the opinions of 77 experts
from more than 25 organizations in over 10 countries to devise and validate the
proposed framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moin_A/0/1/0/all/0/1&quot;&gt;Armin Moin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badii_A/0/1/0/all/0/1&quot;&gt;Atta Badii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Challenger_M/0/1/0/all/0/1&quot;&gt;Moharram Challenger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05254">
<title>Data-driven Intra-Autonomous Systems Graph Generator. (arXiv:2308.05254v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2308.05254</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a novel deep-learning based generator of synthetic
graphs that represent intra-Autonomous System (AS) in the Internet, named
Deep-generative graphs for the Internet (DGGI). It also presents a novel
massive dataset of real intra-AS graphs extracted from the project Internet
Topology Data Kit (ITDK), called Internet Graphs (IGraphs). To create IGraphs,
the Filtered Recurrent Multi-level (FRM) algorithm for community extraction was
developed. It is shown that DGGI creates synthetic graphs which accurately
reproduce the properties of centrality, clustering, assortativity, and node
degree. The DGGI generator overperforms existing Internet topology generators.
On average, DGGI improves the Maximum Mean Discrepancy (MMD) metric 84.4%,
95.1%, 97.9%, and 94.7% for assortativity, betweenness, clustering, and node
degree, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dadauto_C/0/1/0/all/0/1&quot;&gt;Caio Vinicius Dadauto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonseca_N/0/1/0/all/0/1&quot;&gt;Nelson Luis Saldanha da Fonseca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torres_R/0/1/0/all/0/1&quot;&gt;Ricardo da Silva Torres&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05275">
<title>Cross-heterogeneity Graph Few-shot Learning. (arXiv:2308.05275v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05275</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, heterogeneous graph few-shot learning has been proposed to
address the label sparsity issue in heterogeneous graphs (HGs), which contain
various types of nodes and edges. The existing methods have achieved good
performance by transferring generalized knowledge extracted from rich-labeled
classes in source HG(s) to few-labeled classes in a target HG. However, these
methods only consider the single-heterogeneity scenario where the source and
target HGs share a fixed set of node/edge types, ignoring the more general
scenario of cross-heterogeneity, where each HG can have a different and
non-fixed set of node/edge types. To this end, we focus on the unexplored
cross-heterogeneity scenario and propose a novel model for Cross-heterogeneity
Graph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patterns
to capture heterogeneous information and propose a multi-view heterogeneous
graph neural network (MHGN) to learn meta-patterns across HGs. Then, we propose
a score module to measure the informativeness of labeled samples and determine
the transferability of each source HG. Finally, by integrating MHGN and the
score module into a meta-learning mechanism, CGFL can effectively transfer
generalized knowledge to predict new classes with few-labeled data. Extensive
experiments on four real-world datasets have demonstrated the superior
performance of CGFL over the state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1&quot;&gt;Pengfei Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guanfeng Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05281">
<title>Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season. (arXiv:2308.05281v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2308.05281</link>
<description rdf:parseType="Literal">&lt;p&gt;Effective disaster response is critical for affected communities. Responders
and decision-makers would benefit from reliable, timely measures of the issues
impacting their communities during a disaster, and social media offers a
potentially rich data source. Social media can reflect public concerns and
demands during a disaster, offering valuable insights for decision-makers to
understand evolving situations and optimize resource allocation. We used
Bidirectional Encoder Representations from Transformers (BERT) topic modeling
to cluster topics from Twitter data. Then, we conducted a temporal-spatial
analysis to examine the distribution of these topics across different regions
during the 2020 western U.S. wildfire season. Our results show that Twitter
users mainly focused on three topics:&quot;health impact,&quot; &quot;damage,&quot; and
&quot;evacuation.&quot; We used the Susceptible-Infected-Recovered (SIR) theory to
explore the magnitude and velocity of topic diffusion on Twitter. The results
displayed a clear relationship between topic trends and wildfire propagation
patterns. The estimated parameters obtained from the SIR model in selected
cities revealed that residents exhibited a high level of several concerns
during the wildfire. Our study details how the SIR model and topic modeling
using social media data can provide decision-makers with a quantitative
approach to measure disaster response and support their decision-making
processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zihui Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lingyao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemphill_L/0/1/0/all/0/1&quot;&gt;Libby Hemphill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baecher_G/0/1/0/all/0/1&quot;&gt;Gregory B. Baecher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05292">
<title>Byzantine-Robust Decentralized Stochastic Optimization with Stochastic Gradient Noise-Independent Learning Error. (arXiv:2308.05292v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05292</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies Byzantine-robust stochastic optimization over a
decentralized network, where every agent periodically communicates with its
neighbors to exchange local models, and then updates its own local model by
stochastic gradient descent (SGD). The performance of such a method is affected
by an unknown number of Byzantine agents, which conduct adversarially during
the optimization process. To the best of our knowledge, there is no existing
work that simultaneously achieves a linear convergence speed and a small
learning error. We observe that the learning error is largely dependent on the
intrinsic stochastic gradient noise. Motivated by this observation, we
introduce two variance reduction methods, stochastic average gradient algorithm
(SAGA) and loopless stochastic variance-reduced gradient (LSVRG), to
Byzantine-robust decentralized stochastic optimization for eliminating the
negative effect of the stochastic gradient noise. The two resulting methods,
BRAVO-SAGA and BRAVO-LSVRG, enjoy both linear convergence speeds and stochastic
gradient noise-independent learning errors. Such learning errors are optimal
for a class of methods based on total variation (TV)-norm regularization and
stochastic subgradient update. We conduct extensive numerical experiments to
demonstrate their effectiveness under various Byzantine attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1&quot;&gt;Jie Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Weiyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_Q/0/1/0/all/0/1&quot;&gt;Qing Ling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05305">
<title>From CNN to Transformer: A Review of Medical Image Segmentation Models. (arXiv:2308.05305v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2308.05305</link>
<description rdf:parseType="Literal">&lt;p&gt;Medical image segmentation is an important step in medical image analysis,
especially as a crucial prerequisite for efficient disease diagnosis and
treatment. The use of deep learning for image segmentation has become a
prevalent trend. The widely adopted approach currently is U-Net and its
variants. Additionally, with the remarkable success of pre-trained models in
natural language processing tasks, transformer-based models like TransUNet have
achieved desirable performance on multiple medical image segmentation datasets.
In this paper, we conduct a survey of the most representative four medical
image segmentation models in recent years. We theoretically analyze the
characteristics of these models and quantitatively evaluate their performance
on two benchmark datasets (i.e., Tuberculosis Chest X-rays and ovarian tumors).
Finally, we discuss the main challenges and future trends in medical image
segmentation. Our work can assist researchers in the related field to quickly
establish medical segmentation models tailored to specific regions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yao_W/0/1/0/all/0/1&quot;&gt;Wenjian Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bai_J/0/1/0/all/0/1&quot;&gt;Jiajun Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liao_W/0/1/0/all/0/1&quot;&gt;Wei Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Mengjuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yao Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05309">
<title>Homophily-enhanced Structure Learning for Graph Clustering. (arXiv:2308.05309v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05309</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph clustering is a fundamental task in graph analysis, and recent advances
in utilizing graph neural networks (GNNs) have shown impressive results.
Despite the success of existing GNN-based graph clustering methods, they often
overlook the quality of graph structure, which is inherent in real-world graphs
due to their sparse and multifarious nature, leading to subpar performance.
Graph structure learning allows refining the input graph by adding missing
links and removing spurious connections. However, previous endeavors in graph
structure learning have predominantly centered around supervised settings, and
cannot be directly applied to our specific clustering tasks due to the absence
of ground-truth labels. To bridge the gap, we propose a novel method called
\textbf{ho}mophily-enhanced structure \textbf{le}arning for graph clustering
(HoLe). Our motivation stems from the observation that subtly enhancing the
degree of homophily within the graph structure can significantly improve GNNs
and clustering outcomes. To realize this objective, we develop two
clustering-oriented structure learning modules, i.e., hierarchical correlation
estimation and cluster-aware sparsification. The former module enables a more
accurate estimation of pairwise node relationships by leveraging guidance from
latent and clustering spaces, while the latter one generates a sparsified
structure based on the similarity matrix and clustering assignments.
Additionally, we devise a joint optimization approach alternating between
training the homophily-enhanced structure learning and GNN-based clustering,
thereby enforcing their reciprocal effects. Extensive experiments on seven
benchmark datasets of various types and scales, across a range of clustering
metrics, demonstrate the superiority of HoLe against state-of-the-art
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_M/0/1/0/all/0/1&quot;&gt;Ming Gu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Gaoming Yang&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sheng Zhou&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_N/0/1/0/all/0/1&quot;&gt;Ning Ma&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiawei Chen&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Q/0/1/0/all/0/1&quot;&gt;Qiaoyu Tan&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Meihan Liu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bu_J/0/1/0/all/0/1&quot;&gt;Jiajun Bu&lt;/a&gt; (1) ((1) College of Computer Science and Technology, Zhejiang University, (2) School of Software Technology, Zhejiang University, (3) Zhejiang Provincial Key Laboratory of Service Robot, Zhejiang University, (4) Department of Computer Science, New York University Shanghai)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05326">
<title>OpenProteinSet: Training data for structural biology at scale. (arXiv:2308.05326v1 [q-bio.BM])</title>
<link>http://arxiv.org/abs/2308.05326</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple sequence alignments (MSAs) of proteins encode rich biological
information and have been workhorses in bioinformatic methods for tasks like
protein design and protein structure prediction for decades. Recent
breakthroughs like AlphaFold2 that use transformers to attend directly over
large quantities of raw MSAs have reaffirmed their importance. Generation of
MSAs is highly computationally intensive, however, and no datasets comparable
to those used to train AlphaFold2 have been made available to the research
community, hindering progress in machine learning for proteins. To remedy this
problem, we introduce OpenProteinSet, an open-source corpus of more than 16
million MSAs, associated structural homologs from the Protein Data Bank, and
AlphaFold2 protein structure predictions. We have previously demonstrated the
utility of OpenProteinSet by successfully retraining AlphaFold2 on it. We
expect OpenProteinSet to be broadly useful as training and validation data for
1) diverse tasks focused on protein structure, function, and design and 2)
large-scale multimodal machine learning research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ahdritz_G/0/1/0/all/0/1&quot;&gt;Gustaf Ahdritz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Bouatta_N/0/1/0/all/0/1&quot;&gt;Nazim Bouatta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kadyan_S/0/1/0/all/0/1&quot;&gt;Sachin Kadyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Jarosch_L/0/1/0/all/0/1&quot;&gt;Lukas Jarosch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Berenberg_D/0/1/0/all/0/1&quot;&gt;Daniel Berenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Fisk_I/0/1/0/all/0/1&quot;&gt;Ian Fisk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Watkins_A/0/1/0/all/0/1&quot;&gt;Andrew M. Watkins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ra_S/0/1/0/all/0/1&quot;&gt;Stephen Ra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Bonneau_R/0/1/0/all/0/1&quot;&gt;Richard Bonneau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+AlQuraishi_M/0/1/0/all/0/1&quot;&gt;Mohammed AlQuraishi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05345">
<title>RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model. (arXiv:2308.05345v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05345</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by the recent success of large language models (LLMs) like ChatGPT,
researchers start to explore the adoption of LLMs for agile hardware design,
such as generating design RTL based on natural-language instructions. However,
in existing works, their target designs are all relatively simple and in a
small scale, and proposed by the authors themselves, making a fair comparison
among different LLM solutions challenging. In addition, many prior works only
focus on the design correctness, without evaluating the design qualities of
generated design RTL. In this work, we propose an open-source benchmark named
RTLLM, for generating design RTL with natural language instructions. To
systematically evaluate the auto-generated design RTL, we summarized three
progressive goals, named syntax goal, functionality goal, and design quality
goal. This benchmark can automatically provide a quantitative evaluation of any
given LLM-based solution. Furthermore, we propose an easy-to-use yet
surprisingly effective prompt engineering technique named self-planning, which
proves to significantly boost the performance of GPT-3.5 in our proposed
benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yao Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qijun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1&quot;&gt;Zhiyao Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05353">
<title>Preemptive Detection of Fake Accounts on Social Networks via Multi-Class Preferential Attachment Classifiers. (arXiv:2308.05353v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2308.05353</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we describe a new algorithm called Preferential Attachment
k-class Classifier (PreAttacK) for detecting fake accounts in a social network.
Recently, several algorithms have obtained high accuracy on this problem.
However, they have done so by relying on information about fake accounts&apos;
friendships or the content they share with others--the very things we seek to
prevent. PreAttacK represents a significant departure from these approaches. We
provide some of the first detailed distributional analyses of how new fake (and
real) accounts first attempt to request friends after joining a major network
(Facebook). We show that even before a new account has made friends or shared
content, these initial friend request behaviors evoke a natural multi-class
extension of the canonical Preferential Attachment model of social network
growth. We use this model to derive a new algorithm, PreAttacK. We prove that
in relevant problem instances, PreAttacK near-optimally approximates the
posterior probability that a new account is fake under this multi-class
Preferential Attachment model of new accounts&apos; (not-yet-answered) friend
requests. These are the first provable guarantees for fake account detection
that apply to new users, and that do not require strong homophily assumptions.
This principled approach also makes PreAttacK the only algorithm with provable
guarantees that obtains state-of-the-art performance on new users on the global
Facebook network, where it converges to AUC=0.9 after new users send + receive
a total of just 20 not-yet-answered friend requests. For comparison,
state-of-the-art benchmarks do not obtain this AUC even after observing
additional data on new users&apos; first 100 friend requests. Thus, unlike
mainstream algorithms, PreAttacK converges before the median new fake account
has made a single friendship (accepted friend request) with a human.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Breuer_A/0/1/0/all/0/1&quot;&gt;Adam Breuer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khosravani_N/0/1/0/all/0/1&quot;&gt;Nazanin Khosravani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tingley_M/0/1/0/all/0/1&quot;&gt;Michael Tingley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cottel_B/0/1/0/all/0/1&quot;&gt;Bradford Cottel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05362">
<title>FINER: Enhancing State-of-the-art Classifiers with Feature Attribution to Facilitate Security Analysis. (arXiv:2308.05362v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2308.05362</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning classifiers achieve state-of-the-art performance in various
risk detection applications. They explore rich semantic representations and are
supposed to automatically discover risk behaviors. However, due to the lack of
transparency, the behavioral semantics cannot be conveyed to downstream
security experts to reduce their heavy workload in security analysis. Although
feature attribution (FA) methods can be used to explain deep learning, the
underlying classifier is still blind to what behavior is suspicious, and the
generated explanation cannot adapt to downstream tasks, incurring poor
explanation fidelity and intelligibility. In this paper, we propose FINER, the
first framework for risk detection classifiers to generate high-fidelity and
high-intelligibility explanations. The high-level idea is to gather explanation
efforts from model developer, FA designer, and security experts. To improve
fidelity, we fine-tune the classifier with an explanation-guided multi-task
learning strategy. To improve intelligibility, we engage task knowledge to
adjust and ensemble FA methods. Extensive evaluations show that FINER improves
explanation quality for risk detection. Moreover, we demonstrate that FINER
outperforms a state-of-the-art tool in facilitating malware analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yiling He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1&quot;&gt;Jian Lou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1&quot;&gt;Zhan Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1&quot;&gt;Kui Ren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05364">
<title>Machine Learning aided Computer Architecture Design for CNN Inferencing Systems. (arXiv:2308.05364v1 [cs.AR])</title>
<link>http://arxiv.org/abs/2308.05364</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient and timely calculations of Machine Learning (ML) algorithms are
essential for emerging technologies like autonomous driving, the Internet of
Things (IoT), and edge computing. One of the primary ML algorithms used in such
systems is Convolutional Neural Networks (CNNs), which demand high
computational resources. This requirement has led to the use of ML accelerators
like GPGPUs to meet design constraints. However, selecting the most suitable
accelerator involves Design Space Exploration (DSE), a process that is usually
time-consuming and requires significant manual effort. Our work presents
approaches to expedite the DSE process by identifying the most appropriate
GPGPU for CNN inferencing systems. We have developed a quick and precise
technique for forecasting the power and performance of CNNs during inference,
with a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computer
architects to estimate power and performance in the early stages of
development, reducing the necessity for numerous prototypes. This saves time
and money while also improving the time-to-market period.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metz_C/0/1/0/all/0/1&quot;&gt;Christopher A. Metz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05371">
<title>Flexible Isosurface Extraction for Gradient-Based Mesh Optimization. (arXiv:2308.05371v1 [cs.GR])</title>
<link>http://arxiv.org/abs/2308.05371</link>
<description rdf:parseType="Literal">&lt;p&gt;This work considers gradient-based mesh optimization, where we iteratively
optimize for a 3D surface mesh by representing it as the isosurface of a scalar
field, an increasingly common paradigm in applications including
photogrammetry, generative modeling, and inverse physics. Existing
implementations adapt classic isosurface extraction algorithms like Marching
Cubes or Dual Contouring; these techniques were designed to extract meshes from
fixed, known fields, and in the optimization setting they lack the degrees of
freedom to represent high-quality feature-preserving meshes, or suffer from
numerical instabilities. We introduce FlexiCubes, an isosurface representation
specifically designed for optimizing an unknown mesh with respect to geometric,
visual, or even physical objectives. Our main insight is to introduce
additional carefully-chosen parameters into the representation, which allow
local flexible adjustments to the extracted mesh geometry and connectivity.
These parameters are updated along with the underlying scalar field via
automatic differentiation when optimizing for a downstream task. We base our
extraction scheme on Dual Marching Cubes for improved topological properties,
and present extensions to optionally generate tetrahedral and
hierarchically-adaptive meshes. Extensive experiments validate FlexiCubes on
both synthetic benchmarks and real-world applications, showing that it offers
significant improvements in mesh quality and geometric fidelity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1&quot;&gt;Tianchang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munkberg_J/0/1/0/all/0/1&quot;&gt;Jacob Munkberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasselgren_J/0/1/0/all/0/1&quot;&gt;Jon Hasselgren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1&quot;&gt;Kangxue Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wenzheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gojcic_Z/0/1/0/all/0/1&quot;&gt;Zan Gojcic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1&quot;&gt;Sanja Fidler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharp_N/0/1/0/all/0/1&quot;&gt;Nicholas Sharp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jun Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05374">
<title>Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models&apos; Alignment. (arXiv:2308.05374v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2308.05374</link>
<description rdf:parseType="Literal">&lt;p&gt;Ensuring alignment, which refers to making models behave in accordance with
human intentions [1,2], has become a critical task before deploying large
language models (LLMs) in real-world applications. For instance, OpenAI devoted
six months to iteratively aligning GPT-4 before its release [3]. However, a
major challenge faced by practitioners is the lack of clear guidance on
evaluating whether LLM outputs align with social norms, values, and
regulations. This obstacle hinders systematic iteration and deployment of LLMs.
To address this issue, this paper presents a comprehensive survey of key
dimensions that are crucial to consider when assessing LLM trustworthiness. The
survey covers seven major categories of LLM trustworthiness: reliability,
safety, fairness, resistance to misuse, explainability and reasoning, adherence
to social norms, and robustness. Each major category is further divided into
several sub-categories, resulting in a total of 29 sub-categories.
Additionally, a subset of 8 sub-categories is selected for further
investigation, where corresponding measurement studies are designed and
conducted on several widely-used LLMs. The measurement results indicate that,
in general, more aligned models tend to perform better in terms of overall
trustworthiness. However, the effectiveness of alignment varies across the
different trustworthiness categories considered. This highlights the importance
of conducting more fine-grained analyses, testing, and making continuous
improvements on LLM alignment. By shedding light on these key dimensions of LLM
trustworthiness, this paper aims to provide valuable insights and guidance to
practitioners in the field. Understanding and addressing these concerns will be
crucial in achieving reliable and ethically sound deployment of LLMs in various
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yuanshun Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ton_J/0/1/0/all/0/1&quot;&gt;Jean-Francois Ton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaoying Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_R/0/1/0/all/0/1&quot;&gt;Ruocheng Guo Hao Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klochkov_Y/0/1/0/all/0/1&quot;&gt;Yegor Klochkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taufiq_M/0/1/0/all/0/1&quot;&gt;Muhammad Faaiz Taufiq&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05390">
<title>Product Review Image Ranking for Fashion E-commerce. (arXiv:2308.05390v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05390</link>
<description rdf:parseType="Literal">&lt;p&gt;In a fashion e-commerce platform where customers can&apos;t physically examine the
products on their own, being able to see other customers&apos; text and image
reviews of the product is critical while making purchase decisions. Given the
high reliance on these reviews, over the years we have observed customers
proactively sharing their reviews. With an increase in the coverage of User
Generated Content (UGC), there has been a corresponding increase in the number
of customer images. It is thus imperative to display the most relevant images
on top as it may influence users&apos; online shopping choices and behavior. In this
paper, we propose a simple yet effective training procedure for ranking
customer images. We created a dataset consisting of Myntra (A Major Indian
Fashion e-commerce company) studio posts and highly engaged (upvotes/downvotes)
UGC images as our starting point and used selected distortion techniques on the
images of the above dataset to bring their quality at par with those of bad UGC
images. We train our network to rank bad-quality images lower than high-quality
ones. Our proposed method outperforms the baseline models on two metrics,
namely correlation coefficient, and accuracy, by substantial margins.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaiswal_S/0/1/0/all/0/1&quot;&gt;Sangeet Jaiswal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1&quot;&gt;Dhruv Patel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vempati_S/0/1/0/all/0/1&quot;&gt;Sreekanth Vempati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saiswaroop_K/0/1/0/all/0/1&quot;&gt;Konduru Saiswaroop&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05407">
<title>A Comparative Assessment of Multi-view fusion learning for Crop Classification. (arXiv:2308.05407v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05407</link>
<description rdf:parseType="Literal">&lt;p&gt;With a rapidly increasing amount and diversity of remote sensing (RS) data
sources, there is a strong need for multi-view learning modeling. This is a
complex task when considering the differences in resolution, magnitude, and
noise of RS data. The typical approach for merging multiple RS sources has been
input-level fusion, but other - more advanced - fusion strategies may
outperform this traditional approach. This work assesses different fusion
strategies for crop classification in the CropHarvest dataset. The fusion
methods proposed in this work outperform models based on individual views and
previous fusion methods. We do not find one single fusion method that
consistently outperforms all other approaches. Instead, we present a comparison
of multi-view fusion methods for three different datasets and show that,
depending on the test region, different methods obtain the best performance.
Despite this, we suggest a preliminary criterion for the selection of fusion
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mena_F/0/1/0/all/0/1&quot;&gt;Francisco Mena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arenas_D/0/1/0/all/0/1&quot;&gt;Diego Arenas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nuske_M/0/1/0/all/0/1&quot;&gt;Marlon Nuske&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1&quot;&gt;Andreas Dengel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05411">
<title>Explainable AI applications in the Medical Domain: a systematic review. (arXiv:2308.05411v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2308.05411</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prentzas_N/0/1/0/all/0/1&quot;&gt;Nicoletta Prentzas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakas_A/0/1/0/all/0/1&quot;&gt;Antonis Kakas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pattichis_C/0/1/0/all/0/1&quot;&gt;Constantinos S. Pattichis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05451">
<title>A Forecaster&apos;s Review of Judea Pearl&apos;s Causality: Models, Reasoning and Inference, Second Edition, 2009. (arXiv:2308.05451v1 [stat.ME])</title>
<link>http://arxiv.org/abs/2308.05451</link>
<description rdf:parseType="Literal">&lt;p&gt;With the big popularity and success of Judea Pearl&apos;s original causality book,
this review covers the main topics updated in the second edition in 2009 and
illustrates an easy-to-follow causal inference strategy in a forecast scenario.
It further discusses some potential benefits and challenges for causal
inference with time series forecasting when modeling the counterfactuals,
estimating the uncertainty and incorporating prior knowledge to estimate causal
effects in different forecasting scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Feng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05463">
<title>$\mathcal{G}^2Pxy$: Generative Open-Set Node Classification on Graphs with Proxy Unknowns. (arXiv:2308.05463v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05463</link>
<description rdf:parseType="Literal">&lt;p&gt;Node classification is the task of predicting the labels of unlabeled nodes
in a graph. State-of-the-art methods based on graph neural networks achieve
excellent performance when all labels are available during training. But in
real-life, models are often applied on data with new classes, which can lead to
massive misclassification and thus significantly degrade performance. Hence,
developing open-set classification methods is crucial to determine if a given
sample belongs to a known class. Existing methods for open-set node
classification generally use transductive learning with part or all of the
features of real unseen class nodes to help with open-set classification. In
this paper, we propose a novel generative open-set node classification method,
i.e. $\mathcal{G}^2Pxy$, which follows a stricter inductive learning setting
where no information about unknown classes is available during training and
validation. Two kinds of proxy unknown nodes, inter-class unknown proxies and
external unknown proxies are generated via mixup to efficiently anticipate the
distribution of novel classes. Using the generated proxies, a closed-set
classifier can be transformed into an open-set one, by augmenting it with an
extra proxy classifier. Under the constraints of both cross entropy loss and
complement entropy loss, $\mathcal{G}^2Pxy$ achieves superior effectiveness for
unknown class detection and known class classification, which is validated by
experiments on benchmark graph datasets. Moreover, $\mathcal{G}^2Pxy$ does not
have specific requirement on the GNN architecture and shows good
generalizations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zelin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaolin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiaojun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fournier_Viger_P/0/1/0/all/0/1&quot;&gt;Philippe Fournier-Viger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1&quot;&gt;Shirui Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05471">
<title>Provably Efficient Algorithm for Nonstationary Low-Rank MDPs. (arXiv:2308.05471v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05471</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) under changing environment models many real-world
applications via nonstationary Markov Decision Processes (MDPs), and hence
gains considerable interest. However, theoretical studies on nonstationary MDPs
in the literature have mainly focused on tabular and linear (mixture) MDPs,
which do not capture the nature of unknown representation in deep RL. In this
paper, we make the first effort to investigate nonstationary RL under episodic
low-rank MDPs, where both transition kernels and rewards may vary over time,
and the low-rank model contains unknown representation in addition to the
linear state embedding function. We first propose a parameter-dependent policy
optimization algorithm called PORTAL, and further improve PORTAL to its
parameter-free version of Ada-PORTAL, which is able to tune its
hyper-parameters adaptively without any prior knowledge of nonstationarity. For
both algorithms, we provide upper bounds on the average dynamic suboptimality
gap, which show that as long as the nonstationarity is not significantly large,
PORTAL and Ada-PORTAL are sample-efficient and can achieve arbitrarily small
average dynamic suboptimality gap with polynomial sample complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yuan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jing Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yingbin Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05476">
<title>Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis. (arXiv:2308.05476v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.05476</link>
<description rdf:parseType="Literal">&lt;p&gt;Deceptive text classification is a critical task in natural language
processing that aims to identify deceptive or fraudulent content. This study
presents a comparative analysis of machine learning and transformer-based
approaches for deceptive text classification. We investigate the effectiveness
of traditional machine learning algorithms and state-of-the-art transformer
models, such as BERT, XLNET, DistilBERT, and RoBERTa, in detecting deceptive
text. A labeled dataset consisting of deceptive and non-deceptive texts is used
for training and evaluation purposes. Through extensive experimentation, we
compare the performance metrics, including accuracy, precision, recall, and F1
score, of the different approaches. The results of this study shed light on the
strengths and limitations of machine learning and transformer-based methods for
deceptive text classification, enabling researchers and practitioners to make
informed decisions when dealing with deceptive content
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1&quot;&gt;Anusuya Krishnan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05481">
<title>LLM As DBA. (arXiv:2308.05481v1 [cs.DB])</title>
<link>http://arxiv.org/abs/2308.05481</link>
<description rdf:parseType="Literal">&lt;p&gt;Database administrators (DBAs) play a crucial role in managing, maintaining
and optimizing a database system to ensure data availability, performance, and
reliability. However, it is hard and tedious for DBAs to manage a large number
of database instances (e.g., millions of instances on the cloud databases).
Recently large language models (LLMs) have shown great potential to understand
valuable documents and accordingly generate reasonable answers. Thus, we
propose D-Bot, a LLM-based database administrator that can continuously acquire
database maintenance experience from textual sources, and provide reasonable,
well-founded, in-time diagnosis and optimization advice for target databases.
This paper presents a revolutionary LLM-centric framework for database
maintenance, including (i) database maintenance knowledge detection from
documents and tools, (ii) tree of thought reasoning for root cause analysis,
and (iii) collaborative diagnosis among multiple LLMs. Our preliminary
experimental results that D-Bot can efficiently and effectively diagnose the
root causes and our code is available at
github.com/TsinghuaDatabaseGroup/DB-GPT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1&quot;&gt;Xuanhe Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guoliang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05483">
<title>Quality Diversity under Sparse Reward and Sparse Interaction: Application to Grasping in Robotics. (arXiv:2308.05483v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2308.05483</link>
<description rdf:parseType="Literal">&lt;p&gt;Quality-Diversity (QD) methods are algorithms that aim to generate a set of
diverse and high-performing solutions to a given problem. Originally developed
for evolutionary robotics, most QD studies are conducted on a limited set of
domains - mainly applied to locomotion, where the fitness and the behavior
signal are dense. Grasping is a crucial task for manipulation in robotics.
Despite the efforts of many research communities, this task is yet to be
solved. Grasping cumulates unprecedented challenges in QD literature: it
suffers from reward sparsity, behavioral sparsity, and behavior space
misalignment. The present work studies how QD can address grasping. Experiments
have been conducted on 15 different methods on 10 grasping domains,
corresponding to 2 different robot-gripper setups and 5 standard objects. An
evaluation framework that distinguishes the evaluation of an algorithm from its
internal components has also been proposed for a fair comparison. The obtained
results show that MAP-Elites variants that select successful solutions in
priority outperform all the compared methods on the studied metrics by a large
margin. We also found experimental evidence that sparse interaction can lead to
deceptive novelty. To our knowledge, the ability to efficiently produce
examples of grasping trajectories demonstrated in this work has no precedent in
the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huber_J/0/1/0/all/0/1&quot;&gt;J. Huber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helenon_F/0/1/0/all/0/1&quot;&gt;F. H&amp;#xe9;l&amp;#xe9;non&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coninx_M/0/1/0/all/0/1&quot;&gt;M. Coninx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amar_F/0/1/0/all/0/1&quot;&gt;F. Ben Amar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doncieux_S/0/1/0/all/0/1&quot;&gt;S. Doncieux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05509">
<title>On the Optimal Expressive Power of ReLU DNNs and Its Application in Approximation with Kolmogorov Superposition Theorem. (arXiv:2308.05509v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05509</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is devoted to studying the optimal expressive power of ReLU deep
neural networks (DNNs) and its application in approximation via the Kolmogorov
Superposition Theorem. We first constructively prove that any continuous
piecewise linear functions on $[0,1]$, comprising $O(N^2L)$ segments, can be
represented by ReLU DNNs with $L$ hidden layers and $N$ neurons per layer.
Subsequently, we demonstrate that this construction is optimal regarding the
parameter count of the DNNs, achieved through investigating the shattering
capacity of ReLU DNNs. Moreover, by invoking the Kolmogorov Superposition
Theorem, we achieve an enhanced approximation rate for ReLU DNNs of arbitrary
width and depth when dealing with continuous functions in high-dimensional
spaces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Juncai He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05522">
<title>Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning. (arXiv:2308.05522v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2308.05522</link>
<description rdf:parseType="Literal">&lt;p&gt;Retrosynthesis consists of breaking down a chemical compound recursively
step-by-step into molecular precursors until a set of commercially available
molecules is found with the goal to provide a synthesis route. Its two primary
research directions, single-step retrosynthesis prediction, which models the
chemical reaction logic, and multi-step synthesis planning, which tries to find
the correct sequence of reactions, are inherently intertwined. Still, this
connection is not reflected in contemporary research. In this work, we combine
these two major research directions by applying multiple single-step
retrosynthesis models within multi-step synthesis planning and analyzing their
impact using public and proprietary reaction data. We find a disconnection
between high single-step performance and potential route-finding success,
suggesting that single-step models must be evaluated within synthesis planning
in the future. Furthermore, we show that the commonly used single-step
retrosynthesis benchmark dataset USPTO-50k is insufficient as this evaluation
task does not represent model performance and scalability on larger and more
diverse datasets. For multi-step synthesis planning, we show that the choice of
the single-step model can improve the overall success rate of synthesis
planning by up to +28% compared to the commonly used baseline model. Finally,
we show that each single-step model finds unique synthesis routes, and differs
in aspects such as route-finding success, the number of found synthesis routes,
and chemical validity, making the combination of single-step retrosynthesis
prediction and multi-step synthesis planning a crucial aspect when developing
future methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torren_Peraire_P/0/1/0/all/0/1&quot;&gt;Paula Torren-Peraire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassen_A/0/1/0/all/0/1&quot;&gt;Alan Kai Hassen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Genheden_S/0/1/0/all/0/1&quot;&gt;Samuel Genheden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verhoeven_J/0/1/0/all/0/1&quot;&gt;Jonas Verhoeven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clevert_D/0/1/0/all/0/1&quot;&gt;Djork-Arne Clevert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Preuss_M/0/1/0/all/0/1&quot;&gt;Mike Preuss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tetko_I/0/1/0/all/0/1&quot;&gt;Igor Tetko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05525">
<title>Critical Points ++: An Agile Point Cloud Importance Measure for Robust Classification, Adversarial Defense and Explainable AI. (arXiv:2308.05525v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05525</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to cope accurately and fast with Out-Of-Distribution (OOD)
samples is crucial in real-world safety demanding applications. In this work we
first study the interplay between critical points of 3D point clouds and OOD
samples. Our findings are that common corruptions and outliers are often
interpreted as critical points. We generalize the notion of critical points
into importance measures. We show that training a classification network based
only on less important points dramatically improves robustness, at a cost of
minor performance loss on the clean set. We observe that normalized entropy is
highly informative for corruption analysis. An adaptive threshold based on
normalized entropy is suggested for selecting the set of uncritical points. Our
proposed importance measure is extremely fast to compute. We show it can be
used for a variety of applications, such as Explainable AI (XAI), Outlier
Removal, Uncertainty Estimation, Robust Classification and Adversarial Defense.
We reach SOTA results on the two latter tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levi_M/0/1/0/all/0/1&quot;&gt;Meir Yossef Levi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilboa_G/0/1/0/all/0/1&quot;&gt;Guy Gilboa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05564">
<title>Efficient Variational Inference for Large Skew-t Copulas with Application to Intraday Equity Returns. (arXiv:2308.05564v1 [econ.EM])</title>
<link>http://arxiv.org/abs/2308.05564</link>
<description rdf:parseType="Literal">&lt;p&gt;Large skew-t factor copula models are attractive for the modeling of
financial data because they allow for asymmetric and extreme tail dependence.
We show that the copula implicit in the skew-t distribution of Azzalini and
Capitanio (2003) allows for a higher level of pairwise asymmetric dependence
than two popular alternative skew-t copulas. Estimation of this copula in high
dimensions is challenging, and we propose a fast and accurate Bayesian
variational inference (VI) approach to do so. The method uses a conditionally
Gaussian generative representation of the skew-t distribution to define an
augmented posterior that can be approximated accurately. A fast stochastic
gradient ascent algorithm is used to solve the variational optimization. The
new methodology is used to estimate copula models for intraday returns from
2017 to 2021 on 93 U.S. equities. The copula captures substantial heterogeneity
in asymmetric dependence over equity pairs, in addition to the variability in
pairwise correlations. We show that intraday predictive densities from the
skew-t copula are more accurate than from some other copula models, while
portfolio selection strategies based on the estimated pairwise tail
dependencies improve performance relative to the benchmark index.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Deng_L/0/1/0/all/0/1&quot;&gt;Lin Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Smith_M/0/1/0/all/0/1&quot;&gt;Michael Stanley Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Maneesoonthorn_W/0/1/0/all/0/1&quot;&gt;Worapree Maneesoonthorn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05566">
<title>AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting. (arXiv:2308.05566v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05566</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce AutoGluon-TimeSeries - an open-source AutoML library for
probabilistic time series forecasting. Focused on ease of use and robustness,
AutoGluon-TimeSeries enables users to generate accurate point and quantile
forecasts with just 3 lines of Python code. Built on the design philosophy of
AutoGluon, AutoGluon-TimeSeries leverages ensembles of diverse forecasting
models to deliver high accuracy within a short training time.
AutoGluon-TimeSeries combines both conventional statistical models,
machine-learning based forecasting approaches, and ensembling techniques. In
our evaluation on 29 benchmark datasets, AutoGluon-TimeSeries demonstrates
strong empirical performance, outperforming a range of forecasting methods in
terms of both point and quantile forecast accuracy, and often even improving
upon the best-in-hindsight combination of prior methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shchur_O/0/1/0/all/0/1&quot;&gt;Oleksandr Shchur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turkmen_C/0/1/0/all/0/1&quot;&gt;Caner Turkmen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erickson_N/0/1/0/all/0/1&quot;&gt;Nick Erickson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Huibin Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shirkov_A/0/1/0/all/0/1&quot;&gt;Alexander Shirkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1&quot;&gt;Tony Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuyang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05575">
<title>Symmetry Defense Against XGBoost Adversarial Perturbation Attacks. (arXiv:2308.05575v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05575</link>
<description rdf:parseType="Literal">&lt;p&gt;We examine whether symmetry can be used to defend tree-based ensemble
classifiers such as gradient-boosting decision trees (GBDTs) against
adversarial perturbation attacks. The idea is based on a recent symmetry
defense for convolutional neural network classifiers (CNNs) that utilizes CNNs&apos;
lack of invariance with respect to symmetries. CNNs lack invariance because
they can classify a symmetric sample, such as a horizontally flipped image,
differently from the original sample. CNNs&apos; lack of invariance also means that
CNNs can classify symmetric adversarial samples differently from the incorrect
classification of adversarial samples. Using CNNs&apos; lack of invariance, the
recent CNN symmetry defense has shown that the classification of symmetric
adversarial samples reverts to the correct sample classification. In order to
apply the same symmetry defense to GBDTs, we examine GBDT invariance and are
the first to show that GBDTs also lack invariance with respect to symmetries.
We apply and evaluate the GBDT symmetry defense for nine datasets against six
perturbation attacks with a threat model that ranges from zero-knowledge to
perfect-knowledge adversaries. Using the feature inversion symmetry against
zero-knowledge adversaries, we achieve up to 100% accuracy on adversarial
samples even when default and robust classifiers have 0% accuracy. Using the
feature inversion and horizontal flip symmetries against perfect-knowledge
adversaries, we achieve up to over 95% accuracy on adversarial samples for the
GBDT classifier of the F-MNIST dataset even when default and robust classifiers
have 0% accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindqvist_B/0/1/0/all/0/1&quot;&gt;Blerta Lindqvist&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05600">
<title>NUPES : Non-Uniform Post-Training Quantization via Power Exponent Search. (arXiv:2308.05600v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05600</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural network (DNN) deployment has been confined to larger hardware
devices due to their expensive computational requirements. This challenge has
recently reached another scale with the emergence of large language models
(LLMs). In order to reduce both their memory footprint and latency, a promising
technique is quantization. It consists in converting floating point
representations to low bit-width fixed point representations, usually by
assuming a uniform mapping onto a regular grid. This process, referred to in
the literature as uniform quantization, may however be ill-suited as most DNN
weights and activations follow a bell-shaped distribution. This is even worse
on LLMs whose weight distributions are known to exhibit large, high impact,
outlier values. In this work, we propose an improvement over the most commonly
adopted way to tackle this limitation in deep learning models quantization,
namely, non-uniform quantization. NUPES leverages automorphisms to preserve the
scalar multiplications. Such transformations are derived from power functions.
However, the optimization of the exponent parameter and weight values remains a
challenging and novel problem which could not be solved with previous post
training optimization techniques which only learn to round up or down weight
values in order to preserve the predictive function. We circumvent this
limitation with a new paradigm: learning new quantized weights over the entire
quantized space. Similarly, we enable the optimization of the power exponent,
i.e. the optimization of the quantization operator itself during training by
alleviating all the numerical instabilities. The resulting predictive function
is compatible with integer-only low-bit inference. We show the ability of the
method to achieve state-of-the-art compression rates in both, data-free and
data-driven configurations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yvinec_E/0/1/0/all/0/1&quot;&gt;Edouard Yvinec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dapogny_A/0/1/0/all/0/1&quot;&gt;Arnaud Dapogny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bailly_K/0/1/0/all/0/1&quot;&gt;Kevin Bailly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05601">
<title>Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction. (arXiv:2308.05601v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05601</link>
<description rdf:parseType="Literal">&lt;p&gt;Inter-city highway transportation is significant for urban life. As one of
the key functions in intelligent transportation system (ITS), traffic
evaluation always plays significant role nowadays, and daily traffic flow
prediction still faces challenges at network-wide toll stations. On the one
hand, the data imbalance in practice among various locations deteriorates the
performance of prediction. On the other hand, complex correlative
spatio-temporal factors cannot be comprehensively employed in long-term
duration. In this paper, a prediction method is proposed for daily traffic flow
in highway domain through spatio-temporal deep learning. In our method, data
normalization strategy is used to deal with data imbalance, due to long-tail
distribution of traffic flow at network-wide toll stations. And then, based on
graph convolutional network, we construct networks in distinct semantics to
capture spatio-temporal features. Beside that, meteorology and calendar
features are used by our model in the full connection stage to extra external
characteristics of traffic flow. By extensive experiments and case studies in
one Chinese provincial highway, our method shows clear improvement in
predictive accuracy than baselines and practical benefits in business.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1&quot;&gt;Weilong Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianpu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianwu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhuofeng Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05619">
<title>Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance. (arXiv:2308.05619v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2308.05619</link>
<description rdf:parseType="Literal">&lt;p&gt;As data shift or new data become available, updating clinical machine
learning models may be necessary to maintain or improve performance over time.
However, updating a model can introduce compatibility issues when the behavior
of the updated model does not align with user expectations, resulting in poor
user-model team performance. Existing compatibility measures depend on model
decision thresholds, limiting their applicability in settings where models are
used to generate rankings based on estimated risk. To address this limitation,
we propose a novel rank-based compatibility measure, $C^R$, and a new loss
function that aims to optimize discriminative performance while encouraging
good compatibility. Applied to a case study in mortality risk stratification
leveraging data from MIMIC, our approach yields more compatible models while
maintaining discriminative performance compared to existing model selection
techniques, with an increase in $C^R$ of $0.019$ ($95\%$ confidence interval:
$0.005$, $0.035$). This work provides new tools to analyze and update risk
stratification models used in clinical care.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Otles_E/0/1/0/all/0/1&quot;&gt;Erkin &amp;#xd6;tle&amp;#x15f;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Denton_B/0/1/0/all/0/1&quot;&gt;Brian T. Denton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiens_J/0/1/0/all/0/1&quot;&gt;Jenna Wiens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05621">
<title>Normalized Gradients for All. (arXiv:2308.05621v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05621</link>
<description rdf:parseType="Literal">&lt;p&gt;In this short note, I show how to adapt to H\&quot;{o}lder smoothness using
normalized gradients in a black-box way. Moreover, the bound will depend on a
novel notion of local H\&quot;{o}lder smoothness. The main idea directly comes from
Levy [2017].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orabona_F/0/1/0/all/0/1&quot;&gt;Francesco Orabona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05629">
<title>ReLU and Addition-based Gated RNN. (arXiv:2308.05629v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05629</link>
<description rdf:parseType="Literal">&lt;p&gt;We replace the multiplication and sigmoid function of the conventional
recurrent gate with addition and ReLU activation. This mechanism is designed to
maintain long-term memory for sequence processing but at a reduced
computational cost, thereby opening up for more efficient execution or larger
models on restricted hardware. Recurrent Neural Networks (RNNs) with gating
mechanisms such as LSTM and GRU have been widely successful in learning from
sequential data due to their ability to capture long-term dependencies.
Conventionally, the update based on current inputs and the previous state
history is each multiplied with dynamic weights and combined to compute the
next state. However, multiplication can be computationally expensive,
especially for certain hardware architectures or alternative arithmetic systems
such as homomorphic encryption. It is demonstrated that the novel gating
mechanism can capture long-term dependencies for a standard synthetic sequence
learning task while significantly reducing computational costs such that
execution time is reduced by half on CPU and by one-third under encryption.
Experimental results on handwritten text recognition tasks furthermore show
that the proposed architecture can be trained to achieve comparable accuracy to
conventional GRU and LSTM baselines. The gating mechanism introduced in this
paper may enable privacy-preserving AI applications operating under homomorphic
encryption by avoiding the multiplication of encrypted variables. It can also
support quantization in (unencrypted) plaintext applications, with the
potential for substantial performance gains since the addition-based
formulation can avoid the expansion to double precision often required for
multiplication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brannvall_R/0/1/0/all/0/1&quot;&gt;Rickard Br&amp;#xe4;nnvall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forsgren_H/0/1/0/all/0/1&quot;&gt;Henrik Forsgren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandin_F/0/1/0/all/0/1&quot;&gt;Fredrik Sandin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1&quot;&gt;Marcus Liwicki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05633">
<title>IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer. (arXiv:2308.05633v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05633</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated medical report generation has become increasingly important in
medical analysis. It can produce computer-aided diagnosis descriptions and thus
significantly alleviate the doctors&apos; work. Inspired by the huge success of
neural machine translation and image captioning, various deep learning methods
have been proposed for medical report generation. However, due to the inherent
properties of medical data, including data imbalance and the length and
correlation between report sequences, the generated reports by existing methods
may exhibit linguistic fluency but lack adequate clinical accuracy. In this
work, we propose an image-to-indicator hierarchical transformer (IIHT)
framework for medical report generation. It consists of three modules, i.e., a
classifier module, an indicator expansion module and a generator module. The
classifier module first extracts image features from the input medical images
and produces disease-related indicators with their corresponding states. The
disease-related indicators are subsequently utilised as input for the indicator
expansion module, incorporating the &quot;data-text-data&quot; strategy. The
transformer-based generator then leverages these extracted features along with
image features as auxiliary information to generate final reports. Furthermore,
the proposed IIHT method is feasible for radiologists to modify disease
indicators in real-world scenarios and integrate the operations into the
indicator expansion module for fluent and accurate medical report generation.
Extensive experiments and comparisons with state-of-the-art methods under
various evaluation metrics demonstrate the great performance of the proposed
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_K/0/1/0/all/0/1&quot;&gt;Keqiang Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1&quot;&gt;Xiaohao Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niranjan_M/0/1/0/all/0/1&quot;&gt;Mahesan Niranjan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05646">
<title>AST-MHSA : Code Summarization using Multi-Head Self-Attention. (arXiv:2308.05646v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.05646</link>
<description rdf:parseType="Literal">&lt;p&gt;Code summarization aims to generate concise natural language descriptions for
source code. The prevailing approaches adopt transformer-based encoder-decoder
architectures, where the Abstract Syntax Tree (AST) of the source code is
utilized for encoding structural information. However, ASTs are much longer
than the corresponding source code, and existing methods ignore this size
constraint by directly feeding the entire linearized AST into the encoders.
This simplistic approach makes it challenging to extract truly valuable
dependency relations from the overlong input sequence and leads to significant
computational overhead due to self-attention applied to all nodes in the AST.
&lt;/p&gt;
&lt;p&gt;To address this issue effectively and efficiently, we present a model,
AST-MHSA that uses multi-head attention to extract the important semantic
information from the AST. The model consists of two main components: an encoder
and a decoder. The encoder takes as input the abstract syntax tree (AST) of the
code and generates a sequence of hidden states. The decoder then takes these
hidden states as input and generates a natural language summary of the code.
&lt;/p&gt;
&lt;p&gt;The multi-head attention mechanism allows the model to learn different
representations of the input code, which can be combined to generate a more
comprehensive summary. The model is trained on a dataset of code and summaries,
and the parameters of the model are optimized to minimize the loss between the
generated summaries and the ground-truth summaries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagaraj_Y/0/1/0/all/0/1&quot;&gt;Yeshwanth Nagaraj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1&quot;&gt;Ujjwal Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05680">
<title>Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning. (arXiv:2308.05680v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.05680</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of retrieving already debunked narratives aims to detect stories
that have already been fact-checked. The successful detection of claims that
have already been debunked not only reduces the manual efforts of professional
fact-checkers but can also contribute to slowing the spread of misinformation.
Mainly due to the lack of readily available data, this is an understudied
problem, particularly when considering the cross-lingual task, i.e. the
retrieval of fact-checking articles in a language different from the language
of the online post being checked. This paper fills this gap by (i) creating a
novel dataset to enable research on cross-lingual retrieval of already debunked
narratives, using tweets as queries to a database of fact-checking articles;
(ii) presenting an extensive experiment to benchmark fine-tuned and
off-the-shelf multilingual pre-trained Transformer models for this task; and
(iii) proposing a novel multistage framework that divides this cross-lingual
debunk retrieval task into refinement and re-ranking stages. Results show that
the task of cross-lingual retrieval of already debunked narratives is
challenging and off-the-shelf Transformer models fail to outperform a strong
lexical-based baseline (BM25). Nevertheless, our multistage retrieval framework
is robust, outperforming BM25 in most scenarios and enabling cross-domain and
zero-shot learning, without significantly harming the model&apos;s performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_I/0/1/0/all/0/1&quot;&gt;Iknoor Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1&quot;&gt;Carolina Scarton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1&quot;&gt;Xingyi Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1&quot;&gt;Kalina Bontcheva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05681">
<title>Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient. (arXiv:2308.05681v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05681</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, methods for skeleton-based human activity recognition have been
shown to be vulnerable to adversarial attacks. However, these attack methods
require either the full knowledge of the victim (i.e. white-box attacks),
access to training data (i.e. transfer-based attacks) or frequent model queries
(i.e. black-box attacks). All their requirements are highly restrictive,
raising the question of how detrimental the vulnerability is. In this paper, we
show that the vulnerability indeed exists. To this end, we consider a new
attack task: the attacker has no access to the victim model or the training
data or labels, where we coin the term hard no-box attack. Specifically, we
first learn a motion manifold where we define an adversarial loss to compute a
new gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our
gradient contains information of the motion dynamics, which is different from
existing gradient-based attack methods that compute the loss gradient assuming
each dimension in the data is independent. The SMI gradient can augment many
gradient-based attack methods, leading to a new family of no-box attack
methods. Extensive evaluation and comparison show that our method imposes a
real threat to existing classifiers. They also show that the SMI gradient
improves the transferability and imperceptibility of adversarial samples in
both no-box and transfer-based black-box settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhengzhi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;He Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Z/0/1/0/all/0/1&quot;&gt;Ziyi Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Guoan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1&quot;&gt;Hubert P. H. Shum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05707">
<title>Shadow Datasets, New challenging datasets for Causal Representation Learning. (arXiv:2308.05707v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05707</link>
<description rdf:parseType="Literal">&lt;p&gt;Discovering causal relations among semantic factors is an emergent topic in
representation learning. Most causal representation learning (CRL) methods are
fully supervised, which is impractical due to costly labeling. To resolve this
restriction, weakly supervised CRL methods were introduced. To evaluate CRL
performance, four existing datasets, Pendulum, Flow, CelebA(BEARD) and
CelebA(SMILE), are utilized. However, existing CRL datasets are limited to
simple graphs with few generative factors. Thus we propose two new datasets
with a larger number of diverse generative factors and more sophisticated
causal graphs. In addition, current real datasets, CelebA(BEARD) and
CelebA(SMILE), the originally proposed causal graphs are not aligned with the
dataset distributions. Thus, we propose modifications to them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jiageng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1&quot;&gt;Hanchen Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jianhua Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiazhi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khayatkhoei_M/0/1/0/all/0/1&quot;&gt;Mahyar Khayatkhoei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hussein_M/0/1/0/all/0/1&quot;&gt;Mohamed E. Hussein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+AbdAlmageed_W/0/1/0/all/0/1&quot;&gt;Wael AbdAlmageed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05711">
<title>A Comparison of Classical and Deep Reinforcement Learning Methods for HVAC Control. (arXiv:2308.05711v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05711</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) is a promising approach for optimizing HVAC
control. RL offers a framework for improving system performance, reducing
energy consumption, and enhancing cost efficiency. We benchmark two popular
classical and deep RL methods (Q-Learning and Deep-Q-Networks) across multiple
HVAC environments and explore the practical consideration of model
hyper-parameter selection and reward tuning. The findings provide insight for
configuring RL agents in HVAC systems, promoting energy-efficient and
cost-effective operation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Marshall Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Willes_J/0/1/0/all/0/1&quot;&gt;John Willes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiralerspong_T/0/1/0/all/0/1&quot;&gt;Thomas Jiralerspong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moezzi_M/0/1/0/all/0/1&quot;&gt;Matin Moezzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05724">
<title>Optimizing Performance of Feedforward and Convolutional Neural Networks through Dynamic Activation Functions. (arXiv:2308.05724v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05724</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning training training algorithms are a huge success in recent years
in many fields including speech, text,image video etc. Deeper and deeper layers
are proposed with huge success with resnet structures having around 152 layers.
Shallow convolution neural networks(CNN&apos;s) are still an active research, where
some phenomena are still unexplained. Activation functions used in the network
are of utmost importance, as they provide non linearity to the networks. Relu&apos;s
are the most commonly used activation function.We show a complex piece-wise
linear(PWL) activation in the hidden layer. We show that these PWL activations
work much better than relu activations in our networks for convolution neural
networks and multilayer perceptrons. Result comparison in PyTorch for shallow
and deep CNNs are given to further strengthen our case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rane_C/0/1/0/all/0/1&quot;&gt;Chinmay Rane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tyagi_K/0/1/0/all/0/1&quot;&gt;Kanishka Tyagi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manry_M/0/1/0/all/0/1&quot;&gt;Michael Manry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05725">
<title>EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis. (arXiv:2308.05725v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.05725</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown that it is possible to resynthesize high-quality speech
based, not on text, but on low bitrate discrete units that have been learned in
a self-supervised fashion and can therefore capture expressive aspects of
speech that are hard to transcribe (prosody, voice styles, non-verbal
vocalization). The adoption of these methods is still limited by the fact that
most speech synthesis datasets are read, severely limiting spontaneity and
expressivity. Here, we introduce Expresso, a high-quality expressive speech
dataset for textless speech synthesis that includes both read speech and
improvised dialogues rendered in 26 spontaneous expressive styles. We
illustrate the challenges and potentials of this dataset with an expressive
resynthesis benchmark where the task is to encode the input in low-bitrate
units and resynthesize it in a target voice while preserving content and style.
We evaluate resynthesis quality with automatic metrics for different
self-supervised discrete encoders, and explore tradeoffs between quality,
bitrate and invariance to speaker and style. All the dataset, evaluation
metrics and baseline models are open source
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Tu Anh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1&quot;&gt;Wei-Ning Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DAvirro_A/0/1/0/all/0/1&quot;&gt;Antony D&amp;#x27;Avirro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1&quot;&gt;Bowen Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1&quot;&gt;Itai Gat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fazel_Zarani_M/0/1/0/all/0/1&quot;&gt;Maryam Fazel-Zarani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1&quot;&gt;Tal Remez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Copet_J/0/1/0/all/0/1&quot;&gt;Jade Copet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1&quot;&gt;Gabriel Synnaeve&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassid_M/0/1/0/all/0/1&quot;&gt;Michael Hassid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreuk_F/0/1/0/all/0/1&quot;&gt;Felix Kreuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1&quot;&gt;Yossi Adi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1&quot;&gt;Emmanuel Dupoux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05731">
<title>Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review. (arXiv:2308.05731v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2308.05731</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated driving has the potential to revolutionize personal, public, and
freight mobility. Besides the enormous challenge of perception, i.e. accurately
perceiving the environment using available sensor data, automated driving
comprises planning a safe, comfortable, and efficient motion trajectory. To
promote safety and progress, many works rely on modules that predict the future
motion of surrounding traffic. Modular automated driving systems commonly
handle prediction and planning as sequential separate tasks. While this
accounts for the influence of surrounding traffic on the ego-vehicle, it fails
to anticipate the reactions of traffic participants to the ego-vehicle&apos;s
behavior. Recent works suggest that integrating prediction and planning in an
interdependent joint step is necessary to achieve safe, efficient, and
comfortable driving. While various models implement such integrated systems, a
comprehensive overview and theoretical understanding of different principles
are lacking. We systematically review state-of-the-art deep learning-based
prediction, planning, and integrated prediction and planning models. Different
facets of the integration ranging from model architecture and model design to
behavioral aspects are considered and related to each other. Moreover, we
discuss the implications, strengths, and limitations of different integration
methods. By pointing out research gaps, describing relevant future challenges,
and highlighting trends in the research field, we identify promising directions
for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hagedorn_S/0/1/0/all/0/1&quot;&gt;Steffen Hagedorn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hallgarten_M/0/1/0/all/0/1&quot;&gt;Marcel Hallgarten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoll_M/0/1/0/all/0/1&quot;&gt;Martin Stoll&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Condurache_A/0/1/0/all/0/1&quot;&gt;Alexandru Condurache&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05732">
<title>PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers. (arXiv:2308.05732v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.05732</link>
<description rdf:parseType="Literal">&lt;p&gt;Time-dependent partial differential equations (PDEs) are ubiquitous in
science and engineering. Recently, mostly due to the high computational cost of
traditional solution techniques, deep neural network based surrogates have
gained increased interest. The practical utility of such neural PDE solvers
relies on their ability to provide accurate, stable predictions over long time
horizons, which is a notoriously hard problem. In this work, we present a
large-scale analysis of common temporal rollout strategies, identifying the
neglect of non-dominant spatial frequency information, often associated with
high frequencies in PDE solutions, as the primary pitfall limiting stable,
accurate rollout performance. Based on these insights, we draw inspiration from
recent advances in diffusion models to introduce PDE-Refiner; a novel model
class that enables more accurate modeling of all frequency components via a
multistep refinement process. We validate PDE-Refiner on challenging benchmarks
of complex fluid dynamics, demonstrating stable and accurate rollouts that
consistently outperform state-of-the-art models, including neural, numerical,
and hybrid neural-numerical architectures. We further demonstrate that
PDE-Refiner greatly enhances data efficiency, since the denoising objective
implicitly induces a novel form of spectral data augmentation. Finally,
PDE-Refiner&apos;s connection to diffusion models enables an accurate and efficient
assessment of the model&apos;s predictive uncertainty, allowing us to estimate when
the surrogate becomes inaccurate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lippe_P/0/1/0/all/0/1&quot;&gt;Phillip Lippe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veeling_B/0/1/0/all/0/1&quot;&gt;Bastiaan S. Veeling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1&quot;&gt;Paris Perdikaris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brandstetter_J/0/1/0/all/0/1&quot;&gt;Johannes Brandstetter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05737">
<title>Follow Anything: Open-set detection, tracking, and following in real-time. (arXiv:2308.05737v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2308.05737</link>
<description rdf:parseType="Literal">&lt;p&gt;Tracking and following objects of interest is critical to several robotics
use cases, ranging from industrial automation to logistics and warehousing, to
healthcare and security. In this paper, we present a robotic system to detect,
track, and follow any object in real-time. Our approach, dubbed ``follow
anything&apos;&apos; (FAn), is an open-vocabulary and multimodal model -- it is not
restricted to concepts seen at training time and can be applied to novel
classes at inference time using text, images, or click queries. Leveraging rich
visual descriptors from large-scale pre-trained models (foundation models), FAn
can detect and segment objects by matching multimodal queries (text, images,
clicks) against an input image sequence. These detected and segmented objects
are tracked across image frames, all while accounting for occlusion and object
re-emergence. We demonstrate FAn on a real-world robotic system (a micro aerial
vehicle) and report its ability to seamlessly follow the objects of interest in
a real-time control loop. FAn can be deployed on a laptop with a lightweight
(6-8 GB) graphics card, achieving a throughput of 6-20 frames per second. To
enable rapid adoption, deployment, and extensibility, we open-source all our
code on our project webpage at https://github.com/alaamaalouf/FollowAnything .
We also encourage the reader the watch our 5-minutes explainer video in this
https://www.youtube.com/watch?v=6Mgt3EPytrw .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maalouf_A/0/1/0/all/0/1&quot;&gt;Alaa Maalouf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jadhav_N/0/1/0/all/0/1&quot;&gt;Ninad Jadhav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jatavallabhula_K/0/1/0/all/0/1&quot;&gt;Krishna Murthy Jatavallabhula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chahine_M/0/1/0/all/0/1&quot;&gt;Makram Chahine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vogt_D/0/1/0/all/0/1&quot;&gt;Daniel M.Vogt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wood_R/0/1/0/all/0/1&quot;&gt;Robert J. Wood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1&quot;&gt;Antonio Torralba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1&quot;&gt;Daniela Rus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05739">
<title>Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics. (arXiv:2308.05739v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05739</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient-based optimization is now ubiquitous across graphics, but
unfortunately can not be applied to problems with undefined or zero gradients.
To circumvent this issue, the loss function can be manually replaced by a
&quot;surrogate&quot; that has similar minima but is differentiable. Our proposed
framework, ZeroGrads, automates this process by learning a neural approximation
of the objective function, the surrogate, which in turn can be used to
differentiate through arbitrary black-box graphics pipelines. We train the
surrogate on an actively smoothed version of the objective and encourage
locality, focusing the surrogate&apos;s capacity on what matters at the current
training episode. The fitting is performed online, alongside the parameter
optimization, and self-supervised, without pre-computed data or pre-trained
models. As sampling the objective is expensive (it requires a full rendering or
simulator run), we devise an efficient sampling scheme that allows for
tractable run-times and competitive performance at little overhead. We
demonstrate optimizing diverse non-convex, non-differentiable black-box
problems in graphics, such as visibility in rendering, discrete parameter
spaces in procedural modelling or optimal control in physics-driven animation.
In contrast to more traditional algorithms, our approach scales well to higher
dimensions, which we demonstrate on problems with up to 35k interlinked
variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1&quot;&gt;Michael Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ritschel_T/0/1/0/all/0/1&quot;&gt;Tobias Ritschel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05741">
<title>Neural Progressive Meshes. (arXiv:2308.05741v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.05741</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent proliferation of 3D content that can be consumed on hand-held
devices necessitates efficient tools for transmitting large geometric data,
e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a
challenge to storage as well as transmission bandwidth, and level-of-detail
techniques are often used to transmit an asset using an appropriate bandwidth
budget. It is especially desirable for these methods to transmit data
progressively, improving the quality of the geometry with more data. Our key
insight is that the geometric details of 3D meshes often exhibit similar local
patterns even across different shapes, and thus can be effectively represented
with a shared learned generative space. We learn this space using a
subdivision-based encoder-decoder architecture trained in advance on a large
collection of surfaces. We further observe that additional residual features
can be transmitted progressively between intermediate levels of subdivision
that enable the client to control the tradeoff between bandwidth cost and
quality of reconstruction, providing a neural progressive mesh representation.
We evaluate our method on a diverse set of complex 3D shapes and demonstrate
that it outperforms baselines in terms of compression ratio and reconstruction
quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yun-Chun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_V/0/1/0/all/0/1&quot;&gt;Vladimir G. Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aigerman_N/0/1/0/all/0/1&quot;&gt;Noam Aigerman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobson_A/0/1/0/all/0/1&quot;&gt;Alec Jacobson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.02495">
<title>InfoNCE is variational inference in a recognition parameterised model. (arXiv:2107.02495v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2107.02495</link>
<description rdf:parseType="Literal">&lt;p&gt;Here, we show that the InfoNCE objective is equivalent to the ELBO in a new
class of probabilistic generative model, the recognition parameterised model
(RPM). When we learn the optimal prior, the RPM ELBO becomes equal to the
mutual information (MI; up to a constant), establishing a connection to
pre-existing self-supervised learning methods such as InfoNCE. However,
practical InfoNCE methods do not use the MI as an objective; the MI is
invariant to arbitrary invertible transformations, so using an MI objective can
lead to highly entangled representations (Tschannen et al., 2019). Instead, the
actual InfoNCE objective is a simplified lower bound on the MI which is loose
even in the infinite sample limit. Thus, an objective that works (i.e. the
actual InfoNCE objective) appears to be motivated as a loose bound on an
objective that does not work (i.e. the true MI which gives arbitrarily
entangled representations). We give an alternative motivation for the actual
InfoNCE objective. In particular, we show that in the infinite sample limit,
and for a particular choice of prior, the actual InfoNCE objective is equal to
the ELBO (up to a constant); and the ELBO is equal to the marginal likelihood
with a deterministic recognition model. Thus, we argue that our VAE perspective
gives a better motivation for InfoNCE than MI, as the actual InfoNCE objective
is only loosely bounded by the MI, but is equal to the ELBO/marginal likelihood
(up to a constant).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1&quot;&gt;Laurence Aitchison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ganev_S/0/1/0/all/0/1&quot;&gt;Stoil Ganev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2202.09518">
<title>Distributed Out-of-Memory NMF on CPU/GPU Architectures. (arXiv:2202.09518v3 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2202.09518</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an efficient distributed out-of-memory implementation of the
Non-negative Matrix Factorization (NMF) algorithm for heterogeneous
high-performance-computing (HPC) systems. The proposed implementation is based
on prior work on NMFk, which can perform automatic model selection and extract
latent variables and patterns from data. In this work, we extend NMFk by adding
support for dense and sparse matrix operation on multi-node, multi-GPU systems.
The resulting algorithm is optimized for out-of-memory (OOM) problems where the
memory required to factorize a given matrix is greater than the available GPU
memory. Memory complexity is reduced by batching/tiling strategies, and sparse
and dense matrix operations are significantly accelerated with GPU cores (or
tensor cores when available). Input/Output (I/O) latency associated with batch
copies between host and device is hidden using CUDA streams to overlap data
transfers and compute asynchronously, and latency associated with collective
communications (both intra-node and inter-node) is reduced using optimized
NVIDIA Collective Communication Library NCCL based communicators. Benchmark
results show significant improvement, from 32X to 76x speedup, with the new
implementation using GPUs over the CPU-based NMFk. Good weak scaling was
demonstrated on up to 4096 multi-GPU cluster nodes with approximately 25,000
GPUs when decomposing a dense 340 Terabyte-size matrix and an 11 Exabyte-size
sparse matrix of density 10e-6.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boureima_I/0/1/0/all/0/1&quot;&gt;Ismael Boureima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattarai_M/0/1/0/all/0/1&quot;&gt;Manish Bhattarai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eren_M/0/1/0/all/0/1&quot;&gt;Maksim Eren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skau_E/0/1/0/all/0/1&quot;&gt;Erik Skau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romero_P/0/1/0/all/0/1&quot;&gt;Philip Romero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eidenbenz_S/0/1/0/all/0/1&quot;&gt;Stephan Eidenbenz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alexandrov_B/0/1/0/all/0/1&quot;&gt;Boian Alexandrov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2202.13341">
<title>Overlooked Implications of the Reconstruction Loss for VAE Disentanglement. (arXiv:2202.13341v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2202.13341</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning disentangled representations with variational autoencoders (VAEs) is
often attributed to the regularisation component of the loss. In this work, we
highlight the interaction between data and the reconstruction term of the loss
as the main contributor to disentanglement in VAEs. We show that standard
benchmark datasets have unintended correlations between their subjective
ground-truth factors and perceived axes in the data according to typical VAE
reconstruction losses. Our work exploits this relationship to provide a theory
for what constitutes an adversarial dataset under a given reconstruction loss.
We verify this by constructing an example dataset that prevents disentanglement
in state-of-the-art frameworks while maintaining human-intuitive ground-truth
factors. Finally, we re-enable disentanglement by designing an example
reconstruction loss that is once again able to perceive the ground-truth
factors. Our findings demonstrate the subjective nature of disentanglement and
the importance of considering the interaction between the ground-truth factors,
data and notably, the reconstruction loss, which is under-recognised in the
literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michlo_N/0/1/0/all/0/1&quot;&gt;Nathan Michlo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klein_R/0/1/0/all/0/1&quot;&gt;Richard Klein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+James_S/0/1/0/all/0/1&quot;&gt;Steven James&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.07902">
<title>MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning. (arXiv:2209.07902v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.07902</link>
<description rdf:parseType="Literal">&lt;p&gt;As a successful approach to self-supervised learning, contrastive learning
aims to learn invariant information shared among distortions of the input
sample. While contrastive learning has yielded continuous advancements in
sampling strategy and architecture design, it still remains two persistent
defects: the interference of task-irrelevant information and sample
inefficiency, which are related to the recurring existence of trivial constant
solutions. From the perspective of dimensional analysis, we find out that the
dimensional redundancy and dimensional confounder are the intrinsic issues
behind the phenomena, and provide experimental evidence to support our
viewpoint. We further propose a simple yet effective approach MetaMask, short
for the dimensional Mask learned by Meta-learning, to learn representations
against dimensional redundancy and confounder. MetaMask adopts the
redundancy-reduction technique to tackle the dimensional redundancy issue and
innovatively introduces a dimensional mask to reduce the gradient effects of
specific dimensions containing the confounder, which is trained by employing a
meta-learning paradigm with the objective of improving the performance of
masked representations on a typical self-supervised task. We provide solid
theoretical analyses to prove MetaMask can obtain tighter risk bounds for
downstream classification compared to typical contrastive methods. Empirically,
our method achieves state-of-the-art performance on various benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiangmeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiang_W/0/1/0/all/0/1&quot;&gt;Wenwen Qiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yanan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mo_W/0/1/0/all/0/1&quot;&gt;Wenyi Mo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Changwen Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_B/0/1/0/all/0/1&quot;&gt;Bing Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Hui Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.14408">
<title>RALACs: Action Recognition in Autonomous Vehicles using Interaction Encoding and Optical Flow. (arXiv:2209.14408v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2209.14408</link>
<description rdf:parseType="Literal">&lt;p&gt;When applied to autonomous vehicle (AV) settings, action recognition can
enhance an environment model&apos;s situational awareness. This is especially
prevalent in scenarios where traditional geometric descriptions and heuristics
in AVs are insufficient. However, action recognition has traditionally been
studied for humans, and its limited adaptability to noisy, un-clipped,
un-pampered, raw RGB data has limited its application in other fields. To push
for the advancement and adoption of action recognition into AVs, this work
proposes a novel two-stage action recognition system, termed RALACs. RALACs
formulates the problem of action recognition for road scenes, and bridges the
gap between it and the established field of human action recognition. This work
shows how attention layers can be useful for encoding the relations across
agents, and stresses how such a scheme can be class-agnostic. Furthermore, to
address the dynamic nature of agents on the road, RALACs constructs a novel
approach to adapting Region of Interest (ROI) Alignment to agent tracks for
downstream action classification. Finally, our scheme also considers the
problem of active agent detection, and utilizes a novel application of fusing
optical flow maps to discern relevant agents in a road scene. We show that our
proposed scheme can outperform the baseline on the ICCV2021 Road Challenge
dataset and by deploying it on a real vehicle platform, we provide preliminary
insight to the usefulness of action recognition in decision making.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1&quot;&gt;Eddy Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_A/0/1/0/all/0/1&quot;&gt;Alex Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budhwani_A/0/1/0/all/0/1&quot;&gt;Alikasim Budhwani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dempster_R/0/1/0/all/0/1&quot;&gt;Rowan Dempster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Quanquan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Sharman_M/0/1/0/all/0/1&quot;&gt;Mohammad Al-Sharman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rayside_D/0/1/0/all/0/1&quot;&gt;Derek Rayside&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melek_W/0/1/0/all/0/1&quot;&gt;William Melek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.04087">
<title>Symmetry Defense Against CNN Adversarial Perturbation Attacks. (arXiv:2210.04087v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.04087</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper uses symmetry to make Convolutional Neural Network classifiers
(CNNs) robust against adversarial perturbation attacks. Such attacks add
perturbation to original images to generate adversarial images that fool
classifiers such as road sign classifiers of autonomous vehicles. Although
symmetry is a pervasive aspect of the natural world, CNNs are unable to handle
symmetry well. For example, a CNN can classify an image differently from its
mirror image. For an adversarial image that misclassifies with a wrong label
$l_w$, CNN inability to handle symmetry means that a symmetric adversarial
image can classify differently from the wrong label $l_w$. Further than that,
we find that the classification of a symmetric adversarial image reverts to the
correct label. To classify an image when adversaries are unaware of the
defense, we apply symmetry to the image and use the classification label of the
symmetric image. To classify an image when adversaries are aware of the
defense, we use mirror symmetry and pixel inversion symmetry to form a symmetry
group. We apply all the group symmetries to the image and decide on the output
label based on the agreement of any two of the classification labels of the
symmetry images. Adaptive attacks fail because they need to rely on loss
functions that use conflicting CNN output values for symmetric images. Without
attack knowledge, the proposed symmetry defense succeeds against both
gradient-based and random-search attacks, with up to near-default accuracies
for ImageNet. The defense even improves the classification accuracy of original
images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindqvist_B/0/1/0/all/0/1&quot;&gt;Blerta Lindqvist&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.13662">
<title>Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis Testing: A Lesson From Fano. (arXiv:2210.13662v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.13662</link>
<description rdf:parseType="Literal">&lt;p&gt;Differential privacy (DP) is by far the most widely accepted framework for
mitigating privacy risks in machine learning. However, exactly how small the
privacy parameter $\epsilon$ needs to be to protect against certain privacy
risks in practice is still not well-understood. In this work, we study data
reconstruction attacks for discrete data and analyze it under the framework of
multiple hypothesis testing. We utilize different variants of the celebrated
Fano&apos;s inequality to derive upper bounds on the inferential power of a data
reconstruction adversary when the model is trained differentially privately.
Importantly, we show that if the underlying private data takes values from a
set of size $M$, then the target privacy parameter $\epsilon$ can be $O(\log
M)$ before the adversary gains significant inferential power. Our analysis
offers theoretical evidence for the empirical effectiveness of DP against data
reconstruction attacks even at relatively large values of $\epsilon$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1&quot;&gt;Chuan Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sablayrolles_A/0/1/0/all/0/1&quot;&gt;Alexandre Sablayrolles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1&quot;&gt;Maziar Sanjabi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.03942">
<title>Privacy-Aware Compression for Federated Learning Through Numerical Mechanism Design. (arXiv:2211.03942v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.03942</link>
<description rdf:parseType="Literal">&lt;p&gt;In private federated learning (FL), a server aggregates differentially
private updates from a large number of clients in order to train a machine
learning model. The main challenge in this setting is balancing privacy with
both classification accuracy of the learnt model as well as the number of bits
communicated between the clients and server. Prior work has achieved a good
trade-off by designing a privacy-aware compression mechanism, called the
minimum variance unbiased (MVU) mechanism, that numerically solves an
optimization problem to determine the parameters of the mechanism. This paper
builds upon it by introducing a new interpolation procedure in the numerical
design process that allows for a far more efficient privacy analysis. The
result is the new Interpolated MVU mechanism that is more scalable, has a
better privacy-utility trade-off, and provides SOTA results on
communication-efficient private FL on a variety of datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1&quot;&gt;Chuan Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_K/0/1/0/all/0/1&quot;&gt;Kamalika Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stock_P/0/1/0/all/0/1&quot;&gt;Pierre Stock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1&quot;&gt;Mike Rabbat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.04702">
<title>A survey of some recent developments in measures of association. (arXiv:2211.04702v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/2211.04702</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper surveys some recent developments in measures of association
related to a new coefficient of correlation introduced by the author. A
straightforward extension of this coefficient to standard Borel spaces (which
includes all Polish spaces), overlooked in the literature so far, is proposed
at the end of the survey.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chatterjee_S/0/1/0/all/0/1&quot;&gt;Sourav Chatterjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.00790">
<title>Online learning techniques for prediction of temporal tabular datasets with regime changes. (arXiv:2301.00790v4 [q-fin.CP] UPDATED)</title>
<link>http://arxiv.org/abs/2301.00790</link>
<description rdf:parseType="Literal">&lt;p&gt;The application of deep learning to non-stationary temporal datasets can lead
to overfitted models that underperform under regime changes. In this work, we
propose a modular machine learning pipeline for ranking predictions on temporal
panel datasets which is robust under regime changes. The modularity of the
pipeline allows the use of different models, including Gradient Boosting
Decision Trees (GBDTs) and Neural Networks, with and without feature
engineering. We evaluate our framework on financial data for stock portfolio
prediction, and find that GBDT models with dropout display high performance,
robustness and generalisability with reduced complexity and computational cost.
We then demonstrate how online learning techniques, which require no retraining
of models, can be used post-prediction to enhance the results. First, we show
that dynamic feature projection improves robustness by reducing drawdown in
regime changes. Second, we demonstrate that dynamical model ensembling based on
selection of models with good recent performance leads to improved Sharpe and
Calmar ratios of out-of-sample predictions. We also evaluate the robustness of
our pipeline across different data splits and random seeds with good
reproducibility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Wong_T/0/1/0/all/0/1&quot;&gt;Thomas Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Barahona_M/0/1/0/all/0/1&quot;&gt;Mauricio Barahona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.05869">
<title>Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification. (arXiv:2301.05869v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.05869</link>
<description rdf:parseType="Literal">&lt;p&gt;It is desirable for statistical models to detect signals of interest
independently of their position. If the data is generated by some smooth
process, this additional structure should be taken into account. We introduce a
new class of neural networks that are shift invariant and preserve smoothness
of the data: functional neural networks (FNNs). For this, we use methods from
functional data analysis (FDA) to extend multi-layer perceptrons and
convolutional neural networks to functional data. We propose different model
architectures, show that the models outperform a benchmark model from FDA in
terms of accuracy and successfully use FNNs to classify electroencephalography
(EEG) data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinrichs_F/0/1/0/all/0/1&quot;&gt;Florian Heinrichs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heim_M/0/1/0/all/0/1&quot;&gt;Mavin Heim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1&quot;&gt;Corinna Weber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.10822">
<title>RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks. (arXiv:2301.10822v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2301.10822</link>
<description rdf:parseType="Literal">&lt;p&gt;The state-of-the-art predictive maintenance (PdM) techniques have shown great
success in reducing maintenance costs and downtime of complicated machines
while increasing overall productivity through extensive utilization of
Internet-of-Things (IoT) and Deep Learning (DL). Unfortunately, IoT sensors and
DL algorithms are both prone to cyber-attacks. For instance, DL algorithms are
known for their susceptibility to adversarial examples. Such adversarial
attacks are vastly under-explored in the PdM domain. This is because the
adversarial attacks in the computer vision domain for classification tasks
cannot be directly applied to the PdM domain for multivariate time series (MTS)
regression tasks. In this work, we propose an end-to-end methodology to design
adversarially robust PdM systems by extensively analyzing the effect of
different types of adversarial attacks and proposing a novel adversarial
defense technique for DL-enabled PdM models. First, we propose novel MTS
Projected Gradient Descent (PGD) and MTS PGD with random restarts (PGD_r)
attacks. Then, we evaluate the impact of MTS PGD and PGD_r along with MTS Fast
Gradient Sign Method (FGSM) and MTS Basic Iterative Method (BIM) on Long
Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), Convolutional Neural
Network (CNN), and Bi-directional LSTM based PdM system. Our results using
NASA&apos;s turbofan engine dataset show that adversarial attacks can cause a severe
defect (up to 11X) in the RUL prediction, outperforming the effectiveness of
the state-of-the-art PdM attacks by 3X. Furthermore, we present a novel
approximate adversarial training method to defend against adversarial attacks.
We observe that approximate adversarial training can significantly improve the
robustness of PdM models (up to 54X) and outperforms the state-of-the-art PdM
defense methods by offering 3X more robustness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siddique_A/0/1/0/all/0/1&quot;&gt;Ayesha Siddique&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kundu_R/0/1/0/all/0/1&quot;&gt;Ripan Kumar Kundu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mode_G/0/1/0/all/0/1&quot;&gt;Gautam Raj Mode&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoque_K/0/1/0/all/0/1&quot;&gt;Khaza Anuarul Hoque&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.00453">
<title>Width and Depth Limits Commute in Residual Networks. (arXiv:2302.00453v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2302.00453</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that taking the width and depth to infinity in a deep neural network
with skip connections, when branches are scaled by $1/\sqrt{depth}$ (the only
nontrivial scaling), result in the same covariance structure no matter how that
limit is taken. This explains why the standard infinite-width-then-depth
approach provides practical insights even for networks with depth of the same
order as width. We also demonstrate that the pre-activations, in this case,
have Gaussian distributions which has direct applications in Bayesian deep
learning. We conduct extensive simulations that show an excellent match with
our theoretical findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hayou_S/0/1/0/all/0/1&quot;&gt;Soufiane Hayou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Greg Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.09738">
<title>Simplifying Momentum-based Positive-definite Submanifold Optimization with Applications to Deep Learning. (arXiv:2302.09738v7 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2302.09738</link>
<description rdf:parseType="Literal">&lt;p&gt;Riemannian submanifold optimization with momentum is computationally
challenging because, to ensure that the iterates remain on the submanifold, we
often need to solve difficult differential equations. Here, we simplify such
difficulties for a class of sparse or structured symmetric positive-definite
matrices with the affine-invariant metric. We do so by proposing a generalized
version of the Riemannian normal coordinates that dynamically orthonormalizes
the metric and locally converts the problem into an unconstrained problem in
the Euclidean space. We use our approach to simplify existing approaches for
structured covariances and develop matrix-inverse-free $2^\text{nd}$-order
optimizers for deep learning with low precision by using only matrix
multiplications. Code: https://github.com/yorkerlin/StructuredNGD-DL
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_W/0/1/0/all/0/1&quot;&gt;Wu Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duruisseaux_V/0/1/0/all/0/1&quot;&gt;Valentin Duruisseaux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Leok_M/0/1/0/all/0/1&quot;&gt;Melvin Leok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nielsen_F/0/1/0/all/0/1&quot;&gt;Frank Nielsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Mohammad Emtiyaz Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schmidt_M/0/1/0/all/0/1&quot;&gt;Mark Schmidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.14679">
<title>Synthesizing Mixed-type Electronic Health Records using Diffusion Models. (arXiv:2302.14679v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.14679</link>
<description rdf:parseType="Literal">&lt;p&gt;Electronic Health Records (EHRs) contain sensitive patient information, which
presents privacy concerns when sharing such data. Synthetic data generation is
a promising solution to mitigate these risks, often relying on deep generative
models such as Generative Adversarial Networks (GANs). However, recent studies
have shown that diffusion models offer several advantages over GANs, such as
generation of more realistic synthetic data and stable training in generating
data modalities, including image, text, and sound. In this work, we investigate
the potential of diffusion models for generating realistic mixed-type tabular
EHRs, comparing TabDDPM model with existing methods on four datasets in terms
of data quality, utility, privacy, and augmentation. Our experiments
demonstrate that TabDDPM outperforms the state-of-the-art models across all
evaluation metrics, except for privacy, which confirms the trade-off between
privacy and utility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceritli_T/0/1/0/all/0/1&quot;&gt;Taha Ceritli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosheh_G/0/1/0/all/0/1&quot;&gt;Ghadeer O. Ghosheh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1&quot;&gt;Vinod Kumar Chauhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1&quot;&gt;Tingting Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Creagh_A/0/1/0/all/0/1&quot;&gt;Andrew P. Creagh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1&quot;&gt;David A. Clifton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.06024">
<title>A hybrid deep-learning-metaheuristic framework for bi-level network design problems. (arXiv:2303.06024v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/2303.06024</link>
<description rdf:parseType="Literal">&lt;p&gt;This study proposes a hybrid deep-learning-metaheuristic framework with a
bi-level architecture for road network design problems (NDPs). We train a graph
neural network (GNN) to approximate the solution of the user equilibrium (UE)
traffic assignment problem and use inferences made by the trained model to
calculate fitness function evaluations of a genetic algorithm (GA) to
approximate solutions for NDPs. Using three test networks, two NDP variants and
an exact solver as benchmark, we show that on average, our proposed framework
can provide solutions within 1.5% gap of the best results in less than 0.5% of
the time used by the exact solution procedure. Our framework can be utilized
within an expert system for infrastructure planning to determine the best
infrastructure planning and management decisions under different scenarios.
Given the flexibility of the framework, it can easily be adapted to many other
decision problems that can be modeled as bi-level problems on graphs. Moreover,
we foreseen interesting future research directions, thus we also put forward a
brief research agenda for this topic. The key observation from our research
that can shape future research is that the fitness function evaluation time
using the inferences made by the GNN model was in the order of milliseconds,
which points to an opportunity and a need for novel heuristics that 1) can cope
well with noisy fitness function values provided by deep learning models, and
2) can use the significantly enlarged efficiency of the evaluation step to
explore the search space effectively (rather than efficiently). This opens a
new avenue for a modern class of metaheuristics that are crafted for use with
AI-powered predictors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madadi_B/0/1/0/all/0/1&quot;&gt;Bahman Madadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Correia_G/0/1/0/all/0/1&quot;&gt;Goncalo Homem de Almeida Correia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.06601">
<title>Multi-metrics adaptively identifies backdoors in Federated learning. (arXiv:2303.06601v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2303.06601</link>
<description rdf:parseType="Literal">&lt;p&gt;The decentralized and privacy-preserving nature of federated learning (FL)
makes it vulnerable to backdoor attacks aiming to manipulate the behavior of
the resulting model on specific adversary-chosen inputs. However, most existing
defenses based on statistical differences take effect only against specific
attacks, especially when the malicious gradients are similar to benign ones or
the data are highly non-independent and identically distributed (non-IID). In
this paper, we revisit the distance-based defense methods and discover that i)
Euclidean distance becomes meaningless in high dimensions and ii) malicious
gradients with diverse characteristics cannot be identified by a single metric.
To this end, we present a simple yet effective defense strategy with
multi-metrics and dynamic weighting to identify backdoors adaptively.
Furthermore, our novel defense has no reliance on predefined assumptions over
attack settings or data distributions and little impact on benign performance.
To evaluate the effectiveness of our approach, we conduct comprehensive
experiments on different datasets under various attack settings, where our
method achieves the best defensive performance. For instance, we achieve the
lowest backdoor accuracy of 3.06% under the difficult Edge-case PGD, showing
significant superiority over previous defenses. The results also demonstrate
that our method can be well-adapted to a wide range of non-IID degrees without
sacrificing the benign performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Siquan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yijiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1&quot;&gt;Leyu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Ying Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.07925">
<title>Deep incremental learning models for financial temporal tabular datasets with distribution shifts. (arXiv:2303.07925v7 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.07925</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a robust deep incremental learning framework for regression tasks
on financial temporal tabular datasets which is built upon the incremental use
of commonly available tabular and time series prediction models to adapt to
distributional shifts typical of financial datasets. The framework uses a
simple basic building block (decision trees) to build self-similar models of
any required complexity to deliver robust performance under adverse situations
such as regime changes, fat-tailed distributions, and low signal-to-noise
ratios. As a detailed study, we demonstrate our scheme using XGBoost models
trained on the Numerai dataset and show that a two layer deep ensemble of
XGBoost models over different model snapshots delivers high quality predictions
under different market regimes. We also show that the performance of XGBoost
models with different number of boosting rounds in three scenarios (small,
standard and large) is monotonically increasing with respect to model size and
converges towards the generalisation upper bound. We also evaluate the
robustness of the model under variability of different hyperparameters, such as
model complexity and data sampling settings. Our model has low hardware
requirements as no specialised neural architectures are used and each base
model can be independently trained in parallel.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1&quot;&gt;Thomas Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barahona_M/0/1/0/all/0/1&quot;&gt;Mauricio Barahona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.08902">
<title>Learning ground states of gapped quantum Hamiltonians with Kernel Methods. (arXiv:2303.08902v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2303.08902</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network approaches to approximate the ground state of quantum
hamiltonians require the numerical solution of a highly nonlinear optimization
problem. We introduce a statistical learning approach that makes the
optimization trivial by using kernel methods. Our scheme is an approximate
realization of the power method, where supervised learning is used to learn the
next step of the power iteration. We show that the ground state properties of
arbitrary gapped quantum hamiltonians can be reached with polynomial resources
under the assumption that the supervised learning is efficient. Using kernel
ridge regression, we provide numerical evidence that the learning assumption is
verified by applying our scheme to find the ground states of several
prototypical interacting many-body quantum systems, both in one and two
dimensions, showing the flexibility of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Giuliani_C/0/1/0/all/0/1&quot;&gt;Clemens Giuliani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Vicentini_F/0/1/0/all/0/1&quot;&gt;Filippo Vicentini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rossi_R/0/1/0/all/0/1&quot;&gt;Riccardo Rossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Carleo_G/0/1/0/all/0/1&quot;&gt;Giuseppe Carleo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.14961">
<title>Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection. (arXiv:2303.14961v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.14961</link>
<description rdf:parseType="Literal">&lt;p&gt;As the use of machine learning continues to expand, the importance of
ensuring its safety cannot be overstated. A key concern in this regard is the
ability to identify whether a given sample is from the training distribution,
or is an &quot;Out-Of-Distribution&quot; (OOD) sample. In addition, adversaries can
manipulate OOD samples in ways that lead a classifier to make a confident
prediction. In this study, we present a novel approach for certifying the
robustness of OOD detection within a $\ell_2$-norm around the input, regardless
of network architecture and without the need for specific components or
additional training. Further, we improve current techniques for detecting
adversarial attacks on OOD samples, while providing high levels of certified
and adversarial robustness on in-distribution samples. The average of all OOD
detection metrics on CIFAR10/100 shows an increase of $\sim 13 \% / 5\%$
relative to previous approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franco_N/0/1/0/all/0/1&quot;&gt;Nicola Franco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korth_D/0/1/0/all/0/1&quot;&gt;Daniel Korth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lorenz_J/0/1/0/all/0/1&quot;&gt;Jeanette Miriam Lorenz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roscher_K/0/1/0/all/0/1&quot;&gt;Karsten Roscher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guennemann_S/0/1/0/all/0/1&quot;&gt;Stephan Guennemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.05874">
<title>Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer&apos;s Disease using EEG Data. (arXiv:2304.05874v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/2304.05874</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural network (GNN) models are increasingly being used for the
classification of electroencephalography (EEG) data. However, GNN-based
diagnosis of neurological disorders, such as Alzheimer&apos;s disease (AD), remains
a relatively unexplored area of research. Previous studies have relied on
functional connectivity methods to infer brain graph structures and used simple
GNN architectures for the diagnosis of AD. In this work, we propose a novel
adaptive gated graph convolutional network (AGGCN) that can provide explainable
predictions. AGGCN adaptively learns graph structures by combining
convolution-based node feature enhancement with a well-known correlation-based
measure of functional connectivity. Furthermore, the gated graph convolution
can dynamically weigh the contribution of various spatial scales. The proposed
model achieves high accuracy in both eyes-closed and eyes-open conditions,
indicating the stability of learned representations. Finally, we demonstrate
that the proposed AGGCN model generates consistent explanations of its
predictions that might be relevant for further study of AD-related alterations
of brain networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Klepl_D/0/1/0/all/0/1&quot;&gt;Dominik Klepl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+He_F/0/1/0/all/0/1&quot;&gt;Fei He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Min Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Blackburn_D/0/1/0/all/0/1&quot;&gt;Daniel J. Blackburn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sarrigiannis_P/0/1/0/all/0/1&quot;&gt;Ptolemaios G. Sarrigiannis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.09797">
<title>Progressive-Hint Prompting Improves Reasoning in Large Language Models. (arXiv:2304.09797v5 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2304.09797</link>
<description rdf:parseType="Literal">&lt;p&gt;The performance of Large Language Models (LLMs) in reasoning tasks depends
heavily on prompt design, with Chain-of-Thought (CoT) and self-consistency
being critical methods that enhance this ability. However, these methods do not
fully exploit the answers generated by the LLM to guide subsequent responses.
This paper proposes a new prompting method, named Progressive-Hint Prompting
(PHP), that enables automatic multiple interactions between users and LLMs by
using previously generated answers as hints to progressively guide toward the
correct answers. PHP is orthogonal to CoT and self-consistency, making it easy
to combine with state-of-the-art techniques to further improve performance. We
conducted extensive and comprehensive experiments on seven benchmarks. The
results show that PHP significantly improves accuracy while remaining highly
efficient. For instance, with text-davinci-003, we observed a 4.2% improvement
on GSM8K with greedy decoding compared to Complex CoT, and a 46.17% reduction
in sample paths with self-consistency. With GPT-4 and PHP, we achieve
state-of-the-art performances on SVAMP (89.1% -&amp;gt; 91.9%), GSM8K (92% -&amp;gt; 95.5%),
AQuA (76.4% -&amp;gt; 79.9%) and MATH (50.3% -&amp;gt; 53.9%).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Chuanyang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhengying Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1&quot;&gt;Enze Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenguo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yu Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.10382">
<title>Conditional Generative Models for Learning Stochastic Processes. (arXiv:2304.10382v4 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2304.10382</link>
<description rdf:parseType="Literal">&lt;p&gt;A framework to learn a multi-modal distribution is proposed, denoted as the
Conditional Quantum Generative Adversarial Network (C-qGAN). The neural network
structure is strictly within a quantum circuit and, as a consequence, is shown
to represent a more efficient state preparation procedure than current methods.
This methodology has the potential to speed-up algorithms, such as Monte Carlo
analysis. In particular, after demonstrating the effectiveness of the network
in the learning task, the technique is applied to price Asian option
derivatives, providing the foundation for further research on other
path-dependent options.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Certo_S/0/1/0/all/0/1&quot;&gt;Salvatore Certo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pham_A/0/1/0/all/0/1&quot;&gt;Anh Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Robles_N/0/1/0/all/0/1&quot;&gt;Nicolas Robles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Vlasic_A/0/1/0/all/0/1&quot;&gt;Andrew Vlasic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.12177">
<title>{\Pi}-ML: A dimensional analysis-based machine learning parameterization of optical turbulence in the atmospheric surface layer. (arXiv:2304.12177v2 [physics.ao-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2304.12177</link>
<description rdf:parseType="Literal">&lt;p&gt;Turbulent fluctuations of the atmospheric refraction index, so-called optical
turbulence, can significantly distort propagating laser beams. Therefore,
modeling the strength of these fluctuations ($C_n^2$) is highly relevant for
the successful development and deployment of future free-space optical
communication links. In this letter, we propose a physics-informed machine
learning (ML) methodology, $\Pi$-ML, based on dimensional analysis and gradient
boosting to estimate $C_n^2$. Through a systematic feature importance analysis,
we identify the normalized variance of potential temperature as the dominating
feature for predicting $C_n^2$. For statistical robustness, we train an
ensemble of models which yields high performance on the out-of-sample data of
$R^2=0.958\pm0.001$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Pierzyna_M/0/1/0/all/0/1&quot;&gt;Maximilian Pierzyna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Saathof_R/0/1/0/all/0/1&quot;&gt;Rudolf Saathof&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Basu_S/0/1/0/all/0/1&quot;&gt;Sukanta Basu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.03829">
<title>Improving Image-Based Precision Medicine with Uncertainty-Aware Causal Models. (arXiv:2305.03829v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.03829</link>
<description rdf:parseType="Literal">&lt;p&gt;Image-based precision medicine aims to personalize treatment decisions based
on an individual&apos;s unique imaging features so as to improve their clinical
outcome. Machine learning frameworks that integrate uncertainty estimation as
part of their treatment recommendations would be safer and more reliable.
However, little work has been done in adapting uncertainty estimation
techniques and validation metrics for precision medicine. In this paper, we use
Bayesian deep learning for estimating the posterior distribution over factual
and counterfactual outcomes on several treatments. This allows for estimating
the uncertainty for each treatment option and for the individual treatment
effects (ITE) between any two treatments. We train and evaluate this model to
predict future new and enlarging T2 lesion counts on a large, multi-center
dataset of MR brain images of patients with multiple sclerosis, exposed to
several treatments during randomized controlled trials. We evaluate the
correlation of the uncertainty estimate with the factual error, and, given the
lack of ground truth counterfactual outcomes, demonstrate how uncertainty for
the ITE prediction relates to bounds on the ITE error. Lastly, we demonstrate
how knowledge of uncertainty could modify clinical decision-making to improve
individual patient and clinical trial outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durso_Finley_J/0/1/0/all/0/1&quot;&gt;Joshua Durso-Finley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Falet_J/0/1/0/all/0/1&quot;&gt;Jean-Pierre Falet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_R/0/1/0/all/0/1&quot;&gt;Raghav Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arnold_D/0/1/0/all/0/1&quot;&gt;Douglas L. Arnold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawlowski_N/0/1/0/all/0/1&quot;&gt;Nick Pawlowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arbel_T/0/1/0/all/0/1&quot;&gt;Tal Arbel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.11122">
<title>Autonomous sputter synthesis of thin film nitrides with composition controlled by Bayesian optimization of optical plasma emission. (arXiv:2305.11122v3 [physics.app-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2305.11122</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous experimentation has emerged as an efficient approach to accelerate
the pace of materials discovery. Although instruments for autonomous synthesis
have become popular in molecular and polymer science, solution processing of
hybrid materials and nanoparticles, examples of autonomous tools for physical
vapor deposition are scarce yet important for the semiconductor industry. Here,
we report the design and implementation of an autonomous workflow for sputter
deposition of thin films with controlled composition, leveraging a highly
automated sputtering reactor custom-controlled by Python, optical emission
spectroscopy (OES), and a Bayesian optimization algorithm. We modeled film
composition, measured by x-ray fluorescence, as a linear function of emission
lines monitored during the co-sputtering from elemental Zn and Ti targets in
N$_2$ atmosphere. A Bayesian control algorithm, informed by OES, navigates the
space of sputtering power to fabricate films with user-defined composition, by
minimizing the absolute error between desired and measured emission signals. We
validated our approach by autonomously fabricating Zn$_x$Ti$_{1-x}$N$_y$ films
with deviations from the targeted cation composition within relative 3.5 %,
even for 15 nm thin films, demonstrating that the proposed approach can
reliably synthesize thin films with specific composition and minimal human
interference. Moreover, the proposed method can be extended to more difficult
synthesis experiments where plasma intensity depends non-linearly on pressure,
or the elemental sticking coefficients strongly depend on the substrate
temperature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Febba_D/0/1/0/all/0/1&quot;&gt;Davi M. Febba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Talley_K/0/1/0/all/0/1&quot;&gt;Kevin R. Talley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Johnson_K/0/1/0/all/0/1&quot;&gt;Kendal Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Schaefer_S/0/1/0/all/0/1&quot;&gt;Stephen Schaefer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Bauers_S/0/1/0/all/0/1&quot;&gt;Sage R. Bauers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mangum_J/0/1/0/all/0/1&quot;&gt;John S. Mangum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Smaha_R/0/1/0/all/0/1&quot;&gt;Rebecca W. Smaha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zakutayev_A/0/1/0/all/0/1&quot;&gt;Andriy Zakutayev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.11509">
<title>From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.11509</link>
<description rdf:parseType="Literal">&lt;p&gt;Random Search is one of the most widely-used method for Hyperparameter
Optimization, and is critical to the success of deep learning models. Despite
its astonishing performance, little non-heuristic theory has been developed to
describe the underlying working mechanism. This paper gives a theoretical
accounting of Random Search. We introduce the concept of \emph{scattering
dimension} that describes the landscape of the underlying function, and
quantifies the performance of random search. We show that, when the environment
is noise-free, the output of random search converges to the optimal value in
probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T}
\right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering
dimension of the underlying function. When the observed function values are
corrupted by bounded $iid$ noise, the output of random search converges to the
optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left(
\frac{1}{T} \right)^{ \frac{1}{d_s + 1} } \right) $. In addition, based on the
principles of random search, we introduce an algorithm, called BLiN-MOS, for
Lipschitz bandits in doubling metric spaces that are also endowed with a
probability measure, and show that BLiN-MOS achieves a regret rate of order $
\widetilde{\mathcal{O}} \left( T^{ \frac{d_z}{d_z + 1} } \right) $, where $d_z$
is the zooming dimension of the problem instance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1&quot;&gt;Chuying Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yasong Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tianyu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12932">
<title>Forecasting Irregularly Sampled Time Series using Graphs. (arXiv:2305.12932v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12932</link>
<description rdf:parseType="Literal">&lt;p&gt;Forecasting irregularly sampled time series with missing values is a crucial
task for numerous real-world applications such as healthcare, astronomy, and
climate sciences. State-of-the-art approaches to this problem rely on Ordinary
Differential Equations (ODEs) which are known to be slow and often require
additional features to handle missing values. To address this issue, we propose
a novel model using Graphs for Forecasting Irregularly Sampled Time Series with
missing values which we call GraFITi. GraFITi first converts the time series to
a Sparsity Structure Graph which is a sparse bipartite graph, and then
reformulates the forecasting problem as the edge weight prediction task in the
graph. It uses the power of Graph Neural Networks to learn the graph and
predict the target edge weights. GraFITi has been tested on 3 real-world and 1
synthetic irregularly sampled time series dataset with missing values and
compared with various state-of-the-art models. The experimental results
demonstrate that GraFITi improves the forecasting accuracy by up to 17% and
reduces the run time up to 5 times compared to the state-of-the-art forecasting
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yalavarthi_V/0/1/0/all/0/1&quot;&gt;Vijaya Krishna Yalavarthi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madhusudhanan_K/0/1/0/all/0/1&quot;&gt;Kiran Madhusudhanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sholz_R/0/1/0/all/0/1&quot;&gt;Randolf Sholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1&quot;&gt;Nourhan Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burchert_J/0/1/0/all/0/1&quot;&gt;Johannes Burchert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jawed_S/0/1/0/all/0/1&quot;&gt;Shayan Jawed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Born_S/0/1/0/all/0/1&quot;&gt;Stefan Born&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1&quot;&gt;Lars Schmidt-Thieme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19170">
<title>Forward-Forward Training of an Optical Neural Network. (arXiv:2305.19170v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19170</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks (NN) have demonstrated remarkable capabilities in various
tasks, but their computation-intensive nature demands faster and more
energy-efficient hardware implementations. Optics-based platforms, using
technologies such as silicon photonics and spatial light modulators, offer
promising avenues for achieving this goal. However, training multiple trainable
layers in tandem with these physical systems poses challenges, as they are
difficult to fully characterize and describe with differentiable functions,
hindering the use of error backpropagation algorithm. The recently introduced
Forward-Forward Algorithm (FFA) eliminates the need for perfect
characterization of the learning system and shows promise for efficient
training with large numbers of programmable parameters. The FFA does not
require backpropagating an error signal to update the weights, rather the
weights are updated by only sending information in one direction. The local
loss function for each set of trainable weights enables low-power analog
hardware implementations without resorting to metaheuristic algorithms or
reinforcement learning. In this paper, we present an experiment utilizing
multimode nonlinear wave propagation in an optical fiber demonstrating the
feasibility of the FFA approach using an optical system. The results show that
incorporating optical transforms in multilayer NN architectures trained with
the FFA, can lead to performance improvements, even with a relatively small
number of trainable weights. The proposed method offers a new path to the
challenge of training optical NNs and provides insights into leveraging
physical transformations for enhancing NN performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oguz_I/0/1/0/all/0/1&quot;&gt;Ilker Oguz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_J/0/1/0/all/0/1&quot;&gt;Junjie Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qifei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Feng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yildirim_M/0/1/0/all/0/1&quot;&gt;Mustafa Yildirim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dinc_N/0/1/0/all/0/1&quot;&gt;Niyazi Ulas Dinc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_J/0/1/0/all/0/1&quot;&gt;Jih-Liang Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moser_C/0/1/0/all/0/1&quot;&gt;Christophe Moser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Psaltis_D/0/1/0/all/0/1&quot;&gt;Demetri Psaltis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.03805">
<title>The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter. (arXiv:2306.03805v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.03805</link>
<description rdf:parseType="Literal">&lt;p&gt;Large pre-trained transformers are show-stealer in modern-day deep learning,
and it becomes crucial to comprehend the parsimonious patterns that exist
within them as they grow in scale. With exploding parameter counts, Lottery
Ticket Hypothesis (LTH) and its variants, have lost their pragmatism in
sparsifying them due to high computation and memory bottleneck of repetitive
train-prune-retrain routine of iterative magnitude pruning (IMP) which worsens
with increasing model size. This paper comprehensively studies induced sparse
patterns across multiple large pre-trained vision and language transformers. We
propose the existence of -- essential sparsity defined with a sharp dropping
point beyond which the performance declines much faster w.r.t the rise of
sparsity level, when we directly remove weights with the smallest magnitudes in
one-shot without re-training. We also find essential sparsity to hold valid for
N:M sparsity patterns as well as on modern-scale large language models
(Vicuna-7B). We also present an intriguing emerging phenomenon of abrupt
sparsification during the pre-training of BERT, i.e., BERT suddenly becomes
heavily sparse in pre-training after certain iterations. Moreover, our
observations also indicate a counter-intuitive finding that BERT trained with a
larger amount of pre-training data tends to have a better ability to condense
knowledge in comparatively relatively fewer parameters. Lastly, we investigate
the effect of the pre-training loss on essential sparsity and discover that
self-supervised learning (SSL) objectives trigger stronger emergent
sparsification properties than supervised learning (SL). Our codes are
available at \url{https://github.com/VITA-Group/essential_sparsity}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaiswal_A/0/1/0/all/0/1&quot;&gt;Ajay Jaiswal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shiwei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianlong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhangyang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.06955">
<title>A Brief Review of Hypernetworks in Deep Learning. (arXiv:2306.06955v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.06955</link>
<description rdf:parseType="Literal">&lt;p&gt;Hypernetworks, or hypernets in short, are neural networks that generate
weights for another neural network, known as the target network. They have
emerged as a powerful deep learning technique that allows for greater
flexibility, adaptability, dynamism, faster training, information sharing, and
model compression etc. Hypernets have shown promising results in a variety of
deep learning problems, including continual learning, causal inference,
transfer learning, weight pruning, uncertainty quantification, zero-shot
learning, natural language processing, and reinforcement learning etc. Despite
their success across different problem settings, currently, there is no review
available to inform the researchers about the developments and to help in
utilizing hypernets. To fill this gap, we review the progress in hypernets. We
present an illustrative example to train deep neural networks using hypernets
and propose categorizing hypernets based on five design criteria as inputs,
outputs, variability of inputs and outputs, and architecture of hypernets. We
also review applications of hypernets across different deep learning problem
settings, followed by a discussion of general scenarios where hypernets can be
effectively employed. Finally, we discuss the challenges and future directions
that remain under-explored in the field of hypernets. We believe that
hypernetworks have the potential to revolutionize the field of deep learning.
They offer a new way to design and train neural networks, and they have the
potential to improve the performance of deep learning models on a variety of
tasks. Through this review, we aim to inspire further advancements in deep
learning through hypernetworks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1&quot;&gt;Vinod Kumar Chauhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiandong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1&quot;&gt;Ping Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molaei_S/0/1/0/all/0/1&quot;&gt;Soheila Molaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1&quot;&gt;David A. Clifton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.09807">
<title>FALL-E: A Foley Sound Synthesis Model and Strategies. (arXiv:2306.09807v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2306.09807</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces FALL-E, a foley synthesis system and its
training/inference strategies. The FALL-E model employs a cascaded approach
comprising low-resolution spectrogram generation, spectrogram super-resolution,
and a vocoder. We trained every sound-related model from scratch using our
extensive datasets, and utilized a pre-trained language model. We conditioned
the model with dataset-specific texts, enabling it to learn sound quality and
recording environment based on text input. Moreover, we leveraged external
language models to improve text descriptions of our datasets and performed
prompt engineering for quality, coherence, and diversity. FALL-E was evaluated
by an objective measure as well as listening tests in the DCASE 2023 challenge
Task 7. The submission achieved the second place on average, while achieving
the best score for diversity, second place for audio quality, and third place
for class fitness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kang_M/0/1/0/all/0/1&quot;&gt;Minsung Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Sangshin Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Moon_H/0/1/0/all/0/1&quot;&gt;Hyeongi Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kyungyun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chon_B/0/1/0/all/0/1&quot;&gt;Ben Sangbae Chon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.13759">
<title>Incremental Profit per Conversion: a Response Transformation for Uplift Modeling in E-Commerce Promotions. (arXiv:2306.13759v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.13759</link>
<description rdf:parseType="Literal">&lt;p&gt;Promotions play a crucial role in e-commerce platforms, and various cost
structures are employed to drive user engagement. This paper focuses on
promotions with response-dependent costs, where expenses are incurred only when
a purchase is made. Such promotions include discounts and coupons. While
existing uplift model approaches aim to address this challenge, these
approaches often necessitate training multiple models, like meta-learners, or
encounter complications when estimating profit due to zero-inflated values
stemming from non-converted individuals with zero cost and profit.
&lt;/p&gt;
&lt;p&gt;To address these challenges, we introduce Incremental Profit per Conversion
(IPC), a novel uplift measure of promotional campaigns&apos; efficiency in unit
economics. Through a proposed response transformation, we demonstrate that IPC
requires only converted data, its propensity, and a single model to be
estimated. As a result, IPC resolves the issues mentioned above while
mitigating the noise typically associated with the class imbalance in
conversion datasets and biases arising from the many-to-one mapping between
search and purchase data. Lastly, we validate the efficacy of our approach by
presenting results obtained from a synthetic simulation of a discount coupon
campaign.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Proenca_H/0/1/0/all/0/1&quot;&gt;Hugo Manuel Proen&amp;#xe7;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moraes_F/0/1/0/all/0/1&quot;&gt;Felipe Moraes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.16021">
<title>Structure in Reinforcement Learning: A Survey and Open Problems. (arXiv:2306.16021v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.16021</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement Learning (RL), bolstered by the expressive capabilities of Deep
Neural Networks (DNNs) for function approximation, has demonstrated
considerable success in numerous applications. However, its practicality in
addressing various real-world scenarios, characterized by diverse and
unpredictable dynamics, noisy signals, and large state and action spaces,
remains limited. This limitation stems from issues such as poor data
efficiency, limited generalization capabilities, a lack of safety guarantees,
and the absence of interpretability, among other factors. To overcome these
challenges and improve performance across these crucial metrics, one promising
avenue is to incorporate additional structural information about the problem
into the RL learning process. Various sub-fields of RL have proposed methods
for incorporating such inductive biases. We amalgamate these diverse
methodologies under a unified framework, shedding light on the role of
structure in the learning problem, and classify these methods into distinct
patterns of incorporating structure. By leveraging this comprehensive
framework, we provide valuable insights into the challenges of structured RL
and lay the groundwork for a design pattern perspective on RL research. This
novel perspective paves the way for future advancements and aids in developing
more effective and efficient RL algorithms that can potentially handle
real-world scenarios better.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohan_A/0/1/0/all/0/1&quot;&gt;Aditya Mohan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Amy Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1&quot;&gt;Marius Lindauer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02279">
<title>From NeurODEs to AutoencODEs: a mean-field control framework for width-varying Neural Networks. (arXiv:2307.02279v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02279</link>
<description rdf:parseType="Literal">&lt;p&gt;The connection between Residual Neural Networks (ResNets) and continuous-time
control systems (known as NeurODEs) has led to a mathematical analysis of
neural networks which has provided interesting results of both theoretical and
practical significance. However, by construction, NeurODEs have been limited to
describing constant-width layers, making them unsuitable for modeling deep
learning architectures with layers of variable width. In this paper, we propose
a continuous-time Autoencoder, which we call AutoencODE, based on a
modification of the controlled field that drives the dynamics. This adaptation
enables the extension of the mean-field control framework originally devised
for conventional NeurODEs. In this setting, we tackle the case of low Tikhonov
regularization, resulting in potentially non-convex cost landscapes. While the
global results obtained for high Tikhonov regularization may not hold globally,
we show that many of them can be recovered in regions where the loss function
is locally convex. Inspired by our theoretical findings, we develop a training
method tailored to this specific type of Autoencoders with residual
connections, and we validate our approach through numerical experiments
conducted on various examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cipriani_C/0/1/0/all/0/1&quot;&gt;Cristina Cipriani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Fornasier_M/0/1/0/all/0/1&quot;&gt;Massimo Fornasier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Scagliotti_A/0/1/0/all/0/1&quot;&gt;Alessandro Scagliotti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.07944">
<title>Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling. (arXiv:2307.07944v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.07944</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised domain adaptation (DA) with the aid of pseudo labeling
techniques has emerged as a crucial approach for domain-adaptive 3D object
detection. While effective, existing DA methods suffer from a substantial drop
in performance when applied to a multi-class training setting, due to the
co-existence of low-quality pseudo labels and class imbalance issues. In this
paper, we address this challenge by proposing a novel ReDB framework tailored
for learning to detect all classes at once. Our approach produces Reliable,
Diverse, and class-Balanced pseudo 3D boxes to iteratively guide the
self-training on a distributionally different target domain. To alleviate
disruptions caused by the environmental discrepancy (e.g., beam numbers), the
proposed cross-domain examination (CDE) assesses the correctness of pseudo
labels by copy-pasting target instances into a source environment and measuring
the prediction consistency. To reduce computational overhead and mitigate the
object shift (e.g., scales and point densities), we design an overlapped boxes
counting (OBC) metric that allows to uniformly downsample pseudo-labeled
objects across different geometric characteristics. To confront the issue of
inter-class imbalance, we progressively augment the target point clouds with a
class-balanced set of pseudo-labeled target instances and source objects, which
boosts recognition accuracies on both frequently appearing and rare classes.
Experimental results on three benchmark datasets using both voxel-based (i.e.,
SECOND) and point-based 3D detectors (i.e., PointRCNN) demonstrate that our
proposed ReDB approach outperforms existing 3D domain adaptation methods by a
large margin, improving 23.15% mAP on the nuScenes $\rightarrow$ KITTI task.
The code is available at https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhuoxiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yadan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baktashmotlagh_M/0/1/0/all/0/1&quot;&gt;Mahsa Baktashmotlagh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zi Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.14527">
<title>Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad. (arXiv:2307.14527v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.14527</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper details the challenges in applying two computer vision systems, an
EfficientDET supervised learning model and the unsupervised RX spectral
classifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search and
rescue (WSAR) effort in Japan and identifies 3 directions for future research.
There have been at least 19 proposed approaches and 3 datasets aimed at
locating missing persons in drone imagery, but only 3 approaches (2
unsupervised and 1 of an unknown structure) are referenced in the literature as
having been used in an actual WSAR operation. Of these proposed approaches, the
EfficientDET architecture and the unsupervised spectral RX classifier were
selected as the most appropriate for this setting. The EfficientDET model was
applied to the HERIDAL dataset and despite achieving performance that is
statistically equivalent to the state-of-the-art, the model fails to translate
to the real world in terms of false positives (e.g., identifying tree limbs and
rocks as people), and false negatives (e.g., failing to identify members of the
search team). The poor results in practice for algorithms that showed good
results on datasets suggest 3 areas of future research: more realistic datasets
for wilderness SAR, computer vision models that are capable of seamlessly
handling the variety of imagery that can be collected during actual WSAR
operations, and better alignment on performance measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manzini_T/0/1/0/all/0/1&quot;&gt;Thomas Manzini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murphy_R/0/1/0/all/0/1&quot;&gt;Robin Murphy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15644">
<title>Scaling Data Generation in Vision-and-Language Navigation. (arXiv:2307.15644v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.15644</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent research in language-guided visual navigation has demonstrated a
significant demand for the diversity of traversable environments and the
quantity of supervision for training generalizable agents. To tackle the common
data scarcity issue in existing vision-and-language navigation datasets, we
propose an effective paradigm for generating large-scale data for learning,
which applies 1200+ photo-realistic environments from HM3D and Gibson datasets
and synthesizes 4.9 million instruction trajectory pairs using fully-accessible
resources on the web. Importantly, we investigate the influence of each
component in this paradigm on the agent&apos;s performance and study how to
adequately apply the augmented data to pre-train and fine-tune an agent. Thanks
to our large-scale dataset, the performance of an existing agent can be pushed
up (+11% absolute with regard to previous SoTA) to a significantly new best of
80% single-run success rate on the R2R test split by simple imitation learning.
The long-lasting generalization gap between navigating in seen and unseen
environments is also reduced to less than 1% (versus 8% in the previous best
method). Moreover, our paradigm also facilitates different models to achieve
new state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuous
environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jialu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Yicong Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1&quot;&gt;Stephen Gould&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1&quot;&gt;Hao Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1&quot;&gt;Yu Qiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.16361">
<title>Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples. (arXiv:2307.16361v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.16361</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks (DNNs) for 3D point cloud recognition are vulnerable to
adversarial examples, threatening their practical deployment. Despite the many
research endeavors have been made to tackle this issue in recent years, the
diversity of adversarial examples on 3D point clouds makes them more
challenging to defend against than those on 2D images. For examples, attackers
can generate adversarial examples by adding, shifting, or removing points.
Consequently, existing defense strategies are hard to counter unseen point
cloud adversarial examples. In this paper, we first establish a comprehensive,
and rigorous point cloud adversarial robustness benchmark to evaluate
adversarial robustness, which can provide a detailed understanding of the
effects of the defense and attack methods. We then collect existing defense
tricks in point cloud adversarial defenses and then perform extensive and
systematic experiments to identify an effective combination of these tricks.
Furthermore, we propose a hybrid training augmentation methods that consider
various types of point cloud adversarial examples to adversarial training,
significantly improving the adversarial robustness. By combining these tricks,
we construct a more robust defense framework achieving an average accuracy of
83.45\% against various attacks, demonstrating its capability to enabling
robust learners. Our codebase are open-sourced on:
\url{https://github.com/qiufan319/benchmark_pc_attack.git}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_Q/0/1/0/all/0/1&quot;&gt;Qiufan Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1&quot;&gt;Cong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1&quot;&gt;Shengshan Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yingying Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Lichao Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03152">
<title>AI-GOMS: Large AI-Driven Global Ocean Modeling System. (arXiv:2308.03152v2 [physics.ao-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03152</link>
<description rdf:parseType="Literal">&lt;p&gt;Ocean modeling is a powerful tool for simulating the physical, chemical, and
biological processes of the ocean, which is the foundation for marine science
research and operational oceanography. Modern numerical ocean modeling mainly
consists of governing equations and numerical algorithms. Nonlinear
instability, computational expense, low reusability efficiency and high
coupling costs have gradually become the main bottlenecks for the further
development of numerical ocean modeling. Recently, artificial
intelligence-based modeling in scientific computing has shown revolutionary
potential for digital twins and scientific simulations, but the bottlenecks of
numerical ocean modeling have not been further solved. Here, we present
AI-GOMS, a large AI-driven global ocean modeling system, for accurate and
efficient global ocean daily prediction. AI-GOMS consists of a backbone model
with the Fourier-based Masked Autoencoder structure for basic ocean variable
prediction and lightweight fine-tuning models incorporating regional
downscaling, wave decoding, and biochemistry coupling modules. AI-GOMS has
achieved the best performance in 30 days of prediction for the global ocean
basic variables with 15 depth layers at 1/4{\deg} spatial resolution. Beyond
the good performance in statistical metrics, AI-GOMS realizes the simulation of
mesoscale eddies in the Kuroshio region at 1/12{\deg} spatial resolution and
ocean stratification in the tropical Pacific Ocean. AI-GOMS provides a new
backbone-downstream paradigm for Earth system modeling, which makes the system
transferable, scalable and reusable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Xiong_W/0/1/0/all/0/1&quot;&gt;Wei Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Xiang_Y/0/1/0/all/0/1&quot;&gt;Yanfei Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Shuyi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yuze Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ma_M/0/1/0/all/0/1&quot;&gt;Muyuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xiaomeng Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03382">
<title>Enhancing Nucleus Segmentation with HARU-Net: A Hybrid Attention Based Residual U-Blocks Network. (arXiv:2308.03382v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03382</link>
<description rdf:parseType="Literal">&lt;p&gt;Nucleus image segmentation is a crucial step in the analysis, pathological
diagnosis, and classification, which heavily relies on the quality of nucleus
segmentation. However, the complexity of issues such as variations in nucleus
size, blurred nucleus contours, uneven staining, cell clustering, and
overlapping cells poses significant challenges. Current methods for nucleus
segmentation primarily rely on nuclear morphology or contour-based approaches.
Nuclear morphology-based methods exhibit limited generalization ability and
struggle to effectively predict irregular-shaped nuclei, while contour-based
extraction methods face challenges in accurately segmenting overlapping nuclei.
To address the aforementioned issues, we propose a dual-branch network using
hybrid attention based residual U-blocks for nucleus instance segmentation. The
network simultaneously predicts target information and target contours.
Additionally, we introduce a post-processing method that combines the target
information and target contours to distinguish overlapping nuclei and generate
an instance segmentation image. Within the network, we propose a context fusion
block (CF-block) that effectively extracts and merges contextual information
from the network. Extensive quantitative evaluations are conducted to assess
the performance of our method. Experimental results demonstrate the superior
performance of the proposed method compared to state-of-the-art approaches on
the BNS, MoNuSeg, CoNSeg, and CPM-17 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Junzhou Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qian Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yulin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Qian_L/0/1/0/all/0/1&quot;&gt;Linyi Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chengyuan Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03712">
<title>Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience. (arXiv:2308.03712v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03712</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper asks whether current self-supervised learning methods, if
sufficiently scaled up, would be able to reach human-level visual object
recognition capabilities with the same type and amount of visual experience
humans learn from. Previous work on this question only considered the scaling
of data size. Here, we consider the simultaneous scaling of data size, model
size, and image resolution. We perform a scaling experiment with vision
transformers up to 633M parameters in size (ViT-H/14) trained with up to 5K
hours of human-like video data (long, continuous, mostly egocentric videos)
with image resolutions of up to 476x476 pixels. The efficiency of masked
autoencoders (MAEs) as a self-supervised learning algorithm makes it possible
to run this scaling experiment on an unassuming academic budget. We find that
it is feasible to reach human-level object recognition capacity at sub-human
scales of model size, data size, and image size, if these factors are scaled up
simultaneously. To give a concrete example, we estimate that a 2.5B parameter
ViT model trained with 20K hours (2.3 years) of human-like video data with a
spatial resolution of 952x952 pixels should be able to reach roughly
human-level accuracy on ImageNet. Human-level competence is thus achievable for
a fundamental perceptual capability from human-like perceptual experience
(human-like in both amount and type) with extremely generic learning algorithms
and architectures and without any substantive inductive biases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orhan_A/0/1/0/all/0/1&quot;&gt;A. Emin Orhan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04365">
<title>SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2308.04365</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference is a crucial goal of science, enabling researchers to arrive
at meaningful conclusions regarding the predictions of hypothetical
interventions using observational data. Path models, Structural Equation Models
(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to
unambiguously specify assumptions regarding the causal structure underlying a
phenomenon. Unlike DAGs, which make very few assumptions about the functional
and parametric form, SEM assumes linearity. This can result in functional
misspecification which prevents researchers from undertaking reliable effect
size estimation. In contrast, we propose Super Learner Equation Modeling, a
path modeling technique integrating machine learning Super Learner ensembles.
We empirically demonstrate its ability to provide consistent and unbiased
estimates of causal effects, its competitive performance for linear models when
compared with SEM, and highlight its superiority over SEM when dealing with
non-linear relationships. We provide open-source code, and a tutorial notebook
with example usage, accentuating the easy-to-use nature of the method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vowels_M/0/1/0/all/0/1&quot;&gt;Matthew J. Vowels&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04704">
<title>A Feature Set of Small Size for the PDF Malware Detection. (arXiv:2308.04704v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2308.04704</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning (ML)-based malware detection systems are becoming
increasingly important as malware threats increase and get more sophisticated.
PDF files are often used as vectors for phishing attacks because they are
widely regarded as trustworthy data resources, and are accessible across
different platforms. Therefore, researchers have developed many different PDF
malware detection methods. Performance in detecting PDF malware is greatly
influenced by feature selection. In this research, we propose a small features
set that don&apos;t require too much domain knowledge of the PDF file. We evaluate
proposed features with six different machine learning models. We report the
best accuracy of 99.75% when using Random Forest model. Our proposed feature
set, which consists of just 12 features, is one of the most conciseness in the
field of PDF malware detection. Despite its modest size, we obtain comparable
results to state-of-the-art that employ a much larger set of features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Ran Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1&quot;&gt;Charles Nicholas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05011">
<title>Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories. (arXiv:2308.05011v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.05011</link>
<description rdf:parseType="Literal">&lt;p&gt;With the increasing volume of astronomical data generated by modern survey
telescopes, automated pipelines and machine learning techniques have become
crucial for analyzing and extracting knowledge from these datasets. Anomaly
detection, i.e. the task of identifying irregular or unexpected patterns in the
data, is a complex challenge in astronomy. In this paper, we propose
Multi-Class Deep Support Vector Data Description (MCDSVDD), an extension of the
state-of-the-art anomaly detection algorithm One-Class Deep SVDD, specifically
designed to handle different inlier categories with distinct data
distributions. MCDSVDD uses a neural network to map the data into hyperspheres,
where each hypersphere represents a specific inlier category. The distance of
each sample from the centers of these hyperspheres determines the anomaly
score. We evaluate the effectiveness of MCDSVDD by comparing its performance
with several anomaly detection algorithms on a large dataset of astronomical
light-curves obtained from the Zwicky Transient Facility. Our results
demonstrate the efficacy of MCDSVDD in detecting anomalous sources while
leveraging the presence of different inlier categories. The code and the data
needed to reproduce our results are publicly available at
https://github.com/mperezcarrasco/AnomalyALeRCE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Carrasco_M/0/1/0/all/0/1&quot;&gt;Manuel P&amp;#xe9;rez-Carrasco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cabrera_Vives_G/0/1/0/all/0/1&quot;&gt;Guillermo Cabrera-Vives&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Garcia_L/0/1/0/all/0/1&quot;&gt;Lorena Hern&amp;#xe1;ndez-Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forster_F/0/1/0/all/0/1&quot;&gt;Francisco Forster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_Saez_P/0/1/0/all/0/1&quot;&gt;Paula S&amp;#xe1;nchez-S&amp;#xe1;ez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arancibia_A/0/1/0/all/0/1&quot;&gt;Alejandra Mu&amp;#xf1;oz Arancibia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Astorga_N/0/1/0/all/0/1&quot;&gt;Nicol&amp;#xe1;s Astorga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bauer_F/0/1/0/all/0/1&quot;&gt;Franz Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bayo_A/0/1/0/all/0/1&quot;&gt;Amelia Bayo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cadiz_Leyton_M/0/1/0/all/0/1&quot;&gt;Martina C&amp;#xe1;diz-Leyton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catelan_M/0/1/0/all/0/1&quot;&gt;Marcio Catelan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19069">
<title>Multi-source adversarial transfer learning for ultrasound image segmentation with limited similarity. (arXiv:2305.19069v1 [eess.IV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2305.19069</link>
<description rdf:parseType="Literal">&lt;p&gt;Lesion segmentation of ultrasound medical images based on deep learning
techniques is a widely used method for diagnosing diseases. Although there is a
large amount of ultrasound image data in medical centers and other places,
labeled ultrasound datasets are a scarce resource, and it is likely that no
datasets are available for new tissues/organs. Transfer learning provides the
possibility to solve this problem, but there are too many features in natural
images that are not related to the target domain. As a source domain, redundant
features that are not conducive to the task will be extracted. Migration
between ultrasound images can avoid this problem, but there are few types of
public datasets, and it is difficult to find sufficiently similar source
domains. Compared with natural images, ultrasound images have less information,
and there are fewer transferable features between different ultrasound images,
which may cause negative transfer. To this end, a multi-source adversarial
transfer learning network for ultrasound image segmentation is proposed.
Specifically, to address the lack of annotations, the idea of adversarial
transfer learning is used to adaptively extract common features between a
certain pair of source and target domains, which provides the possibility to
utilize unlabeled ultrasound data. To alleviate the lack of knowledge in a
single source domain, multi-source transfer learning is adopted to fuse
knowledge from multiple source domains. In order to ensure the effectiveness of
the fusion and maximize the use of precious data, a multi-source domain
independent strategy is also proposed to improve the estimation of the target
domain data distribution, which further increases the learning ability of the
multi-source adversarial migration learning network in multiple domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yifu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongru Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_T/0/1/0/all/0/1&quot;&gt;Tao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tao_R/0/1/0/all/0/1&quot;&gt;Rui Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhengyuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shi_S/0/1/0/all/0/1&quot;&gt;Shimeng Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiansong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ma_N/0/1/0/all/0/1&quot;&gt;Ning Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Feng_W/0/1/0/all/0/1&quot;&gt;Wujin Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhanhu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinyu Zhang&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>