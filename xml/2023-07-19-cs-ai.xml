<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.AI updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Artificial Intelligence (cs.AI) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-07-18T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Artificial Intelligence</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08721" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08766" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08767" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08775" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08794" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08809" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08810" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08816" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08849" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08859" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08873" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08876" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08897" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08920" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08925" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08930" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08933" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08962" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08964" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08974" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08985" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08987" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08988" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09004" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09009" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09014" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09036" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09042" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09047" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09048" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09050" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09051" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09059" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09072" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09099" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09114" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09132" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09136" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09141" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09151" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09166" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09168" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09177" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09193" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09209" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09218" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09225" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09244" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09249" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09274" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09288" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09296" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09320" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09321" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09332" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09342" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09361" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09364" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09375" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09423" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09426" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09435" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09437" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09476" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.09477" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.10278" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.07082" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.09920" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.01426" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.02405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.03181" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.13066" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.13816" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.00270" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.09775" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.02401" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.05118" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.02689" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.03209" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.05560" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.07617" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.09378" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.11997" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12421" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13115" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.16044" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.05439" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.09662" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.15656" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.15788" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00497" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02839" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.03109" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.04550" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.04964" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.07250" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.07754" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.07909" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08087" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08481" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08533" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08671" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.13697" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.10224" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2307.08721">
<title>Where Did the President Visit Last Week? Detecting Celebrity Trips from News Articles. (arXiv:2307.08721v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.08721</link>
<description rdf:parseType="Literal">&lt;p&gt;Celebrities&apos; whereabouts are of pervasive importance. For instance, where
politicians go, how often they visit, and who they meet, come with profound
geopolitical and economic implications. Although news articles contain travel
information of celebrities, it is not possible to perform large-scale and
network-wise analysis due to the lack of automatic itinerary detection tools.
To design such tools, we have to overcome difficulties from the heterogeneity
among news articles: 1)One single article can be noisy, with irrelevant people
and locations, especially when the articles are long. 2)Though it may be
helpful if we consider multiple articles together to determine a particular
trip, the key semantics are still scattered across different articles
intertwined with various noises, making it hard to aggregate them effectively.
3)Over 20% of the articles refer to the celebrities&apos; trips indirectly, instead
of using the exact celebrity names or location names, leading to large portions
of trips escaping regular detecting algorithms. We model text content across
articles related to each candidate location as a graph to better associate
essential information and cancel out the noises. Besides, we design a special
pooling layer based on attention mechanism and node similarity, reducing
irrelevant information from longer articles. To make up the missing information
resulted from indirect mentions, we construct knowledge sub-graphs for named
entities (person, organization, facility, etc.). Specifically, we dynamically
update embeddings of event entities like the G7 summit from news descriptions
since the properties (date and location) of the event change each time, which
is not captured by the pre-trained event representations. The proposed CeleTrip
jointly trains these modules, which outperforms all baseline models and
achieves 82.53% in the F1 metric.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1&quot;&gt;Kai Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Ying Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1&quot;&gt;Shuai Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_Z/0/1/0/all/0/1&quot;&gt;Zhaoru Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haipeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08766">
<title>Quality Assessment of Photoplethysmography Signals For Cardiovascular Biomarkers Monitoring Using Wearable Devices. (arXiv:2307.08766v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.08766</link>
<description rdf:parseType="Literal">&lt;p&gt;Photoplethysmography (PPG) is a non-invasive technology that measures changes
in blood volume in the microvascular bed of tissue. It is commonly used in
medical devices such as pulse oximeters and wrist worn heart rate monitors to
monitor cardiovascular hemodynamics. PPG allows for the assessment of
parameters (e.g., heart rate, pulse waveform, and peripheral perfusion) that
can indicate conditions such as vasoconstriction or vasodilation, and provides
information about microvascular blood flow, making it a valuable tool for
monitoring cardiovascular health. However, PPG is subject to a number of
sources of variations that can impact its accuracy and reliability, especially
when using a wearable device for continuous monitoring, such as motion
artifacts, skin pigmentation, and vasomotion. In this study, we extracted 27
statistical features from the PPG signal for training machine-learning models
based on gradient boosting (XGBoost and CatBoost) and Random Forest (RF)
algorithms to assess quality of PPG signals that were labeled as good or poor
quality. We used the PPG time series from a publicly available dataset and
evaluated the algorithm s performance using Sensitivity (Se), Positive
Predicted Value (PPV), and F1-score (F1) metrics. Our model achieved Se, PPV,
and F1-score of 94.4, 95.6, and 95.0 for XGBoost, 94.7, 95.9, and 95.3 for
CatBoost, and 93.7, 91.3 and 92.5 for RF, respectively. Our findings are
comparable to state-of-the-art reported in the literature but using a much
simpler model, indicating that ML models are promising for developing remote,
non-invasive, and continuous measurement devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dias_F/0/1/0/all/0/1&quot;&gt;Felipe M. Dias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toledo_M/0/1/0/all/0/1&quot;&gt;Marcelo A. F. Toledo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardenas_D/0/1/0/all/0/1&quot;&gt;Diego A. C. Cardenas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Almeida_D/0/1/0/all/0/1&quot;&gt;Douglas A. Almeida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveira_F/0/1/0/all/0/1&quot;&gt;Filipe A. C. Oliveira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_E/0/1/0/all/0/1&quot;&gt;Estela Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krieger_J/0/1/0/all/0/1&quot;&gt;Jose E. Krieger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutierrez_M/0/1/0/all/0/1&quot;&gt;Marco A. Gutierrez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08767">
<title>A mixed policy to improve performance of language models on math problems. (arXiv:2307.08767v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.08767</link>
<description rdf:parseType="Literal">&lt;p&gt;When to solve math problems, most language models take a sampling strategy to
predict next word according conditional probabilities. In the math reasoning
step, it may generate wrong answer. Considering math problems are
deterministic, we propose a mixed policy exploration approach to solve math
problems with reinforcement learning. In peculiar, we propose a two level token
exploration policy: the abstract level explores next token with probability and
the second level is deterministic. Specifically, the abstract level policy will
decide whether the token is operator or operand with probability sampling,
while the second level is deterministic to select next token with the highest
score in a greedy way. We test our method on GSM8K dataset with GPT-2 model,
and demonstrate more than $2\%$ performance gain. Our implementation is
available at https://github.com/vividitytech/math_lm_rl.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1&quot;&gt;Gang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08774">
<title>Reflections from the Workshop on AI-Assisted Decision Making for Conservation. (arXiv:2307.08774v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.08774</link>
<description rdf:parseType="Literal">&lt;p&gt;In this white paper, we synthesize key points made during presentations and
discussions from the AI-Assisted Decision Making for Conservation workshop,
hosted by the Center for Research on Computation and Society at Harvard
University on October 20-21, 2022. We identify key open research questions in
resource allocation, planning, and interventions for biodiversity conservation,
highlighting conservation challenges that not only require AI solutions, but
also require novel methodological advances. In addition to providing a summary
of the workshop talks and discussions, we hope this document serves as a
call-to-action to orient the expansion of algorithmic decision-making
approaches to prioritize real-world conservation challenges, through
collaborative efforts of ecologists, conservation decision-makers, and AI
researchers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1&quot;&gt;Lily Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rolf_E/0/1/0/all/0/1&quot;&gt;Esther Rolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beery_S/0/1/0/all/0/1&quot;&gt;Sara Beery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bennett_J/0/1/0/all/0/1&quot;&gt;Joseph R. Bennett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berger_Wolf_T/0/1/0/all/0/1&quot;&gt;Tanya Berger-Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Birch_T/0/1/0/all/0/1&quot;&gt;Tanya Birch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bondi_Kelly_E/0/1/0/all/0/1&quot;&gt;Elizabeth Bondi-Kelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brashares_J/0/1/0/all/0/1&quot;&gt;Justin Brashares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chapman_M/0/1/0/all/0/1&quot;&gt;Melissa Chapman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corso_A/0/1/0/all/0/1&quot;&gt;Anthony Corso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davies_A/0/1/0/all/0/1&quot;&gt;Andrew Davies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_N/0/1/0/all/0/1&quot;&gt;Nikhil Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaylard_A/0/1/0/all/0/1&quot;&gt;Angela Gaylard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heilmayr_R/0/1/0/all/0/1&quot;&gt;Robert Heilmayr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kerner_H/0/1/0/all/0/1&quot;&gt;Hannah Kerner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klemmer_K/0/1/0/all/0/1&quot;&gt;Konstantin Klemmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vipin Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1&quot;&gt;Lester Mackey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monteleoni_C/0/1/0/all/0/1&quot;&gt;Claire Monteleoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moorcroft_P/0/1/0/all/0/1&quot;&gt;Paul Moorcroft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palmer_J/0/1/0/all/0/1&quot;&gt;Jonathan Palmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perrault_A/0/1/0/all/0/1&quot;&gt;Andrew Perrault&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thau_D/0/1/0/all/0/1&quot;&gt;David Thau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1&quot;&gt;Milind Tambe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08775">
<title>GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution. (arXiv:2307.08775v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.08775</link>
<description rdf:parseType="Literal">&lt;p&gt;Augmenting large language models (LLM) to use external tools enhances their
performance across a variety of tasks. However, prior works over-rely on
task-specific demonstration of tool use that limits their generalizability and
computational cost due to making many calls to large-scale LLMs. We introduce
GEAR, a computationally efficient query-tool grounding algorithm that is
generalizable to various tasks that require tool use while not relying on
task-specific demonstrations. GEAR achieves better efficiency by delegating
tool grounding and execution to small language models (SLM) and LLM,
respectively; while leveraging semantic and pattern-based evaluation at both
question and answer levels for generalizable tool grounding. We evaluate GEAR
on 14 datasets across 6 downstream tasks, demonstrating its strong
generalizability to novel tasks, tools and different SLMs. Despite offering
more efficiency, GEAR achieves higher precision in tool grounding compared to
prior strategies using LLM prompting, thus improving downstream accuracy at a
reduced computational cost. For example, we demonstrate that GEAR-augmented
GPT-J and GPT-3 outperform counterpart tool-augmented baselines because of
better tool use.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yining Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Haoping Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1&quot;&gt;Daniel Khashabi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08794">
<title>Non-Stationary Policy Learning for Multi-Timescale Multi-Agent Reinforcement Learning. (arXiv:2307.08794v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.08794</link>
<description rdf:parseType="Literal">&lt;p&gt;In multi-timescale multi-agent reinforcement learning (MARL), agents interact
across different timescales. In general, policies for time-dependent behaviors,
such as those induced by multiple timescales, are non-stationary. Learning
non-stationary policies is challenging and typically requires sophisticated or
inefficient algorithms. Motivated by the prevalence of this control problem in
real-world complex systems, we introduce a simple framework for learning
non-stationary policies for multi-timescale MARL. Our approach uses available
information about agent timescales to define a periodic time encoding. In
detail, we theoretically demonstrate that the effects of non-stationarity
introduced by multiple timescales can be learned by a periodic multi-agent
policy. To learn such policies, we propose a policy gradient algorithm that
parameterizes the actor and critic with phase-functioned neural networks, which
provide an inductive bias for periodicity. The framework&apos;s ability to
effectively learn multi-timescale policies is validated on a gridworld and
building energy management environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emami_P/0/1/0/all/0/1&quot;&gt;Patrick Emami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiangyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biagioni_D/0/1/0/all/0/1&quot;&gt;David Biagioni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamzam_A/0/1/0/all/0/1&quot;&gt;Ahmed S. Zamzam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08809">
<title>Local or Global: Selective Knowledge Assimilation for Federated Learning with Limited Labels. (arXiv:2307.08809v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.08809</link>
<description rdf:parseType="Literal">&lt;p&gt;Many existing FL methods assume clients with fully-labeled data, while in
realistic settings, clients have limited labels due to the expensive and
laborious process of labeling. Limited labeled local data of the clients often
leads to their local model having poor generalization abilities to their larger
unlabeled local data, such as having class-distribution mismatch with the
unlabeled data. As a result, clients may instead look to benefit from the
global model trained across clients to leverage their unlabeled data, but this
also becomes difficult due to data heterogeneity across clients. In our work,
we propose FedLabel where clients selectively choose the local or global model
to pseudo-label their unlabeled data depending on which is more of an expert of
the data. We further utilize both the local and global models&apos; knowledge via
global-local consistency regularization which minimizes the divergence between
the two models&apos; outputs when they have identical pseudo-labels for the
unlabeled data. Unlike other semi-supervised FL baselines, our method does not
require additional experts other than the local or global model, nor require
additional parameters to be communicated. We also do not assume any
server-labeled data or fully labeled clients. For both cross-device and
cross-silo settings, we show that FedLabel outperforms other semi-supervised FL
baselines by $8$-$24\%$, and even outperforms standard fully supervised FL
baselines ($100\%$ labeled data) with only $5$-$20\%$ of labeled data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1&quot;&gt;Yae Jee Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_G/0/1/0/all/0/1&quot;&gt;Gauri Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dimitriadis_D/0/1/0/all/0/1&quot;&gt;Dimitrios Dimitriadis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08810">
<title>Operator Guidance Informed by AI-Augmented Simulations. (arXiv:2307.08810v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.08810</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper will present a multi-fidelity, data-adaptive approach with a Long
Short-Term Memory (LSTM) neural network to estimate ship response statistics in
bimodal, bidirectional seas. The study will employ a fast low-fidelity,
volume-based tool SimpleCode and a higher-fidelity tool known as the Large
Amplitude Motion Program (LAMP). SimpleCode and LAMP data were generated by
common bi-modal, bi-directional sea conditions in the North Atlantic as
training data. After training an LSTM network with LAMP ship motion response
data, a sample route was traversed and randomly sampled historical weather was
input into SimpleCode and the LSTM network, and compared against the higher
fidelity results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_S/0/1/0/all/0/1&quot;&gt;Samuel J. Edwards&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_M/0/1/0/all/0/1&quot;&gt;Michael Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08816">
<title>Towards Accelerating Benders Decomposition via Reinforcement Learning Surrogate Models. (arXiv:2307.08816v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.08816</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic optimization (SO) attempts to offer optimal decisions in the
presence of uncertainty. Often, the classical formulation of these problems
becomes intractable due to (a) the number of scenarios required to capture the
uncertainty and (b) the discrete nature of real-world planning problems. To
overcome these tractability issues, practitioners turn to decomposition methods
that divide the problem into smaller, more tractable sub-problems. The focal
decomposition method of this paper is Benders decomposition (BD), which
decomposes stochastic optimization problems on the basis of scenario
independence. In this paper we propose a method of accelerating BD with the aid
of a surrogate model in place of an NP-hard integer master problem. Through the
acceleration method we observe 30% faster average convergence when compared to
other accelerated BD implementations. We introduce a reinforcement learning
agent as a surrogate and demonstrate how it can be used to solve a stochastic
inventory management problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mak_S/0/1/0/all/0/1&quot;&gt;Stephen Mak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mana_K/0/1/0/all/0/1&quot;&gt;Kyle Mana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zehtabi_P/0/1/0/all/0/1&quot;&gt;Parisa Zehtabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cashmore_M/0/1/0/all/0/1&quot;&gt;Michael Cashmore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1&quot;&gt;Daniele Magazzeni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1&quot;&gt;Manuela Veloso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08849">
<title>Autoregressive Diffusion Model for Graph Generation. (arXiv:2307.08849v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.08849</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion-based graph generative models have recently obtained promising
results for graph generation. However, existing diffusion-based graph
generative models are mostly one-shot generative models that apply Gaussian
diffusion in the dequantized adjacency matrix space. Such a strategy can suffer
from difficulty in model training, slow sampling speed, and incapability of
incorporating constraints. We propose an \emph{autoregressive diffusion} model
for graph generation. Unlike existing methods, we define a node-absorbing
diffusion process that operates directly in the discrete graph space. For
forward diffusion, we design a \emph{diffusion ordering network}, which learns
a data-dependent node absorbing ordering from graph topology. For reverse
generation, we design a \emph{denoising network} that uses the reverse node
ordering to efficiently reconstruct the graph by predicting the node type of
the new node and its edges with previously denoised nodes at a time. Based on
the permutation invariance of graph, we show that the two networks can be
jointly trained by optimizing a simple lower bound of data likelihood. Our
experiments on six diverse generic graph datasets and two molecule datasets
show that our model achieves better or comparable generation performance with
previous state-of-the-art, and meanwhile enjoys fast generation speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1&quot;&gt;Lingkai Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1&quot;&gt;Jiaming Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Haotian Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1&quot;&gt;Yuchen Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1&quot;&gt;B. Aditya Prakash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08859">
<title>Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach. (arXiv:2307.08859v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.08859</link>
<description rdf:parseType="Literal">&lt;p&gt;A curriculum is a planned sequence of learning materials and an effective one
can make learning efficient and effective for both humans and machines. Recent
studies developed effective data-driven curriculum learning approaches for
training graph neural networks in language applications. However, existing
curriculum learning approaches often employ a single criterion of difficulty in
their training paradigms. In this paper, we propose a new perspective on
curriculum learning by introducing a novel approach that builds on graph
complexity formalisms (as difficulty criteria) and model competence during
training. The model consists of a scheduling scheme which derives effective
curricula by accounting for different views of sample difficulty and model
competence during training. The proposed solution advances existing research in
curriculum learning for graph neural networks with the ability to incorporate a
fine-grained spectrum of graph difficulty criteria in their training paradigms.
Experimental results on real-world link prediction and node classification
tasks illustrate the effectiveness of the proposed approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vakil_N/0/1/0/all/0/1&quot;&gt;Nidhi Vakil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amiri_H/0/1/0/all/0/1&quot;&gt;Hadi Amiri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08873">
<title>An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient. (arXiv:2307.08873v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.08873</link>
<description rdf:parseType="Literal">&lt;p&gt;Restricting the variance of a policy&apos;s return is a popular choice in
risk-averse Reinforcement Learning (RL) due to its clear mathematical
definition and easy interpretability. Traditional methods directly restrict the
total return variance. Recent methods restrict the per-step reward variance as
a proxy. We thoroughly examine the limitations of these variance-based methods,
such as sensitivity to numerical scale and hindering of policy learning, and
propose to use an alternative risk measure, Gini deviation, as a substitute. We
study various properties of this new risk measure and derive a policy gradient
algorithm to minimize it. Empirical evaluation in domains where risk-aversion
can be clearly defined, shows that our algorithm can mitigate the limitations
of variance-based risk measures and achieves high return with low risk in terms
of variance and Gini deviation when others fail to learn a reasonable policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yudong Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guiliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1&quot;&gt;Pascal Poupart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yangchen Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08876">
<title>AI for the Generation and Testing of Ideas Towards an AI Supported Knowledge Development Environment. (arXiv:2307.08876v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.08876</link>
<description rdf:parseType="Literal">&lt;p&gt;New systems employ Machine Learning to sift through large knowledge sources,
creating flexible Large Language Models. These models discern context and
predict sequential information in various communication forms. Generative AI,
leveraging Transformers, generates textual or visual outputs mimicking human
responses. It proposes one or multiple contextually feasible solutions for a
user to contemplate. However, generative AI does not currently support
traceability of ideas, a useful feature provided by search engines indicating
origin of information. The narrative style of generative AI has gained positive
reception. People learn from stories. Yet, early ChatGPT efforts had difficulty
with truth, reference, calculations, and aspects like accurate maps. Current
capabilities of referencing locations and linking to apps seem to be better
catered by the link-centric search methods we&apos;ve used for two decades.
Deploying truly believable solutions extends beyond simulating contextual
relevance as done by generative AI. Combining the creativity of generative AI
with the provenance of internet sources in hybrid scenarios could enhance
internet usage. Generative AI, viewed as drafts, stimulates thinking, offering
alternative ideas for final versions or actions. Scenarios for information
requests are considered. We discuss how generative AI can boost idea generation
by eliminating human bias. We also describe how search can verify facts, logic,
and context. The user evaluates these generated ideas for selection and usage.
This paper introduces a system for knowledge workers, Generate And Search Test,
enabling individuals to efficiently create solutions previously requiring top
collaborations of experts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Selker_T/0/1/0/all/0/1&quot;&gt;Ted Selker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08897">
<title>Basal-Bolus Advisor for Type 1 Diabetes (T1D) Patients Using Multi-Agent Reinforcement Learning (RL) Methodology. (arXiv:2307.08897v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.08897</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel multi-agent reinforcement learning (RL) approach
for personalized glucose control in individuals with type 1 diabetes (T1D). The
method employs a closed-loop system consisting of a blood glucose (BG)
metabolic model and a multi-agent soft actor-critic RL model acting as the
basal-bolus advisor. Performance evaluation is conducted in three scenarios,
comparing the RL agents to conventional therapy. Evaluation metrics include
glucose levels (minimum, maximum, and mean), time spent in different BG ranges,
and average daily bolus and basal insulin dosages. Results demonstrate that the
RL-based basal-bolus advisor significantly improves glucose control, reducing
glycemic variability and increasing time spent within the target range (70-180
mg/dL). Hypoglycemia events are effectively prevented, and severe hyperglycemia
events are reduced. The RL approach also leads to a statistically significant
reduction in average daily basal insulin dosage compared to conventional
therapy. These findings highlight the effectiveness of the multi-agent RL
approach in achieving better glucose control and mitigating the risk of severe
hyperglycemia in individuals with T1D.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jalolia_M/0/1/0/all/0/1&quot;&gt;Mehrad Jalolia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cescon_M/0/1/0/all/0/1&quot;&gt;Marzia Cescon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08920">
<title>Continuous-Time Reinforcement Learning: New Design Algorithms with Theoretical Insights and Performance Guarantees. (arXiv:2307.08920v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2307.08920</link>
<description rdf:parseType="Literal">&lt;p&gt;Continuous-time nonlinear optimal control problems hold great promise in
real-world applications. After decades of development, reinforcement learning
(RL) has achieved some of the greatest successes as a general nonlinear control
design method. However, a recent comprehensive analysis of state-of-the-art
continuous-time RL (CT-RL) methods, namely, adaptive dynamic programming
(ADP)-based CT-RL algorithms, reveals they face significant design challenges
due to their complexity, numerical conditioning, and dimensional scaling
issues. Despite advanced theoretical results, existing ADP CT-RL synthesis
methods are inadequate in solving even small, academic problems. The goal of
this work is thus to introduce a suite of new CT-RL algorithms for control of
affine nonlinear systems. Our design approach relies on two important factors.
First, our methods are applicable to physical systems that can be partitioned
into smaller subproblems. This constructive consideration results in reduced
dimensionality and greatly improved intuitiveness of design. Second, we
introduce a new excitation framework to improve persistence of excitation (PE)
and numerical conditioning performance via classical input/output insights.
Such a design-centric approach is the first of its kind in the ADP CT-RL
community. In this paper, we progressively introduce a suite of (decentralized)
excitable integral reinforcement learning (EIRL) algorithms. We provide
convergence and closed-loop stability guarantees, and we demonstrate these
guarantees on a significant application problem of controlling an unstable,
nonminimum phase hypersonic vehicle (HSV).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wallace_B/0/1/0/all/0/1&quot;&gt;Brent A. Wallace&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Si_J/0/1/0/all/0/1&quot;&gt;Jennie Si&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08925">
<title>Federated Large Language Model: A Position Paper. (arXiv:2307.08925v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.08925</link>
<description rdf:parseType="Literal">&lt;p&gt;Large scale language models (LLM) have received significant attention and
found diverse applications across various domains, but their development
encounters challenges in real-world scenarios. These challenges arise due to
the scarcity of public domain data availability and the need to maintain
privacy with respect to private domain data. To address these issues, federated
learning (FL) has emerged as a promising technology that enables collaborative
training of shared models while preserving decentralized data. We propose the
concept of federated LLM, which comprises three key components, i.e., federated
LLM pre-training, federated LLM fine-tuning, and federated LLM prompt
engineering. For each component, we discuss its advantage over traditional LLM
training methods and propose specific engineering strategies for
implementation. Furthermore, we explore the novel challenges introduced by the
integration of FL and LLM. We analyze existing solutions and identify potential
obstacles faced by these solutions within the context of federated LLM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chaochao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1&quot;&gt;Xiaohua Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1&quot;&gt;Jianwei Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1&quot;&gt;Xiaolin Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08930">
<title>Unsupervised Deep Graph Matching Based on Cycle Consistency. (arXiv:2307.08930v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.08930</link>
<description rdf:parseType="Literal">&lt;p&gt;We contribute to the sparsely populated area of unsupervised deep graph
matching with application to keypoint matching in images. Contrary to the
standard \emph{supervised} approach, our method does not require ground truth
correspondences between keypoint pairs. Instead, it is self-supervised by
enforcing consistency of matchings between images of the same object category.
As the matching and the consistency loss are discrete, their derivatives cannot
be straightforwardly used for learning. We address this issue in a principled
way by building our method upon the recent results on black-box differentiation
of combinatorial solvers. This makes our method exceptionally flexible, as it
is compatible with arbitrary network architectures and combinatorial solvers.
Our experimental evaluation suggests that our technique sets a new
state-of-the-art for unsupervised graph matching.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tourani_S/0/1/0/all/0/1&quot;&gt;Siddharth Tourani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rother_C/0/1/0/all/0/1&quot;&gt;Carsten Rother&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Muhammad Haris Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savchynskkyy_B/0/1/0/all/0/1&quot;&gt;Bogdan Savchynskkyy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08933">
<title>IxDRL: A Novel Explainable Deep Reinforcement Learning Toolkit based on Analyses of Interestingness. (arXiv:2307.08933v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.08933</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, advances in deep learning have resulted in a plethora of
successes in the use of reinforcement learning (RL) to solve complex sequential
decision tasks with high-dimensional inputs. However, existing systems lack the
necessary mechanisms to provide humans with a holistic view of their
competence, presenting an impediment to their adoption, particularly in
critical applications where the decisions an agent makes can have significant
consequences. Yet, existing RL-based systems are essentially competency-unaware
in that they lack the necessary interpretation mechanisms to allow human
operators to have an insightful, holistic view of their competency. Towards
more explainable Deep RL (xDRL), we propose a new framework based on analyses
of interestingness. Our tool provides various measures of RL agent competence
stemming from interestingness analysis and is applicable to a wide range of RL
algorithms, natively supporting the popular RLLib toolkit. We showcase the use
of our framework by applying the proposed pipeline in a set of scenarios of
varying complexity. We empirically assess the capability of the approach in
identifying agent behavior patterns and competency-controlling conditions, and
the task elements mostly responsible for an agent&apos;s competence, based on global
and local analyses of interestingness. Overall, we show that our framework can
provide agent designers with insights about RL agent competence, both their
capabilities and limitations, enabling more informed decisions about
interventions, additional training, and other interactions in collaborative
human-machine settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sequeira_P/0/1/0/all/0/1&quot;&gt;Pedro Sequeira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gervasio_M/0/1/0/all/0/1&quot;&gt;Melinda Gervasio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08944">
<title>Siamese Networks for Weakly Supervised Human Activity Recognition. (arXiv:2307.08944v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2307.08944</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has been successfully applied to human activity recognition.
However, training deep neural networks requires explicitly labeled data which
is difficult to acquire. In this paper, we present a model with multiple
siamese networks that are trained by using only the information about the
similarity between pairs of data samples without knowing the explicit labels.
The trained model maps the activity data samples into fixed size representation
vectors such that the distance between the vectors in the representation space
approximates the similarity of the data samples in the input space. Thus, the
trained model can work as a metric for a wide range of different clustering
algorithms. The training process minimizes a similarity loss function that
forces the distance metric to be small for pairs of samples from the same kind
of activity, and large for pairs of samples from different kinds of activities.
We evaluate the model on three datasets to verify its effectiveness in
segmentation and recognition of continuous human activity sequences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_T/0/1/0/all/0/1&quot;&gt;Taoran Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huber_M/0/1/0/all/0/1&quot;&gt;Manfred Huber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08962">
<title>REX: Rapid Exploration and eXploitation for AI Agents. (arXiv:2307.08962v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.08962</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose an enhanced approach for Rapid Exploration and
eXploitation for AI Agents called REX. Existing AutoGPT-style techniques have
inherent limitations, such as a heavy reliance on precise descriptions for
decision-making, and the lack of a systematic approach to leverage try-and-fail
procedures akin to traditional Reinforcement Learning (RL). REX introduces an
additional layer of rewards and integrates concepts similar to Upper Confidence
Bound (UCB) scores, leading to more robust and efficient AI agent performance.
This approach has the advantage of enabling the utilization of offline
behaviors from logs and allowing seamless integration with existing foundation
models while it does not require any model fine-tuning. Through comparative
analysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA
Planning(RAP), REX-based methods demonstrate comparable performance and, in
certain cases, even surpass the results achieved by these existing techniques.
Notably, REX-based methods exhibit remarkable reductions in execution time,
enhancing their practical applicability across a diverse set of scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murthy_R/0/1/0/all/0/1&quot;&gt;Rithesh Murthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinecke_S/0/1/0/all/0/1&quot;&gt;Shelby Heinecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niebles_J/0/1/0/all/0/1&quot;&gt;Juan Carlos Niebles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1&quot;&gt;Le Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1&quot;&gt;Weiran Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yihao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokul_A/0/1/0/all/0/1&quot;&gt;Akash Gokul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1&quot;&gt;Devansh Arpit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1&quot;&gt;Ran Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mui_P/0/1/0/all/0/1&quot;&gt;Phil Mui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08964">
<title>Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information. (arXiv:2307.08964v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.08964</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent works in learning-integrated optimization have shown promise in
settings where the optimization problem is only partially observed or where
general-purpose optimizers perform poorly without expert tuning. By learning an
optimizer $\mathbf{g}$ to tackle these challenging problems with $f$ as the
objective, the optimization process can be substantially accelerated by
leveraging past experience. The optimizer can be trained with supervision from
known optimal solutions or implicitly by optimizing the compound function
$f\circ \mathbf{g}$. The implicit approach may not require optimal solutions as
labels and is capable of handling problem uncertainty; however, it is slow to
train and deploy due to frequent calls to optimizer $\mathbf{g}$ during both
training and testing. The training is further challenged by sparse gradients of
$\mathbf{g}$, especially for combinatorial solvers. To address these
challenges, we propose using a smooth and learnable Landscape Surrogate $M$ as
a replacement for $f\circ \mathbf{g}$. This surrogate, learnable by neural
networks, can be computed faster than the solver $\mathbf{g}$, provides dense
and smooth gradients during training, can generalize to unseen optimization
problems, and is efficiently learned via alternating optimization. We test our
approach on both synthetic problems, including shortest path and
multidimensional knapsack, and real-world problems such as portfolio
optimization, achieving comparable or superior objective values compared to
state-of-the-art baselines while reducing the number of calls to $\mathbf{g}$.
Notably, our approach outperforms existing methods for computationally
expensive high-dimensional problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zharmagambetov_A/0/1/0/all/0/1&quot;&gt;Arman Zharmagambetov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1&quot;&gt;Brandon Amos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1&quot;&gt;Aaron Ferber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Taoan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1&quot;&gt;Bistra Dilkina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yuandong Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08974">
<title>Development of the ChatGPT, Generative Artificial Intelligence and Natural Large Language Models for Accountable Reporting and Use (CANGARU) Guidelines. (arXiv:2307.08974v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.08974</link>
<description rdf:parseType="Literal">&lt;p&gt;The swift progress and ubiquitous adoption of Generative AI (GAI), Generative
Pre-trained Transformers (GPTs), and large language models (LLMs) like ChatGPT,
have spurred queries about their ethical application, use, and disclosure in
scholarly research and scientific productions. A few publishers and journals
have recently created their own sets of rules; however, the absence of a
unified approach may lead to a &apos;Babel Tower Effect,&apos; potentially resulting in
confusion rather than desired standardization. In response to this, we present
the ChatGPT, Generative Artificial Intelligence, and Natural Large Language
Models for Accountable Reporting and Use Guidelines (CANGARU) initiative, with
the aim of fostering a cross-disciplinary global inclusive consensus on the
ethical use, disclosure, and proper reporting of GAI/GPT/LLM technologies in
academia. The present protocol consists of four distinct parts: a) an ongoing
systematic review of GAI/GPT/LLM applications to understand the linked ideas,
findings, and reporting standards in scholarly research, and to formulate
guidelines for its use and disclosure, b) a bibliometric analysis of existing
author guidelines in journals that mention GAI/GPT/LLM, with the goal of
evaluating existing guidelines, analyzing the disparity in their
recommendations, and identifying common rules that can be brought into the
Delphi consensus process, c) a Delphi survey to establish agreement on the
items for the guidelines, ensuring principled GAI/GPT/LLM use, disclosure, and
reporting in academia, and d) the subsequent development and dissemination of
the finalized guidelines and their supplementary explanation and elaboration
documents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cacciamani_G/0/1/0/all/0/1&quot;&gt;Giovanni E. Cacciamani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eppler_M/0/1/0/all/0/1&quot;&gt;Michael B. Eppler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganjavi_C/0/1/0/all/0/1&quot;&gt;Conner Ganjavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pekan_A/0/1/0/all/0/1&quot;&gt;Asli Pekan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biedermann_B/0/1/0/all/0/1&quot;&gt;Brett Biedermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collins_G/0/1/0/all/0/1&quot;&gt;Gary S. Collins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gill_I/0/1/0/all/0/1&quot;&gt;Inderbir S. Gill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08985">
<title>PromptCrafter: Crafting Text-to-Image Prompt through Mixed-Initiative Dialogue with LLM. (arXiv:2307.08985v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2307.08985</link>
<description rdf:parseType="Literal">&lt;p&gt;Text-to-image generation model is able to generate images across a diverse
range of subjects and styles based on a single prompt. Recent works have
proposed a variety of interaction methods that help users understand the
capabilities of models and utilize them. However, how to support users to
efficiently explore the model&apos;s capability and to create effective prompts are
still open-ended research questions. In this paper, we present PromptCrafter, a
novel mixed-initiative system that allows step-by-step crafting of
text-to-image prompt. Through the iterative process, users can efficiently
explore the model&apos;s capability, and clarify their intent. PromptCrafter also
supports users to refine prompts by answering various responses to clarifying
questions generated by a Large Language Model. Lastly, users can revert to a
desired step by reviewing the work history. In this workshop paper, we discuss
the design process of PromptCrafter and our plans for follow-up studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baek_S/0/1/0/all/0/1&quot;&gt;Seungho Baek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Im_H/0/1/0/all/0/1&quot;&gt;Hyerin Im&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_J/0/1/0/all/0/1&quot;&gt;Jiseung Ryu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Juhyeong Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1&quot;&gt;Takyeon Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08987">
<title>AI-assisted Improved Service Provisioning for Low-latency XR over 5G NR. (arXiv:2307.08987v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2307.08987</link>
<description rdf:parseType="Literal">&lt;p&gt;Extended Reality (XR) is one of the most important 5G/6G media applications
that will fundamentally transform human interactions. However, ensuring low
latency, high data rate, and reliability to support XR services poses
significant challenges. This letter presents a novel AI-assisted service
provisioning scheme that leverages predicted frames for processing rather than
relying solely on actual frames. This method virtually increases the network
delay budget and consequently improves service provisioning, albeit at the
expense of minor prediction errors. The proposed scheme is validated by
extensive simulations demonstrating a multi-fold increase in supported XR users
and also provides crucial network design insights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laha_M/0/1/0/all/0/1&quot;&gt;Moyukh Laha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1&quot;&gt;Dibbendu Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1&quot;&gt;Sourav Dutta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_G/0/1/0/all/0/1&quot;&gt;Goutam Das&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08988">
<title>EVIL: Evidential Inference Learning for Trustworthy Semi-supervised Medical Image Segmentation. (arXiv:2307.08988v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.08988</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, uncertainty-aware methods have attracted increasing attention in
semi-supervised medical image segmentation. However, current methods usually
suffer from the drawback that it is difficult to balance the computational
cost, estimation accuracy, and theoretical support in a unified framework. To
alleviate this problem, we introduce the Dempster-Shafer Theory of Evidence
(DST) into semi-supervised medical image segmentation, dubbed Evidential
Inference Learning (EVIL). EVIL provides a theoretically guaranteed solution to
infer accurate uncertainty quantification in a single forward pass. Trustworthy
pseudo labels on unlabeled data are generated after uncertainty estimation. The
recently proposed consistency regularization-based training paradigm is adopted
in our framework, which enforces the consistency on the perturbed predictions
to enhance the generalization with few labeled data. Experimental results show
that EVIL achieves competitive performance in comparison with several
state-of-the-art methods on the public dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yingyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Ziyuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Chenyu Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhiwen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1&quot;&gt;Yang Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09004">
<title>Ord2Seq: Regard Ordinal Regression as Label Sequence Prediction. (arXiv:2307.09004v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09004</link>
<description rdf:parseType="Literal">&lt;p&gt;Ordinal regression refers to classifying object instances into ordinal
categories. It has been widely studied in many scenarios, such as medical
disease grading, movie rating, etc. Known methods focused only on learning
inter-class ordinal relationships, but still incur limitations in
distinguishing adjacent categories thus far. In this paper, we propose a simple
sequence prediction framework for ordinal regression called Ord2Seq, which, for
the first time, transforms each ordinal category label into a special label
sequence and thus regards an ordinal regression task as a sequence prediction
process. In this way, we decompose an ordinal regression task into a series of
recursive binary classification steps, so as to subtly distinguish adjacent
categories. Comprehensive experiments show the effectiveness of distinguishing
adjacent categories for performance improvement and our new approach exceeds
state-of-the-art performances in four different scenarios. Codes will be
available upon acceptance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jinhong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yi Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jintai Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tingting Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Danny Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jian Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09009">
<title>How is ChatGPT&apos;s behavior changing over time?. (arXiv:2307.09009v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.09009</link>
<description rdf:parseType="Literal">&lt;p&gt;GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)
services. However, when and how these models are updated over time is opaque.
Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on
four diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous
questions, 3) generating code and 4) visual reasoning. We find that the
performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.
For example, GPT-4 (March 2023) was very good at identifying prime numbers
(accuracy 97.6%) but GPT-4 (June 2023) was very poor on these same questions
(accuracy 2.4%). Interestingly GPT-3.5 (June 2023) was much better than GPT-3.5
(March 2023) in this task. GPT-4 was less willing to answer sensitive questions
in June than in March, and both GPT-4 and GPT-3.5 had more formatting mistakes
in code generation in June than in March. Overall, our findings shows that the
behavior of the same LLM service can change substantially in a relatively short
amount of time, highlighting the need for continuous monitoring of LLM quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lingjiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1&quot;&gt;Matei Zaharia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1&quot;&gt;James Zou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09014">
<title>Exploring acceptance of autonomous vehicle policies using KeyBERT and SNA: Targeting engineering students. (arXiv:2307.09014v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2307.09014</link>
<description rdf:parseType="Literal">&lt;p&gt;This study aims to explore user acceptance of Autonomous Vehicle (AV)
policies with improved text-mining methods. Recently, South Korean policymakers
have viewed Autonomous Driving Car (ADC) and Autonomous Driving Robot (ADR) as
next-generation means of transportation that will reduce the cost of
transporting passengers and goods. They support the construction of V2I and V2V
communication infrastructures for ADC and recognize that ADR is equivalent to
pedestrians to promote its deployment into sidewalks. To fill the gap where
end-user acceptance of these policies is not well considered, this study
applied two text-mining methods to the comments of graduate students in the
fields of Industrial, Mechanical, and Electronics-Electrical-Computer. One is
the Co-occurrence Network Analysis (CNA) based on TF-IWF and Dice coefficient,
and the other is the Contextual Semantic Network Analysis (C-SNA) based on both
KeyBERT, which extracts keywords that contextually represent the comments, and
double cosine similarity. The reason for comparing these approaches is to
balance interest not only in the implications for the AV policies but also in
the need to apply quality text mining to this research domain. Significantly,
the limitation of frequency-based text mining, which does not reflect textual
context, and the trade-off of adjusting thresholds in Semantic Network Analysis
(SNA) were considered. As the results of comparing the two approaches, the
C-SNA provided the information necessary to understand users&apos; voices using
fewer nodes and features than the CNA. The users who pre-emptively understood
the AV policies based on their engineering literacy and the given texts
revealed potential risks of the AV accident policies. This study adds
suggestions to manage these risks to support the successful deployment of AVs
on public roads.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1&quot;&gt;Jinwoo Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dongsoo Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09036">
<title>PromptMagician: Interactive Prompt Engineering for Text-to-Image Creation. (arXiv:2307.09036v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09036</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative text-to-image models have gained great popularity among the public
for their powerful capability to generate high-quality images based on natural
language prompts. However, developing effective prompts for desired images can
be challenging due to the complexity and ambiguity of natural language. This
research proposes PromptMagician, a visual analysis system that helps users
explore the image results and refine the input prompts. The backbone of our
system is a prompt recommendation model that takes user prompts as input,
retrieves similar prompt-image pairs from DiffusionDB, and identifies special
(important and relevant) prompt keywords. To facilitate interactive prompt
refinement, PromptMagician introduces a multi-level visualization for the
cross-modal embedding of the retrieved images and recommended keywords, and
supports users in specifying multiple criteria for personalized exploration.
Two usage scenarios, a user study, and expert interviews demonstrate the
effectiveness and usability of our system, suggesting it facilitates prompt
engineering and improves the creativity support of the generative text-to-image
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yingchaojie Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xingbo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1&quot;&gt;Kam Kwai Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sijia Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yuhong Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Minfeng Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Baicheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09042">
<title>Emotional Intelligence of Large Language Models. (arXiv:2307.09042v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09042</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have demonstrated remarkable abilities across
numerous disciplines, primarily assessed through tasks in language generation,
knowledge utilization, and complex reasoning. However, their alignment with
human emotions and values, which is critical for real-world applications, has
not been systematically evaluated. Here, we assessed LLMs&apos; Emotional
Intelligence (EI), encompassing emotion recognition, interpretation, and
understanding, which is necessary for effective communication and social
interactions. Specifically, we first developed a novel psychometric assessment
focusing on Emotion Understanding (EU), a core component of EI, suitable for
both humans and LLMs. This test requires evaluating complex emotions (e.g.,
surprised, joyful, puzzled, proud) in realistic scenarios (e.g., despite
feeling underperformed, John surprisingly achieved a top score). With a
reference frame constructed from over 500 adults, we tested a variety of
mainstream LLMs. Most achieved above-average EQ scores, with GPT-4 exceeding
89% of human participants with an EQ of 117. Interestingly, a multivariate
pattern analysis revealed that some LLMs apparently did not reply on the
human-like mechanism to achieve human-level performance, as their
representational patterns were qualitatively distinct from humans. In addition,
we discussed the impact of factors such as model size, training method, and
architecture on LLMs&apos; EQ. In summary, our study presents one of the first
psychometric evaluations of the human-like characteristics of LLMs, which may
shed light on the future development of LLMs aiming for both high intellectual
and emotional intelligence. Project website:
https://emotional-intelligence.github.io/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xuena Wang&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xueting Li&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zi Yin&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yue Wu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_L/0/1/0/all/0/1&quot;&gt;Liu Jia&lt;/a&gt; (1) ((1) Department of Psychology &amp;amp; Tsinghua Laboratory of Brain and Intelligence, Tsinghua University, (2) Department of Psychology, Renmin University)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09047">
<title>Multimodal Machine Learning for Extraction of Theorems and Proofs in the Scientific Literature. (arXiv:2307.09047v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09047</link>
<description rdf:parseType="Literal">&lt;p&gt;Scholarly articles in mathematical fields feature mathematical statements
such as theorems, propositions, etc., as well as their proofs. Extracting them
from the PDF representation of the articles requires understanding of
scientific text along with visual and font-based indicators. We pose this
problem as a multimodal classification problem using text, font features, and
bitmap image rendering of the PDF as different modalities. In this paper we
propose a multimodal machine learning approach for extraction of theorem-like
environments and proofs, based on late fusion of features extracted by
individual unimodal classifiers, taking into account the sequential succession
of blocks in the document. For the text modality, we pretrain a new language
model on a 11 GB scientific corpus; experiments shows similar performance for
our task than a model (RoBERTa) pretrained on 160 GB, with faster convergence
while requiring much less fine-tuning data. Font-based information relies on
training a 128-cell LSTM on the sequence of font names and sizes within each
block. Bitmap renderings are dealt with using an EfficientNetv2 deep network
tuned to classify each image block. Finally, a simple CRF-based approach uses
the features of the multimodal model along with information on block sequences.
Experimental results show the benefits of using a multimodal approach vs any
single modality, as well as major performance improvements using the CRF
modeling of block sequences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1&quot;&gt;Shrey Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gauquier_A/0/1/0/all/0/1&quot;&gt;Antoine Gauquier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Senellart_P/0/1/0/all/0/1&quot;&gt;Pierre Senellart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09048">
<title>FedDefender: Client-Side Attack-Tolerant Federated Learning. (arXiv:2307.09048v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2307.09048</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning enables learning from decentralized data sources without
compromising privacy, which makes it a crucial technique. However, it is
vulnerable to model poisoning attacks, where malicious clients interfere with
the training process. Previous defense mechanisms have focused on the
server-side by using careful model aggregation, but this may not be effective
when the data is not identically distributed or when attackers can access the
information of benign clients. In this paper, we propose a new defense
mechanism that focuses on the client-side, called FedDefender, to help benign
clients train robust local models and avoid the adverse impact of malicious
model updates from attackers, even when a server-side defense cannot identify
or remove adversaries. Our method consists of two main components: (1)
attack-tolerant local meta update and (2) attack-tolerant global knowledge
distillation. These components are used to find noise-resilient model
parameters while accurately extracting knowledge from a potentially corrupted
global model. Our client-side defense strategy has a flexible structure and can
work in conjunction with any existing server-side strategies. Evaluations of
real-world scenarios across multiple datasets show that the proposed method
enhances the robustness of federated learning against model poisoning attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sungwon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Sungwon Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fangzhao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sundong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1&quot;&gt;Bin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cha_M/0/1/0/all/0/1&quot;&gt;Meeyoung Cha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09050">
<title>R-Cut: Enhancing Explainability in Vision Transformers with Relationship Weighted Out and Cut. (arXiv:2307.09050v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.09050</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer-based models have gained popularity in the field of natural
language processing (NLP) and are extensively utilized in computer vision tasks
and multi-modal models such as GPT4. This paper presents a novel method to
enhance the explainability of Transformer-based image classification models.
Our method aims to improve trust in classification results and empower users to
gain a deeper understanding of the model for downstream tasks by providing
visualizations of class-specific maps. We introduce two modules: the
``Relationship Weighted Out&quot; and the ``Cut&quot; modules. The ``Relationship
Weighted Out&quot; module focuses on extracting class-specific information from
intermediate layers, enabling us to highlight relevant features. Additionally,
the ``Cut&quot; module performs fine-grained feature decomposition, taking into
account factors such as position, texture, and color. By integrating these
modules, we generate dense class-specific visual explainability maps. We
validate our method with extensive qualitative and quantitative experiments on
the ImageNet dataset. Furthermore, we conduct a large number of experiments on
the LRN dataset, specifically designed for automatic driving danger alerts, to
evaluate the explainability of our method in complex backgrounds. The results
demonstrate a significant improvement over previous methods. Moreover, we
conduct ablation experiments to validate the effectiveness of each module.
Through these experiments, we are able to confirm the respective contributions
of each module, thus solidifying the overall effectiveness of our proposed
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_Y/0/1/0/all/0/1&quot;&gt;Yingjie Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Ming Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_M/0/1/0/all/0/1&quot;&gt;Maoning Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karlsson_R/0/1/0/all/0/1&quot;&gt;Robin Karlsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuxiao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1&quot;&gt;Kazuya Takeda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09051">
<title>QMNet: Importance-Aware Message Exchange for Decentralized Multi-Agent Reinforcement Learning. (arXiv:2307.09051v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09051</link>
<description rdf:parseType="Literal">&lt;p&gt;To improve the performance of multi-agent reinforcement learning under the
constraint of wireless resources, we propose a message importance metric and
design an importance-aware scheduling policy to effectively exchange messages.
The key insight is spending the precious communication resources on important
messages. The message importance depends not only on the messages themselves,
but also on the needs of agents who receive them. Accordingly, we propose a
query-message-based architecture, called QMNet. Agents generate queries and
messages with the environment observation. Sharing queries can help calculate
message importance. Exchanging messages can help agents cooperate better.
Besides, we exploit the message importance to deal with random access
collisions in decentralized systems. Furthermore, a message prediction
mechanism is proposed to compensate for messages that are not transmitted.
Finally, we evaluate the proposed schemes in a traffic junction environment,
where only a fraction of agents can send messages due to limited wireless
resources. Results show that QMNet can extract valuable information to
guarantee the system performance even when only $30\%$ of agents can share
messages. By exploiting message prediction, the system can further save $40\%$
of wireless resources. The importance-aware decentralized multi-access
mechanism can effectively avoid collisions, achieving almost the same
performance as centralized scheduling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xiufeng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sheng Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09059">
<title>Unleashing the Imagination of Text: A Novel Framework for Text-to-image Person Retrieval via Exploring the Power of Words. (arXiv:2307.09059v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.09059</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of Text-to-image person retrieval is to retrieve person images from
a large gallery that match the given textual descriptions. The main challenge
of this task lies in the significant differences in information representation
between the visual and textual modalities. The textual modality conveys
abstract and precise information through vocabulary and grammatical structures,
while the visual modality conveys concrete and intuitive information through
images. To fully leverage the expressive power of textual representations, it
is essential to accurately map abstract textual descriptions to specific
images.
&lt;/p&gt;
&lt;p&gt;To address this issue, we propose a novel framework to Unleash the
Imagination of Text (UIT) in text-to-image person retrieval, aiming to fully
explore the power of words in sentences. Specifically, the framework employs
the pre-trained full CLIP model as a dual encoder for the images and texts ,
taking advantage of prior cross-modal alignment knowledge. The Text-guided
Image Restoration auxiliary task is proposed with the aim of implicitly mapping
abstract textual entities to specific image regions, facilitating alignment
between textual and visual embeddings. Additionally, we introduce a cross-modal
triplet loss tailored for handling hard samples, enhancing the model&apos;s ability
to distinguish minor differences.
&lt;/p&gt;
&lt;p&gt;To focus the model on the key components within sentences, we propose a novel
text data augmentation technique. Our proposed methods achieve state-of-the-art
results on three popular benchmark datasets, and the source code will be made
publicly available shortly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Delong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haiwen Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09072">
<title>DiTTO: Diffusion-inspired Temporal Transformer Operator. (arXiv:2307.09072v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.09072</link>
<description rdf:parseType="Literal">&lt;p&gt;Solving partial differential equations (PDEs) using a data-driven approach
has become increasingly common. The recent development of the operator learning
paradigm has enabled the solution of a broader range of PDE-related problems.
We propose an operator learning method to solve time-dependent PDEs
continuously in time without needing any temporal discretization. The proposed
approach, named DiTTO, is inspired by latent diffusion models. While diffusion
models are usually used in generative artificial intelligence tasks, their
time-conditioning mechanism is extremely useful for PDEs. The
diffusion-inspired framework is combined with elements from the Transformer
architecture to improve its capabilities.
&lt;/p&gt;
&lt;p&gt;We demonstrate the effectiveness of the new approach on a wide variety of
PDEs in multiple dimensions, namely the 1-D Burgers&apos; equation, 2-D
Navier-Stokes equations, and the acoustic wave equation in 2-D and 3-D. DiTTO
achieves state-of-the-art results in terms of accuracy for these problems. We
also present a method to improve the performance of DiTTO by using fast
sampling concepts from diffusion models. Finally, we show that DiTTO can
accurately perform zero-shot super-resolution in time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ovadia_O/0/1/0/all/0/1&quot;&gt;Oded Ovadia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turkel_E/0/1/0/all/0/1&quot;&gt;Eli Turkel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahana_A/0/1/0/all/0/1&quot;&gt;Adar Kahana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1&quot;&gt;George Em Karniadakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09099">
<title>A Survey on Multi-Objective Neural Architecture Search. (arXiv:2307.09099v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.09099</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the expert-crafted neural architectures is increasing overtaken by
the utilization of neural architecture search (NAS) and automatic generation
(and tuning) of network structures which has a close relation to the
Hyperparameter Optimization and Auto Machine Learning (AutoML). After the
earlier NAS attempts to optimize only the prediction accuracy, Multi-Objective
Neural architecture Search (MONAS) has been attracting attentions which
considers more goals such as computational complexity, power consumption, and
size of the network for optimization, reaching a trade-off between the accuracy
and other features like the computational cost. In this paper, we present an
overview of principal and state-of-the-art works in the field of MONAS.
Starting from a well-categorized taxonomy and formulation for the NAS, we
address and correct some miscategorizations in previous surveys of the NAS
field. We also provide a list of all known objectives used and add a number of
new ones and elaborate their specifications. We have provides analyses about
the most important objectives and shown that the stochastic properties of some
the them should be differed from deterministic ones in the multi-objective
optimization procedure of NAS. We finalize this paper with a number of future
directions and topics in the field of MONAS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shariatzadeh_S/0/1/0/all/0/1&quot;&gt;Seyed Mahdi Shariatzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fathy_M/0/1/0/all/0/1&quot;&gt;Mahmood Fathy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berangi_R/0/1/0/all/0/1&quot;&gt;Reza Berangi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahverdy_M/0/1/0/all/0/1&quot;&gt;Mohammad Shahverdy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09114">
<title>BOLD: A Benchmark for Linked Data User Agents and a Simulation Framework for Dynamic Linked Data Environments. (arXiv:2307.09114v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2307.09114</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper presents the BOLD (Buildings on Linked Data) benchmark for Linked
Data agents, next to the framework to simulate dynamic Linked Data
environments, using which we built BOLD. The BOLD benchmark instantiates the
BOLD framework by providing a read-write Linked Data interface to a smart
building with simulated time, occupancy movement and sensors and actuators
around lighting. On the Linked Data representation of this environment, agents
carry out several specified tasks, such as controlling illumination. The
simulation environment provides means to check for the correct execution of the
tasks and to measure the performance of agents. We conduct measurements on
Linked Data agents based on condition-action rules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kafer_T/0/1/0/all/0/1&quot;&gt;Tobias K&amp;#xe4;fer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Charpenay_V/0/1/0/all/0/1&quot;&gt;Victor Charpenay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Harth_A/0/1/0/all/0/1&quot;&gt;Andreas Harth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09132">
<title>Cloud-native RStudio on Kubernetes for Hopsworks. (arXiv:2307.09132v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2307.09132</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to fully benefit from cloud computing, services are designed
following the &quot;multi-tenant&quot; architectural model, which is aimed at maximizing
resource sharing among users. However, multi-tenancy introduces challenges of
security, performance isolation, scaling, and customization. RStudio server is
an open-source Integrated Development Environment (IDE) accessible over a web
browser for the R programming language. We present the design and
implementation of a multi-user distributed system on Hopsworks, a
data-intensive AI platform, following the multi-tenant model that provides
RStudio as Software as a Service (SaaS). We use the most popular cloud-native
technologies: Docker and Kubernetes, to solve the problems of performance
isolation, security, and scaling that are present in a multi-tenant
environment. We further enable secure data sharing in RStudio server instances
to provide data privacy and allow collaboration among RStudio users. We
integrate our system with Apache Spark, which can scale and handle Big Data
processing workloads. Also, we provide a UI where users can provide custom
configurations and have full control of their own RStudio server instances. Our
system was tested on a Google Cloud Platform cluster with four worker nodes,
each with 30GB of RAM allocated to them. The tests on this cluster showed that
44 RStudio servers, each with 2GB of RAM, can be run concurrently. Our system
can scale out to potentially support hundreds of concurrently running RStudio
servers by adding more resources (CPUs and RAM) to the cluster or system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chikafa_G/0/1/0/all/0/1&quot;&gt;Gibson Chikafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheikholeslami_S/0/1/0/all/0/1&quot;&gt;Sina Sheikholeslami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niazi_S/0/1/0/all/0/1&quot;&gt;Salman Niazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dowling_J/0/1/0/all/0/1&quot;&gt;Jim Dowling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vlassov_V/0/1/0/all/0/1&quot;&gt;Vladimir Vlassov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09136">
<title>DropMix: Reducing Class Dependency in Mixed Sample Data Augmentation. (arXiv:2307.09136v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.09136</link>
<description rdf:parseType="Literal">&lt;p&gt;Mixed sample data augmentation (MSDA) is a widely used technique that has
been found to improve performance in a variety of tasks. However, in this
paper, we show that the effects of MSDA are class-dependent, with some classes
seeing an improvement in performance while others experience a decline. To
reduce class dependency, we propose the DropMix method, which excludes a
specific percentage of data from the MSDA computation. By training on a
combination of MSDA and non-MSDA data, the proposed method not only improves
the performance of classes that were previously degraded by MSDA, but also
increases overall average accuracy, as shown in experiments on two datasets
(CIFAR-100 and ImageNet) using three MSDA methods (Mixup, CutMix and
PuzzleMix).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Haeil Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hansang Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junmo Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09141">
<title>Machine Learning for SAT: Restricted Heuristics and New Graph Representations. (arXiv:2307.09141v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09141</link>
<description rdf:parseType="Literal">&lt;p&gt;Boolean satisfiability (SAT) is a fundamental NP-complete problem with many
applications, including automated planning and scheduling. To solve large
instances, SAT solvers have to rely on heuristics, e.g., choosing a branching
variable in DPLL and CDCL solvers. Such heuristics can be improved with machine
learning (ML) models; they can reduce the number of steps but usually hinder
the running time because useful models are relatively large and slow. We
suggest the strategy of making a few initial steps with a trained ML model and
then releasing control to classical heuristics; this simplifies cold start for
SAT solving and can decrease both the number of steps and overall runtime, but
requires a separate decision of when to release control to the solver.
Moreover, we introduce a modification of Graph-Q-SAT tailored to SAT problems
converted from other domains, e.g., open shop scheduling problems. We validate
the feasibility of our approach with random and industrial SAT problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shirokikh_M/0/1/0/all/0/1&quot;&gt;Mikhail Shirokikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shenbin_I/0/1/0/all/0/1&quot;&gt;Ilya Shenbin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alekseev_A/0/1/0/all/0/1&quot;&gt;Anton Alekseev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolenko_S/0/1/0/all/0/1&quot;&gt;Sergey Nikolenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09151">
<title>Enhancing Network Slicing Architectures with Machine Learning, Security, Sustainability and Experimental Networks Integration. (arXiv:2307.09151v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2307.09151</link>
<description rdf:parseType="Literal">&lt;p&gt;Network Slicing (NS) is an essential technique extensively used in 5G
networks computing strategies, mobile edge computing, mobile cloud computing,
and verticals like the Internet of Vehicles and industrial IoT, among others.
NS is foreseen as one of the leading enablers for 6G futuristic and highly
demanding applications since it allows the optimization and customization of
scarce and disputed resources among dynamic, demanding clients with highly
distinct application requirements. Various standardization organizations, like
3GPP&apos;s proposal for new generation networks and state-of-the-art 5G/6G research
projects, are proposing new NS architectures. However, new NS architectures
have to deal with an extensive range of requirements that inherently result in
having NS architecture proposals typically fulfilling the needs of specific
sets of domains with commonalities. The Slicing Future Internet Infrastructures
(SFI2) architecture proposal explores the gap resulting from the diversity of
NS architectures target domains by proposing a new NS reference architecture
with a defined focus on integrating experimental networks and enhancing the NS
architecture with Machine Learning (ML) native optimizations, energy-efficient
slicing, and slicing-tailored security functionalities. The SFI2 architectural
main contribution includes the utilization of the slice-as-a-service paradigm
for end-to-end orchestration of resources across multi-domains and
multi-technology experimental networks. In addition, the SFI2 reference
architecture instantiations will enhance the multi-domain and multi-technology
integrated experimental network deployment with native ML optimization,
energy-efficient aware slicing, and slicing-tailored security functionalities
for the practical domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martins_J/0/1/0/all/0/1&quot;&gt;Joberto S. B. Martins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_T/0/1/0/all/0/1&quot;&gt;Tereza C. Carvalho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreira_R/0/1/0/all/0/1&quot;&gt;Rodrigo Moreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Both_C/0/1/0/all/0/1&quot;&gt;Cristiano Both&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donatti_A/0/1/0/all/0/1&quot;&gt;Adnei Donatti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Correa_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o H. Corr&amp;#xea;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suruagy_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; A. Suruagy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Correa_S/0/1/0/all/0/1&quot;&gt;Sand L. Corr&amp;#xea;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abelem_A/0/1/0/all/0/1&quot;&gt;Antonio J. G. Abelem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1&quot;&gt;Mois&amp;#xe9;s R. N. Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nogueira_J/0/1/0/all/0/1&quot;&gt;Jose-Marcos Nogueira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magalhaes_L/0/1/0/all/0/1&quot;&gt;Luiz C. S. Magalh&amp;#xe3;es&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wickboldt_J/0/1/0/all/0/1&quot;&gt;Juliano Wickboldt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreto_T/0/1/0/all/0/1&quot;&gt;Tiago Ferreto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mello_R/0/1/0/all/0/1&quot;&gt;Ricardo Mello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasquini_R/0/1/0/all/0/1&quot;&gt;Rafael Pasquini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwarz_M/0/1/0/all/0/1&quot;&gt;Marcos Schwarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sampaio_L/0/1/0/all/0/1&quot;&gt;Leobino N. Sampaio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macedo_D/0/1/0/all/0/1&quot;&gt;Daniel F. Macedo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezende_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; F. de Rezende&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardoso_K/0/1/0/all/0/1&quot;&gt;Kleber V. Cardoso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_F/0/1/0/all/0/1&quot;&gt;Fl&amp;#xe1;vio O. Silva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09166">
<title>Safe Formulas in the General Theory of Stable Models. (arXiv:2307.09166v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09166</link>
<description rdf:parseType="Literal">&lt;p&gt;Safe first-order formulas generalize the concept of a safe rule, which plays
an important role in the design of answer set solvers. We show that any safe
sentence is equivalent, in a certain sense, to the result of its grounding --
to the variable-free sentence obtained from it by replacing all quantifiers
with multiple conjunctions and disjunctions. It follows that a safe sentence
and the result of its grounding have the same stable models, and that the
stable models of a safe sentence can be characterized by a formula of a simple
syntactic form.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joohyung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lifschitz_V/0/1/0/all/0/1&quot;&gt;Vladimir Lifschitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palla_R/0/1/0/all/0/1&quot;&gt;Ravi Palla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09168">
<title>Elementary Sets for Logic Programs. (arXiv:2307.09168v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09168</link>
<description rdf:parseType="Literal">&lt;p&gt;By introducing the concepts of a loop and a loop formula, Lin and Zhao showed
that the answer sets of a nondisjunctive logic program are exactly the models
of its Clark&apos;s completion that satisfy the loop formulas of all loops.
Recently, Gebser and Schaub showed that the Lin-Zhao theorem remains correct
even if we restrict loop formulas to a special class of loops called
``elementary loops.&apos;&apos; In this paper, we simplify and generalize the notion of
an elementary loop, and clarify its role. We propose the notion of an
elementary set, which is almost equivalent to the notion of an elementary loop
for nondisjunctive programs, but is simpler, and, unlike elementary loops, can
be extended to disjunctive programs without producing unintuitive results. We
show that the maximal unfounded elementary sets for the ``relevant&apos;&apos; part of a
program are exactly the minimal sets among the nonempty unfounded sets. We also
present a graph-theoretic characterization of elementary sets for
nondisjunctive programs, which is simpler than the one proposed in (Gebser &amp;amp;
Schaub 2005). Unlike the case of nondisjunctive programs, we show that the
problem of deciding an elementary set is coNP-complete for disjunctive
programs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gebser_M/0/1/0/all/0/1&quot;&gt;Martin Gebser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joohyung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lierler_Y/0/1/0/all/0/1&quot;&gt;Yuliya Lierler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09177">
<title>Intuitive Access to Smartphone Settings Using Relevance Model Trained by Contrastive Learning. (arXiv:2307.09177v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2307.09177</link>
<description rdf:parseType="Literal">&lt;p&gt;The more new features that are being added to smartphones, the harder it
becomes for users to find them. This is because the feature names are usually
short, and there are just too many to remember. In such a case, the users may
want to ask contextual queries that describe the features they are looking for,
but the standard term frequency-based search cannot process them. This paper
presents a novel retrieval system for mobile features that accepts intuitive
and contextual search queries. We trained a relevance model via contrastive
learning from a pre-trained language model to perceive the contextual relevance
between query embeddings and indexed mobile features. Also, to make it run
efficiently on-device using minimal resources, we applied knowledge
distillation to compress the model without degrading much performance. To
verify the feasibility of our method, we collected test queries and conducted
comparative experiments with the currently deployed search baselines. The
results show that our system outperforms the others on contextual sentence
queries and even on usual keyword-based queries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Joonyoung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kangwook Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_H/0/1/0/all/0/1&quot;&gt;Haebin Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hurnjoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1&quot;&gt;Sechun Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_B/0/1/0/all/0/1&quot;&gt;Byunguk Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_D/0/1/0/all/0/1&quot;&gt;Dong Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joohyung Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09193">
<title>ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint. (arXiv:2307.09193v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09193</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale online recommender system spreads all over the Internet being in
charge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion
Rate (CVR) estimations. However, traditional CVR estimators suffer from
well-known Sample Selection Bias and Data Sparsity issues. Entire space models
were proposed to address the two issues via tracing the decision-making path of
&quot;exposure_click_purchase&quot;. Further, some researchers observed that there are
purchase-related behaviors between click and purchase, which can better draw
the user&apos;s decision-making intention and improve the recommendation
performance. Thus, the decision-making path has been extended to
&quot;exposure_click_in-shop action_purchase&quot; and can be modeled with conditional
probability approach. Nevertheless, we observe that the chain rule of
conditional probability does not always hold. We report Probability Space
Confusion (PSC) issue and give a derivation of difference between ground-truth
and estimation mathematically. We propose a novel Entire Space Multi-Task Model
for Post-Click Conversion Rate via Parameter Constraint (ESMC) and two
alternatives: Entire Space Multi-Task Model with Siamese Network (ESMS) and
Entire Space Multi-Task Model in Global Domain (ESMG) to address the PSC issue.
Specifically, we handle &quot;exposure_click_in-shop action&quot; and &quot;in-shop
action_purchase&quot; separately in the light of characteristics of in-shop action.
The first path is still treated with conditional probability while the second
one is treated with parameter constraint strategy. Experiments on both offline
and online environments in a large-scale recommendation system illustrate the
superiority of our proposed methods over state-of-the-art models. The
real-world datasets will be released.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Zhenhao Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_B/0/1/0/all/0/1&quot;&gt;Biao Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1&quot;&gt;Hao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1&quot;&gt;Jicong Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1&quot;&gt;Jia Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_N/0/1/0/all/0/1&quot;&gt;Ning Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xingyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_X/0/1/0/all/0/1&quot;&gt;Xuguang Lan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09209">
<title>Automated Ableism: An Exploration of Explicit Disability Biases in Sentiment and Toxicity Analysis Models. (arXiv:2307.09209v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.09209</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze sentiment analysis and toxicity detection models to detect the
presence of explicit bias against people with disability (PWD). We employ the
bias identification framework of Perturbation Sensitivity Analysis to examine
conversations related to PWD on social media platforms, specifically Twitter
and Reddit, in order to gain insight into how disability bias is disseminated
in real-world social settings. We then create the \textit{Bias Identification
Test in Sentiment} (BITS) corpus to quantify explicit disability bias in any
sentiment analysis and toxicity detection models. Our study utilizes BITS to
uncover significant biases in four open AIaaS (AI as a Service) sentiment
analysis tools, namely TextBlob, VADER, Google Cloud Natural Language API,
DistilBERT and two toxicity detection models, namely two versions of
Toxic-BERT. Our findings indicate that all of these models exhibit
statistically significant explicit bias against PWD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkit_P/0/1/0/all/0/1&quot;&gt;Pranav Narayanan Venkit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinath_M/0/1/0/all/0/1&quot;&gt;Mukund Srinath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_S/0/1/0/all/0/1&quot;&gt;Shomir Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09218">
<title>A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning. (arXiv:2307.09218v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.09218</link>
<description rdf:parseType="Literal">&lt;p&gt;Forgetting refers to the loss or deterioration of previously acquired
information or knowledge. While the existing surveys on forgetting have
primarily focused on continual learning, forgetting is a prevalent phenomenon
observed in various other research domains within deep learning. Forgetting
manifests in research fields such as generative models due to generator shifts,
and federated learning due to heterogeneous data distributions across clients.
Addressing forgetting encompasses several challenges, including balancing the
retention of old task knowledge with fast learning of new tasks, managing task
interference with conflicting goals, and preventing privacy leakage, etc.
Moreover, most existing surveys on continual learning implicitly assume that
forgetting is always harmful. In contrast, our survey argues that forgetting is
a double-edged sword and can be beneficial and desirable in certain cases, such
as privacy-preserving scenarios. By exploring forgetting in a broader context,
we aim to present a more nuanced understanding of this phenomenon and highlight
its potential advantages. Through this comprehensive survey, we aspire to
uncover potential solutions by drawing upon ideas and approaches from various
fields that have dealt with forgetting. By examining forgetting beyond its
conventional boundaries, in future work, we hope to encourage the development
of novel strategies for mitigating, harnessing, or even embracing forgetting in
real applications. A comprehensive list of papers about forgetting in various
research fields is available at
\url{https://github.com/EnnengYang/Awesome-Forgetting-in-Deep-Learning}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhenyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1&quot;&gt;Enneng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1&quot;&gt;Li Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Heng Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09225">
<title>Human Body Digital Twin: A Master Plan. (arXiv:2307.09225v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09225</link>
<description rdf:parseType="Literal">&lt;p&gt;The human body DT has the potential to revolutionize healthcare and wellness,
but its responsible and effective implementation requires consideration of
various factors. This article presents a comprehensive overview of the current
status and future prospects of the human body DT and proposes a five-level
roadmap for its development. The roadmap covers the development of various
components, such as wearable devices, data collection, data analysis, and
decision-making systems. The article also highlights the necessary support,
security, cost, and ethical considerations that must be addressed in order to
ensure responsible and effective implementation of the human body DT. The
proposed roadmap provides a framework for guiding future development and offers
a unique perspective on the future of the human body DT, facilitating new
interdisciplinary research and innovative solutions in this rapidly evolving
field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1&quot;&gt;Chenyu Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Shuo Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Occhipinti_L/0/1/0/all/0/1&quot;&gt;Luigi G. Occhipinti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09244">
<title>Towards Sustainable Deep Learning for Multi-Label Classification on NILM. (arXiv:2307.09244v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.09244</link>
<description rdf:parseType="Literal">&lt;p&gt;Non-intrusive load monitoring (NILM) is the process of obtaining
appliance-level data from a single metering point, measuring total electricity
consumption of a household or a business. Appliance-level data can be directly
used for demand response applications and energy management systems as well as
for awareness raising and motivation for improvements in energy efficiency and
reduction in the carbon footprint. Recently, classical machine learning and
deep learning (DL) techniques became very popular and proved as highly
effective for NILM classification, but with the growing complexity these
methods are faced with significant computational and energy demands during both
their training and operation. In this paper, we introduce a novel DL model
aimed at enhanced multi-label classification of NILM with improved computation
and energy efficiency. We also propose a testing methodology for comparison of
different models using data synthesized from the measurement datasets so as to
better represent real-world scenarios. Compared to the state-of-the-art, the
proposed model has its carbon footprint reduced by more than 23% while
providing on average approximately 8 percentage points in performance
improvement when testing on data derived from REFIT and UK-DALE datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pirnat_A/0/1/0/all/0/1&quot;&gt;An&amp;#x17e;e Pirnat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertalanic_B/0/1/0/all/0/1&quot;&gt;Bla&amp;#x17e; Bertalani&amp;#x10d;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cerar_G/0/1/0/all/0/1&quot;&gt;Gregor Cerar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohorcic_M/0/1/0/all/0/1&quot;&gt;Mihael Mohor&amp;#x10d;i&amp;#x10d;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fortuna_C/0/1/0/all/0/1&quot;&gt;Carolina Fortuna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09249">
<title>UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data. (arXiv:2307.09249v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.09249</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advancements in Natural Language Processing (NLP) have witnessed the
groundbreaking impact of pretrained models, yielding impressive outcomes across
various tasks. This study seeks to extend the power of pretraining
methodologies to tabular data, a domain traditionally overlooked, yet
inherently challenging due to the plethora of table schemas intrinsic to
different tasks. The primary research questions underpinning this work revolve
around the adaptation to heterogeneous table structures, the establishment of a
universal pretraining protocol for tabular data, the generalizability and
transferability of learned knowledge across tasks, the adaptation to diverse
downstream applications, and the incorporation of incremental columns over
time. In response to these challenges, we introduce UniTabE, a pioneering
method designed to process tables in a uniform manner, devoid of constraints
imposed by specific table structures. UniTabE&apos;s core concept relies on
representing each basic table element with a module, termed TabUnit. This is
subsequently followed by a Transformer encoder to refine the representation.
Moreover, our model is designed to facilitate pretraining and finetuning
through the utilization of free-form prompts. In order to implement the
pretraining phase, we curated an expansive tabular dataset comprising
approximately 13 billion samples, meticulously gathered from the Kaggle
platform. Rigorous experimental testing and analyses were performed under a
myriad of scenarios to validate the effectiveness of our methodology. The
experimental results demonstrate UniTabE&apos;s superior performance against several
baseline models across a multitude of benchmark datasets. This, therefore,
underscores UniTabE&apos;s potential to significantly enhance the semantic
representation of tabular data, thereby marking a significant stride in the
field of tabular data analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yazheng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Ledell Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09274">
<title>Improving Text Semantic Similarity Modeling through a 3D Siamese Network. (arXiv:2307.09274v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.09274</link>
<description rdf:parseType="Literal">&lt;p&gt;Siamese networks have gained popularity as a method for modeling text
semantic similarity. Traditional methods rely on pooling operation to compress
the semantic representations from Transformer blocks in encoding, resulting in
two-dimensional semantic vectors and the loss of hierarchical semantic
information from Transformer blocks. Moreover, this limited structure of
semantic vectors is akin to a flattened landscape, which restricts the methods
that can be applied in downstream modeling, as they can only navigate this flat
terrain. To address this issue, we propose a novel 3D Siamese network for text
semantic similarity modeling, which maps semantic information to a
higher-dimensional space. The three-dimensional semantic tensors not only
retains more precise spatial and feature domain information but also provides
the necessary structural condition for comprehensive downstream modeling
strategies to capture them. Leveraging this structural advantage, we introduce
several modules to reinforce this 3D framework, focusing on three aspects:
feature extraction, attention, and feature fusion. Our extensive experiments on
four text semantic similarity benchmarks demonstrate the effectiveness and
efficiency of our 3D Siamese Network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zang_J/0/1/0/all/0/1&quot;&gt;Jianxiang Zang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hui Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09288">
<title>Llama 2: Open Foundation and Fine-Tuned Chat Models. (arXiv:2307.09288v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2307.09288</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we develop and release Llama 2, a collection of pretrained and
fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70
billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for
dialogue use cases. Our models outperform open-source chat models on most
benchmarks we tested, and based on our human evaluations for helpfulness and
safety, may be a suitable substitute for closed-source models. We provide a
detailed description of our approach to fine-tuning and safety improvements of
Llama 2-Chat in order to enable the community to build on our work and
contribute to the responsible development of LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1&quot;&gt;Hugo Touvron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_L/0/1/0/all/0/1&quot;&gt;Louis Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stone_K/0/1/0/all/0/1&quot;&gt;Kevin Stone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albert_P/0/1/0/all/0/1&quot;&gt;Peter Albert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Almahairi_A/0/1/0/all/0/1&quot;&gt;Amjad Almahairi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babaei_Y/0/1/0/all/0/1&quot;&gt;Yasmine Babaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bashlykov_N/0/1/0/all/0/1&quot;&gt;Nikolay Bashlykov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_S/0/1/0/all/0/1&quot;&gt;Soumya Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhargava_P/0/1/0/all/0/1&quot;&gt;Prajjwal Bhargava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhosale_S/0/1/0/all/0/1&quot;&gt;Shruti Bhosale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bikel_D/0/1/0/all/0/1&quot;&gt;Dan Bikel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blecher_L/0/1/0/all/0/1&quot;&gt;Lukas Blecher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1&quot;&gt;Cristian Canton Ferrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Moya Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cucurull_G/0/1/0/all/0/1&quot;&gt;Guillem Cucurull&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esiobu_D/0/1/0/all/0/1&quot;&gt;David Esiobu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandes_J/0/1/0/all/0/1&quot;&gt;Jude Fernandes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jeremy Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1&quot;&gt;Wenyin Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuller_B/0/1/0/all/0/1&quot;&gt;Brian Fuller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1&quot;&gt;Cynthia Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1&quot;&gt;Vedanuj Goswami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1&quot;&gt;Naman Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hartshorn_A/0/1/0/all/0/1&quot;&gt;Anthony Hartshorn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1&quot;&gt;Saghar Hosseini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1&quot;&gt;Rui Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inan_H/0/1/0/all/0/1&quot;&gt;Hakan Inan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kardas_M/0/1/0/all/0/1&quot;&gt;Marcin Kardas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kerkez_V/0/1/0/all/0/1&quot;&gt;Viktor Kerkez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1&quot;&gt;Madian Khabsa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kloumann_I/0/1/0/all/0/1&quot;&gt;Isabel Kloumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korenev_A/0/1/0/all/0/1&quot;&gt;Artem Korenev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koura_P/0/1/0/all/0/1&quot;&gt;Punit Singh Koura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lachaux_M/0/1/0/all/0/1&quot;&gt;Marie-Anne Lachaux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lavril_T/0/1/0/all/0/1&quot;&gt;Thibaut Lavril&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jenya Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liskovich_D/0/1/0/all/0/1&quot;&gt;Diana Liskovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yinghai Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1&quot;&gt;Yuning Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinet_X/0/1/0/all/0/1&quot;&gt;Xavier Martinet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mihaylov_T/0/1/0/all/0/1&quot;&gt;Todor Mihaylov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1&quot;&gt;Pushkar Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molybog_I/0/1/0/all/0/1&quot;&gt;Igor Molybog&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1&quot;&gt;Yixin Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poulton_A/0/1/0/all/0/1&quot;&gt;Andrew Poulton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reizenstein_J/0/1/0/all/0/1&quot;&gt;Jeremy Reizenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rungta_R/0/1/0/all/0/1&quot;&gt;Rashi Rungta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saladi_K/0/1/0/all/0/1&quot;&gt;Kalyan Saladi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schelten_A/0/1/0/all/0/1&quot;&gt;Alan Schelten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1&quot;&gt;Ruan Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_E/0/1/0/all/0/1&quot;&gt;Eric Michael Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramanian_R/0/1/0/all/0/1&quot;&gt;Ranjan Subramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1&quot;&gt;Xiaoqing Ellen Tan&lt;/a&gt;, et al. (15 additional authors not shown)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09296">
<title>Rumor Detection with Diverse Counterfactual Evidence. (arXiv:2307.09296v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09296</link>
<description rdf:parseType="Literal">&lt;p&gt;The growth in social media has exacerbated the threat of fake news to
individuals and communities. This draws increasing attention to developing
efficient and timely rumor detection methods. The prevailing approaches resort
to graph neural networks (GNNs) to exploit the post-propagation patterns of the
rumor-spreading process. However, these methods lack inherent interpretation of
rumor detection due to the black-box nature of GNNs. Moreover, these methods
suffer from less robust results as they employ all the propagation patterns for
rumor detection. In this paper, we address the above issues with the proposed
Diverse Counterfactual Evidence framework for Rumor Detection (DCE-RD). Our
intuition is to exploit the diverse counterfactual evidence of an event graph
to serve as multi-view interpretations, which are further aggregated for robust
rumor detection results. Specifically, our method first designs a subgraph
generation strategy to efficiently generate different subgraphs of the event
graph. We constrain the removal of these subgraphs to cause the change in rumor
detection results. Thus, these subgraphs naturally serve as counterfactual
evidence for rumor detection. To achieve multi-view interpretation, we design a
diversity loss inspired by Determinantal Point Processes (DPP) to encourage
diversity among the counterfactual evidence. A GNN-based rumor detection model
further aggregates the diverse counterfactual evidence discovered by the
proposed DCE-RD to achieve interpretable and robust rumor detection results.
Extensive experiments on two real-world datasets show the superior performance
of our method. Our code is available at https://github.com/Vicinity111/DCE-RD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kaiwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Junchi Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1&quot;&gt;Haichao Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jian Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiao-Yu Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09320">
<title>Biomaker CA: a Biome Maker project using Cellular Automata. (arXiv:2307.09320v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09320</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Biomaker CA: a Biome Maker project using Cellular Automata (CA).
In Biomaker CA, morphogenesis is a first class citizen and small seeds need to
grow into plant-like organisms to survive in a nutrient starved environment and
eventually reproduce with variation so that a biome survives for long
timelines. We simulate complex biomes by means of CA rules in 2D grids and
parallelize all of its computation on GPUs through the Python JAX framework. We
show how this project allows for several different kinds of environments and
laws of &apos;physics&apos;, alongside different model architectures and mutation
strategies. We further analyze some configurations to show how plant agents can
grow, survive, reproduce, and evolve, forming stable and unstable biomes. We
then demonstrate how one can meta-evolve models to survive in a harsh
environment either through end-to-end meta-evolution or by a more surgical and
efficient approach, called Petri dish meta-evolution. Finally, we show how to
perform interactive evolution, where the user decides how to evolve a plant
model interactively and then deploys it in a larger environment. We open source
Biomaker CA at: https://tinyurl.com/2x8yu34s .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Randazzo_E/0/1/0/all/0/1&quot;&gt;Ettore Randazzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mordvintsev_A/0/1/0/all/0/1&quot;&gt;Alexander Mordvintsev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09321">
<title>Exploiting Field Dependencies for Learning on Categorical Data. (arXiv:2307.09321v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.09321</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional approaches for learning on categorical data underexploit the
dependencies between columns (\aka fields) in a dataset because they rely on
the embedding of data points driven alone by the classification/regression
loss. In contrast, we propose a novel method for learning on categorical data
with the goal of exploiting dependencies between fields. Instead of modelling
statistics of features globally (i.e., by the covariance matrix of features),
we learn a global field dependency matrix that captures dependencies between
fields and then we refine the global field dependency matrix at the
instance-wise level with different weights (so-called local dependency
modelling) w.r.t. each field to improve the modelling of the field
dependencies. Our algorithm exploits the meta-learning paradigm, i.e., the
dependency matrices are refined in the inner loop of the meta-learning
algorithm without the use of labels, whereas the outer loop intertwines the
updates of the embedding matrix (the matrix performing projection) and global
dependency matrix in a supervised fashion (with the use of labels). Our method
is simple yet it outperforms several state-of-the-art methods on six popular
dataset benchmarks. Detailed ablation studies provide additional insights into
our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhibin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1&quot;&gt;Piotr Koniusz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pagendam_D/0/1/0/all/0/1&quot;&gt;Daniel Edward Pagendam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moghadam_P/0/1/0/all/0/1&quot;&gt;Peyman Moghadam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09332">
<title>Company2Vec -- German Company Embeddings based on Corporate Websites. (arXiv:2307.09332v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09332</link>
<description rdf:parseType="Literal">&lt;p&gt;With Company2Vec, the paper proposes a novel application in representation
learning. The model analyzes business activities from unstructured company
website data using Word2Vec and dimensionality reduction. Company2Vec maintains
semantic language structures and thus creates efficient company embeddings in
fine-granular industries. These semantic embeddings can be used for various
applications in banking. Direct relations between companies and words allow
semantic business analytics (e.g. top-n words for a company). Furthermore,
industry prediction is presented as a supervised learning application and
evaluation method. The vectorized structure of the embeddings allows measuring
companies similarities with the cosine distance. Company2Vec hence offers a
more fine-grained comparison of companies than the standard industry labels
(NACE). This property is relevant for unsupervised learning tasks, such as
clustering. An alternative industry segmentation is shown with k-means
clustering on the company embeddings. Finally, this paper proposes three
algorithms for (1) firm-centric, (2) industry-centric and (3) portfolio-centric
peer-firm identification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerling_C/0/1/0/all/0/1&quot;&gt;Christopher Gerling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09342">
<title>Learning to Select SAT Encodings for Pseudo-Boolean and Linear Integer Constraints. (arXiv:2307.09342v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09342</link>
<description rdf:parseType="Literal">&lt;p&gt;Many constraint satisfaction and optimisation problems can be solved
effectively by encoding them as instances of the Boolean Satisfiability problem
(SAT). However, even the simplest types of constraints have many encodings in
the literature with widely varying performance, and the problem of selecting
suitable encodings for a given problem instance is not trivial. We explore the
problem of selecting encodings for pseudo-Boolean and linear constraints using
a supervised machine learning approach. We show that it is possible to select
encodings effectively using a standard set of features for constraint problems;
however we obtain better performance with a new set of features specifically
designed for the pseudo-Boolean and linear constraints. In fact, we achieve
good results when selecting encodings for unseen problem classes. Our results
compare favourably to AutoFolio when using the same feature set. We discuss the
relative importance of instance features to the task of selecting the best
encodings, and compare several variations of the machine learning method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ulrich_Oltean_F/0/1/0/all/0/1&quot;&gt;Felix Ulrich-Oltean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nightingale_P/0/1/0/all/0/1&quot;&gt;Peter Nightingale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1&quot;&gt;James Alfred Walker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09361">
<title>MOCA: Self-supervised Representation Learning by Predicting Masked Online Codebook Assignments. (arXiv:2307.09361v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2307.09361</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning can be used for mitigating the greedy needs of
Vision Transformer networks for very large fully-annotated datasets. Different
classes of self-supervised learning offer representations with either good
contextual reasoning properties, e.g., using masked image modeling strategies,
or invariance to image perturbations, e.g., with contrastive methods. In this
work, we propose a single-stage and standalone method, MOCA, which unifies both
desired properties using novel mask-and-predict objectives defined with
high-level features (instead of pixel-level details). Moreover, we show how to
effectively employ both learning paradigms in a synergistic and
computation-efficient way. Doing so, we achieve new state-of-the-art results on
low-shot settings and strong experimental results in various evaluation
protocols with a training that is at least 3 times faster than prior methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gidaris_S/0/1/0/all/0/1&quot;&gt;Spyros Gidaris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bursuc_A/0/1/0/all/0/1&quot;&gt;Andrei Bursuc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simeoni_O/0/1/0/all/0/1&quot;&gt;Oriane Simeoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vobecky_A/0/1/0/all/0/1&quot;&gt;Antonin Vobecky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komodakis_N/0/1/0/all/0/1&quot;&gt;Nikos Komodakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1&quot;&gt;Matthieu Cord&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1&quot;&gt;Patrick P&amp;#xe9;rez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09364">
<title>Local Minima Drive Communications in Cooperative Interaction. (arXiv:2307.09364v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09364</link>
<description rdf:parseType="Literal">&lt;p&gt;An important open question in human-robot interaction (HRI) is precisely when
an agent should decide to communicate, particularly in a cooperative task.
Perceptual Control Theory (PCT) tells us that agents are able to cooperate on a
joint task simply by sharing the same &apos;intention&apos;, thereby distributing the
effort required to complete the task among the agents. This is even true for
agents that do not possess the same abilities, so long as the goal is
observable, the combined actions are sufficient to complete the task, and there
is no local minimum in the search space. If these conditions hold, then a
cooperative task can be accomplished without any communication between the
contributing agents. However, for tasks that do contain local minima, the
global solution can only be reached if at least one of the agents adapts its
intention at the appropriate moments, and this can only be achieved by
appropriately timed communication. In other words, it is hypothesised that in
cooperative tasks, the function of communication is to coordinate actions in a
complex search space that contains local minima. These principles have been
verified in a computer-based simulation environment in which two independent
one-dimensional agents are obliged to cooperate in order to solve a
two-dimensional path-finding task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_R/0/1/0/all/0/1&quot;&gt;Roger K. Moore&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09375">
<title>CertPri: Certifiable Prioritization for Deep Neural Networks via Movement Cost in Feature Space. (arXiv:2307.09375v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2307.09375</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have demonstrated their outperformance in various
software systems, but also exhibit misbehavior and even result in irreversible
disasters. Therefore, it is crucial to identify the misbehavior of DNN-based
software and improve DNNs&apos; quality. Test input prioritization is one of the
most appealing ways to guarantee DNNs&apos; quality, which prioritizes test inputs
so that more bug-revealing inputs can be identified earlier with limited time
and manual labeling efforts. However, the existing prioritization methods are
still limited from three aspects: certifiability, effectiveness, and
generalizability. To overcome the challenges, we propose CertPri, a test input
prioritization technique designed based on a movement cost perspective of test
inputs in DNNs&apos; feature space. CertPri differs from previous works in three key
aspects: (1) certifiable: it provides a formal robustness guarantee for the
movement cost; (2) effective: it leverages formally guaranteed movement costs
to identify malicious bug-revealing inputs; and (3) generic: it can be applied
to various tasks, data, models, and scenarios. Extensive evaluations across 2
tasks (i.e., classification and regression), 6 data forms, 4 model structures,
and 2 scenarios (i.e., white-box and black-box) demonstrate CertPri&apos;s superior
performance. For instance, it significantly improves 53.97% prioritization
effectiveness on average compared with baselines. Its robustness and
generalizability are 1.41~2.00 times and 1.33~3.39 times that of baselines on
average, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1&quot;&gt;Haibin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jinyin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Haibo Jin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09423">
<title>Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.09423</link>
<description rdf:parseType="Literal">&lt;p&gt;Imitation Learning (IL) is one of the most widely used methods in machine
learning. Yet, while powerful, many works find it is often not able to fully
recover the underlying expert behavior. However, none of these works deeply
investigate the role of scaling up the model and data size. Inspired by recent
work in Natural Language Processing (NLP) where &quot;scaling up&quot; has resulted in
increasingly more capable LLMs, we investigate whether carefully scaling up
model and data size can bring similar improvements in the imitation learning
setting. To demonstrate our findings, we focus on the game of NetHack, a
challenging environment featuring procedural generation, stochasticity,
long-term dependencies, and partial observability. We find IL loss and mean
return scale smoothly with the compute budget and are strongly correlated,
resulting in power laws for training compute-optimal IL agents with respect to
model size and number of samples. We forecast and train several NetHack agents
with IL and find they outperform prior state-of-the-art by at least 2x in all
settings. Our work both demonstrates the scaling behavior of imitation learning
in a challenging domain, as well as the viability of scaling up current
approaches for increasingly capable agents in NetHack, a game that remains
elusively hard for current AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuyls_J/0/1/0/all/0/1&quot;&gt;Jens Tuyls&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1&quot;&gt;Dhruv Madeka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torkkola_K/0/1/0/all/0/1&quot;&gt;Kari Torkkola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1&quot;&gt;Dean Foster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1&quot;&gt;Karthik Narasimhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09426">
<title>Balancing Privacy and Progress in Artificial Intelligence: Anonymization in Histopathology for Biomedical Research and Education. (arXiv:2307.09426v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09426</link>
<description rdf:parseType="Literal">&lt;p&gt;The advancement of biomedical research heavily relies on access to large
amounts of medical data. In the case of histopathology, Whole Slide Images
(WSI) and clinicopathological information are valuable for developing
Artificial Intelligence (AI) algorithms for Digital Pathology (DP).
Transferring medical data &quot;as open as possible&quot; enhances the usability of the
data for secondary purposes but poses a risk to patient privacy. At the same
time, existing regulations push towards keeping medical data &quot;as closed as
necessary&quot; to avoid re-identification risks. Generally, these legal regulations
require the removal of sensitive data but do not consider the possibility of
data linkage attacks due to modern image-matching algorithms. In addition, the
lack of standardization in DP makes it harder to establish a single solution
for all formats of WSIs. These challenges raise problems for bio-informatics
researchers in balancing privacy and progress while developing AI algorithms.
This paper explores the legal regulations and terminologies for medical
data-sharing. We review existing approaches and highlight challenges from the
histopathological perspective. We also present a data-sharing guideline for
histological data to foster multidisciplinary research and education.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanwal_N/0/1/0/all/0/1&quot;&gt;Neel Kanwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janssen_E/0/1/0/all/0/1&quot;&gt;Emiel A.M. Janssen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engan_K/0/1/0/all/0/1&quot;&gt;Kjersti Engan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09435">
<title>SLMGAN: Exploiting Speech Language Model Representations for Unsupervised Zero-Shot Voice Conversion in GANs. (arXiv:2307.09435v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2307.09435</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, large-scale pre-trained speech language models (SLMs) have
demonstrated remarkable advancements in various generative speech modeling
applications, such as text-to-speech synthesis, voice conversion, and speech
enhancement. These applications typically involve mapping text or speech inputs
to pre-trained SLM representations, from which target speech is decoded. This
paper introduces a new approach, SLMGAN, to leverage SLM representations for
discriminative tasks within the generative adversarial network (GAN) framework,
specifically for voice conversion. Building upon StarGANv2-VC, we add our novel
SLM-based WavLM discriminators on top of the mel-based discriminators along
with our newly designed SLM feature matching loss function, resulting in an
unsupervised zero-shot voice conversion system that does not require text
labels during training. Subjective evaluation results show that SLMGAN
outperforms existing state-of-the-art zero-shot voice conversion models in
terms of naturalness and achieves comparable similarity, highlighting the
potential of SLM-based discriminators for related applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yinghao Aaron Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1&quot;&gt;Cong Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mesgarani_N/0/1/0/all/0/1&quot;&gt;Nima Mesgarani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09437">
<title>Unsupervised Conditional Slot Attention for Object Centric Learning. (arXiv:2307.09437v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.09437</link>
<description rdf:parseType="Literal">&lt;p&gt;Extracting object-level representations for downstream reasoning tasks is an
emerging area in AI. Learning object-centric representations in an unsupervised
setting presents multiple challenges, a key one being binding an arbitrary
number of object instances to a specialized object slot. Recent object-centric
representation methods like Slot Attention utilize iterative attention to learn
composable representations with dynamic inference level binding but fail to
achieve specialized slot level binding. To address this, in this paper we
propose Unsupervised Conditional Slot Attention using a novel Probabilistic
Slot Dictionary (PSD). We define PSD with (i) abstract object-level property
vectors as key and (ii) parametric Gaussian distribution as its corresponding
value. We demonstrate the benefits of the learnt specific object-level
conditioning distributions in multiple downstream tasks, namely object
discovery, compositional scene generation, and compositional visual reasoning.
We show that our method provides scene composition capabilities and a
significant boost in a few shot adaptability tasks of compositional visual
reasoning, while performing similarly or better than slot attention in object
discovery tasks
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kori_A/0/1/0/all/0/1&quot;&gt;Avinash Kori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1&quot;&gt;Francesco Locatello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toni_F/0/1/0/all/0/1&quot;&gt;Francesca Toni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1&quot;&gt;Ben Glocker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09476">
<title>Overthinking the Truth: Understanding how Language Models Process False Demonstrations. (arXiv:2307.09476v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2307.09476</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern language models can imitate complex patterns through few-shot
learning, enabling them to complete challenging tasks without fine-tuning.
However, imitation can also lead models to reproduce inaccuracies or harmful
content if present in the context. We study harmful imitation through the lens
of a model&apos;s internal representations, and identify two related phenomena:
overthinking and false induction heads. The first phenomenon, overthinking,
appears when we decode predictions from intermediate layers, given correct vs.
incorrect few-shot demonstrations. At early layers, both demonstrations induce
similar model behavior, but the behavior diverges sharply at some &quot;critical
layer&quot;, after which the accuracy given incorrect demonstrations progressively
decreases. The second phenomenon, false induction heads, are a possible
mechanistic cause of overthinking: these are heads in late layers that attend
to and copy false information from previous demonstrations, and whose ablation
reduces overthinking. Beyond scientific understanding, our results suggest that
studying intermediate model computations could be a promising avenue for
understanding and guarding against harmful model behaviors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halawi_D/0/1/0/all/0/1&quot;&gt;Danny Halawi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denain_J/0/1/0/all/0/1&quot;&gt;Jean-Stanislas Denain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1&quot;&gt;Jacob Steinhardt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.09477">
<title>Towards Ordinal Data Science. (arXiv:2307.09477v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2307.09477</link>
<description rdf:parseType="Literal">&lt;p&gt;Order is one of the main instruments to measure the relationship between
objects in (empirical) data. However, compared to methods that use numerical
properties of objects, the amount of ordinal methods developed is rather small.
One reason for this is the limited availability of computational resources in
the last century that would have been required for ordinal computations.
Another reason -- particularly important for this line of research -- is that
order-based methods are often seen as too mathematically rigorous for applying
them to real-world data. In this paper, we will therefore discuss different
means for measuring and &apos;calculating&apos; with ordinal structures -- a specific
class of directed graphs -- and show how to infer knowledge from them. Our aim
is to establish Ordinal Data Science as a fundamentally new research agenda.
Besides cross-fertilization with other cornerstone machine learning and
knowledge representation methods, a broad range of disciplines will benefit
from this endeavor, including, psychology, sociology, economics, web science,
knowledge engineering, scientometrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stumme_G/0/1/0/all/0/1&quot;&gt;Gerd Stumme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durrschnabel_D/0/1/0/all/0/1&quot;&gt;Dominik D&amp;#xfc;rrschnabel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanika_T/0/1/0/all/0/1&quot;&gt;Tom Hanika&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.10278">
<title>A theoretical framework for self-supervised MR image reconstruction using sub-sampling via variable density Noisier2Noise. (arXiv:2205.10278v5 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2205.10278</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, there has been attention on leveraging the statistical
modeling capabilities of neural networks for reconstructing sub-sampled
Magnetic Resonance Imaging (MRI) data. Most proposed methods assume the
existence of a representative fully-sampled dataset and use fully-supervised
training. However, for many applications, fully sampled training data is not
available, and may be highly impractical to acquire. The development and
understanding of self-supervised methods, which use only sub-sampled data for
training, are therefore highly desirable. This work extends the Noisier2Noise
framework, which was originally constructed for self-supervised denoising
tasks, to variable density sub-sampled MRI data. We use the Noisier2Noise
framework to analytically explain the performance of Self-Supervised Learning
via Data Undersampling (SSDU), a recently proposed method that performs well in
practice but until now lacked theoretical justification. Further, we propose
two modifications of SSDU that arise as a consequence of the theoretical
developments. Firstly, we propose partitioning the sampling set so that the
subsets have the same type of distribution as the original sampling mask.
Secondly, we propose a loss weighting that compensates for the sampling and
partitioning densities. On the fastMRI dataset we show that these changes
significantly improve SSDU&apos;s image restoration quality and robustness to the
partitioning parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Millard_C/0/1/0/all/0/1&quot;&gt;Charles Millard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chiew_M/0/1/0/all/0/1&quot;&gt;Mark Chiew&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.07082">
<title>Stability and Generalization of Stochastic Optimization with Nonconvex and Nonsmooth Problems. (arXiv:2206.07082v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2206.07082</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic optimization has found wide applications in minimizing objective
functions in machine learning, which motivates a lot of theoretical studies to
understand its practical success. Most of existing studies focus on the
convergence of optimization errors, while the generalization analysis of
stochastic optimization is much lagging behind. This is especially the case for
nonconvex and nonsmooth problems often encountered in practice. In this paper,
we initialize a systematic stability and generalization analysis of stochastic
optimization on nonconvex and nonsmooth problems. We introduce novel
algorithmic stability measures and establish their quantitative connection on
the gap between population gradients and empirical gradients, which is then
further extended to study the gap between the Moreau envelope of the empirical
risk and that of the population risk. To our knowledge, these quantitative
connection between stability and generalization in terms of either gradients or
Moreau envelopes have not been studied in the literature. We introduce a class
of sampling-determined algorithms, for which we develop bounds for three
stability measures. Finally, we apply these discussions to derive error bounds
for stochastic gradient descent and its adaptive variant, where we show how to
achieve an implicit regularization by tuning the step sizes and the number of
iterations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1&quot;&gt;Yunwen Lei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.09920">
<title>DESCN: Deep Entire Space Cross Networks for Individual Treatment Effect Estimation. (arXiv:2207.09920v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2207.09920</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal Inference has wide applications in various areas such as E-commerce
and precision medicine, and its performance heavily relies on the accurate
estimation of the Individual Treatment Effect (ITE). Conventionally, ITE is
predicted by modeling the treated and control response functions separately in
their individual sample spaces. However, such an approach usually encounters
two issues in practice, i.e. divergent distribution between treated and control
groups due to treatment bias, and significant sample imbalance of their
population sizes. This paper proposes Deep Entire Space Cross Networks (DESCN)
to model treatment effects from an end-to-end perspective. DESCN captures the
integrated information of the treatment propensity, the response, and the
hidden treatment effect through a cross network in a multi-task learning
manner. Our method jointly learns the treatment and response functions in the
entire sample space to avoid treatment bias and employs an intermediate pseudo
treatment effect prediction network to relieve sample imbalance. Extensive
experiments are conducted on a synthetic dataset and a large-scaled production
dataset from the E-commerce voucher distribution business. The results indicate
that DESCN can successfully enhance the accuracy of ITE estimation and improve
the uplift ranking performance. A sample of the production dataset and the
source code are released to facilitate future research in the community, which
is, to the best of our knowledge, the first large-scale public biased treatment
dataset for causal inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_K/0/1/0/all/0/1&quot;&gt;Kailiang Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_F/0/1/0/all/0/1&quot;&gt;Fengtong Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1&quot;&gt;Yan Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yaorong Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1&quot;&gt;Wenqing Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xiaofeng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cen_L/0/1/0/all/0/1&quot;&gt;Ling Cen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.01426">
<title>Continuous Monte Carlo Graph Search. (arXiv:2210.01426v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2210.01426</link>
<description rdf:parseType="Literal">&lt;p&gt;In many complex sequential decision-making tasks, online planning is crucial
for high performance. For efficient online planning, Monte Carlo Tree Search
(MCTS) employs a principled mechanism for trading off exploration for
exploitation. MCTS outperforms comparison methods in many discrete
decision-making domains such as Go, Chess, and Shogi. Following, extensions of
MCTS to continuous domains have been proposed. However, the inherent high
branching factor and the resulting explosion of search tree size are limiting
existing methods. To address this problem, we propose Continuous Monte Carlo
Graph Search (CMCGS), a novel extension of MCTS to online planning in
environments with continuous state and action spaces. CMCGS takes advantage of
the insight that, during planning, sharing the same action policy between
several states can yield high performance. To implement this idea, at each time
step, CMCGS clusters similar states into a limited number of stochastic action
bandit nodes, which produce a layered directed graph instead of an MCTS search
tree. Experimental evaluation shows that CMCGS outperforms comparable planning
methods in several complex continuous DeepMind Control Suite benchmarks and a
2D navigation task with limited sample budgets. Furthermore, CMCGS can be
parallelized to scale up and it outperforms the Cross-Entropy Method (CEM) in
continuous control with learned dynamics models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kujanpaa_K/0/1/0/all/0/1&quot;&gt;Kalle Kujanp&amp;#xe4;&amp;#xe4;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babadi_A/0/1/0/all/0/1&quot;&gt;Amin Babadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yi Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannala_J/0/1/0/all/0/1&quot;&gt;Juho Kannala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilin_A/0/1/0/all/0/1&quot;&gt;Alexander Ilin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1&quot;&gt;Joni Pajarinen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.02405">
<title>Inverting Cryptographic Hash Functions via Cube-and-Conquer. (arXiv:2212.02405v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2212.02405</link>
<description rdf:parseType="Literal">&lt;p&gt;MD4 and MD5 are seminal cryptographic hash functions proposed in early 1990s.
MD4 consists of 48 steps and produces a 128-bit hash given a message of
arbitrary finite size. MD5 is a more secure 64-step extension of MD4. Both MD4
and MD5 are vulnerable to practical collision attacks, yet it is still not
realistic to invert them, i.e. to find a message given a hash. In 2007, the
39-step version of MD4 was inverted via reducing to SAT and applying a CDCL
solver along with the so-called Dobbertin&apos;s constraints. As for MD5, in 2012
its 28-step version was inverted via a CDCL solver for one specified hash
without adding any additional constraints. In this study, Cube-and-Conquer (a
combination of CDCL and lookahead) is applied to invert step-reduced versions
of MD4 and MD5. For this purpose, two algorithms are proposed. The first one
generates inversion problems for MD4 by gradually modifying the Dobbertin&apos;s
constraints. The second algorithm tries the cubing phase of Cube-and-Conquer
with different cutoff thresholds to find the one with minimal runtime
estimation of the conquer phase. This algorithm operates in two modes: (i)
estimating the hardness of a given propositional Boolean formula; (ii)
incomplete SAT-solving of a given satisfiable propositional Boolean formula.
While the first algorithm is focused on inverting step-reduced MD4, the second
one is not area-specific and so is applicable to a variety of classes of hard
SAT instances. In this study, 40-, 41-, 42-, and 43-step MD4 are inverted for
the first time via the first algorithm and the estimating mode of the second
algorithm. 28-step MD5 is inverted for four hashes via the incomplete
SAT-solving mode of the second algorithm. For three hashes out of them this is
done for the first time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaikin_O/0/1/0/all/0/1&quot;&gt;Oleg Zaikin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.03181">
<title>Funnel-based Reward Shaping for Signal Temporal Logic Tasks in Reinforcement Learning. (arXiv:2212.03181v2 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2212.03181</link>
<description rdf:parseType="Literal">&lt;p&gt;Signal Temporal Logic (STL) is a powerful framework for describing the
complex temporal and logical behaviour of the dynamical system. Numerous
studies have attempted to employ reinforcement learning to learn a controller
that enforces STL specifications; however, they have been unable to effectively
tackle the challenges of ensuring robust satisfaction in continuous state space
and maintaining tractability. In this paper, leveraging the concept of funnel
functions, we propose a tractable reinforcement learning algorithm to learn a
time-dependent policy for robust satisfaction of STL specification in
continuous state space. We demonstrate the utility of our approach on several
STL tasks using different environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Saxena_N/0/1/0/all/0/1&quot;&gt;Naman Saxena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sandeep_G/0/1/0/all/0/1&quot;&gt;Gorantla Sandeep&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jagtap_P/0/1/0/all/0/1&quot;&gt;Pushpak Jagtap&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.13066">
<title>A Human Word Association based model for topic detection in social networks. (arXiv:2301.13066v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2301.13066</link>
<description rdf:parseType="Literal">&lt;p&gt;With the widespread use of social networks, detecting the topics discussed in
these networks has become a significant challenge. The current works are mainly
based on frequent pattern mining or semantic relations, and the language
structure is not considered. The meaning of language structural methods is to
discover the relationship between words and how humans understand them.
Therefore, this paper uses the Concept of the Imitation of the Mental Ability
of Word Association to propose a topic detection framework in social networks.
This framework is based on the Human Word Association method. A special
extraction algorithm has also been designed for this purpose. The performance
of this method is evaluated on the FA-CUP dataset. It is a benchmark dataset in
the field of topic detection. The results show that the proposed method is a
good improvement compared to other methods, based on the Topic-recall and the
keyword F1 measure. Also, most of the previous works in the field of topic
detection are limited to the English language, and the Persian language,
especially microblogs written in this language, is considered a low-resource
language. Therefore, a data set of Telegram posts in the Farsi language has
been collected. Applying the proposed method to this dataset also shows that
this method works better than other topic detection methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khadivi_M/0/1/0/all/0/1&quot;&gt;Mehrdad Ranjbar Khadivi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akbarpour_S/0/1/0/all/0/1&quot;&gt;Shahin Akbarpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1&quot;&gt;Mohammad-Reza Feizi-Derakhshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anari_B/0/1/0/all/0/1&quot;&gt;Babak Anari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.13816">
<title>Execution-based Code Generation using Deep Reinforcement Learning. (arXiv:2301.13816v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.13816</link>
<description rdf:parseType="Literal">&lt;p&gt;The utilization of programming language (PL) models, pre-trained on
large-scale code corpora, as a means of automating software engineering
processes has demonstrated considerable potential in streamlining various code
generation tasks such as code completion, code translation, and program
synthesis. However, current approaches mainly rely on supervised fine-tuning
objectives borrowed from text generation, neglecting unique sequence-level
characteristics of code, including but not limited to compilability as well as
syntactic and functional correctness. To address this limitation, we propose
PPOCoder, a new framework for code generation that synergistically combines
pre-trained PL models with Proximal Policy Optimization (PPO) which is a widely
used deep reinforcement learning technique. By utilizing non-differentiable
feedback from code execution and structure alignment, PPOCoder seamlessly
integrates external code-specific knowledge into the model optimization
process. It&apos;s important to note that PPOCoder is a task-agnostic and
model-agnostic framework that can be used across different code generation
tasks and PLs. Extensive experiments on three code generation tasks demonstrate
the effectiveness of our proposed approach compared to SOTA methods, achieving
significant improvements in compilation success rates and functional
correctness across different PLs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shojaee_P/0/1/0/all/0/1&quot;&gt;Parshin Shojaee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1&quot;&gt;Aneesh Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tipirneni_S/0/1/0/all/0/1&quot;&gt;Sindhu Tipirneni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1&quot;&gt;Chandan K. Reddy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.00270">
<title>Internally Rewarded Reinforcement Learning. (arXiv:2302.00270v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.00270</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a class of reinforcement learning problems where the reward signals
for policy learning are generated by a discriminator that is dependent on and
jointly optimized with the policy. This interdependence between the policy and
the discriminator leads to an unstable learning process because reward signals
from an immature discriminator are noisy and impede policy learning, and
conversely, an under-optimized policy impedes discriminator learning. We call
this learning setting \textit{Internally Rewarded Reinforcement Learning}
(IRRL) as the reward is not provided directly by the environment but
\textit{internally} by the discriminator. In this paper, we formally formulate
IRRL and present a class of problems that belong to IRRL. We theoretically
derive and empirically analyze the effect of the reward function in IRRL and
based on these analyses propose the clipped linear reward function.
Experimental results show that the proposed reward function can consistently
stabilize the training process by reducing the impact of reward noise, which
leads to faster convergence and higher performance compared with baselines in
diverse tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mengdi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xufeng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jae Hee Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1&quot;&gt;Cornelius Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.09775">
<title>Persian topic detection based on Human Word association and graph embedding. (arXiv:2302.09775v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2302.09775</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a framework to detect topics in social media based
on Human Word Association. Identifying topics discussed in these media has
become a critical and significant challenge. Most of the work done in this area
is in English, but much has been done in the Persian language, especially
microblogs written in Persian. Also, the existing works focused more on
exploring frequent patterns or semantic relationships and ignored the
structural methods of language. In this paper, a topic detection framework
using HWA, a method for Human Word Association, is proposed. This method uses
the concept of imitation of mental ability for word association. This method
also calculates the Associative Gravity Force that shows how words are related.
Using this parameter, a graph can be generated. The topics can be extracted by
embedding this graph and using clustering methods. This approach has been
applied to a Persian language dataset collected from Telegram. Several
experimental studies have been performed to evaluate the proposed framework&apos;s
performance. Experimental results show that this approach works better than
other topic detection methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranjbar_Khadivi_M/0/1/0/all/0/1&quot;&gt;Mehrdad Ranjbar-Khadivi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akbarpour_S/0/1/0/all/0/1&quot;&gt;Shahin Akbarpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1&quot;&gt;Mohammad-Reza Feizi-Derakhshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anari_B/0/1/0/all/0/1&quot;&gt;Babak Anari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.02401">
<title>Open-Vocabulary Affordance Detection in 3D Point Clouds. (arXiv:2303.02401v4 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2303.02401</link>
<description rdf:parseType="Literal">&lt;p&gt;Affordance detection is a challenging problem with a wide variety of robotic
applications. Traditional affordance detection methods are limited to a
predefined set of affordance labels, hence potentially restricting the
adaptability of intelligent robots in complex and dynamic environments. In this
paper, we present the Open-Vocabulary Affordance Detection (OpenAD) method,
which is capable of detecting an unbounded number of affordances in 3D point
clouds. By simultaneously learning the affordance text and the point feature,
OpenAD successfully exploits the semantic relationships between affordances.
Therefore, our proposed method enables zero-shot detection and can be able to
detect previously unseen affordances without a single annotation example.
Intensive experimental results show that OpenAD works effectively on a wide
range of affordance detection setups and outperforms other baselines by a large
margin. Additionally, we demonstrate the practicality of the proposed OpenAD in
real-world robotic applications with a fast inference speed (~100ms). Our
project is available at https://openad2023.github.io.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Toan Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vu_M/0/1/0/all/0/1&quot;&gt;Minh Nhat Vu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vuong_A/0/1/0/all/0/1&quot;&gt;An Vuong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Dzung Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vo_T/0/1/0/all/0/1&quot;&gt;Thieu Vo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1&quot;&gt;Ngan Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1&quot;&gt;Anh Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.05118">
<title>SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained Model. (arXiv:2303.05118v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.05118</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of continual learning is to improve the performance of recognition
models in learning sequentially arrived data. Although most existing works are
established on the premise of learning from scratch, growing efforts have been
devoted to incorporating the benefits of pre-training. However, how to
adaptively exploit the pre-trained knowledge for each incremental task while
maintaining its generalizability remains an open question. In this work, we
present an extensive analysis for continual learning on a pre-trained model
(CLPM), and attribute the key challenge to a progressive overfitting problem.
Observing that selectively reducing the learning rate can almost resolve this
issue in the representation layer, we propose a simple but extremely effective
approach named Slow Learner with Classifier Alignment (SLCA), which further
improves the classification layer by modeling the class-wise distributions and
aligning the classification layers in a post-hoc fashion. Across a variety of
scenarios, our proposal provides substantial improvements for CLPM (e.g., up to
49.76%, 50.05%, 44.69% and 40.16% on Split CIFAR-100, Split ImageNet-R, Split
CUB-200 and Split Cars-196, respectively), and thus outperforms
state-of-the-art approaches by a large margin. Based on such a strong baseline,
critical factors and promising directions are analyzed in-depth to facilitate
subsequent research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Gengwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liyuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1&quot;&gt;Guoliang Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Ling Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1&quot;&gt;Yunchao Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.02689">
<title>ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast. (arXiv:2304.02689v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.02689</link>
<description rdf:parseType="Literal">&lt;p&gt;Medical data often exhibits long-tail distributions with heavy class
imbalance, which naturally leads to difficulty in classifying the minority
classes (i.e., boundary regions or rare objects). Recent work has significantly
improved semi-supervised medical image segmentation in long-tailed scenarios by
equipping them with unsupervised contrastive criteria. However, it remains
unclear how well they will perform in the labeled portion of data where class
distribution is also highly imbalanced. In this work, we present ACTION++, an
improved contrastive learning framework with adaptive anatomical contrast for
semi-supervised medical segmentation. Specifically, we propose an adaptive
supervised contrastive loss, where we first compute the optimal locations of
class centers uniformly distributed on the embedding space (i.e., off-line),
and then perform online contrastive matching training by encouraging different
class features to adaptively match these distinct and uniformly distributed
class centers. Moreover, we argue that blindly adopting a constant temperature
$\tau$ in the contrastive loss on long-tailed medical data is not optimal, and
propose to use a dynamic $\tau$ via a simple cosine schedule to yield better
separation between majority and minority classes. Empirically, we evaluate
ACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art
across two semi-supervised settings. Theoretically, we analyze the performance
of adaptive anatomical contrast and confirm its superiority in label
efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1&quot;&gt;Chenyu You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1&quot;&gt;Weicheng Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1&quot;&gt;Yifei Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Staib_L/0/1/0/all/0/1&quot;&gt;Lawrence Staib&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sekhon_J/0/1/0/all/0/1&quot;&gt;Jasjeet S. Sekhon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duncan_J/0/1/0/all/0/1&quot;&gt;James S. Duncan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.03209">
<title>Implicit Anatomical Rendering for Medical Image Segmentation with Stochastic Experts. (arXiv:2304.03209v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.03209</link>
<description rdf:parseType="Literal">&lt;p&gt;Integrating high-level semantically correlated contents and low-level
anatomical features is of central importance in medical image segmentation.
Towards this end, recent deep learning-based medical segmentation methods have
shown great promise in better modeling such information. However, convolution
operators for medical segmentation typically operate on regular grids, which
inherently blur the high-frequency regions, i.e., boundary regions. In this
work, we propose MORSE, a generic implicit neural rendering framework designed
at an anatomical level to assist learning in medical image segmentation. Our
method is motivated by the fact that implicit neural representation has been
shown to be more effective in fitting complex signals and solving computer
graphics problems than discrete grid-based representation. The core of our
approach is to formulate medical image segmentation as a rendering problem in
an end-to-end manner. Specifically, we continuously align the coarse
segmentation prediction with the ambiguous coordinate-based point
representations and aggregate these features to adaptively refine the boundary
region. To parallelly optimize multi-scale pixel-level features, we leverage
the idea from Mixture-of-Expert (MoE) to design and train our MORSE with a
stochastic gating mechanism. Our experiments demonstrate that MORSE can work
well with different medical segmentation backbones, consistently achieving
competitive performance improvements in both 2D and 3D supervised medical
segmentation methods. We also theoretically analyze the superiority of MORSE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1&quot;&gt;Chenyu You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1&quot;&gt;Weicheng Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1&quot;&gt;Yifei Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Staib_L/0/1/0/all/0/1&quot;&gt;Lawrence Staib&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duncan_J/0/1/0/all/0/1&quot;&gt;James S. Duncan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.05560">
<title>Distributional Multi-Objective Decision Making. (arXiv:2305.05560v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2305.05560</link>
<description rdf:parseType="Literal">&lt;p&gt;For effective decision support in scenarios with conflicting objectives, sets
of potentially optimal solutions can be presented to the decision maker. We
explore both what policies these sets should contain and how such sets can be
computed efficiently. With this in mind, we take a distributional approach and
introduce a novel dominance criterion relating return distributions of policies
directly. Based on this criterion, we present the distributional undominated
set and show that it contains optimal policies otherwise ignored by the Pareto
front. In addition, we propose the convex distributional undominated set and
prove that it comprises all policies that maximise expected utility for
multivariate risk-averse decision makers. We propose a novel algorithm to learn
the distributional undominated set and further contribute pruning operators to
reduce the set to the convex distributional undominated set. Through
experiments, we demonstrate the feasibility and effectiveness of these methods,
making this a valuable new approach for decision support in real-world
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ropke_W/0/1/0/all/0/1&quot;&gt;Willem R&amp;#xf6;pke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayes_C/0/1/0/all/0/1&quot;&gt;Conor F. Hayes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannion_P/0/1/0/all/0/1&quot;&gt;Patrick Mannion&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howley_E/0/1/0/all/0/1&quot;&gt;Enda Howley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nowe_A/0/1/0/all/0/1&quot;&gt;Ann Now&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roijers_D/0/1/0/all/0/1&quot;&gt;Diederik M. Roijers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.07617">
<title>Scalable Coupling of Deep Learning with Logical Reasoning. (arXiv:2305.07617v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2305.07617</link>
<description rdf:parseType="Literal">&lt;p&gt;In the ongoing quest for hybridizing discrete reasoning with neural nets,
there is an increasing interest in neural architectures that can learn how to
solve discrete reasoning or optimization problems from natural inputs. In this
paper, we introduce a scalable neural architecture and loss function dedicated
to learning the constraints and criteria of NP-hard reasoning problems
expressed as discrete Graphical Models. Our loss function solves one of the
main limitations of Besag&apos;s pseudo-loglikelihood, enabling learning of high
energies. We empirically show it is able to efficiently learn how to solve
NP-hard reasoning problems from natural inputs as the symbolic, visual or
many-solutions Sudoku problems as well as the energy optimization formulation
of the protein design problem, providing data efficiency, interpretability, and
\textit{a posteriori} control over predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Defresne_M/0/1/0/all/0/1&quot;&gt;Marianne Defresne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbe_S/0/1/0/all/0/1&quot;&gt;Sophie Barbe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schiex_T/0/1/0/all/0/1&quot;&gt;Thomas Schiex&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.09378">
<title>Capturing Emerging Complexity in Lenia. (arXiv:2305.09378v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/2305.09378</link>
<description rdf:parseType="Literal">&lt;p&gt;This research project investigates Lenia, an artificial life platform that
simulates ecosystems of digital creatures. Lenia&apos;s ecosystem consists of
simple, artificial organisms that can move, consume, grow, and reproduce. The
platform is important as a tool for studying artificial life and evolution, as
it provides a scalable and flexible environment for creating a diverse range of
organisms with varying abilities and behaviors. Measuring complexity in Lenia
is a key aspect of the study, which identifies the metrics for measuring
long-term complex emerging behavior of rules, with the aim of evolving better
Lenia behaviors which are yet not discovered. The Genetic Algorithm uses
neighborhoods or kernels as genotype while keeping the rest of the parameters
of Lenia as fixed, for example growth function, to produce different behaviors
respective to the population and then measures fitness value to decide the
complexity of the resulting behavior. First, we use Variation over Time as a
fitness function where higher variance between the frames are rewarded. Second,
we use Auto-encoder based fitness where variation of the list of reconstruction
loss for the frames is rewarded. Third, we perform combined fitness where
higher variation of the pixel density of reconstructed frames is rewarded. All
three experiments are tweaked with pixel alive threshold and frames used.
Finally, after performing nine experiments of each fitness for 500 generations,
we pick configurations from all experiments such that there is a scope of
further evolution, and run it for 2500 generations. Results show that the
kernel&apos;s center of mass increases with a specific set of pixels and together
with borders the kernel try to achieve a Gaussian distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1&quot;&gt;Sanyam Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrestha_A/0/1/0/all/0/1&quot;&gt;Aarati Shrestha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nichele_S/0/1/0/all/0/1&quot;&gt;Stefano Nichele&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.11997">
<title>Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees. (arXiv:2305.11997v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2305.11997</link>
<description rdf:parseType="Literal">&lt;p&gt;There is an emerging interest in generating robust counterfactual
explanations that would remain valid if the model is updated or changed even
slightly. Towards finding robust counterfactuals, existing literature often
assumes that the original model $m$ and the new model $M$ are bounded in the
parameter space, i.e., $\|\text{Params}(M){-}\text{Params}(m)\|{&amp;lt;}\Delta$.
However, models can often change significantly in the parameter space with
little to no change in their predictions or accuracy on the given dataset. In
this work, we introduce a mathematical abstraction termed
\emph{naturally-occurring} model change, which allows for arbitrary changes in
the parameter space such that the change in predictions on points that lie on
the data manifold is limited. Next, we propose a measure -- that we call
\emph{Stability} -- to quantify the robustness of counterfactuals to potential
model changes for differentiable models, e.g., neural networks. Our main
contribution is to show that counterfactuals with sufficiently high value of
\emph{Stability} as defined by our measure will remain valid after potential
``naturally-occurring&apos;&apos; model changes with high probability (leveraging
concentration bounds for Lipschitz function of independent Gaussians). Since
our quantification depends on the local Lipschitz constant around a data point
which is not always available, we also examine practical relaxations of our
proposed measure and demonstrate experimentally how they can be incorporated to
find robust counterfactuals for neural networks that are close, realistic, and
remain valid after potential model changes. This work also has interesting
connections with model multiplicity, also known as, the Rashomon effect.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hamman_F/0/1/0/all/0/1&quot;&gt;Faisal Hamman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Noorani_E/0/1/0/all/0/1&quot;&gt;Erfaun Noorani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mishra_S/0/1/0/all/0/1&quot;&gt;Saumitra Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Magazzeni_D/0/1/0/all/0/1&quot;&gt;Daniele Magazzeni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dutta_S/0/1/0/all/0/1&quot;&gt;Sanghamitra Dutta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12421">
<title>Evaluating Open-QA Evaluation. (arXiv:2305.12421v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12421</link>
<description rdf:parseType="Literal">&lt;p&gt;This study focuses on the evaluation of the Open Question Answering (Open-QA)
task, which can directly estimate the factuality of large language models
(LLMs). Current automatic evaluation methods have shown limitations, indicating
that human evaluation still remains the most reliable approach. We introduce a
new task, Evaluating QA Evaluation (QA-Eval) and the corresponding dataset
EVOUNA, designed to assess the accuracy of AI-generated answers in relation to
standard answers within Open-QA. Our evaluation of these methods utilizes
human-annotated results to measure their performance. Specifically, the work
investigates methods that show high correlation with human evaluations, deeming
them more reliable. We also discuss the pitfalls of current methods and methods
to improve LLM-based evaluators. We believe this new QA-Eval task and
corresponding dataset EVOUNA will facilitate the development of more effective
automatic evaluation tools and prove valuable for future research in this area.
All resources are available at \url{https://github.com/wangcunxiang/QA-Eval}
and it is under the Apache-2.0 License.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Cunxiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Sirui Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1&quot;&gt;Qipeng Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhikun Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1&quot;&gt;Bowen Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yidong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xiangkun Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yue Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13115">
<title>Causal-Based Supervision of Attention in Graph Neural Network: A Better and Simpler Choice towards Powerful Attention. (arXiv:2305.13115v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13115</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed the great potential of attention mechanism in
graph representation learning. However, while variants of attention-based GNNs
are setting new benchmarks for numerous real-world datasets, recent works have
pointed out that their induced attentions are less robust and generalizable
against noisy graphs due to lack of direct supervision. In this paper, we
present a new framework which utilizes the tool of causality to provide a
powerful supervision signal for the learning process of attention functions.
Specifically, we estimate the direct causal effect of attention to the final
prediction, and then maximize such effect to guide attention attending to more
meaningful neighbors. Our method can serve as a plug-and-play module for any
canonical attention-based GNNs in an end-to-end fashion. Extensive experiments
on a wide range of benchmark datasets illustrated that, by directly supervising
attention functions, the model is able to converge faster with a clearer
decision boundary, and thus yields better performances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongjun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1&quot;&gt;Lun Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1&quot;&gt;Qiang Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Shi Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1&quot;&gt;Xuan Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.16044">
<title>Exploiting Noise as a Resource for Computation and Learning in Spiking Neural Networks. (arXiv:2305.16044v5 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/2305.16044</link>
<description rdf:parseType="Literal">&lt;p&gt;Networks of spiking neurons underpin the extraordinary information-processing
capabilities of the brain and have become pillar models in neuromorphic
artificial intelligence. Despite extensive research on spiking neural networks
(SNNs), most studies are established on deterministic models, overlooking the
inherent non-deterministic, noisy nature of neural computations. This study
introduces the noisy spiking neural network (NSNN) and the noise-driven
learning rule (NDL) by incorporating noisy neuronal dynamics to exploit the
computational advantages of noisy neural processing. NSNN provides a
theoretical framework that yields scalable, flexible, and reliable computation.
We demonstrate that NSNN leads to spiking neural models with competitive
performance, improved robustness against challenging perturbations than
deterministic SNNs, and better reproducing probabilistic neural computation in
neural coding. This study offers a powerful and easy-to-use tool for machine
learning, neuromorphic intelligence practitioners, and computational
neuroscience researchers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1&quot;&gt;Gehua Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1&quot;&gt;Rui Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Huajin Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.05439">
<title>Contrastive Representation Disentanglement for Clustering. (arXiv:2306.05439v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.05439</link>
<description rdf:parseType="Literal">&lt;p&gt;Clustering continues to be a significant and challenging task. Recent studies
have demonstrated impressive results by applying clustering to feature
representations acquired through self-supervised learning, particularly on
small datasets. However, when dealing with datasets containing a large number
of clusters, such as ImageNet, current methods struggle to achieve satisfactory
clustering performance. In this paper, we introduce a novel method called
Contrastive representation Disentanglement for Clustering (CDC) that leverages
contrastive learning to directly disentangle the feature representation for
clustering. In CDC, we decompose the representation into two distinct
components: one component encodes categorical information under an
equipartition constraint, and the other component captures instance-specific
factors. To train our model, we propose a contrastive loss that effectively
utilizes both components of the representation. We conduct a theoretical
analysis of the proposed loss and highlight how it assigns different weights to
negative samples during the process of disentangling the feature
representation. Further analysis of the gradients reveals that larger weights
emphasize a stronger focus on hard negative samples. As a result, the proposed
loss exhibits strong expressiveness, enabling efficient disentanglement of
categorical information. Through experimental evaluation on various benchmark
datasets, our method demonstrates either state-of-the-art or highly competitive
clustering performance. Notably, on the complete ImageNet dataset, we achieve
an accuracy of 53.4%, surpassing existing methods by a substantial margin of
+10.2%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1&quot;&gt;Fei Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krovi_V/0/1/0/all/0/1&quot;&gt;Venkat Krovi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1&quot;&gt;Feng Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.09662">
<title>Cooperative Multi-Objective Reinforcement Learning for Traffic Signal Control and Carbon Emission Reduction. (arXiv:2306.09662v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.09662</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing traffic signal control systems rely on oversimplified rule-based
methods, and even RL-based methods are often suboptimal and unstable. To
address this, we propose a cooperative multi-objective architecture called
Multi-Objective Multi-Agent Deep Deterministic Policy Gradient (MOMA-DDPG),
which estimates multiple reward terms for traffic signal control optimization
using age-decaying weights. Our approach involves two types of agents: one
focuses on optimizing local traffic at each intersection, while the other aims
to optimize global traffic throughput. We evaluate our method using real-world
traffic data collected from an Asian country&apos;s traffic cameras. Despite the
inclusion of a global agent, our solution remains decentralized as this agent
is no longer necessary during the inference stage. Our results demonstrate the
effectiveness of MOMA-DDPG, outperforming state-of-the-art methods across all
performance metrics. Additionally, our proposed system minimizes both waiting
time and carbon emissions. Notably, this paper is the first to link carbon
emissions and global agents in traffic signal control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1&quot;&gt;Cheng Ruei Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_J/0/1/0/all/0/1&quot;&gt;Jun Wei Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teng_S/0/1/0/all/0/1&quot;&gt;Shin You Teng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.15656">
<title>SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate via Compiler Co-design. (arXiv:2306.15656v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.15656</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces SparseOptimizer, a novel deep learning optimizer that
exploits Moreau-Yosida regularization to naturally induce sparsity in large
language models such as BERT, ALBERT and GPT. Key to the design of
SparseOptimizer is an embedded shrinkage operator, which imparts sparsity
directly within the optimization process. This operator, backed by a sound
theoretical framework, includes an analytical solution, thereby reinforcing the
optimizer&apos;s robustness and efficacy. Crucially, SparseOptimizer&apos;s plug-and-play
functionality eradicates the need for code modifications, making it a
universally adaptable tool for a wide array of large language models. Empirical
evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2
confirm that SparseBERT and SparseALBERT, when sparsified using
SparseOptimizer, achieve performance comparable to their dense counterparts,
BERT and ALBERT, while significantly reducing their parameter count. Further,
this work proposes an innovative optimizer-compiler co-design strategy,
demonstrating the potential of inference acceleration (\textbf{3.37x},
\textbf{6.30x}, and \textbf{7.15x} in comparison with Pytorch, TensorFlow, and
LLVM generic compile, respectively) in SparseBERT when paired with an
appropriately designed compiler. This study represents a significant step
forward in the evolution of efficient, scalable, and high-performing large
language models, setting a precedent for future exploration and optimization in
this domain. The SparseOptimizer code and SparseALBERT model will be publicly
available upon paper acceptance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1&quot;&gt;Fu-Ming Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.15788">
<title>Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correction for Brazilian Portuguese. (arXiv:2306.15788v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2306.15788</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the effectiveness of GPT-3.5 and GPT-4, two large language
models, as Grammatical Error Correction (GEC) tools for Brazilian Portuguese
and compare their performance against Microsoft Word and Google Docs. We
introduce a GEC dataset for Brazilian Portuguese with four categories: Grammar,
Spelling, Internet, and Fast typing. Our results show that while GPT-4 has
higher recall than other methods, LLMs tend to have lower precision, leading to
overcorrection. This study demonstrates the potential of LLMs as practical GEC
tools for Brazilian Portuguese and encourages further exploration of LLMs for
non-English languages and other educational settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Penteado_M/0/1/0/all/0/1&quot;&gt;Maria Carolina Penteado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_F/0/1/0/all/0/1&quot;&gt;F&amp;#xe1;bio Perez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00497">
<title>Don&apos;t Memorize; Mimic The Past: Federated Class Incremental Learning Without Episodic Memory. (arXiv:2307.00497v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.00497</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models are prone to forgetting information learned in the past
when trained on new data. This problem becomes even more pronounced in the
context of federated learning (FL), where data is decentralized and subject to
independent changes for each user. Continual Learning (CL) studies this
so-called \textit{catastrophic forgetting} phenomenon primarily in centralized
settings, where the learner has direct access to the complete training dataset.
However, applying CL techniques to FL is not straightforward due to privacy
concerns and resource limitations. This paper presents a framework for
federated class incremental learning that utilizes a generative model to
synthesize samples from past distributions instead of storing part of past
data. Then, clients can leverage the generative model to mitigate catastrophic
forgetting locally. The generative model is trained on the server using
data-free methods at the end of each task without requesting data from clients.
Therefore, it reduces the risk of data leakage as opposed to training it on the
client&apos;s private data. We demonstrate significant improvements for the
CIFAR-100 dataset compared to existing baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babakniya_S/0/1/0/all/0/1&quot;&gt;Sara Babakniya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fabian_Z/0/1/0/all/0/1&quot;&gt;Zalan Fabian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1&quot;&gt;Chaoyang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1&quot;&gt;Mahdi Soltanolkotabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1&quot;&gt;Salman Avestimehr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02839">
<title>Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation. (arXiv:2307.02839v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02839</link>
<description rdf:parseType="Literal">&lt;p&gt;News summary generation is an important task in the field of intelligence
analysis, which can provide accurate and comprehensive information to help
people better understand and respond to complex real-world events. However,
traditional news summary generation methods face some challenges, which are
limited by the model itself and the amount of training data, as well as the
influence of text noise, making it difficult to generate reliable information
accurately. In this paper, we propose a new paradigm for news summary
generation using LLM with powerful natural language understanding and
generative capabilities. We use LLM to extract multiple structured event
patterns from the events contained in news paragraphs, evolve the event pattern
population with genetic algorithm, and select the most adaptive event pattern
to input into the LLM to generate news summaries. A News Summary Generator
(NSG) is designed to select and evolve the event pattern populations and
generate news summaries. The experimental results show that the news summary
generator is able to generate accurate and reliable news summaries with some
generalization ability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1&quot;&gt;Le Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiaolin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.03109">
<title>A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v5 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.03109</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) are gaining increasing popularity in both
academia and industry, owing to their unprecedented performance in various
applications. As LLMs continue to play a vital role in both research and daily
use, their evaluation becomes increasingly critical, not only at the task
level, but also at the society level for better understanding of their
potential risks. Over the past years, significant efforts have been made to
examine LLMs from various perspectives. This paper presents a comprehensive
review of these evaluation methods for LLMs, focusing on three key dimensions:
what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide
an overview from the perspective of evaluation tasks, encompassing general
natural language processing tasks, reasoning, medical usage, ethics,
educations, natural and social sciences, agent applications, and other areas.
Secondly, we answer the `where&apos; and `how&apos; questions by diving into the
evaluation methods and benchmarks, which serve as crucial components in
assessing performance of LLMs. Then, we summarize the success and failure cases
of LLMs in different tasks. Finally, we shed light on several future challenges
that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to
researchers in the realm of LLMs evaluation, thereby aiding the development of
more proficient LLMs. Our key point is that evaluation should be treated as an
essential discipline to better assist the development of LLMs. We consistently
maintain the related open-source materials at:
https://github.com/MLGroupJLU/LLM-eval-survey.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yupeng Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yuan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1&quot;&gt;Kaijie Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Linyi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1&quot;&gt;Xiaoyuan Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Cunxiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yidong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1&quot;&gt;Wei Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yue Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yi Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.04550">
<title>Gradient Surgery for One-shot Unlearning on Generative Model. (arXiv:2307.04550v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.04550</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent regulation on right-to-be-forgotten emerges tons of interest in
unlearning pre-trained machine learning models. While approximating a
straightforward yet expensive approach of retrain-from-scratch, recent machine
unlearning methods unlearn a sample by updating weights to remove its influence
on the weight parameters. In this paper, we introduce a simple yet effective
approach to remove a data influence on the deep generative model. Inspired by
works in multi-task learning, we propose to manipulate gradients to regularize
the interplay of influence among samples by projecting gradients onto the
normal plane of the gradients to be retained. Our work is agnostic to
statistics of the removal samples, outperforming existing baselines while
providing theoretical analysis for the first time in unlearning a generative
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1&quot;&gt;Seohui Bae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seoyoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1&quot;&gt;Hyemin Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_W/0/1/0/all/0/1&quot;&gt;Woohyung Lim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.04964">
<title>Secrets of RLHF in Large Language Models Part I: PPO. (arXiv:2307.04964v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.04964</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have formulated a blueprint for the advancement
of artificial general intelligence. Its primary objective is to function as a
human-centric (helpful, honest, and harmless) assistant. Alignment with humans
assumes paramount significance, and reinforcement learning with human feedback
(RLHF) emerges as the pivotal technological paradigm underpinning this pursuit.
Current technical routes usually include \textbf{reward models} to measure
human preferences, \textbf{Proximal Policy Optimization} (PPO) to optimize
policy model outputs, and \textbf{process supervision} to improve step-by-step
reasoning capabilities. However, due to the challenges of reward design,
environment interaction, and agent training, coupled with huge trial and error
cost of large language models, there is a significant barrier for AI
researchers to motivate the development of technical alignment and safe landing
of LLMs. The stable training of RLHF has still been a puzzle. In the first
report, we dissect the framework of RLHF, re-evaluate the inner workings of
PPO, and explore how the parts comprising PPO algorithms impact policy agent
training. We identify policy constraints being the key factor for the effective
implementation of the PPO algorithm. Therefore, we explore the PPO-max, an
advanced version of PPO algorithm, to efficiently improve the training
stability of the policy model. Based on our main results, we perform a
comprehensive analysis of RLHF abilities compared with SFT models and ChatGPT.
The absence of open-source implementations has posed significant challenges to
the investigation of LLMs alignment. Therefore, we are eager to release
technical reports, reward models and PPO codes, aiming to make modest
contributions to the advancement of LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1&quot;&gt;Rui Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1&quot;&gt;Shihan Dou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Songyang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1&quot;&gt;Yuan Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1&quot;&gt;Wei Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Binghai Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1&quot;&gt;Senjie Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuhao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1&quot;&gt;Limao Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1&quot;&gt;Zhiheng Xi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1&quot;&gt;Nuo Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1&quot;&gt;Wenbin Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Minghao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1&quot;&gt;Cheng Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zhangyue Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_R/0/1/0/all/0/1&quot;&gt;Rongxiang Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1&quot;&gt;Wensen Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Haoran Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tianxiang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1&quot;&gt;Hang Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1&quot;&gt;Tao Gui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1&quot;&gt;Xipeng Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xuanjing Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.07250">
<title>Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning. (arXiv:2307.07250v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.07250</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples derived from deliberately crafted perturbations on
visual inputs can easily harm decision process of deep neural networks. To
prevent potential threats, various adversarial training-based defense methods
have grown rapidly and become a de facto standard approach for robustness.
Despite recent competitive achievements, we observe that adversarial
vulnerability varies across targets and certain vulnerabilities remain
prevalent. Intriguingly, such peculiar phenomenon cannot be relieved even with
deeper architectures and advanced defense methods. To address this issue, in
this paper, we introduce a causal approach called Adversarial Double Machine
Learning (ADML), which allows us to quantify the degree of adversarial
vulnerability for network predictions and capture the effect of treatments on
outcome of interests. ADML can directly estimate causal parameter of
adversarial perturbations per se and mitigate negative effects that can
potentially damage robustness, bridging a causal perspective into the
adversarial vulnerability. Through extensive experiments on various CNN and
Transformer architectures, we corroborate that ADML improves adversarial
robustness with large margins and relieve the empirical observation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1&quot;&gt;Byung-Kwan Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junho Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ro_Y/0/1/0/all/0/1&quot;&gt;Yong Man Ro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.07754">
<title>Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer. (arXiv:2307.07754v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.07754</link>
<description rdf:parseType="Literal">&lt;p&gt;Video-based human pose transfer is a video-to-video generation task that
animates a plain source human image based on a series of target human poses.
Considering the difficulties in transferring highly structural patterns on the
garments and discontinuous poses, existing methods often generate
unsatisfactory results such as distorted textures and flickering artifacts. To
address these issues, we propose a novel Deformable Motion Modulation (DMM)
that utilizes geometric kernel offset with adaptive weight modulation to
simultaneously perform feature alignment and style transfer. Different from
normal style modulation used in style transfer, the proposed modulation
mechanism adaptively reconstructs smoothed frames from style codes according to
the object shape through an irregular receptive field of view. To enhance the
spatio-temporal consistency, we leverage bidirectional propagation to extract
the hidden motion information from a warped image sequence generated by noisy
poses. The proposed feature propagation significantly enhances the motion
prediction ability by forward and backward propagation. Both quantitative and
qualitative experimental results demonstrate superiority over the
state-of-the-arts in terms of image fidelity and visual continuity. The source
code is publicly available at github.com/rocketappslab/bdmm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wing-Yin Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Po_L/0/1/0/all/0/1&quot;&gt;Lai-Man Po&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_R/0/1/0/all/0/1&quot;&gt;Ray C.C. Cheung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yuzhi Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1&quot;&gt;Yu Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kun Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.07909">
<title>Is Imitation All You Need? Generalized Decision-Making with Dual-Phase Training. (arXiv:2307.07909v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2307.07909</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce DualMind, a generalist agent designed to tackle various
decision-making tasks that addresses challenges posed by current methods, such
as overfitting behaviors and dependence on task-specific fine-tuning. DualMind
uses a novel &quot;Dual-phase&quot; training strategy that emulates how humans learn to
act in the world. The model first learns fundamental common knowledge through a
self-supervised objective tailored for control tasks and then learns how to
make decisions based on different contexts through imitating behaviors
conditioned on given prompts. DualMind can handle tasks across domains, scenes,
and embodiments using just a single set of model weights and can execute
zero-shot prompting without requiring task-specific fine-tuning. We evaluate
DualMind on MetaWorld and Habitat through extensive experiments and demonstrate
its superior generalizability compared to previous techniques, outperforming
other generalist agents by over 50$\%$ and 70$\%$ on Habitat and MetaWorld,
respectively. On the 45 tasks in MetaWorld, DualMind achieves over 30 tasks at
a 90$\%$ success rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1&quot;&gt;Yao Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanchao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1&quot;&gt;Ruijie Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vemprala_S/0/1/0/all/0/1&quot;&gt;Sai Vemprala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonatti_R/0/1/0/all/0/1&quot;&gt;Rogerio Bonatti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shuhang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madaan_R/0/1/0/all/0/1&quot;&gt;Ratnesh Madaan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ba_Z/0/1/0/all/0/1&quot;&gt;Zhongjie Ba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapoor_A/0/1/0/all/0/1&quot;&gt;Ashish Kapoor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shuang Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08087">
<title>A Recursive Bateson-Inspired Model for the Generation of Semantic Formal Concepts from Spatial Sensory Data. (arXiv:2307.08087v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08087</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural-symbolic approaches to machine learning incorporate the advantages
from both connectionist and symbolic methods. Typically, these models employ a
first module based on a neural architecture to extract features from complex
data. Then, these features are processed as symbols by a symbolic engine that
provides reasoning, concept structures, composability, better generalization
and out-of-distribution learning among other possibilities. However, neural
approaches to the grounding of symbols in sensory data, albeit powerful, still
require heavy training and tedious labeling for the most part. This paper
presents a new symbolic-only method for the generation of hierarchical concept
structures from complex spatial sensory data. The approach is based on
Bateson&apos;s notion of difference as the key to the genesis of an idea or a
concept. Following his suggestion, the model extracts atomic features from raw
data by computing elemental sequential comparisons in a stream of multivariate
numerical values. Higher-level constructs are built from these features by
subjecting them to further comparisons in a recursive process. At any stage in
the recursion, a concept structure may be obtained from these constructs and
features by means of Formal Concept Analysis. Results show that the model is
able to produce fairly rich yet human-readable conceptual representations
without training. Additionally, the concept structures obtained through the
model (i) present high composability, which potentially enables the generation
of &apos;unseen&apos; concepts, (ii) allow formal reasoning, and (iii) have inherent
abilities for generalization and out-of-distribution learning. Consequently,
this method may offer an interesting angle to current neural-symbolic research.
Future work is required to develop a training methodology so that the model can
be tested against a larger dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miguel_Rodriguez_J/0/1/0/all/0/1&quot;&gt;Jaime de Miguel-Rodriguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sancho_Caparrini_F/0/1/0/all/0/1&quot;&gt;Fernando Sancho-Caparrini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08424">
<title>Unstoppable Attack: Label-Only Model Inversion via Conditional Diffusion Model. (arXiv:2307.08424v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08424</link>
<description rdf:parseType="Literal">&lt;p&gt;Model inversion attacks (MIAs) are aimed at recovering private data from a
target model&apos;s training set, which poses a threat to the privacy of deep
learning models. MIAs primarily focus on the white-box scenario where the
attacker has full access to the structure and parameters of the target model.
However, practical applications are black-box, it is not easy for adversaries
to obtain model-related parameters, and various models only output predicted
labels. Existing black-box MIAs primarily focused on designing the optimization
strategy, and the generative model is only migrated from the GAN used in
white-box MIA. Our research is the pioneering study of feasible attack models
in label-only black-box scenarios, to the best of our knowledge.
&lt;/p&gt;
&lt;p&gt;In this paper, we develop a novel method of MIA using the conditional
diffusion model to recover the precise sample of the target without any extra
optimization, as long as the target model outputs the label. Two primary
techniques are introduced to execute the attack. Firstly, select an auxiliary
dataset that is relevant to the target model task, and the labels predicted by
the target model are used as conditions to guide the training process.
Secondly, target labels and random standard normally distributed noise are
input into the trained conditional diffusion model, generating target samples
with pre-defined guidance strength. We then filter out the most robust and
representative samples. Furthermore, we propose for the first time to use
Learned Perceptual Image Patch Similarity (LPIPS) as one of the evaluation
metrics for MIA, with systematic quantitative and qualitative evaluation in
terms of attack accuracy, realism, and similarity. Experimental results show
that this method can generate similar and accurate data to the target without
optimization and outperforms generators of previous approaches in the
label-only scenario.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Rongke Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08481">
<title>Derivation-Graph-Based Characterizations of Decidable Existential Rule Sets. (arXiv:2307.08481v2 [cs.LO] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08481</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper establishes alternative characterizations of very expressive
classes of existential rule sets with decidable query entailment. We consider
the notable class of greedy bounded-treewidth sets (gbts) and a new,
generalized variant, called weakly gbts (wgbts). Revisiting and building on the
notion of derivation graphs, we define (weakly) cycle-free derivation graph
sets ((w)cdgs) and employ elaborate proof-theoretic arguments to obtain that
gbts and cdgs coincide, as do wgbts and wcdgs. These novel characterizations
advance our analytic proof-theoretic understanding of existential rules and
will likely be instrumental in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyon_T/0/1/0/all/0/1&quot;&gt;Tim S. Lyon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudolph_S/0/1/0/all/0/1&quot;&gt;Sebastian Rudolph&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08533">
<title>Nonlinear Processing with Linear Optics. (arXiv:2307.08533v2 [physics.optics] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08533</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have achieved remarkable breakthroughs by leveraging
multiple layers of data processing to extract hidden representations, albeit at
the cost of large electronic computing power. To enhance energy efficiency and
speed, the optical implementation of neural networks aims to harness the
advantages of optical bandwidth and the energy efficiency of optical
interconnections. In the absence of low-power optical nonlinearities, the
challenge in the implementation of multilayer optical networks lies in
realizing multiple optical layers without resorting to electronic components.
In this study, we present a novel framework that uses multiple scattering that
is capable of synthesizing programmable linear and nonlinear transformations
concurrently at low optical power by leveraging the nonlinear relationship
between the scattering potential, represented by data, and the scattered field.
Theoretical and experimental investigations show that repeating the data by
multiple scattering enables non-linear optical computing at low power
continuous wave light.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yildirim_M/0/1/0/all/0/1&quot;&gt;Mustafa Yildirim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Dinc_N/0/1/0/all/0/1&quot;&gt;Niyazi Ulas Dinc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Oguz_I/0/1/0/all/0/1&quot;&gt;Ilker Oguz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Psaltis_D/0/1/0/all/0/1&quot;&gt;Demetri Psaltis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Moser_C/0/1/0/all/0/1&quot;&gt;Christophe Moser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08671">
<title>Deep Cross-Modal Steganography Using Neural Representations. (arXiv:2307.08671v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08671</link>
<description rdf:parseType="Literal">&lt;p&gt;Steganography is the process of embedding secret data into another message or
data, in such a way that it is not easily noticeable. With the advancement of
deep learning, Deep Neural Networks (DNNs) have recently been utilized in
steganography. However, existing deep steganography techniques are limited in
scope, as they focus on specific data types and are not effective for
cross-modal steganography. Therefore, We propose a deep cross-modal
steganography framework using Implicit Neural Representations (INRs) to hide
secret data of various formats in cover images. The proposed framework employs
INRs to represent the secret data, which can handle data of various modalities
and resolutions. Experiments on various secret datasets of diverse types
demonstrate that the proposed approach is expandable and capable of
accommodating different modalities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_G/0/1/0/all/0/1&quot;&gt;Gyojin Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Dong-Jae Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hur_J/0/1/0/all/0/1&quot;&gt;Jiwan Hur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jaehyun Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junmo Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08674">
<title>TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT. (arXiv:2307.08674v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08674</link>
<description rdf:parseType="Literal">&lt;p&gt;Tables are prevalent in real-world databases, requiring significant time and
effort for humans to analyze and manipulate. The advancements in large language
models (LLMs) have made it possible to interact with tables using natural
language input, bringing this capability closer to reality. In this paper, we
present TableGPT, a unified fine-tuned framework that enables LLMs to
understand and operate on tables using external functional commands. It
introduces the capability to seamlessly interact with tables, enabling a wide
range of functionalities such as question answering, data manipulation (e.g.,
insert, delete, query, and modify operations), data visualization, analysis
report generation, and automated prediction. TableGPT aims to provide
convenience and accessibility to users by empowering them to effortlessly
leverage tabular data. At the core of TableGPT lies the novel concept of global
tabular representations, which empowers LLMs to gain a comprehensive
understanding of the entire table beyond meta-information. By jointly training
LLMs on both table and text modalities, TableGPT achieves a deep understanding
of tabular data and the ability to perform complex operations on tables through
chain-of-command instructions. Importantly, TableGPT offers the advantage of
being a self-contained system rather than relying on external API interfaces.
Moreover, it supports efficient data process flow, query rejection (when
appropriate) and private deployment, enabling faster domain data fine-tuning
and ensuring data privacy, which enhances the framework&apos;s adaptability to
specific use cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_L/0/1/0/all/0/1&quot;&gt;Liangyu Zha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Junlin Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Liyao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Rui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qingyi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Saisai Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1&quot;&gt;Jing Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1&quot;&gt;Changbao Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_A/0/1/0/all/0/1&quot;&gt;Aofeng Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1&quot;&gt;Chen Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shou_K/0/1/0/all/0/1&quot;&gt;Kaizhe Shou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Miao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wufang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1&quot;&gt;Guoshan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_C/0/1/0/all/0/1&quot;&gt;Chao Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yali Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1&quot;&gt;Wentao Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yiming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1&quot;&gt;Xinglong Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jie Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haobo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1&quot;&gt;Gang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Junbo Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.13697">
<title>FedFormer: Contextual Federation with Attention in Reinforcement Learning. (arXiv:2205.13697v3 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2205.13697</link>
<description rdf:parseType="Literal">&lt;p&gt;A core issue in multi-agent federated reinforcement learning is defining how
to aggregate insights from multiple agents. This is commonly done by taking the
average of each participating agent&apos;s model weights into one common model
(FedAvg). We instead propose FedFormer, a novel federation strategy that
utilizes Transformer Attention to contextually aggregate embeddings from models
originating from different learner agents. In so doing, we attentively weigh
the contributions of other agents with respect to the current agent&apos;s
environment and learned relationships, thus providing a more effective and
efficient federation. We evaluate our methods on the Meta-World environment and
find that our approach yields significant improvements over FedAvg and
non-federated Soft Actor-Critic single-agent methods. Our results compared to
Soft Actor-Critic show that FedFormer achieves higher episodic return while
still abiding by the privacy constraints of federated learning. Finally, we
also demonstrate improvements in effectiveness with increased agent pools
across all methods in certain tasks. This is contrasted by FedAvg, which fails
to make noticeable improvements when scaled.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hebert_L/0/1/0/all/0/1&quot;&gt;Liam Hebert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golab_L/0/1/0/all/0/1&quot;&gt;Lukasz Golab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1&quot;&gt;Pascal Poupart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_R/0/1/0/all/0/1&quot;&gt;Robin Cohen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.10224">
<title>Bloated Disclosures: Can ChatGPT Help Investors Process Financial Information?. (arXiv:2306.10224v1 [econ.GN] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2306.10224</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative AI tools such as ChatGPT can fundamentally change the way
investors process information. We probe the economic usefulness of these tools
in summarizing complex corporate disclosures using the stock market as a
laboratory. The unconstrained summaries are dramatically shorter, often by more
than 70% compared to the originals, whereas their information content is
amplified. When a document has a positive (negative) sentiment, its summary
becomes more positive (negative). More importantly, the summaries are more
effective at explaining stock market reactions to the disclosed information.
Motivated by these findings, we propose a measure of information &quot;bloat.&quot; We
show that bloated disclosure is associated with adverse capital markets
consequences, such as lower price efficiency and higher information asymmetry.
Finally, we show that the model is effective at constructing targeted summaries
that identify firms&apos; (non-)financial performance and risks. Collectively, our
results indicate that generative language modeling adds considerable value for
investors with information processing constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Kim_A/0/1/0/all/0/1&quot;&gt;Alex Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Muhn_M/0/1/0/all/0/1&quot;&gt;Maximilian Muhn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Nikolaev_V/0/1/0/all/0/1&quot;&gt;Valeri Nikolaev&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>