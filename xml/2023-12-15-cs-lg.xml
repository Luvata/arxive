<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-12-13T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07546" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07547" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07550" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07552" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07560" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07561" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07571" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07577" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07580" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07583" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07586" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07599" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07601" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07609" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07615" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07624" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07627" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07633" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07636" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07661" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07671" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07679" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07680" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07682" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07685" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07694" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07698" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07705" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07718" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07729" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07730" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07743" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07759" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07762" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07769" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07781" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07784" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07790" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07792" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07795" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07802" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07813" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07821" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07822" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07831" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07833" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07835" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07837" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07839" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07841" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07851" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07854" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07855" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07859" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07861" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07887" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07899" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07910" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07929" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07930" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07931" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07952" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07953" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07955" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07965" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07977" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07979" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07981" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07983" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07987" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07991" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08008" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08010" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08016" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08021" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08029" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08033" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08034" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08052" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08053" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08055" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08057" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08063" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08066" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08075" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08083" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08096" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08103" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08107" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08132" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08135" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08143" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08150" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08153" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08174" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08193" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08194" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08200" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08221" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08224" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08227" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08255" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08257" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08264" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08287" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08288" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08290" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08295" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08298" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08307" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08358" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08361" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08369" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2008.07324" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.11992" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.11003" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2103.13389" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.01559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.10756" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.12674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2203.01881" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.07553" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.04690" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.08716" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.10187" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.00736" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.10814" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.12361" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.13428" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.07350" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.10915" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.14407" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.02618" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.01075" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.07939" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.08485" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.09329" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.13850" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.02148" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06408" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.10697" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18290" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19414" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.04064" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02345" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.10705" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.12971" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.00031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03977" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.07707" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.08742" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.09065" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.09888" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.01226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.01922" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.02784" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03999" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.04856" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.06260" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.09866" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.10441" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.14585" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.00429" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.01217" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.02948" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03149" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04796" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.04925" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.05718" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.08320" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.10659" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.20545" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02546" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.03426" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.15317" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.16080" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.16442" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.17929" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.18188" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.00102" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.00812" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.01479" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.02462" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.03038" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.03940" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.06036" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.06585" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07186" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07285" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07439" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07511" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2312.07546">
<title>Decoding Working-Memory Load During n-Back Task Performance from High Channel NIRS Data. (arXiv:2312.07546v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.07546</link>
<description rdf:parseType="Literal">&lt;p&gt;Near-infrared spectroscopy (NIRS) can measure neural activity through blood
oxygenation changes in the brain in a wearable form factor, enabling unique
applications for research in and outside the lab. NIRS has proven capable of
measuring cognitive states such as mental workload, often using machine
learning (ML) based brain-computer interfaces (BCIs). To date, NIRS research
has largely relied on probes with under ten to several hundred channels,
although recently a new class of wearable NIRS devices with thousands of
channels has emerged. This poses unique challenges for ML classification, as
NIRS is typically limited by few training trials which results in severely
under-determined estimation problems. So far, it is not well understood how
such high-resolution data is best leveraged in practical BCIs and whether
state-of-the-art (SotA) or better performance can be achieved. To address these
questions, we propose an ML strategy to classify working-memory load that
relies on spatio-temporal regularization and transfer learning from other
subjects in a combination that has not been used in previous NIRS BCIs. The
approach can be interpreted as an end-to-end generalized linear model and
allows for a high degree of interpretability using channel-level or cortical
imaging approaches. We show that using the proposed methodology, it is possible
to achieve SotA decoding performance with high-resolution NIRS data. We also
replicated several SotA approaches on our dataset of 43 participants wearing a
3198 dual-channel NIRS device while performing the n-Back task and show that
these existing methods struggle in the high-channel regime and are largely
outperformed by the proposed method. Our approach helps establish high-channel
NIRS devices as a viable platform for SotA BCI and opens new applications using
this class of headset while also enabling high-resolution model imaging and
interpretation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kothe_C/0/1/0/all/0/1&quot;&gt;Christian Kothe&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hanada_G/0/1/0/all/0/1&quot;&gt;Grant Hanada&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mullen_S/0/1/0/all/0/1&quot;&gt;Sean Mullen&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mullen_T/0/1/0/all/0/1&quot;&gt;Tim Mullen&lt;/a&gt; (1) ((1) Intheon, La Jolla, United States)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07547">
<title>Active Inference and Intentional Behaviour. (arXiv:2312.07547v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/2312.07547</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in theoretical biology suggest that basal cognition and
sentient behaviour are emergent properties of in vitro cell cultures and
neuronal networks, respectively. Such neuronal networks spontaneously learn
structured behaviours in the absence of reward or reinforcement. In this paper,
we characterise this kind of self-organisation through the lens of the free
energy principle, i.e., as self-evidencing. We do this by first discussing the
definitions of reactive and sentient behaviour in the setting of active
inference, which describes the behaviour of agents that model the consequences
of their actions. We then introduce a formal account of intentional behaviour,
that describes agents as driven by a preferred endpoint or goal in latent
state-spaces. We then investigate these forms of (reactive, sentient, and
intentional) behaviour using simulations. First, we simulate the aforementioned
in vitro experiments, in which neuronal cultures spontaneously learn to play
Pong, by implementing nested, free energy minimising processes. The simulations
are then used to deconstruct the ensuing predictive behaviour, leading to the
distinction between merely reactive, sentient, and intentional behaviour, with
the latter formalised in terms of inductive planning. This distinction is
further studied using simple machine learning benchmarks (navigation in a grid
world and the Tower of Hanoi problem), that show how quickly and efficiently
adaptive behaviour emerges under an inductive form of active inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Friston_K/0/1/0/all/0/1&quot;&gt;Karl J. Friston&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Salvatori_T/0/1/0/all/0/1&quot;&gt;Tommaso Salvatori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Isomura_T/0/1/0/all/0/1&quot;&gt;Takuya Isomura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tschantz_A/0/1/0/all/0/1&quot;&gt;Alexander Tschantz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kiefer_A/0/1/0/all/0/1&quot;&gt;Alex Kiefer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Verbelen_T/0/1/0/all/0/1&quot;&gt;Tim Verbelen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Koudahl_M/0/1/0/all/0/1&quot;&gt;Magnus Koudahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Paul_A/0/1/0/all/0/1&quot;&gt;Aswin Paul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Parr_T/0/1/0/all/0/1&quot;&gt;Thomas Parr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Razi_A/0/1/0/all/0/1&quot;&gt;Adeel Razi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kagan_B/0/1/0/all/0/1&quot;&gt;Brett Kagan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Buckley_C/0/1/0/all/0/1&quot;&gt;Christopher L. Buckley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ramstead_M/0/1/0/all/0/1&quot;&gt;Maxwell J. D. Ramstead&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07550">
<title>Understanding (Un)Intended Memorization in Text-to-Image Generative Models. (arXiv:2312.07550v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07550</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal machine learning, especially text-to-image models like Stable
Diffusion and DALL-E 3, has gained significance for transforming text into
detailed images.
&lt;/p&gt;
&lt;p&gt;Despite their growing use and remarkable generative capabilities, there is a
pressing need for a detailed examination of these models&apos; behavior,
particularly with respect to memorization. Historically, memorization in
machine learning has been context-dependent, with diverse definitions emerging
from classification tasks to complex models like Large Language Models (LLMs)
and Diffusion models. Yet, a definitive concept of memorization that aligns
with the intricacies of text-to-image synthesis remains elusive. This
understanding is vital as memorization poses privacy risks yet is essential for
meeting user expectations, especially when generating representations of
underrepresented entities. In this paper, we introduce a specialized definition
of memorization tailored to text-to-image models, categorizing it into three
distinct types according to user expectations. We closely examine the subtle
distinctions between intended and unintended memorization, emphasizing the
importance of balancing user privacy with the generative quality of the model
outputs. Using the Stable Diffusion model, we offer examples to validate our
memorization definitions and clarify their application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naseh_A/0/1/0/all/0/1&quot;&gt;Ali Naseh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roh_J/0/1/0/all/0/1&quot;&gt;Jaechul Roh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houmansadr_A/0/1/0/all/0/1&quot;&gt;Amir Houmansadr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07552">
<title>Large Language Models for Intent-Driven Session Recommendations. (arXiv:2312.07552v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.07552</link>
<description rdf:parseType="Literal">&lt;p&gt;Intent-aware session recommendation (ISR) is pivotal in discerning user
intents within sessions for precise predictions. Traditional approaches,
however, face limitations due to their presumption of a uniform number of
intents across all sessions. This assumption overlooks the dynamic nature of
user sessions, where the number and type of intentions can significantly vary.
In addition, these methods typically operate in latent spaces, thus hinder the
model&apos;s transparency.Addressing these challenges, we introduce a novel ISR
approach, utilizing the advanced reasoning capabilities of large language
models (LLMs). First, this approach begins by generating an initial prompt that
guides LLMs to predict the next item in a session, based on the varied intents
manifested in user sessions. Then, to refine this process, we introduce an
innovative prompt optimization mechanism that iteratively self-reflects and
adjusts prompts. Furthermore, our prompt selection module, built upon the LLMs&apos;
broad adaptability, swiftly selects the most optimized prompts across diverse
domains. This new paradigm empowers LLMs to discern diverse user intents at a
semantic level, leading to more accurate and interpretable session
recommendations. Our extensive experiments on three real-world datasets
demonstrate the effectiveness of our method, marking a significant advancement
in ISR systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zhu Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hongyang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1&quot;&gt;Xinghua Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_K/0/1/0/all/0/1&quot;&gt;Kaidong Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ong_Y/0/1/0/all/0/1&quot;&gt;Yew-Soon Ong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07559">
<title>PaperQA: Retrieval-Augmented Generative Agent for Scientific Research. (arXiv:2312.07559v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.07559</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) generalize well across language tasks, but
suffer from hallucinations and uninterpretability, making it difficult to
assess their accuracy without ground-truth. Retrieval-Augmented Generation
(RAG) models have been proposed to reduce hallucinations and provide provenance
for how an answer was generated. Applying such models to the scientific
literature may enable large-scale, systematic processing of scientific
knowledge. We present PaperQA, a RAG agent for answering questions over the
scientific literature. PaperQA is an agent that performs information retrieval
across full-text scientific articles, assesses the relevance of sources and
passages, and uses RAG to provide answers. Viewing this agent as a question
answering model, we find it exceeds performance of existing LLMs and LLM agents
on current science QA benchmarks. To push the field closer to how humans
perform research on scientific literature, we also introduce LitQA, a more
complex benchmark that requires retrieval and synthesis of information from
full-text scientific papers across the literature. Finally, we demonstrate
PaperQA&apos;s matches expert human researchers on LitQA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lala_J/0/1/0/all/0/1&quot;&gt;Jakub L&amp;#xe1;la&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ODonoghue_O/0/1/0/all/0/1&quot;&gt;Odhran O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shtedritski_A/0/1/0/all/0/1&quot;&gt;Aleksandar Shtedritski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cox_S/0/1/0/all/0/1&quot;&gt;Sam Cox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriques_S/0/1/0/all/0/1&quot;&gt;Samuel G. Rodriques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1&quot;&gt;Andrew D. White&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07560">
<title>AI-driven Structure Detection and Information Extraction from Historical Cadastral Maps (Early 19th Century Franciscean Cadastre in the Province of Styria) and Current High-resolution Satellite and Aerial Imagery for Remote Sensing. (arXiv:2312.07560v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07560</link>
<description rdf:parseType="Literal">&lt;p&gt;Cadastres from the 19th century are a complex as well as rich source for
historians and archaeologists, whose use presents them with great challenges.
For archaeological and historical remote sensing, we have trained several Deep
Learning models, CNNs as well as Vision Transformers, to extract large-scale
data from this knowledge representation. We present the principle results of
our work here and we present a the demonstrator of our browser-based tool that
allows researchers and public stakeholders to quickly identify spots that
featured buildings in the 19th century Franciscean Cadastre. The tool not only
supports scholars and fellow researchers in building a better understanding of
the settlement history of the region of Styria, it also helps public
administration and fellow citizens to swiftly identify areas of heightened
sensibility with regard to the cultural heritage of the region.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goderle_W/0/1/0/all/0/1&quot;&gt;Wolfgang G&amp;#xf6;derle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macher_C/0/1/0/all/0/1&quot;&gt;Christian Macher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mauthner_K/0/1/0/all/0/1&quot;&gt;Katrin Mauthner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pimas_O/0/1/0/all/0/1&quot;&gt;Oliver Pimas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rampetsreiter_F/0/1/0/all/0/1&quot;&gt;Fabian Rampetsreiter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07561">
<title>Annotating sleep states in children from wrist-worn accelerometer data using Machine Learning. (arXiv:2312.07561v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.07561</link>
<description rdf:parseType="Literal">&lt;p&gt;Sleep detection and annotation are crucial for researchers to understand
sleep patterns, especially in children. With modern wrist-worn watches
comprising built-in accelerometers, sleep logs can be collected. However, the
annotation of these logs into distinct sleep events: onset and wakeup, proves
to be challenging. These annotations must be automated, precise, and scalable.
We propose to model the accelerometer data using different machine learning
(ML) techniques such as support vectors, boosting, ensemble methods, and more
complex approaches involving LSTMs and Region-based CNNs. Later, we aim to
evaluate these approaches using the Event Detection Average Precision (EDAP)
score (similar to the IOU metric) to eventually compare the predictive power
and model performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ram_A/0/1/0/all/0/1&quot;&gt;Ashwin Ram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+S%2E_S/0/1/0/all/0/1&quot;&gt;Sundar Sripada V. S.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Keshari_S/0/1/0/all/0/1&quot;&gt;Shuvam Keshari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Zizhe Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07571">
<title>Investigating YOLO Models Towards Outdoor Obstacle Detection For Visually Impaired People. (arXiv:2312.07571v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07571</link>
<description rdf:parseType="Literal">&lt;p&gt;The utilization of deep learning-based object detection is an effective
approach to assist visually impaired individuals in avoiding obstacles. In this
paper, we implemented seven different YOLO object detection models
\textit{viz}., YOLO-NAS (small, medium, large), YOLOv8, YOLOv7, YOLOv6, and
YOLOv5 and performed comprehensive evaluation with carefully tuned
hyperparameters, to analyze how these models performed on images containing
common daily-life objects presented on roads and sidewalks. After a systematic
investigation, YOLOv8 was found to be the best model, which reached a precision
of $80\%$ and a recall of $68.2\%$ on a well-known Obstacle Dataset which
includes images from VOC dataset, COCO dataset, and TT100K dataset along with
images collected by the researchers in the field. Despite being the latest
model and demonstrating better performance in many other applications, YOLO-NAS
was found to be suboptimal for the obstacle detection task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1&quot;&gt;Chenhao He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_P/0/1/0/all/0/1&quot;&gt;Pramit Saha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07577">
<title>Benchmarking Distribution Shift in Tabular Data with TableShift. (arXiv:2312.07577v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07577</link>
<description rdf:parseType="Literal">&lt;p&gt;Robustness to distribution shift has become a growing concern for text and
image models as they transition from research subjects to deployment in the
real world. However, high-quality benchmarks for distribution shift in tabular
machine learning tasks are still lacking despite the widespread real-world use
of tabular data and differences in the models used for tabular data in
comparison to text and images. As a consequence, the robustness of tabular
models to distribution shift is poorly understood. To address this issue, we
introduce TableShift, a distribution shift benchmark for tabular data.
TableShift contains 15 binary classification tasks in total, each with an
associated shift, and includes a diverse set of data sources, prediction
targets, and distribution shifts. The benchmark covers domains including
finance, education, public policy, healthcare, and civic participation, and is
accessible using only a few lines of Python code via the TableShift API. We
conduct a large-scale study comparing several state-of-the-art tabular data
models alongside robust learning and domain generalization methods on the
benchmark tasks. Our study demonstrates (1) a linear trend between
in-distribution (ID) and out-of-distribution (OOD) accuracy; (2) domain
robustness methods can reduce shift gaps but at the cost of reduced ID
accuracy; (3) a strong relationship between shift gap (difference between ID
and OOD performance) and shifts in the label distribution.
&lt;/p&gt;
&lt;p&gt;The benchmark data, Python package, model implementations, and more
information about TableShift are available at
https://github.com/mlfoundations/tableshift and https://tableshift.org .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1&quot;&gt;Josh Gardner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popovic_Z/0/1/0/all/0/1&quot;&gt;Zoran Popovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1&quot;&gt;Ludwig Schmidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07580">
<title>COVID-19 Detection Using Slices Processing Techniques and a Modified Xception Classifier from Computed Tomography Images. (arXiv:2312.07580v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.07580</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper extends our previous method for COVID-19 diagnosis, proposing an
enhanced solution for detecting COVID-19 from computed tomography (CT) images.
To decrease model misclassifications, two key steps of image processing were
employed. Firstly, the uppermost and lowermost slices were removed, preserving
sixty percent of each patient&apos;s slices. Secondly, all slices underwent manual
cropping to emphasize the lung areas. Subsequently, resized CT scans (224 by
224) were input into an Xception transfer learning model. Leveraging Xception&apos;s
architecture and pre-trained weights, the modified model achieved binary
classification. Promising results on the COV19-CT database showcased higher
validation accuracy and macro F1 score at both the slice and patient levels
compared to our previous solution and alternatives on the same dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Morani_K/0/1/0/all/0/1&quot;&gt;Kenan Morani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07583">
<title>Classification with Partially Private Features. (arXiv:2312.07583v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07583</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider differentially private classification when some
features are sensitive, while the rest of the features and the label are not.
We adapt the definition of differential privacy naturally to this setting. Our
main contribution is a novel adaptation of AdaBoost that is not only provably
differentially private, but also significantly outperforms a natural benchmark
that assumes the entire data of the individual is sensitive in the experiments.
As a surprising observation, we show that boosting randomly generated
classifiers suffices to achieve high accuracy. Our approach easily adapts to
the classical setting where all the features are sensitive, providing an
alternate algorithm for differentially private linear classification with a
much simpler privacy proof and comparable or higher accuracy than
differentially private logistic regression on real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zeyu Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnaswamy_A/0/1/0/all/0/1&quot;&gt;Anilesh Krishnaswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1&quot;&gt;Janardhan Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munagala_K/0/1/0/all/0/1&quot;&gt;Kamesh Munagala&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07586">
<title>Characteristic Guidance: Non-linear Correction for DDPM at Large Guidance Scale. (arXiv:2312.07586v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07586</link>
<description rdf:parseType="Literal">&lt;p&gt;Popular guidance for denoising diffusion probabilistic model (DDPM) linearly
combines distinct conditional models together to provide enhanced control over
samples. However, this approach overlooks nonlinear effects that become
significant when guidance scale is large. To address this issue, we propose
characteristic guidance, a novel method that provides non-linear correction for
classifier-free guided DDPMs. Such correction forces the guided DDPMs to
respect the Fokker-Planck equation of their underlying diffusion process, in a
way that is first-principle, training-free, derivative-free, and compatible
with existing sampling methods. Experiments show that characteristic guidance
is robust to various applications, offers enhanced control over sample
generation, suppresses color and exposure issues even for latent space
sampling, and can handle physics problems such as the phase transitions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Candi Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1&quot;&gt;Yuan Lan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07599">
<title>Contrastive News and Social Media Linking using BERT for Articles and Tweets across Dual Platforms. (arXiv:2312.07599v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.07599</link>
<description rdf:parseType="Literal">&lt;p&gt;X (formerly Twitter) has evolved into a contemporary agora, offering a
platform for individuals to express opinions and viewpoints on current events.
The majority of the topics discussed on Twitter are directly related to ongoing
events, making it an important source for monitoring public discourse. However,
linking tweets to specific news presents a significant challenge due to their
concise and informal nature. Previous approaches, including topic models,
graph-based models, and supervised classifiers, have fallen short in
effectively capturing the unique characteristics of tweets and articles.
&lt;/p&gt;
&lt;p&gt;Inspired by the success of the CLIP model in computer vision, which employs
contrastive learning to model similarities between images and captions, this
paper introduces a contrastive learning approach for training a representation
space where linked articles and tweets exhibit proximity. We present our
contrastive learning approach, CATBERT (Contrastive Articles Tweets BERT),
leveraging pre-trained BERT models. The model is trained and tested on a
dataset containing manually labeled English and Polish tweets and articles
related to the Russian-Ukrainian war. We evaluate CATBERT&apos;s performance against
traditional approaches like LDA, and the novel method based on OpenAI
embeddings, which has not been previously applied to this task. Our findings
indicate that CATBERT demonstrates superior performance in associating tweets
with relevant news articles. Furthermore, we demonstrate the performance of the
models when applied to finding the main topic -- represented by an article --
of the whole cascade of tweets. In this new task, we report the performance of
the different models in dependence on the cascade size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piotrowski_J/0/1/0/all/0/1&quot;&gt;Jan Piotrowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wachnicki_M/0/1/0/all/0/1&quot;&gt;Marek Wachnicki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perlik_M/0/1/0/all/0/1&quot;&gt;Mateusz Perlik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Podolak_J/0/1/0/all/0/1&quot;&gt;Jakub Podolak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rucki_G/0/1/0/all/0/1&quot;&gt;Grzegorz Rucki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brzozowski_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Brzozowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olejnik_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; Olejnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozlowski_J/0/1/0/all/0/1&quot;&gt;Julian Koz&amp;#x142;owski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nocon_T/0/1/0/all/0/1&quot;&gt;Tomasz Noco&amp;#x144;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koziel_J/0/1/0/all/0/1&quot;&gt;Jakub Kozie&amp;#x142;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gizinski_S/0/1/0/all/0/1&quot;&gt;Stanis&amp;#x142;aw Gizi&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankowski_P/0/1/0/all/0/1&quot;&gt;Piotr Sankowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07601">
<title>Non-contact Multimodal Indoor Human Monitoring Systems: A Survey. (arXiv:2312.07601v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.07601</link>
<description rdf:parseType="Literal">&lt;p&gt;Indoor human monitoring systems leverage a wide range of sensors, including
cameras, radio devices, and inertial measurement units, to collect extensive
data from users and the environment. These sensors contribute diverse data
modalities, such as video feeds from cameras, received signal strength
indicators and channel state information from WiFi devices, and three-axis
acceleration data from inertial measurement units. In this context, we present
a comprehensive survey of multimodal approaches for indoor human monitoring
systems, with a specific focus on their relevance in elderly care. Our survey
primarily highlights non-contact technologies, particularly cameras and radio
devices, as key components in the development of indoor human monitoring
systems. Throughout this article, we explore well-established techniques for
extracting features from multimodal data sources. Our exploration extends to
methodologies for fusing these features and harnessing multiple modalities to
improve the accuracy and robustness of machine learning models. Furthermore, we
conduct comparative analysis across different data modalities in diverse human
monitoring tasks and undertake a comprehensive examination of existing
multimodal datasets. This extensive survey not only highlights the significance
of indoor human monitoring systems but also affirms their versatile
applications. In particular, we emphasize their critical role in enhancing the
quality of elderly care, offering valuable insights into the development of
non-contact monitoring solutions applicable to the needs of aging populations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_L/0/1/0/all/0/1&quot;&gt;Le Ngu Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Susarla_P/0/1/0/all/0/1&quot;&gt;Praneeth Susarla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mukherjee_A/0/1/0/all/0/1&quot;&gt;Anirban Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Canellas_M/0/1/0/all/0/1&quot;&gt;Manuel Lage Ca&amp;#xf1;ellas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Casado_C/0/1/0/all/0/1&quot;&gt;Constantino &amp;#xc1;lvarez Casado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaoting Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Silven_O/0/1/0/all/0/1&quot;&gt;Olli~Silv&amp;#xe9;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jayagopi_D/0/1/0/all/0/1&quot;&gt;Dinesh Babu Jayagopi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lopez_M/0/1/0/all/0/1&quot;&gt;Miguel Bordallo L&amp;#xf3;pez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07609">
<title>IndoorGNN: A Graph Neural Network based approach for Indoor Localization using WiFi RSSI. (arXiv:2312.07609v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.07609</link>
<description rdf:parseType="Literal">&lt;p&gt;Indoor localization is the process of determining the location of a person or
object inside a building. Potential usage of indoor localization includes
navigation, personalization, safety and security, and asset tracking. Commonly
used technologies for indoor localization include WiFi, Bluetooth, RFID, and
Ultra-wideband. Among these, WiFi&apos;s Received Signal Strength Indicator
(RSSI)-based localization is preferred because of widely available WiFi Access
Points (APs). We have two main contributions. First, we develop our method,
&apos;IndoorGNN&apos; which involves using a Graph Neural Network (GNN) based algorithm
in a supervised manner to classify a specific location into a particular region
based on the RSSI values collected at that location. Most of the ML algorithms
that perform this classification require a large number of labeled data points
(RSSI vectors with location information). Collecting such data points is a
labor-intensive and time-consuming task. To overcome this challenge, as our
second contribution, we demonstrate the performance of IndoorGNN on the
restricted dataset. It shows a comparable prediction accuracy to that of the
complete dataset. We performed experiments on the UJIIndoorLoc and MNAV
datasets, which are real-world standard indoor localization datasets. Our
experiments show that IndoorGNN gives better location prediction accuracies
when compared with state-of-the-art existing conventional as well as GNN-based
methods for this same task. It continues to outperform these algorithms even
with restricted datasets. It is noteworthy that its performance does not
decrease a lot with a decrease in the number of available data points. Our
method can be utilized for navigation and wayfinding in complex indoor
environments, asset tracking and building management, enhancing mobile
applications with location-based services, and improving safety and security
during emergencies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Vishwakarma_R/0/1/0/all/0/1&quot;&gt;Rahul Vishwakarma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Joshi_R/0/1/0/all/0/1&quot;&gt;Rucha Bhalchandra Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mishra_S/0/1/0/all/0/1&quot;&gt;Subhankar Mishra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07615">
<title>Optimizing Likelihood-free Inference using Self-supervised Neural Symmetry Embeddings. (arXiv:2312.07615v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07615</link>
<description rdf:parseType="Literal">&lt;p&gt;Likelihood-free inference is quickly emerging as a powerful tool to perform
fast/effective parameter estimation. We demonstrate a technique of optimizing
likelihood-free inference to make it even faster by marginalizing symmetries in
a physical problem. In this approach, physical symmetries, for example,
time-translation are learned using joint-embedding via self-supervised learning
with symmetry data augmentations. Subsequently, parameter inference is
performed using a normalizing flow where the embedding network is used to
summarize the data before conditioning the parameters. We present this approach
on two simple physical problems and we show faster convergence in a smaller
number of parameters compared to a normalizing flow that does not use a
pre-trained symmetry-informed representation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_D/0/1/0/all/0/1&quot;&gt;Deep Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harris_P/0/1/0/all/0/1&quot;&gt;Philip C. Harris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goel_M/0/1/0/all/0/1&quot;&gt;Maanas Goel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Desai_M/0/1/0/all/0/1&quot;&gt;Malina Desai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coughlin_M/0/1/0/all/0/1&quot;&gt;Michael W. Coughlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katsavounidis_E/0/1/0/all/0/1&quot;&gt;Erik Katsavounidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07624">
<title>Adaptive Proximal Policy Optimization with Upper Confidence Bound. (arXiv:2312.07624v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07624</link>
<description rdf:parseType="Literal">&lt;p&gt;Trust Region Policy Optimization (TRPO) attractively optimizes the policy
while constraining the update of the new policy within a trust region, ensuring
the stability and monotonic optimization. Building on the theoretical
guarantees of trust region optimization, Proximal Policy Optimization (PPO)
successfully enhances the algorithm&apos;s sample efficiency and reduces deployment
complexity by confining the update of the new and old policies within a
surrogate trust region. However, this approach is limited by the fixed setting
of surrogate trust region and is not sufficiently adaptive, because there is no
theoretical proof that the optimal clipping bound remains consistent throughout
the entire training process, truncating the ratio of the new and old policies
within surrogate trust region can ensure that the algorithm achieves its best
performance, therefore, exploring and researching a dynamic clip bound for
improving PPO&apos;s performance can be quite beneficial. To design an adaptive
clipped trust region and explore the dynamic clip bound&apos;s impact on the
performance of PPO, we introduce an adaptive PPO-CLIP (Adaptive-PPO) method
that dynamically explores and exploits the clip bound using a bandit during the
online training process. Furthermore, ample experiments will initially
demonstrate that our Adaptive-PPO exhibits sample efficiency and performance
compared to PPO-CLIP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Ziqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jingzehua Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1&quot;&gt;Zifeng Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jinxin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+wang_D/0/1/0/all/0/1&quot;&gt;Donglin wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07627">
<title>Multimodal Sentiment Analysis: Perceived vs Induced Sentiments. (arXiv:2312.07627v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07627</link>
<description rdf:parseType="Literal">&lt;p&gt;Social media has created a global network where people can easily access and
exchange vast information. This information gives rise to a variety of
opinions, reflecting both positive and negative viewpoints. GIFs stand out as a
multimedia format offering a visually engaging way for users to communicate. In
this research, we propose a multimodal framework that integrates visual and
textual features to predict the GIF sentiment. It also incorporates attributes
including face emotion detection and OCR generated captions to capture the
semantic aspects of the GIF. The developed classifier achieves an accuracy of
82.7% on Twitter GIFs, which is an improvement over state-of-the-art models.
Moreover, we have based our research on the ReactionGIF dataset, analysing the
variance in sentiment perceived by the author and sentiment induced in the
reader
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1&quot;&gt;Aditi Aggarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varshney_D/0/1/0/all/0/1&quot;&gt;Deepika Varshney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1&quot;&gt;Saurabh Patel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07633">
<title>SE(3)-Invariant Multiparameter Persistent Homology for Chiral-Sensitive Molecular Property Prediction. (arXiv:2312.07633v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07633</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we present a novel computational method for generating
molecular fingerprints using multiparameter persistent homology (MPPH). This
technique holds considerable significance for drug discovery and materials
science, where precise molecular property prediction is vital. By integrating
SE(3)-invariance with Vietoris-Rips persistent homology, we effectively capture
the three-dimensional representations of molecular chirality. This
non-superimposable mirror image property directly influences the molecular
interactions, serving as an essential factor in molecular property prediction.
We explore the underlying topologies and patterns in molecular structures by
applying Vietoris-Rips persistent homology across varying scales and parameters
such as atomic weight, partial charge, bond type, and chirality. Our method&apos;s
efficacy can be improved by incorporating additional parameters such as
aromaticity, orbital hybridization, bond polarity, conjugated systems, as well
as bond and torsion angles. Additionally, we leverage Stochastic Gradient
Langevin Boosting in a Bayesian ensemble of GBDTs to obtain aleatoric and
epistemic uncertainty estimates for gradient boosting models. With these
uncertainty estimates, we prioritize high-uncertainty samples for active
learning and model fine-tuning, benefiting scenarios where data labeling is
costly or time consuming. Compared to conventional GNNs which usually suffer
from oversmoothing and oversquashing, MPPH provides a more comprehensive and
interpretable characterization of molecular data topology. We substantiate our
approach with theoretical stability guarantees and demonstrate its superior
performance over existing state-of-the-art methods in predicting molecular
properties through extensive evaluations on the MoleculeNet benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demir_A/0/1/0/all/0/1&quot;&gt;Andac Demir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prael_F/0/1/0/all/0/1&quot;&gt;Francis Prael III&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiziltan_B/0/1/0/all/0/1&quot;&gt;Bulent Kiziltan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07636">
<title>Go beyond End-to-End Training: Boosting Greedy Local Learning with Context Supply. (arXiv:2312.07636v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07636</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional end-to-end (E2E) training of deep networks necessitates storing
intermediate activations for back-propagation, resulting in a large memory
footprint on GPUs and restricted model parallelization. As an alternative,
greedy local learning partitions the network into gradient-isolated modules and
trains supervisely based on local preliminary losses, thereby providing
asynchronous and parallel training methods that substantially reduce memory
cost. However, empirical experiments reveal that as the number of segmentations
of the gradient-isolated module increases, the performance of the local
learning scheme degrades substantially, severely limiting its expansibility. To
avoid this issue, we theoretically analyze the greedy local learning from the
standpoint of information theory and propose a ContSup scheme, which
incorporates context supply between isolated modules to compensate for
information loss. Experiments on benchmark datasets (i.e. CIFAR, SVHN, STL-10)
achieve SOTA results and indicate that our proposed method can significantly
improve the performance of greedy local learning with minimal memory and
computational overhead, allowing for the boost of the number of isolated
modules. Our codes are available at https://github.com/Tab-ct/ContSup.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chengting Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fengzhao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1&quot;&gt;Hanzhi Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1&quot;&gt;Aili Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_E/0/1/0/all/0/1&quot;&gt;Erping Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07661">
<title>CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor. (arXiv:2312.07661v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07661</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing open-vocabulary image segmentation methods require a fine-tuning
step on mask annotations and/or image-text datasets. Mask labels are
labor-intensive, which limits the number of categories in segmentation
datasets. As a result, the open-vocabulary capacity of pre-trained VLMs is
severely reduced after fine-tuning. However, without fine-tuning, VLMs trained
under weak image-text supervision tend to make suboptimal mask predictions when
there are text queries referring to non-existing concepts in the image. To
alleviate these issues, we introduce a novel recurrent framework that
progressively filters out irrelevant texts and enhances mask quality without
training efforts. The recurrent unit is a two-stage segmenter built upon a VLM
with frozen weights. Thus, our model retains the VLM&apos;s broad vocabulary space
and strengthens its segmentation capability. Experimental results show that our
method outperforms not only the training-free counterparts, but also those
fine-tuned with millions of additional data samples, and sets new
state-of-the-art records for both zero-shot semantic and referring image
segmentation tasks. Specifically, we improve the current record by 28.8, 16.0,
and 6.9 mIoU on Pascal VOC, COCO Object, and Pascal Context.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Shuyang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Runjia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip Torr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1&quot;&gt;Xiuye Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Siyang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07671">
<title>Reacting like Humans: Incorporating Intrinsic Human Behaviors into NAO through Sound-Based Reactions for Enhanced Sociability. (arXiv:2312.07671v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.07671</link>
<description rdf:parseType="Literal">&lt;p&gt;Robots&apos; acceptability among humans and their sociability can be significantly
enhanced by incorporating human-like reactions. Humans can react to
environmental events very quickly and without thinking. An instance where
humans display natural reactions is when they encounter a sudden and loud sound
that startles or frightens them. During such moments, individuals may
instinctively move their hands, turn toward the origin of the sound, and try to
determine the event&apos;s cause. This inherent behavior motivated us to explore
this less-studied part of social robotics. In this work, a multi-modal system
composed of an action generator, sound classifier, and YOLO object detector was
designed to sense the environment and, in the presence of sudden loud sounds,
show natural human fear reactions, and finally, locate the fear-causing sound
source in the environment. These unique and valid generated motions and
inferences could imitate intrinsic human reactions and enhance the sociability
of robots. For motion generation, a model based on LSTM and MDN networks was
proposed to synthesize various motions. Also, in the case of sound detection, a
transfer learning model was preferred that used the spectrogram of sound
signals as its input. After developing individual models for sound detection,
motion generation, and image recognition, they were integrated into a
comprehensive fear module that was implemented on the NAO robot. Finally, the
fear module was tested in practical application and two groups of experts and
non-experts filled out a questionnaire to evaluate the performance of the
robot. Given our promising results, this preliminary exploratory research
provides a fresh perspective on social robotics and could be a starting point
for modeling intrinsic human behaviors and emotions in robots.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghadami_A/0/1/0/all/0/1&quot;&gt;Ali Ghadami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taghimohammadi_M/0/1/0/all/0/1&quot;&gt;Mohammadreza Taghimohammadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammadzadeh_M/0/1/0/all/0/1&quot;&gt;Mohammad Mohammadzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hosseinipour_M/0/1/0/all/0/1&quot;&gt;Mohammad Hosseinipour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taheri_A/0/1/0/all/0/1&quot;&gt;Alireza Taheri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07679">
<title>Bayesian Online Learning for Consensus Prediction. (arXiv:2312.07679v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07679</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a pre-trained classifier and multiple human experts, we investigate the
task of online classification where model predictions are provided for free but
querying humans incurs a cost. In this practical but under-explored setting,
oracle ground truth is not available. Instead, the prediction target is defined
as the consensus vote of all experts. Given that querying full consensus can be
costly, we propose a general framework for online Bayesian consensus
estimation, leveraging properties of the multivariate hypergeometric
distribution. Based on this framework, we propose a family of methods that
dynamically estimate expert consensus from partial feedback by producing a
posterior over expert and model beliefs. Analyzing this posterior induces an
interpretable trade-off between querying cost and classification performance.
We demonstrate the efficacy of our framework against a variety of baselines on
CIFAR-10H and ImageNet-16H, two large-scale crowdsourced datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Showalter_S/0/1/0/all/0/1&quot;&gt;Sam Showalter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boyd_A/0/1/0/all/0/1&quot;&gt;Alex Boyd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smyth_P/0/1/0/all/0/1&quot;&gt;Padhraic Smyth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steyvers_M/0/1/0/all/0/1&quot;&gt;Mark Steyvers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07680">
<title>I Open at the Close: A Deep Reinforcement Learning Evaluation of Open Streets Initiatives. (arXiv:2312.07680v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07680</link>
<description rdf:parseType="Literal">&lt;p&gt;The open streets initiative &quot;opens&quot; streets to pedestrians and bicyclists by
closing them to cars and trucks. The initiative, adopted by many cities across
North America, increases community space in urban environments. But could open
streets also make cities safer and less congested? We study this question by
framing the choice of which streets to open as a reinforcement learning
problem. In order to simulate the impact of opening streets, we first compare
models for predicting vehicle collisions given network and temporal data. We
find that a recurrent graph neural network, leveraging the graph structure and
the short-term temporal dependence of the data, gives the best predictive
performance. Then, with the ability to simulate collisions and traffic, we
frame a reinforcement learning problem to find which streets to open. We
compare the streets in the NYC Open Streets program to those proposed by a
Q-learning algorithm. We find that the streets proposed by the Q-learning
algorithm have reliably better outcomes, while streets in the program have
similar outcomes to randomly selected streets. We present our work as a step
toward principally choosing which streets to open for safer and less congested
cities. All our code and data are available on Github.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witter_R/0/1/0/all/0/1&quot;&gt;R. Teal Witter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenblatt_L/0/1/0/all/0/1&quot;&gt;Lucas Rosenblatt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07682">
<title>An Online, Adaptive and Unsupervised Regression Framework with Drift Detection for Label Scarcity Contexts. (arXiv:2312.07682v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07682</link>
<description rdf:parseType="Literal">&lt;p&gt;In scenarios where obtaining real-time labels proves challenging,
conventional approaches may result in sub-optimal performance. This paper
presents an optimal strategy for streaming contexts with limited labeled data,
introducing an adaptive technique for unsupervised regression. The proposed
method leverages a sparse set of initial labels and introduces an innovative
drift detection mechanism to enable dynamic model adaptations in response to
evolving patterns in the data. To enhance adaptability, we integrate the ADWIN
(ADaptive WINdowing) algorithm with error generalization based on Root Mean
Square Error (RMSE). ADWIN facilitates real-time drift detection, while RMSE
provides a robust measure of model prediction accuracy. This combination
enables our multivariate method to effectively navigate the challenges of
streaming data, continuously adapting to changing patterns while maintaining a
high level of predictive precision. Finally, we evaluate the performance of our
multivariate method across various public datasets, comparing it to
non-adapting baselines. Through comprehensive assessments, we demonstrate the
superior efficacy of our adaptive regression technique for tasks where
obtaining labels in real-time is a significant challenge. The results
underscore the method&apos;s capacity to outperform traditional approaches and
highlight its potential in scenarios characterized by label scarcity and
evolving data patterns.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richard_R/0/1/0/all/0/1&quot;&gt;Rene Richard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belacel_N/0/1/0/all/0/1&quot;&gt;Nabil Belacel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07685">
<title>A Perspective of Q-value Estimation on Offline-to-Online Reinforcement Learning. (arXiv:2312.07685v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07685</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline-to-online Reinforcement Learning (O2O RL) aims to improve the
performance of offline pretrained policy using only a few online samples. Built
on offline RL algorithms, most O2O methods focus on the balance between RL
objective and pessimism, or the utilization of offline and online samples. In
this paper, from a novel perspective, we systematically study the challenges
that remain in O2O RL and identify that the reason behind the slow improvement
of the performance and the instability of online finetuning lies in the
inaccurate Q-value estimation inherited from offline pretraining. Specifically,
we demonstrate that the estimation bias and the inaccurate rank of Q-value
cause a misleading signal for the policy update, making the standard offline RL
algorithms, such as CQL and TD3-BC, ineffective in the online finetuning. Based
on this observation, we address the problem of Q-value estimation by two
techniques: (1) perturbed value update and (2) increased frequency of Q-value
updates. The first technique smooths out biased Q-value estimation with sharp
peaks, preventing early-stage policy exploitation of sub-optimal actions. The
second one alleviates the estimation bias inherited from offline pretraining by
accelerating learning. Extensive experiments on the MuJoco and Adroit
environments demonstrate that the proposed method, named SO2, significantly
alleviates Q-value estimation issues, and consistently improves the performance
against the state-of-the-art methods by up to 83.1%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yinmin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chuming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_Y/0/1/0/all/0/1&quot;&gt;Yazhe Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1&quot;&gt;Wanli Ouyang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07694">
<title>GP+: A Python Library for Kernel-based learning via Gaussian Processes. (arXiv:2312.07694v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07694</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we introduce GP+, an open-source library for kernel-based
learning via Gaussian processes (GPs) which are powerful statistical models
that are completely characterized by their parametric covariance and mean
functions. GP+ is built on PyTorch and provides a user-friendly and
object-oriented tool for probabilistic learning and inference. As we
demonstrate with a host of examples, GP+ has a few unique advantages over other
GP modeling libraries. We achieve these advantages primarily by integrating
nonlinear manifold learning techniques with GPs&apos; covariance and mean functions.
As part of introducing GP+, in this paper we also make methodological
contributions that (1) enable probabilistic data fusion and inverse parameter
estimation, and (2) equip GPs with parsimonious parametric mean functions which
span mixed feature spaces that have both categorical and quantitative
variables. We demonstrate the impact of these contributions in the context of
Bayesian optimization, multi-fidelity modeling, sensitivity analysis, and
calibration of computer models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yousefpour_A/0/1/0/all/0/1&quot;&gt;Amin Yousefpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foumani_Z/0/1/0/all/0/1&quot;&gt;Zahra Zanjani Foumani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shishehbor_M/0/1/0/all/0/1&quot;&gt;Mehdi Shishehbor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mora_C/0/1/0/all/0/1&quot;&gt;Carlos Mora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bostanabad_R/0/1/0/all/0/1&quot;&gt;Ramin Bostanabad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07698">
<title>Machine Learning and Citizen Science Approaches for Monitoring the Changing Environment. (arXiv:2312.07698v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07698</link>
<description rdf:parseType="Literal">&lt;p&gt;This dissertation will combine new tools and methodologies to answer pressing
questions regarding inundation area and hurricane events in complex,
heterogeneous changing environments. In addition to remote sensing approaches,
citizen science and machine learning are both emerging fields that harness
advancing technology to answer environmental management and disaster response
questions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sulong Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07705">
<title>Brain-optimized inference improves reconstructions of fMRI brain activity. (arXiv:2312.07705v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/2312.07705</link>
<description rdf:parseType="Literal">&lt;p&gt;The release of large datasets and developments in AI have led to dramatic
improvements in decoding methods that reconstruct seen images from human brain
activity. We evaluate the prospect of further improving recent decoding methods
by optimizing for consistency between reconstructions and brain activity during
inference. We sample seed reconstructions from a base decoding method, then
iteratively refine these reconstructions using a brain-optimized encoding model
that maps images to brain activity. At each iteration, we sample a small
library of images from an image distribution (a diffusion model) conditioned on
a seed reconstruction from the previous iteration. We select those that best
approximate the measured brain activity when passed through our encoding model,
and use these images for structural guidance during the generation of the small
library in the next iteration. We reduce the stochasticity of the image
distribution at each iteration, and stop when a criterion on the &quot;width&quot; of the
image distribution is met. We show that when this process is applied to recent
decoding methods, it outperforms the base decoding method as measured by human
raters, a variety of image feature metrics, and alignment to brain activity.
These results demonstrate that reconstruction quality can be significantly
improved by explicitly aligning decoding distributions to brain activity
distributions, even when the seed reconstruction is output from a
state-of-the-art decoding algorithm. Interestingly, the rate of refinement
varies systematically across visual cortex, with earlier visual areas generally
converging more slowly and preferring narrower image distributions, relative to
higher-level brain areas. Brain-optimized inference thus offers a succinct and
novel method for improving reconstructions and exploring the diversity of
representations across visual brain areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kneeland_R/0/1/0/all/0/1&quot;&gt;Reese Kneeland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ojeda_J/0/1/0/all/0/1&quot;&gt;Jordyn Ojeda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+St_Yves_G/0/1/0/all/0/1&quot;&gt;Ghislain St-Yves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Naselaris_T/0/1/0/all/0/1&quot;&gt;Thomas Naselaris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07718">
<title>CaVE: A Cone-Aligned Approach for Fast Predict-then-optimize with Binary Linear Programs. (arXiv:2312.07718v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07718</link>
<description rdf:parseType="Literal">&lt;p&gt;The end-to-end predict-then-optimize framework, also known as
decision-focused learning, has gained popularity for its ability to integrate
optimization into the training procedure of machine learning models that
predict the unknown cost (objective function) coefficients of optimization
problems from contextual instance information. Naturally, most of the problems
of interest in this space can be cast as integer linear programs. In this work,
we focus on binary linear programs (BLPs) and propose a new end-to-end training
method for predict-then-optimize. Our method, Cone-aligned Vector Estimation
(CaVE), aligns the predicted cost vectors with the cone corresponding to the
true optimal solution of a training instance. When the predicted cost vector
lies inside the cone, the optimal solution to the linear relaxation of the
binary problem is optimal w.r.t. to the true cost vector. Not only does this
alignment produce decision-aware learning models, but it also dramatically
reduces training time as it circumvents the need to solve BLPs to compute a
loss function with its gradients. Experiments across multiple datasets show
that our method exhibits a favorable trade-off between training time and
solution quality, particularly with large-scale optimization problems such as
vehicle routing, a hard BLP that has yet to benefit from predict-then-optimize
methods in the literature due to its difficulty.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1&quot;&gt;Bo Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalil_E/0/1/0/all/0/1&quot;&gt;Elias B. Khalil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07729">
<title>MedYOLO: A Medical Image Object Detection Framework. (arXiv:2312.07729v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.07729</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial intelligence-enhanced identification of organs, lesions, and other
structures in medical imaging is typically done using convolutional neural
networks (CNNs) designed to make voxel-accurate segmentations of the region of
interest. However, the labels required to train these CNNs are time-consuming
to generate and require attention from subject matter experts to ensure
quality. For tasks where voxel-level precision is not required, object
detection models offer a viable alternative that can reduce annotation effort.
Despite this potential application, there are few options for general purpose
object detection frameworks available for 3-D medical imaging. We report on
MedYOLO, a 3-D object detection framework using the one-shot detection method
of the YOLO family of models and designed for use with medical imaging. We
tested this model on four different datasets: BRaTS, LIDC, an abdominal organ
Computed Tomography (CT) dataset, and an ECG-gated heart CT dataset. We found
our models achieve high performance on commonly present medium and large-sized
structures such as the heart, liver, and pancreas even without hyperparameter
tuning. However, the models struggle with very small or rarely present
structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sobek_J/0/1/0/all/0/1&quot;&gt;Joseph Sobek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Inojosa_J/0/1/0/all/0/1&quot;&gt;Jose R. Medina Inojosa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Inojosa_B/0/1/0/all/0/1&quot;&gt;Betsy J. Medina Inojosa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rassoulinejad_Mousavi_S/0/1/0/all/0/1&quot;&gt;S. M. Rassoulinejad-Mousavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Conte_G/0/1/0/all/0/1&quot;&gt;Gian Marco Conte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lopez_Jimenez_F/0/1/0/all/0/1&quot;&gt;Francisco Lopez-Jimenez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Erickson_B/0/1/0/all/0/1&quot;&gt;Bradley J. Erickson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07730">
<title>Hierarchical Classification of Financial Transactions Through Context-Fusion of Transformer-based Embeddings and Taxonomy-aware Attention Layer. (arXiv:2312.07730v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07730</link>
<description rdf:parseType="Literal">&lt;p&gt;This work proposes the Two-headed DragoNet, a Transformer-based model for
hierarchical multi-label classification of financial transactions. Our model is
based on a stack of Transformers encoder layers that generate contextual
embeddings from two short textual descriptors (merchant name and business
activity), followed by a Context Fusion layer and two output heads that
classify transactions according to a hierarchical two-level taxonomy (macro and
micro categories). Finally, our proposed Taxonomy-aware Attention Layer
corrects predictions that break categorical hierarchy rules defined in the
given taxonomy. Our proposal outperforms classical machine learning methods in
experiments of macro-category classification by achieving an F1-score of 93\%
on a card dataset and 95% on a current account dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Busson_A/0/1/0/all/0/1&quot;&gt;Antonio J. G. Busson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rocha_R/0/1/0/all/0/1&quot;&gt;Rafael Rocha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaio_R/0/1/0/all/0/1&quot;&gt;Rennan Gaio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miceli_R/0/1/0/all/0/1&quot;&gt;Rafael Miceli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereira_I/0/1/0/all/0/1&quot;&gt;Ivan Pereira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moraes_D/0/1/0/all/0/1&quot;&gt;Daniel de S. Moraes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colcher_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;rgio Colcher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veiga_A/0/1/0/all/0/1&quot;&gt;Alvaro Veiga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizzi_B/0/1/0/all/0/1&quot;&gt;Bruno Rizzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evangelista_F/0/1/0/all/0/1&quot;&gt;Francisco Evangelista&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_L/0/1/0/all/0/1&quot;&gt;Leandro Santos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marques_F/0/1/0/all/0/1&quot;&gt;Fellipe Marques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabaioli_M/0/1/0/all/0/1&quot;&gt;Marcos Rabaioli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldberg_D/0/1/0/all/0/1&quot;&gt;Diego Feldberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mattos_D/0/1/0/all/0/1&quot;&gt;Debora Mattos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasqua_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Pasqua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dias_D/0/1/0/all/0/1&quot;&gt;Diogo Dias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07743">
<title>FULL-W2V: Fully Exploiting Data Reuse for W2V on GPU-Accelerated Systems. (arXiv:2312.07743v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07743</link>
<description rdf:parseType="Literal">&lt;p&gt;Word2Vec remains one of the highly-impactful innovations in the field of
Natural Language Processing (NLP) that represents latent grammatical and
syntactical information in human text with dense vectors in a low dimension.
Word2Vec has high computational cost due to the algorithm&apos;s inherent
sequentiality, intensive memory accesses, and the large vocabularies it
represents. While prior studies have investigated technologies to explore
parallelism and improve memory system performance, they struggle to effectively
gain throughput on powerful GPUs.
&lt;/p&gt;
&lt;p&gt;We identify memory data access and latency as the primary bottleneck in prior
works on GPUs, which prevents highly optimized kernels from attaining the
architecture&apos;s peak performance. We present a novel algorithm, FULL-W2V, which
maximally exploits the opportunities for data reuse in the W2V algorithm and
leverages GPU architecture and resources to reduce access to low memory levels
and improve temporal locality. FULL-W2V is capable of reducing accesses to GPU
global memory significantly, e.g., by more than 89\%, compared to prior
state-of-the-art GPU implementations, resulting in significant performance
improvement that scales across successive hardware generations. Our prototype
implementation achieves 2.97X speedup when ported from Nvidia Pascal P100 to
Volta V100 cards, and outperforms the state-of-the-art by 5.72X on V100 cards
with the same embedding quality. In-depth analysis indicates that the reduction
of memory accesses through register and shared memory caching and
high-throughput shared memory reduction leads to a significantly improved
arithmetic intensity. FULL-W2V can potentially benefit many applications in NLP
and other domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Randall_T/0/1/0/all/0/1&quot;&gt;Thomas Randall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_T/0/1/0/all/0/1&quot;&gt;Tyler Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_R/0/1/0/all/0/1&quot;&gt;Rong Ge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07751">
<title>Large Human Language Models: A Need and the Challenges. (arXiv:2312.07751v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.07751</link>
<description rdf:parseType="Literal">&lt;p&gt;As research in human-centered NLP advances, there is a growing recognition of
the importance of incorporating human and social factors into NLP models. At
the same time, our NLP systems have become heavily reliant on LLMs, most of
which do not model authors. To build NLP systems that can truly understand
human language, we must better integrate human contexts into LLMs. This brings
to the fore a range of design considerations and challenges in terms of what
human aspects to capture, how to represent them, and what modeling strategies
to pursue. To address these, we advocate for three positions toward creating
large human language models (LHLMs) using concepts from psychological and
behavioral sciences: First, LM training should include the human context.
Second, LHLMs should recognize that people are more than their group(s). Third,
LHLMs should be able to account for the dynamic and temporally-dependent nature
of the human context. We refer to relevant advances and present open challenges
that need to be addressed and their possible solutions in realizing these
goals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soni_N/0/1/0/all/0/1&quot;&gt;Nikita Soni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1&quot;&gt;H. Andrew Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Sedoc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1&quot;&gt;Niranjan Balasubramanian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07759">
<title>IDKM: Memory Efficient Neural Network Quantization via Implicit, Differentiable $k$-Means. (arXiv:2312.07759v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07759</link>
<description rdf:parseType="Literal">&lt;p&gt;Compressing large neural networks with minimal performance loss is crucial to
enabling their deployment on edge devices. (Cho et al., 2022) proposed a weight
quantization method that uses an attention-based clustering algorithm called
differentiable $k$-means (DKM). Despite achieving state-of-the-art results,
DKM&apos;s performance is constrained by its heavy memory dependency. We propose an
implicit, differentiable $k$-means algorithm (IDKM), which eliminates the major
memory restriction of DKM. Let $t$ be the number of $k$-means iterations, $m$
be the number of weight-vectors, and $b$ be the number of bits per cluster
address. IDKM reduces the overall memory complexity of a single $k$-means layer
from $\mathcal{O}(t \cdot m \cdot 2^b)$ to $\mathcal{O}( m \cdot 2^b)$. We also
introduce a variant, IDKM with Jacobian-Free-Backpropagation (IDKM-JFB), for
which the time complexity of the gradient calculation is independent of $t$ as
well. We provide a proof of concept of our methods by showing that, under the
same settings, IDKM achieves comparable performance to DKM with less compute
time and less memory. We also use IDKM and IDKM-JFB to quantize a large neural
network, Resnet18, on hardware where DKM cannot train at all.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaffe_S/0/1/0/all/0/1&quot;&gt;Sean Jaffe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Ambuj K. Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bullo_F/0/1/0/all/0/1&quot;&gt;Francesco Bullo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07762">
<title>Interpretable factorization of clinical questionnaires to identify latent factors of psychopathology. (arXiv:2312.07762v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07762</link>
<description rdf:parseType="Literal">&lt;p&gt;Psychiatry research seeks to understand the manifestations of psychopathology
in behavior, as measured in questionnaire data, by identifying a small number
of latent factors that explain them. While factor analysis is the traditional
tool for this purpose, the resulting factors may not be interpretable, and may
also be subject to confounding variables. Moreover, missing data are common,
and explicit imputation is often required. To overcome these limitations, we
introduce interpretability constrained questionnaire factorization (ICQF), a
non-negative matrix factorization method with regularization tailored for
questionnaire data. Our method aims to promote factor interpretability and
solution stability. We provide an optimization procedure with theoretical
convergence guarantees, and an automated procedure to detect latent
dimensionality accurately. We validate these procedures using realistic
synthetic data. We demonstrate the effectiveness of our method in a widely used
general-purpose questionnaire, in two independent datasets (the Healthy Brain
Network and Adolescent Brain Cognitive Development studies). Specifically, we
show that ICQF improves interpretability, as defined by domain experts, while
preserving diagnostic information across a range of disorders, and outperforms
competing methods for smaller dataset sizes. This suggests that the
regularization in our method matches domain characteristics. The python
implementation for ICQF is available at
\url{https://github.com/jefferykclam/ICQF}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1&quot;&gt;Ka Chun Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahony_B/0/1/0/all/0/1&quot;&gt;Bridget W Mahony&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raznahan_A/0/1/0/all/0/1&quot;&gt;Armin Raznahan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereira_F/0/1/0/all/0/1&quot;&gt;Francisco Pereira&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07769">
<title>Incremental hierarchical text clustering methods: a review. (arXiv:2312.07769v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07769</link>
<description rdf:parseType="Literal">&lt;p&gt;The growth in Internet usage has contributed to a large volume of
continuously available data, and has created the need for automatic and
efficient organization of the data. In this context, text clustering techniques
are significant because they aim to organize documents according to their
characteristics. More specifically, hierarchical and incremental clustering
techniques can organize dynamic data in a hierarchical form, thus guaranteeing
that this organization is updated and its exploration is facilitated. Based on
the relevance and contemporary nature of the field, this study aims to analyze
various hierarchical and incremental clustering techniques; the main
contribution of this research is the organization and comparison of the
techniques used by studies published between 2010 and 2018 that aimed to texts
documents clustering. We describe the principal concepts related to the
challenge and the different characteristics of these published works in order
to provide a better understanding of the research in this field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simeone_F/0/1/0/all/0/1&quot;&gt;Fernando Simeone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaves_M/0/1/0/all/0/1&quot;&gt;Maik Olher Chaves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esmin_A/0/1/0/all/0/1&quot;&gt;Ahmed Esmin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07781">
<title>Combining propensity score methods with variational autoencoders for generating synthetic data in presence of latent sub-groups. (arXiv:2312.07781v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07781</link>
<description rdf:parseType="Literal">&lt;p&gt;In settings requiring synthetic data generation based on a clinical cohort,
e.g., due to data protection regulations, heterogeneity across individuals
might be a nuisance that we need to control or faithfully preserve. The sources
of such heterogeneity might be known, e.g., as indicated by sub-groups labels,
or might be unknown and thus reflected only in properties of distributions,
such as bimodality or skewness. We investigate how such heterogeneity can be
preserved and controlled when obtaining synthetic data from variational
autoencoders (VAEs), i.e., a generative deep learning technique that utilizes a
low-dimensional latent representation. To faithfully reproduce unknown
heterogeneity reflected in marginal distributions, we propose to combine VAEs
with pre-transformations. For dealing with known heterogeneity due to
sub-groups, we complement VAEs with models for group membership, specifically
from propensity score regression. The evaluation is performed with a realistic
simulation design that features sub-groups and challenging marginal
distributions. The proposed approach faithfully recovers the latter, compared
to synthetic data approaches that focus purely on marginal distributions.
Propensity scores add complementary information, e.g., when visualized in the
latent space, and enable sampling of synthetic data with or without sub-group
specific characteristics. We also illustrate the proposed approach with real
data from an international stroke trial that exhibits considerable distribution
differences between study sites, in addition to bimodality. These results
indicate that describing heterogeneity by statistical approaches, such as
propensity score regression, might be more generally useful for complementing
generative deep learning for obtaining synthetic data that faithfully reflects
structure from clinical cohorts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farhadyar_K/0/1/0/all/0/1&quot;&gt;Kiana Farhadyar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonofiglio_F/0/1/0/all/0/1&quot;&gt;Federico Bonofiglio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hackenberg_M/0/1/0/all/0/1&quot;&gt;Maren Hackenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoeller_D/0/1/0/all/0/1&quot;&gt;Daniela Zoeller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binder_H/0/1/0/all/0/1&quot;&gt;Harald Binder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07784">
<title>Robust MRI Reconstruction by Smoothed Unrolling (SMUG). (arXiv:2312.07784v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.07784</link>
<description rdf:parseType="Literal">&lt;p&gt;As the popularity of deep learning (DL) in the field of magnetic resonance
imaging (MRI) continues to rise, recent research has indicated that DL-based
MRI reconstruction models might be excessively sensitive to minor input
disturbances, including worst-case additive perturbations. This sensitivity
often leads to unstable, aliased images. This raises the question of how to
devise DL techniques for MRI reconstruction that can be robust to train-test
variations. To address this problem, we propose a novel image reconstruction
framework, termed Smoothed Unrolling (SMUG), which advances a deep
unrolling-based MRI reconstruction model using a randomized smoothing
(RS)-based robust learning approach. RS, which improves the tolerance of a
model against input noises, has been widely used in the design of adversarial
defense approaches for image classification tasks. Yet, we find that the
conventional design that applies RS to the entire DL-based MRI model is
ineffective. In this paper, we show that SMUG and its variants address the
above issue by customizing the RS process based on the unrolling architecture
of a DL-based MRI reconstruction model. Compared to the vanilla RS approach, we
show that SMUG improves the robustness of MRI reconstruction with respect to a
diverse set of instability sources, including worst-case and random noise
perturbations to input measurements, varying measurement sampling rates, and
different numbers of unrolling steps. Furthermore, we theoretically analyze the
robustness of our method in the presence of perturbations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liang_S/0/1/0/all/0/1&quot;&gt;Shijun Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_V/0/1/0/all/0/1&quot;&gt;Van Hoang Minh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jia_J/0/1/0/all/0/1&quot;&gt;Jinghan Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Alkhouri_I/0/1/0/all/0/1&quot;&gt;Ismail Alkhouri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ravishankar_S/0/1/0/all/0/1&quot;&gt;Saiprasad Ravishankar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07790">
<title>Characteristic Circuits. (arXiv:2312.07790v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07790</link>
<description rdf:parseType="Literal">&lt;p&gt;In many real-world scenarios, it is crucial to be able to reliably and
efficiently reason under uncertainty while capturing complex relationships in
data. Probabilistic circuits (PCs), a prominent family of tractable
probabilistic models, offer a remedy to this challenge by composing simple,
tractable distributions into a high-dimensional probability distribution.
However, learning PCs on heterogeneous data is challenging and densities of
some parametric distributions are not available in closed form, limiting their
potential use. We introduce characteristic circuits (CCs), a family of
tractable probabilistic models providing a unified formalization of
distributions over heterogeneous data in the spectral domain. The one-to-one
relationship between characteristic functions and probability measures enables
us to learn high-dimensional distributions on heterogeneous data domains and
facilitates efficient probabilistic inference even when no closed-form density
function is available. We show that the structure and parameters of CCs can be
learned efficiently from the data and find that CCs outperform state-of-the-art
density estimators for heterogeneous data domains on common benchmark data
sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhongjie Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trapp_M/0/1/0/all/0/1&quot;&gt;Martin Trapp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1&quot;&gt;Kristian Kersting&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07792">
<title>Differentially private projection-depth-based medians. (arXiv:2312.07792v1 [math.ST])</title>
<link>http://arxiv.org/abs/2312.07792</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop $(\epsilon,\delta)$-differentially private projection-depth-based
medians using the propose-test-release (PTR) and exponential mechanisms. Under
general conditions on the input parameters and the population measure, (e.g. we
do not assume any moment bounds), we quantify the probability the test in PTR
fails, as well as the cost of privacy via finite sample deviation bounds. We
demonstrate our main result on the canonical projection-depth-based median. In
the Gaussian setting, we show that the resulting deviation bound matches the
known lower bound for private Gaussian mean estimation, up to a polynomial
function of the condition number of the covariance matrix. In the Cauchy
setting, we show that the ``outlier error amplification&apos;&apos; effect resulting from
the heavy tails outweighs the cost of privacy. This result is then verified via
numerical simulations. Additionally, we present results on general PTR
mechanisms and a uniform concentration result on the projected spacings of
order statistics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ramsay_K/0/1/0/all/0/1&quot;&gt;Kelly Ramsay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Spicker_D/0/1/0/all/0/1&quot;&gt;Dylan Spicker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07795">
<title>Traffic Signal Control Using Lightweight Transformers: An Offline-to-Online RL Approach. (arXiv:2312.07795v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07795</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient traffic signal control is critical for reducing traffic congestion
and improving overall transportation efficiency. The dynamic nature of traffic
flow has prompted researchers to explore Reinforcement Learning (RL) for
traffic signal control (TSC). Compared with traditional methods, RL-based
solutions have shown preferable performance. However, the application of
RL-based traffic signal controllers in the real world is limited by the low
sample efficiency and high computational requirements of these solutions. In
this work, we propose DTLight, a simple yet powerful lightweight Decision
Transformer-based TSC method that can learn policy from easily accessible
offline datasets. DTLight novelly leverages knowledge distillation to learn a
lightweight controller from a well-trained larger teacher model to reduce
implementation computation. Additionally, it integrates adapter modules to
mitigate the expenses associated with fine-tuning, which makes DTLight
practical for online adaptation with minimal computation and only a few
fine-tuning steps during real deployment. Moreover, DTLight is further enhanced
to be more applicable to real-world TSC problems. Extensive experiments on
synthetic and real-world scenarios show that DTLight pre-trained purely on
offline datasets can outperform state-of-the-art online RL-based methods in
most scenarios. Experiment results also show that online fine-tuning further
improves the performance of DTLight by up to 42.6% over the best online RL
baseline methods. In this work, we also introduce Datasets specifically
designed for TSC with offline RL (referred to as DTRL). Our datasets and code
are publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xingshuai Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Di Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boulet_B/0/1/0/all/0/1&quot;&gt;Benoit Boulet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07802">
<title>Estimation of embedding vectors in high dimensions. (arXiv:2312.07802v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07802</link>
<description rdf:parseType="Literal">&lt;p&gt;Embeddings are a basic initial feature extraction step in many machine
learning models, particularly in natural language processing. An embedding
attempts to map data tokens to a low-dimensional space where similar tokens are
mapped to vectors that are close to one another by some metric in the embedding
space. A basic question is how well can such embedding be learned? To study
this problem, we consider a simple probability model for discrete data where
there is some &quot;true&quot; but unknown embedding where the correlation of random
variables is related to the similarity of the embeddings. Under this model, it
is shown that the embeddings can be learned by a variant of low-rank
approximate message passing (AMP) method. The AMP approach enables precise
predictions of the accuracy of the estimation in certain high-dimensional
limits. In particular, the methodology provides insight on the relations of key
parameters such as the number of samples per value, the frequency of the terms,
and the strength of the embedding correlation on the probability distribution.
Our theoretical findings are validated by simulations on both synthetic data
and real text data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azar_G/0/1/0/all/0/1&quot;&gt;Golara Ahmadi Azar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emami_M/0/1/0/all/0/1&quot;&gt;Melika Emami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fletcher_A/0/1/0/all/0/1&quot;&gt;Alyson Fletcher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rangan_S/0/1/0/all/0/1&quot;&gt;Sundeep Rangan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07813">
<title>On a Foundation Model for Operating Systems. (arXiv:2312.07813v1 [cs.OS])</title>
<link>http://arxiv.org/abs/2312.07813</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper lays down the research agenda for a domain-specific foundation
model for operating systems (OSes). Our case for a foundation model revolves
around the observations that several OS components such as CPU, memory, and
network subsystems are interrelated and that OS traces offer the ideal dataset
for a foundation model to grasp the intricacies of diverse OS components and
their behavior in varying environments and workloads. We discuss a wide range
of possibilities that then arise, from employing foundation models as policy
agents to utilizing them as generators and predictors to assist traditional OS
control algorithms. Our hope is that this paper spurs further research into OS
foundation models and creating the next generation of operating systems for the
evolving computing landscape.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxena_D/0/1/0/all/0/1&quot;&gt;Divyanshu Saxena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1&quot;&gt;Nihal Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Donghyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dwivedula_R/0/1/0/all/0/1&quot;&gt;Rohit Dwivedula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiayi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chenxi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravula_S/0/1/0/all/0/1&quot;&gt;Sriram Ravula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zichao Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akella_A/0/1/0/all/0/1&quot;&gt;Aditya Akella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angel_S/0/1/0/all/0/1&quot;&gt;Sebastian Angel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biswas_J/0/1/0/all/0/1&quot;&gt;Joydeep Biswas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1&quot;&gt;Swarat Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dillig_I/0/1/0/all/0/1&quot;&gt;Isil Dillig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1&quot;&gt;Alex Dimakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godfrey_P/0/1/0/all/0/1&quot;&gt;P. Brighten Godfrey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Daehyeok Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossbach_C/0/1/0/all/0/1&quot;&gt;Chris Rossbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Gang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07821">
<title>Radio Signal Classification by Adversarially Robust Quantum Machine Learning. (arXiv:2312.07821v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2312.07821</link>
<description rdf:parseType="Literal">&lt;p&gt;Radio signal classification plays a pivotal role in identifying the
modulation scheme used in received radio signals, which is essential for
demodulation and proper interpretation of the transmitted information.
Researchers have underscored the high susceptibility of ML algorithms for radio
signal classification to adversarial attacks. Such vulnerability could result
in severe consequences, including misinterpretation of critical messages,
interception of classified information, or disruption of communication
channels. Recent advancements in quantum computing have revolutionized theories
and implementations of computation, bringing the unprecedented development of
Quantum Machine Learning (QML). It is shown that quantum variational
classifiers (QVCs) provide notably enhanced robustness against classical
adversarial attacks in image classification. However, no research has yet
explored whether QML can similarly mitigate adversarial threats in the context
of radio signal classification. This work applies QVCs to radio signal
classification and studies their robustness to various adversarial attacks. We
also propose the novel application of the approximate amplitude encoding (AAE)
technique to encode radio signal data efficiently. Our extensive simulation
results present that attacks generated on QVCs transfer well to CNN models,
indicating that these adversarial examples can fool neural networks that they
are not explicitly designed to attack. However, the converse is not true. QVCs
primarily resist the attacks generated on CNNs. Overall, with comprehensive
simulations, our results shed new light on the growing field of QML by bridging
knowledge gaps in QAML in radio signal classification and uncovering the
advantages of applying QML methods in practical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yanqiu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Adermann_E/0/1/0/all/0/1&quot;&gt;Eromanga Adermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Thapa_C/0/1/0/all/0/1&quot;&gt;Chandra Thapa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Camtepe_S/0/1/0/all/0/1&quot;&gt;Seyit Camtepe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Suzuki_H/0/1/0/all/0/1&quot;&gt;Hajime Suzuki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Usman_M/0/1/0/all/0/1&quot;&gt;Muhammad Usman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07822">
<title>Prototypical Self-Explainable Models Without Re-training. (arXiv:2312.07822v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07822</link>
<description rdf:parseType="Literal">&lt;p&gt;Explainable AI (XAI) has unfolded in two distinct research directions with,
on the one hand, post-hoc methods that explain the predictions of a pre-trained
black-box model and, on the other hand, self-explainable models (SEMs) which
are trained directly to provide explanations alongside their predictions. While
the latter is preferred in most safety-critical scenarios, post-hoc approaches
have received the majority of attention until now, owing to their simplicity
and ability to explain base models without retraining. Current SEMs instead,
require complex architectures and heavily regularized loss functions, thus
necessitating specific and costly training. To address this shortcoming and
facilitate wider use of SEMs, we propose a simple yet efficient universal
method called KMEx (K-Means Explainer), which can convert any existing
pre-trained model into a prototypical SEM. The motivation behind KMEx is to
push towards more transparent deep learning-based decision-making via
class-prototype-based explanations that are guaranteed to be diverse and
trustworthy without retraining the base model. We compare models obtained from
KMEx to state-of-the-art SEMs using an extensive qualitative evaluation to
highlight the strengths and weaknesses of each model, further paving the way
toward a more reliable and objective evaluation of SEMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gautam_S/0/1/0/all/0/1&quot;&gt;Srishti Gautam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boubekki_A/0/1/0/all/0/1&quot;&gt;Ahcene Boubekki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hohne_M/0/1/0/all/0/1&quot;&gt;Marina M. C. H&amp;#xf6;hne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1&quot;&gt;Michael C. Kampffmeyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07831">
<title>Abusive Span Detection for Vietnamese Narrative Texts. (arXiv:2312.07831v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.07831</link>
<description rdf:parseType="Literal">&lt;p&gt;Abuse in its various forms, including physical, psychological, verbal,
sexual, financial, and cultural, has a negative impact on mental health.
However, there are limited studies on applying natural language processing
(NLP) in this field in Vietnam. Therefore, we aim to contribute by building a
human-annotated Vietnamese dataset for detecting abusive content in Vietnamese
narrative texts. We sourced these texts from VnExpress, Vietnam&apos;s popular
online newspaper, where readers often share stories containing abusive content.
Identifying and categorizing abusive spans in these texts posed significant
challenges during dataset creation, but it also motivated our research. We
experimented with lightweight baseline models by freezing PhoBERT and
XLM-RoBERTa and using their hidden states in a BiLSTM to assess the complexity
of the dataset. According to our experimental results, PhoBERT outperforms
other models in both labeled and unlabeled abusive span detection tasks. These
results indicate that it has the potential for future improvements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Nhu-Thanh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_K/0/1/0/all/0/1&quot;&gt;Khoa Thi-Kim Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Duc-Vu Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Ngan Luu-Thuy Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07833">
<title>Stable Rivers: A Case Study in the Application of Text-to-Image Generative Models for Earth Sciences. (arXiv:2312.07833v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07833</link>
<description rdf:parseType="Literal">&lt;p&gt;Text-to-image (TTI) generative models can be used to generate photorealistic
images from a given text-string input. These models offer great potential to
mitigate challenges to the uptake of machine learning in the earth sciences.
However, the rapid increase in their use has raised questions about fairness
and biases, with most research to-date focusing on social and cultural areas
rather than domain-specific considerations. We conducted a case study for the
earth sciences, focusing on the field of fluvial geomorphology, where we
evaluated subject-area specific biases in the training data and downstream
model performance of Stable Diffusion (v1.5). In addition to perpetuating
Western biases, we found that the training data over-represented scenic
locations, such as famous rivers and waterfalls, and showed serious under- and
over-representation of many morphological and environmental terms. Despite
biased training data, we found that with careful prompting, the Stable
Diffusion model was able to generate photorealistic synthetic river images
reproducing many important environmental and morphological characteristics.
Furthermore, conditional control techniques, such as the use of condition maps
with ControlNet were effective for providing additional constraints on output
images. Despite great potential for the use of TTI models in the earth sciences
field, we advocate for caution in sensitive applications, and advocate for
domain-specific reviews of training data and image generation biases to
mitigate perpetuation of existing biases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kupferschmidt_C/0/1/0/all/0/1&quot;&gt;C Kupferschmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binns_A/0/1/0/all/0/1&quot;&gt;A.D. Binns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kupferschmidt_K/0/1/0/all/0/1&quot;&gt;K.L. Kupferschmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1&quot;&gt;G.W Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07835">
<title>Video Dynamics Prior: An Internal Learning Approach for Robust Video Enhancements. (arXiv:2312.07835v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07835</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a novel robust framework for low-level vision
tasks, including denoising, object removal, frame interpolation, and
super-resolution, that does not require any external training data corpus. Our
proposed approach directly learns the weights of neural modules by optimizing
over the corrupted test sequence, leveraging the spatio-temporal coherence and
internal statistics of videos. Furthermore, we introduce a novel spatial
pyramid loss that leverages the property of spatio-temporal patch recurrence in
a video across the different scales of the video. This loss enhances robustness
to unstructured noise in both the spatial and temporal domains. This further
results in our framework being highly robust to degradation in input frames and
yields state-of-the-art results on downstream tasks such as denoising, object
removal, and frame interpolation. To validate the effectiveness of our
approach, we conduct qualitative and quantitative evaluations on standard video
datasets such as DAVIS, UCF-101, and VIMEO90K-T.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrivastava_G/0/1/0/all/0/1&quot;&gt;Gaurav Shrivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1&quot;&gt;Ser-Nam Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1&quot;&gt;Abhinav Shrivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07837">
<title>Synthetic Data: Can We Trust Statistical Estimators?. (arXiv:2312.07837v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07837</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing interest in data sharing makes synthetic data appealing.
However, the analysis of synthetic data raises a unique set of methodological
challenges. In this work, we highlight the importance of inferential utility
and provide empirical evidence against naive inference from synthetic data
(that handles these as if they were really observed). We argue that the rate of
false-positive findings (type 1 error) will be unacceptably high, even when the
estimates are unbiased. One of the reasons is the underestimation of the true
standard error, which may even progressively increase with larger sample sizes
due to slower convergence. This is especially problematic for deep generative
models. Before publishing synthetic data, it is essential to develop
statistical inference tools for such data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Decruyenaere_A/0/1/0/all/0/1&quot;&gt;Alexander Decruyenaere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dehaene_H/0/1/0/all/0/1&quot;&gt;Heidelinde Dehaene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabaey_P/0/1/0/all/0/1&quot;&gt;Paloma Rabaey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polet_C/0/1/0/all/0/1&quot;&gt;Christiaan Polet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Decruyenaere_J/0/1/0/all/0/1&quot;&gt;Johan Decruyenaere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vansteelandt_S/0/1/0/all/0/1&quot;&gt;Stijn Vansteelandt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1&quot;&gt;Thomas Demeester&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07839">
<title>Minimax-optimal estimation for sparse multi-reference alignment with collision-free signals. (arXiv:2312.07839v1 [math.ST])</title>
<link>http://arxiv.org/abs/2312.07839</link>
<description rdf:parseType="Literal">&lt;p&gt;The Multi-Reference Alignment (MRA) problem aims at the recovery of an
unknown signal from repeated observations under the latent action of a group of
cyclic isometries, in the presence of additive noise of high intensity
$\sigma$. It is a more tractable version of the celebrated cryo EM model. In
the crucial high noise regime, it is known that its sample complexity scales as
$\sigma^6$. Recent investigations have shown that for the practically
significant setting of sparse signals, the sample complexity of the maximum
likelihood estimator asymptotically scales with the noise level as $\sigma^4$.
In this work, we investigate minimax optimality for signal estimation under the
MRA model for so-called collision-free signals. In particular, this signal
class covers the setting of generic signals of dilute sparsity (wherein the
support size $s=O(L^{1/3})$, where $L$ is the ambient dimension.
&lt;/p&gt;
&lt;p&gt;We demonstrate that the minimax optimal rate of estimation in for the sparse
MRA problem in this setting is $\sigma^2/\sqrt{n}$, where $n$ is the sample
size. In particular, this widely generalizes the sample complexity asymptotics
for the restricted MLE in this setting, establishing it as the statistically
optimal estimator. Finally, we demonstrate a concentration inequality for the
restricted MLE on its deviations from the ground truth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Subhro Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mukherjee_S/0/1/0/all/0/1&quot;&gt;Soumendu Sundar Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pan_J/0/1/0/all/0/1&quot;&gt;Jing Bin Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07841">
<title>On the Dynamics Under the Unhinged Loss and Beyond. (arXiv:2312.07841v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07841</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent works have studied implicit biases in deep learning, especially the
behavior of last-layer features and classifier weights. However, they usually
need to simplify the intermediate dynamics under gradient flow or gradient
descent due to the intractability of loss functions and model architectures. In
this paper, we introduce the unhinged loss, a concise loss function, that
offers more mathematical opportunities to analyze the closed-form dynamics
while requiring as few simplifications or assumptions as possible. The unhinged
loss allows for considering more practical techniques, such as time-vary
learning rates and feature normalization. Based on the layer-peeled model that
views last-layer features as free optimization variables, we conduct a thorough
analysis in the unconstrained, regularized, and spherical constrained cases, as
well as the case where the neural tangent kernel remains invariant. To bridge
the performance of the unhinged loss to that of Cross-Entropy (CE), we
investigate the scenario of fixing classifier weights with a specific
structure, (e.g., a simplex equiangular tight frame). Our analysis shows that
these dynamics converge exponentially fast to a solution depending on the
initialization of features and classifier weights. These theoretical results
not only offer valuable insights, including explicit feature regularization and
rescaled learning rates for enhancing practical training with the unhinged
loss, but also extend their applicability to other loss functions. Finally, we
empirically demonstrate these theoretical results and insights through
extensive experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1&quot;&gt;Xiong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xianming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hanzhang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhai_D/0/1/0/all/0/1&quot;&gt;Deming Zhai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Junjun Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1&quot;&gt;Xiangyang Ji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07851">
<title>Noise in the reverse process improves the approximation capabilities of diffusion models. (arXiv:2312.07851v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07851</link>
<description rdf:parseType="Literal">&lt;p&gt;In Score based Generative Modeling (SGMs), the state-of-the-art in generative
modeling, stochastic reverse processes are known to perform better than their
deterministic counterparts. This paper delves into the heart of this
phenomenon, comparing neural ordinary differential equations (ODEs) and neural
stochastic differential equations (SDEs) as reverse processes. We use a control
theoretic perspective by posing the approximation of the reverse process as a
trajectory tracking problem. We analyze the ability of neural SDEs to
approximate trajectories of the Fokker-Planck equation, revealing the
advantages of stochasticity. First, neural SDEs exhibit a powerful regularizing
effect, enabling $L^2$ norm trajectory approximation surpassing the Wasserstein
metric approximation achieved by neural ODEs under similar conditions, even
when the reference vector field or score function is not Lipschitz. Applying
this result, we establish the class of distributions that can be sampled using
score matching in SGMs, relaxing the Lipschitz requirement on the gradient of
the data distribution in existing literature. Second, we show that this
approximation property is preserved when network width is limited to the input
dimension of the network. In this limited width case, the weights act as
control inputs, framing our analysis as a controllability problem for neural
SDEs in probability density space. This sheds light on how noise helps to steer
the system towards the desired solution and illuminates the empirical success
of stochasticity in generative modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elamvazhuthi_K/0/1/0/all/0/1&quot;&gt;Karthik Elamvazhuthi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasqualetti_F/0/1/0/all/0/1&quot;&gt;Fabio Pasqualetti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07854">
<title>Diffusion Models Enable Zero-Shot Pose Estimation for Lower-Limb Prosthetic Users. (arXiv:2312.07854v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07854</link>
<description rdf:parseType="Literal">&lt;p&gt;The application of 2D markerless gait analysis has garnered increasing
interest and application within clinical settings. However, its effectiveness
in the realm of lower-limb amputees has remained less than optimal. In
response, this study introduces an innovative zero-shot method employing image
generation diffusion models to achieve markerless pose estimation for
lower-limb prosthetics, presenting a promising solution to gait analysis for
this specific population. Our approach demonstrates an enhancement in detecting
key points on prosthetic limbs over existing methods, and enables clinicians to
gain invaluable insights into the kinematics of lower-limb amputees across the
gait cycle. The outcomes obtained not only serve as a proof-of-concept for the
feasibility of this zero-shot approach but also underscore its potential in
advancing rehabilitation through gait analysis for this unique population.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tianxun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iskandar_M/0/1/0/all/0/1&quot;&gt;Muhammad Nur Shahril Iskandar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiam_K/0/1/0/all/0/1&quot;&gt;Keng-Hwee Chiam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07855">
<title>Exploring Popularity Bias in Session-based Recommendation. (arXiv:2312.07855v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2312.07855</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing work has revealed that large-scale offline evaluation of recommender
systems for user-item interactions is prone to bias caused by the deployed
system itself, as a form of closed loop feedback. Many adopt the
\textit{propensity} concept to analyze or mitigate this empirical issue. In
this work, we extend the analysis to session-based setup and adapted propensity
calculation to the unique characteristics of session-based recommendation
tasks. Our experiments incorporate neural models and KNN-based models, and
cover both the music and the e-commerce domain. We study the distributions of
propensity and different stratification techniques on different datasets and
find that propensity-related traits are actually dataset-specific. We then
leverage the effect of stratification and achieve promising results compared to
the original models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haowen Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07859">
<title>Invariant Graph Transformer. (arXiv:2312.07859v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07859</link>
<description rdf:parseType="Literal">&lt;p&gt;Rationale discovery is defined as finding a subset of the input data that
maximally supports the prediction of downstream tasks. In graph machine
learning context, graph rationale is defined to locate the critical subgraph in
the given graph topology, which fundamentally determines the prediction
results. In contrast to the rationale subgraph, the remaining subgraph is named
the environment subgraph. Graph rationalization can enhance the model
performance as the mapping between the graph rationale and prediction label is
viewed as invariant, by assumption. To ensure the discriminative power of the
extracted rationale subgraphs, a key technique named &quot;intervention&quot; is applied.
The core idea of intervention is that given any changing environment subgraphs,
the semantics from the rationale subgraph is invariant, which guarantees the
correct prediction result. However, most, if not all, of the existing
rationalization works on graph data develop their intervention strategies on
the graph level, which is coarse-grained. In this paper, we propose
well-tailored intervention strategies on graph data. Our idea is driven by the
development of Transformer models, whose self-attention module provides rich
interactions between input nodes. Based on the self-attention module, our
proposed invariant graph Transformer (IGT) can achieve fine-grained, more
specifically, node-level and virtual node-level intervention. Our comprehensive
experiments involve 7 real-world datasets, and the proposed IGT shows
significant performance advantages compared to 13 baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhe Xu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_M/0/1/0/all/0/1&quot;&gt;Menghai Pan&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuzhong Chen&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huiyuan Chen&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1&quot;&gt;Yuchen Yan&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_M/0/1/0/all/0/1&quot;&gt;Mahashweta Das&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1&quot;&gt;Hanghang Tong&lt;/a&gt; (1) ((1) University of Illinois Urbana-Champaign, (2) Visa Research)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07861">
<title>GraphGuard: Detecting and Counteracting Training Data Misuse in Graph Neural Networks. (arXiv:2312.07861v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07861</link>
<description rdf:parseType="Literal">&lt;p&gt;The emergence of Graph Neural Networks (GNNs) in graph data analysis and
their deployment on Machine Learning as a Service platforms have raised
critical concerns about data misuse during model training. This situation is
further exacerbated due to the lack of transparency in local training
processes, potentially leading to the unauthorized accumulation of large
volumes of graph data, thereby infringing on the intellectual property rights
of data owners. Existing methodologies often address either data misuse
detection or mitigation, and are primarily designed for local GNN models rather
than cloud-based MLaaS platforms. These limitations call for an effective and
comprehensive solution that detects and mitigates data misuse without requiring
exact training data while respecting the proprietary nature of such data. This
paper introduces a pioneering approach called GraphGuard, to tackle these
challenges. We propose a training-data-free method that not only detects graph
data misuse but also mitigates its impact via targeted unlearning, all without
relying on the original training data. Our innovative misuse detection
technique employs membership inference with radioactive data, enhancing the
distinguishability between member and non-member data distributions. For
mitigation, we utilize synthetic graphs that emulate the characteristics
previously learned by the target model, enabling effective unlearning even in
the absence of exact graph data. We conduct comprehensive experiments utilizing
four real-world graph datasets to demonstrate the efficacy of GraphGuard in
both detection and unlearning. We show that GraphGuard attains a near-perfect
detection rate of approximately 100% across these datasets with various GNN
models. In addition, it performs unlearning by eliminating the impact of the
unlearned graph with a marginal decrease in accuracy (less than 5%).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1&quot;&gt;Bang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;He Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xiangwen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shuo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1&quot;&gt;Minhui Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1&quot;&gt;Shirui Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xingliang Yuan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07887">
<title>Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models. (arXiv:2312.07887v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.07887</link>
<description rdf:parseType="Literal">&lt;p&gt;Incremental Learning (IL) has been a long-standing problem in both vision and
Natural Language Processing (NLP) communities. In recent years, as Pre-trained
Language Models (PLMs) have achieved remarkable progress in various NLP
downstream tasks, utilizing PLMs as backbones has become a common practice in
recent research of IL in NLP. Most assume that catastrophic forgetting is the
biggest obstacle to achieving superior IL performance and propose various
techniques to overcome this issue. However, we find that this assumption is
problematic. Specifically, we revisit more than 20 methods on four
classification tasks (Text Classification, Intent Classification, Relation
Extraction, and Named Entity Recognition) under the two most popular IL
settings (Class-Incremental and Task-Incremental) and reveal that most of them
severely underestimate the inherent anti-forgetting ability of PLMs. Based on
the observation, we propose a frustratingly easy method called SEQ* for IL with
PLMs. The results show that SEQ* has competitive or superior performance
compared to state-of-the-art (SOTA) IL methods and requires considerably less
trainable parameters and training time. These findings urge us to revisit the
IL with PLMs and encourage future studies to have a fundamental understanding
of the catastrophic forgetting in PLMs. The data, code and scripts are publicly
available at
https://github.com/zzz47zzz/pretrained-lm-for-incremental-learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Junhao Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1&quot;&gt;Shengjie Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1&quot;&gt;Qianli Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07899">
<title>Morphological Profiling for Drug Discovery in the Era of Deep Learning. (arXiv:2312.07899v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/2312.07899</link>
<description rdf:parseType="Literal">&lt;p&gt;Morphological profiling is a valuable tool in phenotypic drug discovery. The
advent of high-throughput automated imaging has enabled the capturing of a wide
range of morphological features of cells or organisms in response to
perturbations at the single-cell resolution. Concurrently, significant advances
in machine learning and deep learning, especially in computer vision, have led
to substantial improvements in analyzing large-scale high-content images at
high-throughput. These efforts have facilitated understanding of compound
mechanism-of-action (MOA), drug repurposing, characterization of cell
morphodynamics under perturbation, and ultimately contributing to the
development of novel therapeutics. In this review, we provide a comprehensive
overview of the recent advances in the field of morphological profiling. We
summarize the image profiling analysis workflow, survey a broad spectrum of
analysis strategies encompassing feature engineering- and deep learning-based
approaches, and introduce publicly available benchmark datasets. We place a
particular emphasis on the application of deep learning in this pipeline,
covering cell segmentation, image representation learning, and multimodal
learning. Additionally, we illuminate the application of morphological
profiling in phenotypic drug discovery and highlight potential challenges and
opportunities in this field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tang_Q/0/1/0/all/0/1&quot;&gt;Qiaosi Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ratnayake_R/0/1/0/all/0/1&quot;&gt;Ranjala Ratnayake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Seabra_G/0/1/0/all/0/1&quot;&gt;Gustavo Seabra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Zhe Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Fang_R/0/1/0/all/0/1&quot;&gt;Ruogu Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Lina Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ding_Y/0/1/0/all/0/1&quot;&gt;Yousong Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kahveci_T/0/1/0/all/0/1&quot;&gt;Tamer Kahveci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Bian_J/0/1/0/all/0/1&quot;&gt;Jiang Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chenglong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Luesch_H/0/1/0/all/0/1&quot;&gt;Hendrik Luesch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yanjun Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07910">
<title>PromptBench: A Unified Library for Evaluation of Large Language Models. (arXiv:2312.07910v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.07910</link>
<description rdf:parseType="Literal">&lt;p&gt;The evaluation of large language models (LLMs) is crucial to assess their
performance and mitigate potential security risks. In this paper, we introduce
PromptBench, a unified library to evaluate LLMs. It consists of several key
components that are easily used and extended by researchers: prompt
construction, prompt engineering, dataset and model loading, adversarial prompt
attack, dynamic evaluation protocols, and analysis tools. PromptBench is
designed to be an open, general, and flexible codebase for research purposes
that can facilitate original study in creating new benchmarks, deploying
downstream applications, and designing new evaluation protocols. The code is
available at: https://github.com/microsoft/promptbench and will be continuously
supported.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1&quot;&gt;Kaijie Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qinlin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07929">
<title>Robust and Performance Incentivizing Algorithms for Multi-Armed Bandits with Strategic Agents. (arXiv:2312.07929v1 [cs.GT])</title>
<link>http://arxiv.org/abs/2312.07929</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a variant of the stochastic multi-armed bandit problem.
Specifically, the arms are strategic agents who can improve their rewards or
absorb them. The utility of an agent increases if she is pulled more or absorbs
more of her rewards but decreases if she spends more effort improving her
rewards. Agents have heterogeneous properties, specifically having different
means and able to improve their rewards up to different levels. Further, a
non-empty subset of agents are &apos;&apos;honest&apos;&apos; and in the worst case always give
their rewards without absorbing any part. The principal wishes to obtain a high
revenue (cumulative reward) by designing a mechanism that incentives top level
performance at equilibrium. At the same time, the principal wishes to be robust
and obtain revenue at least at the level of the honest agent with the highest
mean in case of non-equilibrium behaviour. We identify a class of MAB
algorithms which we call performance incentivizing which satisfy a collection
of properties and show that they lead to mechanisms that incentivize top level
performance at equilibrium and are robust under any strategy profile.
Interestingly, we show that UCB is an example of such a MAB algorithm. Further,
in the case where the top performance level is unknown we show that combining
second price auction ideas with performance incentivizing algorithms achieves
performance at least at the second top level while also being robust.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esmaeili_S/0/1/0/all/0/1&quot;&gt;Seyed A. Esmaeili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1&quot;&gt;Suho Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1&quot;&gt;Aleksandrs Slivkins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07930">
<title>Towards Optimal Statistical Watermarking. (arXiv:2312.07930v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07930</link>
<description rdf:parseType="Literal">&lt;p&gt;We study statistical watermarking by formulating it as a hypothesis testing
problem, a general framework which subsumes all previous statistical
watermarking methods. Key to our formulation is a coupling of the output tokens
and the rejection region, realized by pseudo-random generators in practice,
that allows non-trivial trade-off between the Type I error and Type II error.
We characterize the Uniformly Most Powerful (UMP) watermark in this context. In
the most common scenario where the output is a sequence of $n$ tokens, we
establish matching upper and lower bounds on the number of i.i.d. tokens
required to guarantee small Type I and Type II errors. Our rate scales as
$\Theta(h^{-1} \log (1/h))$ with respect to the average entropy per token $h$
and thus greatly improves the $O(h^{-2})$ rate in the previous works. For
scenarios where the detector lacks knowledge of the model&apos;s distribution, we
introduce the concept of model-agnostic watermarking and establish the minimax
bounds for the resultant increase in Type II error. Moreover, we formulate the
robust watermarking problem where user is allowed to perform a class of
perturbation on the generated texts, and characterize the optimal type II error
of robust UMP tests via a linear programming problem. To the best of our
knowledge, this is the first systematic statistical treatment on the
watermarking problem with near-optimal rates in the i.i.d. setting, and might
be of interest for future works.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Baihe Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1&quot;&gt;Banghua Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hanlin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason D. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jiantao Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07931">
<title>Levenshtein Distance Embedding with Poisson Regression for DNA Storage. (arXiv:2312.07931v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07931</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient computation or approximation of Levenshtein distance, a widely-used
metric for evaluating sequence similarity, has attracted significant attention
with the emergence of DNA storage and other biological applications. Sequence
embedding, which maps Levenshtein distance to a conventional distance between
embedding vectors, has emerged as a promising solution. In this paper, a novel
neural network-based sequence embedding technique using Poisson regression is
proposed. We first provide a theoretical analysis of the impact of embedding
dimension on model performance and present a criterion for selecting an
appropriate embedding dimension. Under this embedding dimension, the Poisson
regression is introduced by assuming the Levenshtein distance between sequences
of fixed length following a Poisson distribution, which naturally aligns with
the definition of Levenshtein distance. Moreover, from the perspective of the
distribution of embedding distances, Poisson regression approximates the
negative log likelihood of the chi-squared distribution and offers advancements
in removing the skewness. Through comprehensive experiments on real DNA storage
data, we demonstrate the superior performance of the proposed method compared
to state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1&quot;&gt;Xiang Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_A/0/1/0/all/0/1&quot;&gt;Alan J.X. Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Sihan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_M/0/1/0/all/0/1&quot;&gt;Mengyi Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wei Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07945">
<title>Linear Combination of Exponential Moving Averages for Wireless Channel Prediction. (arXiv:2312.07945v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2312.07945</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to predict the behavior of a wireless channel in terms of the
frame delivery ratio is quite valuable, and permits, e.g., to optimize the
operating parameters of a wireless network at runtime, or to proactively react
to the degradation of the channel quality, in order to meet the stringent
requirements about dependability and end-to-end latency that typically
characterize industrial applications.
&lt;/p&gt;
&lt;p&gt;In this work, prediction models based on the exponential moving average (EMA)
are investigated in depth, which are proven to outperform other simple
statistical methods and whose performance is nearly as good as artificial
neural networks, but with dramatically lower computational requirements.
Regarding the innovation and motivation of this work, a new model that we
called EMA linear combination (ELC), is introduced, explained, and evaluated
experimentally.
&lt;/p&gt;
&lt;p&gt;Its prediction accuracy, tested on some databases acquired from a real setup
based on Wi-Fi devices, showed that ELC brings tangible improvements over EMA
in any experimental conditions, the only drawback being a slight increase in
computational complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Formis_G/0/1/0/all/0/1&quot;&gt;Gabriele Formis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scanzio_S/0/1/0/all/0/1&quot;&gt;Stefano Scanzio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cena_G/0/1/0/all/0/1&quot;&gt;Gianluca Cena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valenzano_A/0/1/0/all/0/1&quot;&gt;Adriano Valenzano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07950">
<title>CBQ: Cross-Block Quantization for Large Language Models. (arXiv:2312.07950v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07950</link>
<description rdf:parseType="Literal">&lt;p&gt;Post-training quantization (PTQ) has driven attention to producing efficient
large language models (LLMs) with ultra-low costs. Since hand-craft
quantization parameters lead to low performance in low-bit quantization, recent
methods optimize the quantization parameters through block-wise reconstruction
between the floating-point and quantized models. However, these methods suffer
from two challenges: accumulated errors from independent one-by-one block
quantization and reconstruction difficulties from extreme weight and activation
outliers. To address these two challenges, we propose CBQ, a cross-block
reconstruction-based PTQ method for LLMs. To reduce error accumulation, we
introduce a cross-block dependency with the aid of a homologous reconstruction
scheme to build the long-range dependency between adjacent multi-blocks with
overlapping. To reduce reconstruction difficulty, we design a coarse-to-fine
pre-processing (CFP) to truncate weight outliers and dynamically scale
activation outliers before optimization, and an adaptive rounding scheme,
called LoRA-Rounding, with two low-rank learnable matrixes to further rectify
weight quantization errors. Extensive experiments demonstrate that: (1) CBQ
pushes both activation and weight quantization to low-bit settings W4A4, W4A8,
and W2A16. (2) CBQ achieves better performance than the existing
state-of-the-art methods on various LLMs and benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1&quot;&gt;Xin Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1&quot;&gt;Zhijun Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jie Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hanting Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yehui Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1&quot;&gt;Baoqun Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yunhe Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07952">
<title>Meta-learning to Calibrate Gaussian Processes with Deep Kernels for Regression Uncertainty Estimation. (arXiv:2312.07952v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.07952</link>
<description rdf:parseType="Literal">&lt;p&gt;Although Gaussian processes (GPs) with deep kernels have been successfully
used for meta-learning in regression tasks, its uncertainty estimation
performance can be poor. We propose a meta-learning method for calibrating deep
kernel GPs for improving regression uncertainty estimation performance with a
limited number of training data. The proposed method meta-learns how to
calibrate uncertainty using data from various tasks by minimizing the test
expected calibration error, and uses the knowledge for unseen tasks. We design
our model such that the adaptation and calibration for each task can be
performed without iterative procedures, which enables effective meta-learning.
In particular, a task-specific uncalibrated output distribution is modeled by a
GP with a task-shared encoder network, and it is transformed to a calibrated
one using a cumulative density function of a task-specific Gaussian mixture
model (GMM). By integrating the GP and GMM into our neural network-based model,
we can meta-learn model parameters in an end-to-end fashion. Our experiments
demonstrate that the proposed method improves uncertainty estimation
performance while keeping high regression performance compared with the
existing methods using real-world datasets in few-shot settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1&quot;&gt;Tomoharu Iwata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kumagai_A/0/1/0/all/0/1&quot;&gt;Atsutoshi Kumagai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07953">
<title>Enhancing Robotic Navigation: An Evaluation of Single and Multi-Objective Reinforcement Learning Strategies. (arXiv:2312.07953v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.07953</link>
<description rdf:parseType="Literal">&lt;p&gt;This study presents a comparative analysis between single-objective and
multi-objective reinforcement learning methods for training a robot to navigate
effectively to an end goal while efficiently avoiding obstacles. Traditional
reinforcement learning techniques, namely Deep Q-Network (DQN), Deep
Deterministic Policy Gradient (DDPG), and Twin Delayed DDPG (TD3), have been
evaluated using the Gazebo simulation framework in a variety of environments
with parameters such as random goal and robot starting locations. These methods
provide a numerical reward to the robot, offering an indication of action
quality in relation to the goal. However, their limitations become apparent in
complex settings where multiple, potentially conflicting, objectives are
present. To address these limitations, we propose an approach employing
Multi-Objective Reinforcement Learning (MORL). By modifying the reward function
to return a vector of rewards, each pertaining to a distinct objective, the
robot learns a policy that effectively balances the different goals, aiming to
achieve a Pareto optimal solution. This comparative study highlights the
potential for MORL in complex, dynamic robotic navigation tasks, setting the
stage for future investigations into more adaptable and robust robotic
behaviors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Young_V/0/1/0/all/0/1&quot;&gt;Vicki Young&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hossain_J/0/1/0/all/0/1&quot;&gt;Jumman Hossain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_N/0/1/0/all/0/1&quot;&gt;Nirmalya Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07955">
<title>Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking. (arXiv:2312.07955v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.07955</link>
<description rdf:parseType="Literal">&lt;p&gt;Researchers have recently found that Self-Supervised Learning (SSL) is
vulnerable to backdoor attacks. The attacker can embed hidden SSL backdoors via
a few poisoned examples in the training dataset and maliciously manipulate the
behavior of downstream models. To defend against SSL backdoor attacks, a
feasible route is to detect and remove the poisonous samples in the training
set. However, the existing SSL backdoor defense method fails to detect the
poisonous samples precisely. In this paper, we propose to erase the SSL
backdoor by cluster activation masking and propose a novel PoisonCAM method.
After obtaining the threat model trained on the poisoned dataset, our method
can precisely detect poisonous samples based on the assumption that masking the
backdoor trigger can effectively change the activation of a downstream
clustering model. In experiments, our PoisonCAM achieves 96% accuracy for
backdoor trigger detection compared to 3% of the state-of-the-art method on
poisoned ImageNet-100. Moreover, our proposed PoisonCAM significantly improves
the performance of the trained SSL model under backdoor attacks compared to the
state-of-the-art method. Our code will be available at
https://github.com/LivXue/PoisonCAM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1&quot;&gt;Shengsheng Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yifei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_D/0/1/0/all/0/1&quot;&gt;Dizhan Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shengjie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huaiwen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Changsheng Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07965">
<title>Pneumonia Detection on chest X-ray images Using Ensemble of Deep Convolutional Neural Networks. (arXiv:2312.07965v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.07965</link>
<description rdf:parseType="Literal">&lt;p&gt;Pneumonia is a life-threatening lung infection resulting from several
different viral infections. Identifying and treating pneumonia on chest X-ray
images can be difficult due to its similarity to other pulmonary diseases.
Thus, the existing methods for predicting pneumonia cannot attain substantial
levels of accuracy. Therefore, this paper presents a computer-aided
classification of pneumonia, coined as Ensemble Learning (EL), to simplify the
diagnosis process on chest X-ray images. Our proposal is based on Convolutional
Neural Network (CNN) models, which are pre-trained CNN models that have been
recently employed to enhance the performance of many medical tasks instead of
training CNN models from scratch. We propose to use three well-known CNN
pre-trained (DenseNet169, MobileNetV2 and Vision Transformer) using the
ImageNet database. Then, these models are trained on the chest X-ray data set
using fine-tuning. Finally, the results are obtained by combining the extracted
features from these three models during the experimental phase. The proposed EL
approach outperforms other existing state-of-the-art methods, and it obtains an
accuracy of 93.91% and a F1-Score of 93.88% on the testing phase.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mabrouk_A/0/1/0/all/0/1&quot;&gt;Alhassan Mabrouk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Redondo_R/0/1/0/all/0/1&quot;&gt;Rebeca P. D&amp;#xed;az Redondo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dahou_A/0/1/0/all/0/1&quot;&gt;Abdelghani Dahou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Elaziz_M/0/1/0/all/0/1&quot;&gt;Mohamed Abd Elaziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kayed_M/0/1/0/all/0/1&quot;&gt;Mohammed Kayed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07977">
<title>Modeling non-genetic information dynamics in cells using reservoir computing. (arXiv:2312.07977v1 [q-bio.CB])</title>
<link>http://arxiv.org/abs/2312.07977</link>
<description rdf:parseType="Literal">&lt;p&gt;Virtually all cells use energy and ion-specific membrane pumps to maintain
large transmembrane gradients of Na$^+$, K$^+$, Cl$^-$, Mg$^{++}$, and
Ca$^{++}$. Although they consume up to 1/3 of a cell&apos;s energy budget, the
corresponding evolutionary benefit of transmembrane ion gradients remain
unclear. Here, we propose that ion gradients enable a dynamic and versatile
biological system that acquires, analyzes, and responds to environmental
information. We hypothesize environmental signals are transmitted into the cell
by ion fluxes along pre-existing gradients through gated ion-specific membrane
channels. The consequent changes of cytoplasmic ion concentration can generate
a local response and orchestrate global or regional responses through wire-like
ion fluxes along pre-existing and self-assembling cytoskeleton to engage the
endoplasmic reticulum, mitochondria, and nucleus.
&lt;/p&gt;
&lt;p&gt;Here, we frame our hypothesis through a quasi-physical (Cell-Reservoir) model
that treats intra-cellular ion-based information dynamics as a sub-cellular
process permitting spatiotemporally resolved cellular response that is also
capable of learning complex nonlinear dynamical cellular behavior. We
demonstrate the proposed ion dynamics permits rapid dissemination of response
to information extrinsic perturbations that is consistent with experimental
observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Niraula_D/0/1/0/all/0/1&quot;&gt;Dipesh Niraula&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Naqa_I/0/1/0/all/0/1&quot;&gt;Issam El Naqa&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tuszynski_J/0/1/0/all/0/1&quot;&gt;Jack Adam Tuszynski&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gatenby_R/0/1/0/all/0/1&quot;&gt;Robert A. Gatenby&lt;/a&gt; (3) ((1) Department of Machine Learning, Moffitt Cancer Center, Tampa, FL, USA (2) Departments of Physics and Oncology, University of Alberta, Edmonton, AB, CAN (3) Departments of Radiology and Integrated Mathematical Oncology, Moffitt Cancer Center, Tampa, FL, USA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07979">
<title>SLJP: Semantic Extraction based Legal Judgment Prediction. (arXiv:2312.07979v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.07979</link>
<description rdf:parseType="Literal">&lt;p&gt;Legal Judgment Prediction (LJP) is a judicial assistance system that
recommends the legal components such as applicable statues, prison term and
penalty term by analyzing the given input case document. Indian legal system is
in the need of technical assistance such as artificial intelligence to solve
the crores of pending cases in various courts for years and its being increased
day to day. Most of the existing Indian models did not adequately concentrate
on the semantics embedded in the fact description (FD) that impacts the
decision. The proposed semantic extraction based LJP (SLJP) model provides the
advantages of pretrained transformers for complex unstructured legal case
document understanding and to generate embeddings. The model draws the in-depth
semantics of the given FD at multiple levels i.e., chunk and case document
level by following the divide and conquer approach. It creates the concise view
of the given fact description using the extracted semantics as per the original
court case document structure and predicts judgment using attention mechanism.
We tested the model performance on two available Indian datasets Indian Legal
Documents corpus (ILDC) and Indian Legal Statue Identification (ILSI) and got
promising results. Also shown the highest performance and less performance
degradation for increased epochs than base models on ILDC dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madambakam_P/0/1/0/all/0/1&quot;&gt;Prameela Madambakam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajmohan_S/0/1/0/all/0/1&quot;&gt;Shathanaa Rajmohan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_H/0/1/0/all/0/1&quot;&gt;Himangshu Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_T/0/1/0/all/0/1&quot;&gt;Tummepalli Anka Chandrahas Purushotham Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07981">
<title>Time Series Diffusion Method: A Denoising Diffusion Probabilistic Model for Vibration Signal Generation. (arXiv:2312.07981v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07981</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion models have demonstrated robust data generation capabilities in
various research fields. In this paper, a Time Series Diffusion Method (TSDM)
is proposed for vibration signal generation, leveraging the foundational
principles of diffusion models. The TSDM uses an improved U-net architecture
with attention block to effectively segment and extract features from
one-dimensional time series data. It operates based on forward diffusion and
reverse denoising processes for time-series generation. Experimental validation
is conducted using single-frequency, multi-frequency datasets, and bearing
fault datasets. The results show that TSDM can accurately generate the
single-frequency and multi-frequency features in the time series and retain the
basic frequency features for the diffusion generation results of the bearing
fault series. Finally, TSDM is applied to the small sample fault diagnosis of
three public bearing fault datasets, and the results show that the accuracy of
small sample fault diagnosis of the three datasets is improved by 32.380%,
18.355% and 9.298% at most, respectively
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_H/0/1/0/all/0/1&quot;&gt;Haiming Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1&quot;&gt;Lei Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yuhong Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saeed_N/0/1/0/all/0/1&quot;&gt;Nasser A. Saeed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07983">
<title>Multi-perspective Feedback-attention Coupling Model for Continuous-time Dynamic Graphs. (arXiv:2312.07983v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07983</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, representation learning over graph networks has gained popularity,
with various models showing promising results. Despite this, several challenges
persist: 1) most methods are designed for static or discrete-time dynamic
graphs; 2) existing continuous-time dynamic graph algorithms focus on a single
evolving perspective; and 3) many continuous-time dynamic graph approaches
necessitate numerous temporal neighbors to capture long-term dependencies. In
response, this paper introduces the Multi-Perspective Feedback-Attention
Coupling (MPFA) model. MPFA incorporates information from both evolving and raw
perspectives, efficiently learning the interleaved dynamics of observed
processes. The evolving perspective employs temporal self-attention to
distinguish continuously evolving temporal neighbors for information
aggregation. Through dynamic updates, this perspective can capture long-term
dependencies using a small number of temporal neighbors. Meanwhile, the raw
perspective utilizes a feedback attention module with growth characteristic
coefficients to aggregate raw neighborhood information. Experimental results on
a self-organizing dataset and seven public datasets validate the efficacy and
competitiveness of our proposed model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaobo Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hailong Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Che_J/0/1/0/all/0/1&quot;&gt;Jin Che&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhanheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liying Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07987">
<title>SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention. (arXiv:2312.07987v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07987</link>
<description rdf:parseType="Literal">&lt;p&gt;The costly self-attention layers in modern Transformers require memory and
compute quadratic in sequence length. Existing approximation methods usually
underperform and fail to obtain significant speedups in practice. Here we
present SwitchHead - a novel method that reduces both compute and memory
requirements and achieves wall-clock speedup, while matching the language
modeling performance of baseline Transformers with the same parameter budget.
SwitchHead uses Mixture-of-Experts (MoE) layers for the value and output
projections and requires 4 to 8 times fewer attention matrices than standard
Transformers. Our novel attention can also be combined with MoE MLP layers,
resulting in an efficient fully-MoE &quot;SwitchHead&quot; Transformer model. Our code is
public.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Csordas_R/0/1/0/all/0/1&quot;&gt;R&amp;#xf3;bert Csord&amp;#xe1;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piekos_P/0/1/0/all/0/1&quot;&gt;Piotr Pi&amp;#x119;kos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1&quot;&gt;Kazuki Irie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07991">
<title>Accelerating the Global Aggregation of Local Explanations. (arXiv:2312.07991v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.07991</link>
<description rdf:parseType="Literal">&lt;p&gt;Local explanation methods highlight the input tokens that have a considerable
impact on the outcome of classifying the document at hand. For example, the
Anchor algorithm applies a statistical analysis of the sensitivity of the
classifier to changes in the token. Aggregating local explanations over a
dataset provides a global explanation of the model. Such aggregation aims to
detect words with the most impact, giving valuable insights about the model,
like what it has learned in training and which adversarial examples expose its
weaknesses. However, standard aggregation methods bear a high computational
cost: a na\&quot;ive implementation applies a costly algorithm to each token of each
document, and hence, it is infeasible for a simple user running in the scope of
a short analysis session. % We devise techniques for accelerating the global
aggregation of the Anchor algorithm. Specifically, our goal is to compute a set
of top-$k$ words with the highest global impact according to different
aggregation functions. Some of our techniques are lossless and some are lossy.
We show that for a very mild loss of quality, we are able to accelerate the
computation by up to 30$\times$, reducing the computation from hours to
minutes. We also devise and study a probabilistic model that accounts for noise
in the Anchor algorithm and diminishes the bias toward words that are frequent
yet low in impact.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mor_A/0/1/0/all/0/1&quot;&gt;Alon Mor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1&quot;&gt;Yonatan Belinkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimelfeld_B/0/1/0/all/0/1&quot;&gt;Benny Kimelfeld&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08008">
<title>Learning Nash Equilibria in Zero-Sum Markov Games: A Single Time-scale Algorithm Under Weak Reachability. (arXiv:2312.08008v1 [cs.GT])</title>
<link>http://arxiv.org/abs/2312.08008</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider decentralized learning for zero-sum games, where players only see
their payoff information and are agnostic to actions and payoffs of the
opponent. Previous works demonstrated convergence to a Nash equilibrium in this
setting using double time-scale algorithms under strong reachability
assumptions. We address the open problem of achieving an approximate Nash
equilibrium efficiently with an uncoupled and single time-scale algorithm under
weaker conditions. Our contribution is a rational and convergent algorithm,
utilizing Tsallis-entropy regularization in a value-iteration-based approach.
The algorithm learns an approximate Nash equilibrium in polynomial time,
requiring only the existence of a policy pair that induces an irreducible and
aperiodic Markov chain, thus considerably weakening past assumptions. Our
analysis leverages negative drift inequalities and introduces novel properties
of Tsallis entropy that are of independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouhamma_R/0/1/0/all/0/1&quot;&gt;Reda Ouhamma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamgarpour_M/0/1/0/all/0/1&quot;&gt;Maryam Kamgarpour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08010">
<title>EZ-CLIP: Efficient Zeroshot Video Action Recognition. (arXiv:2312.08010v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.08010</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advancements in large-scale pre-training of visual-language models on
paired image-text data have demonstrated impressive generalization capabilities
for zero-shot tasks. Building on this success, efforts have been made to adapt
these image-based visual-language models, such as CLIP, for videos extending
their zero-shot capabilities to the video domain. While these adaptations have
shown promising results, they come at a significant computational cost and
struggle with effectively modeling the crucial temporal aspects inherent to the
video domain. In this study, we present EZ-CLIP, a simple and efficient
adaptation of CLIP that addresses these challenges. EZ-CLIP leverages temporal
visual prompting for seamless temporal adaptation, requiring no fundamental
alterations to the core CLIP architecture while preserving its remarkable
generalization abilities. Moreover, we introduce a novel learning objective
that guides the temporal visual prompts to focus on capturing motion, thereby
enhancing its learning capabilities from video data. We conducted extensive
experiments on five different benchmark datasets, thoroughly evaluating EZ-CLIP
for zero-shot learning and base-to-novel video action recognition, and also
demonstrating its potential for few-shot generalization.Impressively, with a
mere 5.2 million learnable parameters (as opposed to the 71.1 million in the
prior best model), EZ-CLIP can be efficiently trained on a single GPU,
outperforming existing approaches in several evaluations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmad_S/0/1/0/all/0/1&quot;&gt;Shahzad Ahmad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chanda_S/0/1/0/all/0/1&quot;&gt;Sukalpa Chanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rawat_Y/0/1/0/all/0/1&quot;&gt;Yogesh S Rawat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08016">
<title>Secure Deep Reinforcement Learning for Dynamic Resource Allocation in Wireless MEC Networks. (arXiv:2312.08016v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08016</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a blockchain-secured deep reinforcement learning (BC-DRL)
optimization framework for {data management and} resource allocation in
decentralized {wireless mobile edge computing (MEC)} networks. In our
framework, {we design a low-latency reputation-based proof-of-stake (RPoS)
consensus protocol to select highly reliable blockchain-enabled BSs to securely
store MEC user requests and prevent data tampering attacks.} {We formulate the
MEC resource allocation optimization as a constrained Markov decision process
that balances minimum processing latency and denial-of-service (DoS)
probability}. {We use the MEC aggregated features as the DRL input to
significantly reduce the high-dimensionality input of the remaining service
processing time for individual MEC requests. Our designed constrained DRL
effectively attains the optimal resource allocations that are adapted to the
dynamic DoS requirements. We provide extensive simulation results and analysis
to} validate that our BC-DRL framework achieves higher security, reliability,
and resource utilization efficiency than benchmark blockchain consensus
protocols and {MEC} resource allocation algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_X/0/1/0/all/0/1&quot;&gt;Xin Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeoh_P/0/1/0/all/0/1&quot;&gt;Phee Lep Yeoh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+She_C/0/1/0/all/0/1&quot;&gt;Changyang She&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vucetic_B/0/1/0/all/0/1&quot;&gt;Branka Vucetic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yonghui Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08021">
<title>Improving search relevance of Azure Cognitive Search by Bayesian optimization. (arXiv:2312.08021v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2312.08021</link>
<description rdf:parseType="Literal">&lt;p&gt;Azure Cognitive Search (ACS) has emerged as a major contender in &quot;Search as a
Service&quot; cloud products in recent years. However, one of the major challenges
for ACS users is to improve the relevance of the search results for their
specific usecases. In this paper, we propose a novel method to find the optimal
ACS configuration that maximizes search relevance for a specific usecase
(product search, document search...) The proposed solution improves key online
marketplace metrics such as click through rates (CTR) by formulating the search
relevance problem as hyperparameter tuning. We have observed significant
improvements in real-world search call to action (CTA) rate in multiple
marketplaces by introducing optimized weights generated from the proposed
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_N/0/1/0/all/0/1&quot;&gt;Nitin Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Ashish Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+R_K/0/1/0/all/0/1&quot;&gt;Kiran R&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1&quot;&gt;Manish Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boue_L/0/1/0/all/0/1&quot;&gt;Laurent Bou&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08029">
<title>ClusterDDPM: An EM clustering framework with Denoising Diffusion Probabilistic Models. (arXiv:2312.08029v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08029</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational autoencoder (VAE) and generative adversarial networks (GAN) have
found widespread applications in clustering and have achieved significant
success. However, the potential of these approaches may be limited due to VAE&apos;s
mediocre generation capability or GAN&apos;s well-known instability during
adversarial training. In contrast, denoising diffusion probabilistic models
(DDPMs) represent a new and promising class of generative models that may
unlock fresh dimensions in clustering. In this study, we introduce an
innovative expectation-maximization (EM) framework for clustering using DDPMs.
In the E-step, we aim to derive a mixture of Gaussian priors for the subsequent
M-step. In the M-step, our focus lies in learning clustering-friendly latent
representations for the data by employing the conditional DDPM and matching the
distribution of latent representations to the mixture of Gaussian priors. We
present a rigorous theoretical analysis of the optimization process in the
M-step, proving that the optimizations are equivalent to maximizing the lower
bound of the Q function within the vanilla EM framework under certain
constraints. Comprehensive experiments validate the advantages of the proposed
framework, showcasing superior performance in clustering, unsupervised
conditional generation and latent representation learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Jie Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhong-yuan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08033">
<title>Beyond Top-Class Agreement: Using Divergences to Forecast Performance under Distribution Shift. (arXiv:2312.08033v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08033</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowing if a model will generalize to data &apos;in the wild&apos; is crucial for safe
deployment. To this end, we study model disagreement notions that consider the
full predictive distribution - specifically disagreement based on Hellinger
distance, Jensen-Shannon and Kullback-Leibler divergence. We find that
divergence-based scores provide better test error estimates and detection rates
on out-of-distribution data compared to their top-1 counterparts. Experiments
involve standard vision and foundation models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schirmer_M/0/1/0/all/0/1&quot;&gt;Mona Schirmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nalisnick_E/0/1/0/all/0/1&quot;&gt;Eric Nalisnick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08034">
<title>Individualized Deepfake Detection Exploiting Traces Due to Double Neural-Network Operations. (arXiv:2312.08034v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.08034</link>
<description rdf:parseType="Literal">&lt;p&gt;In today&apos;s digital landscape, journalists urgently require tools to verify
the authenticity of facial images and videos depicting specific public figures
before incorporating them into news stories. Existing deepfake detectors are
not optimized for this detection task when an image is associated with a
specific and identifiable individual. This study focuses on the deepfake
detection of facial images of individual public figures. We propose to
condition the proposed detector on the identity of the identified individual
given the advantages revealed by our theory-driven simulations. While most
detectors in the literature rely on perceptible or imperceptible artifacts
present in deepfake facial images, we demonstrate that the detection
performance can be improved by exploiting the idempotency property of neural
networks. In our approach, the training process involves double neural-network
operations where we pass an authentic image through a deepfake simulating
network twice. Experimental results show that the proposed method improves the
area under the curve (AUC) from 0.92 to 0.94 and reduces its standard deviation
by 17\%. For evaluating the detection performance of individual public figures,
a facial image dataset with individuals&apos; names is required, a criterion not met
by the current deepfake datasets. To address this, we curated a dataset
comprising 32k images featuring 45 public figures, which we intend to release
to the public after the paper is published.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rahman_M/0/1/0/all/0/1&quot;&gt;Mushfiqur Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Runze Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wong_C/0/1/0/all/0/1&quot;&gt;Chau-Wai Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Huaiyu Dai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08052">
<title>Explainable Trajectory Representation through Dictionary Learning. (arXiv:2312.08052v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08052</link>
<description rdf:parseType="Literal">&lt;p&gt;Trajectory representation learning on a network enhances our understanding of
vehicular traffic patterns and benefits numerous downstream applications.
Existing approaches using classic machine learning or deep learning embed
trajectories as dense vectors, which lack interpretability and are inefficient
to store and analyze in downstream tasks. In this paper, an explainable
trajectory representation learning framework through dictionary learning is
proposed. Given a collection of trajectories on a network, it extracts a
compact dictionary of commonly used subpaths called &quot;pathlets&quot;, which optimally
reconstruct each trajectory by simple concatenations. The resulting
representation is naturally sparse and encodes strong spatial semantics.
Theoretical analysis of our proposed algorithm is conducted to provide a
probabilistic bound on the estimation error of the optimal dictionary. A
hierarchical dictionary learning scheme is also proposed to ensure the
algorithm&apos;s scalability on large networks, leading to a multi-scale trajectory
representation. Our framework is evaluated on two large-scale real-world taxi
datasets. Compared to previous work, the dictionary learned by our method is
more compact and has better reconstruction rate for new trajectories. We also
demonstrate the promising performance of this method in downstream tasks
including trip time prediction task and data compression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yuanbo Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08053">
<title>Kimad: Adaptive Gradient Compression with Bandwidth Awareness. (arXiv:2312.08053v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08053</link>
<description rdf:parseType="Literal">&lt;p&gt;In distributed training, communication often emerges as a bottleneck. In
response, we introduce Kimad, a solution that offers adaptive gradient
compression. By consistently monitoring bandwidth, Kimad refines compression
ratios to match specific neural network layer requirements. Our exhaustive
tests and proofs confirm Kimad&apos;s outstanding performance, establishing it as a
benchmark in adaptive compression for distributed deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1&quot;&gt;Jihao Xin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilin_I/0/1/0/all/0/1&quot;&gt;Ivan Ilin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shunkang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Canini_M/0/1/0/all/0/1&quot;&gt;Marco Canini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1&quot;&gt;Peter Richt&amp;#xe1;rik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08055">
<title>Breaking the Silence: the Threats of Using LLMs in Software Engineering. (arXiv:2312.08055v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2312.08055</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have gained considerable traction within the
Software Engineering (SE) community, impacting various SE tasks from code
completion to test generation, from program repair to code summarization.
Despite their promise, researchers must still be careful as numerous intricate
factors can influence the outcomes of experiments involving LLMs. This paper
initiates an open discussion on potential threats to the validity of LLM-based
research including issues such as closed-source models, possible data leakage
between LLM training data and research evaluation, and the reproducibility of
LLM-based findings. In response, this paper proposes a set of guidelines
tailored for SE researchers and Language Model (LM) providers to mitigate these
concerns. The implications of the guidelines are illustrated using existing
good practices followed by LLM providers and a practical example for SE
researchers in the context of test case generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sallou_J/0/1/0/all/0/1&quot;&gt;June Sallou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durieux_T/0/1/0/all/0/1&quot;&gt;Thomas Durieux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panichella_A/0/1/0/all/0/1&quot;&gt;Annibale Panichella&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08057">
<title>Combinatorial Stochastic-Greedy Bandit. (arXiv:2312.08057v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08057</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel combinatorial stochastic-greedy bandit (SGB) algorithm for
combinatorial multi-armed bandit problems when no extra information other than
the joint reward of the selected set of $n$ arms at each time step $t\in [T]$
is observed. SGB adopts an optimized stochastic-explore-then-commit approach
and is specifically designed for scenarios with a large set of base arms.
Unlike existing methods that explore the entire set of unselected base arms
during each selection step, our SGB algorithm samples only an optimized
proportion of unselected arms and selects actions from this subset. We prove
that our algorithm achieves a $(1-1/e)$-regret bound of
$\mathcal{O}(n^{\frac{1}{3}} k^{\frac{2}{3}} T^{\frac{2}{3}}
\log(T)^{\frac{2}{3}})$ for monotone stochastic submodular rewards, which
outperforms the state-of-the-art in terms of the cardinality constraint $k$.
Furthermore, we empirically evaluate the performance of our algorithm in the
context of online constrained social influence maximization. Our results
demonstrate that our proposed approach consistently outperforms the other
algorithms, increasing the performance gap as $k$ grows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fourati_F/0/1/0/all/0/1&quot;&gt;Fares Fourati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1&quot;&gt;Christopher John Quinn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alouini_M/0/1/0/all/0/1&quot;&gt;Mohamed-Slim Alouini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1&quot;&gt;Vaneet Aggarwal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08063">
<title>Estimation of Concept Explanations Should be Uncertainty Aware. (arXiv:2312.08063v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08063</link>
<description rdf:parseType="Literal">&lt;p&gt;Model explanations are very valuable for interpreting and debugging
prediction models. We study a specific kind of global explanations called
Concept Explanations, where the goal is to interpret a model using
human-understandable concepts. Recent advances in multi-modal learning
rekindled interest in concept explanations and led to several label-efficient
proposals for estimation. However, existing estimation methods are unstable to
the choice of concepts or dataset that is used for computing explanations. We
observe that instability in explanations is due to high variance in point
estimation of importance scores. We propose an uncertainty aware Bayesian
estimation method, which readily improved reliability of the concept
explanations. We demonstrate with theoretical analysis and empirical evaluation
that explanations computed by our method are more reliable while also being
label-efficient and faithful.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piratla_V/0/1/0/all/0/1&quot;&gt;Vihari Piratla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heo_J/0/1/0/all/0/1&quot;&gt;Juyeon Heo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sukriti Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1&quot;&gt;Adrian Weller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08066">
<title>A Novel Metric for Measuring Data Quality in Classification Applications (extended version). (arXiv:2312.08066v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08066</link>
<description rdf:parseType="Literal">&lt;p&gt;Data quality is a key element for building and optimizing good learning
models. Despite many attempts to characterize data quality, there is still a
need for rigorous formalization and an efficient measure of the quality from
available observations. Indeed, without a clear understanding of the training
and testing processes, it is hard to evaluate the intrinsic performance of a
model. Besides, tools allowing to measure data quality specific to machine
learning are still lacking. In this paper, we introduce and explain a novel
metric to measure data quality. This metric is based on the correlated
evolution between the classification performance and the deterioration of data.
The proposed method has the major advantage of being model-independent.
Furthermore, we provide an interpretation of each criterion and examples of
assessment levels. We confirm the utility of the proposed metric with intensive
numerical experiments and detail some illustrative cases with controlled and
interpretable qualities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roxane_J/0/1/0/all/0/1&quot;&gt;Jouseau Roxane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sebastien_S/0/1/0/all/0/1&quot;&gt;Salva S&amp;#xe9;bastien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chafik_S/0/1/0/all/0/1&quot;&gt;Samir Chafik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08075">
<title>TERM Model: Tensor Ring Mixture Model for Density Estimation. (arXiv:2312.08075v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08075</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient probability density estimation is a core challenge in statistical
machine learning. Tensor-based probabilistic graph methods address
interpretability and stability concerns encountered in neural network
approaches. However, a substantial number of potential tensor permutations can
lead to a tensor network with the same structure but varying expressive
capabilities. In this paper, we take tensor ring decomposition for density
estimator, which significantly reduces the number of permutation candidates
while enhancing expressive capability compared with existing used
decompositions. Additionally, a mixture model that incorporates multiple
permutation candidates with adaptive weights is further designed, resulting in
increased expressive flexibility and comprehensiveness. Different from the
prevailing directions of tensor network structure/permutation search, our
approach provides a new viewpoint inspired by ensemble learning. This approach
acknowledges that suboptimal permutations can offer distinctive information
besides that of optimal permutations. Experiments show the superiority of the
proposed approach in estimating probability density for moderately dimensional
datasets and sampling to capture intricate details.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1&quot;&gt;Ruituo Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiani Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Ce Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_A/0/1/0/all/0/1&quot;&gt;Anh-Huy Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1&quot;&gt;Ivan V. Oseledets&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yipeng Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08083">
<title>Training of Neural Networks with Uncertain Data, A Mixture of Experts Approach. (arXiv:2312.08083v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.08083</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents the &quot;Uncertainty-aware Mixture of Experts&quot; (uMoE), a
novel approach designed to address aleatoric uncertainty in the training of
predictive models based on Neural Networks (NNs). While existing methods
primarily focus on managing uncertainty during infer-ence, uMoE integrates
uncertainty directly into the train-ing process. The uMoE approach adopts a
&quot;Divide and Conquer&quot; paradigm to partition the uncertain input space into more
manageable subspaces. It consists of Expert components, each trained solely on
the portion of input uncertainty corresponding to their subspace. On top of the
Experts, a Gating Unit, guided by additional infor-mation about the
distribution of uncertain inputs across these subspaces, learns to weight the
Experts to minimize deviations from the ground truth. Our results highlight
that uMoE significantly outperforms baseline methods in handling data
uncertainty. Furthermore, we conducted a robustness analysis, illustrating its
capability to adapt to varying levels of uncertainty and suggesting optimal
threshold parameters. This innovative approach holds wide applicability across
diverse data-driven domains, in-cluding biomedical signal processing,
autonomous driv-ing, and production quality control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Luttner_L/0/1/0/all/0/1&quot;&gt;Lucas Luttner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08096">
<title>An Incentive Mechanism for Federated Learning Based on Multiple Resource Exchange. (arXiv:2312.08096v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08096</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) is a distributed machine learning paradigm that
addresses privacy concerns in machine learning and still guarantees high test
accuracy. However, achieving the necessary accuracy by having all clients
participate in FL is impractical, given the constraints of client local
computing resource. In this paper, we introduce a multi-user collaborative
computing framework, categorizing users into two roles: model owners (MOs) and
data owner (DOs). Without resorting to monetary incentives, an MO can encourage
more DOs to join in FL by allowing the DOs to offload extra local computing
tasks to the MO for execution. This exchange of &quot;data&quot; for &quot;computing
resources&quot; streamlines the incentives for clients to engage more effectively in
FL. We formulate the interaction between MO and DOs as an optimization problem,
and the objective is to effectively utilize the communication and computing
resource of the MO and DOs to minimize the time to complete an FL task. The
proposed problem is a mixed integer nonlinear programming (MINLP) with high
computational complexity. We first decompose it into two distinct subproblems,
namely the client selection problem and the resource allocation problem to
segregate the integer variables from the continuous variables. Then, an
effective iterative algorithm is proposed to solve problem. Simulation results
demonstrate that the proposed collaborative computing framework can achieve an
accuracy of more than 95\% while minimizing the overall time to complete an FL
task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1&quot;&gt;Ruonan Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hui Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Han Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;GuoPeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08103">
<title>Machine Learning for the Multi-Dimensional Bin Packing Problem: Literature Review and Empirical Evaluation. (arXiv:2312.08103v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08103</link>
<description rdf:parseType="Literal">&lt;p&gt;The Bin Packing Problem (BPP) is a well-established combinatorial
optimization (CO) problem. Since it has many applications in our daily life,
e.g. logistics and resource allocation, people are seeking efficient bin
packing algorithms. On the other hand, researchers have been making constant
advances in machine learning (ML), which is famous for its efficiency. In this
article, we first formulate BPP, introducing its variants and practical
constraints. Then, a comprehensive survey on ML for multi-dimensional BPP is
provided. We further collect some public benchmarks of 3D BPP, and evaluate
some online methods on the Cutting Stock Dataset. Finally, we share our
perspective on challenges and future directions in BPP. To the best of our
knowledge, this is the first systematic review of ML-related methods for BPP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1&quot;&gt;Wenjie Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1&quot;&gt;Changjun Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jincai Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Junchi Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08107">
<title>Causal Optimal Transport of Abstractions. (arXiv:2312.08107v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08107</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal abstraction (CA) theory establishes formal criteria for relating
multiple structural causal models (SCMs) at different levels of granularity by
defining maps between them. These maps have significant relevance for
real-world challenges such as synthesizing causal evidence from multiple
experimental environments, learning causally consistent representations at
different resolutions, and linking interventions across multiple SCMs. In this
work, we propose COTA, the first method to learn abstraction maps from
observational and interventional data without assuming complete knowledge of
the underlying SCMs. In particular, we introduce a multi-marginal Optimal
Transport (OT) formulation that enforces do-calculus causal constraints,
together with a cost function that relies on interventional information. We
extensively evaluate COTA on synthetic and real world problems, and showcase
its advantages over non-causal, independent and aggregated COTA formulations.
Finally, we demonstrate the efficiency of our method as a data augmentation
tool by comparing it against the state-of-the-art CA learning framework, which
assumes fully specified SCMs, on a real-world downstream task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Felekis_Y/0/1/0/all/0/1&quot;&gt;Yorgos Felekis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zennaro_F/0/1/0/all/0/1&quot;&gt;Fabio Massimo Zennaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Branchini_N/0/1/0/all/0/1&quot;&gt;Nicola Branchini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damoulas_T/0/1/0/all/0/1&quot;&gt;Theodoros Damoulas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08132">
<title>Ultra Low Complexity Deep Learning Based Noise Suppression. (arXiv:2312.08132v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2312.08132</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces an innovative method for reducing the computational
complexity of deep neural networks in real-time speech enhancement on
resource-constrained devices. The proposed approach utilizes a two-stage
processing framework, employing channelwise feature reorientation to reduce the
computational load of convolutional operations. By combining this with a
modified power law compression technique for enhanced perceptual quality, this
approach achieves noise suppression performance comparable to state-of-the-art
methods with significantly less computational requirements. Notably, our
algorithm exhibits 3 to 4 times less computational complexity and memory usage
than prior state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shetu_S/0/1/0/all/0/1&quot;&gt;Shrishti Saha Shetu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chakrabarty_S/0/1/0/all/0/1&quot;&gt;Soumitro Chakrabarty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Thiergart_O/0/1/0/all/0/1&quot;&gt;Oliver Thiergart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mabande_E/0/1/0/all/0/1&quot;&gt;Edwin Mabande&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08135">
<title>A New Perspective On Denoising Based On Optimal Transport. (arXiv:2312.08135v1 [math.ST])</title>
<link>http://arxiv.org/abs/2312.08135</link>
<description rdf:parseType="Literal">&lt;p&gt;In the standard formulation of the denoising problem, one is given a
probabilistic model relating a latent variable $\Theta \in \Omega \subset
\mathbb{R}^m \; (m\ge 1)$ and an observation $Z \in \mathbb{R}^d$ according to:
$Z \mid \Theta \sim p(\cdot\mid \Theta)$ and $\Theta \sim G^*$, and the goal is
to construct a map to recover the latent variable from the observation. The
posterior mean, a natural candidate for estimating $\Theta$ from $Z$, attains
the minimum Bayes risk (under the squared error loss) but at the expense of
over-shrinking the $Z$, and in general may fail to capture the geometric
features of the prior distribution $G^*$ (e.g., low dimensionality,
discreteness, sparsity, etc.). To rectify these drawbacks, in this paper we
take a new perspective on this denoising problem that is inspired by optimal
transport (OT) theory and use it to propose a new OT-based denoiser at the
population level setting. We rigorously prove that, under general assumptions
on the model, our OT-based denoiser is well-defined and unique, and is closely
connected to solutions to a Monge OT problem. We then prove that, under
appropriate identifiability assumptions on the model, our OT-based denoiser can
be recovered solely from information of the marginal distribution of $Z$ and
the posterior mean of the model, after solving a linear relaxation problem over
a suitable space of couplings that is reminiscent of a standard multimarginal
OT (MOT) problem. In particular, thanks to Tweedie&apos;s formula, when the
likelihood model $\{ p(\cdot \mid \theta) \}_{\theta \in \Omega}$ is an
exponential family of distributions, the OT-based denoiser can be recovered
solely from the marginal distribution of $Z$. In general, our family of OT-like
relaxations is of interest in its own right and for the denoising problem
suggests alternative numerical methods inspired by the rich literature on
computational OT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Trillos_N/0/1/0/all/0/1&quot;&gt;Nicolas Garcia Trillos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sen_B/0/1/0/all/0/1&quot;&gt;Bodhisattva Sen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08143">
<title>Efficient Representation of the Activation Space in Deep Neural Networks. (arXiv:2312.08143v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08143</link>
<description rdf:parseType="Literal">&lt;p&gt;The representations of the activation space of deep neural networks (DNNs)
are widely utilized for tasks like natural language processing, anomaly
detection and speech recognition. Due to the diverse nature of these tasks and
the large size of DNNs, an efficient and task-independent representation of
activations becomes crucial. Empirical p-values have been used to quantify the
relative strength of an observed node activation compared to activations
created by already-known inputs. Nonetheless, keeping raw data for these
calculations increases memory resource consumption and raises privacy concerns.
To this end, we propose a model-agnostic framework for creating representations
of activations in DNNs using node-specific histograms to compute p-values of
observed activations without retaining already-known inputs. Our proposed
approach demonstrates promising potential when validated with multiple network
architectures across various downstream tasks and compared with the kernel
density estimates and brute-force empirical baselines. In addition, the
framework reduces memory usage by 30% with up to 4 times faster p-value
computing time while maintaining state of-the-art detection power in downstream
tasks such as the detection of adversarial attacks and synthesized content.
Moreover, as we do not persist raw data at inference time, we could potentially
reduce susceptibility to attacks and privacy issues.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akumu_T/0/1/0/all/0/1&quot;&gt;Tanya Akumu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cintas_C/0/1/0/all/0/1&quot;&gt;Celia Cintas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tadesse_G/0/1/0/all/0/1&quot;&gt;Girmaw Abebe Tadesse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oshingbesan_A/0/1/0/all/0/1&quot;&gt;Adebayo Oshingbesan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Speakman_S/0/1/0/all/0/1&quot;&gt;Skyler Speakman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McFowland_E/0/1/0/all/0/1&quot;&gt;Edward McFowland III&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08150">
<title>Active learning with biased non-response to label requests. (arXiv:2312.08150v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08150</link>
<description rdf:parseType="Literal">&lt;p&gt;Active learning can improve the efficiency of training prediction models by
identifying the most informative new labels to acquire. However, non-response
to label requests can impact active learning&apos;s effectiveness in real-world
contexts. We conceptualise this degradation by considering the type of
non-response present in the data, demonstrating that biased non-response is
particularly detrimental to model performance. We argue that this sort of
non-response is particularly likely in contexts where the labelling process, by
nature, relies on user interactions. To mitigate the impact of biased
non-response, we propose a cost-based correction to the sampling strategy--the
Upper Confidence Bound of the Expected Utility (UCB-EU)--that can, plausibly,
be applied to any active learning algorithm. Through experiments, we
demonstrate that our method successfully reduces the harm from labelling
non-response in many settings. However, we also characterise settings where the
non-response bias in the annotations remains detrimental under UCB-EU for
particular sampling methods and data generating processes. Finally, we evaluate
our method on a real-world dataset from e-commerce platform Taobao. We show
that UCB-EU yields substantial performance improvements to conversion models
that are trained on clicked impressions. Most generally, this research serves
to both better conceptualise the interplay between types of non-response and
model improvements via active learning, and to provide a practical, easy to
implement correction that helps mitigate model degradation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_T/0/1/0/all/0/1&quot;&gt;Thomas Robinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tax_N/0/1/0/all/0/1&quot;&gt;Niek Tax&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mudd_R/0/1/0/all/0/1&quot;&gt;Richard Mudd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guy_I/0/1/0/all/0/1&quot;&gt;Ido Guy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08153">
<title>$\rho$-Diffusion: A diffusion-based density estimation framework for computational physics. (arXiv:2312.08153v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/2312.08153</link>
<description rdf:parseType="Literal">&lt;p&gt;In physics, density $\rho(\cdot)$ is a fundamentally important scalar
function to model, since it describes a scalar field or a probability density
function that governs a physical process. Modeling $\rho(\cdot)$ typically
scales poorly with parameter space, however, and quickly becomes prohibitively
difficult and computationally expensive. One promising avenue to bypass this is
to leverage the capabilities of denoising diffusion models often used in
high-fidelity image generation to parameterize $\rho(\cdot)$ from existing
scientific data, from which new samples can be trivially sampled from. In this
paper, we propose $\rho$-Diffusion, an implementation of denoising diffusion
probabilistic models for multidimensional density estimation in physics, which
is currently in active development and, from our results, performs well on
physically motivated 2D and 3D density functions. Moreover, we propose a novel
hashing technique that allows $\rho$-Diffusion to be conditioned by arbitrary
amounts of physical parameters of interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Cai_M/0/1/0/all/0/1&quot;&gt;Maxwell X. Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kin Long Kelvin Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08174">
<title>Double Machine Learning for Static Panel Models with Fixed Effects. (arXiv:2312.08174v1 [econ.EM])</title>
<link>http://arxiv.org/abs/2312.08174</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning (ML) algorithms are powerful data-driven tools for
approximating high-dimensional or non-linear nuisance functions which are
useful in practice because the true functional form of the predictors is
ex-ante unknown. In this paper, we develop estimators of policy interventions
from panel data which allow for non-linear effects of the confounding
regressors, and investigate the performance of these estimators using three
well-known ML algorithms, specifically, LASSO, classification and regression
trees, and random forests. We use Double Machine Learning (DML) (Chernozhukov
et al., 2018) for the estimation of causal effects of homogeneous treatments
with unobserved individual heterogeneity (fixed effects) and no unobserved
confounding by extending Robinson (1988)&apos;s partially linear regression model.
We develop three alternative approaches for handling unobserved individual
heterogeneity based on extending the within-group estimator, first-difference
estimator, and correlated random effect estimator (Mundlak, 1978) for
non-linear models. Using Monte Carlo simulations, we find that conventional
least squares estimators can perform well even if the data generating process
is non-linear, but there are substantial performance gains in terms of bias
reduction under a process where the true effect of the regressors is non-linear
and discontinuous. However, for the same scenarios, we also find -- despite
extensive hyperparameter tuning -- inference to be problematic for both
tree-based learners because these lead to highly non-normal estimator
distributions and the estimator variance being severely under-estimated. This
contradicts the performance of trees in other circumstances and requires
further investigation. Finally, we provide an illustrative example of DML for
observational panel data showing the impact of the introduction of the national
minimum wage in the UK.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Clarke_P/0/1/0/all/0/1&quot;&gt;Paul Clarke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Polselli_A/0/1/0/all/0/1&quot;&gt;Annalivia Polselli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08193">
<title>Universal Adversarial Framework to Improve Adversarial Robustness for Diabetic Retinopathy Detection. (arXiv:2312.08193v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.08193</link>
<description rdf:parseType="Literal">&lt;p&gt;Diabetic Retinopathy (DR) is a prevalent illness associated with Diabetes
which, if left untreated, can result in irreversible blindness. Deep Learning
based systems are gradually being introduced as automated support for clinical
diagnosis. Since healthcare has always been an extremely important domain
demanding error-free performance, any adversaries could pose a big threat to
the applicability of such systems. In this work, we use Universal Adversarial
Perturbations (UAPs) to quantify the vulnerability of Medical Deep Neural
Networks (DNNs) for detecting DR. To the best of our knowledge, this is the
very first attempt that works on attacking complete fine-grained classification
of DR images using various UAPs. Also, as a part of this work, we use UAPs to
fine-tune the trained models to defend against adversarial samples. We
experiment on several models and observe that the performance of such models
towards unseen adversarial attacks gets boosted on average by $3.41$
Cohen-kappa value and maximum by $31.92$ Cohen-kappa value. The performance
degradation on normal data upon ensembling the fine-tuned models was found to
be statistically insignificant using t-test, highlighting the benefits of
UAP-based adversarial fine-tuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mukherjee_S/0/1/0/all/0/1&quot;&gt;Samrat Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bandyopadhyay_D/0/1/0/all/0/1&quot;&gt;Dibyanayan Bandyopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gain_B/0/1/0/all/0/1&quot;&gt;Baban Gain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ekbal_A/0/1/0/all/0/1&quot;&gt;Asif Ekbal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08194">
<title>SVInvNet: A Densely Connected Encoder-Decoder Architecture for Seismic Velocity Inversion. (arXiv:2312.08194v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08194</link>
<description rdf:parseType="Literal">&lt;p&gt;This study presents a deep learning-based approach to seismic velocity
inversion problem, focusing on both noisy and noiseless training datasets of
varying sizes. Our Seismic Velocity Inversion Network (SVInvNet) introduces a
novel architecture that contains a multi-connection encoder-decoder structure
enhanced with dense blocks. This design is specifically tuned to effectively
process complex information, crucial for addressing the challenges of
non-linear seismic velocity inversion. For training and testing, we created
diverse seismic velocity models, including multi-layered, faulty, and salt dome
categories. We also investigated how different kinds of ambient noise, both
coherent and stochastic, and the size of the training dataset affect learning
outcomes. SVInvNet is trained on datasets ranging from 750 to 6,000 samples and
is tested using a large benchmark dataset of 12,000 samples. Despite its fewer
parameters compared to the baseline, SVInvNet achieves superior performance
with this dataset. The outcomes of the SVInvNet are additionally compared to
those of the Full Waveform Inversion (FWI) method. The comparative analysis
clearly reveals the effectiveness of the proposed model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khatounabad_M/0/1/0/all/0/1&quot;&gt;Mojtaba Najafi Khatounabad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keles_H/0/1/0/all/0/1&quot;&gt;Hacer Yalim Keles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadioglu_S/0/1/0/all/0/1&quot;&gt;Selma Kadioglu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08200">
<title>SPD-DDPM: Denoising Diffusion Probabilistic Models in the Symmetric Positive Definite Space. (arXiv:2312.08200v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08200</link>
<description rdf:parseType="Literal">&lt;p&gt;Symmetric positive definite~(SPD) matrices have shown important value and
applications in statistics and machine learning, such as FMRI analysis and
traffic prediction. Previous works on SPD matrices mostly focus on
discriminative models, where predictions are made directly on $E(X|y)$, where
$y$ is a vector and $X$ is an SPD matrix. However, these methods are
challenging to handle for large-scale data, as they need to access and process
the whole data. In this paper, inspired by denoising diffusion probabilistic
model~(DDPM), we propose a novel generative model, termed SPD-DDPM, by
introducing Gaussian distribution in the SPD space to estimate $E(X|y)$.
Moreover, our model is able to estimate $p(X)$ unconditionally and flexibly
without giving $y$. On the one hand, the model conditionally learns $p(X|y)$
and utilizes the mean of samples to obtain $E(X|y)$ as a prediction. On the
other hand, the model unconditionally learns the probability distribution of
the data $p(X)$ and generates samples that conform to this distribution.
Furthermore, we propose a new SPD net which is much deeper than the previous
networks and allows for the inclusion of conditional factors. Experiment
results on toy data and real taxi data demonstrate that our models effectively
fit the data distribution both unconditionally and unconditionally and provide
accurate predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yunchen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhou Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_G/0/1/0/all/0/1&quot;&gt;Gaoqi He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yunhang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Ke Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xing Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Shaohui Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08221">
<title>Curriculum-Enhanced Residual Soft An-Isotropic Normalization for Over-smoothness in Deep GNNs. (arXiv:2312.08221v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08221</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite Graph neural networks&apos; significant performance gain over many classic
techniques in various graph-related downstream tasks, their successes are
restricted in shallow models due to over-smoothness and the difficulties of
optimizations among many other issues. In this paper, to alleviate the
over-smoothing issue, we propose a soft graph normalization method to preserve
the diversities of node embeddings and prevent indiscrimination due to possible
over-closeness. Combined with residual connections, we analyze the reason why
the method can effectively capture the knowledge in both input graph structures
and node features even with deep networks. Additionally, inspired by Curriculum
Learning that learns easy examples before the hard ones, we propose a novel
label-smoothing-based learning framework to enhance the optimization of deep
GNNs, which iteratively smooths labels in an auxiliary graph and constructs
many gradual non-smooth tasks for extracting increasingly complex knowledge and
gradually discriminating nodes from coarse to fine. The method arguably reduces
the risk of overfitting and generalizes better results. Finally, extensive
experiments are carried out to demonstrate the effectiveness and potential of
the proposed model and learning framework through comparison with twelve
existing baselines including the state-of-the-art methods on twelve real-world
node classification benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qirong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shuling Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinlong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1&quot;&gt;Longkun Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yang-Geng Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08224">
<title>GLOP: Learning Global Partition and Local Construction for Solving Large-scale Routing Problems in Real-time. (arXiv:2312.08224v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.08224</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent end-to-end neural solvers have shown promise for small-scale
routing problems but suffered from limited real-time scaling-up performance.
This paper proposes GLOP (Global and Local Optimization Policies), a unified
hierarchical framework that efficiently scales toward large-scale routing
problems. GLOP partitions large routing problems into Travelling Salesman
Problems (TSPs) and TSPs into Shortest Hamiltonian Path Problems. For the first
time, we hybridize non-autoregressive neural heuristics for coarse-grained
problem partitions and autoregressive neural heuristics for fine-grained route
constructions, leveraging the scalability of the former and the meticulousness
of the latter. Experimental results show that GLOP achieves competitive and
state-of-the-art real-time performance on large-scale routing problems,
including TSP, ATSP, CVRP, and PCTSP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1&quot;&gt;Haoran Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiarui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1&quot;&gt;Helan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1&quot;&gt;Zhiguang Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Fanzhang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08227">
<title>Differentially Private Gradient Flow based on the Sliced Wasserstein Distance for Non-Parametric Generative Modeling. (arXiv:2312.08227v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.08227</link>
<description rdf:parseType="Literal">&lt;p&gt;Safeguarding privacy in sensitive training data is paramount, particularly in
the context of generative modeling. This is done through either differentially
private stochastic gradient descent, or with a differentially private metric
for training models or generators. In this paper, we introduce a novel
differentially private generative modeling approach based on parameter-free
gradient flows in the space of probability measures. The proposed algorithm is
a new discretized flow which operates through a particle scheme, utilizing
drift derived from the sliced Wasserstein distance and computed in a private
manner. Our experiments show that compared to a generator-based model, our
proposed model can generate higher-fidelity data at a low privacy budget,
offering a viable alternative to generator-based approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sebag_I/0/1/0/all/0/1&quot;&gt;Ilana Sebag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+PYDI_M/0/1/0/all/0/1&quot;&gt;Muni Sreenivas PYDI&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Franceschi_J/0/1/0/all/0/1&quot;&gt;Jean-Yves Franceschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rakotomamonjy_A/0/1/0/all/0/1&quot;&gt;Alain Rakotomamonjy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gartrell_M/0/1/0/all/0/1&quot;&gt;Mike Gartrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Atif_J/0/1/0/all/0/1&quot;&gt;Jamal Atif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Allauzen_A/0/1/0/all/0/1&quot;&gt;Alexandre Allauzen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08230">
<title>Partial Symmetry Detection for 3D Geometry using Contrastive Learning with Geodesic Point Cloud Patches. (arXiv:2312.08230v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.08230</link>
<description rdf:parseType="Literal">&lt;p&gt;Symmetry detection, especially partial and extrinsic symmetry, is essential
for various downstream tasks, like 3D geometry completion, segmentation,
compression and structure-aware shape encoding or generation. In order to
detect partial extrinsic symmetries, we propose to learn rotation, reflection,
translation and scale invariant local shape features for geodesic point cloud
patches via contrastive learning, which are robust across multiple classes and
generalize over different datasets. We show that our approach is able to
extract multiple valid solutions for this ambiguous problem. Furthermore, we
introduce a novel benchmark test for partial extrinsic symmetry detection to
evaluate our method. Lastly, we incorporate the detected symmetries together
with a region growing algorithm to demonstrate a downstream task with the goal
of computing symmetry-aware partitions of 3D shapes. To our knowledge, we are
the first to propose a self-supervised data-driven method for partial extrinsic
symmetry detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kobsik_G/0/1/0/all/0/1&quot;&gt;Gregor Kobsik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_I/0/1/0/all/0/1&quot;&gt;Isaak Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kobbelt_L/0/1/0/all/0/1&quot;&gt;Leif Kobbelt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08255">
<title>OCTDL: Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods. (arXiv:2312.08255v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.08255</link>
<description rdf:parseType="Literal">&lt;p&gt;Optical coherence tomography (OCT) is a non-invasive imaging technique with
extensive clinical applications in ophthalmology. OCT enables the visualization
of the retinal layers, playing a vital role in the early detection and
monitoring of retinal diseases. OCT uses the principle of light wave
interference to create detailed images of the retinal microstructures, making
it a valuable tool for diagnosing ocular conditions. This work presents an
open-access OCT dataset (OCTDL) comprising over 1600 high-resolution OCT images
labeled according to disease group and retinal pathology. The dataset consists
of OCT records of patients with Age-related Macular Degeneration (AMD),
Diabetic Macular Edema (DME), Epiretinal Membrane (ERM), Retinal Artery
Occlusion (RAO), Retinal Vein Occlusion (RVO), and Vitreomacular Interface
Disease (VID). The images were acquired with an Optovue Avanti RTVue XR using
raster scanning protocols with dynamic scan length and image resolution. Each
retinal b-scan was acquired by centering on the fovea and interpreted and
cataloged by an experienced retinal specialist. In this work, we applied Deep
Learning classification techniques to this new open-access dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kulyabin_M/0/1/0/all/0/1&quot;&gt;Mikhail Kulyabin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhdanov_A/0/1/0/all/0/1&quot;&gt;Aleksei Zhdanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nikiforova_A/0/1/0/all/0/1&quot;&gt;Anastasia Nikiforova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Stepichev_A/0/1/0/all/0/1&quot;&gt;Andrey Stepichev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kuznetsova_A/0/1/0/all/0/1&quot;&gt;Anna Kuznetsova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ronkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Ronkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Borisov_V/0/1/0/all/0/1&quot;&gt;Vasilii Borisov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bogachev_A/0/1/0/all/0/1&quot;&gt;Alexander Bogachev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Korotkich_S/0/1/0/all/0/1&quot;&gt;Sergey Korotkich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Constable_P/0/1/0/all/0/1&quot;&gt;Paul A Constable&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Maier_A/0/1/0/all/0/1&quot;&gt;Andreas Maier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08257">
<title>\emph{Lifted} RDT based capacity analysis of the 1-hidden layer treelike \emph{sign} perceptrons neural networks. (arXiv:2312.08257v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.08257</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the memorization capabilities of multilayered \emph{sign}
perceptrons neural networks (SPNNs). A recent rigorous upper-bounding capacity
characterization, obtained in \cite{Stojnictcmspnncaprdt23} utilizing the
Random Duality Theory (RDT), demonstrated that adding neurons in a network
configuration may indeed be very beneficial. Moreover, for particular
\emph{treelike committee machines} (TCM) architectures with $d\leq 5$ neurons
in the hidden layer, \cite{Stojnictcmspnncaprdt23} made a very first
mathematically rigorous progress in over 30 years by lowering the previously
best known capacity bounds of \cite{MitchDurb89}. Here, we first establish that
the RDT bounds from \cite{Stojnictcmspnncaprdt23} scale as $\sim \sqrt{d}$ and
can not on their own \emph{universally} (over the entire range of $d$) beat the
best known $\sim \log(d)$ scaling of the bounds from \cite{MitchDurb89}. After
recognizing that the progress from \cite{Stojnictcmspnncaprdt23} is therefore
promising, but yet without a complete concretization, we then proceed by
considering the recently developed fully lifted RDT (fl RDT) as an alternative.
While the fl RDT is indeed a powerful juggernaut, it typically relies on heavy
numerical evaluations. To avoid such heavy numerics, we here focus on a
simplified, \emph{partially lifted}, variant and show that it allows for very
neat, closed form, analytical capacity characterizations. Moreover, we obtain
the concrete capacity bounds that \emph{universally} improve for \emph{any} $d$
over the best known ones of \cite{MitchDurb89}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stojnic_M/0/1/0/all/0/1&quot;&gt;Mihailo Stojnic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08264">
<title>Kunyu: A High-Performing Global Weather Model Beyond Regression Losses. (arXiv:2312.08264v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.08264</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past year, data-driven global weather forecasting has emerged as a
new alternative to traditional numerical weather prediction. This innovative
approach yields forecasts of comparable accuracy at a tiny fraction of
computational costs. Regrettably, as far as I know, existing models exclusively
rely on regression losses, producing forecasts with substantial blurring. Such
blurring, although compromises practicality, enjoys an unfair advantage on
evaluation metrics. In this paper, I present Kunyu, a global data-driven
weather forecasting model which delivers accurate predictions across a
comprehensive array of atmospheric variables at 0.35{\deg} resolution. With
both regression and adversarial losses integrated in its training framework,
Kunyu generates forecasts with enhanced clarity and realism. Its performance
outpaces even ECMWF HRES in some aspects such as the estimation of anomaly
extremes, while remaining competitive with ECMWF HRES on evaluation metrics
such as RMSE and ACC. Kunyu is an important step forward in closing the utility
gap between numerical and data-driven weather prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ni_Z/0/1/0/all/0/1&quot;&gt;Zekun Ni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08287">
<title>On the verification of Embeddings using Hybrid Markov Logic. (arXiv:2312.08287v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08287</link>
<description rdf:parseType="Literal">&lt;p&gt;The standard approach to verify representations learned by Deep Neural
Networks is to use them in specific tasks such as classification or regression,
and measure their performance based on accuracy in such tasks. However, in many
cases, we would want to verify more complex properties of a learned
representation. To do this, we propose a framework based on a probabilistic
first-order language, namely, Hybrid Markov Logic Networks (HMLNs) where we
specify properties over embeddings mixed with symbolic domain knowledge. We
present an approach to learn parameters for the properties within this
framework. Further, we develop a verification method to test embeddings in this
framework by encoding this task as a Mixed Integer Linear Program for which we
can leverage existing state-of-the-art solvers. We illustrate verification in
Graph Neural Networks, Deep Knowledge Tracing and Intelligent Tutoring Systems
to demonstrate the generality of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shakya_A/0/1/0/all/0/1&quot;&gt;Anup Shakya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magar_A/0/1/0/all/0/1&quot;&gt;Abisha Thapa Magar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkhel_S/0/1/0/all/0/1&quot;&gt;Somdeb Sarkhel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venugopal_D/0/1/0/all/0/1&quot;&gt;Deepak Venugopal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08288">
<title>Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data Setting. (arXiv:2312.08288v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.08288</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models are known to suffer from the problem of bias, and
researchers have been exploring methods to address this issue. However, most of
these methods require prior knowledge of the bias and are not always practical.
In this paper, we focus on a more practical setting with no prior information
about the bias. Generally, in this setting, there are a large number of
bias-aligned samples that cause the model to produce biased predictions and a
few bias-conflicting samples that do not conform to the bias. If the training
data is limited, the influence of the bias-aligned samples may become even
stronger on the model predictions, and we experimentally demonstrate that
existing debiasing techniques suffer severely in such cases. In this paper, we
examine the effects of unknown bias in small dataset regimes and present a
novel approach to mitigate this issue. The proposed approach directly addresses
the issue of the extremely low occurrence of bias-conflicting samples in
limited data settings through the synthesis of hybrid samples that can be used
to reduce the effect of bias. We perform extensive experiments on several
benchmark datasets and experimentally demonstrate the effectiveness of our
proposed approach in addressing any unknown bias in the presence of limited
data. Specifically, our approach outperforms the vanilla, LfF, LDD, and DebiAN
debiasing methods by absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% when
only 10% of the Corrupted CIFAR-10 Type 1 dataset is available with a
bias-conflicting sample ratio of 0.05.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_P/0/1/0/all/0/1&quot;&gt;Piyush Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazumder_P/0/1/0/all/0/1&quot;&gt;Pratik Mazumder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08290">
<title>PhenDiff: Revealing Invisible Phenotypes with Conditional Diffusion Models. (arXiv:2312.08290v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.08290</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the last five years, deep generative models have gradually been adopted
for various tasks in biological research. Notably, image-to-image translation
methods showed to be effective in revealing subtle phenotypic cell variations
otherwise invisible to the human eye. Current methods to achieve this goal
mainly rely on Generative Adversarial Networks (GANs). However, these models
are known to suffer from some shortcomings such as training instability and
mode collapse. Furthermore, the lack of robustness to invert a real image into
the latent of a trained GAN prevents flexible editing of real images. In this
work, we propose PhenDiff, an image-to-image translation method based on
conditional diffusion models to identify subtle phenotypes in microscopy
images. We evaluate this approach on biological datasets against previous work
such as CycleGAN. We show that PhenDiff outperforms this baseline in terms of
quality and diversity of the generated images. We then apply this method to
display invisible phenotypic changes triggered by a rare neurodevelopmental
disorder on microscopy images of organoids. Altogether, we demonstrate that
PhenDiff is able to perform high quality biological image-to-image translation
allowing to spot subtle phenotype variations on a real image.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bourou_A/0/1/0/all/0/1&quot;&gt;Anis Bourou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Boyer_T/0/1/0/all/0/1&quot;&gt;Thomas Boyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Daupin_K/0/1/0/all/0/1&quot;&gt;K&amp;#xe9;vin Daupin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dubreuil_V/0/1/0/all/0/1&quot;&gt;V&amp;#xe9;ronique Dubreuil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Thonel_A/0/1/0/all/0/1&quot;&gt;Aur&amp;#xe9;lie De Thonel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mezger_V/0/1/0/all/0/1&quot;&gt;Val&amp;#xe9;rie Mezger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Genovesio_A/0/1/0/all/0/1&quot;&gt;Auguste Genovesio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08295">
<title>Inferring Atmospheric Properties of Exoplanets with Flow Matching and Neural Importance Sampling. (arXiv:2312.08295v1 [astro-ph.IM])</title>
<link>http://arxiv.org/abs/2312.08295</link>
<description rdf:parseType="Literal">&lt;p&gt;Atmospheric retrievals (AR) characterize exoplanets by estimating atmospheric
parameters from observed light spectra, typically by framing the task as a
Bayesian inference problem. However, traditional approaches such as nested
sampling are computationally expensive, thus sparking an interest in solutions
based on machine learning (ML). In this ongoing work, we first explore flow
matching posterior estimation (FMPE) as a new ML-based method for AR and find
that, in our case, it is more accurate than neural posterior estimation (NPE),
but less accurate than nested sampling. We then combine both FMPE and NPE with
importance sampling, in which case both methods outperform nested sampling in
terms of accuracy and simulation efficiency. Going forward, our analysis
suggests that simulation-based inference with likelihood-based importance
sampling provides a framework for accurate and efficient AR that may become a
valuable tool not only for the analysis of observational data from existing
telescopes, but also for the development of new missions and instruments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Gebhard_T/0/1/0/all/0/1&quot;&gt;Timothy D. Gebhard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Wildberger_J/0/1/0/all/0/1&quot;&gt;Jonas Wildberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Dax_M/0/1/0/all/0/1&quot;&gt;Maximilian Dax&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Angerhausen_D/0/1/0/all/0/1&quot;&gt;Daniel Angerhausen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Quanz_S/0/1/0/all/0/1&quot;&gt;Sascha P. Quanz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08298">
<title>Venn: Resource Management Across Federated Learning Jobs. (arXiv:2312.08298v1 [cs.DC])</title>
<link>http://arxiv.org/abs/2312.08298</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, federated learning (FL) has emerged as a promising approach
for machine learning (ML) and data science across distributed edge devices.
With the increasing popularity of FL, resource contention between multiple FL
jobs training on the same device population is increasing as well. Scheduling
edge resources among multiple FL jobs is different from GPU scheduling for
cloud ML because of the ephemeral nature and planetary scale of participating
devices as well as the overlapping resource requirements of diverse FL jobs.
Existing resource managers for FL jobs opt for random assignment of devices to
FL jobs for simplicity and scalability, which leads to poor performance. In
this paper, we present Venn, an FL resource manager, that efficiently schedules
ephemeral, heterogeneous devices among many FL jobs, with the goal of reducing
their average job completion time (JCT). Venn formulates the Intersection
Resource Scheduling (IRS) problem to identify complex resource contention among
multiple FL jobs. Then, Venn proposes a contention-aware scheduling heuristic
to minimize the average scheduling delay. Furthermore, it proposes a
resource-aware device-to-job matching heuristic that focuses on optimizing
response collection time by mitigating stragglers. Our evaluation shows that,
compared to the state-of-the-art FL resource managers, Venn improves the
average JCT by up to 1.88X.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiachen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_F/0/1/0/all/0/1&quot;&gt;Fan Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1&quot;&gt;Ding Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yiwen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1&quot;&gt;Mosharaf Chowdhury&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08307">
<title>EquiReact: An equivariant neural network for chemical reactions. (arXiv:2312.08307v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2312.08307</link>
<description rdf:parseType="Literal">&lt;p&gt;Equivariant neural networks have considerably improved the accuracy and
data-efficiency of predictions of molecular properties. Building on this
success, we introduce EquiReact, an equivariant neural network to infer
properties of chemical reactions, built from three-dimensional structures of
reactants and products. We illustrate its competitive performance on the
prediction of activation barriers on the GDB7-22-TS, Cyclo-23-TS and
Proparg-21-TS datasets with different regimes according to the inclusion of
atom-mapping information. We show that, compared to state-of-the-art models for
reaction property prediction, EquiReact offers: (i) a flexible model with
reduced sensitivity between atom-mapping regimes, (ii) better extrapolation
capabilities to unseen chemistries, (iii) impressive prediction errors for
datasets exhibiting subtle variations in three-dimensional geometries of
reactants/products, (iv) reduced sensitivity to geometry quality and (iv)
excellent data efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gerwen_P/0/1/0/all/0/1&quot;&gt;Puck van Gerwen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Briling_K/0/1/0/all/0/1&quot;&gt;Ksenia R. Briling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Bunne_C/0/1/0/all/0/1&quot;&gt;Charlotte Bunne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Somnath_V/0/1/0/all/0/1&quot;&gt;Vignesh Ram Somnath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Laplaza_R/0/1/0/all/0/1&quot;&gt;Ruben Laplaza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Corminboeuf_C/0/1/0/all/0/1&quot;&gt;Clemence Corminboeuf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08358">
<title>Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF. (arXiv:2312.08358v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08358</link>
<description rdf:parseType="Literal">&lt;p&gt;In practice, preference learning from human feedback depends on incomplete
data with hidden context. Hidden context refers to data that affects the
feedback received, but which is not represented in the data used to train a
preference model. This captures common issues of data collection, such as
having human annotators with varied preferences, cognitive processes that
result in seemingly irrational behavior, and combining data labeled according
to different criteria. We prove that standard applications of preference
learning, including reinforcement learning from human feedback (RLHF),
implicitly aggregate over hidden contexts according to a well-known voting rule
called Borda count. We show this can produce counter-intuitive results that are
very different from other methods which implicitly aggregate via expected
utility. Furthermore, our analysis formalizes the way that preference learning
from users with diverse values tacitly implements a social choice function. A
key implication of this result is that annotators have an incentive to
misreport their preferences in order to influence the learned model, leading to
vulnerabilities in the deployment of RLHF. As a step towards mitigating these
problems, we introduce a class of methods called distributional preference
learning (DPL). DPL methods estimate a distribution of possible score values
for each alternative in order to better account for hidden context.
Experimental results indicate that applying DPL to RLHF for LLM chatbots
identifies hidden context in the data and significantly reduces subsequent
jailbreak vulnerability. Our code and data are available at
https://github.com/cassidylaidlaw/hidden-context
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siththaranjan_A/0/1/0/all/0/1&quot;&gt;Anand Siththaranjan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laidlaw_C/0/1/0/all/0/1&quot;&gt;Cassidy Laidlaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1&quot;&gt;Dylan Hadfield-Menell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08361">
<title>Distributed Inference and Fine-tuning of Large Language Models Over The Internet. (arXiv:2312.08361v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08361</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) are useful in many NLP tasks and become more
capable with size, with the best open-source models having over 50 billion
parameters. However, using these 50B+ models requires high-end hardware, making
them inaccessible to most researchers. In this work, we investigate methods for
cost-efficient inference and fine-tuning of LLMs, comparing local and
distributed strategies. We observe that a large enough model (50B+) can run
efficiently even on geodistributed devices in a consumer-grade network. This
could allow running LLM efficiently by pooling together idle compute resources
of multiple research groups and volunteers. We address two open problems: (1)
how to perform inference and fine-tuning reliably if any device can disconnect
abruptly and (2) how to partition LLMs between devices with uneven hardware,
joining and leaving at will. In order to do that, we develop special
fault-tolerant inference algorithms and load-balancing protocols that
automatically assign devices to maximize the total system throughput. We
showcase these algorithms in Petals - a decentralized system that runs Llama 2
(70B) and BLOOM (176B) over the Internet up to 10x faster than offloading for
interactive generation. We evaluate the performance of our system in simulated
conditions and a real-world setup spanning two continents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borzunov_A/0/1/0/all/0/1&quot;&gt;Alexander Borzunov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryabinin_M/0/1/0/all/0/1&quot;&gt;Max Ryabinin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chumachenko_A/0/1/0/all/0/1&quot;&gt;Artem Chumachenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baranchuk_D/0/1/0/all/0/1&quot;&gt;Dmitry Baranchuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dettmers_T/0/1/0/all/0/1&quot;&gt;Tim Dettmers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belkada_Y/0/1/0/all/0/1&quot;&gt;Younes Belkada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samygin_P/0/1/0/all/0/1&quot;&gt;Pavel Samygin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1&quot;&gt;Colin Raffel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08365">
<title>An Invitation to Deep Reinforcement Learning. (arXiv:2312.08365v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.08365</link>
<description rdf:parseType="Literal">&lt;p&gt;Training a deep neural network to maximize a target objective has become the
standard recipe for successful machine learning over the last decade. These
networks can be optimized with supervised learning, if the target objective is
differentiable. For many interesting problems, this is however not the case.
Common objectives like intersection over union (IoU), bilingual evaluation
understudy (BLEU) score or rewards cannot be optimized with supervised
learning. A common workaround is to define differentiable surrogate losses,
leading to suboptimal solutions with respect to the actual objective.
Reinforcement learning (RL) has emerged as a promising alternative for
optimizing deep neural networks to maximize non-differentiable objectives in
recent years. Examples include aligning large language models via human
feedback, code generation, object detection or control problems. This makes RL
techniques relevant to the larger machine learning audience. The subject is,
however, time intensive to approach due to the large range of methods, as well
as the often very theoretical presentation. In this introduction, we take an
alternative approach, different from classic reinforcement learning textbooks.
Rather than focusing on tabular problems, we introduce reinforcement learning
as a generalization of supervised learning, which we first apply to
non-differentiable objectives and later to temporal problems. Assuming only
basic knowledge of supervised learning, the reader will be able to understand
state-of-the-art deep RL algorithms like proximal policy optimization (PPO)
after reading this tutorial.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaeger_B/0/1/0/all/0/1&quot;&gt;Bernhard Jaeger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1&quot;&gt;Andreas Geiger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08369">
<title>The Effective Horizon Explains Deep RL Performance in Stochastic Environments. (arXiv:2312.08369v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.08369</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) theory has largely focused on proving minimax
sample complexity bounds. These require strategic exploration algorithms that
use relatively limited function classes for representing the policy or value
function. Our goal is to explain why deep RL algorithms often perform well in
practice, despite using random exploration and much more expressive function
classes like neural networks. Our work arrives at an explanation by showing
that many stochastic MDPs can be solved by performing only a few steps of value
iteration on the random policy&apos;s Q function and then acting greedily. When this
is true, we find that it is possible to separate the exploration and learning
components of RL, making it much easier to analyze. We introduce a new RL
algorithm, SQIRL, that iteratively learns a near-optimal policy by exploring
randomly to collect rollouts and then performing a limited number of steps of
fitted-Q iteration over those rollouts. Any regression algorithm that satisfies
basic in-distribution generalization properties can be used in SQIRL to
efficiently solve common MDPs. This can explain why deep RL works neural
networks, since it is empirically established that neural networks generalize
well in-distribution. Furthermore, SQIRL explains why random exploration works
well in practice, since we show many environments can be solved by estimating
the random policy&apos;s Q-function and then applying zero or a few steps of value
iteration. We leverage SQIRL to derive instance-dependent sample complexity
bounds for RL that are exponential only in an &quot;effective horizon&quot; of lookahead
and on the complexity of the class used for function approximation.
Empirically, we also find that SQIRL performance strongly correlates with PPO
and DQN performance in a variety of stochastic environments, supporting that
our theoretical analysis is predictive of practical performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Laidlaw_C/0/1/0/all/0/1&quot;&gt;Cassidy Laidlaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_B/0/1/0/all/0/1&quot;&gt;Banghua Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Russell_S/0/1/0/all/0/1&quot;&gt;Stuart Russell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca Dragan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2008.07324">
<title>Intelligence Primer. (arXiv:2008.07324v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2008.07324</link>
<description rdf:parseType="Literal">&lt;p&gt;Intelligence is a fundamental part of all living things, as well as the
foundation for Artificial Intelligence. In this primer we explore the ideas
associated with intelligence and, by doing so, understand the implications and
constraints and potentially outline the capabilities of future systems.
Artificial Intelligence, in the form of Machine Learning, has already had a
significant impact on our lives. As an exploration, we journey into different
parts of intelligence that appear essential. We hope that people find this
helpful in determining the future. Also, during the exploration, we hope to
create new thought-provoking questions. Intelligence is not a single weighable
quantity but a subject that spans Biology, Physics, Philosophy, Cognitive
Science, Neuroscience, Psychology, and Computer Science. The historian Yuval
Noah Harari pointed out that engineers and scientists in the future will have
to broaden their understandings to include disciplines such as Psychology,
Philosophy, and Ethics. Fiction writers have long portrayed engineers and
scientists as deficient in these areas. Today, in modern society, the emergence
of Artificial Intelligence and legal requirements act as forcing functions to
push these broader subjects into the foreground. We start with an introduction
to intelligence and move quickly to more profound thoughts and ideas. We call
this a Life, the Universe, and Everything primer, after the famous science
fiction book by Douglas Adams. Forty-two may be the correct answer, but what
are the questions?
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fezer_K/0/1/0/all/0/1&quot;&gt;Karl Fezer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sloss_A/0/1/0/all/0/1&quot;&gt;Andrew Sloss&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.11992">
<title>Acting in Delayed Environments with Non-Stationary Markov Policies. (arXiv:2101.11992v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2101.11992</link>
<description rdf:parseType="Literal">&lt;p&gt;The standard Markov Decision Process (MDP) formulation hinges on the
assumption that an action is executed immediately after it was chosen. However,
assuming it is often unrealistic and can lead to catastrophic failures in
applications such as robotic manipulation, cloud computing, and finance. We
introduce a framework for learning and planning in MDPs where the
decision-maker commits actions that are executed with a delay of $m$ steps. The
brute-force state augmentation baseline where the state is concatenated to the
last $m$ committed actions suffers from an exponential complexity in $m$, as we
show for policy iteration. We then prove that with execution delay,
deterministic Markov policies in the original state-space are sufficient for
attaining maximal reward, but need to be non-stationary. As for stationary
Markov policies, we show they are sub-optimal in general. Consequently, we
devise a non-stationary Q-learning style model-based algorithm that solves
delayed execution tasks without resorting to state-augmentation. Experiments on
tabular, physical, and Atari domains reveal that it converges quickly to high
performance even for substantial delays, while standard approaches that either
ignore the delay or rely on state-augmentation struggle or fail due to
divergence. The code is available at github.com/galdl/rl_delay_basic and
github.com/galdl/rl_delay_atari.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Derman_E/0/1/0/all/0/1&quot;&gt;Esther Derman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_G/0/1/0/all/0/1&quot;&gt;Gal Dalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.11003">
<title>Differentially private inference via noisy optimization. (arXiv:2103.11003v4 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/2103.11003</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a general optimization-based framework for computing
differentially private M-estimators and a new method for constructing
differentially private confidence regions. Firstly, we show that robust
statistics can be used in conjunction with noisy gradient descent or noisy
Newton methods in order to obtain optimal private estimators with global linear
or quadratic convergence, respectively. We establish local and global
convergence guarantees, under both local strong convexity and self-concordance,
showing that our private estimators converge with high probability to a small
neighborhood of the non-private M-estimators. Secondly, we tackle the problem
of parametric inference by constructing differentially private estimators of
the asymptotic variance of our private M-estimators. This naturally leads to
approximate pivotal statistics for constructing confidence regions and
conducting hypothesis testing. We demonstrate the effectiveness of a bias
correction that leads to enhanced small-sample empirical performance in
simulations. We illustrate the benefits of our methods in several numerical
examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Avella_Medina_M/0/1/0/all/0/1&quot;&gt;Marco Avella-Medina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bradshaw_C/0/1/0/all/0/1&quot;&gt;Casey Bradshaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Loh_P/0/1/0/all/0/1&quot;&gt;Po-Ling Loh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2103.13389">
<title>Generating Novel Scene Compositions from Single Images and Videos. (arXiv:2103.13389v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2103.13389</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a large dataset for training, generative adversarial networks (GANs)
can achieve remarkable performance for the image synthesis task. However,
training GANs in extremely low data regimes remains a challenge, as overfitting
often occurs, leading to memorization or training divergence. In this work, we
introduce SIV-GAN, an unconditional generative model that can generate new
scene compositions from a single training image or a single video clip. We
propose a two-branch discriminator architecture, with content and layout
branches designed to judge internal content and scene layout realism separately
from each other. This discriminator design enables synthesis of visually
plausible, novel compositions of a scene, with varying content and layout,
while preserving the context of the original sample. Compared to previous
single image GANs, our model generates more diverse, higher quality images,
while not being restricted to a single image setting. We further introduce a
new challenging task of learning from a few frames of a single video. In this
training setup the training images are highly similar to each other, which
makes it difficult for prior GAN models to achieve a synthesis of both high
quality and diversity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sushko_V/0/1/0/all/0/1&quot;&gt;Vadim Sushko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1&quot;&gt;Juergen Gall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoreva_A/0/1/0/all/0/1&quot;&gt;Anna Khoreva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.01559">
<title>Smoothed Differential Privacy. (arXiv:2107.01559v4 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2107.01559</link>
<description rdf:parseType="Literal">&lt;p&gt;Differential privacy (DP) is a widely-accepted and widely-applied notion of
privacy based on worst-case analysis. Often, DP classifies most mechanisms
without additive noise as non-private (Dwork et al., 2014). Thus, additive
noises are added to improve privacy (to achieve DP). However, in many
real-world applications, adding additive noise is undesirable (Bagdasaryan et
al., 2019) and sometimes prohibited (Liu et al., 2020).
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a natural extension of DP following the worst
average-case idea behind the celebrated smoothed analysis (Spielman &amp;amp; Teng, May
2004). Our notion, smoothed DP, can effectively measure the privacy leakage of
mechanisms without additive noises under realistic settings. We prove that any
discrete mechanism with sampling procedures is more private than what DP
predicts, while many continuous mechanisms with sampling procedures are still
non-private under smoothed DP. In addition, we prove several desirable
properties of smoothed DP, including composition, robustness to
post-processing, and distribution reduction. Based on those properties, we
propose an efficient algorithm to calculate the privacy parameters for smoothed
DP. Experimentally, we verify that, according to smoothed DP, the discrete
sampling mechanisms are private in real-world elections, and some discrete
neural networks can be private without adding any additive noise. We believe
that these results contribute to the theoretical foundation of realistic
privacy measures beyond worst-case analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1&quot;&gt;Ao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1&quot;&gt;Lirong Xia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.10756">
<title>Semantic Text-to-Face GAN -ST^2FG. (arXiv:2107.10756v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2107.10756</link>
<description rdf:parseType="Literal">&lt;p&gt;Faces generated using generative adversarial networks (GANs) have reached
unprecedented realism. These faces, also known as &quot;Deep Fakes&quot;, appear as
realistic photographs with very little pixel-level distortions. While some work
has enabled the training of models that lead to the generation of specific
properties of the subject, generating a facial image based on a natural
language description has not been fully explored. For security and criminal
identification, the ability to provide a GAN-based system that works like a
sketch artist would be incredibly useful. In this paper, we present a novel
approach to generate facial images from semantic text descriptions. The learned
model is provided with a text description and an outline of the type of face,
which the model uses to sketch the features. Our models are trained using an
Affine Combination Module (ACM) mechanism to combine the text embedding from
BERT and the GAN latent space using a self-attention matrix. This avoids the
loss of features due to inadequate &quot;attention&quot;, which may happen if text
embedding and latent vector are simply concatenated. Our approach is capable of
generating images that are very accurately aligned to the exhaustive textual
descriptions of faces with many fine detail features of the face and helps in
generating better images. The proposed method is also capable of making
incremental changes to a previously generated image if it is provided with
additional textual descriptions or sentences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oza_M/0/1/0/all/0/1&quot;&gt;Manan Oza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chanda_S/0/1/0/all/0/1&quot;&gt;Sukalpa Chanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doermann_D/0/1/0/all/0/1&quot;&gt;David Doermann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.12674">
<title>Rewiring with Positional Encodings for Graph Neural Networks. (arXiv:2201.12674v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2201.12674</link>
<description rdf:parseType="Literal">&lt;p&gt;Several recent works use positional encodings to extend the receptive fields
of graph neural network (GNN) layers equipped with attention mechanisms. These
techniques, however, extend receptive fields to the complete graph, at
substantial computational cost and risking a change in the inductive biases of
conventional GNNs, or require complex architecture adjustments. As a
conservative alternative, we use positional encodings to expand receptive
fields to $r$-hop neighborhoods. More specifically, our method augments the
input graph with additional nodes/edges and uses positional encodings as node
and/or edge features. We thus modify graphs before inputting them to a
downstream GNN model, instead of modifying the model itself. This makes our
method model-agnostic, i.e., compatible with any of the existing GNN
architectures. We also provide examples of positional encodings that are
lossless with a one-to-one map between the original and the modified graphs. We
demonstrate that extending receptive fields via positional encodings and a
virtual fully-connected node significantly improves GNN performance and
alleviates over-squashing using small $r$. We obtain improvements on a variety
of models and datasets and reach competitive performance using traditional GNNs
or graph Transformers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruel_Gabrielsson_R/0/1/0/all/0/1&quot;&gt;Rickard Br&amp;#xfc;el-Gabrielsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yurochkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Yurochkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1&quot;&gt;Justin Solomon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2203.01881">
<title>Measuring Self-Supervised Representation Quality for Downstream Classification using Discriminative Features. (arXiv:2203.01881v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2203.01881</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning (SSL) has shown impressive results in downstream
classification tasks. However, there is limited work in understanding their
failure modes and interpreting their learned representations. In this paper, we
study the representation space of state-of-the-art self-supervised models
including SimCLR, SwaV, MoCo, BYOL, DINO, SimSiam, VICReg and Barlow Twins.
Without the use of class label information, we discover discriminative features
that correspond to unique physical attributes in images, present mostly in
correctly-classified representations. Using these features, we can compress the
representation space by up to 40% without significantly affecting linear
classification performance. We then propose Self-Supervised Representation
Quality Score (or Q-Score), an unsupervised score that can reliably predict if
a given sample is likely to be mis-classified during linear evaluation,
achieving AUPRC of 91.45 on ImageNet-100 and 78.78 on ImageNet-1K. Q-Score can
also be used as a regularization term on pre-trained encoders to remedy
low-quality representations. Fine-tuning with Q-Score regularization can boost
the linear probing accuracy of SSL models by up to 5.8% on ImageNet-100 and
3.7% on ImageNet-1K compared to their baselines. Finally, using gradient
heatmaps and Salient ImageNet masks, we define a metric to quantify the
interpretability of each representation. We show that discriminative features
are strongly correlated to core attributes and, enhancing these features
through Q-score regularization makes SSL representations more interpretable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalibhat_N/0/1/0/all/0/1&quot;&gt;Neha Kalibhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narang_K/0/1/0/all/0/1&quot;&gt;Kanika Narang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1&quot;&gt;Hamed Firooz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1&quot;&gt;Maziar Sanjabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1&quot;&gt;Soheil Feizi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.07553">
<title>On the fast convergence of minibatch heavy ball momentum. (arXiv:2206.07553v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.07553</link>
<description rdf:parseType="Literal">&lt;p&gt;Simple stochastic momentum methods are widely used in machine learning
optimization, but their good practical performance is at odds with an absence
of theoretical guarantees of acceleration in the literature. In this work, we
aim to close the gap between theory and practice by showing that stochastic
heavy ball momentum retains the fast linear rate of (deterministic) heavy ball
momentum on quadratic optimization problems, at least when minibatching with a
sufficiently large batch size. The algorithm we study can be interpreted as an
accelerated randomized Kaczmarz algorithm with minibatching and heavy ball
momentum. The analysis relies on carefully decomposing the momentum transition
matrix, and using new spectral norm concentration bounds for products of
independent random matrices. We provide numerical illustrations demonstrating
that our bounds are reasonably sharp.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bollapragada_R/0/1/0/all/0/1&quot;&gt;Raghu Bollapragada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tyler Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ward_R/0/1/0/all/0/1&quot;&gt;Rachel Ward&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.04690">
<title>Dynamic Budget Throttling in Repeated Second-Price Auctions. (arXiv:2207.04690v7 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/2207.04690</link>
<description rdf:parseType="Literal">&lt;p&gt;In today&apos;s online advertising markets, a crucial requirement for an
advertiser is to control her total expenditure within a time horizon under some
budget. Among various budget control methods, throttling has emerged as a
popular choice, managing an advertiser&apos;s total expenditure by selecting only a
subset of auctions to participate in. This paper provides a theoretical
panorama of a single advertiser&apos;s dynamic budget throttling process in repeated
second-price auctions. We first establish a lower bound on the regret and an
upper bound on the asymptotic competitive ratio for any throttling algorithm,
respectively, when the advertiser&apos;s values are stochastic and adversarial.
Regarding the algorithmic side, we propose the OGD-CB algorithm, which
guarantees a near-optimal expected regret with stochastic values. On the other
hand, when values are adversarial, we prove that this algorithm also reaches
the upper bound on the asymptotic competitive ratio. We further compare
throttling with pacing, another widely adopted budget control method, in
repeated second-price auctions. In the stochastic case, we demonstrate that
pacing is generally superior to throttling for the advertiser, supporting the
well-known result that pacing is asymptotically optimal in this scenario.
However, in the adversarial case, we give an exciting result indicating that
throttling is also an asymptotically optimal dynamic bidding strategy. Our
results bridge the gaps in theoretical research of throttling in repeated
auctions and comprehensively reveal the ability of this popular
budget-smoothing strategy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhaohua Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yuqi Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zhuming Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1&quot;&gt;Zheng Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1&quot;&gt;Yukun Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhihua Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1&quot;&gt;Xiaotie Deng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.08716">
<title>GLARE: A Dataset for Traffic Sign Detection in Sun Glare. (arXiv:2209.08716v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2209.08716</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time machine learning object detection algorithms are often found within
autonomous vehicle technology and depend on quality datasets. It is essential
that these algorithms work correctly in everyday conditions as well as under
strong sun glare. Reports indicate glare is one of the two most prominent
environment-related reasons for crashes. However, existing datasets, such as
the Laboratory for Intelligent &amp;amp; Safe Automobiles Traffic Sign (LISA) Dataset
and the German Traffic Sign Recognition Benchmark, do not reflect the existence
of sun glare at all. This paper presents the GLARE (GLARE is available at:
https://github.com/NicholasCG/GLARE_Dataset ) traffic sign dataset: a
collection of images with U.S-based traffic signs under heavy visual
interference by sunlight. GLARE contains 2,157 images of traffic signs with sun
glare, pulled from 33 videos of dashcam footage of roads in the United States.
It provides an essential enrichment to the widely used LISA Traffic Sign
dataset. Our experimental study shows that although several state-of-the-art
baseline architectures have demonstrated good performance on traffic sign
detection in conditions without sun glare in the past, they performed poorly
when tested against GLARE (e.g., average mAP0.5:0.95 of 19.4). We also notice
that current architectures have better detection when trained on images of
traffic signs in sun glare performance (e.g., average mAP0.5:0.95 of 39.6), and
perform best when trained on a mixture of conditions (e.g., average mAP0.5:0.95
of 42.3).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gray_N/0/1/0/all/0/1&quot;&gt;Nicholas Gray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moraes_M/0/1/0/all/0/1&quot;&gt;Megan Moraes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1&quot;&gt;Jiang Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1&quot;&gt;Alex Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_A/0/1/0/all/0/1&quot;&gt;Allen Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_K/0/1/0/all/0/1&quot;&gt;Kurt Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Haoyi Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1&quot;&gt;Zhishan Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.10187">
<title>On the convex formulations of robust Markov decision processes. (arXiv:2209.10187v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2209.10187</link>
<description rdf:parseType="Literal">&lt;p&gt;Robust Markov decision processes (MDPs) are used for applications of dynamic
optimization in uncertain environments and have been studied extensively. Many
of the main properties and algorithms of MDPs, such as value iteration and
policy iteration, extend directly to RMDPs. Surprisingly, there is no known
analog of the MDP convex optimization formulation for solving RMDPs. This work
describes the first convex optimization formulation of RMDPs under the
classical sa-rectangularity and s-rectangularity assumptions. By using entropic
regularization and exponential change of variables, we derive a convex
formulation with a number of variables and constraints polynomial in the number
of states and actions, but with large coefficients in the constraints. We
further simplify the formulation for RMDPs with polyhedral, ellipsoidal, or
entropy-based uncertainty sets, showing that, in these cases, RMDPs can be
reformulated as conic programs based on exponential cones, quadratic cones, and
non-negative orthants. Our work opens a new research direction for RMDPs and
can serve as a first step toward obtaining a tractable convex formulation of
RMDPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Grand_Clement_J/0/1/0/all/0/1&quot;&gt;Julien Grand-Cl&amp;#xe9;ment&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Petrik_M/0/1/0/all/0/1&quot;&gt;Marek Petrik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.00736">
<title>Mixed moving average field guided learning for spatio-temporal data. (arXiv:2301.00736v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2301.00736</link>
<description rdf:parseType="Literal">&lt;p&gt;Influenced mixed moving average fields are a versatile modeling class for
spatio-temporal data. However, their predictive distribution is not generally
known. Under this modeling assumption, we define a novel spatio-temporal
embedding and a theory-guided machine learning approach that employs a
generalized Bayesian algorithm to make ensemble forecasts. We employ Lipschitz
predictors and determine fixed-time and any-time PAC Bayesian bounds in the
batch learning setting. Performing causal forecast is a highlight of our
methodology as its potential application to data with spatial and temporal
short and long-range dependence. We then test the performance of our learning
methodology by using linear predictors and data sets simulated from a
spatio-temporal Ornstein-Uhlenbeck process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Curato_I/0/1/0/all/0/1&quot;&gt;Imma Valentina Curato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Furat_O/0/1/0/all/0/1&quot;&gt;Orkun Furat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Proietti_L/0/1/0/all/0/1&quot;&gt;Lorenzo Proietti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stroeh_B/0/1/0/all/0/1&quot;&gt;Bennet Stroeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.10814">
<title>Unsupervised Protein-Ligand Binding Energy Prediction via Neural Euler&apos;s Rotation Equation. (arXiv:2301.10814v2 [q-bio.BM] UPDATED)</title>
<link>http://arxiv.org/abs/2301.10814</link>
<description rdf:parseType="Literal">&lt;p&gt;Protein-ligand binding prediction is a fundamental problem in AI-driven drug
discovery. Prior work focused on supervised learning methods using a large set
of binding affinity data for small molecules, but it is hard to apply the same
strategy to other drug classes like antibodies as labelled data is limited. In
this paper, we explore unsupervised approaches and reformulate binding energy
prediction as a generative modeling task. Specifically, we train an
energy-based model on a set of unlabelled protein-ligand complexes using SE(3)
denoising score matching and interpret its log-likelihood as binding affinity.
Our key contribution is a new equivariant rotation prediction network called
Neural Euler&apos;s Rotation Equations (NERE) for SE(3) score matching. It predicts
a rotation by modeling the force and torque between protein and ligand atoms,
where the force is defined as the gradient of an energy function with respect
to atom coordinates. We evaluate NERE on protein-ligand and antibody-antigen
binding affinity prediction benchmarks. Our model outperforms all unsupervised
baselines (physics-based and statistical potentials) and matches supervised
learning methods in the antibody case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Jin_W/0/1/0/all/0/1&quot;&gt;Wengong Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sarkizova_S/0/1/0/all/0/1&quot;&gt;Siranush Sarkizova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hacohen_N/0/1/0/all/0/1&quot;&gt;Nir Hacohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Uhler_C/0/1/0/all/0/1&quot;&gt;Caroline Uhler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.12361">
<title>Graph Harmony: Denoising and Nuclear-Norm Wasserstein Adaptation for Enhanced Domain Transfer in Graph-Structured Data. (arXiv:2301.12361v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.12361</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph-structured data can be found in numerous domains, yet the scarcity of
labeled instances hinders its effective utilization of deep learning in many
scenarios. Traditional unsupervised domain adaptation (UDA) strategies for
graphs primarily hinge on adversarial learning and pseudo-labeling. These
approaches fail to effectively leverage graph discriminative features, leading
to class mismatching and unreliable label quality. To navigate these obstacles,
we develop the Denoising and Nuclear-Norm Wasserstein Adaptation Network
(DNAN). DNAN employs the Nuclear-norm Wasserstein discrepancy (NWD), which can
simultaneously achieve domain alignment and class distinguishment. DANA also
integrates a denoising mechanism via a variational graph autoencoder that
mitigates data noise. This denoising mechanism helps capture essential features
of both source and target domains, improving the robustness of the domain
adaptation process. Our comprehensive experiments demonstrate that DNAN
outperforms state-of-the-art methods on standard UDA benchmarks for graph
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Mengxi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rostami_M/0/1/0/all/0/1&quot;&gt;Mohammad Rostami&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.13428">
<title>Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation. (arXiv:2301.13428v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2301.13428</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised domain adaptation uses source data from different distributions
to solve the problem of classifying data from unlabeled target domains.
However, conventional methods require access to source data, which often raise
concerns about data privacy. In this paper, we consider a more practical but
challenging setting where the source domain data is unavailable and the target
domain data is unlabeled. Specifically, we address the domain discrepancy
problem from the perspective of contrastive learning. The key idea of our work
is to learn a domain-invariant feature by 1) performing clustering directly in
the original feature space with nearest neighbors; 2) constructing truly hard
negative pairs by extended neighbors without introducing additional
computational complexity; and 3) combining noise-contrastive estimation theory
to gain computational advantage. We conduct careful ablation studies and
extensive experiments on three common benchmarks: VisDA, Office-Home, and
Office-31. The results demonstrate the superiority of our methods compared with
other state-of-the-art works.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiangbin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yonggang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingjian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1&quot;&gt;Haojie Fang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.07350">
<title>Graph schemas as abstractions for transfer learning, inference, and planning. (arXiv:2302.07350v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2302.07350</link>
<description rdf:parseType="Literal">&lt;p&gt;Transferring latent structure from one environment or problem to another is a
mechanism by which humans and animals generalize with very little data.
Inspired by cognitive and neurobiological insights, we propose graph schemas as
a mechanism of abstraction for transfer learning. Graph schemas start with
latent graph learning where perceptually aliased observations are disambiguated
in the latent space using contextual information. Latent graph learning is also
emerging as a new computational model of the hippocampus to explain map
learning and transitive inference. Our insight is that a latent graph can be
treated as a flexible template -- a schema -- that models concepts and
behaviors, with slots that bind groups of latent nodes to the specific
observations or groundings. By treating learned latent graphs (schemas) as
prior knowledge, new environments can be quickly learned as compositions of
schemas and their newly learned bindings. We evaluate graph schemas on two
previously published challenging tasks: the memory &amp;amp; planning game and one-shot
StreetLearn, which are designed to test rapid task solving in novel
environments. Graph schemas can be learned in far fewer episodes than previous
baselines, and can model and plan in a few steps in novel variations of these
tasks. We also demonstrate learning, matching, and reusing graph schemas in
more challenging 2D and 3D environments with extensive perceptual aliasing and
size variations, and show how different schemas can be composed to model larger
and more complex environments. To summarize, our main contribution is a unified
system, inspired and grounded in cognitive science, that facilitates rapid
transfer learning of new environments using schemas via map-induction and
composition that handles perceptual aliasing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guntupalli_J/0/1/0/all/0/1&quot;&gt;J. Swaroop Guntupalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raju_R/0/1/0/all/0/1&quot;&gt;Rajkumar Vasudeva Raju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kushagra_S/0/1/0/all/0/1&quot;&gt;Shrinu Kushagra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wendelken_C/0/1/0/all/0/1&quot;&gt;Carter Wendelken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sawyer_D/0/1/0/all/0/1&quot;&gt;Danny Sawyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_I/0/1/0/all/0/1&quot;&gt;Ishan Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1&quot;&gt;Guangyao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazaro_Gredilla_M/0/1/0/all/0/1&quot;&gt;Miguel L&amp;#xe1;zaro-Gredilla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+George_D/0/1/0/all/0/1&quot;&gt;Dileep George&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.10915">
<title>Conformers are All You Need for Visual Speech Recognition. (arXiv:2302.10915v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.10915</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual speech recognition models extract visual features in a hierarchical
manner. At the lower level, there is a visual front-end with a limited temporal
receptive field that processes the raw pixels depicting the lips or faces. At
the higher level, there is an encoder that attends to the embeddings produced
by the front-end over a large temporal receptive field. Previous work has
focused on improving the visual front-end of the model to extract more useful
features for speech recognition. Surprisingly, our work shows that complex
visual front-ends are not necessary. Instead of allocating resources to a
sophisticated visual front-end, we find that a linear visual front-end paired
with a larger Conformer encoder results in lower latency, more efficient memory
usage, and improved WER performance. We achieve a new state-of-the-art of 12.8%
WER for visual speech recognition on the TED LRS3 dataset, which rivals the
performance of audio-only models from just four years ago.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_O/0/1/0/all/0/1&quot;&gt;Oscar Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1&quot;&gt;Hank Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serdyuk_D/0/1/0/all/0/1&quot;&gt;Dmitriy Serdyuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1&quot;&gt;Ankit Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siohan_O/0/1/0/all/0/1&quot;&gt;Olivier Siohan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.14407">
<title>The Choice of Noninformative Priors for Thompson Sampling in Multiparameter Bandit Models. (arXiv:2302.14407v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.14407</link>
<description rdf:parseType="Literal">&lt;p&gt;Thompson sampling (TS) has been known for its outstanding empirical
performance supported by theoretical guarantees across various reward models in
the classical stochastic multi-armed bandit problems. Nonetheless, its
optimality is often restricted to specific priors due to the common observation
that TS is fairly insensitive to the choice of the prior when it comes to
asymptotic regret bounds. However, when the model contains multiple parameters,
the optimality of TS highly depends on the choice of priors, which casts doubt
on the generalizability of previous findings to other models. To address this
gap, this study explores the impact of selecting noninformative priors,
offering insights into the performance of TS when dealing with new models that
lack theoretical understanding. We first extend the regret analysis of TS to
the model of uniform distributions with unknown supports, which would be the
simplest non-regular model. Our findings reveal that changing noninformative
priors can significantly affect the expected regret, aligning with previously
known results in other multiparameter bandit models. Although the uniform prior
is shown to be optimal, we highlight the inherent limitation of its optimality,
which is limited to specific parameterizations and emphasizes the significance
of the invariance property of priors. In light of this limitation, we propose a
slightly modified TS-based policy, called TS with Truncation (TS-T), which can
achieve the asymptotic optimality for the Gaussian models and the uniform
models by using the reference prior and the Jeffreys prior that are invariant
under one-to-one reparameterizations. This policy provides an alternative
approach to achieving optimality by employing fine-tuned truncation, which
would be much easier than hunting for optimal priors in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jongyeong Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiang_C/0/1/0/all/0/1&quot;&gt;Chao-Kai Chiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.02618">
<title>Ensemble Reinforcement Learning: A Survey. (arXiv:2303.02618v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.02618</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement Learning (RL) has emerged as a highly effective technique for
addressing various scientific and applied problems. Despite its success,
certain complex tasks remain challenging to be addressed solely with a single
model and algorithm. In response, ensemble reinforcement learning (ERL), a
promising approach that combines the benefits of both RL and ensemble learning
(EL), has gained widespread popularity. ERL leverages multiple models or
training algorithms to comprehensively explore the problem space and possesses
strong generalization capabilities. In this study, we present a comprehensive
survey on ERL to provide readers with an overview of recent advances and
challenges in the field. Firstly, we provide an introduction to the background
and motivation for ERL. Secondly, we conduct a detailed analysis of strategies
such as model selection and combination that have been successfully implemented
in ERL. Subsequently, we explore the application of ERL, summarize the
datasets, and analyze the algorithms employed. Finally, we outline several open
questions and discuss future research directions of ERL. By offering guidance
for future scientific research and engineering applications, this survey
significantly contributes to the advancement of ERL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yanjie Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suganthan_P/0/1/0/all/0/1&quot;&gt;P. N. Suganthan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1&quot;&gt;Witold Pedrycz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ou_J/0/1/0/all/0/1&quot;&gt;Junwei Ou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yongming He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yingwu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yutong Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.01075">
<title>Conformal Prediction Regions for Time Series using Linear Complementarity Programming. (arXiv:2304.01075v4 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2304.01075</link>
<description rdf:parseType="Literal">&lt;p&gt;Conformal prediction is a statistical tool for producing prediction regions
of machine learning models that are valid with high probability. However,
applying conformal prediction to time series data leads to conservative
prediction regions. In fact, to obtain prediction regions over $T$ time steps
with confidence $1-\delta$, {previous works require that each individual
prediction region is valid} with confidence $1-\delta/T$. We propose an
optimization-based method for reducing this conservatism to enable long horizon
planning and verification when using learning-enabled time series predictors.
Instead of considering prediction errors individually at each time step, we
consider a parameterized prediction error over multiple time steps. By
optimizing the parameters over an additional dataset, we find prediction
regions that are not conservative. We show that this problem can be cast as a
mixed integer linear complementarity program (MILCP), which we then relax into
a linear complementarity program (LCP). Additionally, we prove that the relaxed
LP has the same optimal cost as the original MILCP. Finally, we demonstrate the
efficacy of our method on case studies using pedestrian trajectory predictors
and F16 fighter jet altitude predictors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cleaveland_M/0/1/0/all/0/1&quot;&gt;Matthew Cleaveland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_I/0/1/0/all/0/1&quot;&gt;Insup Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pappas_G/0/1/0/all/0/1&quot;&gt;George J. Pappas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lindemann_L/0/1/0/all/0/1&quot;&gt;Lars Lindemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.07939">
<title>Leveraging sparse and shared feature activations for disentangled representation learning. (arXiv:2304.07939v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.07939</link>
<description rdf:parseType="Literal">&lt;p&gt;Recovering the latent factors of variation of high dimensional data has so
far focused on simple synthetic settings. Mostly building on unsupervised and
weakly-supervised objectives, prior work missed out on the positive
implications for representation learning on real world data. In this work, we
propose to leverage knowledge extracted from a diversified set of supervised
tasks to learn a common disentangled representation. Assuming each supervised
task only depends on an unknown subset of the factors of variation, we
disentangle the feature space of a supervised multi-task model, with features
activating sparsely across different tasks and information being shared as
appropriate. Importantly, we never directly observe the factors of variations
but establish that access to multiple tasks is sufficient for identifiability
under sufficiency and minimality assumptions. We validate our approach on six
real world distribution shift benchmarks, and different data modalities
(images, text), demonstrating how disentangled representations can be
transferred to real settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fumero_M/0/1/0/all/0/1&quot;&gt;Marco Fumero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wenzel_F/0/1/0/all/0/1&quot;&gt;Florian Wenzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zancato_L/0/1/0/all/0/1&quot;&gt;Luca Zancato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1&quot;&gt;Alessandro Achille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodola_E/0/1/0/all/0/1&quot;&gt;Emanuele Rodol&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1&quot;&gt;Stefano Soatto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1&quot;&gt;Francesco Locatello&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.08485">
<title>Visual Instruction Tuning. (arXiv:2304.08485v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.08485</link>
<description rdf:parseType="Literal">&lt;p&gt;Instruction tuning large language models (LLMs) using machine-generated
instruction-following data has improved zero-shot capabilities on new tasks,
but the idea is less explored in the multimodal field. In this paper, we
present the first attempt to use language-only GPT-4 to generate multimodal
language-image instruction-following data. By instruction tuning on such
generated data, we introduce LLaVA: Large Language and Vision Assistant, an
end-to-end trained large multimodal model that connects a vision encoder and
LLM for general-purpose visual and language understanding.Our early experiments
show that LLaVA demonstrates impressive multimodel chat abilities, sometimes
exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and
yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal
instruction-following dataset. When fine-tuned on Science QA, the synergy of
LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make
GPT-4 generated visual instruction tuning data, our model and code base
publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haotian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chunyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qingyang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yong Jae Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.09329">
<title>Learning to Transmit with Provable Guarantees in Wireless Federated Learning. (arXiv:2304.09329v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.09329</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel data-driven approach to allocate transmit power for
federated learning (FL) over interference-limited wireless networks. The
proposed method is useful in challenging scenarios where the wireless channel
is changing during the FL training process and when the training data are not
independent and identically distributed (non-i.i.d.) on the local devices.
Intuitively, the power policy is designed to optimize the information received
at the server end during the FL process under communication constraints.
Ultimately, our goal is to improve the accuracy and efficiency of the global FL
model being trained. The proposed power allocation policy is parameterized
using graph convolutional networks (GCNs), and the associated constrained
optimization problem is solved through a primal-dual (PD) algorithm.
Theoretically, we show that the formulated problem has a zero duality gap and,
once the power policy is parameterized, optimality depends on how expressive
this parameterization is. Numerically, we demonstrate that the proposed method
outperforms existing baselines under different wireless channel settings and
varying degrees of data heterogeneity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Boning Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perazzone_J/0/1/0/all/0/1&quot;&gt;Jake Perazzone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swami_A/0/1/0/all/0/1&quot;&gt;Ananthram Swami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1&quot;&gt;Santiago Segarra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.13850">
<title>Do SSL Models Have D\&apos;ej\`a Vu? A Case of Unintended Memorization in Self-supervised Learning. (arXiv:2304.13850v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.13850</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning (SSL) algorithms can produce useful image
representations by learning to associate different parts of natural images with
one another. However, when taken to the extreme, SSL models can unintendedly
memorize specific parts in individual training samples rather than learning
semantically meaningful associations. In this work, we perform a systematic
study of the unintended memorization of image-specific information in SSL
models -- which we refer to as d\&apos;ej\`a vu memorization. Concretely, we show
that given the trained model and a crop of a training image containing only the
background (e.g., water, sky, grass), it is possible to infer the foreground
object with high accuracy or even visually reconstruct it. Furthermore, we show
that d\&apos;ej\`a vu memorization is common to different SSL algorithms, is
exacerbated by certain design choices, and cannot be detected by conventional
techniques for evaluating representation quality. Our study of d\&apos;ej\`a vu
memorization reveals previously unknown privacy risks in SSL models, as well as
suggests potential practical mitigation strategies. Code is available at
https://github.com/facebookresearch/DejaVu.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meehan_C/0/1/0/all/0/1&quot;&gt;Casey Meehan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bordes_F/0/1/0/all/0/1&quot;&gt;Florian Bordes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1&quot;&gt;Pascal Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_K/0/1/0/all/0/1&quot;&gt;Kamalika Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1&quot;&gt;Chuan Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.02148">
<title>Semi-Supervised Segmentation of Functional Tissue Units at the Cellular Level. (arXiv:2305.02148v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.02148</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new method for functional tissue unit segmentation at the
cellular level, which utilizes the latest deep learning semantic segmentation
approaches together with domain adaptation and semi-supervised learning
techniques. This approach allows for minimizing the domain gap, class
imbalance, and captures settings influence between HPA and HubMAP datasets. The
presented approach achieves comparable with state-of-the-art-result in
functional tissue unit segmentation at the cellular level. The source code is
available at https://github.com/VSydorskyy/hubmap_2022_htt_solution
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sydorskyi_V/0/1/0/all/0/1&quot;&gt;Volodymyr Sydorskyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Krashenyi_I/0/1/0/all/0/1&quot;&gt;Igor Krashenyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sakva_D/0/1/0/all/0/1&quot;&gt;Denis Sakva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zarichkovyi_O/0/1/0/all/0/1&quot;&gt;Oleksandr Zarichkovyi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06408">
<title>Accelerating Batch Active Learning Using Continual Learning Techniques. (arXiv:2305.06408v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06408</link>
<description rdf:parseType="Literal">&lt;p&gt;A major problem with Active Learning (AL) is high training costs since models
are typically retrained from scratch after every query round. We start by
demonstrating that standard AL on neural networks with warm starting fails,
both to accelerate training and to avoid catastrophic forgetting when using
fine-tuning over AL query rounds. We then develop a new class of techniques,
circumventing this problem, by biasing further training towards previously
labeled sets. We accomplish this by employing existing, and developing novel,
replay-based Continual Learning (CL) algorithms that are effective at quickly
learning the new without forgetting the old, especially when data comes from an
evolving distribution. We call this paradigm Continual Active Learning (CAL).
We show CAL achieves significant speedups using a plethora of replay schemes
that use model distillation and that select diverse, uncertain points from the
history. We conduct experiments across many data domains, including natural
language, vision, medical imaging, and computational biology, each with
different neural architectures and dataset sizes. CAL consistently provides a
3x reduction in training time, while retaining performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Arnav Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhatt_G/0/1/0/all/0/1&quot;&gt;Gantavya Bhatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhalerao_M/0/1/0/all/0/1&quot;&gt;Megh Bhalerao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_V/0/1/0/all/0/1&quot;&gt;Vianne Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Rui Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilmes_J/0/1/0/all/0/1&quot;&gt;Jeff Bilmes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.10697">
<title>The Blessing of Heterogeneity in Federated Q-Learning: Linear Speedup and Beyond. (arXiv:2305.10697v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.10697</link>
<description rdf:parseType="Literal">&lt;p&gt;When the data used for reinforcement learning (RL) are collected by multiple
agents in a distributed manner, federated versions of RL algorithms allow
collaborative learning without the need for agents to share their local data.
In this paper, we consider federated Q-learning, which aims to learn an optimal
Q-function by periodically aggregating local Q-estimates trained on local data
alone. Focusing on infinite-horizon tabular Markov decision processes, we
provide sample complexity guarantees for both the synchronous and asynchronous
variants of federated Q-learning. In both cases, our bounds exhibit a linear
speedup with respect to the number of agents and near-optimal dependencies on
other salient problem parameters.
&lt;/p&gt;
&lt;p&gt;In the asynchronous setting, existing analyses of federated Q-learning, which
adopt an equally weighted averaging of local Q-estimates, require that every
agent covers the entire state-action space. In contrast, our improved sample
complexity scales inverse proportionally to the minimum entry of the average
stationary state-action occupancy distribution of all agents, thus only
requiring the agents to collectively cover the entire state-action space,
unveiling the blessing of heterogeneity in enabling collaborative learning by
relaxing the coverage requirement of the single-agent case. However, its sample
complexity still suffers when the local trajectories are highly heterogeneous.
In response, we propose a novel federated Q-learning algorithm with importance
averaging, giving larger weights to more frequently visited state-action pairs,
which achieves a robust linear speedup as if all trajectories are centrally
processed, regardless of the heterogeneity of local behavior policies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1&quot;&gt;Jiin Woo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_G/0/1/0/all/0/1&quot;&gt;Gauri Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1&quot;&gt;Yuejie Chi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18290">
<title>Direct Preference Optimization: Your Language Model is Secretly a Reward Model. (arXiv:2305.18290v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18290</link>
<description rdf:parseType="Literal">&lt;p&gt;While large-scale unsupervised language models (LMs) learn broad world
knowledge and some reasoning skills, achieving precise control of their
behavior is difficult due to the completely unsupervised nature of their
training. Existing methods for gaining such steerability collect human labels
of the relative quality of model generations and fine-tune the unsupervised LM
to align with these preferences, often with reinforcement learning from human
feedback (RLHF). However, RLHF is a complex and often unstable procedure, first
fitting a reward model that reflects the human preferences, and then
fine-tuning the large unsupervised LM using reinforcement learning to maximize
this estimated reward without drifting too far from the original model. In this
paper we introduce a new parameterization of the reward model in RLHF that
enables extraction of the corresponding optimal policy in closed form, allowing
us to solve the standard RLHF problem with only a simple classification loss.
The resulting algorithm, which we call Direct Preference Optimization (DPO), is
stable, performant, and computationally lightweight, eliminating the need for
sampling from the LM during fine-tuning or performing significant
hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align
with human preferences as well as or better than existing methods. Notably,
fine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of
generations, and matches or improves response quality in summarization and
single-turn dialogue while being substantially simpler to implement and train.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rafailov_R/0/1/0/all/0/1&quot;&gt;Rafael Rafailov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Archit Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitchell_E/0/1/0/all/0/1&quot;&gt;Eric Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1&quot;&gt;Christopher D. Manning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19414">
<title>Efficient Training of Energy-Based Models Using Jarzynski Equality. (arXiv:2305.19414v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19414</link>
<description rdf:parseType="Literal">&lt;p&gt;Energy-based models (EBMs) are generative models inspired by statistical
physics with a wide range of applications in unsupervised learning. Their
performance is best measured by the cross-entropy (CE) of the model
distribution relative to the data distribution. Using the CE as the objective
for training is however challenging because the computation of its gradient
with respect to the model parameters requires sampling the model distribution.
Here we show how results for nonequilibrium thermodynamics based on Jarzynski
equality together with tools from sequential Monte-Carlo sampling can be used
to perform this computation efficiently and avoid the uncontrolled
approximations made using the standard contrastive divergence algorithm.
Specifically, we introduce a modification of the unadjusted Langevin algorithm
(ULA) in which each walker acquires a weight that enables the estimation of the
gradient of the cross-entropy at any step during GD, thereby bypassing sampling
biases induced by slow mixing of ULA. We illustrate these results with
numerical experiments on Gaussian mixture distributions as well as the MNIST
dataset. We show that the proposed approach outperforms methods based on the
contrastive divergence algorithm in all the considered situations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carbone_D/0/1/0/all/0/1&quot;&gt;Davide Carbone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_M/0/1/0/all/0/1&quot;&gt;Mengjian Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coste_S/0/1/0/all/0/1&quot;&gt;Simon Coste&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1&quot;&gt;Eric Vanden-Eijnden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.04064">
<title>Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings. (arXiv:2306.04064v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.04064</link>
<description rdf:parseType="Literal">&lt;p&gt;Research on adversarial robustness is primarily focused on image and text
data. Yet, many scenarios in which lack of robustness can result in serious
risks, such as fraud detection, medical diagnosis, or recommender systems often
do not rely on images or text but instead on tabular data. Adversarial
robustness in tabular data poses two serious challenges. First, tabular
datasets often contain categorical features, and therefore cannot be tackled
directly with existing optimization procedures. Second, in the tabular domain,
algorithms that are not based on deep networks are widely used and offer great
performance, but algorithms to enhance robustness are tailored to neural
networks (e.g. adversarial training).
&lt;/p&gt;
&lt;p&gt;In this paper, we tackle both challenges. We present a method that allows us
to train adversarially robust deep networks for tabular data and to transfer
this robustness to other classifiers via universal robust embeddings tailored
to categorical data. These embeddings, created using a bilevel alternating
minimization framework, can be transferred to boosted trees or random forests
making them robust without the need for adversarial training while preserving
their high accuracy on tabular data. We show that our methods outperform
existing techniques within a practical threat model suitable for tabular data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kireev_K/0/1/0/all/0/1&quot;&gt;Klim Kireev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andriushchenko_M/0/1/0/all/0/1&quot;&gt;Maksym Andriushchenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Troncoso_C/0/1/0/all/0/1&quot;&gt;Carmela Troncoso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1&quot;&gt;Nicolas Flammarion&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02345">
<title>LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning. (arXiv:2307.02345v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02345</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern reinforcement learning (RL) can be categorized into online and offline
variants. As a pivotal aspect of both online and offline RL, current research
on the Bellman equation revolves primarily around optimization techniques and
performance enhancement rather than exploring the inherent structural
properties of the Bellman error, such as its distribution characteristics. This
study investigates the distribution of the Bellman approximation error through
iterative exploration of the Bellman equation with the observation that the
Bellman error approximately follows the Logistic distribution. Based on this,
we proposed the utilization of the Logistic maximum likelihood function (LLoss)
as an alternative to the commonly used mean squared error (MSELoss) that
assumes a Normal distribution for Bellman errors. We validated the hypotheses
through extensive numerical experiments across diverse online and offline
environments. In particular, we applied the Logistic correction to loss
functions in various RL baseline methods and observed that the results with
LLoss consistently outperformed the MSE counterparts. We also conducted the
Kolmogorov-Smirnov tests to confirm the reliability of the Logistic
distribution. Moreover, our theory connects the Bellman error to the
proportional reward scaling phenomenon by providing a distribution-based
analysis. Furthermore, we applied the bias-variance decomposition for sampling
from the Logistic distribution. The theoretical and empirical insights of this
study lay a valuable foundation for future investigations and enhancements
centered on the distribution of Bellman error.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_O/0/1/0/all/0/1&quot;&gt;Outongyi Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Bingxin Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.10705">
<title>TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and Lane Segmentation in Self-Driving Cars. (arXiv:2307.10705v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.10705</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic segmentation is a common task in autonomous driving to understand
the surrounding environment. Driveable Area Segmentation and Lane Detection are
particularly important for safe and efficient navigation on the road. However,
original semantic segmentation models are computationally expensive and require
high-end hardware, which is not feasible for embedded systems in autonomous
vehicles. This paper proposes a lightweight model for the driveable area and
lane line segmentation. TwinLiteNet is designed cheaply but achieves accurate
and efficient segmentation results. We evaluate TwinLiteNet on the BDD100K
dataset and compare it with modern models. Experimental results show that our
TwinLiteNet performs similarly to existing approaches, requiring significantly
fewer computational resources. Specifically, TwinLiteNet achieves a mIoU score
of 91.3% for the Drivable Area task and 31.08% IoU for the Lane Detection task
with only 0.4 million parameters and achieves 415 FPS on GPU RTX A5000.
Furthermore, TwinLiteNet can run in real-time on embedded devices with limited
computing power, especially since it achieves 60FPS on Jetson Xavier NX, making
it an ideal solution for self-driving vehicles. Code is available:
url{https://github.com/chequanghuy/TwinLiteNet}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Che_Q/0/1/0/all/0/1&quot;&gt;Quang Huy Che&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Dinh Phuc Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_M/0/1/0/all/0/1&quot;&gt;Minh Quan Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_D/0/1/0/all/0/1&quot;&gt;Duc Khai Lam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.12971">
<title>Big Data -- Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques. (arXiv:2307.12971v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.12971</link>
<description rdf:parseType="Literal">&lt;p&gt;This article intends to systematically identify and comparatively analyze
state-of-the-art supply chain (SC) forecasting strategies and technologies. A
novel framework has been proposed incorporating Big Data Analytics in SC
Management (problem identification, data sources, exploratory data analysis,
machine-learning model training, hyperparameter tuning, performance evaluation,
and optimization), forecasting effects on human-workforce, inventory, and
overall SC. Initially, the need to collect data according to SC strategy and
how to collect them has been discussed. The article discusses the need for
different types of forecasting according to the period or SC objective. The SC
KPIs and the error-measurement systems have been recommended to optimize the
top-performing model. The adverse effects of phantom inventory on forecasting
and the dependence of managerial decisions on the SC KPIs for determining model
performance parameters and improving operations management, transparency, and
planning efficiency have been illustrated. The cyclic connection within the
framework introduces preprocessing optimization based on the post-process KPIs,
optimizing the overall control process (inventory management, workforce
determination, cost, production and capacity planning). The contribution of
this research lies in the standard SC process framework proposal, recommended
forecasting data analysis, forecasting effects on SC performance, machine
learning algorithms optimization followed, and in shedding light on future
research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jahin_M/0/1/0/all/0/1&quot;&gt;Md Abrar Jahin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shovon_M/0/1/0/all/0/1&quot;&gt;Md Sakib Hossain Shovon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jungpil Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ridoy_I/0/1/0/all/0/1&quot;&gt;Istiyaque Ahmed Ridoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomioka_Y/0/1/0/all/0/1&quot;&gt;Yoichi Tomioka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mridha_M/0/1/0/all/0/1&quot;&gt;M. F. Mridha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.00031">
<title>Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges. (arXiv:2308.00031v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.00031</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Artificial Intelligence (AI) is one of the most exciting
developments in Computer Science of the last decade. At the same time,
Reinforcement Learning (RL) has emerged as a very successful paradigm for a
variety of machine learning tasks. In this survey, we discuss the state of the
art, opportunities and open research questions in applying RL to generative AI.
In particular, we will discuss three types of applications, namely, RL as an
alternative way for generation without specified objectives; as a way for
generating outputs while concurrently maximizing an objective function; and,
finally, as a way of embedding desired characteristics, which cannot be easily
captured by means of an objective function, into the generative process. We
conclude the survey with an in-depth discussion of the opportunities and
challenges in this fascinating emerging area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franceschelli_G/0/1/0/all/0/1&quot;&gt;Giorgio Franceschelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musolesi_M/0/1/0/all/0/1&quot;&gt;Mirco Musolesi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03977">
<title>PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning. (arXiv:2308.03977v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03977</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthetic image datasets offer unmatched advantages for designing and
evaluating deep neural networks: they make it possible to (i) render as many
data samples as needed, (ii) precisely control each scene and yield granular
ground truth labels (and captions), (iii) precisely control distribution shifts
between training and testing to isolate variables of interest for sound
experimentation. Despite such promise, the use of synthetic image data is still
limited -- and often played down -- mainly due to their lack of realism. Most
works therefore rely on datasets of real images, which have often been scraped
from public images on the internet, and may have issues with regards to
privacy, bias, and copyright, while offering little control over how objects
precisely appear. In this work, we present a path to democratize the use of
photorealistic synthetic data: we develop a new generation of interactive
environments for representation learning research, that offer both
controllability and realism. We use the Unreal Engine, a powerful game engine
well known in the entertainment industry, to produce PUG (Photorealistic Unreal
Graphics) environments and datasets for representation learning. In this paper,
we demonstrate the potential of PUG to enable more rigorous evaluations of
vision models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bordes_F/0/1/0/all/0/1&quot;&gt;Florian Bordes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shekhar_S/0/1/0/all/0/1&quot;&gt;Shashank Shekhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1&quot;&gt;Mark Ibrahim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouchacourt_D/0/1/0/all/0/1&quot;&gt;Diane Bouchacourt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1&quot;&gt;Pascal Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1&quot;&gt;Ari S. Morcos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.07707">
<title>Fast Machine Unlearning Without Retraining Through Selective Synaptic Dampening. (arXiv:2308.07707v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.07707</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine unlearning, the ability for a machine learning model to forget, is
becoming increasingly important to comply with data privacy regulations, as
well as to remove harmful, manipulated, or outdated information. The key
challenge lies in forgetting specific information while protecting model
performance on the remaining data. While current state-of-the-art methods
perform well, they typically require some level of retraining over the retained
data, in order to protect or restore model performance. This adds computational
overhead and mandates that the training data remain available and accessible,
which may not be feasible. In contrast, other methods employ a retrain-free
paradigm, however, these approaches are prohibitively computationally expensive
and do not perform on par with their retrain-based counterparts. We present
Selective Synaptic Dampening (SSD), a novel two-step, post hoc, retrain-free
approach to machine unlearning which is fast, performant, and does not require
long-term storage of the training data. First, SSD uses the Fisher information
matrix of the training and forgetting data to select parameters that are
disproportionately important to the forget set. Second, SSD induces forgetting
by dampening these parameters proportional to their relative importance to the
forget set with respect to the wider training data. We evaluate our method
against several existing unlearning methods in a range of experiments using
ResNet18 and Vision Transformer. Results show that the performance of SSD is
competitive with retrain-based post hoc methods, demonstrating the viability of
retrain-free post hoc unlearning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_J/0/1/0/all/0/1&quot;&gt;Jack Foster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schoepf_S/0/1/0/all/0/1&quot;&gt;Stefan Schoepf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1&quot;&gt;Alexandra Brintrup&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.08742">
<title>PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.08742</link>
<description rdf:parseType="Literal">&lt;p&gt;Model editing techniques modify a minor proportion of knowledge in Large
Language Models (LLMs) at a relatively low cost, which have demonstrated
notable success. Existing methods assume Transformer Layer (TL) hidden states
are values of key-value memories of the Feed-Forward Network (FFN). They
usually optimize the TL hidden states to memorize target knowledge and use it
to update the weights of the FFN in LLMs. However, the information flow of TL
hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN,
and residual connections. Existing methods neglect the fact that the TL hidden
states contains information not specifically required for FFN. Consequently,
the performance of model editing decreases. To achieve more precise model
editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes
certain general knowledge extraction patterns. This implies that MHSA weights
do not require updating when new knowledge is introduced. Based on above
findings, we introduce PMET, which simultaneously optimizes Transformer
Component (TC, namely MHSA and FFN) hidden states, while only using the
optimized TC hidden states of FFN to precisely update FFN weights. Our
experiments demonstrate that PMET exhibits state-of-the-art performance on both
the COUNTERFACT and zsRE datasets. Our ablation experiments substantiate the
effectiveness of our enhancements, further reinforcing the finding that the
MHSA encodes certain general knowledge extraction patterns and indicating its
storage of a small amount of factual knowledge. Our code is available at
https://github.com/xpq-tech/PMET.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaopeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shasha Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Shezheng Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jing Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jun Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jie Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.09065">
<title>Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression. (arXiv:2308.09065v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.09065</link>
<description rdf:parseType="Literal">&lt;p&gt;Uncertainty quantification is critical for deploying deep neural networks
(DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE)
is one of the most effective means to estimate the uncertainty of the main task
prediction without modifying the main task model. To be considered robust, an
AuxUE must be capable of maintaining its performance and triggering higher
uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to
provide robust aleatoric and epistemic uncertainty. However, for vision
regression tasks, current AuxUE designs are mainly adopted for aleatoric
uncertainty estimates, and AuxUE robustness has not been explored. In this
work, we propose a generalized AuxUE scheme for more robust uncertainty
quantification on regression tasks. Concretely, to achieve a more robust
aleatoric uncertainty estimation, different distribution assumptions are
considered for heteroscedastic noise, and Laplace distribution is finally
chosen to approximate the prediction error. For epistemic uncertainty, we
propose a novel solution named Discretization-Induced Dirichlet pOsterior
(DIDO), which models the Dirichlet posterior on the discretized prediction
error. Extensive experiments on age estimation, monocular depth estimation, and
super-resolution tasks show that our proposed method can provide robust
uncertainty estimates in the face of noisy inputs and that it can be scalable
to both image-level and pixel-wise tasks. Code is available at
https://github.com/ENSTA-U2IS/DIDO .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xuanlong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franchi_G/0/1/0/all/0/1&quot;&gt;Gianni Franchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jindong Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aldea_E/0/1/0/all/0/1&quot;&gt;Emanuel Aldea&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.09888">
<title>On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design. (arXiv:2308.09888v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2308.09888</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian Experimental Design (BED), which aims to find the optimal
experimental conditions for Bayesian inference, is usually posed as to optimize
the expected information gain (EIG). The gradient information is often needed
for efficient EIG optimization, and as a result the ability to estimate the
gradient of EIG is essential for BED problems. The primary goal of this work is
to develop methods for estimating the gradient of EIG, which, combined with the
stochastic gradient descent algorithms, result in efficient optimization of
EIG. Specifically, we first introduce a posterior expected representation of
the EIG gradient with respect to the design variables. Based on this, we
propose two methods for estimating the EIG gradient, UEEG-MCMC that leverages
posterior samples generated through Markov Chain Monte Carlo (MCMC) to estimate
the EIG gradient, and BEEG-AP that focuses on achieving high simulation
efficiency by repeatedly using parameter samples. Theoretical analysis and
numerical studies illustrate that UEEG-MCMC is robust agains the actual EIG
value, while BEEG-AP is more efficient when the EIG value to be optimized is
small. Moreover, both methods show superior performance compared to several
popular benchmarks in our numerical experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ao_Z/0/1/0/all/0/1&quot;&gt;Ziqiao Ao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jinglai Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.01226">
<title>Saturn: An Optimized Data System for Large Model Deep Learning Workloads. (arXiv:2309.01226v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.01226</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models such as GPT-3 &amp;amp; ChatGPT have transformed deep learning
(DL), powering applications that have captured the public&apos;s imagination. These
models are rapidly being adopted across domains for analytics on various
modalities, often by finetuning pre-trained base models. Such models need
multiple GPUs due to both their size and computational load, driving the
development of a bevy of &quot;model parallelism&quot; techniques &amp;amp; tools. Navigating
such parallelism choices, however, is a new burden for end users of DL such as
data scientists, domain scientists, etc. who may lack the necessary systems
knowhow. The need for model selection, which leads to many models to train due
to hyper-parameter tuning or layer-wise finetuning, compounds the situation
with two more burdens: resource apportioning and scheduling. In this work, we
tackle these three burdens for DL users in a unified manner by formalizing them
as a joint problem that we call SPASE: Select a Parallelism, Allocate
resources, and SchedulE. We propose a new information system architecture to
tackle the SPASE problem holistically, representing a key step toward enabling
wider adoption of large DL models. We devise an extensible template for
existing parallelism schemes and combine it with an automated empirical
profiler for runtime estimation. We then formulate SPASE as an MILP.
&lt;/p&gt;
&lt;p&gt;We find that direct use of an MILP-solver is significantly more effective
than several baseline heuristics. We optimize the system runtime further with
an introspective scheduling approach. We implement all these techniques into a
new data system we call Saturn. Experiments with benchmark DL workloads show
that Saturn achieves 39-49% lower model selection runtimes than typical current
DL practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagrecha_K/0/1/0/all/0/1&quot;&gt;Kabir Nagrecha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Arun Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.01922">
<title>Regret Analysis of Policy Gradient Algorithm for Infinite Horizon Average Reward Markov Decision Processes. (arXiv:2309.01922v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.01922</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider an infinite horizon average reward Markov Decision
Process (MDP). Distinguishing itself from existing works within this context,
our approach harnesses the power of the general policy gradient-based
algorithm, liberating it from the constraints of assuming a linear MDP
structure. We propose a policy gradient-based algorithm and show its global
convergence property. We then prove that the proposed algorithm has
$\tilde{\mathcal{O}}({T}^{3/4})$ regret. Remarkably, this paper marks a
pioneering effort by presenting the first exploration into regret-bound
computation for the general parameterized policy gradient algorithm in the
context of average reward scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Q/0/1/0/all/0/1&quot;&gt;Qinbo Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mondal_W/0/1/0/all/0/1&quot;&gt;Washim Uddin Mondal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1&quot;&gt;Vaneet Aggarwal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.02784">
<title>Norm Tweaking: High-performance Low-bit Quantization of Large Language Models. (arXiv:2309.02784v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.02784</link>
<description rdf:parseType="Literal">&lt;p&gt;As the size of large language models (LLMs) continues to grow, model
compression without sacrificing accuracy has become a crucial challenge for
deployment. While some quantization methods, such as GPTQ, have made progress
in achieving acceptable 4-bit weight-only quantization, attempts at lower-bit
quantization often result in severe performance degradation. In this paper, we
introduce a technique called norm tweaking, which can be used as a plugin in
current PTQ methods to achieve high precision while being cost-efficient. Our
approach is inspired by the observation that rectifying the quantized
activation distribution to match its float counterpart can readily restore
accuracy for LLMs. To achieve this, we carefully design a tweaking strategy
that includes calibration data generation and channel-wise distance constraint
to update the weights of normalization layers for better generalization. We
conduct extensive experiments on various datasets using several open-sourced
LLMs. Our method demonstrates significant improvements in both weight-only
quantization and joint quantization of weights and activations, surpassing
existing PTQ methods. On GLM-130B and OPT-66B, our method even achieves the
same level of accuracy at 2-bit quantization as their float ones. Our simple
and effective approach makes it more practical for real-world applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Liang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qingyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1&quot;&gt;Xiangxiang Chu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03999">
<title>Adapting Self-Supervised Representations to Multi-Domain Setups. (arXiv:2309.03999v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.03999</link>
<description rdf:parseType="Literal">&lt;p&gt;Current state-of-the-art self-supervised approaches, are effective when
trained on individual domains but show limited generalization on unseen
domains. We observe that these models poorly generalize even when trained on a
mixture of domains, making them unsuitable to be deployed under diverse
real-world setups. We therefore propose a general-purpose, lightweight Domain
Disentanglement Module (DDM) that can be plugged into any self-supervised
encoder to effectively perform representation learning on multiple, diverse
domains with or without shared classes. During pre-training according to a
self-supervised loss, DDM enforces a disentanglement in the representation
space by splitting it into a domain-variant and a domain-invariant portion.
When domain labels are not available, DDM uses a robust clustering approach to
discover pseudo-domains. We show that pre-training with DDM can show up to 3.5%
improvement in linear probing accuracy on state-of-the-art self-supervised
models including SimCLR, MoCo, BYOL, DINO, SimSiam and Barlow Twins on
multi-domain benchmarks including PACS, DomainNet and WILDS. Models trained
with DDM show significantly improved generalization (7.4%) to unseen domains
compared to baselines. Therefore, DDM can efficiently adapt self-supervised
encoders to provide high-quality, generalizable representations for diverse
multi-domain data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalibhat_N/0/1/0/all/0/1&quot;&gt;Neha Kalibhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharpe_S/0/1/0/all/0/1&quot;&gt;Sam Sharpe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodsitt_J/0/1/0/all/0/1&quot;&gt;Jeremy Goodsitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruss_B/0/1/0/all/0/1&quot;&gt;Bayan Bruss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1&quot;&gt;Soheil Feizi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.04856">
<title>AmbientFlow: Invertible generative models from incomplete, noisy measurements. (arXiv:2309.04856v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.04856</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative models have gained popularity for their potential applications in
imaging science, such as image reconstruction, posterior sampling and data
sharing. Flow-based generative models are particularly attractive due to their
ability to tractably provide exact density estimates along with fast,
inexpensive and diverse samples. Training such models, however, requires a
large, high quality dataset of objects. In applications such as computed
imaging, it is often difficult to acquire such data due to requirements such as
long acquisition time or high radiation dose, while acquiring noisy or
partially observed measurements of these objects is more feasible. In this
work, we propose AmbientFlow, a framework for learning flow-based generative
models directly from noisy and incomplete data. Using variational Bayesian
methods, a novel framework for establishing flow-based generative models from
noisy, incomplete data is proposed. Extensive numerical studies demonstrate the
effectiveness of AmbientFlow in learning the object distribution. The utility
of AmbientFlow in a downstream inference task of image reconstruction is
demonstrated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kelkar_V/0/1/0/all/0/1&quot;&gt;Varun A. Kelkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_R/0/1/0/all/0/1&quot;&gt;Rucha Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1&quot;&gt;Arindam Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anastasio_M/0/1/0/all/0/1&quot;&gt;Mark A. Anastasio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.06260">
<title>Toward Discretization-Consistent Closure Schemes for Large Eddy Simulation Using Reinforcement Learning. (arXiv:2309.06260v2 [physics.flu-dyn] UPDATED)</title>
<link>http://arxiv.org/abs/2309.06260</link>
<description rdf:parseType="Literal">&lt;p&gt;This study proposes a novel method for developing discretization-consistent
closure schemes for implicitly filtered Large Eddy Simulation (LES). Here, the
induced filter kernel, and thus the closure terms, are determined by the
properties of the grid and the discretization operator, leading to additional
computational subgrid terms that are generally unknown in a priori analysis. In
this work, the task of adapting the coefficients of LES closure models is thus
framed as a Markov decision process and solved in an a posteriori manner with
Reinforcement Learning (RL). This optimization framework is applied to both
explicit and implicit closure models. The explicit model is based on an
element-local eddy viscosity model. The optimized model is found to adapt its
induced viscosity within discontinuous Galerkin (DG) methods to homogenize the
dissipation within an element by adding more viscosity near its center. For the
implicit modeling, RL is applied to identify an optimal blending strategy for a
hybrid DG and Finite Volume (FV) scheme. The resulting optimized discretization
yields more accurate results in LES than either the pure DG or FV method and
renders itself as a viable modeling ansatz that could initiate a novel class of
high-order schemes for compressible turbulence by combining turbulence modeling
with shock capturing in a single framework. All newly derived models achieve
accurate results that either match or outperform traditional models for
different discretizations and resolutions. Overall, the results demonstrate
that the proposed RL optimization can provide discretization-consistent
closures that could reduce the uncertainty in implicitly filtered LES.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Beck_A/0/1/0/all/0/1&quot;&gt;Andrea Beck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kurz_M/0/1/0/all/0/1&quot;&gt;Marius Kurz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.09866">
<title>Domain Generalization with Fourier Transform and Soft Thresholding. (arXiv:2309.09866v3 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.09866</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain generalization aims to train models on multiple source domains so that
they can generalize well to unseen target domains. Among many domain
generalization methods, Fourier-transform-based domain generalization methods
have gained popularity primarily because they exploit the power of Fourier
transformation to capture essential patterns and regularities in the data,
making the model more robust to domain shifts. The mainstream
Fourier-transform-based domain generalization swaps the Fourier amplitude
spectrum while preserving the phase spectrum between the source and the target
images. However, it neglects background interference in the amplitude spectrum.
To overcome this limitation, we introduce a soft-thresholding function in the
Fourier domain. We apply this newly designed algorithm to retinal fundus image
segmentation, which is important for diagnosing ocular diseases but the neural
network&apos;s performance can degrade across different sources due to domain
shifts. The proposed technique basically enhances fundus image augmentation by
eliminating small values in the Fourier domain and providing better
generalization. The innovative nature of the soft thresholding fused with
Fourier-transform-based domain generalization improves neural network models&apos;
performance by reducing the target images&apos; background interference
significantly. Experiments on public data validate our approach&apos;s effectiveness
over conventional and state-of-the-art methods with superior segmentation
metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pan_H/0/1/0/all/0/1&quot;&gt;Hongyi Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zheyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jha_D/0/1/0/all/0/1&quot;&gt;Debesh Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cetin_A/0/1/0/all/0/1&quot;&gt;Ahmet Enis Cetin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Spampinato_C/0/1/0/all/0/1&quot;&gt;Concetto Spampinato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bagci_U/0/1/0/all/0/1&quot;&gt;Ulas Bagci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.10441">
<title>Coreset selection can accelerate quantum machine learning models with provable generalization. (arXiv:2309.10441v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2309.10441</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum neural networks (QNNs) and quantum kernels stand as prominent figures
in the realm of quantum machine learning, poised to leverage the nascent
capabilities of near-term quantum computers to surmount classical machine
learning challenges. Nonetheless, the training efficiency challenge poses a
limitation on both QNNs and quantum kernels, curbing their efficacy when
applied to extensive datasets. To confront this concern, we present a unified
approach: coreset selection, aimed at expediting the training of QNNs and
quantum kernels by distilling a judicious subset from the original training
dataset. Furthermore, we analyze the generalization error bounds of QNNs and
quantum kernels when trained on such coresets, unveiling the comparable
performance with those training on the complete original dataset. Through
systematic numerical simulations, we illuminate the potential of coreset
selection in expediting tasks encompassing synthetic data classification,
identification of quantum correlations, and quantum compiling. Our work offers
a useful way to improve diverse quantum machine learning models with a
theoretical guarantee while reducing the training cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yiming Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Huiyuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yuxuan Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xiao Yuan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.14585">
<title>DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature Space. (arXiv:2309.14585v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.14585</link>
<description rdf:parseType="Literal">&lt;p&gt;This work investigates efficient score-based black-box adversarial attacks
with a high Attack Success Rate (ASR) and good generalizability. We design a
novel attack method based on a Disentangled Feature space, called DifAttack,
which differs significantly from the existing ones operating over the entire
feature space. Specifically, DifAttack firstly disentangles an image&apos;s latent
feature into an adversarial feature and a visual feature, where the former
dominates the adversarial capability of an image, while the latter largely
determines its visual appearance. We train an autoencoder for the
disentanglement by using pairs of clean images and their Adversarial Examples
(AEs) generated from available surrogate models via white-box attack methods.
Eventually, DifAttack iteratively optimizes the adversarial feature according
to the query feedback from the victim model until a successful AE is generated,
while keeping the visual feature unaltered. In addition, due to the avoidance
of using surrogate models&apos; gradient information when optimizing AEs for
black-box models, our proposed DifAttack inherently possesses better attack
capability in the open-set scenario, where the training dataset of the victim
model is unknown. Extensive experimental results demonstrate that our method
achieves significant improvements in ASR and query efficiency simultaneously,
especially in the targeted attack and open-set scenarios. The code is available
at https://github.com/csjunjun/DifAttack.git.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jun_L/0/1/0/all/0/1&quot;&gt;Liu Jun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiantao_Z/0/1/0/all/0/1&quot;&gt;Zhou Jiantao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiandian_Z/0/1/0/all/0/1&quot;&gt;Zeng Jiandian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1&quot;&gt;Jinyu Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.00429">
<title>On the Stability of Iterative Retraining of Generative Models on their own Data. (arXiv:2310.00429v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.00429</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative models have made tremendous progress in modeling complex
data, often exhibiting generation quality that surpasses a typical human&apos;s
ability to discern the authenticity of samples. Undeniably, a key driver of
this success is enabled by the massive amounts of web-scale data consumed by
these models. Due to these models&apos; striking performance and ease of
availability, the web will inevitably be increasingly populated with synthetic
content. Such a fact directly implies that future iterations of generative
models must contend with the reality that their training is curated from both
clean data and artificially generated data from past models. In this paper, we
develop a framework to rigorously study the impact of training generative
models on mixed datasets (of real and synthetic data) on their stability. We
first prove the stability of iterative training under the condition that the
initial generative models approximate the data distribution well enough and the
proportion of clean training data (w.r.t. synthetic data) is large enough. We
empirically validate our theory on both synthetic and natural images by
iteratively training normalizing flows and state-of-the-art diffusion models on
CIFAR10 and FFHQ.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertrand_Q/0/1/0/all/0/1&quot;&gt;Quentin Bertrand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1&quot;&gt;Avishek Joey Bose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duplessis_A/0/1/0/all/0/1&quot;&gt;Alexandre Duplessis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiralerspong_M/0/1/0/all/0/1&quot;&gt;Marco Jiralerspong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1&quot;&gt;Gauthier Gidel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.01217">
<title>ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale. (arXiv:2310.01217v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.01217</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-task learning (MTL) has shown considerable practical benefits,
particularly when using pre-trained language models (PLMs). While this is
commonly achieved by simultaneously learning $n$ tasks under a joint
optimization procedure, recent methods such as AdapterFusion structure the
problem into two distinct stages: (i) task learning, where knowledge specific
to a task is encapsulated within sets of parameters (e.g., adapters), and (ii)
transfer, where this already learned knowledge is leveraged for a target task.
This separation of concerns provides numerous benefits, such as promoting
reusability, and addressing cases involving data privacy and societal concerns;
on the flip side, current two-stage MTL methods come with the cost of
introducing a substantial number of additional parameters. In this work, we
address this issue by leveraging the usefulness of linearly scaling the output
representations of source adapters for transfer learning. We introduce
ScaLearn, a simple and highly parameter-efficient two-stage MTL method that
capitalizes on the knowledge of the source tasks by learning a minimal set of
scaling parameters that enable effective knowledge transfer to a target task.
Our experiments on three benchmarks (GLUE, SuperGLUE, and HumSet) show that our
ScaLearn, in addition to facilitating the benefits of two-stage MTL,
consistently outperforms strong baselines with only a small number of transfer
parameters - roughly 0.35% of those of AdapterFusion. Remarkably, we observe
that ScaLearn maintains its strong abilities even when further reducing
parameters through uniform scaling and layer-sharing, achieving similarly
competitive results with only $8$ transfer parameters for each target task. Our
proposed approach thus demonstrates the power of simple scaling as a promise
for more efficient task transfer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frohmann_M/0/1/0/all/0/1&quot;&gt;Markus Frohmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holtermann_C/0/1/0/all/0/1&quot;&gt;Carolin Holtermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masoudian_S/0/1/0/all/0/1&quot;&gt;Shahed Masoudian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1&quot;&gt;Anne Lauscher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rekabsaz_N/0/1/0/all/0/1&quot;&gt;Navid Rekabsaz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.02948">
<title>HappyFeat -- An interactive and efficient BCI framework for clinical applications. (arXiv:2310.02948v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/2310.02948</link>
<description rdf:parseType="Literal">&lt;p&gt;Brain-Computer Interface (BCI) systems allow users to perform actions by
translating their brain activity into commands. Such systems usually need a
training phase, consisting in training a classification algorithm to
discriminate between mental states using specific features from the recorded
signals. This phase of feature selection and training is crucial for BCI
performance and presents specific constraints to be met in a clinical context,
such as post-stroke rehabilitation.
&lt;/p&gt;
&lt;p&gt;In this paper, we present HappyFeat, a software making Motor Imagery (MI)
based BCI experiments easier, by gathering all necessary manipulations and
analysis in a single convenient GUI and via automation of experiment or
analysis parameters. The resulting workflow allows for effortlessly selecting
the best features, helping to achieve good BCI performance in time-constrained
environments. Alternative features based on Functional Connectivity can be used
and compared or combined with Power Spectral Density, allowing a
network-oriented approach.
&lt;/p&gt;
&lt;p&gt;We then give details of HappyFeat&apos;s main mechanisms, and a review of its
performances in typical use cases. We also show that it can be used as an
efficient tool for comparing different metrics extracted from the signals, to
train the classification algorithm. To this end, we show a comparison between
the commonly-used Power Spectral Density and network metrics based on
Functional Connectivity.
&lt;/p&gt;
&lt;p&gt;HappyFeat is available as an open-source project which can be freely
downloaded on GitHub.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Desbois_A/0/1/0/all/0/1&quot;&gt;Arthur Desbois&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Venot_T/0/1/0/all/0/1&quot;&gt;Tristan Venot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Fallani_F/0/1/0/all/0/1&quot;&gt;Fabrizio De Vico Fallani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Corsi_M/0/1/0/all/0/1&quot;&gt;Marie-Constance Corsi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03149">
<title>Attributing Learned Concepts in Neural Networks to Training Data. (arXiv:2310.03149v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03149</link>
<description rdf:parseType="Literal">&lt;p&gt;By now there is substantial evidence that deep learning models learn certain
human-interpretable features as part of their internal representations of data.
As having the right (or wrong) concepts is critical to trustworthy machine
learning systems, it is natural to ask which inputs from the model&apos;s original
training set were most important for learning a concept at a given layer. To
answer this, we combine data attribution methods with methods for probing the
concepts learned by a model. Training network and probe ensembles for two
concept datasets on a range of network layers, we use the recently developed
TRAK method for large-scale data attribution. We find some evidence for
convergence, where removing the 10,000 top attributing images for a concept and
retraining the model does not change the location of the concept in the network
nor the probing sparsity of the concept. This suggests that rather than being
highly dependent on a few specific examples, the features that inform the
development of a concept are spread in a more diffuse manner across its
exemplars, implying robustness in concept formation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konz_N/0/1/0/all/0/1&quot;&gt;Nicholas Konz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godfrey_C/0/1/0/all/0/1&quot;&gt;Charles Godfrey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapiro_M/0/1/0/all/0/1&quot;&gt;Madelyn Shapiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1&quot;&gt;Jonathan Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1&quot;&gt;Henry Kvinge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Davis Brown&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04353">
<title>A Language-Agent Approach to Formal Theorem-Proving. (arXiv:2310.04353v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.04353</link>
<description rdf:parseType="Literal">&lt;p&gt;Language agents, which use a large language model (LLM) capable of in-context
learning to interact with an external environment, have recently emerged as a
promising approach to control tasks. We present the first language-agent
approach to formal theorem-proving. Our method, COPRA, uses a high-capacity,
black-box LLM (GPT-4) as part of a policy for a stateful backtracking search.
During the search, the policy can select proof tactics and retrieve lemmas and
definitions from an external database. Each selected tactic is executed in the
underlying proof framework, and the execution feedback is used to build the
prompt for the next policy invocation. The search also tracks selected
information from its history and uses it to reduce hallucinations and
unnecessary LLM queries.
&lt;/p&gt;
&lt;p&gt;We evaluate our implementation of COPRA on the miniF2F benchmark for Lean and
a set of Coq tasks from the Compcert project. On these benchmarks, COPRA
significantly outperforms one-shot invocations of GPT-4, as well as
state-of-the-art models fine-tuned on proof data, at finding correct proofs
quickly. Our code and data are available at
https://github.com/trishullab/copra.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakur_A/0/1/0/all/0/1&quot;&gt;Amitayush Thakur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yeming Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1&quot;&gt;Swarat Chaudhuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04796">
<title>Accelerate Multi-Agent Reinforcement Learning in Zero-Sum Games with Subgame Curriculum Learning. (arXiv:2310.04796v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.04796</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning Nash equilibrium (NE) in complex zero-sum games with multi-agent
reinforcement learning (MARL) can be extremely computationally expensive.
Curriculum learning is an effective way to accelerate learning, but an
under-explored dimension for generating a curriculum is the difficulty-to-learn
of the subgames -- games induced by starting from a specific state. In this
work, we present a novel subgame curriculum learning framework for zero-sum
games. It adopts an adaptive initial state distribution by resetting agents to
some previously visited states where they can quickly learn to improve
performance. Building upon this framework, we derive a subgame selection metric
that approximates the squared distance to NE values and further adopt a
particle-based state sampler for subgame generation. Integrating these
techniques leads to our new algorithm, Subgame Automatic Curriculum Learning
(SACL), which is a realization of the subgame curriculum learning framework.
SACL can be combined with any MARL algorithm such as MAPPO. Experiments in the
particle-world environment and Google Research Football environment show SACL
produces much stronger policies than baselines. In the challenging
hide-and-seek quadrant environment, SACL produces all four emergent stages and
uses only half the samples of MAPPO with self-play. The project website is at
https://sites.google.com/view/sacl-rl.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiayu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zelai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yunfei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jiaming Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Huazhong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1&quot;&gt;Fei Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.04925">
<title>Crystal-GFN: sampling crystals with desirable properties and constraints. (arXiv:2310.04925v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.04925</link>
<description rdf:parseType="Literal">&lt;p&gt;Accelerating material discovery holds the potential to greatly help mitigate
the climate crisis. Discovering new solid-state materials such as
electrocatalysts, super-ionic conductors or photovoltaic materials can have a
crucial impact, for instance, in improving the efficiency of renewable energy
production and storage. In this paper, we introduce Crystal-GFN, a generative
model of crystal structures that sequentially samples structural properties of
crystalline materials, namely the space group, composition and lattice
parameters. This domain-inspired approach enables the flexible incorporation of
physical and structural hard constraints, as well as the use of any available
predictive model of a desired physicochemical property as an objective
function. To design stable materials, one must target the candidates with the
lowest formation energy. Here, we use as objective the formation energy per
atom of a crystal structure predicted by a new proxy machine learning model
trained on MatBench. The results demonstrate that Crystal-GFN is able to sample
highly diverse crystals with low (median -3.1 eV/atom) predicted formation
energy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+AI4Science_M/0/1/0/all/0/1&quot;&gt;Mila AI4Science&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Garcia_A/0/1/0/all/0/1&quot;&gt;Alex Hernandez-Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duval_A/0/1/0/all/0/1&quot;&gt;Alexandre Duval&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volokhova_A/0/1/0/all/0/1&quot;&gt;Alexandra Volokhova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1&quot;&gt;Divya Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carrier_P/0/1/0/all/0/1&quot;&gt;Pierre Luc Carrier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benabed_Y/0/1/0/all/0/1&quot;&gt;Yasmine Benabed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koziarski_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Koziarski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_V/0/1/0/all/0/1&quot;&gt;Victor Schmidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.05718">
<title>EdVAE: Mitigating Codebook Collapse with Evidential Discrete Variational Autoencoders. (arXiv:2310.05718v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2310.05718</link>
<description rdf:parseType="Literal">&lt;p&gt;Codebook collapse is a common problem in training deep generative models with
discrete representation spaces like Vector Quantized Variational Autoencoders
(VQ-VAEs). We observe that the same problem arises for the alternatively
designed discrete variational autoencoders (dVAEs) whose encoder directly
learns a distribution over the codebook embeddings to represent the data. We
hypothesize that using the softmax function to obtain a probability
distribution causes the codebook collapse by assigning overconfident
probabilities to the best matching codebook elements. In this paper, we propose
a novel way to incorporate evidential deep learning (EDL) instead of softmax to
combat the codebook collapse problem of dVAE. We evidentially monitor the
significance of attaining the probability distribution over the codebook
embeddings, in contrast to softmax usage. Our experiments using various
datasets show that our model, called EdVAE, mitigates codebook collapse while
improving the reconstruction performance, and enhances the codebook usage
compared to dVAE and VQ-VAE based models. Our code can be found at
https://github.com/ituvisionlab/EdVAE .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baykal_G/0/1/0/all/0/1&quot;&gt;Gulcin Baykal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kandemir_M/0/1/0/all/0/1&quot;&gt;Melih Kandemir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Unal_G/0/1/0/all/0/1&quot;&gt;Gozde Unal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.08320">
<title>Defending Our Privacy With Backdoors. (arXiv:2310.08320v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.08320</link>
<description rdf:parseType="Literal">&lt;p&gt;The proliferation of large AI models trained on uncurated, often sensitive
web-scraped data has raised significant privacy concerns. One of the concerns
is that adversaries can extract information about the training data using
privacy attacks. Unfortunately, the task of removing specific information from
the models without sacrificing performance is not straightforward and has
proven to be challenging. We propose a rather easy yet effective defense based
on backdoor attacks to remove private information such as names of individuals
from models, and focus in this work on text encoders. Specifically, through
strategic insertion of backdoors, we align the embeddings of sensitive phrases
with those of neutral terms-&quot;a person&quot; instead of the person&apos;s name. Our
empirical results demonstrate the effectiveness of our backdoor-based defense
on CLIP by assessing its performance using a specialized privacy attack for
zero-shot classifiers. Our approach provides not only a new &quot;dual-use&quot;
perspective on backdoor attacks, but also presents a promising avenue to
enhance the privacy of individuals within models trained on uncurated
web-scraped data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1&quot;&gt;Dominik Hintersdorf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1&quot;&gt;Lukas Struppek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neider_D/0/1/0/all/0/1&quot;&gt;Daniel Neider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1&quot;&gt;Kristian Kersting&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.10659">
<title>Exploiting Machine Unlearning for Backdoor Attacks in Deep Learning System. (arXiv:2310.10659v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2310.10659</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the security issues of artificial intelligence have become
increasingly prominent due to the rapid development of deep learning research
and applications. Backdoor attack is an attack targeting the vulnerability of
deep learning models, where hidden backdoors are activated by triggers embedded
by the attacker, thereby outputting malicious predictions that may not align
with the intended output for a given input. In this work, we propose a novel
black-box backdoor attack based on machine unlearning. The attacker first
augments the training set with carefully designed samples, including poison and
mitigation data, to train a `benign&apos; model. Then, the attacker posts unlearning
requests for the mitigation samples to remove the impact of relevant data on
the model, gradually activating the hidden backdoor. Since backdoors are
implanted during the iterative unlearning process, it significantly increases
the computational overhead of existing defense methods for backdoor detection
or mitigation. To address this new security threat, we proposes two methods for
detecting or mitigating such malicious unlearning requests. We conduct the
experiment in both exact unlearning and approximate unlearning (i.e., SISA)
settings. Experimental results indicate that: 1) our attack approach can
successfully implant backdoor into the model, and sharding increases the
difficult of attack; 2) our detection algorithms are effective in identifying
the mitigation samples, while sharding reduces the effectiveness of our
detection algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Peixin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jun Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1&quot;&gt;Mingtian Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinyu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.20545">
<title>Optimizing accuracy and diversity: a multi-task approach to forecast combinations. (arXiv:2310.20545v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.20545</link>
<description rdf:parseType="Literal">&lt;p&gt;Forecast combination involves using multiple forecasts to create a single,
more accurate prediction. Recently, feature-based forecasting has been employed
to either select the most appropriate forecasting models or to optimize the
weights of their combination. In this paper, we present a multi-task
optimization paradigm that focuses on solving both problems simultaneously and
enriches current operational research approaches to forecasting. In essence, it
incorporates an additional learning and optimization task into the standard
feature-based forecasting approach, focusing on the identification of an
optimal set of forecasting methods. During the training phase, an optimization
model with linear constraints and quadratic objective function is employed to
identify accurate and diverse methods for each time series. Moreover, within
the training phase, a neural network is used to learn the behavior of that
optimization model. Once training is completed the candidate set of methods is
identified using the network. The proposed approach elicits the essential role
of diversity in feature-based forecasting and highlights the interplay between
model combination and model selection when optimizing forecasting ensembles.
Experimental results on a large set of series from the M4 competition dataset
show that our proposal enhances point forecast accuracy compared to
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Felici_G/0/1/0/all/0/1&quot;&gt;Giovanni Felici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudoso_A/0/1/0/all/0/1&quot;&gt;Antonio M. Sudoso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02546">
<title>On the Second-Order Convergence of Biased Policy Gradient Algorithms. (arXiv:2311.02546v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.02546</link>
<description rdf:parseType="Literal">&lt;p&gt;Since the objective functions of reinforcement learning problems are
typically highly nonconvex, we seek guarantees that these algorithms escape
saddle points and arrive at second-order stationary points. Existing results
only consider vanilla policy gradient algorithms with unbiased gradient
estimators, but practical implementations under the infinite-horizon discounted
reward setting are biased due to finite-horizon sampling. Moreover,
actor-critic methods, whose second-order convergence has not yet been
established, are also biased due to the critic approximation of the value
function. We provide a novel second-order analysis of biased policy gradient
methods, including the vanilla gradient estimator computed from Monte-Carlo
sampling of trajectories as well as the double-loop actor-critic algorithm,
where in the inner loop the the critic parameter improves the approximation of
the value function via TD(0) learning. Separately, we also establish the
convergence of TD(0) on Markov chains irrespective of initial state
distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mu_S/0/1/0/all/0/1&quot;&gt;Siqiao Mu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1&quot;&gt;Diego Klabjan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.03426">
<title>GQKVA: Efficient Pre-training of Transformers by Grouping Queries, Keys, and Values. (arXiv:2311.03426v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.03426</link>
<description rdf:parseType="Literal">&lt;p&gt;Massive transformer-based models face several challenges, including slow and
computationally intensive pre-training and over-parametrization. This paper
addresses these challenges by proposing a versatile method called GQKVA, which
generalizes query, key, and value grouping techniques. GQKVA is designed to
speed up transformer pre-training while reducing the model size. Our
experiments with various GQKVA variants highlight a clear trade-off between
performance and model size, allowing for customized choices based on resource
and time limitations. Our findings also indicate that the conventional
multi-head attention approach is not always the best choice, as there are
lighter and faster alternatives available. We tested our method on ViT, which
achieved an approximate 0.3% increase in accuracy while reducing the model size
by about 4% in the task of image classification. Additionally, our most
aggressive model reduction experiment resulted in a reduction of approximately
15% in model size, with only around a 1% drop in accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javadi_F/0/1/0/all/0/1&quot;&gt;Farnoosh Javadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_W/0/1/0/all/0/1&quot;&gt;Walid Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajimolahoseini_H/0/1/0/all/0/1&quot;&gt;Habib Hajimolahoseini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ataiefard_F/0/1/0/all/0/1&quot;&gt;Foozhan Ataiefard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassanpour_M/0/1/0/all/0/1&quot;&gt;Mohammad Hassanpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asani_S/0/1/0/all/0/1&quot;&gt;Saina Asani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_A/0/1/0/all/0/1&quot;&gt;Austin Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Awad_O/0/1/0/all/0/1&quot;&gt;Omar Mohamed Awad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Kangling Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.15317">
<title>Generalized Graph Prompt: Toward a Unification of Pre-Training and Downstream Tasks on Graphs. (arXiv:2311.15317v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.15317</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks have emerged as a powerful tool for graph
representation learning, but their performance heavily relies on abundant
task-specific supervision. To reduce labeling requirement, the &quot;pre-train,
prompt&quot; paradigms have become increasingly common. However, existing study of
prompting on graphs is limited, lacking a universal treatment to appeal to
different downstream tasks. In this paper, we propose GraphPrompt, a novel
pre-training and prompting framework on graphs. GraphPrompt not only unifies
pre-training and downstream tasks into a common task template but also employs
a learnable prompt to assist a downstream task in locating the most relevant
knowledge from the pre-trained model in a task-specific manner. To further
enhance GraphPrompt in these two stages, we extend it into GraphPrompt+ with
two major enhancements. First, we generalize several popular graph pre-training
tasks beyond simple link prediction to broaden the compatibility with our task
template. Second, we propose a more generalized prompt design that incorporates
a series of prompt vectors within every layer of the pre-trained graph encoder,
in order to capitalize on the hierarchical information across different layers
beyond just the readout layer. Finally, we conduct extensive experiments on
five public datasets to evaluate and analyze GraphPrompt and GraphPrompt+.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xingtong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhenghao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1&quot;&gt;Yuan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zemin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Sihong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinming Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.16080">
<title>XLB: A Differentiable Massively Parallel Lattice Boltzmann Library in Python. (arXiv:2311.16080v2 [physics.comp-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2311.16080</link>
<description rdf:parseType="Literal">&lt;p&gt;The lattice Boltzmann method (LBM) has emerged as a prominent technique for
solving fluid dynamics problems due to its algorithmic potential for
computational scalability. We introduce XLB library, a Python-based
differentiable LBM library based on the JAX platform. The architecture of XLB
is predicated upon ensuring accessibility, extensibility, and computational
performance, enabling scaling effectively across CPU, TPU, multi-GPU, and
distributed multi-GPU or TPU systems. The library can be readily augmented with
novel boundary conditions, collision models, or multi-physics simulation
capabilities. XLB&apos;s differentiability and data structure is compatible with the
extensive JAX-based machine learning ecosystem, enabling it to address
physics-based machine learning, optimization, and inverse problems. XLB has
been successfully scaled to handle simulations with billions of cells,
achieving giga-scale lattice updates per second. XLB is released under the
permissive Apache-2.0 license and is available on GitHub at
https://github.com/Autodesk/XLB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ataei_M/0/1/0/all/0/1&quot;&gt;Mohammadmehdi Ataei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Salehipour_H/0/1/0/all/0/1&quot;&gt;Hesam Salehipour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.16442">
<title>Enabling Fast 2-bit LLM on GPUs: Memory Alignment and Asynchronous Dequantization. (arXiv:2311.16442v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.16442</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have demonstrated impressive abilities in
various domains while the inference cost is expensive. The state-of-the-art
methods use 2-bit quantization for mainstream LLMs. However, challenges still
exist: (1) Nonnegligible accuracy loss for 2-bit quantization. Weights are
quantized by groups, while the ranges of weights are large in some groups,
resulting in large quantization errors and nonnegligible accuracy loss (e.g.
&amp;gt;3% for Llama2-7b with 2-bit quantization in GPTQ and Greenbit). (2) Limited
accuracy improvement by adding 4-bit weights. Increasing 10% extra average bit
more 4-bit weights only leads to &amp;lt;0.5% accuracy improvement on a quantized
Llama2-7b. (3) Time-consuming dequantization operations on GPUs. The
dequantization operations lead to &amp;gt;50% execution time, hindering the potential
of reducing LLM inference cost. To tackle these challenges, we propose the
following techniques: (1) We only quantize a small fraction of groups with the
larger range using 4-bit with memory alignment consideration on GPUs.(2) We
design the asynchronous dequantization on GPUs, leading to up to 3.92X speedup.
We conduct extensive experiments on different model sizes. We achieve 2.85-bit
for each weight and the end-to-end speedup for Llama2-7b is 1.74X over the
original model, and we reduce both runtime cost and hardware cost by up to
2.70X and 2.81X with less GPU requirements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jinhao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shiyao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiaming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lian_Y/0/1/0/all/0/1&quot;&gt;Yaoxiu Lian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_G/0/1/0/all/0/1&quot;&gt;Guohao Dai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.17929">
<title>New Online Communities: Graph Deep Learning on Anonymous Voting Networks to Identify Sybils in Polycentric Governance. (arXiv:2311.17929v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.17929</link>
<description rdf:parseType="Literal">&lt;p&gt;This research examines the polycentric governance of digital assets in
blockchain-based Decentralized Autonomous Organizations (DAOs). It offers a
theoretical framework and addresses a critical challenge facing decentralized
governance by developing a method to identify sybils, or spurious identities.
The method uses graph deep learning techniques to identify sybil activity in a
DAO governance dataset (snapshot.org). Specifically, a Graph Convolutional
Neural Network (GCNN) learned voting behaviours and a fast k-means vector
clustering algorithm (FAISS) used the high dimensional embeddings to identify
similar nodes in a graph. The results reveal that deep learning can effectively
identify sybils, reducing the voting graph by 2-5%. This research underscores
the importance of sybil resistance in DAOs and offers a novel perspective on
decentralized governance, informing future policy, regulation, and governance
practices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DuPont_Q/0/1/0/all/0/1&quot;&gt;Quinn DuPont&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.18188">
<title>Leveraging cache to enable SLU on tiny devices. (arXiv:2311.18188v3 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2311.18188</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses spoken language understanding (SLU) on
microcontroller-like embedded devices, integrating on-device execution with
cloud offloading in a novel fashion. We exploit temporal locality in a device&apos;s
speech inputs and accordingly reuse recent SLU inferences. Our idea is simple:
let the device match new inputs against cached results, and only offload
unmatched inputs to the cloud for full inference. Realization of this idea,
however, is non-trivial: the device needs to compare acoustic features in a
robust, low-cost way. To this end, we present XYZ, a speech cache for tiny
devices. It matches speech inputs at two levels of representations: first by
clustered sequences of raw sound units, then as sequences of phonemes. Working
in tandem, the two representations offer complementary cost/accuracy tradeoffs.
To further boost accuracy, our cache is learning: with the mismatched and then
offloaded inputs, it continuously finetunes the device&apos;s feature extractors
(with the assistance of the cloud). We implement XYZ on an off-the-shelf STM32
microcontroller. The resultant implementation has a small memory footprint of
2MB. Evaluated on challenging speech benchmarks, our system resolves 45%--90%
of inputs on device, reducing the average latency by up to 80% compared to
offloading to popular cloud speech services. Our benefit is pronounced even in
adversarial settings -- noisy environments, cold cache, or one device shared by
a number of users.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Benazir_A/0/1/0/all/0/1&quot;&gt;Afsara Benazir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhiming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lin_F/0/1/0/all/0/1&quot;&gt;Felix Xiaozhu Lin&lt;/a&gt; (University of Virginia)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.00102">
<title>FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network And Feature Embedding Aggregation. (arXiv:2312.00102v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.00102</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is an emerging paradigm for decentralized training of
machine learning models on distributed clients, without revealing the data to
the central server. The learning scheme may be horizontal, vertical or hybrid
(both vertical and horizontal). Most existing research work with deep neural
network (DNN) modelling is focused on horizontal data distributions, while
vertical and hybrid schemes are much less studied. In this paper, we propose a
generalized algorithm FedEmb, for modelling vertical and hybrid DNN-based
learning. The idea of our algorithm is characterised by higher inference
accuracy, stronger privacy-preserving properties, and lower client-server
communication bandwidth demands as compared with existing work. The
experimental results show that FedEmb is an effective method to tackle both
split feature &amp;amp; subject space decentralized problems, shows 0.3% to 4.2%
inference accuracy improvement with limited privacy revealing for datasets
stored in local clients, and reduces 88.9 % time complexity over vertical
baseline method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1&quot;&gt;Fanfei Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lele Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuxin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.00812">
<title>Empowering Autonomous Driving with Large Language Models: A Safety Perspective. (arXiv:2312.00812v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2312.00812</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous Driving (AD) faces crucial hurdles for commercial launch, notably
in the form of diminished public trust and safety concerns from long-tail
unforeseen driving scenarios. This predicament is due to the limitation of deep
neural networks in AD software, which struggle with interpretability and
exhibit poor generalization capabilities in out-of-distribution and uncertain
scenarios. To this end, this paper advocates for the integration of Large
Language Models (LLMs) into the AD system, leveraging their robust common-sense
knowledge, reasoning abilities, and human-interaction capabilities. The
proposed approach deploys the LLM as an intelligent decision-maker in planning,
incorporating safety verifiers for contextual safety learning to enhance
overall AD performance and safety. We present results from two case studies
that affirm the efficacy of our approach. We further discuss the potential
integration of LLM for other AD software components including perception,
prediction, and simulation. Despite the observed challenges in the case
studies, the integration of LLMs is promising and beneficial for reinforcing
both safety and performance in AD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yixuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_R/0/1/0/all/0/1&quot;&gt;Ruochen Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lang_C/0/1/0/all/0/1&quot;&gt;Chengtian Lang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_S/0/1/0/all/0/1&quot;&gt;Sinong Simon Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaoran Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1&quot;&gt;Qi Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.01479">
<title>OpenVoice: Versatile Instant Voice Cloning. (arXiv:2312.01479v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2312.01479</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce OpenVoice, a versatile voice cloning approach that requires only
a short audio clip from the reference speaker to replicate their voice and
generate speech in multiple languages. OpenVoice represents a significant
advancement in addressing the following open challenges in the field: 1)
Flexible Voice Style Control. OpenVoice enables granular control over voice
styles, including emotion, accent, rhythm, pauses, and intonation, in addition
to replicating the tone color of the reference speaker. The voice styles are
not directly copied from and constrained by the style of the reference speaker.
Previous approaches lacked the ability to flexibly manipulate voice styles
after cloning. 2) Zero-Shot Cross-Lingual Voice Cloning. OpenVoice achieves
zero-shot cross-lingual voice cloning for languages not included in the
massive-speaker training set. Unlike previous approaches, which typically
require extensive massive-speaker multi-lingual (MSML) dataset for all
languages, OpenVoice can clone voices into a new language without any
massive-speaker training data for that language. OpenVoice is also
computationally efficient, costing tens of times less than commercially
available APIs that offer even inferior performance. To foster further research
in the field, we have made the source code and trained model publicly
accessible. We also provide qualitative results in our demo website. Prior to
its public release, our internal version of OpenVoice was used tens of millions
of times by users worldwide between May and October 2023, serving as the
backend of MyShell.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1&quot;&gt;Zengyi Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wenliang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xumin Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xin Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.02462">
<title>Dimensionality Reduction and Dynamical Mode Recognition of Circular Arrays of Flame Oscillators Using Deep Neural Network. (arXiv:2312.02462v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.02462</link>
<description rdf:parseType="Literal">&lt;p&gt;Oscillatory combustion in aero engines and modern gas turbines often has
significant adverse effects on their operation, and accurately recognizing
various oscillation modes is the prerequisite for understanding and controlling
combustion instability. However, the high-dimensional spatial-temporal data of
a complex combustion system typically poses considerable challenges to the
dynamical mode recognition. Based on a two-layer bidirectional long short-term
memory variational autoencoder (Bi-LSTM-VAE) dimensionality reduction model and
a two-dimensional Wasserstein distance-based classifier (WDC), this study
proposes a promising method (Bi-LSTM-VAE-WDC) for recognizing dynamical modes
in oscillatory combustion systems. Specifically, the Bi-LSTM-VAE dimension
reduction model was introduced to reduce the high-dimensional spatial-temporal
data of the combustion system to a low-dimensional phase space; Gaussian kernel
density estimates (GKDE) were computed based on the distribution of phase
points in a grid; two-dimensional WD values were calculated from the GKDE maps
to recognize the oscillation modes. The time-series data used in this study
were obtained from numerical simulations of circular arrays of laminar flame
oscillators. The results show that the novel Bi-LSTM-VAE method can produce a
non-overlapping distribution of phase points, indicating an effective
unsupervised mode recognition and classification. Furthermore, the present
method exhibits a more prominent performance than VAE and PCA (principal
component analysis) for distinguishing dynamical modes in complex flame
systems, implying its potential in studying turbulent combustion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Weiming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1&quot;&gt;Tao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Peng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.03038">
<title>Sample-based Dynamic Hierarchical Transformer with Layer and Head Flexibility via Contextual Bandit. (arXiv:2312.03038v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.03038</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer requires a fixed number of layers and heads which makes them
inflexible to the complexity of individual samples and expensive in training
and inference. To address this, we propose a sample-based Dynamic Hierarchical
Transformer (DHT) model whose layers and heads can be dynamically configured
with single data samples via solving contextual bandit problems. To determine
the number of layers and heads, we use the Uniform Confidence Bound while we
deploy combinatorial Thompson Sampling in order to select specific head
combinations given their number. Different from previous work that focuses on
compressing trained networks for inference only, DHT is not only advantageous
for adaptively optimizing the underlying network architecture during training
but also has a flexible network for efficient inference. To the best of our
knowledge, this is the first comprehensive data-driven dynamic transformer
without any additional auxiliary neural networks that implement the dynamic
system. According to the experiment results, we achieve up to 74% computational
savings for both training and inference with a minimal loss of accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1&quot;&gt;Fanfei Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lele Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuxin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.03940">
<title>PECANN: Parallel Efficient Clustering with Graph-Based Approximate Nearest Neighbor Search. (arXiv:2312.03940v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2312.03940</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies density-based clustering of point sets. These methods use
dense regions of points to detect clusters of arbitrary shapes. In particular,
we study variants of density peaks clustering, a popular type of algorithm that
has been shown to work well in practice. Our goal is to cluster large
high-dimensional datasets, which are prevalent in practice. Prior solutions are
either sequential, and cannot scale to large data, or are specialized for
low-dimensional data.
&lt;/p&gt;
&lt;p&gt;This paper unifies the different variants of density peaks clustering into a
single framework, PECANN, by abstracting out several key steps common to this
class of algorithms. One such key step is to find nearest neighbors that
satisfy a predicate function, and one of the main contributions of this paper
is an efficient way to do this predicate search using graph-based approximate
nearest neighbor search (ANNS). To provide ample parallelism, we propose a
doubling search technique that enables points to find an approximate nearest
neighbor satisfying the predicate in a small number of rounds. Our technique
can be applied to many existing graph-based ANNS algorithms, which can all be
plugged into PECANN.
&lt;/p&gt;
&lt;p&gt;We implement five clustering algorithms with PECANN and evaluate them on
synthetic and real-world datasets with up to 1.28 million points and up to 1024
dimensions on a 30-core machine with two-way hyper-threading. Compared to the
state-of-the-art FASTDP algorithm for high-dimensional density peaks
clustering, which is sequential, our best algorithm is 45x-734x faster while
achieving competitive ARI scores. Compared to the state-of-the-art parallel
DPC-based algorithm, which is optimized for low dimensions, we show that PECANN
is two orders of magnitude faster. As far as we know, our work is the first to
evaluate DPC variants on large high-dimensional real-world image and text
embedding datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Shangdi Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engels_J/0/1/0/all/0/1&quot;&gt;Joshua Engels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yihao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shun_J/0/1/0/all/0/1&quot;&gt;Julian Shun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.06036">
<title>AI Competitions and Benchmarks: towards impactful challenges with post-challenge papers, benchmarks and other dissemination actions. (arXiv:2312.06036v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.06036</link>
<description rdf:parseType="Literal">&lt;p&gt;Organising an AI challenge does not end with the final event. The
long-lasting impact also needs to be organised. This chapter covers the various
activities after the challenge is formally finished. The target audience of
different post-challenge activities is identified. The various outputs of the
challenge are listed with the means to collect them. The main part of the
chapter is a template for a typical post-challenge paper, including possible
graphs as well as advice on how to turn the challenge into a long-lasting
benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marot_A/0/1/0/all/0/1&quot;&gt;Antoine Marot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rousseau_D/0/1/0/all/0/1&quot;&gt;David Rousseau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhen Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.06585">
<title>Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models. (arXiv:2312.06585v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.06585</link>
<description rdf:parseType="Literal">&lt;p&gt;Fine-tuning language models~(LMs) on human-generated data remains a prevalent
practice. However, the performance of such models is often limited by the
quantity and diversity of high-quality human data. In this paper, we explore
whether we can go beyond human data on tasks where we have access to scalar
feedback, for example, on math problems where one can verify correctness. To do
so, we investigate a simple self-training method based on
expectation-maximization, which we call ReST$^{EM}$, where we (1) generate
samples from the model and filter them using binary feedback, (2) fine-tune the
model on these samples, and (3) repeat this process a few times. Testing on
advanced MATH reasoning and APPS coding benchmarks using PaLM-2 models, we find
that ReST$^{EM}$ scales favorably with model size and significantly surpasses
fine-tuning only on human data. Overall, our findings suggest self-training
with feedback can substantially reduce dependence on human-generated data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Avi Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Co_Reyes_J/0/1/0/all/0/1&quot;&gt;John D. Co-Reyes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_R/0/1/0/all/0/1&quot;&gt;Rishabh Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1&quot;&gt;Ankesh Anand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patil_P/0/1/0/all/0/1&quot;&gt;Piyush Patil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1&quot;&gt;Peter J. Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harrison_J/0/1/0/all/0/1&quot;&gt;James Harrison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jaehoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kelvin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parisi_A/0/1/0/all/0/1&quot;&gt;Aaron Parisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Abhishek Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alemi_A/0/1/0/all/0/1&quot;&gt;Alex Alemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizkowsky_A/0/1/0/all/0/1&quot;&gt;Alex Rizkowsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nova_A/0/1/0/all/0/1&quot;&gt;Azade Nova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adlam_B/0/1/0/all/0/1&quot;&gt;Ben Adlam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bohnet_B/0/1/0/all/0/1&quot;&gt;Bernd Bohnet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elsayed_G/0/1/0/all/0/1&quot;&gt;Gamaleldin Elsayed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sedghi_H/0/1/0/all/0/1&quot;&gt;Hanie Sedghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1&quot;&gt;Igor Mordatch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simpson_I/0/1/0/all/0/1&quot;&gt;Isabelle Simpson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gur_I/0/1/0/all/0/1&quot;&gt;Izzeddin Gur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Snoek_J/0/1/0/all/0/1&quot;&gt;Jasper Snoek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hron_J/0/1/0/all/0/1&quot;&gt;Jiri Hron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kenealy_K/0/1/0/all/0/1&quot;&gt;Kathleen Kenealy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1&quot;&gt;Kevin Swersky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahajan_K/0/1/0/all/0/1&quot;&gt;Kshiteej Mahajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Culp_L/0/1/0/all/0/1&quot;&gt;Laura Culp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1&quot;&gt;Lechao Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bileschi_M/0/1/0/all/0/1&quot;&gt;Maxwell L. Bileschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Constant_N/0/1/0/all/0/1&quot;&gt;Noah Constant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Novak_R/0/1/0/all/0/1&quot;&gt;Roman Novak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Rosanne Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Warkentin_T/0/1/0/all/0/1&quot;&gt;Tris Warkentin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1&quot;&gt;Yundi Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dyer_E/0/1/0/all/0/1&quot;&gt;Ethan Dyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neyshabur_B/0/1/0/all/0/1&quot;&gt;Behnam Neyshabur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiedel_N/0/1/0/all/0/1&quot;&gt;Noah Fiedel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07186">
<title>Towards Optimal Sobolev Norm Rates for the Vector-Valued Regularized Least-Squares Algorithm. (arXiv:2312.07186v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2312.07186</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the first optimal rates for infinite-dimensional vector-valued
ridge regression on a continuous scale of norms that interpolate between $L_2$
and the hypothesis space, which we consider as a vector-valued reproducing
kernel Hilbert space. These rates allow to treat the misspecified case in which
the true regression function is not contained in the hypothesis space. We
combine standard assumptions on the capacity of the hypothesis space with a
novel tensor product construction of vector-valued interpolation spaces in
order to characterize the smoothness of the regression function. Our upper
bound not only attains the same rate as real-valued kernel ridge regression,
but also removes the assumption that the target regression function is bounded.
For the lower bound, we reduce the problem to the scalar setting using a
projection argument. We show that these rates are optimal in most cases and
independent of the dimension of the output space. We illustrate our results for
the special case of vector-valued Sobolev spaces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meunier_D/0/1/0/all/0/1&quot;&gt;Dimitri Meunier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mollenhauer_M/0/1/0/all/0/1&quot;&gt;Mattes Mollenhauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1&quot;&gt;Arthur Gretton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07285">
<title>Forced Exploration in Bandit Problems. (arXiv:2312.07285v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.07285</link>
<description rdf:parseType="Literal">&lt;p&gt;The multi-armed bandit(MAB) is a classical sequential decision problem. Most
work requires assumptions about the reward distribution (e.g., bounded), while
practitioners may have difficulty obtaining information about these
distributions to design models for their problems, especially in non-stationary
MAB problems. This paper aims to design a multi-armed bandit algorithm that can
be implemented without using information about the reward distribution while
still achieving substantial regret upper bounds. To this end, we propose a
novel algorithm alternating between greedy rule and forced exploration. Our
method can be applied to Gaussian, Bernoulli and other subgaussian
distributions, and its implementation does not require additional information.
We employ a unified analysis method for different forced exploration strategies
and provide problem-dependent regret upper bounds for stationary and
piecewise-stationary settings. Furthermore, we compare our algorithm with
popular bandit algorithms on different reward distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1&quot;&gt;Han Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1&quot;&gt;Fei Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1&quot;&gt;Li Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07424">
<title>How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary Investigation. (arXiv:2312.07424v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.07424</link>
<description rdf:parseType="Literal">&lt;p&gt;In machine learning, generalization against distribution shifts -- where
deployment conditions diverge from the training scenarios -- is crucial,
particularly in fields like climate modeling, biomedicine, and autonomous
driving. The emergence of foundation models, distinguished by their extensive
pretraining and task versatility, has led to an increased interest in their
adaptability to distribution shifts. GPT-4V(ision) acts as the most advanced
publicly accessible multimodal foundation model, with extensive applications
across various domains, including anomaly detection, video understanding, image
generation, and medical diagnosis. However, its robustness against data
distributions remains largely underexplored. Addressing this gap, this study
rigorously evaluates GPT-4V&apos;s adaptability and generalization capabilities in
dynamic environments, benchmarking against prominent models like CLIP and
LLaVA. We delve into GPT-4V&apos;s zero-shot generalization across 13 diverse
datasets spanning natural, medical, and molecular domains. We further
investigate its adaptability to controlled data perturbations and examine the
efficacy of in-context learning as a tool to enhance its adaptation. Our
findings delineate GPT-4V&apos;s capability boundaries in distribution shifts,
shedding light on its strengths and limitations across various scenarios.
Importantly, this investigation contributes to our understanding of how AI
foundation models generalize to distribution shifts, offering pivotal insights
into their adaptability and robustness. Code is publicly available at
https://github.com/jameszhou-gl/gpt-4v-distribution-shift.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1&quot;&gt;Zhongyi Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1&quot;&gt;Guanglin Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1&quot;&gt;Rundong He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tailin Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1&quot;&gt;Yilong Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Salman Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1&quot;&gt;Lina Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tongliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07439">
<title>BIRB: A Generalization Benchmark for Information Retrieval in Bioacoustics. (arXiv:2312.07439v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.07439</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability for a machine learning model to cope with differences in training
and deployment conditions--e.g. in the presence of distribution shift or the
generalization to new classes altogether--is crucial for real-world use cases.
However, most empirical work in this area has focused on the image domain with
artificial benchmarks constructed to measure individual aspects of
generalization. We present BIRB, a complex benchmark centered on the retrieval
of bird vocalizations from passively-recorded datasets given focal recordings
from a large citizen science corpus available for training. We propose a
baseline system for this collection of tasks using representation learning and
a nearest-centroid search. Our thorough empirical evaluation and analysis
surfaces open research directions, suggesting that BIRB fills the need for a
more realistic and complex benchmark to drive progress on robustness to
distribution shifts and generalization of ML models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamer_J/0/1/0/all/0/1&quot;&gt;Jenny Hamer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Triantafillou_E/0/1/0/all/0/1&quot;&gt;Eleni Triantafillou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merrienboer_B/0/1/0/all/0/1&quot;&gt;Bart van Merri&amp;#xeb;nboer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahl_S/0/1/0/all/0/1&quot;&gt;Stefan Kahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klinck_H/0/1/0/all/0/1&quot;&gt;Holger Klinck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denton_T/0/1/0/all/0/1&quot;&gt;Tom Denton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumoulin_V/0/1/0/all/0/1&quot;&gt;Vincent Dumoulin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07511">
<title>A Hitchhiker&apos;s Guide to Geometric GNNs for 3D Atomic Systems. (arXiv:2312.07511v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2312.07511</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in computational modelling of atomic systems, spanning
molecules, proteins, and materials, represent them as geometric graphs with
atoms embedded as nodes in 3D Euclidean space. In these graphs, the geometric
attributes transform according to the inherent physical symmetries of 3D atomic
systems, including rotations and translations in Euclidean space, as well as
node permutations. In recent years, Geometric Graph Neural Networks have
emerged as the preferred machine learning architecture powering applications
ranging from protein structure prediction to molecular simulations and material
generation. Their specificity lies in the inductive biases they leverage --
such as physical symmetries and chemical properties -- to learn informative
representations of these geometric graphs. In this opinionated paper, we
provide a comprehensive and self-contained overview of the field of Geometric
GNNs for 3D atomic systems. We cover fundamental background material and
introduce a pedagogical taxonomy of Geometric GNN architectures:(1) invariant
networks, (2) equivariant networks in Cartesian basis, (3) equivariant networks
in spherical basis, and (4) unconstrained networks. Additionally, we outline
key datasets and application areas and suggest future research directions. The
objective of this work is to present a structured perspective on the field,
making it accessible to newcomers and aiding practitioners in gaining an
intuition for its mathematical abstractions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duval_A/0/1/0/all/0/1&quot;&gt;Alexandre Duval&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathis_S/0/1/0/all/0/1&quot;&gt;Simon V. Mathis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_C/0/1/0/all/0/1&quot;&gt;Chaitanya K. Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_V/0/1/0/all/0/1&quot;&gt;Victor Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miret_S/0/1/0/all/0/1&quot;&gt;Santiago Miret&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malliaros_F/0/1/0/all/0/1&quot;&gt;Fragkiskos D. Malliaros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1&quot;&gt;Taco Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1&quot;&gt;Pietro Lio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1&quot;&gt;Michael Bronstein&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>