<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-12-17T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09257" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09259" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09265" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09269" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09299" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09300" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09304" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09323" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09332" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09352" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09355" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09357" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09361" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09391" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09403" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09404" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09410" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09411" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09417" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09418" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09422" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09423" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09426" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09429" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09430" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09433" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09436" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09437" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09442" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09445" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09449" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09454" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09456" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09460" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09461" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09462" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09466" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09468" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09469" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09478" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09481" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09486" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09488" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09489" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09498" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09504" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09505" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09533" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09540" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09578" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09585" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09597" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09601" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09603" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09606" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09610" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09613" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09623" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09627" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09634" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09636" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09639" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09651" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09663" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09673" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09674" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09691" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09734" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09741" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09744" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09748" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09758" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09766" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09775" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09778" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09783" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09787" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09788" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09789" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09790" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09792" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09793" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09797" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09802" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09806" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09817" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09820" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09821" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09830" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09832" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09844" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09845" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09852" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09857" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09860" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09865" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09869" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09871" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09877" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09881" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09885" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09887" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09899" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09912" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09926" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09938" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09939" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09940" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09961" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09969" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09971" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09978" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09982" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09983" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09997" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10001" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10004" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10007" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10008" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10019" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10023" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10024" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10029" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2001.01258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2003.02214" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2107.01460" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.03169" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.05841" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.10547" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.15364" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.14284" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.01272" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.04806" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.11727" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.07514" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.07786" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.12329" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.13764" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.01125" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.05754" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.01731" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.03724" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.05836" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.07213" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.08754" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.11476" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12066" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13030" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14160" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.15835" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18396" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.10395" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00131" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.10870" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.13332" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04237" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.09751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.10822" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.12367" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.15059" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.15316" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.16599" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.01013" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.04339" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11983" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03725" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.03985" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.06622" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.07958" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.14360" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.20092" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02544" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.02909" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05741" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.05836" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.12550" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.16973" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.17104" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.17401" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.00655" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.01878" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.03179" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04103" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.06403" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.06578" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.06942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.06957" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.07577" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08672" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08782" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08820" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08887" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.08948" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.09108" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2312.09257">
<title>Brain-Inspired Machine Intelligence: A Survey of Neurobiologically-Plausible Credit Assignment. (arXiv:2312.09257v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2312.09257</link>
<description rdf:parseType="Literal">&lt;p&gt;In this survey, we examine algorithms for conducting credit assignment in
artificial neural networks that are inspired or motivated by neurobiology,
unifying these various processes under one possible taxonomy. Our proposed
taxonomy is constructed based on how a learning algorithm answers a central
question underpinning the mechanisms of synaptic plasticity in complex adaptive
neuronal systems: where do the signals that drive the learning in individual
elements of a network come from and how are they produced? In this unified
treatment, we organize the ever-growing set of brain-inspired learning
processes into six general families and consider these in the context of
backpropagation of errors and its known criticisms. The results of this review
are meant to encourage future developments in neuro-mimetic systems and their
constituent learning processes, wherein lies the opportunity to build a strong
bridge between machine learning, computational neuroscience, and cognitive
science.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1&quot;&gt;Alexander G. Ororbia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09259">
<title>Livestock feeding behavior: A tutorial review on automated techniques for ruminant monitoring. (arXiv:2312.09259v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09259</link>
<description rdf:parseType="Literal">&lt;p&gt;Livestock feeding behavior is an influential research area for those involved
in animal husbandry and agriculture. In recent years, there has been a growing
interest in automated systems for monitoring the behavior of ruminants. Despite
the developments accomplished in the last decade, there is still much to do and
learn about the methods for measuring and analyzing livestock feeding behavior.
Automated monitoring systems mainly use motion, acoustic, and image sensors to
collect animal behavioral data. The performance evaluation of existing methods
is a complex task and direct comparisons between studies are difficult. Several
factors prevent a direct comparison, starting from the diversity of data and
performance metrics used in the experiments. To the best of our knowledge, this
work represents the first tutorial-style review on the analysis of the feeding
behavior of ruminants, emphasizing the relationship between sensing
methodologies, signal processing and computational intelligence methods. It
assesses the main sensing methodologies (i.e. based on movement, sound,
images/videos and pressure) and the main techniques to measure and analyze the
signals associated with feeding behavior, evaluating their use in different
settings and situations. It also highlights the potentiality of automated
monitoring systems to provide valuable information that improves our
understanding of livestock feeding behavior. The relevance of these systems is
increasingly important due to their impact on production systems and research.
Finally, the paper closes by discussing future challenges and opportunities in
livestock feeding behavior monitoring.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chelotti_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Chelotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Martinez_Rau_L/0/1/0/all/0/1&quot;&gt;Luciano Martinez-Rau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ferrero_M/0/1/0/all/0/1&quot;&gt;Mariano Ferrero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Vignolo_L/0/1/0/all/0/1&quot;&gt;Leandro Vignolo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Galli_J/0/1/0/all/0/1&quot;&gt;Julio Galli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Planisich_A/0/1/0/all/0/1&quot;&gt;Alejandra Planisich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rufiner_H/0/1/0/all/0/1&quot;&gt;H. Leonardo Rufiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Giovanini_L/0/1/0/all/0/1&quot;&gt;Leonardo Giovanini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09262">
<title>Random resistive memory-based deep extreme point learning machine for unified visual processing. (arXiv:2312.09262v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09262</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual sensors, including 3D LiDAR, neuromorphic DVS sensors, and
conventional frame cameras, are increasingly integrated into edge-side
intelligent machines. Realizing intensive multi-sensory data analysis directly
on edge intelligent machines is crucial for numerous emerging edge
applications, such as augmented and virtual reality and unmanned aerial
vehicles, which necessitates unified data representation, unprecedented
hardware energy efficiency and rapid model training. However, multi-sensory
data are intrinsically heterogeneous, causing significant complexity in the
system development for edge-side intelligent machines. In addition, the
performance of conventional digital hardware is limited by the physically
separated processing and memory units, known as the von Neumann bottleneck, and
the physical limit of transistor scaling, which contributes to the slowdown of
Moore&apos;s law. These limitations are further intensified by the tedious training
of models with ever-increasing sizes. We propose a novel hardware-software
co-design, random resistive memory-based deep extreme point learning machine
(DEPLM), that offers efficient unified point set analysis. We show the system&apos;s
versatility across various data modalities and two different learning tasks.
Compared to a conventional digital hardware-based system, our co-design system
achieves huge energy efficiency improvements and training cost reduction when
compared to conventional systems. Our random resistive memory-based deep
extreme point learning machine may pave the way for energy-efficient and
training-friendly edge AI across various data modalities and tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shaocong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yizhao Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Woyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yifei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_N/0/1/0/all/0/1&quot;&gt;Ning Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hegan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yue Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dingchen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jia Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_P/0/1/0/all/0/1&quot;&gt;Peng Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Hao Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1&quot;&gt;Peng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xumeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1&quot;&gt;Xiaojuan Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Xiaoxin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+So_H/0/1/0/all/0/1&quot;&gt;Hayden So&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhongrui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_D/0/1/0/all/0/1&quot;&gt;Dashan Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1&quot;&gt;Kwang-Ting Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Ming Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09265">
<title>Acoustic models of Brazilian Portuguese Speech based on Neural Transformers. (arXiv:2312.09265v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2312.09265</link>
<description rdf:parseType="Literal">&lt;p&gt;An acoustic model, trained on a significant amount of unlabeled data,
consists of a self-supervised learned speech representation useful for solving
downstream tasks, perhaps after a fine-tuning of the model in the respective
downstream task. In this work, we build an acoustic model of Brazilian
Portuguese Speech through a Transformer neural network. This model was
pretrained on more than $800$ hours of Brazilian Portuguese Speech, using a
combination of pretraining techniques. Using a labeled dataset collected for
the detection of respiratory insufficiency in Brazilian Portuguese speakers, we
fine-tune the pretrained Transformer neural network on the following tasks:
respiratory insufficiency detection, gender recognition and age group
classification. We compare the performance of pretrained Transformers on these
tasks with that of Transformers without previous pretraining, noting a
significant improvement. In particular, the performance of respiratory
insufficiency detection obtains the best reported results so far, indicating
this kind of acoustic model as a promising tool for speech-as-biomarker
approach. Moreover, the performance of gender recognition is comparable to the
state of the art models in English.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gauy_M/0/1/0/all/0/1&quot;&gt;Marcelo Matheus Gauy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finger_M/0/1/0/all/0/1&quot;&gt;Marcelo Finger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09269">
<title>Efficient speech detection in environmental audio using acoustic recognition and knowledge distillation. (arXiv:2312.09269v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2312.09269</link>
<description rdf:parseType="Literal">&lt;p&gt;The ongoing biodiversity crisis, driven by factors such as land-use change
and global warming, emphasizes the need for effective ecological monitoring
methods. Acoustic monitoring of biodiversity has emerged as an important
monitoring tool. Detecting human voices in soundscape monitoring projects is
useful both for analysing human disturbance and for privacy filtering. Despite
significant strides in deep learning in recent years, the deployment of large
neural networks on compact devices poses challenges due to memory and latency
constraints. Our approach focuses on leveraging knowledge distillation
techniques to design efficient, lightweight student models for speech detection
in bioacoustics. In particular, we employed the MobileNetV3-Small-Pi model to
create compact yet effective student architectures to compare against the
larger EcoVAD teacher model, a well-regarded voice detection architecture in
eco-acoustic monitoring. The comparative analysis included examining various
configurations of the MobileNetV3-Small-Pi derived student models to identify
optimal performance. Additionally, a thorough evaluation of different
distillation techniques was conducted to ascertain the most effective method
for model selection. Our findings revealed that the distilled models exhibited
comparable performance to the EcoVAD teacher model, indicating a promising
approach to overcoming computational barriers for real-time ecological
monitoring.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Priebe_D/0/1/0/all/0/1&quot;&gt;Drew Priebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghani_B/0/1/0/all/0/1&quot;&gt;Burooj Ghani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stowell_D/0/1/0/all/0/1&quot;&gt;Dan Stowell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09299">
<title>Weight subcloning: direct initialization of transformers using larger pretrained ones. (arXiv:2312.09299v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09299</link>
<description rdf:parseType="Literal">&lt;p&gt;Training large transformer models from scratch for a target task requires
lots of data and is computationally demanding. The usual practice of transfer
learning overcomes this challenge by initializing the model with weights of a
pretrained model of the same size and specification to increase the convergence
and training speed. However, what if no pretrained model of the required size
is available? In this paper, we introduce a simple yet effective technique to
transfer the knowledge of a pretrained model to smaller variants. Our approach
called weight subcloning expedites the training of scaled-down transformers by
initializing their weights from larger pretrained models.
&lt;/p&gt;
&lt;p&gt;Weight subcloning involves an operation on the pretrained model to obtain the
equivalent initialized scaled-down model. It consists of two key steps: first,
we introduce neuron importance ranking to decrease the embedding dimension per
layer in the pretrained model. Then, we remove blocks from the transformer
model to match the number of layers in the scaled-down network. The result is a
network ready to undergo training, which gains significant improvements in
training speed compared to random initialization. For instance, we achieve 4x
faster training for vision transformers in image classification and language
models designed for next token prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samragh_M/0/1/0/all/0/1&quot;&gt;Mohammad Samragh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farajtabar_M/0/1/0/all/0/1&quot;&gt;Mehrdad Farajtabar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1&quot;&gt;Sachin Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vemulapalli_R/0/1/0/all/0/1&quot;&gt;Raviteja Vemulapalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1&quot;&gt;Fartash Faghri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naik_D/0/1/0/all/0/1&quot;&gt;Devang Naik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuzel_O/0/1/0/all/0/1&quot;&gt;Oncel Tuzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1&quot;&gt;Mohammad Rastegari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09300">
<title>Self-Evaluation Improves Selective Generation in Large Language Models. (arXiv:2312.09300v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.09300</link>
<description rdf:parseType="Literal">&lt;p&gt;Safe deployment of large language models (LLMs) may benefit from a reliable
method for assessing their generated content to determine when to abstain or to
selectively generate. While likelihood-based metrics such as perplexity are
widely employed, recent research has demonstrated the limitations of using
sequence-level probability estimates given by LLMs as reliable indicators of
generation quality. Conversely, LLMs have demonstrated strong calibration at
the token level, particularly when it comes to choosing correct answers in
multiple-choice questions or evaluating true/false statements. In this work, we
reformulate open-ended generation tasks into token-level prediction tasks, and
leverage LLMs&apos; superior calibration at the token level. We instruct an LLM to
self-evaluate its answers, employing either a multi-way comparison or a
point-wise evaluation approach, with the option to include a ``None of the
above&apos;&apos; option to express the model&apos;s uncertainty explicitly. We benchmark a
range of scoring methods based on self-evaluation and evaluate their
performance in selective generation using TruthfulQA and TL;DR. Through
experiments with PaLM-2 and GPT-3, we demonstrate that self-evaluation based
scores not only improve accuracy, but also correlate better with the overall
quality of generated content.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1&quot;&gt;Jie Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yao Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1&quot;&gt;Tu Vu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1&quot;&gt;Peter J. Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1&quot;&gt;Balaji Lakshminarayanan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09304">
<title>Well-calibrated Confidence Measures for Multi-label Text Classification with a Large Number of Labels. (arXiv:2312.09304v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09304</link>
<description rdf:parseType="Literal">&lt;p&gt;We extend our previous work on Inductive Conformal Prediction (ICP) for
multi-label text classification and present a novel approach for addressing the
computational inefficiency of the Label Powerset (LP) ICP, arrising when
dealing with a high number of unique labels. We present experimental results
using the original and the proposed efficient LP-ICP on two English and one
Czech language data-sets. Specifically, we apply the LP-ICP on three deep
Artificial Neural Network (ANN) classifiers of two types: one based on
contextualised (bert) and two on non-contextualised (word2vec) word-embeddings.
In the LP-ICP setting we assign nonconformity scores to label-sets from which
the corresponding p-values and prediction-sets are determined. Our approach
deals with the increased computational burden of LP by eliminating from
consideration a significant number of label-sets that will surely have p-values
below the specified significance level. This reduces dramatically the
computational complexity of the approach while fully respecting the standard CP
guarantees. Our experimental results show that the contextualised-based
classifier surpasses the non-contextualised-based ones and obtains
state-of-the-art performance for all data-sets examined. The good performance
of the underlying classifiers is carried on to their ICP counterparts without
any significant accuracy loss, but with the added benefits of ICP, i.e. the
confidence information encapsulated in the prediction sets. We experimentally
demonstrate that the resulting prediction sets can be tight enough to be
practically useful even though the set of all possible label-sets contains more
than $1e+16$ combinations. Additionally, the empirical error rates of the
obtained prediction-sets confirm that our outputs are well-calibrated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maltoudoglou_L/0/1/0/all/0/1&quot;&gt;Lysimachos Maltoudoglou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paisios_A/0/1/0/all/0/1&quot;&gt;Andreas Paisios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lenc_L/0/1/0/all/0/1&quot;&gt;Ladislav Lenc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinek_J/0/1/0/all/0/1&quot;&gt;Ji&amp;#x159;&amp;#xed; Mart&amp;#xed;nek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kral_P/0/1/0/all/0/1&quot;&gt;Pavel Kr&amp;#xe1;l&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papadopoulos_H/0/1/0/all/0/1&quot;&gt;Harris Papadopoulos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09323">
<title>Perspectives on the State and Future of Deep Learning -- 2023. (arXiv:2312.09323v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.09323</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of this series is to chronicle opinions and issues in the field of
machine learning as they stand today and as they change over time. The plan is
to host this survey periodically until the AI singularity
paperclip-frenzy-driven doomsday, keeping an updated list of topical questions
and interviewing new community members for each edition. In this issue, we
probed people&apos;s opinions on interpretable AI, the value of benchmarking in
modern NLP, the state of progress towards understanding deep learning, and the
future of academia.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1&quot;&gt;Micah Goldblum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1&quot;&gt;Richard Baraniuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1&quot;&gt;Tom Goldstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1&quot;&gt;Zachary C Lipton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1&quot;&gt;Melanie Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1&quot;&gt;Preetum Nakkiran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09332">
<title>A Hierarchical Nearest Neighbour Approach to Contextual Bandits. (arXiv:2312.09332v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09332</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we consider the adversarial contextual bandit problem in metric
spaces. The paper &quot;Nearest neighbour with bandit feedback&quot; tackled this problem
but when there are many contexts near the decision boundary of the comparator
policy it suffers from a high regret. In this paper we eradicate this problem,
designing an algorithm in which we can hold out any set of contexts when
computing our regret term. Our algorithm builds on that of &quot;Nearest neighbour
with bandit feedback&quot; and hence inherits its extreme computational efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasteris_S/0/1/0/all/0/1&quot;&gt;Stephen Pasteris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hicks_C/0/1/0/all/0/1&quot;&gt;Chris Hicks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mavroudis_V/0/1/0/all/0/1&quot;&gt;Vasilios Mavroudis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09352">
<title>PBES: PCA Based Exemplar Sampling Algorithm for Continual Learning. (arXiv:2312.09352v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09352</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel exemplar selection approach based on Principal Component
Analysis (PCA) and median sampling, and a neural network training regime in the
setting of class-incremental learning. This approach avoids the pitfalls due to
outliers in the data and is both simple to implement and use across various
incremental machine learning models. It also has independent usage as a
sampling algorithm. We achieve better performance compared to state-of-the-art
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nokhwal_S/0/1/0/all/0/1&quot;&gt;Sahil Nokhwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1&quot;&gt;Nirman Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09355">
<title>iOn-Profiler: intelligent Online multi-objective VNF Profiling with Reinforcement Learning. (arXiv:2312.09355v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2312.09355</link>
<description rdf:parseType="Literal">&lt;p&gt;Leveraging the potential of Virtualised Network Functions (VNFs) requires a
clear understanding of the link between resource consumption and performance.
The current state of the art tries to do that by utilising Machine Learning
(ML) and specifically Supervised Learning (SL) models for given network
environments and VNF types assuming single-objective optimisation targets.
Taking a different approach poses a novel VNF profiler optimising
multi-resource type allocation and performance objectives using adapted
Reinforcement Learning (RL). Our approach can meet Key Performance Indicator
(KPI) targets while minimising multi-resource type consumption and optimising
the VNF output rate compared to existing single-objective solutions. Our
experimental evaluation with three real-world VNF types over a total of 39
study scenarios (13 per VNF), for three resource types (virtual CPU, memory,
and network link capacity), verifies the accuracy of resource allocation
predictions and corresponding successful profiling decisions via a benchmark
comparison between our RL model and SL models. We also conduct a complementary
exhaustive search-space study revealing that different resources impact
performance in varying ways per VNF type, implying the necessity of
multi-objective optimisation, individualised examination per VNF type, and
adaptable online profile learning, such as with the autonomous online learning
approach of iOn-Profiler.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasilakos_X/0/1/0/all/0/1&quot;&gt;Xenofon Vasilakos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moazzeni_S/0/1/0/all/0/1&quot;&gt;Shadi Moazzeni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bravalheri_A/0/1/0/all/0/1&quot;&gt;Anderson Bravalheri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaisudthi_P/0/1/0/all/0/1&quot;&gt;Pratchaya Jaisudthi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nejabati_R/0/1/0/all/0/1&quot;&gt;Reza Nejabati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simeonidou_D/0/1/0/all/0/1&quot;&gt;Dimitra Simeonidou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09357">
<title>DSS: A Diverse Sample Selection Method to Preserve Knowledge in Class-Incremental Learning. (arXiv:2312.09357v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09357</link>
<description rdf:parseType="Literal">&lt;p&gt;Rehearsal-based techniques are commonly used to mitigate catastrophic
forgetting (CF) in Incremental learning (IL). The quality of the exemplars
selected is important for this purpose and most methods do not ensure the
appropriate diversity of the selected exemplars. We propose a new technique
&quot;DSS&quot; -- Diverse Selection of Samples from the input data stream in the
Class-incremental learning (CIL) setup under both disjoint and fuzzy task
boundary scenarios. Our method outperforms state-of-the-art methods and is much
simpler to understand and implement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nokhwal_S/0/1/0/all/0/1&quot;&gt;Sahil Nokhwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1&quot;&gt;Nirman Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09361">
<title>RTRA: Rapid Training of Regularization-based Approaches in Continual Learning. (arXiv:2312.09361v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09361</link>
<description rdf:parseType="Literal">&lt;p&gt;Catastrophic forgetting(CF) is a significant challenge in continual learning
(CL). In regularization-based approaches to mitigate CF, modifications to
important training parameters are penalized in subsequent tasks using an
appropriate loss function. We propose the RTRA, a modification to the widely
used Elastic Weight Consolidation (EWC) regularization scheme, using the
Natural Gradient for loss function optimization. Our approach improves the
training of regularization-based methods without sacrificing test-data
performance. We compare the proposed RTRA approach against EWC using the
iFood251 dataset. We show that RTRA has a clear edge over the state-of-the-art
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nokhwal_S/0/1/0/all/0/1&quot;&gt;Sahil Nokhwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1&quot;&gt;Nirman Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09391">
<title>Exploiting Symmetric Temporally Sparse BPTT for Efficient RNN Training. (arXiv:2312.09391v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09391</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent Neural Networks (RNNs) are useful in temporal sequence tasks.
However, training RNNs involves dense matrix multiplications which require
hardware that can support a large number of arithmetic operations and memory
accesses. Implementing online training of RNNs on the edge calls for optimized
algorithms for an efficient deployment on hardware. Inspired by the spiking
neuron model, the Delta RNN exploits temporal sparsity during inference by
skipping over the update of hidden states from those inactivated neurons whose
change of activation across two timesteps is below a defined threshold. This
work describes a training algorithm for Delta RNNs that exploits temporal
sparsity in the backward propagation phase to reduce computational requirements
for training on the edge. Due to the symmetric computation graphs of forward
and backward propagation during training, the gradient computation of
inactivated neurons can be skipped. Results show a reduction of $\sim$80% in
matrix operations for training a 56k parameter Delta LSTM on the Fluent Speech
Commands dataset with negligible accuracy loss. Logic simulations of a hardware
accelerator designed for the training algorithm show 2-10X speedup in matrix
computations for an activation sparsity range of 50%-90%. Additionally, we show
that the proposed Delta RNN training will be useful for online incremental
learning on edge devices with limited computing resources.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1&quot;&gt;Chang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zuowen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1&quot;&gt;Longbiao Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sheng Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shih-Chii Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delbruck_T/0/1/0/all/0/1&quot;&gt;Tobi Delbruck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09403">
<title>Physics-Informed Deep Learning of Rate-and-State Fault Friction. (arXiv:2312.09403v1 [math-ph])</title>
<link>http://arxiv.org/abs/2312.09403</link>
<description rdf:parseType="Literal">&lt;p&gt;Direct observations of earthquake nucleation and propagation are few and yet
the next decade will likely see an unprecedented increase in indirect, surface
observations that must be integrated into modeling efforts. Machine learning
(ML) excels in the presence of large data and is an actively growing field in
seismology. However, not all ML methods incorporate rigorous physics, and
purely data-driven models can predict physically unrealistic outcomes due to
observational bias or extrapolation. Our work focuses on the recently emergent
Physics-Informed Neural Network (PINN), which seamlessly integrates data while
ensuring that model outcomes satisfy rigorous physical constraints. In this
work we develop a multi-network PINN for both the forward problem as well as
for direct inversion of nonlinear fault friction parameters, constrained by the
physics of motion in the solid Earth, which have direct implications for
assessing seismic hazard. We present the computational PINN framework for
strike-slip faults in 1D and 2D subject to rate-and-state friction. Initial and
boundary conditions define the data on which the PINN is trained. While the
PINN is capable of approximating the solution to the governing equations to
low-errors, our primary interest lies in the network&apos;s capacity to infer
friction parameters during the training loop. We find that the network for the
parameter inversion at the fault performs much better than the network for
material displacements to which it is coupled. Additional training iterations
and model tuning resolves this discrepancy, enabling a robust surrogate model
for solving both forward and inverse problems relevant to seismic faulting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math-ph/1/au:+Rucker_C/0/1/0/all/0/1&quot;&gt;Cody Rucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math-ph/1/au:+Erickson_B/0/1/0/all/0/1&quot;&gt;Brittany A. Erickson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09404">
<title>Unbiasing Enhanced Sampling on a High-dimensional Free Energy Surface with Deep Generative Model. (arXiv:2312.09404v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09404</link>
<description rdf:parseType="Literal">&lt;p&gt;Biased enhanced sampling methods utilizing collective variables (CVs) are
powerful tools for sampling conformational ensembles. Due to high intrinsic
dimensions, efficiently generating conformational ensembles for complex systems
requires enhanced sampling on high-dimensional free energy surfaces. While
methods like temperature-accelerated molecular dynamics (TAMD) can adopt many
CVs in a simulation, unbiasing the simulation requires accurate modeling of a
high-dimensional CV probability distribution, which is challenging for
traditional density estimation techniques. Here we propose an unbiasing method
based on the score-based diffusion model, a deep generative learning method
that excels in density estimation across complex data landscapes. We test the
score-based diffusion unbiasing method on TAMD simulations. The results
demonstrate that this unbiasing approach significantly outperforms traditional
unbiasing methods, and can generate accurate unbiased conformational ensembles
for simulations with a number of CVs higher than usual ranges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yikai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_T/0/1/0/all/0/1&quot;&gt;Tushar K. Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Ming Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09410">
<title>Prediction of rare events in the operation of household equipment using co-evolving time series. (arXiv:2312.09410v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09410</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we propose an approach for predicting rare events by
exploiting time series in coevolution. Our approach involves a weighted
autologistic regression model, where we leverage the temporal behavior of the
data to enhance predictive capabilities. By addressing the issue of imbalanced
datasets, we establish constraints leading to weight estimation and to improved
performance. Evaluation on synthetic and real-world datasets confirms that our
approach outperform state-of-the-art of predicting home equipment failure
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mecheri_H/0/1/0/all/0/1&quot;&gt;Hadia Mecheri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benamirouche_I/0/1/0/all/0/1&quot;&gt;Islam Benamirouche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fass_F/0/1/0/all/0/1&quot;&gt;Feriel Fass&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ziou_D/0/1/0/all/0/1&quot;&gt;Djemel Ziou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadri_N/0/1/0/all/0/1&quot;&gt;Nassima Kadri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09411">
<title>OTOv3: Automatic Architecture-Agnostic Neural Network Training and Compression from Structured Pruning to Erasing Operators. (arXiv:2312.09411v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09411</link>
<description rdf:parseType="Literal">&lt;p&gt;Compressing a predefined deep neural network (DNN) into a compact sub-network
with competitive performance is crucial in the efficient machine learning
realm. This topic spans various techniques, from structured pruning to neural
architecture search, encompassing both pruning and erasing operators
perspectives. Despite advancements, existing methods suffers from complex,
multi-stage processes that demand substantial engineering and domain knowledge,
limiting their broader applications. We introduce the third-generation
Only-Train-Once (OTOv3), which first automatically trains and compresses a
general DNN through pruning and erasing operations, creating a compact and
competitive sub-network without the need of fine-tuning. OTOv3 simplifies and
automates the training and compression process, minimizes the engineering
efforts required from users. It offers key technological advancements: (i)
automatic search space construction for general DNNs based on dependency graph
analysis; (ii) Dual Half-Space Projected Gradient (DHSPG) and its enhanced
version with hierarchical search (H2SPG) to reliably solve (hierarchical)
structured sparsity problems and ensure sub-network validity; and (iii)
automated sub-network construction using solutions from DHSPG/H2SPG and
dependency graphs. Our empirical results demonstrate the efficacy of OTOv3
across various benchmarks in structured pruning and neural architecture search.
OTOv3 produces sub-networks that match or exceed the state-of-the-arts. The
source code will be available at https://github.com/tianyic/only_train_once.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1&quot;&gt;Tianyu Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhihui Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zeyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;HsiangTao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zharkov_I/0/1/0/all/0/1&quot;&gt;Ilya Zharkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1&quot;&gt;Luming Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09417">
<title>DTP-Net: Learning to Reconstruct EEG signals in Time-Frequency Domain by Multi-scale Feature Reuse. (arXiv:2312.09417v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09417</link>
<description rdf:parseType="Literal">&lt;p&gt;Electroencephalography (EEG) signals are easily corrupted by various
artifacts, making artifact removal crucial for improving signal quality in
scenarios such as disease diagnosis and brain-computer interface (BCI). In this
paper, we present a fully convolutional neural architecture, called DTP-Net,
which consists of a Densely Connected Temporal Pyramid (DTP) sandwiched between
a pair of learnable time-frequency transformations for end-to-end
electroencephalogram (EEG) denoising. The proposed method first transforms a
single-channel EEG signal of arbitrary length into the time-frequency domain
via an Encoder layer. Then, noises, such as ocular and muscle artifacts, are
extracted by DTP in a multi-scale fashion and reduced. Finally, a Decoder layer
is employed to reconstruct the artifact-reduced EEG signal. Additionally, we
conduct an in-depth analysis of the representation learning behavior of each
module in DTP-Net to substantiate its robustness and reliability. Extensive
experiments conducted on two public semi-simulated datasets demonstrate the
effective artifact removal performance of DTP-Net, which outperforms
state-of-art approaches. Experimental results demonstrate cleaner waveforms and
significant improvement in Signal-to-Noise Ratio (SNR) and Relative Root Mean
Square Error (RRMSE) after denoised by the proposed model. Moreover, the
proposed DTP-Net is applied in a specific BCI downstream task, improving the
classification accuracy by up to 5.55% compared to that of the raw signals,
validating its potential applications in the fields of EEG-based neuroscience
and neuro-engineering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pei_Y/0/1/0/all/0/1&quot;&gt;Yan Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiahui Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Qianhao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chenhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Feng Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lisan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Luo_W/0/1/0/all/0/1&quot;&gt;Wei Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09418">
<title>Predicting Multi-Joint Kinematics of the Upper Limb from EMG Signals Across Varied Loads with a Physics-Informed Neural Network. (arXiv:2312.09418v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09418</link>
<description rdf:parseType="Literal">&lt;p&gt;In this research, we present an innovative method known as a physics-informed
neural network (PINN) model to predict multi-joint kinematics using
electromyography (EMG) signals recorded from the muscles surrounding these
joints across various loads. The primary aim is to simultaneously predict both
the shoulder and elbow joint angles while executing elbow flexion-extension
(FE) movements, especially under varying load conditions. The PINN model is
constructed by combining a feed-forward Artificial Neural Network (ANN) with a
joint torque computation model. During the training process, the model utilizes
a custom loss function derived from an inverse dynamics joint torque
musculoskeletal model, along with a mean square angle loss. The training
dataset for the PINN model comprises EMG and time data collected from four
different subjects. To assess the model&apos;s performance, we conducted a
comparison between the predicted joint angles and experimental data using a
testing data set. The results demonstrated strong correlations of 58% to 83% in
joint angle prediction. The findings highlight the potential of incorporating
physical principles into the model, not only increasing its versatility but
also enhancing its accuracy. The findings could have significant implications
for the precise estimation of multi-joint kinematics in dynamic scenarios,
particularly concerning the advancement of human-machine interfaces (HMIs) for
exoskeletons and prosthetic control systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Rajnish Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Muthukrishnan_S/0/1/0/all/0/1&quot;&gt;Suriya Prakash Muthukrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kumar_L/0/1/0/all/0/1&quot;&gt;Lalan Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sitikantha Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09422">
<title>Joint Alignment of Multivariate Quasi-Periodic Functional Data Using Deep Learning. (arXiv:2312.09422v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09422</link>
<description rdf:parseType="Literal">&lt;p&gt;The joint alignment of multivariate functional data plays an important role
in various fields such as signal processing, neuroscience and medicine,
including the statistical analysis of data from wearable devices. Traditional
methods often ignore the phase variability and instead focus on the variability
in the observed amplitude. We present a novel method for joint alignment of
multivariate quasi-periodic functions using deep neural networks, decomposing,
but retaining all the information in the data by preserving both phase and
amplitude variability. Our proposed neural network uses a special activation of
the output that builds on the unit simplex transformation, and we utilize a
loss function based on the Fisher-Rao metric to train our model. Furthermore,
our method is unsupervised and can provide an optimal common template function
as well as subject-specific templates. We demonstrate our method on two
simulated datasets and one real example, comprising data from 12-lead 10s
electrocardiogram recordings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pham_V/0/1/0/all/0/1&quot;&gt;Vi Thanh Pham&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nielsen_J/0/1/0/all/0/1&quot;&gt;Jonas Bille Nielsen&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kofoed_K/0/1/0/all/0/1&quot;&gt;Klaus Fuglsang Kofoed&lt;/a&gt; (2 and 3), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kuhl_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf8;rgen Tobias K&amp;#xfc;hl&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jensen_A/0/1/0/all/0/1&quot;&gt;Andreas Kryger Jensen&lt;/a&gt; (1) ((1) Section of Biostatistics, Department of Public Health, Faculty of Health and Medical Sciences, University of Copenhagen, (2) Department of Cardiology and Radiology, Copenhagen University Hospital, (3) Department of Clinical Medicine, Faculty of Health and Medical Sciences, University of Copenhagen, (4) Department of Cardiology, Zealand University Hospital)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09423">
<title>Decoding EEG-based Workload Levels Using Spatio-temporal Features Under Flight Environment. (arXiv:2312.09423v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09423</link>
<description rdf:parseType="Literal">&lt;p&gt;The detection of pilots&apos; mental states is important due to the potential for
their abnormal mental states to result in catastrophic accidents. This study
introduces the feasibility of employing deep learning techniques to classify
different workload levels, specifically normal state, low workload, and high
workload. To the best of our knowledge, this study is the first attempt to
classify workload levels of pilots. Our approach involves the hybrid deep
neural network that consists of five convolutional blocks and one long
short-term memory block to extract the significant features from
electroencephalography signals. Ten pilots participated in the experiment,
which was conducted within the simulated flight environment. In contrast to
four conventional models, our proposed model achieved a superior grand--average
accuracy of 0.8613, surpassing other conventional models by at least 0.0597 in
classifying workload levels across all participants. Our model not only
successfully classified workload levels but also provided valuable feedback to
the participants. Hence, we anticipate that our study will make the significant
contributions to the advancement of autonomous flight and driving leveraging
artificial intelligence technology in the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Dae-Hyeok Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sung-Jin Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Si-Hyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seong-Whan Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09426">
<title>Deep Learning Models for Arrhythmia Classification Using Stacked Time-frequency Scalogram Images from ECG Signals. (arXiv:2312.09426v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09426</link>
<description rdf:parseType="Literal">&lt;p&gt;Electrocardiograms (ECGs), a medical monitoring technology recording cardiac
activity, are widely used for diagnosing cardiac arrhythmia. The diagnosis is
based on the analysis of the deformation of the signal shapes due to irregular
heart rates associated with heart diseases. Due to the infeasibility of manual
examination of large volumes of ECG data, this paper aims to propose an
automated AI based system for ECG-based arrhythmia classification. To this
front, a deep learning based solution has been proposed for ECG-based
arrhythmia classification. Twelve lead electrocardiograms (ECG) of length 10
sec from 45, 152 individuals from Shaoxing People&apos;s Hospital (SPH) dataset from
PhysioNet with four different types of arrhythmias were used. The sampling
frequency utilized was 500 Hz. Median filtering was used to preprocess the ECG
signals. For every 1 sec of ECG signal, the time-frequency (TF) scalogram was
estimated and stacked row wise to obtain a single image from 12 channels,
resulting in 10 stacked TF scalograms for each ECG signal. These stacked TF
scalograms are fed to the pretrained convolutional neural network (CNN), 1D
CNN, and 1D CNN-LSTM (Long short-term memory) models, for arrhythmia
classification. The fine-tuned CNN models obtained the best test accuracy of
about 98% followed by 95% test accuracy by basic CNN-LSTM in arrhythmia
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Aarotale_P/0/1/0/all/0/1&quot;&gt;Parshuram N. Aarotale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rattani_A/0/1/0/all/0/1&quot;&gt;Ajita Rattani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09429">
<title>Deep Learning-Enabled Swallowing Monitoring and Postoperative Recovery Biosensing System. (arXiv:2312.09429v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09429</link>
<description rdf:parseType="Literal">&lt;p&gt;This study introduces an innovative 3D printed dry electrode tailored for
biosensing in postoperative recovery scenarios. Fabricated through a drop
coating process, the electrode incorporates a novel 2D material.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tsai_C/0/1/0/all/0/1&quot;&gt;Chih-Ning Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_P/0/1/0/all/0/1&quot;&gt;Pei-Wen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Tzu-Yen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jung-Chih Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tseng_H/0/1/0/all/0/1&quot;&gt;Hsin-Yi Tseng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Che-Wei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sarmah_A/0/1/0/all/0/1&quot;&gt;Amrit Sarmah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tzu-En Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09430">
<title>Deep Representation Learning for Open Vocabulary Electroencephalography-to-Text Decoding. (arXiv:2312.09430v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09430</link>
<description rdf:parseType="Literal">&lt;p&gt;Previous research has demonstrated the potential of using pre-trained
language models for decoding open vocabulary Electroencephalography (EEG)
signals captured through a non-invasive Brain-Computer Interface (BCI).
However, the impact of embedding EEG signals in the context of language models
and the effect of subjectivity, remain unexplored, leading to uncertainty about
the best approach to enhance decoding performance. Additionally, current
evaluation metrics used to assess decoding effectiveness are predominantly
syntactic and do not provide insights into the comprehensibility of the decoded
output for human understanding. We present an end-to-end deep learning
framework for non-invasive brain recordings that brings modern representational
learning approaches to neuroscience. Our proposal introduces the following
innovations: 1) an end-to-end deep learning architecture for open vocabulary
EEG decoding, incorporating a subject-dependent representation learning module
for raw EEG encoding, a BART language model, and a GPT-4 sentence refinement
module; 2) a more comprehensive sentence-level evaluation metric based on the
BERTScore; 3) an ablation study that analyses the contributions of each module
within our proposal, providing valuable insights for future research. We
evaluate our approach on two publicly available datasets, ZuCo v1.0 and v2.0,
comprising EEG recordings of 30 subjects engaged in natural reading tasks. Our
model achieves a BLEU-1 score of 42.75%, a ROUGE-1-F of 33.28%, and a
BERTScore-F of 53.86%, outperforming the previous state-of-the-art methods by
3.38%, 8.43%, and 6.31%, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Amrani_H/0/1/0/all/0/1&quot;&gt;Hamza Amrani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Micucci_D/0/1/0/all/0/1&quot;&gt;Daniela Micucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Napoletano_P/0/1/0/all/0/1&quot;&gt;Paolo Napoletano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09433">
<title>Point-of-Care Real-Time Signal Quality for Fetal Doppler Ultrasound Using a Deep Learning Approach. (arXiv:2312.09433v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09433</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we present a deep learning framework designed to integrate
with our previously developed system that facilitates large-scale 1D fetal
Doppler data collection, aiming to enhance data quality. This system, tailored
for traditional Indigenous midwives in low-resource communities, leverages a
cost-effective Android phone to improve the quality of recorded signals. We
have shown that the Doppler data can be used to identify fetal growth
restriction, hypertension, and other concerning issues during pregnancy.
However, the quality of the signal is dependent on many factors, including
radio frequency interference, position of the fetus, maternal body habitus, and
usage of the Doppler by the birth attendants. In order to provide instant
feedback to allow correction of the data at source, a signal quality metric is
required that can run in real-time on the mobile phone.
&lt;/p&gt;
&lt;p&gt;In this study, 191 DUS signals with durations mainly in the range between 5
to 10 minutes were evaluated for quality and classified into five categories:
Good, Poor, (Radiofrequency) Interference, Talking, and Silent, at a resolution
of 3.75 seconds. A deep neural network was trained on each 3.75-second segment
from these recordings and validated using five-fold cross-validation.
&lt;/p&gt;
&lt;p&gt;An average micro F1 = 97.4\% and macro F1 = 94.2\% were achieved, with F1 =
99.2\% for `Good&apos; quality data. These results indicate that the algorithm,
which will now be implemented in the midwives&apos; app, should allow a significant
increase in the quality of data at the time of capture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Motie_Shirazi_M/0/1/0/all/0/1&quot;&gt;Mohsen Motie-Shirazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sameni_R/0/1/0/all/0/1&quot;&gt;Reza Sameni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rohloff_P/0/1/0/all/0/1&quot;&gt;Peter Rohloff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Katebi_N/0/1/0/all/0/1&quot;&gt;Nasim Katebi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Clifford_G/0/1/0/all/0/1&quot;&gt;Gari D. Clifford&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09436">
<title>Temporal Transfer Learning for Traffic Optimization with Coarse-grained Advisory Autonomy. (arXiv:2312.09436v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.09436</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent development of connected and automated vehicle (CAV) technologies
has spurred investigations to optimize dense urban traffic. This paper
considers advisory autonomy, in which real-time driving advisories are issued
to drivers, thus blending the CAV and the human driver. Due to the complexity
of traffic systems, recent studies of coordinating CAVs have resorted to
leveraging deep reinforcement learning (RL). Advisory autonomy is formalized as
zero-order holds, and we consider a range of hold duration from 0.1 to 40
seconds. However, despite the similarity of the higher frequency tasks on CAVs,
a direct application of deep RL fails to be generalized to advisory autonomy
tasks. We introduce Temporal Transfer Learning (TTL) algorithms to select
source tasks, systematically leveraging the temporal structure to solve the
full range of tasks. TTL selects the most suitable source tasks to maximize the
performance of the range of tasks. We validate our algorithms on diverse
mixed-traffic scenarios, demonstrating that TTL more reliably solves the tasks
than baselines. This paper underscores the potential of coarse-grained advisory
autonomy with TTL in traffic flow optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1&quot;&gt;Jung-Hoon Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Sirui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jeongyun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Cathy Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09437">
<title>Riemannian Prediction of Anatomical Diagnoses in Congenital Heart Disease based on 12-lead ECGs. (arXiv:2312.09437v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09437</link>
<description rdf:parseType="Literal">&lt;p&gt;Congenital heart disease (CHD) is a relatively rare disease that affects
patients at birth and results in extremely heterogeneous anatomical and
functional defects. 12-lead ECG signal is routinely collected in CHD patients
because it provides significant biomarkers for disease prognosis. However,
developing accurate machine learning models is challenging due to the lack of
large available datasets. Here, we suggest exploiting the Riemannian geometry
of the spatial covariance structure of the ECG signal to improve
classification. Firstly, we use covariance augmentation to mix samples across
the Riemannian geodesic between corresponding classes. Secondly, we suggest to
project the covariance matrices to their respective class Riemannian mean to
enhance the quality of feature extraction via tangent space projection. We
perform several ablation experiments and demonstrate significant improvement
compared to traditional machine learning models and deep learning on ECG time
series data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Alkan_M/0/1/0/all/0/1&quot;&gt;Muhammet Alkan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Veldtman_G/0/1/0/all/0/1&quot;&gt;Gruschen Veldtman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Deligianni_F/0/1/0/all/0/1&quot;&gt;Fani Deligianni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09442">
<title>A Compact LSTM-SVM Fusion Model for Long-Duration Cardiovascular Diseases Detection. (arXiv:2312.09442v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09442</link>
<description rdf:parseType="Literal">&lt;p&gt;Globally, cardiovascular diseases (CVDs) are the leading cause of mortality,
accounting for an estimated 17.9 million deaths annually. One critical clinical
objective is the early detection of CVDs using electrocardiogram (ECG) data, an
area that has received significant attention from the research community.
Recent advancements based on machine learning and deep learning have achieved
great progress in this domain. However, existing methodologies exhibit inherent
limitations, including inappropriate model evaluations and instances of data
leakage. In this study, we present a streamlined workflow paradigm for
preprocessing ECG signals into consistent 10-second durations, eliminating the
need for manual feature extraction/beat detection. We also propose a hybrid
model of Long Short-Term Memory (LSTM) with Support Vector Machine (SVM) for
fraud detection. This architecture consists of two LSTM layers and an SVM
classifier, which achieves a SOTA results with an Average precision score of
0.9402 on the MIT-BIH arrhythmia dataset and 0.9563 on the MIT-BIH atrial
fibrillation dataset. Based on the results, we believe our method can
significantly benefit the early detection and management of CVDs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_S/0/1/0/all/0/1&quot;&gt;Siyang Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09445">
<title>IncepSE: Leveraging InceptionTime&apos;s performance with Squeeze and Excitation mechanism in ECG analysis. (arXiv:2312.09445v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09445</link>
<description rdf:parseType="Literal">&lt;p&gt;Our study focuses on the potential for modifications of Inception-like
architecture within the electrocardiogram (ECG) domain. To this end, we
introduce IncepSE, a novel network characterized by strategic architectural
incorporation that leverages the strengths of both InceptionTime and channel
attention mechanisms. Furthermore, we propose a training setup that employs
stabilization techniques that are aimed at tackling the formidable challenges
of severe imbalance dataset PTB-XL and gradient corruption. By this means, we
manage to set a new height for deep learning model in a supervised learning
manner across the majority of tasks. Our model consistently surpasses
InceptionTime by substantial margins compared to other state-of-the-arts in
this domain, noticeably 0.013 AUROC score improvement in the &quot;all&quot; task, while
also mitigating the inherent dataset fluctuations during training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cao_T/0/1/0/all/0/1&quot;&gt;Tue Minh Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tran_N/0/1/0/all/0/1&quot;&gt;Nhat Hong Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_L/0/1/0/all/0/1&quot;&gt;Le Phi Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pham_H/0/1/0/all/0/1&quot;&gt;Hieu Huy Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Hung Thanh Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09449">
<title>vEEGNet: learning latent representations to reconstruct EEG raw data via variational autoencoders. (arXiv:2312.09449v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09449</link>
<description rdf:parseType="Literal">&lt;p&gt;Electroencephalografic (EEG) data are complex multi-dimensional time-series
that are very useful in many applications, from diagnostics to driving
brain-computer interface systems. Their classification is still a challenging
task, due to the inherent within- and between-subject variability and their low
signal-to-noise ratio. On the other hand, the reconstruction of raw EEG data is
even more difficult because of the high temporal resolution of these signals.
Recent literature has proposed numerous machine and deep learning models that
could classify, e.g., different types of movements, with an accuracy in the
range 70% to 80% (with 4 classes). On the other hand, a limited number of works
targeted the reconstruction problem, with very limited results. In this work,
we propose vEEGNet, a DL architecture with two modules, i.e., an unsupervised
module based on variational autoencoders to extract a latent representation of
the data, and a supervised module based on a feed-forward neural network to
classify different movements. To build the encoder and the decoder of VAE we
exploited the well-known EEGNet network. We implemented two slightly different
architectures of vEEGNet, thus showing state-of-the-art classification
performance, and the ability to reconstruct both low-frequency and middle-range
components of the raw EEG. Although preliminary, this work is promising as we
found out that the low-frequency reconstructed signals are consistent with the
so-called motor-related cortical potentials, well-known motor-related EEG
patterns and we could improve over previous literature by reconstructing faster
EEG components, too. Further investigations are needed to explore the
potentialities of vEEGNet in reconstructing the full EEG data, generating new
samples, and studying the relationship between classification and
reconstruction performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zancanaro_A/0/1/0/all/0/1&quot;&gt;Alberto Zancanaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cisotto_G/0/1/0/all/0/1&quot;&gt;Giulia Cisotto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zoppis_I/0/1/0/all/0/1&quot;&gt;Italo Zoppis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Manzoni_S/0/1/0/all/0/1&quot;&gt;Sara Lucia Manzoni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09454">
<title>Uncertainty Quantification in Machine Learning for Biosignal Applications -- A Review. (arXiv:2312.09454v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09454</link>
<description rdf:parseType="Literal">&lt;p&gt;Uncertainty Quantification (UQ) has gained traction in an attempt to fix the
black-box nature of Deep Learning. Specifically (medical) biosignals such as
electroencephalography (EEG), electrocardiography (ECG), electroocculography
(EOG) and electromyography (EMG) could benefit from good UQ, since these suffer
from a poor signal to noise ratio, and good human interpretability is pivotal
for medical applications and Brain Computer Interfaces. In this paper, we
review the state of the art at the intersection of Uncertainty Quantification
and Biosignal with Machine Learning. We present various methods, shortcomings,
uncertainty measures and theoretical frameworks that currently exist in this
application domain. Overall it can be concluded that promising UQ methods are
available, but that research is needed on how people and systems may interact
with an uncertainty model in a (clinical) environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jong_I/0/1/0/all/0/1&quot;&gt;Ivo Pascal de Jong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sburlea_A/0/1/0/all/0/1&quot;&gt;Andreea Ioana Sburlea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Valdenegro_Toro_M/0/1/0/all/0/1&quot;&gt;Matias Valdenegro-Toro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09456">
<title>Pioneering EEG Motor Imagery Classification Through Counterfactual Analysis. (arXiv:2312.09456v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09456</link>
<description rdf:parseType="Literal">&lt;p&gt;The application of counterfactual explanation (CE) techniques in the realm of
electroencephalography (EEG) classification has been relatively infrequent in
contemporary research. In this study, we attempt to introduce and explore a
novel non-generative approach to CE, specifically tailored for the analysis of
EEG signals. This innovative approach assesses the model&apos;s decision-making
process by strategically swapping patches derived from time-frequency analyses.
By meticulously examining the variations and nuances introduced in the
classification outcomes through this method, we aim to derive insights that can
enhance interpretability. The empirical results obtained from our experimental
investigations serve not only to validate the efficacy of our proposed approach
but also to reinforce human confidence in the model&apos;s predictive capabilities.
Consequently, these findings underscore the significance and potential value of
conducting further, more extensive research in this promising direction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yin_K/0/1/0/all/0/1&quot;&gt;Kang Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shin_H/0/1/0/all/0/1&quot;&gt;Hye-Bin Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hee-Dong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seong-Whan Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09460">
<title>Taming Waves: A Physically-Interpretable Machine Learning Framework for Realizable Control of Wave Dynamics. (arXiv:2312.09460v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09460</link>
<description rdf:parseType="Literal">&lt;p&gt;Controlling systems governed by partial differential equations is an
inherently hard problem. Specifically, control of wave dynamics is challenging
due to additional physical constraints and intrinsic properties of wave
phenomena such as dissipation, attenuation, reflection, and scattering. In this
work, we introduce an environment designed for the study of the control of
acoustic waves by actuated metamaterial designs. We utilize this environment
for the development of a novel machine-learning method, based on deep neural
networks, for efficiently learning the dynamics of an acoustic PDE from
samples. Our model is fully interpretable and maps physical constraints and
intrinsic properties of the real acoustic environment into its latent
representation of information. Within our model we use a trainable perfectly
matched layer to explicitly learn the property of acoustic energy dissipation.
Our model can be used to predict and control scattered wave energy. The
capabilities of our model are demonstrated on an important problem in
acoustics, which is the minimization of total scattered energy. Furthermore, we
show that the prediction of scattered energy by our model generalizes in time
and can be extended to long time horizons. We make our code repository publicly
available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shah_T/0/1/0/all/0/1&quot;&gt;Tristan Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Amirkulova_F/0/1/0/all/0/1&quot;&gt;Feruza Amirkulova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tiomkin_S/0/1/0/all/0/1&quot;&gt;Stas Tiomkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09461">
<title>Improving Generalization of Drowsiness State Classification by Domain-Specific Normalization. (arXiv:2312.09461v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09461</link>
<description rdf:parseType="Literal">&lt;p&gt;Abnormal driver states, particularly have been major concerns for road
safety, emphasizing the importance of accurate drowsiness detection to prevent
accidents. Electroencephalogram (EEG) signals are recognized for their
effectiveness in monitoring a driver&apos;s mental state by monitoring brain
activities. However, the challenge lies in the requirement for prior
calibration due to the variation of EEG signals among and within individuals.
The necessity of calibration has made the brain-computer interface (BCI) less
accessible. We propose a practical generalized framework for classifying driver
drowsiness states to improve accessibility and convenience. We separate the
normalization process for each driver, treating them as individual domains. The
goal of developing a general model is similar to that of domain generalization.
The framework considers the statistics of each domain separately since they
vary among domains. We experimented with various normalization methods to
enhance the ability to generalize across subjects, i.e. the model&apos;s
generalization performance of unseen domains. The experiments showed that
applying individual domain-specific normalization yielded an outstanding
improvement in generalizability. Furthermore, our framework demonstrates the
potential and accessibility by removing the need for calibration in BCI
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dong-Young Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Han_D/0/1/0/all/0/1&quot;&gt;Dong-Kyun Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Seo-Hyeon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jang_G/0/1/0/all/0/1&quot;&gt;Geun-Deok Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seong-Whan Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09462">
<title>Applying Machine Learning Models on Metrology Data for Predicting Device Electrical Performance. (arXiv:2312.09462v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09462</link>
<description rdf:parseType="Literal">&lt;p&gt;Moore Law states that transistor density will double every two years, which
is sustained until today due to continuous multi-directional innovations, such
as extreme ultraviolet lithography, novel patterning techniques etc., leading
the semiconductor industry towards 3nm node and beyond. For any patterning
scheme, the most important metric to evaluate the quality of printed patterns
is EPE, with overlay being its largest contribution. Overlay errors can lead to
fatal failures of IC devices such as short circuits or broken connections in
terms of P2P electrical contacts. Therefore, it is essential to develop
effective overlay analysis and control techniques to ensure good functionality
of fabricated semiconductor devices. In this work we have used an imec N14 BEOL
process flow using LELE patterning technique to print metal layers with minimum
pitch of 48nm with 193i lithography. FF structures are decomposed into two mask
layers (M1A and M1B) and then the LELE flow is carried out to make the final
patterns. Since a single M1 layer is decomposed into two masks, control of
overlay between the two masks is critical. The goal of this work is of two-fold
as, (a) to quantify the impact of overlay on capacitance and (b) to see if we
can predict the final capacitance measurements with selected machine learning
models at an early stage. To do so, scatterometry spectra are collected on
these electrical test structures at (a)post litho, (b)post TiN hardmask etch,
and (c)post Cu plating and CMP. Critical Dimension and overlay measurements for
line-space pattern are done with SEM post litho, post etch and post Cu CMP.
Various machine learning models are applied to do the capacitance prediction
with multiple metrology inputs at different steps of wafer processing. Finally,
we demonstrate that by using appropriate machine learning models we are able to
do better prediction of electrical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dey_B/0/1/0/all/0/1&quot;&gt;Bappaditya Dey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ngo_A/0/1/0/all/0/1&quot;&gt;Anh Tuan Ngo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sacchi_S/0/1/0/all/0/1&quot;&gt;Sara Sacchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Blanco_V/0/1/0/all/0/1&quot;&gt;Victor Blanco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Leray_P/0/1/0/all/0/1&quot;&gt;Philippe Leray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Halder_S/0/1/0/all/0/1&quot;&gt;Sandip Halder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09466">
<title>Enhancing Trajectory Prediction through Self-Supervised Waypoint Noise Prediction. (arXiv:2312.09466v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.09466</link>
<description rdf:parseType="Literal">&lt;p&gt;Trajectory prediction is an important task that involves modeling the
indeterminate nature of traffic actors to forecast future trajectories given
the observed trajectory sequences. However, current methods confine themselves
to presumed data manifolds, assuming that trajectories strictly adhere to these
manifolds, resulting in overly simplified predictions. To this end, we propose
a novel approach called SSWNP (Self-Supervised Waypoint Noise Prediction). In
our approach, we first create clean and noise-augmented views of past observed
trajectories across the spatial domain of waypoints. We then compel the
trajectory prediction model to maintain spatial consistency between predictions
from these two views, in addition to the trajectory prediction task.
Introducing the noise-augmented view mitigates the model&apos;s reliance on a narrow
interpretation of the data manifold, enabling it to learn more plausible and
diverse representations. We also predict the noise present in the two views of
past observed trajectories as an auxiliary self-supervised task, enhancing the
model&apos;s understanding of the underlying representation and future predictions.
Empirical evidence demonstrates that the incorporation of SSWNP into the model
learning process significantly improves performance, even in noisy
environments, when compared to baseline methods. Our approach can complement
existing trajectory prediction methods. To showcase the effectiveness of our
approach, we conducted extensive experiments on three datasets: NBA Sports VU,
ETH-UCY, and TrajNet++, with experimental results highlighting the substantial
improvement achieved in trajectory prediction tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chib_P/0/1/0/all/0/1&quot;&gt;Pranav Singh Chib&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1&quot;&gt;Pravendra Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09468">
<title>Safe Reinforcement Learning in a Simulated Robotic Arm. (arXiv:2312.09468v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.09468</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) agents need to explore their environments in
order to learn optimal policies. In many environments and tasks, safety is of
critical importance. The widespread use of simulators offers a number of
advantages, including safe exploration which will be inevitable in cases when
RL systems need to be trained directly in the physical environment (e.g. in
human-robot interaction). The popular Safety Gym library offers three mobile
agent types that can learn goal-directed tasks while considering various safety
constraints. In this paper, we extend the applicability of safe RL algorithms
by creating a customized environment with Panda robotic arm where Safety Gym
algorithms can be tested. We performed pilot experiments with the popular PPO
algorithm comparing the baseline with the constrained version and show that the
constrained version is able to learn the equally good policy while better
complying with safety constraints and taking longer training time as expected.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kovac_L/0/1/0/all/0/1&quot;&gt;Luka Kova&amp;#x10d;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farkas_I/0/1/0/all/0/1&quot;&gt;Igor Farka&amp;#x161;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09469">
<title>Clinical Text Deduplication Practices for Efficient Pretraining and Improved Clinical Tasks. (arXiv:2312.09469v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.09469</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite being a unique source of information on patients&apos; status and disease
progression, clinical notes are characterized by high levels of duplication and
information redundancy. In general domain text, it has been shown that
deduplication does not harm language model (LM) pretraining, thus helping
reduce the training cost. Although large LMs have proven to learn medical
knowledge, they still require specialized domain adaptation for improved
downstream clinical tasks. By leveraging large real-world clinical corpora, we
first provided a fine-grained characterization of duplicates stemming from
common writing practices and clinical relevancy. Second, we demonstrated that
deduplicating clinical text can help clinical LMs encode less redundant
information in a more efficient manner and do not harm classification tasks via
prompt-based learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Landi_I/0/1/0/all/0/1&quot;&gt;Isotta Landi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alleva_E/0/1/0/all/0/1&quot;&gt;Eugenia Alleva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valentine_A/0/1/0/all/0/1&quot;&gt;Alissa A. Valentine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lepow_L/0/1/0/all/0/1&quot;&gt;Lauren A. Lepow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charney_A/0/1/0/all/0/1&quot;&gt;Alexander W. Charney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09478">
<title>Entropy Causal Graphs for Multivariate Time Series Anomaly Detection. (arXiv:2312.09478v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09478</link>
<description rdf:parseType="Literal">&lt;p&gt;Many multivariate time series anomaly detection frameworks have been proposed
and widely applied. However, most of these frameworks do not consider intrinsic
relationships between variables in multivariate time series data, thus ignoring
the causal relationship among variables and degrading anomaly detection
performance. This work proposes a novel framework called CGAD, an entropy
Causal Graph for multivariate time series Anomaly Detection. CGAD utilizes
transfer entropy to construct graph structures that unveil the underlying
causal relationships among time series data. Weighted graph convolutional
networks combined with causal convolutions are employed to model both the
causal graph structures and the temporal patterns within multivariate time
series data. Furthermore, CGAD applies anomaly scoring, leveraging median
absolute deviation-based normalization to improve the robustness of the anomaly
identification process. Extensive experiments demonstrate that CGAD outperforms
state-of-the-art methods on real-world datasets with a 15% average improvement
based on three different multivariate time series anomaly detection metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Febrinanto_F/0/1/0/all/0/1&quot;&gt;Falih Gozi Febrinanto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_K/0/1/0/all/0/1&quot;&gt;Kristen Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thapa_C/0/1/0/all/0/1&quot;&gt;Chandra Thapa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Mujie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saikrishna_V/0/1/0/all/0/1&quot;&gt;Vidya Saikrishna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jiangang Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1&quot;&gt;Feng Xia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09481">
<title>Continual Adversarial Defense. (arXiv:2312.09481v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.09481</link>
<description rdf:parseType="Literal">&lt;p&gt;In response to the rapidly evolving nature of adversarial attacks on a
monthly basis, numerous defenses have been proposed to generalize against as
many known attacks as possible. However, designing a defense method that can
generalize to all types of attacks, including unseen ones, is not realistic
because the environment in which defense systems operate is dynamic and
comprises various unique attacks used by many attackers. The defense system
needs to upgrade itself by utilizing few-shot defense feedback and efficient
memory. Therefore, we propose the first continual adversarial defense (CAD)
framework that adapts to any attacks in a dynamic scenario, where various
attacks emerge stage by stage. In practice, CAD is modeled under four
principles: (1) continual adaptation to new attacks without catastrophic
forgetting, (2) few-shot adaptation, (3) memory-efficient adaptation, and (4)
high accuracy on both clean and adversarial images. We leverage cutting-edge
continual learning, few-shot learning, and ensemble learning techniques to
qualify the principles. Experiments conducted on CIFAR-10 and ImageNet-100
validate the effectiveness of our approach against multiple stages of 10 modern
adversarial attacks and significant improvements over 10 baseline methods. In
particular, CAD is capable of quickly adapting with minimal feedback and a low
cost of defense failure, while maintaining good performance against old
attacks. Our research sheds light on a brand-new paradigm for continual defense
adaptation against dynamic and evolving attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yaoyao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1&quot;&gt;Hefei Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qihao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Ping Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiazhong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1&quot;&gt;Alan Yuille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1&quot;&gt;Ning Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09486">
<title>Unraveling Batch Normalization for Realistic Test-Time Adaptation. (arXiv:2312.09486v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.09486</link>
<description rdf:parseType="Literal">&lt;p&gt;While recent test-time adaptations exhibit efficacy by adjusting batch
normalization to narrow domain disparities, their effectiveness diminishes with
realistic mini-batches due to inaccurate target estimation. As previous
attempts merely introduce source statistics to mitigate this issue, the
fundamental problem of inaccurate target estimation still persists, leaving the
intrinsic test-time domain shifts unresolved. This paper delves into the
problem of mini-batch degradation. By unraveling batch normalization, we
discover that the inexact target statistics largely stem from the substantially
reduced class diversity in batch. Drawing upon this insight, we introduce a
straightforward tool, Test-time Exponential Moving Average (TEMA), to bridge
the class diversity gap between training and testing batches. Importantly, our
TEMA adaptively extends the scope of typical methods beyond the current batch
to incorporate a diverse set of class information, which in turn boosts an
accurate target estimation. Built upon this foundation, we further design a
novel layer-wise rectification strategy to consistently promote test-time
performance. Our proposed method enjoys a unique advantage as it requires
neither training nor tuning parameters, offering a truly hassle-free solution.
It significantly enhances model robustness against shifted domains and
maintains resilience in diverse real-world scenarios with various batch sizes,
achieving state-of-the-art performance on several major benchmarks. Code is
available at \url{https://github.com/kiwi12138/RealisticTTA}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1&quot;&gt;Zixian Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jingwei Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_K/0/1/0/all/0/1&quot;&gt;Kai Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qiufeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kaizhu Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09488">
<title>Sequence adaptive field-imperfection estimation (SAFE): retrospective estimation and correction of $B_1^+$ and $B_0$ inhomogeneities for enhanced MRF quantification. (arXiv:2312.09488v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.09488</link>
<description rdf:parseType="Literal">&lt;p&gt;$B_1^+$ and $B_0$ field-inhomogeneities can significantly reduce accuracy and
robustness of MRF&apos;s quantitative parameter estimates. Additional $B_1^+$ and
$B_0$ calibration scans can mitigate this but add scan time and cannot be
applied retrospectively to previously collected data. Here, we proposed a
calibration-free sequence-adaptive deep-learning framework, to estimate and
correct for $B_1^+$ and $B_0$ effects of any MRF sequence. We demonstrate its
capability on arbitrary MRF sequences at 3T, where no training data were
previously obtained. Such approach can be applied to any previously-acquired
and future MRF-scans. The flexibility in directly applying this framework to
other quantitative sequences is also highlighted.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gao_M/0/1/0/all/0/1&quot;&gt;Mengze Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cao_X/0/1/0/all/0/1&quot;&gt;Xiaozhi Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Abraham_D/0/1/0/all/0/1&quot;&gt;Daniel Abraham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zihan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Setsompop_K/0/1/0/all/0/1&quot;&gt;Kawin Setsompop&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09489">
<title>Multi-stage Learning for Radar Pulse Activity Segmentation. (arXiv:2312.09489v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09489</link>
<description rdf:parseType="Literal">&lt;p&gt;Radio signal recognition is a crucial function in electronic warfare. Precise
identification and localisation of radar pulse activities are required by
electronic warfare systems to produce effective countermeasures. Despite the
importance of these tasks, deep learning-based radar pulse activity recognition
methods have remained largely underexplored. While deep learning for radar
modulation recognition has been explored previously, classification tasks are
generally limited to short and non-interleaved IQ signals, limiting their
applicability to military applications. To address this gap, we introduce an
end-to-end multi-stage learning approach to detect and localise pulse
activities of interleaved radar signals across an extended time horizon. We
propose a simple, yet highly effective multi-stage architecture for
incrementally predicting fine-grained segmentation masks that localise radar
pulse activities across multiple channels. We demonstrate the performance of
our approach against several reference models on a novel radar dataset, while
also providing a first-of-its-kind benchmark for radar pulse activity
segmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pemasiri_A/0/1/0/all/0/1&quot;&gt;Akila Pemasiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1&quot;&gt;Simon Denman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1&quot;&gt;Clinton Fookes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_T/0/1/0/all/0/1&quot;&gt;Terrence Martin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09498">
<title>Neural Gaussian Similarity Modeling for Differential Graph Structure Learning. (arXiv:2312.09498v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09498</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Structure Learning (GSL) has demonstrated considerable potential in the
analysis of graph-unknown non-Euclidean data across a wide range of domains.
However, constructing an end-to-end graph structure learning model poses a
challenge due to the impediment of gradient flow caused by the nearest neighbor
sampling strategy. In this paper, we construct a differential graph structure
learning model by replacing the non-differentiable nearest neighbor sampling
with a differentiable sampling using the reparameterization trick. Under this
framework, we argue that the act of sampling \mbox{nearest} neighbors may not
invariably be essential, particularly in instances where node features exhibit
a significant degree of similarity. To alleviate this issue, the bell-shaped
Gaussian Similarity (GauSim) modeling is proposed to sample non-nearest
neighbors. To adaptively model the similarity, we further propose Neural
Gaussian Similarity (NeuralGauSim) with learnable parameters featuring flexible
sampling behaviors. In addition, we develop a scalable method by transferring
the large-scale graph to the transition graph to significantly reduce the
complexity. Experimental results demonstrate the effectiveness of the proposed
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1&quot;&gt;Xiaolong Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1&quot;&gt;Maoguo Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yue Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1&quot;&gt;Zedong Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jieyi Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09504">
<title>Combinatorial Complexes: Bridging the Gap Between Cell Complexes and Hypergraphs. (arXiv:2312.09504v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09504</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph-based signal processing techniques have become essential for handling
data in non-Euclidean spaces. However, there is a growing awareness that these
graph models might need to be expanded into `higher-order&apos; domains to
effectively represent the complex relations found in high-dimensional data.
Such higher-order domains are typically modeled either as hypergraphs, or as
simplicial, cubical or other cell complexes. In this context, cell complexes
are often seen as a subclass of hypergraphs with additional algebraic structure
that can be exploited, e.g., to develop a spectral theory. In this article, we
promote an alternative perspective. We argue that hypergraphs and cell
complexes emphasize \emph{different} types of relations, which may have
different utility depending on the application context. Whereas hypergraphs are
effective in modeling set-type, multi-body relations between entities, cell
complexes provide an effective means to model hierarchical,
interior-to-boundary type relations. We discuss the relative advantages of
these two choices and elaborate on the previously introduced concept of a
combinatorial complex that enables co-existing set-type and hierarchical
relations. Finally, we provide a brief numerical experiment to demonstrate that
this modelling flexibility can be advantageous in learning tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajij_M/0/1/0/all/0/1&quot;&gt;Mustafa Hajij&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamzmi_G/0/1/0/all/0/1&quot;&gt;Ghada Zamzmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papamarkou_T/0/1/0/all/0/1&quot;&gt;Theodore Papamarkou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzman_Saenz_A/0/1/0/all/0/1&quot;&gt;Aldo Guzm&amp;#xe1;n-S&amp;#xe1;enz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1&quot;&gt;Tolga Birdal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaub_M/0/1/0/all/0/1&quot;&gt;Michael T. Schaub&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09505">
<title>Adaptive Integration of Partial Label Learning and Negative Learning for Enhanced Noisy Label Learning. (arXiv:2312.09505v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09505</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been significant attention devoted to the effectiveness of various
domains, such as semi-supervised learning, contrastive learning, and
meta-learning, in enhancing the performance of methods for noisy label learning
(NLL) tasks. However, most existing methods still depend on prior assumptions
regarding clean samples amidst different sources of noise (\eg, a pre-defined
drop rate or a small subset of clean samples). In this paper, we propose a
simple yet powerful idea called \textbf{NPN}, which revolutionizes
\textbf{N}oisy label learning by integrating \textbf{P}artial label learning
(PLL) and \textbf{N}egative learning (NL). Toward this goal, we initially
decompose the given label space adaptively into the candidate and complementary
labels, thereby establishing the conditions for PLL and NL. We propose two
adaptive data-driven paradigms of label disambiguation for PLL: hard
disambiguation and soft disambiguation. Furthermore, we generate reliable
complementary labels using all non-candidate labels for NL to enhance model
robustness through indirect supervision. To maintain label reliability during
the later stage of model training, we introduce a consistency regularization
term that encourages agreement between the outputs of multiple augmentations.
Experiments conducted on both synthetically corrupted and real-world noisy
datasets demonstrate the superiority of NPN compared to other state-of-the-art
(SOTA) methods. The source code has been made available at
{\color{purple}{\url{https://github.com/NUST-Machine-Intelligence-Laboratory/NPN}}}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_M/0/1/0/all/0/1&quot;&gt;Mengmeng Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zeren Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1&quot;&gt;Zhenhuang Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yichao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yazhou Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09533">
<title>Adversarial Robustness on Image Classification with $k$-means. (arXiv:2312.09533v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09533</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we explore the challenges and strategies for enhancing the
robustness of $k$-means clustering algorithms against adversarial
manipulations. We evaluate the vulnerability of clustering algorithms to
adversarial attacks, emphasising the associated security risks. Our study
investigates the impact of incremental attack strength on training, introduces
the concept of transferability between supervised and unsupervised models, and
highlights the sensitivity of unsupervised models to sample distributions. We
additionally introduce and evaluate an adversarial training method that
improves testing performance in adversarial scenarios, and we highlight the
importance of various parameters in the proposed training method, such as
continuous learning, centroid initialisation, and adversarial step-count.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Omari_R/0/1/0/all/0/1&quot;&gt;Rollin Omari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junae Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montague_P/0/1/0/all/0/1&quot;&gt;Paul Montague&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09540">
<title>A Novel Hybrid Ordinal Learning Model with Health Care Application. (arXiv:2312.09540v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09540</link>
<description rdf:parseType="Literal">&lt;p&gt;Ordinal learning (OL) is a type of machine learning models with broad utility
in health care applications such as diagnosis of different grades of a disease
(e.g., mild, modest, severe) and prediction of the speed of disease progression
(e.g., very fast, fast, moderate, slow). This paper aims to tackle a situation
when precisely labeled samples are limited in the training set due to cost or
availability constraints, whereas there could be an abundance of samples with
imprecise labels. We focus on imprecise labels that are intervals, i.e., one
can know that a sample belongs to an interval of labels but cannot know which
unique label it has. This situation is quite common in health care datasets due
to limitations of the diagnostic instrument, sparse clinical visits, or/and
patient dropout. Limited research has been done to develop OL models with
imprecise/interval labels. We propose a new Hybrid Ordinal Learner (HOL) to
integrate samples with both precise and interval labels to train a robust OL
model. We also develop a tractable and efficient optimization algorithm to
solve the HOL formulation. We compare HOL with several recently developed OL
methods on four benchmarking datasets, which demonstrate the superior
performance of HOL. Finally, we apply HOL to a real-world dataset for
predicting the speed of progressing to Alzheimer&apos;s Disease (AD) for individuals
with Mild Cognitive Impairment (MCI) based on a combination of multi-modality
neuroimaging and demographic/clinical datasets. HOL achieves high accuracy in
the prediction and outperforms existing methods. The capability of accurately
predicting the speed of progression to AD for each individual with MCI has the
potential for helping facilitate more individually-optimized interventional
strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lujia Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hairong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yi Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lure_F/0/1/0/all/0/1&quot;&gt;Fleming Lure&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jing Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09559">
<title>STEAM &amp; MoSAFE: SOTIF Error-and-Failure Model &amp; Analysis for AI-Enabled Driving Automation. (arXiv:2312.09559v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09559</link>
<description rdf:parseType="Literal">&lt;p&gt;Driving Automation Systems (DAS) are subject to complex road environments and
vehicle behaviors and increasingly rely on sophisticated sensors and Artificial
Intelligence (AI). These properties give rise to unique safety faults stemming
from specification insufficiencies and technological performance limitations,
where sensors and AI introduce errors that vary in magnitude and temporal
patterns, posing potential safety risks. The Safety of the Intended
Functionality (SOTIF) standard emerges as a promising framework for addressing
these concerns, focusing on scenario-based analysis to identify hazardous
behaviors and their causes. Although the current standard provides a basic
cause-and-effect model and high-level process guidance, it lacks concepts
required to identify and evaluate hazardous errors, especially within the
context of AI.
&lt;/p&gt;
&lt;p&gt;This paper introduces two key contributions to bridge this gap. First, it
defines the SOTIF Temporal Error and Failure Model (STEAM) as a refinement of
the SOTIF cause-and-effect model, offering a comprehensive system-design
perspective. STEAM refines error definitions, introduces error sequences, and
classifies them as error sequence patterns, providing particular relevance to
systems employing advanced sensors and AI. Second, this paper proposes the
Model-based SOTIF Analysis of Failures and Errors (MoSAFE) method, which allows
instantiating STEAM based on system-design models by deriving hazardous error
sequence patterns at module level from hazardous behaviors at vehicle level via
weakest precondition reasoning. Finally, the paper presents a case study
centered on an automated speed-control feature, illustrating the practical
applicability of the refined model and the MoSAFE method in addressing complex
safety challenges in DAS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czarnecki_K/0/1/0/all/0/1&quot;&gt;Krzysztof Czarnecki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuwajima_H/0/1/0/all/0/1&quot;&gt;Hiroshi Kuwajima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09578">
<title>Self-Supervised Learning for Anomalous Sound Detection. (arXiv:2312.09578v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2312.09578</link>
<description rdf:parseType="Literal">&lt;p&gt;State-of-the-art anomalous sound detection (ASD) systems are often trained by
using an auxiliary classification task to learn an embedding space. Doing so
enables the system to learn embeddings that are robust to noise and are
ignoring non-target sound events but requires manually annotated meta
information to be used as class labels. However, the less difficult the
classification task becomes, the less informative are the embeddings and the
worse is the resulting ASD performance. A solution to this problem is to
utilize self-supervised learning (SSL). In this work, feature exchange
(FeatEx), a simple yet effective SSL approach for ASD, is proposed. In
addition, FeatEx is compared to and combined with existing SSL approaches. As
the main result, a new state-of-the-art performance for the DCASE2023 ASD
dataset is obtained that outperforms all other published results on this
dataset by a large margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wilkinghoff_K/0/1/0/all/0/1&quot;&gt;Kevin Wilkinghoff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09585">
<title>Joint State Estimation and Noise Identification Based on Variational Optimization. (arXiv:2312.09585v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2312.09585</link>
<description rdf:parseType="Literal">&lt;p&gt;In this article, the state estimation problems with unknown process noise and
measurement noise covariances for both linear and nonlinear systems are
considered. By formulating the joint estimation of system state and noise
parameters into an optimization problem, a novel adaptive Kalman filter method
based on conjugate-computation variational inference, referred to as CVIAKF, is
proposed to approximate the joint posterior probability density function of the
latent variables. Unlike the existing adaptive Kalman filter methods utilizing
variational inference in natural-parameter space, CVIAKF performs optimization
in expectation-parameter space, resulting in a faster and simpler solution.
Meanwhile, CVIAKF divides optimization objectives into conjugate and
non-conjugate parts of nonlinear dynamical models, whereas conjugate
computations and stochastic mirror-descent are applied, respectively.
Remarkably, the reparameterization trick is used to reduce the variance of
stochastic gradients of the non-conjugate parts. The effectiveness of CVIAKF is
validated through synthetic and real-world datasets of maneuvering target
tracking.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lan_H/0/1/0/all/0/1&quot;&gt;Hua Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shijie Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jinjie Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zengfu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jing Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09597">
<title>Deep Generative Models for Detector Signature Simulation: An Analytical Taxonomy. (arXiv:2312.09597v1 [physics.ins-det])</title>
<link>http://arxiv.org/abs/2312.09597</link>
<description rdf:parseType="Literal">&lt;p&gt;In modern collider experiments, the quest to explore fundamental interactions
between elementary particles has reached unparalleled levels of precision.
Signatures from particle physics detectors are low-level objects encoding the
physics of collisions. The complete simulation of them in a detector is a
memory and storage-intensive task. To address this computational bottleneck in
particle physics, &quot;Fast Simulation&quot; has been introduced and refined over the
years. The field has seen a surge in interest in surrogate modeling the
detector simulation, fueled by the advancements in deep generative models.
These models aim to generate responses that are statistically identical to the
observed data. In this paper, we conduct a comprehensive and exhaustive
taxonomic review of the existing literature on the simulation of detector
signatures from both methodological and application-wise perspectives.
Initially, we formulate the problem of detector signature simulation and
discuss its different variations that can be unified. Next, we classify the
state-of-the-art methods into four distinct categories based on their
underlying model architectures, summarizing their respective generation
strategies. We then identify and discuss three key application areas. Finally,
we shed light on the challenges and opportunities that lie ahead in detector
signature simulation, setting the stage for future research and development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hashemi_H/0/1/0/all/0/1&quot;&gt;Hosein Hashemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Krause_C/0/1/0/all/0/1&quot;&gt;Claudius Krause&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09601">
<title>Binary Code Summarization: Benchmarking ChatGPT/GPT-4 and Other Large Language Models. (arXiv:2312.09601v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.09601</link>
<description rdf:parseType="Literal">&lt;p&gt;Binary code summarization, while invaluable for understanding code semantics,
is challenging due to its labor-intensive nature. This study delves into the
potential of large language models (LLMs) for binary code comprehension. To
this end, we present BinSum, a comprehensive benchmark and dataset of over 557K
binary functions and introduce a novel method for prompt synthesis and
optimization. To more accurately gauge LLM performance, we also propose a new
semantic similarity metric that surpasses traditional exact-match approaches.
Our extensive evaluation of prominent LLMs, including ChatGPT, GPT-4, Llama 2,
and Code Llama, reveals 10 pivotal insights. This evaluation generates 4
billion inference tokens, incurred a total expense of 11,418 US dollars and 873
NVIDIA A100 GPU hours. Our findings highlight both the transformative potential
of LLMs in this field and the challenges yet to be overcome.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1&quot;&gt;Xin Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larson_J/0/1/0/all/0/1&quot;&gt;Jonathan Larson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1&quot;&gt;Weiwei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09603">
<title>Stethoscope-guided Supervised Contrastive Learning for Cross-domain Adaptation on Respiratory Sound Classification. (arXiv:2312.09603v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2312.09603</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the remarkable advances in deep learning technology, achieving
satisfactory performance in lung sound classification remains a challenge due
to the scarcity of available data. Moreover, the respiratory sound samples are
collected from a variety of electronic stethoscopes, which could potentially
introduce biases into the trained models. When a significant distribution shift
occurs within the test dataset or in a practical scenario, it can substantially
decrease the performance. To tackle this issue, we introduce cross-domain
adaptation techniques, which transfer the knowledge from a source domain to a
distinct target domain. In particular, by considering different stethoscope
types as individual domains, we propose a novel stethoscope-guided supervised
contrastive learning approach. This method can mitigate any domain-related
disparities and thus enables the model to distinguish respiratory sounds of the
recording variation of the stethoscope. The experimental results on the ICBHI
dataset demonstrate that the proposed methods are effective in reducing the
domain dependency and achieving the ICBHI Score of 61.71%, which is a
significant improvement of 2.16% over the baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;June-Woo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1&quot;&gt;Sangmin Bae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1&quot;&gt;Won-Yang Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1&quot;&gt;Byungjo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1&quot;&gt;Ho-Young Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09606">
<title>Reliable Prediction Intervals with Regression Neural Networks. (arXiv:2312.09606v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09606</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes an extension to conventional regression Neural Networks
(NNs) for replacing the point predictions they produce with prediction
intervals that satisfy a required level of confidence. Our approach follows a
novel machine learning framework, called Conformal Prediction (CP), for
assigning reliable confidence measures to predictions without assuming anything
more than that the data are independent and identically distributed (i.i.d.).
We evaluate the proposed method on four benchmark datasets and on the problem
of predicting Total Electron Content (TEC), which is an important parameter in
trans-ionospheric links; for the latter we use a dataset of more than 60000 TEC
measurements collected over a period of 11 years. Our experimental results show
that the prediction intervals produced by our method are both well-calibrated
and tight enough to be useful in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papadopoulos_H/0/1/0/all/0/1&quot;&gt;Harris Papadopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haralambous_H/0/1/0/all/0/1&quot;&gt;Haris Haralambous&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09610">
<title>A Synthesis of Green Architectural Tactics for ML-Enabled Systems. (arXiv:2312.09610v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2312.09610</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid adoption of artificial intelligence (AI) and machine learning (ML)
has generated growing interest in understanding their environmental impact and
the challenges associated with designing environmentally friendly ML-enabled
systems. While Green AI research, i.e., research that tries to minimize the
energy footprint of AI, is receiving increasing attention, very few concrete
guidelines are available on how ML-enabled systems can be designed to be more
environmentally sustainable. In this paper, we provide a catalog of 30 green
architectural tactics for ML-enabled systems to fill this gap. An architectural
tactic is a high-level design technique to improve software quality, in our
case environmental sustainability. We derived the tactics from the analysis of
51 peer-reviewed publications that primarily explore Green AI, and validated
them using a focus group approach with three experts. The 30 tactics we
identified are aimed to serve as an initial reference guide for further
exploration into Green AI from a software engineering perspective, and assist
in designing sustainable ML-enabled systems. To enhance transparency and
facilitate their widespread use and extension, we make the tactics available
online in easily consumable formats. Wide-spread adoption of these tactics has
the potential to substantially reduce the societal impact of ML-enabled systems
regarding their energy and carbon footprint.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jarvenpaa_H/0/1/0/all/0/1&quot;&gt;Heli J&amp;#xe4;rvenp&amp;#xe4;&amp;#xe4;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lago_P/0/1/0/all/0/1&quot;&gt;Patricia Lago&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bogner_J/0/1/0/all/0/1&quot;&gt;Justus Bogner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lewis_G/0/1/0/all/0/1&quot;&gt;Grace Lewis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muccini_H/0/1/0/all/0/1&quot;&gt;Henry Muccini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozkaya_I/0/1/0/all/0/1&quot;&gt;Ipek Ozkaya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09613">
<title>Rethinking Causal Relationships Learning in Graph Neural Networks. (arXiv:2312.09613v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09613</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) demonstrate their significance by effectively
modeling complex interrelationships within graph-structured data. To enhance
the credibility and robustness of GNNs, it becomes exceptionally crucial to
bolster their ability to capture causal relationships. However, despite recent
advancements that have indeed strengthened GNNs from a causal learning
perspective, conducting an in-depth analysis specifically targeting the causal
modeling prowess of GNNs remains an unresolved issue. In order to
comprehensively analyze various GNN models from a causal learning perspective,
we constructed an artificially synthesized dataset with known and controllable
causal relationships between data and labels. The rationality of the generated
data is further ensured through theoretical foundations. Drawing insights from
analyses conducted using our dataset, we introduce a lightweight and highly
adaptable GNN module designed to strengthen GNNs&apos; causal learning capabilities
across a diverse range of tasks. Through a series of experiments conducted on
both synthetic datasets and other real-world datasets, we empirically validate
the effectiveness of the proposed module.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1&quot;&gt;Hang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_C/0/1/0/all/0/1&quot;&gt;Chengyu Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiangmeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1&quot;&gt;Lingyu Si&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yifan Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fengge Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Changwen Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Huaping Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09623">
<title>A novel dual-stream time-frequency contrastive pretext tasks framework for sleep stage classification. (arXiv:2312.09623v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2312.09623</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning addresses the challenge encountered by many
supervised methods, i.e. the requirement of large amounts of annotated data.
This challenge is particularly pronounced in fields such as the
electroencephalography (EEG) research domain. Self-supervised learning operates
instead by utilizing pseudo-labels, which are generated by pretext tasks, to
obtain a rich and meaningful data representation. In this study, we aim at
introducing a dual-stream pretext task architecture that operates both in the
time and frequency domains. In particular, we have examined the incorporation
of the novel Frequency Similarity (FS) pretext task into two existing pretext
tasks, Relative Positioning (RP) and Temporal Shuffling (TS). We assess the
accuracy of these models using the Physionet Challenge 2018 (PC18) dataset in
the context of the downstream task sleep stage classification. The inclusion of
FS resulted in a notable improvement in downstream task accuracy, with a 1.28
percent improvement on RP and a 2.02 percent improvement on TS. Furthermore,
when visualizing the learned embeddings using Uniform Manifold Approximation
and Projection (UMAP), distinct clusters emerge, indicating that the learned
representations carry meaningful information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kazatzidis_S/0/1/0/all/0/1&quot;&gt;Sergio Kazatzidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mehrkanoon_S/0/1/0/all/0/1&quot;&gt;Siamak Mehrkanoon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09627">
<title>TF-CLIP: Learning Text-free CLIP for Video-based Person Re-Identification. (arXiv:2312.09627v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.09627</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale language-image pre-trained models (e.g., CLIP) have shown
superior performances on many cross-modal retrieval tasks. However, the problem
of transferring the knowledge learned from such models to video-based person
re-identification (ReID) has barely been explored. In addition, there is a lack
of decent text descriptions in current ReID benchmarks. To address these
issues, in this work, we propose a novel one-stage text-free CLIP-based
learning framework named TF-CLIP for video-based person ReID. More
specifically, we extract the identity-specific sequence feature as the
CLIP-Memory to replace the text feature. Meanwhile, we design a
Sequence-Specific Prompt (SSP) module to update the CLIP-Memory online. To
capture temporal information, we further propose a Temporal Memory Diffusion
(TMD) module, which consists of two key components: Temporal Memory
Construction (TMC) and Memory Diffusion (MD). Technically, TMC allows the
frame-level memories in a sequence to communicate with each other, and to
extract temporal information based on the relations within the sequence. MD
further diffuses the temporal memories to each token in the original features
to obtain more robust sequence features. Extensive experiments demonstrate that
our proposed method shows much better results than other state-of-the-art
methods on MARS, LS-VID and iLIDS-VID. The code is available at
https://github.com/AsuradaYuci/TF-CLIP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chenyang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xuehu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yingquan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pingping Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1&quot;&gt;Huchuan Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09634">
<title>Vectorizing string entries for data processing on tables: when are larger language models better?. (arXiv:2312.09634v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.09634</link>
<description rdf:parseType="Literal">&lt;p&gt;There are increasingly efficient data processing pipelines that work on
vectors of numbers, for instance most machine learning models, or vector
databases for fast similarity search. These require converting the data to
numbers. While this conversion is easy for simple numerical and categorical
entries, databases are strife with text entries, such as names or descriptions.
In the age of large language models, what&apos;s the best strategies to vectorize
tables entries, baring in mind that larger models entail more operational
complexity? We study the benefits of language models in 14 analytical tasks on
tables while varying the training size, as well as for a fuzzy join benchmark.
We introduce a simple characterization of a column that reveals two settings:
1) a dirty categories setting, where strings share much similarities across
entries, and conversely 2) a diverse entries setting. For dirty categories,
pretrained language models bring little-to-no benefit compared to simpler
string models. For diverse entries, we show that larger language models improve
data processing. For these we investigate the complexity-performance tradeoffs
and show that they reflect those of classic text embedding: larger models tend
to perform better, but it is useful to fine tune them for embedding purposes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grinsztajn_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe9;o Grinsztajn&lt;/a&gt; (SODA, MLIA, ISIR), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oyallon_E/0/1/0/all/0/1&quot;&gt;Edouard Oyallon&lt;/a&gt; (MLIA, CNRS, ISIR, SU), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Myung Jun Kim&lt;/a&gt; (SODA), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Varoquaux_G/0/1/0/all/0/1&quot;&gt;Ga&amp;#xeb;l Varoquaux&lt;/a&gt; (SODA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09636">
<title>A Malware Classification Survey on Adversarial Attacks and Defences. (arXiv:2312.09636v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2312.09636</link>
<description rdf:parseType="Literal">&lt;p&gt;As the number and complexity of malware attacks continue to increase, there
is an urgent need for effective malware detection systems. While deep learning
models are effective at detecting malware, they are vulnerable to adversarial
attacks. Attacks like this can create malicious files that are resistant to
detection, creating a significant cybersecurity risk. Recent research has seen
the development of several adversarial attack and response approaches aiming at
strengthening deep learning models&apos; resilience to such attacks. This survey
study offers an in-depth look at current research in adversarial attack and
defensive strategies for malware classification in cybersecurity. The methods
are classified into four categories: generative models, feature-based
approaches, ensemble methods, and hybrid tactics. The article outlines
cutting-edge procedures within each area, assessing their benefits and
drawbacks. Each topic presents cutting-edge approaches and explores their
advantages and disadvantages. In addition, the study discusses the datasets and
assessment criteria that are often utilized on this subject. Finally, it
identifies open research difficulties and suggests future study options. This
document is a significant resource for malware categorization and cyber
security researchers and practitioners.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponnuru_M/0/1/0/all/0/1&quot;&gt;Mahesh Datta Sai Ponnuru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amasala_L/0/1/0/all/0/1&quot;&gt;Likhitha Amasala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhimavarapu_T/0/1/0/all/0/1&quot;&gt;Tanu Sree Bhimavarapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garikipati_G/0/1/0/all/0/1&quot;&gt;Guna Chaitanya Garikipati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09639">
<title>Multiple Instance Learning for Uplift Modeling. (arXiv:2312.09639v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09639</link>
<description rdf:parseType="Literal">&lt;p&gt;Uplift modeling is widely used in performance marketing to estimate effects
of promotion campaigns (e.g., increase of customer retention rate). Since it is
impossible to observe outcomes of a recipient in treatment (e.g., receiving a
certain promotion) and control (e.g., without promotion) groups simultaneously
(i.e., counter-factual), uplift models are mainly trained on instances of
treatment and control groups separately to form two models respectively, and
uplifts are predicted by the difference of predictions from these two models
(i.e., two-model method). When responses are noisy and the treatment effect is
fractional, induced individual uplift predictions will be inaccurate, resulting
in targeting undesirable customers. Though it is impossible to obtain the ideal
ground-truth individual uplifts, known as Individual Treatment Effects (ITEs),
alternatively, an average uplift of a group of users, called Average Treatment
Effect (ATE), can be observed from experimental deliveries. Upon this, similar
to Multiple Instance Learning (MIL) in which each training sample is a bag of
instances, our framework sums up individual user uplift predictions for each
bag of users as its bag-wise ATE prediction, and regularizes it to its ATE
label, thus learning more accurate individual uplifts. Additionally, to amplify
the fractional treatment effect, bags are composed of instances with adjacent
individual uplift predictions, instead of random instances. Experiments
conducted on two datasets show the effectiveness and universality of the
proposed framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yao Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haipeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1&quot;&gt;Shiwei Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Ruiying Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jinjie Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Guannan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09651">
<title>What to Remember: Self-Adaptive Continual Learning for Audio Deepfake Detection. (arXiv:2312.09651v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2312.09651</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid evolution of speech synthesis and voice conversion has raised
substantial concerns due to the potential misuse of such technology, prompting
a pressing need for effective audio deepfake detection mechanisms. Existing
detection models have shown remarkable success in discriminating known deepfake
audio, but struggle when encountering new attack types. To address this
challenge, one of the emergent effective approaches is continual learning. In
this paper, we propose a continual learning approach called Radian Weight
Modification (RWM) for audio deepfake detection. The fundamental concept
underlying RWM involves categorizing all classes into two groups: those with
compact feature distributions across tasks, such as genuine audio, and those
with more spread-out distributions, like various types of fake audio. These
distinctions are quantified by means of the in-class cosine distance, which
subsequently serves as the basis for RWM to introduce a trainable gradient
modification direction for distinct data types. Experimental evaluations
against mainstream continual learning methods reveal the superiority of RWM in
terms of knowledge acquisition and mitigating forgetting in audio deepfake
detection. Furthermore, RWM&apos;s applicability extends beyond audio deepfake
detection, demonstrating its potential significance in diverse machine learning
domains such as image recognition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaohui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1&quot;&gt;Jiangyan Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chenglong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chuyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1&quot;&gt;Siding Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1&quot;&gt;Jianhua Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09663">
<title>Toward Deep Drum Source Separation. (arXiv:2312.09663v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2312.09663</link>
<description rdf:parseType="Literal">&lt;p&gt;In the past, the field of drum source separation faced significant challenges
due to limited data availability, hindering the adoption of cutting-edge deep
learning methods that have found success in other related audio applications.
In this manuscript, we introduce StemGMD, a large-scale audio dataset of
isolated single-instrument drum stems. Each audio clip is synthesized from MIDI
recordings of expressive drums performances using ten real-sounding acoustic
drum kits. Totaling 1224 hours, StemGMD is the largest audio dataset of drums
to date and the first to comprise isolated audio clips for every instrument in
a canonical nine-piece drum kit. We leverage StemGMD to develop LarsNet, a
novel deep drum source separation model. Through a bank of dedicated U-Nets,
LarsNet can separate five stems from a stereo drum mixture faster than
real-time and is shown to significantly outperform state-of-the-art nonnegative
spectro-temporal factorization methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mezza_A/0/1/0/all/0/1&quot;&gt;Alessandro Ilic Mezza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Giampiccolo_R/0/1/0/all/0/1&quot;&gt;Riccardo Giampiccolo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bernardini_A/0/1/0/all/0/1&quot;&gt;Alberto Bernardini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sarti_A/0/1/0/all/0/1&quot;&gt;Augusto Sarti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09673">
<title>Style Generation in Robot Calligraphy with Deep Generative Adversarial Networks. (arXiv:2312.09673v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.09673</link>
<description rdf:parseType="Literal">&lt;p&gt;Robot calligraphy is an emerging exploration of artificial intelligence in
the fields of art and education. Traditional calligraphy generation researches
mainly focus on methods such as tool-based image processing, generative models,
and style transfer. Unlike the English alphabet, the number of Chinese
characters is tens of thousands, which leads to difficulties in the generation
of a style consistent Chinese calligraphic font with over 6000 characters. Due
to the lack of high-quality data sets, formal definitions of calligraphy
knowledge, and scientific art evaluation methods, The results generated are
frequently of low quality and falls short of professional-level requirements.
To address the above problem, this paper proposes an automatic calligraphy
generation model based on deep generative adversarial networks (deepGAN) that
can generate style calligraphy fonts with professional standards. The key
highlights of the proposed method include: (1) The datasets use a
high-precision calligraphy synthesis method to ensure its high quality and
sufficient quantity; (2) Professional calligraphers are invited to conduct a
series of Turing tests to evaluate the gap between model generation results and
human artistic level; (3) Experimental results indicate that the proposed model
is the state-of-the-art among current calligraphy generation methods. The
Turing tests and similarity evaluations validate the effectiveness of the
proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaoming Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1&quot;&gt;Zhiguo Gong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09674">
<title>Optimal Regret Bounds for Collaborative Learning in Bandits. (arXiv:2312.09674v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09674</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider regret minimization in a general collaborative multi-agent
multi-armed bandit model, in which each agent faces a finite set of arms and
may communicate with other agents through a central controller. The optimal arm
for each agent in this model is the arm with the largest expected mixed reward,
where the mixed reward of each arm is a weighted average of its rewards across
all agents, making communication among agents crucial. While near-optimal
sample complexities for best arm identification are known under this
collaborative model, the question of optimal regret remains open. In this work,
we address this problem and propose the first algorithm with order optimal
regret bounds under this collaborative bandit model. Furthermore, we show that
only a small constant number of expected communication rounds is needed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shidani_A/0/1/0/all/0/1&quot;&gt;Amitis Shidani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vakili_S/0/1/0/all/0/1&quot;&gt;Sattar Vakili&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09681">
<title>Urban Region Embedding via Multi-View Contrastive Prediction. (arXiv:2312.09681v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09681</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, learning urban region representations utilizing multi-modal data
(information views) has become increasingly popular, for deep understanding of
the distributions of various socioeconomic features in cities. However,
previous methods usually blend multi-view information in a posteriors stage,
falling short in learning coherent and consistent representations across
different views. In this paper, we form a new pipeline to learn consistent
representations across varying views, and propose the multi-view Contrastive
Prediction model for urban Region embedding (ReCP), which leverages the
multiple information views from point-of-interest (POI) and human mobility
data. Specifically, ReCP comprises two major modules, namely an intra-view
learning module utilizing contrastive learning and feature reconstruction to
capture the unique information from each single view, and inter-view learning
module that perceives the consistency between the two views using a contrastive
prediction learning scheme. We conduct thorough experiments on two downstream
tasks to assess the proposed model, i.e., land use clustering and region
popularity prediction. The experimental results demonstrate that our model
outperforms state-of-the-art baseline methods significantly in urban region
representation learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zechen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Weiming Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1&quot;&gt;Kai Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Min Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1&quot;&gt;Yongshun Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Meng Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09691">
<title>Quilt: Robust Data Segment Selection against Concept Drifts. (arXiv:2312.09691v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09691</link>
<description rdf:parseType="Literal">&lt;p&gt;Continuous machine learning pipelines are common in industrial settings where
models are periodically trained on data streams. Unfortunately, concept drifts
may occur in data streams where the joint distribution of the data X and label
y, P(X, y), changes over time and possibly degrade model accuracy. Existing
concept drift adaptation approaches mostly focus on updating the model to the
new data possibly using ensemble techniques of previous models and tend to
discard the drifted historical data. However, we contend that explicitly
utilizing the drifted data together leads to much better model accuracy and
propose Quilt, a data-centric framework for identifying and selecting data
segments that maximize model accuracy. To address the potential downside of
efficiency, Quilt extends existing data subset selection techniques, which can
be used to reduce the training data without compromising model accuracy. These
techniques cannot be used as is because they only assume virtual drifts where
the posterior probabilities P(y|X) are assumed not to change. In contrast, a
key challenge in our setup is to also discard undesirable data segments with
concept drifts. Quilt thus discards drifted data segments and selects data
segment subsets holistically for accurate and efficient model training. The two
operations use gradient-based scores, which have little computation overhead.
In our experiments, we show that Quilt outperforms state-of-the-art drift
adaptation and data selection baselines on synthetic and real datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Minsu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1&quot;&gt;Seong-Hyeon Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whang_S/0/1/0/all/0/1&quot;&gt;Steven Euijong Whang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09708">
<title>GraphRARE: Reinforcement Learning Enhanced Graph Neural Network with Relative Entropy. (arXiv:2312.09708v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09708</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks (GNNs) have shown advantages in graph-based analysis
tasks. However, most existing methods have the homogeneity assumption and show
poor performance on heterophilic graphs, where the linked nodes have dissimilar
features and different class labels, and the semantically related nodes might
be multi-hop away. To address this limitation, this paper presents GraphRARE, a
general framework built upon node relative entropy and deep reinforcement
learning, to strengthen the expressive capability of GNNs. An innovative node
relative entropy, which considers node features and structural similarity, is
used to measure mutual information between node pairs. In addition, to avoid
the sub-optimal solutions caused by mixing useful information and noises of
remote nodes, a deep reinforcement learning-based algorithm is developed to
optimize the graph topology. This algorithm selects informative nodes and
discards noisy nodes based on the defined node relative entropy. Extensive
experiments are conducted on seven real-world datasets. The experimental
results demonstrate the superiority of GraphRARE in node classification and its
capability to optimize the original graph topology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_T/0/1/0/all/0/1&quot;&gt;Tianhao Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1&quot;&gt;Wenjun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1&quot;&gt;Haitao Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pengrui_Z/0/1/0/all/0/1&quot;&gt;Zhao Pengrui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xin Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xuetao Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yanjun Pu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09734">
<title>Learning of Hamiltonian Dynamics with Reproducing Kernel Hilbert Spaces. (arXiv:2312.09734v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.09734</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a method for learning Hamiltonian dynamics from a limited
set of data points. The Hamiltonian vector field is found by regularized
optimization over a reproducing kernel Hilbert space of vector fields that are
inherently Hamiltonian, and where the vector field is required to be odd or
even. This is done with a symplectic kernel, and it is shown how this
symplectic kernel can be modified to be odd or even. The performance of the
method is validated in simulations for two Hamiltonian systems. It is shown
that the learned dynamics are Hamiltonian, and that the learned Hamiltonian
vector field can be prescribed to be odd or even.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_T/0/1/0/all/0/1&quot;&gt;Torbj&amp;#xf8;rn Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Egeland_O/0/1/0/all/0/1&quot;&gt;Olav Egeland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09741">
<title>PELP: Pioneer Event Log Prediction Using Sequence-to-Sequence Neural Networks. (arXiv:2312.09741v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09741</link>
<description rdf:parseType="Literal">&lt;p&gt;Process mining, a data-driven approach for analyzing, visualizing, and
improving business processes using event logs, has emerged as a powerful
technique in the field of business process management. Process forecasting is a
sub-field of process mining that studies how to predict future processes and
process models. In this paper, we introduce and motivate the problem of event
log prediction and present our approach to solving the event log prediction
problem, in particular, using the sequence-to-sequence deep learning approach.
We evaluate and analyze the prediction outcomes on a variety of synthetic logs
and seven real-life logs and show that our approach can generate perfect
predictions on synthetic logs and that deep learning techniques have the
potential to be applied in real-world event log prediction tasks. We further
provide practical recommendations for event log predictions grounded in the
outcomes of the conducted experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wenjun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polyvyanyy_A/0/1/0/all/0/1&quot;&gt;Artem Polyvyanyy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bailey_J/0/1/0/all/0/1&quot;&gt;James Bailey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09744">
<title>Bridging the Semantic-Numerical Gap: A Numerical Reasoning Method of Cross-modal Knowledge Graph for Material Property Prediction. (arXiv:2312.09744v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09744</link>
<description rdf:parseType="Literal">&lt;p&gt;Using machine learning (ML) techniques to predict material properties is a
crucial research topic. These properties depend on numerical data and semantic
factors. Due to the limitations of small-sample datasets, existing methods
typically adopt ML algorithms to regress numerical properties or transfer other
pre-trained knowledge graphs (KGs) to the material. However, these methods
cannot simultaneously handle semantic and numerical information. In this paper,
we propose a numerical reasoning method for material KGs (NR-KG), which
constructs a cross-modal KG using semantic nodes and numerical proxy nodes. It
captures both types of information by projecting KG into a canonical KG and
utilizes a graph neural network to predict material properties. In this
process, a novel projection prediction loss is proposed to extract semantic
features from numerical information. NR-KG facilitates end-to-end processing of
cross-modal data, mining relationships and cross-modal information in
small-sample datasets, and fully utilizes valuable experimental data to enhance
material prediction. We further propose two new High-Entropy Alloys (HEA)
property datasets with semantic descriptions. NR-KG outperforms
state-of-the-art (SOTA) methods, achieving relative improvements of 25.9% and
16.1% on two material datasets. Besides, NR-KG surpasses SOTA methods on two
public physical chemistry molecular datasets, showing improvements of 22.2% and
54.3%, highlighting its potential application and generalizability. We hope the
proposed datasets, algorithms, and pre-trained models can facilitate the
communities of KG and AI for materials.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1&quot;&gt;Guangxuan Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1&quot;&gt;Dongmei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_Z/0/1/0/all/0/1&quot;&gt;Zhongwei Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zijiang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1&quot;&gt;Jiaxin Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lingwei Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dawei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09748">
<title>Verification-Friendly Deep Neural Networks. (arXiv:2312.09748v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09748</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning techniques often lack formal correctness guarantees. This is
evidenced by the widespread adversarial examples that plague most deep-learning
applications. This resulted in several research efforts that aim at verifying
deep neural networks, with a particular focus on safety-critical applications.
However, formal verification techniques still face major scalability and
precision challenges when dealing with the complexity of such networks. The
over-approximation introduced during the formal verification process to tackle
the scalability challenge often results in inconclusive analysis. To address
this challenge, we propose a novel framework to generate Verification-friendly
Neural Networks (VNNs). We present a post-training optimization framework to
achieve a balance between preserving prediction performance and robustness in
the resulting networks. Our proposed framework proves to result in networks
that are comparable to the original ones in terms of prediction performance,
while amenable to verification. This essentially enables us to establish
robustness for more VNNs than their deep neural network counterparts, in a more
time-efficient manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baninajjar_A/0/1/0/all/0/1&quot;&gt;Anahita Baninajjar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezine_A/0/1/0/all/0/1&quot;&gt;Ahmed Rezine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aminifar_A/0/1/0/all/0/1&quot;&gt;Amir Aminifar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09758">
<title>Diagnosing and Rectifying Fake OOD Invariance: A Restructured Causal Approach. (arXiv:2312.09758v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09758</link>
<description rdf:parseType="Literal">&lt;p&gt;Invariant representation learning (IRL) encourages the prediction from
invariant causal features to labels de-confounded from the environments,
advancing the technical roadmap of out-of-distribution (OOD) generalization.
Despite spotlights around, recent theoretical results verified that some causal
features recovered by IRLs merely pretend domain-invariantly in the training
environments but fail in unseen domains. The \emph{fake invariance} severely
endangers OOD generalization since the trustful objective can not be diagnosed
and existing causal surgeries are invalid to rectify. In this paper, we review
a IRL family (InvRat) under the Partially and Fully Informative Invariant
Feature Structural Causal Models (PIIF SCM /FIIF SCM) respectively, to certify
their weaknesses in representing fake invariant features, then, unify their
causal diagrams to propose ReStructured SCM (RS-SCM). RS-SCM can ideally
rebuild the spurious and the fake invariant features simultaneously. Given
this, we further develop an approach based on conditional mutual information
with respect to RS-SCM, then rigorously rectify the spurious and fake invariant
effects. It can be easily implemented by a small feature selection subnet
introduced in the IRL family, which is alternatively optimized to achieve our
goal. Experiments verified the superiority of our approach to fight against the
fake invariant issue across a variety of OOD generalization benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Ziliang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yongsen Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1&quot;&gt;Zhao-Rong Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_Q/0/1/0/all/0/1&quot;&gt;Quanlong Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Liang Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09766">
<title>Celestial Machine Learning: From Data to Mars and Beyond with AI Feynman. (arXiv:2312.09766v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09766</link>
<description rdf:parseType="Literal">&lt;p&gt;Can a machine or algorithm discover or learn Kepler&apos;s first law from
astronomical sightings alone? We emulate Johannes Kepler&apos;s discovery of the
equation of the orbit of Mars with the Rudolphine tables using AI Feynman, a
physics-inspired tool for symbolic regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoo_Z/0/1/0/all/0/1&quot;&gt;Zi-Yu Khoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1&quot;&gt;Abel Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Low_J/0/1/0/all/0/1&quot;&gt;Jonathan Sze Choong Low&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bressan_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Bressan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09775">
<title>A Comparative Evaluation of Additive Separability Tests for Physics-Informed Machine Learning. (arXiv:2312.09775v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09775</link>
<description rdf:parseType="Literal">&lt;p&gt;Many functions characterising physical systems are additively separable. This
is the case, for instance, of mechanical Hamiltonian functions in physics,
population growth equations in biology, and consumer preference and utility
functions in economics. We consider the scenario in which a surrogate of a
function is to be tested for additive separability. The detection that the
surrogate is additively separable can be leveraged to improve further learning.
Hence, it is beneficial to have the ability to test for such separability in
surrogates. The mathematical approach is to test if the mixed partial
derivative of the surrogate is zero; or empirically, lower than a threshold. We
present and comparatively and empirically evaluate the eight methods to compute
the mixed partial derivative of a surrogate function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoo_Z/0/1/0/all/0/1&quot;&gt;Zi-Yu Khoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Low_J/0/1/0/all/0/1&quot;&gt;Jonathan Sze Choong Low&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bressan_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Bressan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09778">
<title>Hypergraph-MLP: Learning on Hypergraphs without Message Passing. (arXiv:2312.09778v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09778</link>
<description rdf:parseType="Literal">&lt;p&gt;Hypergraphs are vital in modelling data with higher-order relations
containing more than two entities, gaining prominence in machine learning and
signal processing. Many hypergraph neural networks leverage message passing
over hypergraph structures to enhance node representation learning, yielding
impressive performances in tasks like hypergraph node classification. However,
these message-passing-based models face several challenges, including
oversmoothing as well as high latency and sensitivity to structural
perturbations at inference time. To tackle those challenges, we propose an
alternative approach where we integrate the information about hypergraph
structures into training supervision without explicit message passing, thus
also removing the reliance on it at inference. Specifically, we introduce
Hypergraph-MLP, a novel learning framework for hypergraph-structured data,
where the learning model is a straightforward multilayer perceptron (MLP)
supervised by a loss function based on a notion of signal smoothness on
hypergraphs. Experiments on hypergraph node classification tasks demonstrate
that Hypergraph-MLP achieves competitive performance compared to existing
baselines, and is considerably faster and more robust against structural
perturbations at inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1&quot;&gt;Bohan Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Siheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1&quot;&gt;Xiaowen Dong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09783">
<title>Keep the Faith: Faithful Explanations in Convolutional Neural Networks for Case-Based Reasoning. (arXiv:2312.09783v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09783</link>
<description rdf:parseType="Literal">&lt;p&gt;Explaining predictions of black-box neural networks is crucial when applied
to decision-critical tasks. Thus, attribution maps are commonly used to
identify important image regions, despite prior work showing that humans prefer
explanations based on similar examples. To this end, ProtoPNet learns a set of
class-representative feature vectors (prototypes) for case-based reasoning.
During inference, similarities of latent features to prototypes are linearly
classified to form predictions and attribution maps are provided to explain the
similarity. In this work, we evaluate whether architectures for case-based
reasoning fulfill established axioms required for faithful explanations using
the example of ProtoPNet. We show that such architectures allow the extraction
of faithful explanations. However, we prove that the attribution maps used to
explain the similarities violate the axioms. We propose a new procedure to
extract explanations for trained ProtoPNets, named ProtoPFaith. Conceptually,
these explanations are Shapley values, calculated on the similarity scores of
each prototype. They allow to faithfully answer which prototypes are present in
an unseen image and quantify each pixel&apos;s contribution to that presence,
thereby complying with all axioms. The theoretical violations of ProtoPNet
manifest in our experiments on three datasets (CUB-200-2011, Stanford Dogs,
RSNA) and five architectures (ConvNet, ResNet, ResNet50, WideResNet50,
ResNeXt50). Our experiments show a qualitative difference between the
explanations given by ProtoPNet and ProtoPFaith. Additionally, we quantify the
explanations with the Area Over the Perturbation Curve, on which ProtoPFaith
outperforms ProtoPNet on all experiments by a factor $&amp;gt;10^3$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_T/0/1/0/all/0/1&quot;&gt;Tom Nuno Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bongratz_F/0/1/0/all/0/1&quot;&gt;Fabian Bongratz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rickmann_A/0/1/0/all/0/1&quot;&gt;Anne-Marie Rickmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polsterl_S/0/1/0/all/0/1&quot;&gt;Sebastian P&amp;#xf6;lsterl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1&quot;&gt;Christian Wachinger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09787">
<title>Physics-informed Neural Network Estimation of Material Properties in Soft Tissue Nonlinear Biomechanical Models. (arXiv:2312.09787v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09787</link>
<description rdf:parseType="Literal">&lt;p&gt;The development of biophysical models for clinical applications is rapidly
advancing in the research community, thanks to their predictive nature and
their ability to assist the interpretation of clinical data. However,
high-resolution and accurate multi-physics computational models are
computationally expensive and their personalisation involves fine calibration
of a large number of parameters, which may be space-dependent, challenging
their clinical translation. In this work, we propose a new approach which
relies on the combination of physics-informed neural networks (PINNs) with
three-dimensional soft tissue nonlinear biomechanical models, capable of
reconstructing displacement fields and estimating heterogeneous
patient-specific biophysical properties. The proposed learning algorithm
encodes information from a limited amount of displacement and, in some cases,
strain data, that can be routinely acquired in the clinical setting, and
combines it with the physics of the problem, represented by a mathematical
model based on partial differential equations, to regularise the problem and
improve its convergence properties. Several benchmarks are presented to show
the accuracy and robustness of the proposed method and its great potential to
enable the robust and effective identification of patient-specific,
heterogeneous physical properties, s.a. tissue stiffness properties. In
particular, we demonstrate the capability of the PINN to detect the presence,
location and severity of scar tissue, which is beneficial to develop
personalised simulation models for disease diagnosis, especially for cardiac
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caforio_F/0/1/0/all/0/1&quot;&gt;Federica Caforio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regazzoni_F/0/1/0/all/0/1&quot;&gt;Francesco Regazzoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pagani_S/0/1/0/all/0/1&quot;&gt;Stefano Pagani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karabelas_E/0/1/0/all/0/1&quot;&gt;Elias Karabelas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Augustin_C/0/1/0/all/0/1&quot;&gt;Christoph Augustin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haase_G/0/1/0/all/0/1&quot;&gt;Gundolf Haase&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plank_G/0/1/0/all/0/1&quot;&gt;Gernot Plank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quarteroni_A/0/1/0/all/0/1&quot;&gt;Alfio Quarteroni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09788">
<title>Collaborating Foundation models for Domain Generalized Semantic Segmentation. (arXiv:2312.09788v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.09788</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain Generalized Semantic Segmentation (DGSS) deals with training a model
on a labeled source domain with the aim of generalizing to unseen domains
during inference. Existing DGSS methods typically effectuate robust features by
means of Domain Randomization (DR). Such an approach is often limited as it can
only account for style diversification and not content. In this work, we take
an orthogonal approach to DGSS and propose to use an assembly of CoLlaborative
FOUndation models for Domain Generalized Semantic Segmentation (CLOUDS). In
detail, CLOUDS is a framework that integrates FMs of various kinds: (i) CLIP
backbone for its robust feature representation, (ii) generative models to
diversify the content, thereby covering various modes of the possible target
distribution, and (iii) Segment Anything Model (SAM) for iteratively refining
the predictions of the segmentation model. Extensive experiments show that our
CLOUDS excels in adapting from synthetic to real DGSS benchmarks and under
varying weather conditions, notably outperforming prior methods by 5.6% and
6.7% on averaged miou, respectively. The code is available at :
https://github.com/yasserben/CLOUDS
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benigmim_Y/0/1/0/all/0/1&quot;&gt;Yasser Benigmim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Subhankar Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Essid_S/0/1/0/all/0/1&quot;&gt;Slim Essid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalogeiton_V/0/1/0/all/0/1&quot;&gt;Vicky Kalogeiton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lathuiliere_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Lathuili&amp;#xe8;re&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09789">
<title>Optimization meets Machine Learning: An Exact Algorithm for Semi-Supervised Support Vector Machines. (arXiv:2312.09789v1 [math.OC])</title>
<link>http://arxiv.org/abs/2312.09789</link>
<description rdf:parseType="Literal">&lt;p&gt;Support vector machines (SVMs) are well-studied supervised learning models
for binary classification. In many applications, large amounts of samples can
be cheaply and easily obtained. What is often a costly and error-prone process
is to manually label these instances. Semi-supervised support vector machines
(S3VMs) extend the well-known SVM classifiers to the semi-supervised approach,
aiming at maximizing the margin between samples in the presence of unlabeled
data. By leveraging both labeled and unlabeled data, S3VMs attempt to achieve
better accuracy and robustness compared to traditional SVMs. Unfortunately, the
resulting optimization problem is non-convex and hence difficult to solve
exactly. In this paper, we present a new branch-and-cut approach for S3VMs
using semidefinite programming (SDP) relaxations. We apply optimality-based
bound tightening to bound the feasible set. Box constraints allow us to include
valid inequalities, strengthening the lower bound. The resulting SDP relaxation
provides bounds significantly stronger than the ones available in the
literature. For the upper bound, instead, we define a local search exploiting
the solution of the SDP relaxation. Computational results highlight the
efficiency of the algorithm, showing its capability to solve instances with a
number of data points 10 times larger than the ones solved in the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Piccialli_V/0/1/0/all/0/1&quot;&gt;Veronica Piccialli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schwiddessen_J/0/1/0/all/0/1&quot;&gt;Jan Schwiddessen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sudoso_A/0/1/0/all/0/1&quot;&gt;Antonio M. Sudoso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09790">
<title>End-to-End Training of Neural Networks for Automotive Radar Interference Mitigation. (arXiv:2312.09790v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09790</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we propose a new method for training neural networks (NNs) for
frequency modulated continuous wave (FMCW) radar mutual interference
mitigation. Instead of training NNs to regress from interfered to clean radar
signals as in previous work, we train NNs directly on object detection maps. We
do so by performing a continuous relaxation of the cell-averaging constant
false alarm rate (CA-CFAR) peak detector, which is a well-established algorithm
for object detection using radar. With this new training objective we are able
to increase object detection performance by a large margin. Furthermore, we
introduce separable convolution kernels to strongly reduce the number of
parameters and computational complexity of convolutional NN architectures for
radar applications. We validate our contributions with experiments on
real-world measurement data and compare them against signal processing
interference mitigation methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oswald_C/0/1/0/all/0/1&quot;&gt;Christian Oswald&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toth_M/0/1/0/all/0/1&quot;&gt;Mate Toth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meissner_P/0/1/0/all/0/1&quot;&gt;Paul Meissner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pernkopf_F/0/1/0/all/0/1&quot;&gt;Franz Pernkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09792">
<title>Latent Diffusion Models with Image-Derived Annotations for Enhanced AI-Assisted Cancer Diagnosis in Histopathology. (arXiv:2312.09792v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.09792</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial Intelligence (AI) based image analysis has an immense potential to
support diagnostic histopathology, including cancer diagnostics. However,
developing supervised AI methods requires large-scale annotated datasets. A
potentially powerful solution is to augment training data with synthetic data.
Latent diffusion models, which can generate high-quality, diverse synthetic
images, are promising. However, the most common implementations rely on
detailed textual descriptions, which are not generally available in this
domain. This work proposes a method that constructs structured textual prompts
from automatically extracted image features. We experiment with the PCam
dataset, composed of tissue patches only loosely annotated as healthy or
cancerous. We show that including image-derived features in the prompt, as
opposed to only healthy and cancerous labels, improves the Fr\&apos;echet Inception
Distance (FID) from 178.8 to 90.2. We also show that pathologists find it
challenging to detect synthetic images, with a median sensitivity/specificity
of 0.55/0.55. Finally, we show that synthetic data effectively trains AI
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osorio_P/0/1/0/all/0/1&quot;&gt;Pedro Osorio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jimenez_Perez_G/0/1/0/all/0/1&quot;&gt;Guillermo Jimenez-Perez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montalt_Tordera_J/0/1/0/all/0/1&quot;&gt;Javier Montalt-Tordera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hooge_J/0/1/0/all/0/1&quot;&gt;Jens Hooge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duran_Ballester_G/0/1/0/all/0/1&quot;&gt;Guillem Duran-Ballester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Shivam Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radbruch_M/0/1/0/all/0/1&quot;&gt;Moritz Radbruch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bach_U/0/1/0/all/0/1&quot;&gt;Ute Bach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schroeder_S/0/1/0/all/0/1&quot;&gt;Sabrina Schroeder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siudak_K/0/1/0/all/0/1&quot;&gt;Krystyna Siudak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vienenkoetter_J/0/1/0/all/0/1&quot;&gt;Julia Vienenkoetter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lawrenz_B/0/1/0/all/0/1&quot;&gt;Bettina Lawrenz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammadi_S/0/1/0/all/0/1&quot;&gt;Sadegh Mohammadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09793">
<title>PAC-Bayes Generalisation Bounds for Dynamical Systems Including Stable RNNs. (arXiv:2312.09793v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09793</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we derive a PAC-Bayes bound on the generalisation gap, in a
supervised time-series setting for a special class of discrete-time non-linear
dynamical systems. This class includes stable recurrent neural networks (RNN),
and the motivation for this work was its application to RNNs. In order to
achieve the results, we impose some stability constraints, on the allowed
models. Here, stability is understood in the sense of dynamical systems. For
RNNs, these stability conditions can be expressed in terms of conditions on the
weights. We assume the processes involved are essentially bounded and the loss
functions are Lipschitz. The proposed bound on the generalisation gap depends
on the mixing coefficient of the data distribution, and the essential supremum
of the data. Furthermore, the bound converges to zero as the dataset size
increases. In this paper, we 1) formalize the learning problem, 2) derive a
PAC-Bayesian error bound for such systems, 3) discuss various consequences of
this error bound, and 4) show an illustrative example, with discussions on
computing the proposed bound. Unlike other available bounds the derived bound
holds for non i.i.d. data (time-series) and it does not grow with the number of
steps of the RNN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eringis_D/0/1/0/all/0/1&quot;&gt;Deividas Eringis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leth_J/0/1/0/all/0/1&quot;&gt;John Leth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1&quot;&gt;Zheng-Hua Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wisniewski_R/0/1/0/all/0/1&quot;&gt;Rafal Wisniewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petreczky_M/0/1/0/all/0/1&quot;&gt;Mihaly Petreczky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09797">
<title>Part Representation Learning with Teacher-Student Decoder for Occluded Person Re-identification. (arXiv:2312.09797v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2312.09797</link>
<description rdf:parseType="Literal">&lt;p&gt;Occluded person re-identification (ReID) is a very challenging task due to
the occlusion disturbance and incomplete target information. Leveraging
external cues such as human pose or parsing to locate and align part features
has been proven to be very effective in occluded person ReID. Meanwhile, recent
Transformer structures have a strong ability of long-range modeling.
Considering the above facts, we propose a Teacher-Student Decoder (TSD)
framework for occluded person ReID, which utilizes the Transformer decoder with
the help of human parsing. More specifically, our proposed TSD consists of a
Parsing-aware Teacher Decoder (PTD) and a Standard Student Decoder (SSD). PTD
employs human parsing cues to restrict Transformer&apos;s attention and imparts this
information to SSD through feature distillation. Thereby, SSD can learn from
PTD to aggregate information of body parts automatically. Moreover, a mask
generator is designed to provide discriminative regions for better ReID. In
addition, existing occluded person ReID benchmarks utilize occluded samples as
queries, which will amplify the role of alleviating occlusion interference and
underestimate the impact of the feature absence issue. Contrastively, we
propose a new benchmark with non-occluded queries, serving as a complement to
the existing benchmark. Extensive experiments demonstrate that our proposed
method is superior and the new benchmark is essential. The source codes are
available at https://github.com/hh23333/TSD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Shang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chenyang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pingping Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1&quot;&gt;Huchuan Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09802">
<title>Concept Prerequisite Relation Prediction by Using Permutation-Equivariant Directed Graph Neural Networks. (arXiv:2312.09802v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09802</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of CPRP, concept prerequisite relation
prediction, which is a fundamental task in using AI for education. CPRP is
usually formulated into a link-prediction task on a relationship graph of
concepts and solved by training the graph neural network (GNN) model. However,
current directed GNNs fail to manage graph isomorphism which refers to the
invariance of non-isomorphic graphs, reducing the expressivity of resulting
representations. We present a permutation-equivariant directed GNN model by
introducing the Weisfeiler-Lehman test into directed GNN learning. Our method
is then used for CPRP and evaluated on three public datasets. The experimental
results show that our model delivers better prediction performance than the
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1&quot;&gt;Xiran Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_X/0/1/0/all/0/1&quot;&gt;Xuequn Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yupei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09806">
<title>Improving Biomedical Entity Linking with Retrieval-enhanced Learning. (arXiv:2312.09806v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.09806</link>
<description rdf:parseType="Literal">&lt;p&gt;Biomedical entity linking (BioEL) has achieved remarkable progress with the
help of pre-trained language models. However, existing BioEL methods usually
struggle to handle rare and difficult entities due to long-tailed distribution.
To address this limitation, we introduce a new scheme $k$NN-BioEL, which
provides a BioEL model with the ability to reference similar instances from the
entire training corpus as clues for prediction, thus improving the
generalization capabilities. Moreover, we design a contrastive learning
objective with dynamic hard negative sampling (DHNS) that improves the quality
of the retrieved neighbors during inference. Extensive experimental results
show that $k$NN-BioEL outperforms state-of-the-art baselines on several
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhenxi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Ziheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xian Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yefeng Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09817">
<title>Calibrated One Round Federated Learning with Bayesian Inference in the Predictive Space. (arXiv:2312.09817v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09817</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) involves training a model over a dataset distributed
among clients, with the constraint that each client&apos;s dataset is localized and
possibly heterogeneous. In FL, small and noisy datasets are common,
highlighting the need for well-calibrated models that represent the uncertainty
of predictions. The closest FL techniques to achieving such goals are the
Bayesian FL methods which collect parameter samples from local posteriors, and
aggregate them to approximate the global posterior. To improve scalability for
larger models, one common Bayesian approach is to approximate the global
predictive posterior by multiplying local predictive posteriors. In this work,
we demonstrate that this method gives systematically overconfident predictions,
and we remedy this by proposing $\beta$-Predictive Bayes, a Bayesian FL
algorithm that interpolates between a mixture and product of the predictive
posteriors, using a tunable parameter $\beta$. This parameter is tuned to
improve the global ensemble&apos;s calibration, before it is distilled to a single
model. Our method is evaluated on a variety of regression and classification
datasets to demonstrate its superiority in calibration to other baselines, even
as data heterogeneity increases. Code available at
https://github.com/hasanmohsin/betaPredBayes_FL
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1&quot;&gt;Mohsin Hasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Guojun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1&quot;&gt;Kaiyang Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1&quot;&gt;Pascal Poupart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09820">
<title>On the locality of local neural operator in learning fluid dynamics. (arXiv:2312.09820v1 [physics.flu-dyn])</title>
<link>http://arxiv.org/abs/2312.09820</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper launches a thorough discussion on the locality of local neural
operator (LNO), which is the core that enables LNO great flexibility on varied
computational domains in solving transient partial differential equations
(PDEs). We investigate the locality of LNO by looking into its receptive field
and receptive range, carrying a main concern about how the locality acts in LNO
training and applications. In a large group of LNO training experiments for
learning fluid dynamics, it is found that an initial receptive range compatible
with the learning task is crucial for LNO to perform well. On the one hand, an
over-small receptive range is fatal and usually leads LNO to numerical
oscillation; on the other hand, an over-large receptive range hinders LNO from
achieving the best accuracy. We deem rules found in this paper general when
applying LNO to learn and solve transient PDEs in diverse fields. Practical
examples of applying the pre-trained LNOs in flow prediction are presented to
confirm the findings further. Overall, with the architecture properly designed
with a compatible receptive range, the pre-trained LNO shows commendable
accuracy and efficiency in solving practical cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ye_X/0/1/0/all/0/1&quot;&gt;Ximeng Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jingjie Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Qin_G/0/1/0/all/0/1&quot;&gt;Guoliang Qin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09821">
<title>Fragility, Robustness and Antifragility in Deep Learning. (arXiv:2312.09821v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09821</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a systematic analysis of deep neural networks (DNNs) based on a
signal processing technique for network parameter removal, in the form of
synaptic filters that identifies the fragility, robustness and antifragility
characteristics of DNN parameters. Our proposed analysis investigates if the
DNN performance is impacted negatively, invariantly, or positively on both
clean and adversarially perturbed test datasets when the DNN undergoes synaptic
filtering. We define three \textit{filtering scores} for quantifying the
fragility, robustness and antifragility characteristics of DNN parameters based
on the performances for (i) clean dataset, (ii) adversarial dataset, and (iii)
the difference in performances of clean and adversarial datasets. We validate
the proposed systematic analysis on ResNet-18, ResNet-50, SqueezeNet-v1.1 and
ShuffleNet V2 x1.0 network architectures for MNIST, CIFAR10 and Tiny ImageNet
datasets. The filtering scores, for a given network architecture, identify
network parameters that are invariant in characteristics across different
datasets over learning epochs. Vice-versa, for a given dataset, the filtering
scores identify the parameters that are invariant in characteristics across
different network architectures. We show that our synaptic filtering method
improves the test accuracy of ResNet and ShuffleNet models on adversarial
datasets when only the robust and antifragile parameters are selectively
retrained at any given epoch, thus demonstrating applications of the proposed
strategy in improving model robustness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pravin_C/0/1/0/all/0/1&quot;&gt;Chandresh Pravin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martino_I/0/1/0/all/0/1&quot;&gt;Ivan Martino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicosia_G/0/1/0/all/0/1&quot;&gt;Giuseppe Nicosia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ojha_V/0/1/0/all/0/1&quot;&gt;Varun Ojha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09830">
<title>Socio-Economic Deprivation Analysis: Diffusion Maps. (arXiv:2312.09830v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09830</link>
<description rdf:parseType="Literal">&lt;p&gt;This report proposes a model to predict the location of the most deprived
areas in a city using data from the census. A census data is very high
dimensional and needs to be simplified. We use a novel algorithm to reduce
dimensionality and find patterns: The diffusion map. Features are defined by
eigenvectors of the Laplacian matrix that defines the diffusion map.
Eigenvectors corresponding to the smallest eigenvalues indicate specific
population features. Previous work has found qualitatively that the second most
important dimension for describing the census data in Bristol is linked to
deprivation. In this report, we analyse how good this dimension is as a model
for predicting deprivation by comparing with the recognised measures. The
Pearson correlation coefficient was found to be over 0.7. The top 10 per cent
of deprived areas in the UK which also locate in Bristol are extracted to test
the accuracy of the model. There are 52 most deprived areas, and 38 areas are
correctly identified by comparing to the model. The influence of scores of IMD
domains that do not correlate with the models, Eigenvector 2 entries of
non-deprived OAs and orthogonality of Eigenvectors cause the model to fail the
prediction of 14 deprived areas.
&lt;/p&gt;
&lt;p&gt;However, overall, the model shows a high performance to predict the future
deprivation of overall areas where the project considers. This project is
expected to support the government to allocate resources and funding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goo_J/0/1/0/all/0/1&quot;&gt;June Moh Goo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09832">
<title>Disentangling Linear Mode-Connectivity. (arXiv:2312.09832v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09832</link>
<description rdf:parseType="Literal">&lt;p&gt;Linear mode-connectivity (LMC) (or lack thereof) is one of the intriguing
characteristics of neural network loss landscapes. While empirically well
established, it unfortunately still lacks a proper theoretical understanding.
Even worse, although empirical data points are abound, a systematic study of
when networks exhibit LMC is largely missing in the literature. In this work we
aim to close this gap. We explore how LMC is affected by three factors: (1)
architecture (sparsity, weight-sharing), (2) training strategy (optimization
setup) as well as (3) the underlying dataset. We place particular emphasis on
minimal but non-trivial settings, removing as much unnecessary complexity as
possible. We believe that our insights can guide future theoretical works on
uncovering the inner workings of LMC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Altintas_G/0/1/0/all/0/1&quot;&gt;Gul Sena Altintas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bachmann_G/0/1/0/all/0/1&quot;&gt;Gregor Bachmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Noci_L/0/1/0/all/0/1&quot;&gt;Lorenzo Noci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1&quot;&gt;Thomas Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09844">
<title>Small Dataset, Big Gains: Enhancing Reinforcement Learning by Offline Pre-Training with Model Based Augmentation. (arXiv:2312.09844v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09844</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline reinforcement learning leverages pre-collected datasets of
transitions to train policies. It can serve as effective initialization for
online algorithms, enhancing sample efficiency and speeding up convergence.
However, when such datasets are limited in size and quality, offline
pre-training can produce sub-optimal policies and lead to degraded online
reinforcement learning performance. In this paper we propose a model-based data
augmentation strategy to maximize the benefits of offline reinforcement
learning pre-training and reduce the scale of data needed to be effective. Our
approach leverages a world model of the environment trained on the offline
dataset to augment states during offline pre-training. We evaluate our approach
on a variety of MuJoCo robotic tasks and our results show it can jump-start
online fine-tuning and substantially reduce - in some cases by an order of
magnitude - the required number of environment interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macaluso_G/0/1/0/all/0/1&quot;&gt;Girolamo Macaluso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sestini_A/0/1/0/all/0/1&quot;&gt;Alessandro Sestini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagdanov_A/0/1/0/all/0/1&quot;&gt;Andrew D. Bagdanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09845">
<title>Learned Regularization for Inverse Problems: Insights from a Spectral Model. (arXiv:2312.09845v1 [math.NA])</title>
<link>http://arxiv.org/abs/2312.09845</link>
<description rdf:parseType="Literal">&lt;p&gt;The aim of this paper is to provide a theoretically founded investigation of
state-of-the-art learning approaches for inverse problems. We give an extended
definition of regularization methods and their convergence in terms of the
underlying data distributions, which paves the way for future theoretical
studies. Based on a simple spectral learning model previously introduced for
supervised learning, we investigate some key properties of different learning
paradigms for inverse problems, which can be formulated independently of
specific architectures. In particular we investigate the regularization
properties, bias, and critical dependence on training data distributions.
Moreover, our framework allows to highlight and compare the specific behavior
of the different paradigms in the infinite-dimensional limit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Burger_M/0/1/0/all/0/1&quot;&gt;Martin Burger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kabri_S/0/1/0/all/0/1&quot;&gt;Samira Kabri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09852">
<title>Learning Distributions on Manifolds with Free-form Flows. (arXiv:2312.09852v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09852</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real world data, particularly in the natural sciences and computer
vision, lie on known Riemannian manifolds such as spheres, tori or the group of
rotation matrices. The predominant approaches to learning a distribution on
such a manifold require solving a differential equation in order to sample from
the model and evaluate densities. The resulting sampling times are slowed down
by a high number of function evaluations. In this work, we propose an
alternative approach which only requires a single function evaluation followed
by a projection to the manifold. Training is achieved by an adaptation of the
recently proposed free-form flow framework to Riemannian manifolds. The central
idea is to estimate the gradient of the negative log-likelihood via a trace
evaluated in the tangent space. We evaluate our method on various manifolds,
and find significantly faster inference at competitive performance compared to
previous work. We make our code public at https://github.com/vislearn/FFF.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sorrenson_P/0/1/0/all/0/1&quot;&gt;Peter Sorrenson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Draxler_F/0/1/0/all/0/1&quot;&gt;Felix Draxler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rousselot_A/0/1/0/all/0/1&quot;&gt;Armand Rousselot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hummerich_S/0/1/0/all/0/1&quot;&gt;Sander Hummerich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothe_U/0/1/0/all/0/1&quot;&gt;Ullrich K&amp;#xf6;the&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09857">
<title>Deep Unsupervised Domain Adaptation for Time Series Classification: a Benchmark. (arXiv:2312.09857v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09857</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised Domain Adaptation (UDA) aims to harness labeled source data to
train models for unlabeled target data. Despite extensive research in domains
like computer vision and natural language processing, UDA remains underexplored
for time series data, which has widespread real-world applications ranging from
medicine and manufacturing to earth observation and human activity recognition.
Our paper addresses this gap by introducing a comprehensive benchmark for
evaluating UDA techniques for time series classification, with a focus on deep
learning methods. We provide seven new benchmark datasets covering various
domain shifts and temporal dynamics, facilitating fair and standardized UDA
method assessments with state of the art neural network backbones (e.g.
Inception) for time series data. This benchmark offers insights into the
strengths and limitations of the evaluated approaches while preserving the
unsupervised nature of domain adaptation, making it directly applicable to
practical problems. Our paper serves as a vital resource for researchers and
practitioners, advancing domain adaptation solutions for time series data and
fostering innovation in this critical field. The implementation code of this
benchmark is available at https://github.com/EricssonResearch/UDA-4-TSC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fawaz_H/0/1/0/all/0/1&quot;&gt;Hassan Ismail Fawaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosso_G/0/1/0/all/0/1&quot;&gt;Ganesh Del Grosso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kerdoncuff_T/0/1/0/all/0/1&quot;&gt;Tanguy Kerdoncuff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boisbunon_A/0/1/0/all/0/1&quot;&gt;Aurelie Boisbunon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saffar_I/0/1/0/all/0/1&quot;&gt;Illyyne Saffar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09860">
<title>Automatic Rao-Blackwellization for Sequential Monte Carlo with Belief Propagation. (arXiv:2312.09860v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09860</link>
<description rdf:parseType="Literal">&lt;p&gt;Exact Bayesian inference on state-space models~(SSM) is in general
untractable, and unfortunately, basic Sequential Monte Carlo~(SMC) methods do
not yield correct approximations for complex models. In this paper, we propose
a mixed inference algorithm that computes closed-form solutions using belief
propagation as much as possible, and falls back to sampling-based SMC methods
when exact computations fail. This algorithm thus implements automatic
Rao-Blackwellization and is even exact for Gaussian tree models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizian_W/0/1/0/all/0/1&quot;&gt;Wa&amp;#xef;ss Azizian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baudart_G/0/1/0/all/0/1&quot;&gt;Guillaume Baudart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lelarge_M/0/1/0/all/0/1&quot;&gt;Marc Lelarge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09865">
<title>Automating reward function configuration for drug design. (arXiv:2312.09865v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09865</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing reward functions that guide generative molecular design (GMD)
algorithms to desirable areas of chemical space is of critical importance in
AI-driven drug discovery. Traditionally, this has been a manual and error-prone
task; the selection of appropriate computational methods to approximate
biological assays is challenging and the aggregation of computed values into a
single score even more so, leading to potential reliance on trial-and-error
approaches. We propose a novel approach for automated reward configuration that
relies solely on experimental data, mitigating the challenges of manual reward
adjustment on drug discovery projects. Our method achieves this by constructing
a ranking over experimental data based on Pareto dominance over the
multi-objective space, then training a neural network to approximate the reward
function such that rankings determined by the predicted reward correlate with
those determined by the Pareto dominance relation. We validate our method using
two case studies. In the first study we simulate Design-Make-Test-Analyse
(DMTA) cycles by alternating reward function updates and generative runs guided
by that function. We show that the learned function adapts over time to yield
compounds that score highly with respect to evaluation functions taken from the
literature. In the second study we apply our algorithm to historical data from
four real drug discovery projects. We show that our algorithm yields reward
functions that outperform the predictive accuracy of human-defined functions,
achieving an improvement of up to 0.4 in Spearman&apos;s correlation against a
ground truth evaluation function that encodes the target drug profile for that
project. Our method provides an efficient data-driven way to configure reward
functions for GMD, and serves as a strong baseline for future research into
transformative approaches for the automation of drug discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urbonas_M/0/1/0/all/0/1&quot;&gt;Marius Urbonas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ajileye_T/0/1/0/all/0/1&quot;&gt;Temitope Ajileye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gainer_P/0/1/0/all/0/1&quot;&gt;Paul Gainer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pires_D/0/1/0/all/0/1&quot;&gt;Douglas Pires&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09869">
<title>Learning in Online Principle-Agent Interactions: The Power of Menus. (arXiv:2312.09869v1 [cs.GT])</title>
<link>http://arxiv.org/abs/2312.09869</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a ubiquitous learning challenge in online principal-agent problems
during which the principal learns the agent&apos;s private information from the
agent&apos;s revealed preferences in historical interactions. This paradigm includes
important special cases such as pricing and contract design, which have been
widely studied in recent literature. However, existing work considers the case
where the principal can only choose a single strategy at every round to
interact with the agent and then observe the agent&apos;s revealed preference
through their actions. In this paper, we extend this line of study to allow the
principal to offer a menu of strategies to the agent and learn additionally
from observing the agent&apos;s selection from the menu. We provide a thorough
investigation of several online principal-agent problem settings and
characterize their sample complexities, accompanied by the corresponding
algorithms we have developed. We instantiate this paradigm to several important
design problems $-$ including Stackelberg (security) games, contract design,
and information design. Finally, we also explore the connection between our
findings and existing results about online learning in Stackelberg games, and
we offer a solution that can overcome a key hard instance of Peng et al.
(2019).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1&quot;&gt;Minbiao Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albert_M/0/1/0/all/0/1&quot;&gt;Michael Albert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Haifeng Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09871">
<title>ChemTime: Rapid and Early Classification for Multivariate Time Series Classification of Chemical Sensors. (arXiv:2312.09871v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09871</link>
<description rdf:parseType="Literal">&lt;p&gt;Multivariate time series data are ubiquitous in the application of machine
learning to problems in the physical sciences. Chemiresistive sensor arrays are
highly promising in chemical detection tasks relevant to industrial, safety,
and military applications. Sensor arrays are an inherently multivariate time
series data collection tool which demand rapid and accurate classification of
arbitrary chemical analytes. Previous research has benchmarked data-agnostic
multivariate time series classifiers across diverse multivariate time series
supervised tasks in order to find general-purpose classification algorithms. To
our knowledge, there has yet to be an effort to survey machine learning and
time series classification approaches to chemiresistive hardware sensor arrays
for the detection of chemical analytes. In addition to benchmarking existing
approaches to multivariate time series classifiers, we incorporate findings
from a model survey to propose the novel \textit{ChemTime} approach to sensor
array classification for chemical sensing. We design experiments addressing the
unique challenges of hardware sensor arrays classification including the rapid
classification ability of classifiers and minimization of inference time while
maintaining performance for deployed lightweight hardware sensing devices. We
find that \textit{ChemTime} is uniquely positioned for the chemical sensing
task by combining rapid and early classification of time series with beneficial
inference and high accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_A/0/1/0/all/0/1&quot;&gt;Alexander M. Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paffenroth_R/0/1/0/all/0/1&quot;&gt;Randy C. Paffenroth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ngo_K/0/1/0/all/0/1&quot;&gt;Kenneth T. Ngo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uzarski_J/0/1/0/all/0/1&quot;&gt;Joshua R. Uzarski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09877">
<title>Distributed Learning of Mixtures of Experts. (arXiv:2312.09877v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09877</link>
<description rdf:parseType="Literal">&lt;p&gt;In modern machine learning problems we deal with datasets that are either
distributed by nature or potentially large for which distributing the
computations is usually a standard way to proceed, since centralized algorithms
are in general ineffective. We propose a distributed learning approach for
mixtures of experts (MoE) models with an aggregation strategy to construct a
reduction estimator from local estimators fitted parallelly to distributed
subsets of the data. The aggregation is based on an optimal minimization of an
expected transportation divergence between the large MoE composed of local
estimators and the unknown desired MoE model. We show that the provided
reduction estimator is consistent as soon as the local estimators to be
aggregated are consistent, and its construction is performed by a proposed
majorization-minimization (MM) algorithm that is computationally effective. We
study the statistical and numerical properties for the proposed reduction
estimator on experiments that demonstrate its performance compared to namely
the global estimator constructed in a centralized way from the full dataset.
For some situations, the computation time is more than ten times faster, for a
comparable performance. Our source codes are publicly available on Github.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chamroukhi_F/0/1/0/all/0/1&quot;&gt;Fa&amp;#xef;cel Chamroukhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_N/0/1/0/all/0/1&quot;&gt;Nhat Thien Pham&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09881">
<title>Dynamic Heterogeneous Federated Learning with Multi-Level Prototypes. (arXiv:2312.09881v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09881</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning shows promise as a privacy-preserving collaborative
learning technique. Existing heterogeneous federated learning mainly focuses on
skewing the label distribution across clients. However, most approaches suffer
from catastrophic forgetting and concept drift, mainly when the global
distribution of all classes is extremely unbalanced and the data distribution
of the client dynamically evolves over time. In this paper, we study the new
task, i.e., Dynamic Heterogeneous Federated Learning (DHFL), which addresses
the practical scenario where heterogeneous data distributions exist among
different clients and dynamic tasks within the client. Accordingly, we propose
a novel federated learning framework named Federated Multi-Level Prototypes
(FedMLP) and design federated multi-level regularizations. To mitigate concept
drift, we construct prototypes and semantic prototypes to provide fruitful
generalization knowledge and ensure the continuity of prototype spaces. To
maintain the model stability and consistency of convergence, three
regularizations are introduced as training losses, i.e., prototype-based
regularization, semantic prototype-based regularization, and federated
inter-task regularization. Extensive experiments show that the proposed method
achieves state-of-the-art performance in various settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1&quot;&gt;Shunxin Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongsong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1&quot;&gt;Xin Geng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09885">
<title>Simple Weak Coresets for Non-Decomposable Classification Measures. (arXiv:2312.09885v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09885</link>
<description rdf:parseType="Literal">&lt;p&gt;While coresets have been growing in terms of their application, barring few
exceptions, they have mostly been limited to unsupervised settings. We consider
supervised classification problems, and non-decomposable evaluation measures in
such settings. We show that stratified uniform sampling based coresets have
excellent empirical performance that are backed by theoretical guarantees too.
We focus on the F1 score and Matthews Correlation Coefficient, two widely used
non-decomposable objective functions that are nontrivial to optimize for and
show that uniform coresets attain a lower bound for coreset size, and have good
empirical performance, comparable with ``smarter&apos;&apos; coreset construction
strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malaviya_J/0/1/0/all/0/1&quot;&gt;Jayesh Malaviya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_A/0/1/0/all/0/1&quot;&gt;Anirban Dasgupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chhaya_R/0/1/0/all/0/1&quot;&gt;Rachit Chhaya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09887">
<title>Probabilistic learning of the Purkinje network from the electrocardiogram. (arXiv:2312.09887v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.09887</link>
<description rdf:parseType="Literal">&lt;p&gt;The identification of the Purkinje conduction system in the heart is a
challenging task, yet essential for a correct definition of cardiac digital
twins for precision cardiology. Here, we propose a probabilistic approach for
identifying the Purkinje network from non-invasive clinical data such as the
standard electrocardiogram (ECG). We use cardiac imaging to build an
anatomically accurate model of the ventricles; we algorithmically generate a
rule-based Purkinje network tailored to the anatomy; we simulate physiological
electrocardiograms with a fast model; we identify the geometrical and
electrical parameters of the Purkinje-ECG model with Bayesian optimization and
approximate Bayesian computation. The proposed approach is inherently
probabilistic and generates a population of plausible Purkinje networks, all
fitting the ECG within a given tolerance. In this way, we can estimate the
uncertainty of the parameters, thus providing reliable predictions. We test our
methodology in physiological and pathological scenarios, showing that we are
able to accurately recover the ECG with our model. We propagate the uncertainty
in the Purkinje network parameters in a simulation of conduction system pacing
therapy. Our methodology is a step forward in creation of digital twins from
non-invasive data in precision medicine. An open source implementation can be
found at &lt;a href=&quot;http://github.com/fsahli/purkinje-learning&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alvarez_Barrientos_F/0/1/0/all/0/1&quot;&gt;Felipe &amp;#xc1;lvarez-Barrientos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Salinas_Camus_M/0/1/0/all/0/1&quot;&gt;Mariana Salinas-Camus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pezzuto_S/0/1/0/all/0/1&quot;&gt;Simone Pezzuto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Costabal_F/0/1/0/all/0/1&quot;&gt;Francisco Sahli Costabal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09899">
<title>SQA-SAM: Segmentation Quality Assessment for Medical Images Utilizing the Segment Anything Model. (arXiv:2312.09899v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2312.09899</link>
<description rdf:parseType="Literal">&lt;p&gt;Segmentation quality assessment (SQA) plays a critical role in the deployment
of a medical image based AI system. Users need to be informed/alerted whenever
an AI system generates unreliable/incorrect predictions. With the introduction
of the Segment Anything Model (SAM), a general foundation segmentation model,
new research opportunities emerged in how one can utilize SAM for medical image
segmentation. In this paper, we propose a novel SQA method, called SQA-SAM,
which exploits SAM to enhance the accuracy of quality assessment for medical
image segmentation. When a medical image segmentation model (MedSeg) produces
predictions for a test image, we generate visual prompts based on the
predictions, and SAM is utilized to generate segmentation maps corresponding to
the visual prompts. How well MedSeg&apos;s segmentation aligns with SAM&apos;s
segmentation indicates how well MedSeg&apos;s segmentation aligns with the general
perception of objectness and image region partition. We develop a score measure
for such alignment. In experiments, we find that the generated scores exhibit
moderate to strong positive correlation (in Pearson correlation and Spearman
correlation) with Dice coefficient scores reflecting the true segmentation
quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yizhe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shuo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dou_Q/0/1/0/all/0/1&quot;&gt;Qi Dou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Danny Z. Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09912">
<title>Reliable Probabilistic Classification with Neural Networks. (arXiv:2312.09912v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09912</link>
<description rdf:parseType="Literal">&lt;p&gt;Venn Prediction (VP) is a new machine learning framework for producing
well-calibrated probabilistic predictions. In particular it provides
well-calibrated lower and upper bounds for the conditional probability of an
example belonging to each possible class of the problem at hand. This paper
proposes five VP methods based on Neural Networks (NNs), which is one of the
most widely used machine learning techniques. The proposed methods are
evaluated experimentally on four benchmark datasets and the obtained results
demonstrate the empirical well-calibratedness of their outputs and their
superiority over the outputs of the traditional NN classifier.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papadopoulos_H/0/1/0/all/0/1&quot;&gt;Harris Papadopoulos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09926">
<title>FuXi-S2S: An accurate machine learning model for global subseasonal forecasts. (arXiv:2312.09926v1 [physics.ao-ph])</title>
<link>http://arxiv.org/abs/2312.09926</link>
<description rdf:parseType="Literal">&lt;p&gt;Skillful subseasonal forecasts beyond 2 weeks are crucial for a wide range of
applications across various sectors of society. Recently, state-of-the-art
machine learning based weather forecasting models have made significant
advancements, outperforming the high-resolution forecast (HRES) from the
European Centre for Medium-Range Weather Forecasts (ECMWF). However, the full
potential of machine learning models in subseasonal forecasts has yet to be
fully explored. In this study, we introduce FuXi Subseasonal-to-Seasonal
(FuXi-S2S), a machine learning based subseasonal forecasting model that
provides global daily mean forecasts up to 42 days, covering 5 upper-air
atmospheric variables at 13 pressure levels and 11 surface variables. FuXi-S2S
integrates an enhanced FuXi base model with a perturbation module for
flow-dependent perturbations in hidden features, and incorporates Perlin noise
to perturb initial conditions. The model is developed using 72 years of daily
statistics from ECMWF ERA5 reanalysis data. When compared to the ECMWF
Subseasonal-to-Seasonal (S2S) reforecasts, the FuXi-S2S forecasts demonstrate
superior deterministic and ensemble forecasts for total precipitation (TP),
outgoing longwave radiation (OLR), and geopotential at 500 hPa (Z500). Although
it shows slightly inferior performance in predicting 2-meter temperature (T2M),
it has clear advantages over land area. Regarding the extreme forecasts,
FuXi-S2S outperforms ECMWF S2S globally for TP. Furthermore, FuXi-S2S forecasts
surpass the ECMWF S2S reforecasts in predicting the Madden Julian Oscillation
(MJO), a key source of subseasonal predictability. They extend the skillful
prediction of MJO from 30 days to 36 days.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhong_X/0/1/0/all/0/1&quot;&gt;Xiaohui Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jie Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Deliang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Xie_S/0/1/0/all/0/1&quot;&gt;Shangping Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chao_Q/0/1/0/all/0/1&quot;&gt;Qingchen Chao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lin_C/0/1/0/all/0/1&quot;&gt;Chensen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zixin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lu_B/0/1/0/all/0/1&quot;&gt;Bo Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Qi_Y/0/1/0/all/0/1&quot;&gt;Yuan Qi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09938">
<title>Assume-Guarantee Reinforcement Learning. (arXiv:2312.09938v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09938</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a modular approach to \emph{reinforcement learning} (RL) in
environments consisting of simpler components evolving in parallel. A
monolithic view of such modular environments may be prohibitively large to
learn, or may require unrealizable communication between the components in the
form of a centralized controller. Our proposed approach is based on the
assume-guarantee paradigm where the optimal control for the individual
components is synthesized in isolation by making \emph{assumptions} about the
behaviors of neighboring components, and providing \emph{guarantees} about
their own behavior. We express these \emph{assume-guarantee contracts} as
regular languages and provide automatic translations to scalar rewards to be
used in RL. By combining local probabilities of satisfaction for each
component, we provide a lower bound on the probability of satisfaction of the
complete system. By solving a Markov game for each component, RL can produce a
controller for each component that maximizes this lower bound. The controller
utilizes the information it receives through communication, observations, and
any knowledge of a coarse model of other agents. We experimentally demonstrate
the efficiency of the proposed approach on a variety of case studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazemi_M/0/1/0/all/0/1&quot;&gt;Milad Kazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1&quot;&gt;Mateo Perez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Somenzi_F/0/1/0/all/0/1&quot;&gt;Fabio Somenzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soudjani_S/0/1/0/all/0/1&quot;&gt;Sadegh Soudjani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1&quot;&gt;Ashutosh Trivedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velasquez_A/0/1/0/all/0/1&quot;&gt;Alvaro Velasquez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09939">
<title>Quantum Generative Adversarial Networks: Bridging Classical and Quantum Realms. (arXiv:2312.09939v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2312.09939</link>
<description rdf:parseType="Literal">&lt;p&gt;In this pioneering research paper, we present a groundbreaking exploration
into the synergistic fusion of classical and quantum computing paradigms within
the realm of Generative Adversarial Networks (GANs). Our objective is to
seamlessly integrate quantum computational elements into the conventional GAN
architecture, thereby unlocking novel pathways for enhanced training processes.
&lt;/p&gt;
&lt;p&gt;Drawing inspiration from the inherent capabilities of quantum bits (qubits),
we delve into the incorporation of quantum data representation methodologies
within the GAN framework. By capitalizing on the unique quantum features, we
aim to accelerate the training process of GANs, offering a fresh perspective on
the optimization of generative models.
&lt;/p&gt;
&lt;p&gt;Our investigation deals with theoretical considerations and evaluates the
potential quantum advantages that may manifest in terms of training efficiency
and generative quality. We confront the challenges inherent in the
quantum-classical amalgamation, addressing issues related to quantum hardware
constraints, error correction mechanisms, and scalability considerations. This
research is positioned at the forefront of quantum-enhanced machine learning,
presenting a critical stride towards harnessing the computational power of
quantum systems to expedite the training of Generative Adversarial Networks.
Through our comprehensive examination of the interface between classical and
quantum realms, we aim to uncover transformative insights that will propel the
field forward, fostering innovation and advancing the frontier of quantum
machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nokhwal_S/0/1/0/all/0/1&quot;&gt;Sahil Nokhwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Nokhwal_S/0/1/0/all/0/1&quot;&gt;Suman Nokhwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Swaroop_R/0/1/0/all/0/1&quot;&gt;Ram Swaroop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bala_R/0/1/0/all/0/1&quot;&gt;Raj Bala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chaudhary_A/0/1/0/all/0/1&quot;&gt;Ankit Chaudhary&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09940">
<title>Sketch and shift: a robust decoder for compressive clustering. (arXiv:2312.09940v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09940</link>
<description rdf:parseType="Literal">&lt;p&gt;Compressive learning is an emerging approach to drastically reduce the memory
footprint of large-scale learning, by first summarizing a large dataset into a
low-dimensional sketch vector, and then decoding from this sketch the latent
information needed for learning. In light of recent progress on information
preservation guarantees for sketches based on random features, a major
objective is to design easy-to-tune algorithms (called decoders) to robustly
and efficiently extract this information. To address the underlying non-convex
optimization problems, various heuristics have been proposed. In the case of
compressive clustering, the standard heuristic is CL-OMPR, a variant of sliding
Frank-Wolfe. Yet, CL-OMPR is hard to tune, and the examination of its
robustness was overlooked. In this work, we undertake a scrutinized examination
of CL-OMPR to circumvent its limitations. In particular, we show how this
algorithm can fail to recover the clusters even in advantageous scenarios. To
gain insight, we show how the deficiencies of this algorithm can be attributed
to optimization difficulties related to the structure of a correlation function
appearing at core steps of the algorithm. To address these limitations, we
propose an alternative decoder offering substantial improvements over CL-OMPR.
Its design is notably inspired from the mean shift algorithm, a classic
approach to detect the local maxima of kernel density estimators. The proposed
algorithm can extract clustering information from a sketch of the MNIST dataset
that is 10 times smaller than previously.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belhadji_A/0/1/0/all/0/1&quot;&gt;Ayoub Belhadji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gribonval_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Gribonval&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09950">
<title>Peer Learning: Learning Complex Policies in Groups from Scratch via Action Recommendations. (arXiv:2312.09950v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09950</link>
<description rdf:parseType="Literal">&lt;p&gt;Peer learning is a novel high-level reinforcement learning framework for
agents learning in groups. While standard reinforcement learning trains an
individual agent in trial-and-error fashion, all on its own, peer learning
addresses a related setting in which a group of agents, i.e., peers, learns to
master a task simultaneously together from scratch. Peers are allowed to
communicate only about their own states and actions recommended by others:
&quot;What would you do in my situation?&quot;. Our motivation is to study the learning
behavior of these agents. We formalize the teacher selection process in the
action advice setting as a multi-armed bandit problem and therefore highlight
the need for exploration. Eventually, we analyze the learning behavior of the
peers and observe their ability to rank the agents&apos; performance within the
study group and understand which agents give reliable advice. Further, we
compare peer learning with single agent learning and a state-of-the-art action
advice baseline. We show that peer learning is able to outperform single-agent
learning and the baseline in several challenging discrete and continuous OpenAI
Gym domains. Doing so, we also show that within such a framework complex
policies from action recommendations beyond discrete action spaces can evolve.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Derstroff_C/0/1/0/all/0/1&quot;&gt;Cedric Derstroff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cerrato_M/0/1/0/all/0/1&quot;&gt;Mattia Cerrato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brugger_J/0/1/0/all/0/1&quot;&gt;Jannis Brugger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1&quot;&gt;Jan Peters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramer_S/0/1/0/all/0/1&quot;&gt;Stefan Kramer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09961">
<title>Risk-Aware Continuous Control with Neural Contextual Bandits. (arXiv:2312.09961v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09961</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in learning techniques have garnered attention for their
applicability to a diverse range of real-world sequential decision-making
problems. Yet, many practical applications have critical constraints for
operation in real environments. Most learning solutions often neglect the risk
of failing to meet these constraints, hindering their implementation in
real-world contexts. In this paper, we propose a risk-aware decision-making
framework for contextual bandit problems, accommodating constraints and
continuous action spaces. Our approach employs an actor multi-critic
architecture, with each critic characterizing the distribution of performance
and constraint metrics. Our framework is designed to cater to various risk
levels, effectively balancing constraint satisfaction against performance. To
demonstrate the effectiveness of our approach, we first compare it against
state-of-the-art baseline methods in a synthetic environment, highlighting the
impact of intrinsic environmental noise across different risk configurations.
Finally, we evaluate our framework in a real-world use case involving a 5G
mobile network where only our approach consistently satisfies the system
constraint (a signal processing reliability target) with a small performance
toll (8.5% increase in power consumption).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ayala_Romero_J/0/1/0/all/0/1&quot;&gt;Jose A. Ayala-Romero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Saavedra_A/0/1/0/all/0/1&quot;&gt;Andres Garcia-Saavedra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_Perez_X/0/1/0/all/0/1&quot;&gt;Xavier Costa-Perez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09969">
<title>Scalable and hyper-parameter-free non-parametric covariate shift adaptation with conditional sampling. (arXiv:2312.09969v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2312.09969</link>
<description rdf:parseType="Literal">&lt;p&gt;Many existing covariate shift adaptation methods estimate sample weights to
be used in the risk estimation in order to mitigate the gap between the source
and the target distribution. However, non-parametrically estimating the optimal
weights typically involves computationally expensive hyper-parameter tuning
that is crucial to the final performance. In this paper, we propose a new
non-parametric approach to covariate shift adaptation which avoids estimating
weights and has no hyper-parameter to be tuned. Our basic idea is to label
unlabeled target data according to the $k$-nearest neighbors in the source
dataset. Our analysis indicates that setting $k = 1$ is an optimal choice.
Thanks to this property, there is no need to tune any hyper-parameters, unlike
other non-parametric methods. Moreover, our method achieves a running time
quasi-linear in the sample size with a theoretical guarantee, for the first
time in the literature to the best of our knowledge. Our results include sharp
rates of convergence for estimating the joint probability distribution of the
target data. In particular, the variance of our estimators has the same rate of
convergence as for standard parametric estimation despite their non-parametric
nature. Our numerical experiments show that proposed method brings drastic
reduction in the running time with accuracy comparable to that of the
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Portier_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Portier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Truquet_L/0/1/0/all/0/1&quot;&gt;Lionel Truquet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamane_I/0/1/0/all/0/1&quot;&gt;Ikko Yamane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09971">
<title>GreenLightningAI: An Efficient AI System with Decoupled Structural and Quantitative Knowledge. (arXiv:2312.09971v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09971</link>
<description rdf:parseType="Literal">&lt;p&gt;The number and complexity of artificial intelligence (AI) applications is
growing relentlessly. As a result, even with the many algorithmic and
mathematical advances experienced over past decades as well as the impressive
energy efficiency and computational capacity of current hardware accelerators,
training the most powerful and popular deep neural networks comes at very high
economic and environmental costs. Recognising that additional optimisations of
conventional neural network training is very difficult, this work takes a
radically different approach by proposing GreenLightningAI, a new AI system
design consisting of a linear model that is capable of emulating the behaviour
of deep neural networks by subsetting the model for each particular sample. The
new AI system stores the information required to select the system subset for a
given sample (referred to as structural information) separately from the linear
model parameters (referred to as quantitative knowledge). In this paper we
present a proof of concept, showing that the structural information stabilises
far earlier than the quantitative knowledge. Additionally, we show
experimentally that the structural information can be kept unmodified when
re-training the AI system with new samples while still achieving a validation
accuracy similar to that obtained when re-training a neural network with
similar size. Since the proposed AI system is based on a linear model, multiple
copies of the model, trained with different datasets, can be easily combined.
This enables faster and greener (re)-training algorithms, including incremental
re-training and federated incremental re-training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duato_J/0/1/0/all/0/1&quot;&gt;Jose Duato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mestre_J/0/1/0/all/0/1&quot;&gt;Jose I. Mestre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dolz_M/0/1/0/all/0/1&quot;&gt;Manuel F. Dolz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quintana_Orti_E/0/1/0/all/0/1&quot;&gt;Enrique S. Quintana-Ort&amp;#xed;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09978">
<title>Small jet engine reservoir computing digital twin. (arXiv:2312.09978v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09978</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning was applied to create a digital twin of a numerical
simulation of a single-scroll jet engine. A similar model based on the insights
gained from this numerical study was used to create a digital twin of a JetCat
P100-RX jet engine using only experimental data. Engine data was collected from
a custom sensor system measuring parameters such as thrust, exhaust gas
temperature, shaft speed, weather conditions, etc. Data was gathered while the
engine was placed under different test conditions by controlling shaft speed.
The machine learning model was generated (trained) using a next-generation
reservoir computer, a best-in-class machine learning algorithm for dynamical
systems. Once the model was trained, it was used to predict behavior it had
never seen with an accuracy of better than 1.8% when compared to the testing
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wright_C/0/1/0/all/0/1&quot;&gt;C. J. Wright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biederman_N/0/1/0/all/0/1&quot;&gt;N. Biederman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gyovai_B/0/1/0/all/0/1&quot;&gt;B. Gyovai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gauthier_D/0/1/0/all/0/1&quot;&gt;D. J. Gauthier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilhelm_J/0/1/0/all/0/1&quot;&gt;J. P. Wilhelm&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09982">
<title>ACPO: AI-Enabled Compiler-Driven Program Optimization. (arXiv:2312.09982v1 [cs.PL])</title>
<link>http://arxiv.org/abs/2312.09982</link>
<description rdf:parseType="Literal">&lt;p&gt;The key to performance optimization of a program is to decide correctly when
a certain transformation should be applied by a compiler. Traditionally, such
profitability decisions are made by hand-coded algorithms tuned for a very
small number of benchmarks, usually requiring a great deal of effort to be
retuned when the benchmark suite changes. This is an ideal opportunity to apply
machine-learning models to speed up the tuning process; while this realization
has been around since the late 90s, only recent advancements in ML enabled a
practical application of ML to compilers as an end-to-end framework. Even so,
seamless integration of ML into the compiler would require constant rebuilding
of the compiler when models are updated.
&lt;/p&gt;
&lt;p&gt;This paper presents ACPO: \textbf{\underline{A}}I-Enabled
\textbf{\underline{C}}ompiler-driven \textbf{\underline{P}}rogram
\textbf{\underline{O}}ptimization; a novel framework to provide LLVM with
simple and comprehensive tools to benefit from employing ML models for
different optimization passes. We first showcase the high-level view, class
hierarchy, and functionalities of ACPO and subsequently, demonstrate \taco{a
couple of use cases of ACPO by ML-enabling the Loop Unroll and Function
Inlining passes and describe how ACPO can be leveraged to optimize other
passes. Experimental results reveal that ACPO model for Loop Unroll is able to
gain on average 4\% and 3\%, 5.4\%, 0.2\% compared to LLVM&apos;s O3 optimization
when deployed on Polybench, Coral-2, CoreMark, and Graph-500, respectively.
Furthermore, by adding the Inliner model as well, ACPO is able to provide up to
4.5\% and 2.4\% on Polybench and Cbench compared with LLVM&apos;s O3 optimization,
respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashouri_A/0/1/0/all/0/1&quot;&gt;Amir H. Ashouri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manzoor_M/0/1/0/all/0/1&quot;&gt;Muhammad Asif Manzoor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vu_D/0/1/0/all/0/1&quot;&gt;Duc Minh Vu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Raymond Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziwen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Angel Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_B/0/1/0/all/0/1&quot;&gt;Bryan Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czajkowski_T/0/1/0/all/0/1&quot;&gt;Tomasz S. Czajkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yaoqing Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09983">
<title>Toward Computationally Efficient Inverse Reinforcement Learning via Reward Shaping. (arXiv:2312.09983v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.09983</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse reinforcement learning (IRL) is computationally challenging, with
common approaches requiring the solution of multiple reinforcement learning
(RL) sub-problems. This work motivates the use of potential-based reward
shaping to reduce the computational burden of each RL sub-problem. This work
serves as a proof-of-concept and we hope will inspire future developments
towards computationally efficient IRL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cooke_L/0/1/0/all/0/1&quot;&gt;Lauren H. Cooke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klyne_H/0/1/0/all/0/1&quot;&gt;Harvey Klyne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_E/0/1/0/all/0/1&quot;&gt;Edwin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laidlaw_C/0/1/0/all/0/1&quot;&gt;Cassidy Laidlaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1&quot;&gt;Milind Tambe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1&quot;&gt;Finale Doshi-Velez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09997">
<title>One Self-Configurable Model to Solve Many Abstract Visual Reasoning Problems. (arXiv:2312.09997v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2312.09997</link>
<description rdf:parseType="Literal">&lt;p&gt;Abstract Visual Reasoning (AVR) comprises a wide selection of various
problems similar to those used in human IQ tests. Recent years have brought
dynamic progress in solving particular AVR tasks, however, in the contemporary
literature AVR problems are largely dealt with in isolation, leading to highly
specialized task-specific methods. With the aim of developing universal
learning systems in the AVR domain, we propose the unified model for solving
Single-Choice Abstract visual Reasoning tasks (SCAR), capable of solving
various single-choice AVR tasks, without making any a priori assumptions about
the task structure, in particular the number and location of panels. The
proposed model relies on a novel Structure-Aware dynamic Layer (SAL), which
adapts its weights to the structure of the considered AVR problem. Experiments
conducted on Raven&apos;s Progressive Matrices, Visual Analogy Problems, and Odd One
Out problems show that SCAR (SAL-based models, in general) effectively solves
diverse AVR tasks, and its performance is on par with the state-of-the-art
task-specific baselines. What is more, SCAR demonstrates effective knowledge
reuse in multi-task and transfer learning settings. To our knowledge, this work
is the first successful attempt to construct a general single-choice AVR solver
relying on self-configurable architecture and unified solving method. With this
work we aim to stimulate and foster progress on task-independent research paths
in the AVR domain, with the long-term goal of development of a general AVR
solver.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malkinski_M/0/1/0/all/0/1&quot;&gt;Miko&amp;#x142;aj Ma&amp;#x142;ki&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandziuk_J/0/1/0/all/0/1&quot;&gt;Jacek Ma&amp;#x144;dziuk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10001">
<title>Modeling Unknown Stochastic Dynamical System via Autoencoder. (arXiv:2312.10001v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.10001</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a numerical method to learn an accurate predictive model for an
unknown stochastic dynamical system from its trajectory data. The method seeks
to approximate the unknown flow map of the underlying system. It employs the
idea of autoencoder to identify the unobserved latent random variables. In our
approach, we design an encoding function to discover the latent variables,
which are modeled as unit Gaussian, and a decoding function to reconstruct the
future states of the system. Both the encoder and decoder are expressed as deep
neural networks (DNNs). Once the DNNs are trained by the trajectory data, the
decoder serves as a predictive model for the unknown stochastic system. Through
an extensive set of numerical examples, we demonstrate that the method is able
to produce long-term system predictions by using short bursts of trajectory
data. It is also applicable to systems driven by non-Gaussian noises.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhongshu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Qifan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiu_D/0/1/0/all/0/1&quot;&gt;Dongbin Xiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10004">
<title>Symplectic Autoencoders for Model Reduction of Hamiltonian Systems. (arXiv:2312.10004v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.10004</link>
<description rdf:parseType="Literal">&lt;p&gt;Many applications, such as optimization, uncertainty quantification and
inverse problems, require repeatedly performing simulations of
large-dimensional physical systems for different choices of parameters. This
can be prohibitively expensive.
&lt;/p&gt;
&lt;p&gt;In order to save computational cost, one can construct surrogate models by
expressing the system in a low-dimensional basis, obtained from training data.
This is referred to as model reduction.
&lt;/p&gt;
&lt;p&gt;Past investigations have shown that, when performing model reduction of
Hamiltonian systems, it is crucial to preserve the symplectic structure
associated with the system in order to ensure long-term numerical stability.
&lt;/p&gt;
&lt;p&gt;Up to this point structure-preserving reductions have largely been limited to
linear transformations. We propose a new neural network architecture in the
spirit of autoencoders, which are established tools for dimension reduction and
feature extraction in data science, to obtain more general mappings.
&lt;/p&gt;
&lt;p&gt;In order to train the network, a non-standard gradient descent approach is
applied that leverages the differential-geometric structure emerging from the
network design.
&lt;/p&gt;
&lt;p&gt;The new architecture is shown to significantly outperform existing designs in
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brantner_B/0/1/0/all/0/1&quot;&gt;Benedikt Brantner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kraus_M/0/1/0/all/0/1&quot;&gt;Michael Kraus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10007">
<title>Faithful Persona-based Conversational Dataset Generation with Large Language Models. (arXiv:2312.10007v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2312.10007</link>
<description rdf:parseType="Literal">&lt;p&gt;High-quality conversational datasets are essential for developing AI models
that can communicate with users. One way to foster deeper interactions between
a chatbot and its user is through personas, aspects of the user&apos;s character
that provide insights into their personality, motivations, and behaviors.
Training Natural Language Processing (NLP) models on a diverse and
comprehensive persona-based dataset can lead to conversational models that
create a deeper connection with the user, and maintain their engagement. In
this paper, we leverage the power of Large Language Models (LLMs) to create a
large, high-quality conversational dataset from a seed dataset. We propose a
Generator-Critic architecture framework to expand the initial dataset, while
improving the quality of its conversations. The Generator is an LLM prompted to
output conversations. The Critic consists of a mixture of expert LLMs that
control the quality of the generated conversations. These experts select the
best generated conversations, which we then use to improve the Generator. We
release Synthetic-Persona-Chat, consisting of 20k conversations seeded from
Persona-Chat. We evaluate the quality of Synthetic-Persona-Chat and our
generation framework on different dimensions through extensive experiments, and
observe that the losing rate of Synthetic-Persona-Chat against Persona-Chat
during Turing test decreases from 17.2% to 8.8% over three iterations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jandaghi_P/0/1/0/all/0/1&quot;&gt;Pegah Jandaghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1&quot;&gt;XiangHai Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1&quot;&gt;Xinyi Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pujara_J/0/1/0/all/0/1&quot;&gt;Jay Pujara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sidahmed_H/0/1/0/all/0/1&quot;&gt;Hakim Sidahmed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10008">
<title>Movement Primitive Diffusion: Learning Gentle Robotic Manipulation of Deformable Objects. (arXiv:2312.10008v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2312.10008</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy learning in robot-assisted surgery (RAS) lacks data efficient and
versatile methods that exhibit the desired motion quality for delicate surgical
interventions. To this end, we introduce Movement Primitive Diffusion (MPD), a
novel method for imitation learning (IL) in RAS that focuses on gentle
manipulation of deformable objects. The approach combines the versatility of
diffusion-based imitation learning (DIL) with the high-quality motion
generation capabilities of Probabilistic Dynamic Movement Primitives (ProDMPs).
This combination enables MPD to achieve gentle manipulation of deformable
objects, while maintaining data efficiency critical for RAS applications where
demonstration data is scarce. We evaluate MPD across various simulated tasks
and a real world robotic setup on both state and image observations. MPD
outperforms state-of-the-art DIL methods in success rate, motion quality, and
data efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheikl_P/0/1/0/all/0/1&quot;&gt;Paul Maria Scheikl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schreiber_N/0/1/0/all/0/1&quot;&gt;Nicolas Schreiber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haas_C/0/1/0/all/0/1&quot;&gt;Christoph Haas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freymuth_N/0/1/0/all/0/1&quot;&gt;Niklas Freymuth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1&quot;&gt;Gerhard Neumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lioutikov_R/0/1/0/all/0/1&quot;&gt;Rudolf Lioutikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathis_Ullrich_F/0/1/0/all/0/1&quot;&gt;Franziska Mathis-Ullrich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10019">
<title>Understanding Probe Behaviors through Variational Bounds of Mutual Information. (arXiv:2312.10019v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2312.10019</link>
<description rdf:parseType="Literal">&lt;p&gt;With the success of self-supervised representations, researchers seek a
better understanding of the information encapsulated within a representation.
Among various interpretability methods, we focus on classification-based linear
probing. We aim to foster a solid understanding and provide guidelines for
linear probing by constructing a novel mathematical framework leveraging
information theory. First, we connect probing with the variational bounds of
mutual information (MI) to relax the probe design, equating linear probing with
fine-tuning. Then, we investigate empirical behaviors and practices of probing
through our mathematical framework. We analyze the layer-wise performance curve
being convex, which seemingly violates the data processing inequality. However,
we show that the intermediate representations can have the biggest MI estimate
because of the tradeoff between better separability and decreasing MI. We
further suggest that the margin of linearly separable representations can be a
criterion for measuring the &quot;goodness of representation.&quot; We also compare
accuracy with MI as the measuring criteria. Finally, we empirically validate
our claims by observing the self-supervised speech models on retaining word and
phoneme information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1&quot;&gt;Kwanghee Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1&quot;&gt;Jee-weon Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1&quot;&gt;Shinji Watanabe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10023">
<title>A Kronecker product accelerated efficient sparse Gaussian Process (E-SGP) for flow emulation. (arXiv:2312.10023v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.10023</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce an efficient sparse Gaussian process (E-SGP) for
the surrogate modelling of fluid mechanics. This novel Bayesian machine
learning algorithm allows efficient model training using databases of different
structures. It is a further development of the approximated sparse GP
algorithm, combining the concept of efficient GP (E-GP) and variational energy
free sparse Gaussian process (VEF-SGP). The developed E-SGP approach exploits
the arbitrariness of inducing points and the monotonically increasing nature of
the objective function with respect to the number of inducing points in
VEF-SGP. By specifying the inducing points on the orthogonal grid/input
subspace and using the Kronecker product, E-SGP significantly improves
computational efficiency without imposing any constraints on the covariance
matrix or increasing the number of parameters that need to be optimised during
training.
&lt;/p&gt;
&lt;p&gt;The E-SGP algorithm developed in this paper outperforms E-GP not only in
scalability but also in model quality in terms of mean standardized logarithmic
loss (MSLL). The computational complexity of E-GP suffers from the cubic growth
regarding the growing structured training database. However, E-SGP maintains
computational efficiency whilst the resolution of the model, (i.e., the number
of inducing points) remains fixed. The examples show that E-SGP produces more
accurate predictions in comparison with E-GP when the model resolutions are
similar in both. E-GP benefits from more training data but comes with higher
computational demands, while E-SGP achieves a comparable level of accuracy but
is more computationally efficient, making E-SGP a potentially preferable choice
for fluid mechanic problems. Furthermore, E-SGP can produce more reasonable
estimates of model uncertainty, whilst E-GP is more likely to produce
over-confident predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1&quot;&gt;Yu Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eaton_M/0/1/0/all/0/1&quot;&gt;Matthew Eaton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bluck_M/0/1/0/all/0/1&quot;&gt;Michael Bluck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10024">
<title>Accelerating Neural Network Training: A Brief Review. (arXiv:2312.10024v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.10024</link>
<description rdf:parseType="Literal">&lt;p&gt;The process of training a deep neural network is characterized by significant
time requirements and associated costs. Although researchers have made
considerable progress in this area, further work is still required due to
resource constraints. This study examines innovative approaches to expedite the
training process of deep neural networks (DNN), with specific emphasis on three
state-of-the-art models such as ResNet50, Vision Transformer (ViT), and
EfficientNet. The research utilizes sophisticated methodologies, including
Gradient Accumulation (GA), Automatic Mixed Precision (AMP), and Pin Memory
(PM), in order to optimize performance and accelerate the training procedure.
&lt;/p&gt;
&lt;p&gt;The study examines the effects of these methodologies on the DNN models
discussed earlier, assessing their efficacy with regard to training rate and
computational efficacy. The study showcases the efficacy of including GA as a
strategic approach, resulting in a noteworthy decrease in the duration required
for training. This enables the models to converge at a faster pace. The
utilization of AMP enhances the speed of computations by taking advantage of
the advantages offered by lower precision arithmetic while maintaining the
correctness of the model.
&lt;/p&gt;
&lt;p&gt;Furthermore, this study investigates the application of Pin Memory as a
strategy to enhance the efficiency of data transmission between the central
processing unit and the graphics processing unit, thereby offering a promising
opportunity for enhancing overall performance. The experimental findings
demonstrate that the combination of these sophisticated methodologies
significantly accelerates the training of DNNs, offering vital insights for
experts seeking to improve the effectiveness of deep learning processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nokhwal_S/0/1/0/all/0/1&quot;&gt;Sahil Nokhwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chilakalapudi_P/0/1/0/all/0/1&quot;&gt;Priyanka Chilakalapudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donekal_P/0/1/0/all/0/1&quot;&gt;Preeti Donekal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandrasekharan_M/0/1/0/all/0/1&quot;&gt;Manoj Chandrasekharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nokhwal_S/0/1/0/all/0/1&quot;&gt;Suman Nokhwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swaroop_R/0/1/0/all/0/1&quot;&gt;Ram Swaroop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bala_R/0/1/0/all/0/1&quot;&gt;Raj Bala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pahune_S/0/1/0/all/0/1&quot;&gt;Saurabh Pahune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1&quot;&gt;Ankit Chaudhary&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10029">
<title>Challenges with unsupervised LLM knowledge discovery. (arXiv:2312.10029v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2312.10029</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that existing unsupervised methods on large language model (LLM)
activations do not discover knowledge -- instead they seem to discover whatever
feature of the activations is most prominent. The idea behind unsupervised
knowledge elicitation is that knowledge satisfies a consistency structure,
which can be used to discover knowledge. We first prove theoretically that
arbitrary features (not just knowledge) satisfy the consistency structure of a
particular leading unsupervised knowledge-elicitation method,
contrast-consistent search (Burns et al. - &lt;a href=&quot;/abs/2212.03827&quot;&gt;arXiv:2212.03827&lt;/a&gt;). We then present a
series of experiments showing settings in which unsupervised methods result in
classifiers that do not predict knowledge, but instead predict a different
prominent feature. We conclude that existing unsupervised methods for
discovering latent knowledge are insufficient, and we contribute sanity checks
to apply to evaluating future knowledge elicitation methods. Conceptually, we
hypothesise that the identification issues explored here, e.g. distinguishing a
model&apos;s knowledge from that of a simulated character&apos;s, will persist for future
unsupervised methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1&quot;&gt;Sebastian Farquhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varma_V/0/1/0/all/0/1&quot;&gt;Vikrant Varma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kenton_Z/0/1/0/all/0/1&quot;&gt;Zachary Kenton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasteiger_J/0/1/0/all/0/1&quot;&gt;Johannes Gasteiger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikulik_V/0/1/0/all/0/1&quot;&gt;Vladimir Mikulik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1&quot;&gt;Rohin Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2001.01258">
<title>The troublesome kernel -- On hallucinations, no free lunches and the accuracy-stability trade-off in inverse problems. (arXiv:2001.01258v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2001.01258</link>
<description rdf:parseType="Literal">&lt;p&gt;Methods inspired by Artificial Intelligence (AI) are starting to
fundamentally change computational science and engineering through breakthrough
performances on challenging problems. However, reliability and trustworthiness
of such techniques is becoming a major concern. In inverse problems in imaging,
the focus of this paper, there is increasing empirical evidence that methods
may suffer from hallucinations, i.e., false, but realistic-looking artifacts;
instability, i.e., sensitivity to perturbations in the data; and unpredictable
generalization, i.e., excellent performance on some images, but significant
deterioration on others. This paper presents a theoretical foundation for these
phenomena. We give a mathematical framework describing how and when such
effects arise in arbitrary reconstruction methods, not just AI-inspired
techniques. Several of our results take the form of `no free lunch&apos; theorems.
Specifically, we show that (i) methods that overperform on a single image can
wrongly transfer details from one image to another, creating a hallucination,
(ii) methods that overperform on two or more images can hallucinate or be
unstable, (iii) optimizing the accuracy-stability trade-off is generally
difficult, (iv) hallucinations and instabilities, if they occur, are not rare
events, and may be encouraged by standard training, (v) it may be impossible to
construct optimal reconstruction maps for certain problems. Our results trace
these effects to the kernel of the forward operator whenever it is nontrivial,
but also extend to the case when the forward operator is ill-conditioned. Based
on these insights, our work aims to spur research into new ways to develop
robust and reliable AI-inspired methods for inverse problems in imaging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschling_N/0/1/0/all/0/1&quot;&gt;Nina M. Gottschling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antun_V/0/1/0/all/0/1&quot;&gt;Vegard Antun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hansen_A/0/1/0/all/0/1&quot;&gt;Anders C. Hansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adcock_B/0/1/0/all/0/1&quot;&gt;Ben Adcock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2003.02214">
<title>Generic Unsupervised Optimization for a Latent Variable Model With Exponential Family Observables. (arXiv:2003.02214v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2003.02214</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent variable models (LVMs) represent observed variables by parameterized
functions of latent variables. Prominent examples of LVMs for unsupervised
learning are probabilistic PCA or probabilistic SC which both assume a weighted
linear summation of the latents to determine the mean of a Gaussian
distribution for the observables. In many cases, however, observables do not
follow a Gaussian distribution. For unsupervised learning, LVMs which assume
specific non-Gaussian observables have therefore been considered. Already for
specific choices of distributions, parameter optimization is challenging and
only a few previous contributions considered LVMs with more generally defined
observable distributions. Here, we consider LVMs that are defined for a range
of different distributions, i.e., observables can follow any (regular)
distribution of the exponential family. The novel class of LVMs presented is
defined for binary latents, and it uses maximization in place of summation to
link the latents to observables. To derive an optimization procedure, we follow
an EM approach for maximum likelihood parameter estimation. We show that a set
of very concise parameter update equations can be derived which feature the
same functional form for all exponential family distributions. The derived
generic optimization can consequently be applied to different types of metric
data as well as to different types of discrete data. Also, the derived
optimization equations can be combined with a recently suggested variational
acceleration which is likewise generically applicable to the LVMs considered
here. So, the combination maintains generic and direct applicability of the
derived optimization procedure, but, crucially, enables efficient scalability.
We numerically verify our analytical results and discuss some potential
applications such as learning of variance structure, noise type estimation and
denoising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mousavi_H/0/1/0/all/0/1&quot;&gt;Hamid Mousavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drefs_J/0/1/0/all/0/1&quot;&gt;Jakob Drefs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hirschberger_F/0/1/0/all/0/1&quot;&gt;Florian Hirschberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucke_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rg L&amp;#xfc;cke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2107.01460">
<title>Mava: a research library for distributed multi-agent reinforcement learning in JAX. (arXiv:2107.01460v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2107.01460</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-agent reinforcement learning (MARL) research is inherently
computationally expensive and it is often difficult to obtain a sufficient
number of experiment samples to test hypotheses and make robust statistical
claims. Furthermore, MARL algorithms are typically complex in their design and
can be tricky to implement correctly. These aspects of MARL present a difficult
challenge when it comes to creating useful software for advanced research. Our
criteria for such software is that it should be simple enough to use to
implement new ideas quickly, while at the same time be scalable and fast enough
to test those ideas in a reasonable amount of time. In this preliminary
technical report, we introduce Mava, a research library for MARL written purely
in JAX, that aims to fulfill these criteria. We discuss the design and core
features of Mava, and demonstrate its use and performance across a variety of
environments. In particular, we show Mava&apos;s substantial speed advantage, with
improvements of 10-100x compared to other popular MARL frameworks, while
maintaining strong performance. This allows for researchers to test ideas in a
few minutes instead of several hours. Finally, Mava forms part of an ecosystem
of libraries that seamlessly integrate with each other to help facilitate
advanced research in MARL. We hope Mava will benefit the community and help
drive scientifically sound and statistically robust research in the field. The
open-source repository for Mava is available at
https://github.com/instadeepai/Mava.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kock_R/0/1/0/all/0/1&quot;&gt;Ruan de Kock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahjoub_O/0/1/0/all/0/1&quot;&gt;Omayma Mahjoub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abramowitz_S/0/1/0/all/0/1&quot;&gt;Sasha Abramowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khlifi_W/0/1/0/all/0/1&quot;&gt;Wiem Khlifi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tilbury_C/0/1/0/all/0/1&quot;&gt;Callum Rhys Tilbury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Formanek_C/0/1/0/all/0/1&quot;&gt;Claude Formanek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smit_A/0/1/0/all/0/1&quot;&gt;Andries Smit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pretorius_A/0/1/0/all/0/1&quot;&gt;Arnu Pretorius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.03169">
<title>Hard Negative Sampling via Regularized Optimal Transport for Contrastive Representation Learning. (arXiv:2111.03169v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.03169</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of designing hard negative sampling distributions for
unsupervised contrastive representation learning. We propose and analyze a
novel min-max framework that seeks a representation which minimizes the maximum
(worst-case) generalized contrastive learning loss over all couplings (joint
distributions between positive and negative samples subject to marginal
constraints) and prove that the resulting min-max optimum representation will
be degenerate. This provides the first theoretical justification for
incorporating additional regularization constraints on the couplings. We
re-interpret the min-max problem through the lens of Optimal Transport (OT)
theory and utilize regularized transport couplings to control the degree of
hardness of negative examples. Through experiments we demonstrate that the
negative samples generated from our designed negative distribution are more
similar to the anchor than those generated from the baseline negative
distribution. We also demonstrate that entropic regularization yields negative
sampling distributions with parametric form similar to that in a recent
state-of-the-art negative sampling design and has similar performance in
multiple datasets. Utilizing the uncovered connection with OT, we propose a new
ground cost for designing the negative distribution and show improved
performance of the learned representation on downstream tasks compared to the
representation learned when using squared Euclidean cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Ruijie Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ishwar_P/0/1/0/all/0/1&quot;&gt;Prakash Ishwar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aeron_S/0/1/0/all/0/1&quot;&gt;Shuchin Aeron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.05841">
<title>Physics-enhanced deep surrogates for partial differential equations. (arXiv:2111.05841v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2111.05841</link>
<description rdf:parseType="Literal">&lt;p&gt;Many physics and engineering applications demand Partial Differential
Equations (PDE) property evaluations that are traditionally computed with
resource-intensive high-fidelity numerical solvers. Data-driven surrogate
models provide an efficient alternative but come with a significant cost of
training. Emerging applications would benefit from surrogates with an improved
accuracy-cost tradeoff, while studied at scale. Here we present a
&quot;physics-enhanced deep-surrogate&quot; (&quot;PEDS&quot;) approach towards developing fast
surrogate models for complex physical systems, which is described by PDEs.
Specifically, a combination of a low-fidelity, explainable physics simulator
and a neural network generator is proposed, which is trained end-to-end to
globally match the output of an expensive high-fidelity numerical solver.
Experiments on three exemplar testcases, diffusion, reaction-diffusion, and
electromagnetic scattering models, show that a PEDS surrogate can be up to
3$\times$ more accurate than an ensemble of feedforward neural networks with
limited data ($\approx 10^3$ training points), and reduces the training data
need by at least a factor of 100 to achieve a target error of 5%. Experiments
reveal that PEDS provides a general, data-driven strategy to bridge the gap
between a vast array of simplified physical models with corresponding
brute-force numerical solvers modeling complex systems, offering accuracy,
speed, data efficiency, as well as physical insights into the process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pestourie_R/0/1/0/all/0/1&quot;&gt;Rapha&amp;#xeb;l Pestourie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mroueh_Y/0/1/0/all/0/1&quot;&gt;Youssef Mroueh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rackauckas_C/0/1/0/all/0/1&quot;&gt;Chris Rackauckas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1&quot;&gt;Payel Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_S/0/1/0/all/0/1&quot;&gt;Steven G. Johnson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.10547">
<title>Optimal Data Selection: An Online Distributed View. (arXiv:2201.10547v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2201.10547</link>
<description rdf:parseType="Literal">&lt;p&gt;The blessing of ubiquitous data also comes with a curse: the communication,
storage, and labeling of massive, mostly redundant datasets. We seek to solve
this problem at its core, collecting only valuable data and throwing out the
rest via submodular maximization. Specifically, we develop algorithms for the
online and distributed version of the problem, where data selection occurs in
an uncoordinated fashion across multiple data streams. We design a general and
flexible core selection routine for our algorithms which, given any stream of
data, any assessment of its value, and any formulation of its selection cost,
extracts the most valuable subset of the stream up to a constant factor while
using minimal memory. Notably, our methods have the same theoretical guarantees
as their offline counterparts, and, as far as we know, provide the first
guarantees for online distributed submodular optimization in the literature.
Finally, in learning tasks on ImageNet and MNIST, we show that our selection
methods outperform random selection by $5-20\%$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Werner_M/0/1/0/all/0/1&quot;&gt;Mariel Werner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angelopoulos_A/0/1/0/all/0/1&quot;&gt;Anastasios Angelopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bates_S/0/1/0/all/0/1&quot;&gt;Stephen Bates&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.15364">
<title>Associative Learning Mechanism for Drug-Target Interaction Prediction. (arXiv:2205.15364v5 [q-bio.BM] UPDATED)</title>
<link>http://arxiv.org/abs/2205.15364</link>
<description rdf:parseType="Literal">&lt;p&gt;As a necessary process in drug development, finding a drug compound that can
selectively bind to a specific protein is highly challenging and costly.
Drug-target affinity (DTA), which represents the strength of drug-target
interaction (DTI), has played an important role in the DTI prediction task over
the past decade. Although deep learning has been applied to DTA-related
research, existing solutions ignore fundamental correlations between molecular
substructures in molecular representation learning of drug compound
molecules/protein targets. Moreover, traditional methods lack the
interpretability of the DTA prediction process. This results in missing feature
information of intermolecular interactions, thereby affecting prediction
performance. Therefore, this paper proposes a DTA prediction method with
interactive learning and an autoencoder mechanism. The proposed model enhances
the corresponding ability to capture the feature information of a single
molecular sequence by the drug/protein molecular representation learning module
and supplements the information interaction between molecular sequence pairs by
the interactive information learning module. The DTA value prediction module
fuses the drug-target pair interaction information to output the predicted
value of DTA. Additionally, this paper theoretically proves that the proposed
method maximizes evidence lower bound (ELBO) for the joint distribution of the
DTA prediction model, which enhances the consistency of the probability
distribution between the actual value and the predicted value. The experimental
results confirm mutual transformer-drug target affinity (MT-DTA) achieves
better performance than other comparative methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhiqin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yao_Z/0/1/0/all/0/1&quot;&gt;Zheng Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Qi_G/0/1/0/all/0/1&quot;&gt;Guanqiu Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Mazur_N/0/1/0/all/0/1&quot;&gt;Neal Mazur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Cong_B/0/1/0/all/0/1&quot;&gt;Baisen Cong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.14284">
<title>Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump ODEs. (arXiv:2206.14284v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2206.14284</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of forecasting general stochastic processes
using a path-dependent extension of the Neural Jump ODE (NJ-ODE) framework
\citep{herrera2021neural}. While NJ-ODE was the first framework to establish
convergence guarantees for the prediction of irregularly observed time series,
these results were limited to data stemming from It\^o-diffusions with complete
observations, in particular Markov processes, where all coordinates are
observed simultaneously. In this work, we generalise these results to generic,
possibly non-Markovian or discontinuous, stochastic processes with incomplete
observations, by utilising the reconstruction properties of the signature
transform. These theoretical results are supported by empirical studies, where
it is shown that the path-dependent NJ-ODE outperforms the original NJ-ODE
framework in the case of non-Markovian data. Moreover, we show that PD-NJ-ODE
can be applied successfully to classical stochastic filtering problems and to
limit order book (LOB) data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krach_F/0/1/0/all/0/1&quot;&gt;Florian Krach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nubel_M/0/1/0/all/0/1&quot;&gt;Marc N&amp;#xfc;bel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teichmann_J/0/1/0/all/0/1&quot;&gt;Josef Teichmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.01272">
<title>A systematic review of the use of Deep Learning in Satellite Imagery for Agriculture. (arXiv:2210.01272v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2210.01272</link>
<description rdf:parseType="Literal">&lt;p&gt;Agricultural research is essential for increasing food production to meet the
requirements of an increasing population in the coming decades. Recently,
satellite technology has been improving rapidly and deep learning has seen much
success in generic computer vision tasks and many application areas which
presents an important opportunity to improve analysis of agricultural land.
Here we present a systematic review of 150 studies to find the current uses of
deep learning on satellite imagery for agricultural research. Although we
identify 5 categories of agricultural monitoring tasks, the majority of the
research interest is in crop segmentation and yield prediction. We found that,
when used, modern deep learning methods consistently outperformed traditional
machine learning across most tasks; the only exception was that Long Short-Term
Memory (LSTM) Recurrent Neural Networks did not consistently outperform Random
Forests (RF) for yield prediction. The reviewed studies have largely adopted
methodologies from generic computer vision, except for one major omission:
benchmark datasets are not utilised to evaluate models across studies, making
it difficult to compare results. Additionally, some studies have specifically
utilised the extra spectral resolution available in satellite imagery, but
other divergent properties of satellite images - such as the hugely different
scales of spatial patterns - are not being taken advantage of in the reviewed
studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Victor_B/0/1/0/all/0/1&quot;&gt;Brandon Victor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhen He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nibali_A/0/1/0/all/0/1&quot;&gt;Aiden Nibali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.04806">
<title>Machine-Learned Exclusion Limits without Binning. (arXiv:2211.04806v2 [hep-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2211.04806</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine-Learned Likelihoods (MLL) combines machine-learning classification
techniques with likelihood-based inference tests to estimate the experimental
sensitivity of high-dimensional data sets. We extend the MLL method by
including Kernel Density Estimators (KDE) to avoid binning the classifier
output to extract the resulting one-dimensional signal and background
probability density functions. We first test our method on toy models generated
with multivariate Gaussian distributions, where the true probability
distribution functions are known. Later, we apply the method to two cases of
interest at the LHC: a search for exotic Higgs bosons, and a $Z&apos;$ boson
decaying into lepton pairs. In contrast to physical-based quantities, the
typical fluctuations of the ML outputs give non-smooth probability
distributions for pure-signal and pure-background samples. The non-smoothness
is propagated into the density estimation due to the good performance and
flexibility of the KDE method. We study its impact on the final significance
computation, and we compare the results using the average of several
independent ML output realizations, which allows us to obtain smoother
distributions. We conclude that the significance estimation turns out to be not
sensible to this issue.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Arganda_E/0/1/0/all/0/1&quot;&gt;Ernesto Arganda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Perez_A/0/1/0/all/0/1&quot;&gt;Andres D. Perez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Rios_M/0/1/0/all/0/1&quot;&gt;Martin de los Rios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Seoane_R/0/1/0/all/0/1&quot;&gt;Rosa Mar&amp;#xed;a Sand&amp;#xe1; Seoane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.11727">
<title>Parametric Classification for Generalized Category Discovery: A Baseline Study. (arXiv:2211.11727v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2211.11727</link>
<description rdf:parseType="Literal">&lt;p&gt;Generalized Category Discovery (GCD) aims to discover novel categories in
unlabelled datasets using knowledge learned from labelled samples. Previous
studies argued that parametric classifiers are prone to overfitting to seen
categories, and endorsed using a non-parametric classifier formed with
semi-supervised k-means. However, in this study, we investigate the failure of
parametric classifiers, verify the effectiveness of previous design choices
when high-quality supervision is available, and identify unreliable
pseudo-labels as a key problem. We demonstrate that two prediction biases
exist: the classifier tends to predict seen classes more often, and produces an
imbalanced distribution across seen and novel categories. Based on these
findings, we propose a simple yet effective parametric classification method
that benefits from entropy regularisation, achieves state-of-the-art
performance on multiple GCD benchmarks and shows strong robustness to unknown
class numbers. We hope the investigation and proposed simple framework can
serve as a strong baseline to facilitate future studies in this field. Our code
is available at: https://github.com/CVMI-Lab/SimGCD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1&quot;&gt;Xin Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1&quot;&gt;Bingchen Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1&quot;&gt;Xiaojuan Qi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.07514">
<title>PulseImpute: A Novel Benchmark Task for Pulsative Physiological Signal Imputation. (arXiv:2212.07514v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.07514</link>
<description rdf:parseType="Literal">&lt;p&gt;The promise of Mobile Health (mHealth) is the ability to use wearable sensors
to monitor participant physiology at high frequencies during daily life to
enable temporally-precise health interventions. However, a major challenge is
frequent missing data. Despite a rich imputation literature, existing
techniques are ineffective for the pulsative signals which comprise many
mHealth applications, and a lack of available datasets has stymied progress. We
address this gap with PulseImpute, the first large-scale pulsative signal
imputation challenge which includes realistic mHealth missingness models, an
extensive set of baselines, and clinically-relevant downstream tasks. Our
baseline models include a novel transformer-based architecture designed to
exploit the structure of pulsative signals. We hope that PulseImpute will
enable the ML community to tackle this significant and challenging task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Maxwell A. Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreno_A/0/1/0/all/0/1&quot;&gt;Alexander Moreno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagesh_S/0/1/0/all/0/1&quot;&gt;Supriya Nagesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aydemir_V/0/1/0/all/0/1&quot;&gt;V. Burak Aydemir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wetter_D/0/1/0/all/0/1&quot;&gt;David W. Wetter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Santosh Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1&quot;&gt;James M. Rehg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.07786">
<title>Convergent Data-driven Regularizations for CT Reconstruction. (arXiv:2212.07786v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/2212.07786</link>
<description rdf:parseType="Literal">&lt;p&gt;The reconstruction of images from their corresponding noisy Radon transform
is a typical example of an ill-posed linear inverse problem as arising in the
application of computerized tomography (CT). As the (naive) solution does not
depend on the measured data continuously, regularization is needed to
re-establish a continuous dependence. In this work, we investigate simple, but
yet still provably convergent approaches to learning linear regularization
methods from data. More specifically, we analyze two approaches: One generic
linear regularization that learns how to manipulate the singular values of the
linear operator in an extension of our previous work, and one tailored approach
in the Fourier domain that is specific to CT-reconstruction. We prove that such
approaches become convergent regularization methods as well as the fact that
the reconstructions they provide are typically much smoother than the training
data they were trained on. Finally, we compare the spectral as well as the
Fourier-based approaches for CT-reconstruction numerically, discuss their
advantages and disadvantages and investigate the effect of discretization
errors at different resolutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kabri_S/0/1/0/all/0/1&quot;&gt;Samira Kabri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Auras_A/0/1/0/all/0/1&quot;&gt;Alexander Auras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Riccio_D/0/1/0/all/0/1&quot;&gt;Danilo Riccio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bauermeister_H/0/1/0/all/0/1&quot;&gt;Hartmut Bauermeister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Benning_M/0/1/0/all/0/1&quot;&gt;Martin Benning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Moeller_M/0/1/0/all/0/1&quot;&gt;Michael Moeller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Burger_M/0/1/0/all/0/1&quot;&gt;Martin Burger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.12329">
<title>Approaching Globally Optimal Energy Efficiency in Interference Networks via Machine Learning. (arXiv:2212.12329v2 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/2212.12329</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents a machine learning approach to optimize the energy
efficiency (EE) in a multi-cell wireless network. This optimization problem is
non-convex and its global optimum is difficult to find. In the literature,
either simple but suboptimal approaches or optimal methods with high complexity
and poor scalability are proposed. In contrast, we propose a machine learning
framework to approach the global optimum. While the neural network (NN)
training takes moderate time, application with the trained model requires very
low computational complexity. In particular, we introduce a novel objective
function based on stochastic actions to solve the non-convex optimization
problem. Besides, we design a dedicated NN architecture for the multi-cell
network optimization problems that is permutation-equivariant. It classifies
channels according to their roles in the EE computation. In this way, we encode
our domain knowledge into the NN design and shed light into the black box of
machine learning. Training and testing results show that the proposed method
without supervision and with reasonable computational effort achieves an EE
close to the global optimum found by the branch-and-bound algorithm. Hence, the
proposed approach balances between computational complexity and performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Peng_B/0/1/0/all/0/1&quot;&gt;Bile Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Besser_K/0/1/0/all/0/1&quot;&gt;Karl-Ludwig Besser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Raghunath_R/0/1/0/all/0/1&quot;&gt;Ramprasad Raghunath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jorswieck_E/0/1/0/all/0/1&quot;&gt;Eduard A. Jorswieck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.13764">
<title>Unsupervised Neighborhood Propagation Kernel Layers for Semi-supervised Node Classification. (arXiv:2301.13764v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.13764</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a deep Graph Convolutional Kernel Machine (GCKM) for
semi-supervised node classification in graphs. The method is built of two main
types of blocks: (i) We introduce unsupervised kernel machine layers
propagating the node features in a one-hop neighborhood, using implicit node
feature mappings. (ii) We specify a semi-supervised classification kernel
machine through the lens of the Fenchel-Young inequality. We derive an
effective initialization scheme and efficient end-to-end training algorithm in
the dual variables for the full architecture. The main idea underlying GCKM is
that, because of the unsupervised core, the final model can achieve higher
performance in semi-supervised node classification when few labels are
available for training. Experimental results demonstrate the effectiveness of
the proposed framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achten_S/0/1/0/all/0/1&quot;&gt;Sonny Achten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tonin_F/0/1/0/all/0/1&quot;&gt;Francesco Tonin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patrinos_P/0/1/0/all/0/1&quot;&gt;Panagiotis Patrinos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1&quot;&gt;Johan A. K. Suykens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.01125">
<title>Distilling Multi-Level X-vector Knowledge for Small-footprint Speaker Verification. (arXiv:2303.01125v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2303.01125</link>
<description rdf:parseType="Literal">&lt;p&gt;Even though deep speaker models have demonstrated impressive accuracy in
speaker verification tasks, this often comes at the expense of increased model
size and computation time, presenting challenges for deployment in
resource-constrained environments. Our research focuses on addressing this
limitation through the development of small footprint deep speaker embedding
extraction using knowledge distillation. While previous work in this domain has
concentrated on speaker embedding extraction at the utterance level, our
approach involves amalgamating embeddings from different levels of the x-vector
model (teacher network) to train a compact student network. The results
highlight the significance of frame-level information, with the student models
exhibiting a remarkable size reduction of 85%-91% compared to their teacher
counterparts, depending on the size of the teacher embeddings. Notably, by
concatenating teacher embeddings, we achieve student networks that maintain
comparable performance to the teacher while enjoying a substantial 75%
reduction in model size. These findings and insights extend to other x-vector
variants, underscoring the broad applicability of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xuechen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahidullah_M/0/1/0/all/0/1&quot;&gt;Md Sahidullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kinnunen_T/0/1/0/all/0/1&quot;&gt;Tomi Kinnunen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.05754">
<title>Decomposed Diffusion Sampler for Accelerating Large-Scale Inverse Problems. (arXiv:2303.05754v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.05754</link>
<description rdf:parseType="Literal">&lt;p&gt;Krylov subspace, which is generated by multiplying a given vector by the
matrix of a linear transformation and its successive powers, has been
extensively studied in classical optimization literature to design algorithms
that converge quickly for large linear inverse problems. For example, the
conjugate gradient method (CG), one of the most popular Krylov subspace
methods, is based on the idea of minimizing the residual error in the Krylov
subspace. However, with the recent advancement of high-performance diffusion
solvers for inverse problems, it is not clear how classical wisdom can be
synergistically combined with modern diffusion models. In this study, we
propose a novel and efficient diffusion sampling strategy that synergistically
combine the diffusion sampling and Krylov subspace methods. Specifically, we
prove that if the tangent space at a denoised sample by Tweedie&apos;s formula forms
a Krylov subspace, then the CG initialized with the denoised data ensures the
data consistency update to remain in the tangent space. This negates the need
to compute the manifold-constrained gradient (MCG), leading to a more efficient
diffusion sampling method. Our method is applicable regardless of the
parametrization and setting (i.e., VE, VP). Notably, we achieve
state-of-the-art reconstruction quality on challenging real-world medical
inverse imaging problems, including multi-coil MRI reconstruction and 3D CT
reconstruction. Moreover, our proposed method achieves more than 80 times
faster inference time than the previous state-of-the-art method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1&quot;&gt;Hyungjin Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Suhyeon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.01731">
<title>Selective Knowledge Sharing for Privacy-Preserving Federated Distillation without A Good Teacher. (arXiv:2304.01731v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.01731</link>
<description rdf:parseType="Literal">&lt;p&gt;While federated learning is promising for privacy-preserving collaborative
learning without revealing local data, it remains vulnerable to white-box
attacks and struggles to adapt to heterogeneous clients. Federated distillation
(FD), built upon knowledge distillation--an effective technique for
transferring knowledge from a teacher model to student models--emerges as an
alternative paradigm, which provides enhanced privacy guarantees and addresses
model heterogeneity. Nevertheless, challenges arise due to variations in local
data distributions and the absence of a well-trained teacher model, which leads
to misleading and ambiguous knowledge sharing that significantly degrades model
performance. To address these issues, this paper proposes a selective knowledge
sharing mechanism for FD, termed Selective-FD. It includes client-side
selectors and a server-side selector to accurately and precisely identify
knowledge from local and ensemble predictions, respectively. Empirical studies,
backed by theoretical insights, demonstrate that our approach enhances the
generalization capabilities of the FD framework and consistently outperforms
baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1&quot;&gt;Jiawei Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fangzhao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.03724">
<title>GeoTMI:Predicting quantum chemical property with easy-to-obtain geometry via positional denoising. (arXiv:2304.03724v3 [physics.chem-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2304.03724</link>
<description rdf:parseType="Literal">&lt;p&gt;As quantum chemical properties have a dependence on their geometries, graph
neural networks (GNNs) using 3D geometric information have achieved high
prediction accuracy in many tasks. However, they often require 3D geometries
obtained from high-level quantum mechanical calculations, which are practically
infeasible, limiting their applicability to real-world problems. To tackle
this, we propose a new training framework, GeoTMI, that employs denoising
process to predict properties accurately using easy-to-obtain geometries
(corrupted versions of correct geometries, such as those obtained from
low-level calculations). Our starting point was the idea that the correct
geometry is the best description of the target property. Hence, to incorporate
information of the correct, GeoTMI aims to maximize mutual information between
three variables: the correct and the corrupted geometries and the property.
GeoTMI also explicitly updates the corrupted input to approach the correct
geometry as it passes through the GNN layers, contributing to more effective
denoising. We investigated the performance of the proposed method using 3D GNNs
for three prediction tasks: molecular properties, a chemical reaction property,
and relaxed energy in a heterogeneous catalytic system. Our results showed
consistent improvements in accuracy across various tasks, demonstrating the
effectiveness and robustness of GeoTMI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyeonsu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Woo_J/0/1/0/all/0/1&quot;&gt;Jeheon Woo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seonghwan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Moon_S/0/1/0/all/0/1&quot;&gt;Seokhyun Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jun Hyeong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kim_W/0/1/0/all/0/1&quot;&gt;Woo Youn Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.05836">
<title>A Game-theoretic Framework for Privacy-preserving Federated Learning. (arXiv:2304.05836v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.05836</link>
<description rdf:parseType="Literal">&lt;p&gt;In federated learning, benign participants aim to optimize a global model
collaboratively. However, the risk of \textit{privacy leakage} cannot be
ignored in the presence of \textit{semi-honest} adversaries. Existing research
has focused either on designing protection mechanisms or on inventing attacking
mechanisms. While the battle between defenders and attackers seems
never-ending, we are concerned with one critical question: is it possible to
prevent potential attacks in advance? To address this, we propose the first
game-theoretic framework that considers both FL defenders and attackers in
terms of their respective payoffs, which include computational costs, FL model
utilities, and privacy leakage risks. We name this game the federated learning
privacy game (FLPG), in which neither defenders nor attackers are aware of all
participants&apos; payoffs.
&lt;/p&gt;
&lt;p&gt;To handle the \textit{incomplete information} inherent in this situation, we
propose associating the FLPG with an \textit{oracle} that has two primary
responsibilities. First, the oracle provides lower and upper bounds of the
payoffs for the players. Second, the oracle acts as a correlation device,
privately providing suggested actions to each player. With this novel
framework, we analyze the optimal strategies of defenders and attackers.
Furthermore, we derive and demonstrate conditions under which the attacker, as
a rational decision-maker, should always follow the oracle&apos;s suggestion
\textit{not to attack}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaojin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Lixin Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Siwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenjie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kai Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.07213">
<title>Very high resolution canopy height maps from RGB imagery using self-supervised vision transformer and convolutional decoder trained on Aerial Lidar. (arXiv:2304.07213v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.07213</link>
<description rdf:parseType="Literal">&lt;p&gt;Vegetation structure mapping is critical for understanding the global carbon
cycle and monitoring nature-based approaches to climate adaptation and
mitigation. Repeated measurements of these data allow for the observation of
deforestation or degradation of existing forests, natural forest regeneration,
and the implementation of sustainable agricultural practices like agroforestry.
Assessments of tree canopy height and crown projected area at a high spatial
resolution are also important for monitoring carbon fluxes and assessing
tree-based land uses, since forest structures can be highly spatially
heterogeneous, especially in agroforestry systems. Very high resolution
satellite imagery (less than one meter (1m) Ground Sample Distance) makes it
possible to extract information at the tree level while allowing monitoring at
a very large scale. This paper presents the first high-resolution canopy height
map concurrently produced for multiple sub-national jurisdictions.
Specifically, we produce very high resolution canopy height maps for the states
of California and Sao Paulo, a significant improvement in resolution over the
ten meter (10m) resolution of previous Sentinel / GEDI based worldwide maps of
canopy height. The maps are generated by the extraction of features from a
self-supervised model trained on Maxar imagery from 2017 to 2020, and the
training of a dense prediction decoder against aerial lidar maps. We also
introduce a post-processing step using a convolutional network trained on GEDI
observations. We evaluate the proposed maps with set-aside validation lidar
data as well as by comparing with other remotely sensed maps and
field-collected data, and find our model produces an average Mean Absolute
Error (MAE) of 2.8 meters and Mean Error (ME) of 0.6 meters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolan_J/0/1/0/all/0/1&quot;&gt;Jamie Tolan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hung-I Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nosarzewski_B/0/1/0/all/0/1&quot;&gt;Ben Nosarzewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Couairon_G/0/1/0/all/0/1&quot;&gt;Guillaume Couairon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vo_H/0/1/0/all/0/1&quot;&gt;Huy Vo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brandt_J/0/1/0/all/0/1&quot;&gt;John Brandt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spore_J/0/1/0/all/0/1&quot;&gt;Justine Spore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1&quot;&gt;Sayantan Majumdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haziza_D/0/1/0/all/0/1&quot;&gt;Daniel Haziza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vamaraju_J/0/1/0/all/0/1&quot;&gt;Janaki Vamaraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moutakanni_T/0/1/0/all/0/1&quot;&gt;Theo Moutakanni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bojanowski_P/0/1/0/all/0/1&quot;&gt;Piotr Bojanowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johns_T/0/1/0/all/0/1&quot;&gt;Tracy Johns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_B/0/1/0/all/0/1&quot;&gt;Brian White&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiecke_T/0/1/0/all/0/1&quot;&gt;Tobias Tiecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Couprie_C/0/1/0/all/0/1&quot;&gt;Camille Couprie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.08754">
<title>W-MAE: Pre-trained weather model with masked autoencoder for multi-variable weather forecasting. (arXiv:2304.08754v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.08754</link>
<description rdf:parseType="Literal">&lt;p&gt;Weather forecasting is a long-standing computational challenge with direct
societal and economic impacts. This task involves a large amount of continuous
data collection and exhibits rich spatiotemporal dependencies over long
periods, making it highly suitable for deep learning models. In this paper, we
apply pre-training techniques to weather forecasting and propose W-MAE, a
Weather model with Masked AutoEncoder pre-training for weather forecasting.
W-MAE is pre-trained in a self-supervised manner to reconstruct spatial
correlations within meteorological variables. On the temporal scale, we
fine-tune the pre-trained W-MAE to predict the future states of meteorological
variables, thereby modeling the temporal dependencies present in weather data.
We conduct our experiments using the fifth-generation ECMWF Reanalysis (ERA5)
data, with samples selected every six hours. Experimental results show that our
W-MAE framework offers three key benefits: 1) when predicting the future state
of meteorological variables, the utilization of our pre-trained W-MAE can
effectively alleviate the problem of cumulative errors in prediction,
maintaining stable performance in the short-to-medium term; 2) when predicting
diagnostic variables (e.g., total precipitation), our model exhibits
significant performance advantages over FourCastNet; 3) Our task-agnostic
pre-training schema can be easily integrated with various task-specific models.
When our pre-training framework is applied to FourCastNet, it yields an average
20% performance improvement in Anomaly Correlation Coefficient (ACC).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Man_X/0/1/0/all/0/1&quot;&gt;Xin Man&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chenghong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jin Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Changyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1&quot;&gt;Jie Shao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.11476">
<title>Learning Diverse Risk Preferences in Population-based Self-play. (arXiv:2305.11476v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.11476</link>
<description rdf:parseType="Literal">&lt;p&gt;Among the great successes of Reinforcement Learning (RL), self-play
algorithms play an essential role in solving competitive games. Current
self-play algorithms optimize the agent to maximize expected win-rates against
its current or historical copies, making it often stuck in the local optimum
and its strategy style simple and homogeneous. A possible solution is to
improve the diversity of policies, which helps the agent break the stalemate
and enhances its robustness when facing different opponents. However, enhancing
diversity in the self-play algorithms is not trivial. In this paper, we aim to
introduce diversity from the perspective that agents could have diverse risk
preferences in the face of uncertainty. Specifically, we design a novel
reinforcement learning algorithm called Risk-sensitive Proximal Policy
Optimization (RPPO), which smoothly interpolates between worst-case and
best-case policy learning and allows for policy learning with desired risk
preferences. Seamlessly integrating RPPO with population-based self-play,
agents in the population optimize dynamic risk-sensitive objectives with
experiences from playing against diverse opponents. Empirical results show that
our method achieves comparable or superior performance in competitive games and
that diverse modes of behaviors emerge. Our code is public online at
\url{https://github.com/Jackory/RPBT}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yuhua Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qihan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaoteng Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chenghao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yiqin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jun Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1&quot;&gt;Bin Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qianchuan Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12066">
<title>Dynamic Gradient Balancing for Enhanced Adversarial Attacks on Multi-Task Models. (arXiv:2305.12066v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12066</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-task learning (MTL) creates a single machine learning model called
multi-task model to simultaneously perform multiple tasks. Although the
security of single task classifiers has been extensively studied, there are
several critical security research questions for multi-task models including 1)
How secure are multi-task models to single task adversarial machine learning
attacks, 2) Can adversarial attacks be designed to attack multiple tasks
simultaneously, and 3) Does task sharing and adversarial training increase
multi-task model robustness to adversarial attacks? In this paper, we answer
these questions through careful analysis and rigorous experimentation. First,
we develop na\&quot;ive adaptation of single-task white-box attacks and analyze
their inherent drawbacks. We then propose a novel attack framework, Dynamic
Gradient Balancing Attack (DGBA). Our framework poses the problem of attacking
a multi-task model as an optimization problem based on averaged relative loss
change, which can be solved by approximating the problem as an integer linear
programming problem. Extensive evaluation on two popular MTL benchmarks, NYUv2
and Tiny-Taxonomy, demonstrates the effectiveness of DGBA compared to na\&quot;ive
multi-task attack baselines on both clean and adversarially trained multi-task
models. The results also reveal a fundamental trade-off between improving task
accuracy by sharing parameters across tasks and undermining model robustness
due to increased attack transferability from parameter sharing. DGBA is
open-sourced and available at https://github.com/zhanglijun95/MTLAttack-DGBA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lijun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_K/0/1/0/all/0/1&quot;&gt;Kaleel Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1&quot;&gt;Caiwen Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_H/0/1/0/all/0/1&quot;&gt;Hui Guan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13030">
<title>Adaptive action supervision in reinforcement learning from real-world multi-agent demonstrations. (arXiv:2305.13030v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13030</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling of real-world biological multi-agents is a fundamental problem in
various scientific and engineering fields. Reinforcement learning (RL) is a
powerful framework to generate flexible and diverse behaviors in cyberspace;
however, when modeling real-world biological multi-agents, there is a domain
gap between behaviors in the source (i.e., real-world data) and the target
(i.e., cyberspace for RL), and the source environment parameters are usually
unknown. In this paper, we propose a method for adaptive action supervision in
RL from real-world demonstrations in multi-agent scenarios. We adopt an
approach that combines RL and supervised learning by selecting actions of
demonstrations in RL based on the minimum distance of dynamic time warping for
utilizing the information of the unknown source dynamics. This approach can be
easily applied to many existing neural network architectures and provide us
with an RL model balanced between reproducibility as imitation and
generalization ability to obtain rewards in cyberspace. In the experiments,
using chase-and-escape and football tasks with the different dynamics between
the unknown source and target environments, we show that our approach achieved
a balance between the reproducibility and the generalization ability compared
with the baselines. In particular, we used the tracking data of professional
football players as expert demonstrations in football and show successful
performances despite the larger gap between behaviors in the source and target
environments than the chase-and-escape task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujii_K/0/1/0/all/0/1&quot;&gt;Keisuke Fujii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsutsui_K/0/1/0/all/0/1&quot;&gt;Kazushi Tsutsui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scott_A/0/1/0/all/0/1&quot;&gt;Atom Scott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakahara_H/0/1/0/all/0/1&quot;&gt;Hiroshi Nakahara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takeishi_N/0/1/0/all/0/1&quot;&gt;Naoya Takeishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawahara_Y/0/1/0/all/0/1&quot;&gt;Yoshinobu Kawahara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14160">
<title>Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning. (arXiv:2305.14160v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14160</link>
<description rdf:parseType="Literal">&lt;p&gt;In-context learning (ICL) emerges as a promising capability of large language
models (LLMs) by providing them with demonstration examples to perform diverse
tasks. However, the underlying mechanism of how LLMs learn from the provided
context remains under-explored. In this paper, we investigate the working
mechanism of ICL through an information flow lens. Our findings reveal that
label words in the demonstration examples function as anchors: (1) semantic
information aggregates into label word representations during the shallow
computation layers&apos; processing; (2) the consolidated information in label words
serves as a reference for LLMs&apos; final predictions. Based on these insights, we
introduce an anchor re-weighting method to improve ICL performance, a
demonstration compression technique to expedite inference, and an analysis
framework for diagnosing ICL errors in GPT2-XL. The promising applications of
our findings again validate the uncovered ICL working mechanism and pave the
way for future studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lean Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1&quot;&gt;Damai Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Deli Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1&quot;&gt;Fandong Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jie Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xu Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.15835">
<title>PDE+: Enhancing Generalization via PDE with Adaptive Distributional Diffusion. (arXiv:2305.15835v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.15835</link>
<description rdf:parseType="Literal">&lt;p&gt;The generalization of neural networks is a central challenge in machine
learning, especially concerning the performance under distributions that differ
from training ones. Current methods, mainly based on the data-driven paradigm
such as data augmentation, adversarial training, and noise injection, may
encounter limited generalization due to model non-smoothness. In this paper, we
propose to investigate generalization from a Partial Differential Equation
(PDE) perspective, aiming to enhance it directly through the underlying
function of neural networks, rather than focusing on adjusting input data.
Specifically, we first establish the connection between neural network
generalization and the smoothness of the solution to a specific PDE, namely
&quot;transport equation&quot;. Building upon this, we propose a general framework that
introduces adaptive distributional diffusion into transport equation to enhance
the smoothness of its solution, thereby improving generalization. In the
context of neural networks, we put this theoretical framework into practice as
$\textbf{PDE+}$ ($\textbf{PDE}$ with $\textbf{A}$daptive
$\textbf{D}$istributional $\textbf{D}$iffusion) which diffuses each sample into
a distribution covering semantically similar inputs. This enables better
coverage of potentially unobserved distributions in training, thus improving
generalization beyond merely data-driven methods. The effectiveness of PDE+ is
validated through extensive experimental settings, demonstrating its superior
performance compared to SOTA methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1&quot;&gt;Yige Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1&quot;&gt;Bingbing Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Bo Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1&quot;&gt;Liang Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fei Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Huawei Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xueqi Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18396">
<title>LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers. (arXiv:2305.18396v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18396</link>
<description rdf:parseType="Literal">&lt;p&gt;The community explored to build private inference frameworks for
transformer-based large language models (LLMs) in a server-client setting,
where the server holds the model parameters and the client inputs its private
data (or prompt) for inference. However, these frameworks impose significant
overhead when the private inputs are forward propagated through the original
LLMs. In this paper, we show that substituting the computation- and
communication-heavy operators in the transformer architecture with
privacy-computing friendly approximations can greatly reduce the private
inference costs while incurring very minor impact on model performance.
Compared to state-of-the-art Iron (NeurIPS 2022), our privacy-computing
friendly model inference pipeline achieves a $5\times$ acceleration in
computation and an 80% reduction in communication overhead, while retaining
nearly identical accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xuanqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhuotao Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.10395">
<title>Distributed Semi-Supervised Sparse Statistical Inference. (arXiv:2306.10395v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.10395</link>
<description rdf:parseType="Literal">&lt;p&gt;The debiased estimator is a crucial tool in statistical inference for
high-dimensional model parameters. However, constructing such an estimator
involves estimating the high-dimensional inverse Hessian matrix, incurring
significant computational costs. This challenge becomes particularly acute in
distributed setups, where traditional methods necessitate computing a debiased
estimator on every machine. This becomes unwieldy, especially with a large
number of machines. In this paper, we delve into semi-supervised sparse
statistical inference in a distributed setup. An efficient multi-round
distributed debiased estimator, which integrates both labeled and unlabelled
data, is developed. We will show that the additional unlabeled data helps to
improve the statistical rate of each round of iteration. Our approach offers
tailored debiasing methods for $M$-estimation and generalized linear models
according to the specific form of the loss function. Our method also applies to
a non-smooth loss like absolute deviation loss. Furthermore, our algorithm is
computationally efficient since it requires only one estimation of a
high-dimensional inverse covariance matrix. We demonstrate the effectiveness of
our method by presenting simulation studies and real data applications that
highlight the benefits of incorporating unlabeled data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tu_J/0/1/0/all/0/1&quot;&gt;Jiyuan Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weidong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mao_X/0/1/0/all/0/1&quot;&gt;Xiaojun Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Mingyue Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00131">
<title>Machine learning for advancing low-temperature plasma modeling and simulation. (arXiv:2307.00131v2 [physics.plasm-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2307.00131</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning has had an enormous impact in many scientific disciplines.
Also in the field of low-temperature plasma modeling and simulation it has
attracted significant interest within the past years. Whereas its application
should be carefully assessed in general, many aspects of plasma modeling and
simulation have benefited substantially from recent developments within the
field of machine learning and data-driven modeling. In this survey, we approach
two main objectives: (a) We review the state-of-the-art focusing on approaches
to low-temperature plasma modeling and simulation. By dividing our survey into
plasma physics, plasma chemistry, plasma-surface interactions, and plasma
process control, we aim to extensively discuss relevant examples from
literature. (b) We provide a perspective of potential advances to plasma
science and technology. We specifically elaborate on advances possibly enabled
by adaptation from other scientific disciplines. We argue that not only the
known unknowns, but also unknown unknowns may be discovered due to the inherent
propensity of data-driven methods to spotlight hidden patterns in data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Trieschmann_J/0/1/0/all/0/1&quot;&gt;Jan Trieschmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Vialetto_L/0/1/0/all/0/1&quot;&gt;Luca Vialetto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gergs_T/0/1/0/all/0/1&quot;&gt;Tobias Gergs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02405">
<title>$\nu^2$-Flows: Fast and improved neutrino reconstruction in multi-neutrino final states with conditional normalizing flows. (arXiv:2307.02405v3 [hep-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02405</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we introduce $\nu^2$-Flows, an extension of the $\nu$-Flows
method to final states containing multiple neutrinos. The architecture can
natively scale for all combinations of object types and multiplicities in the
final state for any desired neutrino multiplicities. In $t\bar{t}$ dilepton
events, the momenta of both neutrinos and correlations between them are
reconstructed more accurately than when using the most popular standard
analytical techniques, and solutions are found for all events. Inference time
is significantly faster than competing methods, and can be reduced further by
evaluating in parallel on graphics processing units. We apply $\nu^2$-Flows to
$t\bar{t}$ dilepton events and show that the per-bin uncertainties in unfolded
distributions is much closer to the limit of performance set by perfect
neutrino reconstruction than standard techniques. For the chosen double
differential observables $\nu^2$-Flows results in improved statistical
precision for each bin by a factor of 1.5 to 2 in comparison to the Neutrino
Weighting method and up to a factor of four in comparison to the Ellipse
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Raine_J/0/1/0/all/0/1&quot;&gt;John Andrew Raine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Leigh_M/0/1/0/all/0/1&quot;&gt;Matthew Leigh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Zoch_K/0/1/0/all/0/1&quot;&gt;Knut Zoch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Golling_T/0/1/0/all/0/1&quot;&gt;Tobias Golling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.10870">
<title>Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2307.10870</link>
<description rdf:parseType="Literal">&lt;p&gt;Many recent theoretical works on \emph{meta-learning} aim to achieve
guarantees in leveraging similar representational structures from related tasks
towards simplifying a target task. Importantly, the main aim in theory works on
the subject is to understand the extent to which convergence rates -- in
learning a common representation -- \emph{may scale with the number $N$ of
tasks} (as well as the number of samples per task). First steps in this setting
demonstrate this property when both the shared representation amongst tasks,
and task-specific regression functions, are linear. This linear setting readily
reveals the benefits of aggregating tasks, e.g., via averaging arguments. In
practice, however, the representation is often highly nonlinear, introducing
nontrivial biases in each task that cannot easily be averaged out as in the
linear case. In the present work, we derive theoretical guarantees for
meta-learning with nonlinear representations. In particular, assuming the
shared nonlinearity maps to an infinite-dimensional RKHS, we show that
additional biases can be mitigated with careful regularization that leverages
the smoothness of task-specific regression functions,
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meunier_D/0/1/0/all/0/1&quot;&gt;Dimitri Meunier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1&quot;&gt;Arthur Gretton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1&quot;&gt;Samory Kpotufe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.13332">
<title>The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation. (arXiv:2307.13332v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.13332</link>
<description rdf:parseType="Literal">&lt;p&gt;Theoretical guarantees in reinforcement learning (RL) are known to suffer
multiplicative blow-up factors with respect to the misspecification error of
function approximation. Yet, the nature of such \emph{approximation factors} --
especially their optimal form in a given learning problem -- is poorly
understood. In this paper we study this question in linear off-policy value
function estimation, where many open questions remain. We study the
approximation factor in a broad spectrum of settings, such as with the weighted
$L_2$-norm (where the weighting is the offline state distribution), the
$L_\infty$ norm, the presence vs. absence of state aliasing, and full vs.
partial coverage of the state space. We establish the optimal asymptotic
approximation factors (up to constants) for all of these settings. In
particular, our bounds identify two instance-dependent factors for the
$L_2(\mu)$ norm and only one for the $L_\infty$ norm, which are shown to
dictate the hardness of off-policy evaluation under misspecification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amortila_P/0/1/0/all/0/1&quot;&gt;Philip Amortila&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1&quot;&gt;Nan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1&quot;&gt;Csaba Szepesv&amp;#xe1;ri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04237">
<title>Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction. (arXiv:2308.04237v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/2308.04237</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider a wireless federated inference scenario in which
devices and a server share a pre-trained machine learning model. The devices
communicate statistical information about their local data to the server over a
common wireless channel, aiming to enhance the quality of the inference
decision at the server. Recent work has introduced federated conformal
prediction (CP), which leverages devices-to-server communication to improve the
reliability of the server&apos;s decision. With federated CP, devices communicate to
the server information about the loss accrued by the shared pre-trained model
on the local data, and the server leverages this information to calibrate a
decision interval, or set, so that it is guaranteed to contain the correct
answer with a pre-defined target reliability level. Previous work assumed
noise-free communication, whereby devices can communicate a single real number
to the server. In this paper, we study for the first time federated CP in a
wireless setting. We introduce a novel protocol, termed wireless federated
conformal prediction (WFCP), which builds on type-based multiple access (TBMA)
and on a novel quantile correction strategy. WFCP is proved to provide formal
reliability guarantees in terms of coverage of the predicted set produced by
the server. Using numerical results, we demonstrate the significant advantages
of WFCP against digital implementations of existing federated CP schemes,
especially in regimes with limited communication resources and/or large number
of devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Meiyi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zecchin_M/0/1/0/all/0/1&quot;&gt;Matteo Zecchin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sangwoo Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1&quot;&gt;Caili Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1&quot;&gt;Chunyan Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1&quot;&gt;Osvaldo Simeone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.09751">
<title>Data Compression and Inference in Cosmology with Self-Supervised Machine Learning. (arXiv:2308.09751v2 [astro-ph.CO] UPDATED)</title>
<link>http://arxiv.org/abs/2308.09751</link>
<description rdf:parseType="Literal">&lt;p&gt;The influx of massive amounts of data from current and upcoming cosmological
surveys necessitates compression schemes that can efficiently summarize the
data with minimal loss of information. We introduce a method that leverages the
paradigm of self-supervised machine learning in a novel manner to construct
representative summaries of massive datasets using simulation-based
augmentations. Deploying the method on hydrodynamical cosmological simulations,
we show that it can deliver highly informative summaries, which can be used for
a variety of downstream tasks, including precise and accurate parameter
inference. We demonstrate how this paradigm can be used to construct summary
representations that are insensitive to prescribed systematic effects, such as
the influence of baryonic physics. Our results indicate that self-supervised
machine learning techniques offer a promising new approach for compression of
cosmological data as well its analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Akhmetzhanova_A/0/1/0/all/0/1&quot;&gt;Aizhan Akhmetzhanova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Mishra_Sharma_S/0/1/0/all/0/1&quot;&gt;Siddharth Mishra-Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Dvorkin_C/0/1/0/all/0/1&quot;&gt;Cora Dvorkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.10822">
<title>A Novel Ehanced Move Recognition Algorithm Based on Pre-trained Models with Positional Embeddings. (arXiv:2308.10822v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.10822</link>
<description rdf:parseType="Literal">&lt;p&gt;The recognition of abstracts is crucial for effectively locating the content
and clarifying the article. Existing move recognition algorithms lack the
ability to learn word position information to obtain contextual semantics. This
paper proposes a novel enhanced move recognition algorithm with an improved
pre-trained model and a gated network with attention mechanism for unstructured
abstracts of Chinese scientific and technological papers. The proposed
algorithm first performs summary data segmentation and vocabulary training. The
EP-ERNIE$\_$AT-GRU framework is leveraged to incorporate word positional
information, facilitating deep semantic learning and targeted feature
extraction. Experimental results demonstrate that the proposed algorithm
achieves 13.37$\%$ higher accuracy on the split dataset than on the original
dataset and a 7.55$\%$ improvement in accuracy over the basic comparison model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1&quot;&gt;Hao Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jie Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_X/0/1/0/all/0/1&quot;&gt;Xiaodong Qiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.12367">
<title>SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies. (arXiv:2308.12367v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.12367</link>
<description rdf:parseType="Literal">&lt;p&gt;With the growing use of machine learning (ML) models in critical domains such
as finance and healthcare, the need to offer recourse for those adversely
affected by the decisions of ML models has become more important; individuals
ought to be provided with recommendations on actions to take for improving
their situation and thus receiving a favorable decision. Prior work on
sequential algorithmic recourse -- which recommends a series of changes --
focuses on action feasibility and uses the proximity of feature changes to
determine action costs. However, the uncertainties of feature changes and the
risk of higher than average costs in recourse have not been considered. It is
undesirable if a recourse could (with some probability) result in a worse
situation from which recovery requires an extremely high cost. It is essential
to incorporate risks when computing and evaluating recourse. We call the
recourse computed with such risk considerations as Safer Algorithmic Recourse
(SafeAR). The objective is to empower people to choose a recourse based on
their risk tolerance. In this work, we discuss and show how existing recourse
desiderata can fail to capture the risk of higher costs. We present a method to
compute recourse policies that consider variability in cost and connect
algorithmic recourse literature with risk-sensitive reinforcement learning. We
also adopt measures &quot;Value at Risk&quot; and &quot;Conditional Value at Risk&quot; from the
financial literature to summarize risk concisely. We apply our method to two
real-world datasets and compare policies with different risk-aversion levels
using risk measures and recourse desiderata (sparsity and proximity).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Haochen Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1&quot;&gt;Shubham Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patra_S/0/1/0/all/0/1&quot;&gt;Sunandita Patra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalakrishnan_S/0/1/0/all/0/1&quot;&gt;Sriram Gopalakrishnan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.15059">
<title>OEBench: Investigating Open Environment Challenges in Real-World Relational Data Streams. (arXiv:2308.15059v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.15059</link>
<description rdf:parseType="Literal">&lt;p&gt;How to get insights from relational data streams in a timely manner is a hot
research topic. Data streams can present unique challenges, such as
distribution drifts, outliers, emerging classes, and changing features, which
have recently been described as open environment challenges for machine
learning. While existing studies have been done on incremental learning for
data streams, their evaluations are mostly conducted with synthetic datasets.
Thus, a natural question is how those open environment challenges look like and
how existing incremental learning algorithms perform on real-world relational
data streams. To fill this gap, we develop an Open Environment Benchmark named
OEBench to evaluate open environment challenges in real-world relational data
streams. Specifically, we investigate 55 real-world relational data streams and
establish that open environment scenarios are indeed widespread, which presents
significant challenges for stream learning algorithms. Through benchmarks with
existing incremental learning algorithms, we find that increased data quantity
may not consistently enhance the model accuracy when applied in open
environment scenarios, where machine learning models can be significantly
compromised by missing values, distribution drifts, or anomalies in real-world
data streams. The current techniques are insufficient in effectively mitigating
these challenges brought by open environments. More researches are needed to
address real-world open environment challenges. All datasets and code are
open-sourced in https://github.com/sjtudyq/OEBench.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diao_Y/0/1/0/all/0/1&quot;&gt;Yiqun Diao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yutong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qinbin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1&quot;&gt;Bingsheng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1&quot;&gt;Mian Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.15316">
<title>3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking. (arXiv:2308.15316v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.15316</link>
<description rdf:parseType="Literal">&lt;p&gt;Markerless methods for animal posture tracking have been rapidly developing
recently, but frameworks and benchmarks for tracking large animal groups in 3D
are still lacking. To overcome this gap in the literature, we present
3D-MuPPET, a framework to estimate and track 3D poses of up to 10 pigeons at
interactive speed using multiple camera views. We train a pose estimator to
infer 2D keypoints and bounding boxes of multiple pigeons, then triangulate the
keypoints to 3D. For identity matching of individuals in all views, we first
dynamically match 2D detections to global identities in the first frame, then
use a 2D tracker to maintain IDs across views in subsequent frames. We achieve
comparable accuracy to a state of the art 3D pose estimator in terms of median
error and Percentage of Correct Keypoints. Additionally, we benchmark the
inference speed of 3D-MuPPET, with up to 9.45 fps in 2D and 1.89 fps in 3D, and
perform quantitative tracking evaluation, which yields encouraging results.
Finally, we showcase two novel applications for 3D-MuPPET. First, we train a
model with data of single pigeons and achieve comparable results in 2D and 3D
posture estimation for up to 5 pigeons. Second, we show that 3D-MuPPET also
works in outdoors without additional annotations from natural environments.
Both use cases simplify the domain shift to new species and environments,
largely reducing annotation effort needed for 3D posture tracking. To the best
of our knowledge we are the first to present a framework for 2D/3D animal
posture and trajectory tracking that works in both indoor and outdoor
environments for up to 10 individuals. We hope that the framework can open up
new opportunities in studying animal collective behaviour and encourages
further developments in 3D multi-animal posture tracking.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waldmann_U/0/1/0/all/0/1&quot;&gt;Urs Waldmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1&quot;&gt;Alex Hoi Hang Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naik_H/0/1/0/all/0/1&quot;&gt;Hemal Naik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagy_M/0/1/0/all/0/1&quot;&gt;M&amp;#xe1;t&amp;#xe9; Nagy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Couzin_I/0/1/0/all/0/1&quot;&gt;Iain D. Couzin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deussen_O/0/1/0/all/0/1&quot;&gt;Oliver Deussen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldluecke_B/0/1/0/all/0/1&quot;&gt;Bastian Goldluecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kano_F/0/1/0/all/0/1&quot;&gt;Fumihiro Kano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.16599">
<title>Using machine learning to understand causal relationships between urban form and travel CO2 emissions across continents. (arXiv:2308.16599v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.16599</link>
<description rdf:parseType="Literal">&lt;p&gt;Climate change mitigation in urban mobility requires policies reconfiguring
urban form to increase accessibility and facilitate low-carbon modes of
transport. However, current policy research has insufficiently assessed urban
form effects on car travel at three levels: (1) Causality -- Can causality be
established beyond theoretical and correlation-based analyses? (2)
Generalizability -- Do relationships hold across different cities and world
regions? (3) Context specificity -- How do relationships vary across
neighborhoods of a city? Here, we address all three gaps via causal graph
discovery and explainable machine learning to detect urban form effects on
intra-city car travel, based on mobility data of six cities across three
continents. We find significant causal effects of urban form on trip emissions
and inter-feature effects, which had been neglected in previous work. Our
results demonstrate that destination accessibility matters most overall, while
low density and low connectivity also sharply increase CO$_2$ emissions. These
general trends are similar across cities but we find idiosyncratic effects that
can lead to substantially different recommendations. In more monocentric
cities, we identify spatial corridors -- about 10--50 km from the city center
-- where subcenter-oriented development is more relevant than increased access
to the main center. Our work demonstrates a novel application of machine
learning that enables new research addressing the needs of causality,
generalizability, and contextual specificity for scaling evidence-based urban
climate solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wagner_F/0/1/0/all/0/1&quot;&gt;Felix Wagner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachtigall_F/0/1/0/all/0/1&quot;&gt;Florian Nachtigall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franken_L/0/1/0/all/0/1&quot;&gt;Lukas Franken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milojevic_Dupont_N/0/1/0/all/0/1&quot;&gt;Nikola Milojevic-Dupont&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereira_R/0/1/0/all/0/1&quot;&gt;Rafael H.M. Pereira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koch_N/0/1/0/all/0/1&quot;&gt;Nicolas Koch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Runge_J/0/1/0/all/0/1&quot;&gt;Jakob Runge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_M/0/1/0/all/0/1&quot;&gt;Marta Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Creutzig_F/0/1/0/all/0/1&quot;&gt;Felix Creutzig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.01013">
<title>Streaming Active Learning for Regression Problems Using Regression via Classification. (arXiv:2309.01013v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.01013</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the challenges in deploying a machine learning model is that the
model&apos;s performance degrades as the operating environment changes. To maintain
the performance, streaming active learning is used, in which the model is
retrained by adding a newly annotated sample to the training dataset if the
prediction of the sample is not certain enough. Although many streaming active
learning methods have been proposed for classification, few efforts have been
made for regression problems, which are often handled in the industrial field.
In this paper, we propose to use the regression-via-classification framework
for streaming active learning for regression. Regression-via-classification
transforms regression problems into classification problems so that streaming
active learning methods proposed for classification problems can be applied
directly to regression problems. Experimental validation on four real data sets
shows that the proposed method can perform regression with higher accuracy at
the same annotation cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horiguchi_S/0/1/0/all/0/1&quot;&gt;Shota Horiguchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dohi_K/0/1/0/all/0/1&quot;&gt;Kota Dohi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawaguchi_Y/0/1/0/all/0/1&quot;&gt;Yohei Kawaguchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.04339">
<title>Online Submodular Maximization via Online Convex Optimization. (arXiv:2309.04339v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.04339</link>
<description rdf:parseType="Literal">&lt;p&gt;We study monotone submodular maximization under general matroid constraints
in the online setting. We prove that online optimization of a large class of
submodular functions, namely, weighted threshold potential functions, reduces
to online convex optimization (OCO). This is precisely because functions in
this class admit a concave relaxation; as a result, OCO policies, coupled with
an appropriate rounding scheme, can be used to achieve sublinear regret in the
combinatorial setting. We show that our reduction extends to many different
versions of the online learning problem, including the dynamic regret, bandit,
and optimistic-learning settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Si_Salem_T/0/1/0/all/0/1&quot;&gt;Tareq Si-Salem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozcan_G/0/1/0/all/0/1&quot;&gt;G&amp;#xf6;zde &amp;#xd6;zcan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolaou_I/0/1/0/all/0/1&quot;&gt;Iasonas Nikolaou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Terzi_E/0/1/0/all/0/1&quot;&gt;Evimaria Terzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ioannidis_S/0/1/0/all/0/1&quot;&gt;Stratis Ioannidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11983">
<title>Variational Connectionist Temporal Classification for Order-Preserving Sequence Modeling. (arXiv:2309.11983v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.11983</link>
<description rdf:parseType="Literal">&lt;p&gt;Connectionist temporal classification (CTC) is commonly adopted for sequence
modeling tasks like speech recognition, where it is necessary to preserve order
between the input and target sequences. However, CTC is only applied to
deterministic sequence models, where the latent space is discontinuous and
sparse, which in turn makes them less capable of handling data variability when
compared to variational models. In this paper, we integrate CTC with a
variational model and derive loss functions that can be used to train more
generalizable sequence models that preserve order. Specifically, we derive two
versions of the novel variational CTC based on two reasonable assumptions, the
first being that the variational latent variables at each time step are
conditionally independent; and the second being that these latent variables are
Markovian. We show that both loss functions allow direct optimization of the
variational lower bound for the model log-likelihood, and present
computationally tractable forms for implementing them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nan_Z/0/1/0/all/0/1&quot;&gt;Zheng Nan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1&quot;&gt;Ting Dang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sethu_V/0/1/0/all/0/1&quot;&gt;Vidhyasaharan Sethu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_B/0/1/0/all/0/1&quot;&gt;Beena Ahmed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03708">
<title>Beyond One-Preference-Fits-All Alignment: Multi-Objective Direct Preference Optimization. (arXiv:2310.03708v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03708</link>
<description rdf:parseType="Literal">&lt;p&gt;A single language model (LM), despite aligning well with an average labeler
through reinforcement learning from human feedback (RLHF), may not universally
suit diverse human preferences. Recent approaches therefore opt for
customization by collecting multi-dimensional feedback and creating distinct
reward models (RMs) for each dimension (e.g., helpfulness, harmlessness, or
honesty). Different LMs can then be optimized for different preferences using
multi-objective RLHF (MORLHF) with different reward weightings. Yet, RL
fine-tuning is unstable and resource-heavy, especially for MORLHF with diverse
and usually conflicting objectives. In this paper, we present Multi-Objective
Direct Preference Optimization (MODPO), an RL-free algorithm that extends
Direct Preference Optimization (DPO) for multiple alignment objectives with
minimal overheads. Essentially, MODPO folds language modeling directly into
reward modeling, training LMs as implicit collective reward models (cRMs) that
combine all objectives with specific weightings. While theoretically guaranteed
to produce the same optimal solutions as MORLHF, MODPO is practically more
stable and computationally efficient. Empirical results from safety alignment
and long-form question answering confirm that MODPO matches or outperforms
existing methods, consistently producing a Pareto front of LMs that cater to
diverse preferences with 3 times less computational resources compared to
MORLHF.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhanhui Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1&quot;&gt;Jing Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1&quot;&gt;Xiangyu Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1&quot;&gt;Wanli Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1&quot;&gt;Yu Qiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03725">
<title>Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03725</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative models inspired by dynamical transport of measure -- such as flows
and diffusions -- construct a continuous-time map between two probability
densities. Conventionally, one of these is the target density, only accessible
through samples, while the other is taken as a simple base density that is
data-agnostic. In this work, using the framework of stochastic interpolants, we
formalize how to \textit{couple} the base and the target densities, whereby
samples from the base are computed conditionally given samples from the target
in a way that is different from (but does preclude) incorporating information
about class labels or continuous embeddings. This enables us to construct
dynamical transport maps that serve as conditional generative models. We show
that these transport maps can be learned by solving a simple square loss
regression problem analogous to the standard independent setting. We
demonstrate the usefulness of constructing dependent couplings in practice
through experiments in super-resolution and in-painting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albergo_M/0/1/0/all/0/1&quot;&gt;Michael S. Albergo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_M/0/1/0/all/0/1&quot;&gt;Mark Goldstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boffi_N/0/1/0/all/0/1&quot;&gt;Nicholas M. Boffi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1&quot;&gt;Rajesh Ranganath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1&quot;&gt;Eric Vanden-Eijnden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.03985">
<title>Dementia Assessment Using Mandarin Speech with an Attention-based Speech Recognition Encoder. (arXiv:2310.03985v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.03985</link>
<description rdf:parseType="Literal">&lt;p&gt;Dementia diagnosis requires a series of different testing methods, which is
complex and time-consuming. Early detection of dementia is crucial as it can
prevent further deterioration of the condition. This paper utilizes a speech
recognition model to construct a dementia assessment system tailored for
Mandarin speakers during the picture description task. By training an
attention-based speech recognition model on voice data closely resembling
real-world scenarios, we have significantly enhanced the model&apos;s recognition
capabilities. Subsequently, we extracted the encoder from the speech
recognition model and added a linear layer for dementia assessment. We
collected Mandarin speech data from 99 subjects and acquired their clinical
assessments from a local hospital. We achieved an accuracy of 92.04% in
Alzheimer&apos;s disease detection and a mean absolute error of 9% in clinical
dementia rating score prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zih-Jyun Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yi-Ju Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuo_P/0/1/0/all/0/1&quot;&gt;Po-Chih Kuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Likai Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1&quot;&gt;Chaur-Jong Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Cheng-Yu Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.06622">
<title>Robustness May be More Brittle than We Think under Different Degrees of Distribution Shifts. (arXiv:2310.06622v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.06622</link>
<description rdf:parseType="Literal">&lt;p&gt;Out-of-distribution (OOD) generalization is a complicated problem due to the
idiosyncrasies of possible distribution shifts between training and test
domains. Most benchmarks employ diverse datasets to address this issue;
however, the degree of the distribution shift between the training domains and
the test domains of each dataset remains largely fixed. This may lead to biased
conclusions that either underestimate or overestimate the actual OOD
performance of a model. Our study delves into a more nuanced evaluation setting
that covers a broad range of shift degrees. We show that the robustness of
models can be quite brittle and inconsistent under different degrees of
distribution shifts, and therefore one should be more cautious when drawing
conclusions from evaluations under a limited range of degrees. In addition, we
observe that large-scale pre-trained models, such as CLIP, are sensitive to
even minute distribution shifts of novel downstream tasks. This indicates that
while pre-trained representations may help improve downstream in-distribution
performance, they could have minimal or even adverse effects on generalization
in certain OOD scenarios of the downstream task if not used properly. In light
of these findings, we encourage future research to conduct evaluations across a
broader range of shift degrees whenever possible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kaican Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yifan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1&quot;&gt;Lanqing Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenguo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1&quot;&gt;Nevin L. Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.07958">
<title>Towards Causal Deep Learning for Vulnerability Detection. (arXiv:2310.07958v4 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2310.07958</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning vulnerability detection has shown promising results in recent
years. However, an important challenge that still blocks it from being very
useful in practice is that the model is not robust under perturbation and it
cannot generalize well over the out-of-distribution (OOD) data, e.g., applying
a trained model to unseen projects in real world. We hypothesize that this is
because the model learned non-robust features, e.g., variable names, that have
spurious correlations with labels. When the perturbed and OOD datasets no
longer have the same spurious features, the model prediction fails. To address
the challenge, in this paper, we introduced causality into deep learning
vulnerability detection. Our approach CausalVul consists of two phases. First,
we designed novel perturbations to discover spurious features that the model
may use to make predictions. Second, we applied the causal learning algorithms,
specifically, do-calculus, on top of existing deep learning models to
systematically remove the use of spurious features and thus promote causal
based prediction. Our results show that CausalVul consistently improved the
model accuracy, robustness and OOD performance for all the state-of-the-art
models and datasets we experimented. To the best of our knowledge, this is the
first work that introduces do calculus based causal learning to software
engineering models and shows it&apos;s indeed useful for improving the model
accuracy, robustness and generalization. Our replication package is located at
https://figshare.com/s/0ffda320dcb96c249ef2.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1&quot;&gt;Md Mahbubur Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceka_I/0/1/0/all/0/1&quot;&gt;Ira Ceka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1&quot;&gt;Chengzhi Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1&quot;&gt;Saikat Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1&quot;&gt;Baishakhi Ray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_W/0/1/0/all/0/1&quot;&gt;Wei Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.14360">
<title>Is ChatGPT a game changer for geocoding -- a benchmark for geocoding address parsing techniques. (arXiv:2310.14360v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.14360</link>
<description rdf:parseType="Literal">&lt;p&gt;The remarkable success of GPT models across various tasks, including toponymy
recognition motivates us to assess the performance of the GPT-3 model in the
geocoding address parsing task. To ensure that the evaluation more accurately
mirrors performance in real-world scenarios with diverse user input qualities
and resolve the pressing need for a &apos;gold standard&apos; evaluation dataset for
geocoding systems, we introduce a benchmark dataset of low-quality address
descriptions synthesized based on human input patterns mining from actual input
logs of a geocoding system in production. This dataset has 21 different input
errors and variations; contains over 239,000 address records that are uniquely
selected from streets across all U.S. 50 states and D.C.; and consists of three
subsets to be used as training, validation, and testing sets. Building on this,
we train and gauge the performance of the GPT-3 model in extracting address
components, contrasting its performance with transformer-based and LSTM-based
models. The evaluation results indicate that Bidirectional LSTM-CRF model has
achieved the best performance over these transformer-based models and GPT-3
model. Transformer-based models demonstrate very comparable results compared to
the Bidirectional LSTM-CRF model. The GPT-3 model, though trailing in
performance, showcases potential in the address parsing task with few-shot
examples, exhibiting room for improvement with additional fine-tuning. We open
source the code and data of this presented benchmark so that researchers can
utilize it for future model development or extend it to evaluate similar tasks,
such as document geocoding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zhengcong Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Diya Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_D/0/1/0/all/0/1&quot;&gt;Daniel W. Goldberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.20092">
<title>The Missing U for Efficient Diffusion Models. (arXiv:2310.20092v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2310.20092</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion Probabilistic Models stand as a critical tool in generative
modelling, enabling the generation of complex data distributions. This family
of generative models yields record-breaking performance in tasks such as image
synthesis, video generation, and molecule design. Despite their capabilities,
their efficiency, especially in the reverse process, remains a challenge due to
slow convergence rates and high computational costs. In this paper, we
introduce an approach that leverages continuous dynamical systems to design a
novel denoising network for diffusion models that is more parameter-efficient,
exhibits faster convergence, and demonstrates increased noise robustness.
Experimenting with Denoising Diffusion Probabilistic Models (DDPMs), our
framework operates with approximately a quarter of the parameters, and $\sim$
30\% of the Floating Point Operations (FLOPs) compared to standard U-Nets in
DDPMs. Furthermore, our model is notably faster in inference than the baseline
when measured in fair and equal conditions. We also provide a mathematical
intuition as to why our proposed reverse process is faster as well as a
mathematical discussion of the empirical tradeoffs in the denoising downstream
task. Finally, we argue that our method is compatible with existing performance
enhancement techniques, enabling further improvements in efficiency, quality,
and speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calvo_Ordonez_S/0/1/0/all/0/1&quot;&gt;Sergio Calvo-Ordonez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Chun-Wun Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jiahao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lipei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Guang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1&quot;&gt;Carola-Bibiane Schonlieb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aviles_Rivero_A/0/1/0/all/0/1&quot;&gt;Angelica I Aviles-Rivero&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02544">
<title>Nonlinear Multi-objective Reinforcement Learning with Provable Guarantees. (arXiv:2311.02544v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.02544</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe RA-E3 (Reward-Aware Explicit Explore or Exploit), an algorithm
with provable guarantees for solving a single or multi-objective Markov
Decision Process (MDP) where we want to maximize the expected value of a
nonlinear function over accumulated rewards. This allows us to model
fairness-aware welfare optimization for multi-objective reinforcement learning
as well as risk-aware reinforcement learning with nonlinear Von
Neumann-Morgenstern utility functions in the single objective setting. RA-E3
extends the classic E3 algorithm that solves MDPs with scalar rewards and
linear preferences. We first state a distinct reward-aware version of value
iteration that calculates a non-stationary policy that is approximately optimal
for a given model of the environment. This sub-procedure is based on an
extended form of Bellman optimality for nonlinear optimization that explicitly
considers time and current accumulated reward. We then describe how to use this
optimization procedure in a larger algorithm that must simultaneously learn a
model of the environment. The algorithm learns an approximately optimal policy
in time that depends polynomially on the MDP size, desired approximation, and
smoothness of the nonlinear function, and exponentially on the number of
objectives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1&quot;&gt;Nianli Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fain_B/0/1/0/all/0/1&quot;&gt;Brandon Fain&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.02909">
<title>Distributed Matrix-Based Sampling for Graph Neural Network Training. (arXiv:2311.02909v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.02909</link>
<description rdf:parseType="Literal">&lt;p&gt;The primary contribution of this paper is new methods for reducing
communication in the sampling step for distributed GNN training. Here, we
propose a matrix-based bulk sampling approach that expresses sampling as a
sparse matrix multiplication (SpGEMM) and samples multiple minibatches at once.
When the input graph topology does not fit on a single device, our method
distributes the graph and use communication-avoiding SpGEMM algorithms to scale
GNN minibatch sampling, enabling GNN training on much larger graphs than those
that can fit into a single device memory. When the input graph topology (but
not the embeddings) fits in the memory of one GPU, our approach (1) performs
sampling without communication, (2) amortizes the overheads of sampling a
minibatch, and (3) can represent multiple sampling algorithms by simply using
different matrix constructions. In addition to new methods for sampling, we
show that judiciously replicating feature data with a simple all-to-all
exchange can outperform current methods for the feature extraction step in
distributed GNN training. We provide experimental results on the largest Open
Graph Benchmark (OGB) datasets on $128$ GPUs, and show that our pipeline is
$2.5\times$ faster Quiver (a distributed extension to PyTorch-Geometric) on a
$3$-layer GraphSAGE network. On datasets outside of OGB, we show a $8.46\times$
speedup on $128$ GPUs in-per epoch time. Finally, we show scaling when the
graph is distributed across GPUs and scaling for both node-wise and layer-wise
sampling algorithms
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathy_A/0/1/0/all/0/1&quot;&gt;Alok Tripathy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yelick_K/0/1/0/all/0/1&quot;&gt;Katherine Yelick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buluc_A/0/1/0/all/0/1&quot;&gt;Aydin Buluc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05741">
<title>Efficiently Adapting Pretrained Language Models To New Languages. (arXiv:2311.05741v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.05741</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent large language models (LLM) exhibit sub-optimal performance on
low-resource languages, as the training data of these models is usually
dominated by English and other high-resource languages. Furthermore, it is
challenging to train models for low-resource languages, especially from
scratch, due to a lack of high quality training data. Adapting pretrained LLMs
reduces the need for data in the new language while also providing cross
lingual transfer capabilities. However, naively adapting to new languages leads
to catastrophic forgetting and poor tokenizer efficiency. In this work, we
study how to efficiently adapt any existing pretrained LLM to a new language
without running into these issues. In particular, we improve the encoding
efficiency of the tokenizer by adding new tokens from the target language and
study the data mixing recipe to mitigate forgetting. Our experiments on
adapting an English LLM to Hungarian and Thai show that our recipe can reach
better performance than open source models on the target language, with minimal
regressions on English.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Csaki_Z/0/1/0/all/0/1&quot;&gt;Zoltan Csaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawakapan_P/0/1/0/all/0/1&quot;&gt;Pian Pawakapan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakker_U/0/1/0/all/0/1&quot;&gt;Urmish Thakker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1&quot;&gt;Qiantong Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.05836">
<title>UMedNeRF: Uncertainty-aware Single View Volumetric Rendering for Medical Neural Radiance Fields. (arXiv:2311.05836v4 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2311.05836</link>
<description rdf:parseType="Literal">&lt;p&gt;In the field of clinical medicine, computed tomography (CT) is an effective
medical imaging modality for the diagnosis of various pathologies. Compared
with X-ray images, CT images can provide more information, including
multi-planar slices and three-dimensional structures for clinical diagnosis.
However, CT imaging requires patients to be exposed to large doses of ionizing
radiation for a long time, which may cause irreversible physical harm. In this
paper, we propose an Uncertainty-aware MedNeRF (UMedNeRF) network based on
generated radiation fields. The network can learn a continuous representation
of CT projections from 2D X-ray images by obtaining the internal structure and
depth information and using adaptive loss weights to ensure the quality of the
generated images. Our model is trained on publicly available knee and chest
datasets, and we show the results of CT projection rendering with a single
X-ray and compare our method with other methods based on generated radiation
fields.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jing Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fan_Q/0/1/0/all/0/1&quot;&gt;Qinrui Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hu_S/0/1/0/all/0/1&quot;&gt;Shu Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lyu_S/0/1/0/all/0/1&quot;&gt;Siwei Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.12550">
<title>Explainable Time Series Anomaly Detection using Masked Latent Generative Modeling. (arXiv:2311.12550v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.12550</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel time series anomaly detection method that achieves
excellent detection accuracy while offering a superior level of explainability.
Our proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted
from the cutting-edge time series generation method known as TimeVQVAE. The
prior model is trained on the discrete latent space of a time-frequency domain.
Notably, the dimensional semantics of the time-frequency domain are preserved
in the latent space, enabling us to compute anomaly scores across different
frequency bands, which provides a better insight into the detected anomalies.
Additionally, the generative nature of the prior model allows for sampling
likely normal states for detected anomalies, enhancing the explainability of
the detected anomalies through counterfactuals. Our experimental evaluation on
the UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD
significantly surpasses the existing methods in terms of detection accuracy and
explainability. We provide our implementation on GitHub:
\url{https://github.com/ML4ITS/TimeVQVAE-AnomalyDetection}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Daesoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malacarne_S/0/1/0/all/0/1&quot;&gt;Sara Malacarne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aune_E/0/1/0/all/0/1&quot;&gt;Erlend Aune&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.16973">
<title>DemoFusion: Democratising High-Resolution Image Generation With No $$$. (arXiv:2311.16973v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2311.16973</link>
<description rdf:parseType="Literal">&lt;p&gt;High-resolution image generation with Generative Artificial Intelligence
(GenAI) has immense potential but, due to the enormous capital investment
required for training, it is increasingly centralised to a few large
corporations, and hidden behind paywalls. This paper aims to democratise
high-resolution GenAI by advancing the frontier of high-resolution generation
while remaining accessible to a broad audience. We demonstrate that existing
Latent Diffusion Models (LDMs) possess untapped potential for higher-resolution
image generation. Our novel DemoFusion framework seamlessly extends open-source
GenAI models, employing Progressive Upscaling, Skip Residual, and Dilated
Sampling mechanisms to achieve higher-resolution image generation. The
progressive nature of DemoFusion requires more passes, but the intermediate
results can serve as &quot;previews&quot;, facilitating rapid prompt iteration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_R/0/1/0/all/0/1&quot;&gt;Ruoyi Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1&quot;&gt;Dongliang Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1&quot;&gt;Timothy Hospedales&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yi-Zhe Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zhanyu Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.17104">
<title>Single-Cell Deep Clustering Method Assisted by Exogenous Gene Information: A Novel Approach to Identifying Cell Types. (arXiv:2311.17104v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.17104</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the field of single-cell data analysis has seen a marked
advancement in the development of clustering methods. Despite advancements,
most of these algorithms still concentrate on analyzing the provided
single-cell matrix data. However, in medical applications, single-cell data
often involves a wealth of exogenous information, including gene networks.
Overlooking this aspect could lead to information loss and clustering results
devoid of significant clinical relevance. An innovative single-cell deep
clustering method, incorporating exogenous gene information, has been proposed
to overcome this limitation. This model leverages exogenous gene network
information to facilitate the clustering process, generating discriminative
representations. Specifically, we have developed an attention-enhanced graph
autoencoder, which is designed to efficiently capture the topological features
between cells. Concurrently, we conducted a random walk on an exogenous
Protein-Protein Interaction (PPI) network, thereby acquiring the gene&apos;s
topological features. Ultimately, during the clustering process, we integrated
both sets of information and reconstructed the features of both cells and genes
to generate a discriminative representation. Extensive experiments have
validated the effectiveness of our proposed method. This research offers
enhanced insights into the characteristics and distribution of cells, thereby
laying the groundwork for early diagnosis and treatment of diseases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1&quot;&gt;Dayu Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1&quot;&gt;Ke Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xinwang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.17401">
<title>Gene-MOE: A Sparsely-gated Framework for Pan-Cancer Genomic Analysis. (arXiv:2311.17401v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2311.17401</link>
<description rdf:parseType="Literal">&lt;p&gt;Benefiting from the advancements in deep learning, various genomic analytical
techniques, such as survival analysis, classification of tumors and their
subtypes, and exploration of specific pathways, have significantly enhanced our
understanding of the biological mechanisms driving cancer. However, the
overfitting issue, arising from the limited number of patient samples, poses a
challenge in improving the accuracy of genome analysis by deepening the neural
network. Furthermore, it remains uncertain whether novel approaches such as the
sparsely gated mixture of expert (MOE) and self-attention mechanisms can
improve the accuracy of genomic analysis. In this paper, we introduce a novel
sparsely gated RNA-seq analysis framework called Gene-MOE. This framework
exploits the potential of the MOE layers and the proposed mixture of attention
expert (MOAE) layers to enhance the analysis accuracy. Additionally, it
addresses overfitting challenges by integrating pan-cancer information from 33
distinct cancer types through pre-training.We pre-trained Gene-MOE on TCGA
pan-cancer RNA-seq dataset with 33 cancer types. Subsequently, we conducted
experiments involving cancer classification and survival analysis based on the
pre-trained Gene-MOE. According to the survival analysis results on 14 cancer
types, Gene-MOE outperformed state-of-the-art models on 12 cancer types.
Through detailed feature analysis, we found that the Gene-MOE model could learn
rich feature representations of high-dimensional genes. According to the
classification results, the total accuracy of the classification model for 33
cancer classifications reached 95.8%, representing the best performance
compared to state-of-the-art models. These results indicate that Gene-MOE holds
strong potential for use in cancer classification and survival analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1&quot;&gt;Xiangyu Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xue Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qing Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Huanhuan Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_L/0/1/0/all/0/1&quot;&gt;Lian Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1&quot;&gt;Hongzhen Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_L/0/1/0/all/0/1&quot;&gt;Long Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.00655">
<title>Machine Learning for Health symposium 2023 -- Findings track. (arXiv:2312.00655v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.00655</link>
<description rdf:parseType="Literal">&lt;p&gt;A collection of the accepted Findings papers that were presented at the 3rd
Machine Learning for Health symposium (ML4H 2023), which was held on December
10, 2023, in New Orleans, Louisiana, USA. ML4H 2023 invited high-quality
submissions on relevant problems in a variety of health-related disciplines
including healthcare, biomedicine, and public health. Two submission tracks
were offered: the archival Proceedings track, and the non-archival Findings
track. Proceedings were targeted at mature work with strong technical
sophistication and a high impact to health. The Findings track looked for new
ideas that could spark insightful discussion, serve as valuable resources for
the community, or could enable new collaborations. Submissions to the
Proceedings track, if not accepted, were automatically considered for the
Findings track. All the manuscripts submitted to ML4H Symposium underwent a
double-blind peer-review process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hegselmann_S/0/1/0/all/0/1&quot;&gt;Stefan Hegselmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parziale_A/0/1/0/all/0/1&quot;&gt;Antonio Parziale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shanmugam_D/0/1/0/all/0/1&quot;&gt;Divya Shanmugam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shengpu Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asiedu_M/0/1/0/all/0/1&quot;&gt;Mercy Nyamewaa Asiedu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1&quot;&gt;Serina Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hartvigsen_T/0/1/0/all/0/1&quot;&gt;Thomas Hartvigsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_H/0/1/0/all/0/1&quot;&gt;Harvineet Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.01878">
<title>HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning. (arXiv:2312.01878v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.01878</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs)
are prominent techniques for homogeneous and heterogeneous graph representation
learning, yet their performance in an end-to-end supervised framework greatly
depends on the availability of task-specific supervision. To reduce the
labeling cost, pre-training on self-supervised pretext tasks has become a
popular paradigm,but there is often a gap between the pre-trained model and
downstream tasks, stemming from the divergence in their objectives. To bridge
the gap, prompt learning has risen as a promising direction especially in
few-shot settings, without the need to fully fine-tune the pre-trained model.
While there has been some early exploration of prompt-based learning on graphs,
they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs
that are prevalent in downstream applications. In this paper, we propose
HGPROMPT, a novel pre-training and prompting framework to unify not only
pre-training and downstream tasks but also homogeneous and heterogeneous graphs
via a dual-template design. Moreover, we propose dual-prompt in HGPROMPT to
assist a downstream task in locating the most relevant prior to bridge the gaps
caused by not only feature variations but also heterogeneity differences across
tasks. Finally, we thoroughly evaluate and analyze HGPROMPT through extensive
experiments on three public datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xingtong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1&quot;&gt;Yuan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zemin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinming Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.03179">
<title>CaloQVAE : Simulating high-energy particle-calorimeter interactions using hybrid quantum-classical generative models. (arXiv:2312.03179v2 [hep-ex] UPDATED)</title>
<link>http://arxiv.org/abs/2312.03179</link>
<description rdf:parseType="Literal">&lt;p&gt;The Large Hadron Collider&apos;s high luminosity era presents major computational
challenges in the analysis of collision events. Large amounts of Monte Carlo
(MC) simulation will be required to constrain the statistical uncertainties of
the simulated datasets below these of the experimental data. Modelling of
high-energy particles propagating through the calorimeter section of the
detector is the most computationally intensive MC simulation task. We introduce
a technique combining recent advancements in generative models and quantum
annealing for fast and efficient simulation of high-energy particle-calorimeter
interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Hoque_S/0/1/0/all/0/1&quot;&gt;Sehmimul Hoque&lt;/a&gt; (1, 2), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Jia_H/0/1/0/all/0/1&quot;&gt;Hao Jia&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Abhishek_A/0/1/0/all/0/1&quot;&gt;Abhishek Abhishek&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Fadaie_M/0/1/0/all/0/1&quot;&gt;Mojde Fadaie&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Toledo_Marin_J/0/1/0/all/0/1&quot;&gt;J. Quetzalcoatl Toledo-Mar&amp;#xed;n&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Vale_T/0/1/0/all/0/1&quot;&gt;Tiago Vale&lt;/a&gt; (5, 4), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Melko_R/0/1/0/all/0/1&quot;&gt;Roger G. Melko&lt;/a&gt; (1, 6), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Swiatlowski_M/0/1/0/all/0/1&quot;&gt;Maximilian Swiatlowski&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/hep-ex/1/au:+Fedorko_W/0/1/0/all/0/1&quot;&gt;Wojciech T. Fedorko&lt;/a&gt; (4) ((1) Perimeter Institute for Theoretical Physics, (2) Faculty of Mathematics, University of Waterloo, (3) Department of Physics and Astronomy, University of British Columbia, (4) TRIUMF, (5) Department of Physics, Simon Fraser University, (6) Department of Physics and Astronomy, University of Waterloo)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04103">
<title>Enhancing the Rationale-Input Alignment for Self-explaining Rationalization. (arXiv:2312.04103v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2312.04103</link>
<description rdf:parseType="Literal">&lt;p&gt;Rationalization empowers deep learning models with self-explaining
capabilities through a cooperative game, where a generator selects a
semantically consistent subset of the input as a rationale, and a subsequent
predictor makes predictions based on the selected rationale. In this paper, we
discover that rationalization is prone to a problem named \emph{rationale
shift}, which arises from the algorithmic bias of the cooperative game.
Rationale shift refers to a situation where the semantics of the selected
rationale may deviate from the original input, but the predictor still produces
accurate predictions based on the deviation, resulting in a compromised
generator with misleading feedback.
&lt;/p&gt;
&lt;p&gt;To address this issue, we first demonstrate the importance of the alignment
between the rationale and the full input through both empirical observations
and theoretical analysis. Subsequently, we introduce a novel approach called
DAR (\textbf{D}iscriminatively \textbf{A}ligned \textbf{R}ationalization),
which utilizes an auxiliary module pretrained on the full input to
discriminatively align the selected rationale and the original input. We
theoretically illustrate how DAR accomplishes the desired alignment, thereby
overcoming the rationale shift problem. The experiments on two widely used
real-world benchmarks show that the proposed method significantly improves the
explanation quality (measured by the overlap between the model-selected
explanation and the human-annotated rationale) as compared to state-of-the-art
techniques. Additionally, results on two synthetic settings further validate
the effectiveness of DAR in addressing the rationale shift problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haozhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1&quot;&gt;Zhiying Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;YuanKai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Cheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ruixuan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.06403">
<title>Debiased Machine Learning and Network Cohesion for Doubly-Robust Differential Reward Models in Contextual Bandits. (arXiv:2312.06403v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2312.06403</link>
<description rdf:parseType="Literal">&lt;p&gt;A common approach to learning mobile health (mHealth) intervention policies
is linear Thompson sampling. Two desirable mHealth policy features are (1)
pooling information across individuals and time and (2) incorporating a
time-varying baseline reward. Previous approaches pooled information across
individuals but not time, failing to capture trends in treatment effects over
time. In addition, these approaches did not explicitly model the baseline
reward, which limited the ability to precisely estimate the parameters in the
differential reward model. In this paper, we propose a novel Thompson sampling
algorithm, termed &apos;&apos;DML-TS-NNR&apos;&apos; that leverages (1) nearest-neighbors to
efficiently pool information on the differential reward function across users
and time and (2) the Double Machine Learning (DML) framework to explicitly
model baseline rewards and stay agnostic to the supervised learning algorithms
used. By explicitly modeling baseline rewards, we obtain smaller confidence
sets for the differential reward parameters. We offer theoretical guarantees on
the pseudo-regret, which are supported by empirical results. Importantly, the
DML-TS-NNR algorithm demonstrates robustness to potential misspecifications in
the baseline reward model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huch_E/0/1/0/all/0/1&quot;&gt;Easton K. Huch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jieru Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Abbott_M/0/1/0/all/0/1&quot;&gt;Madeline R. Abbott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Golbus_J/0/1/0/all/0/1&quot;&gt;Jessica R. Golbus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moreno_A/0/1/0/all/0/1&quot;&gt;Alexander Moreno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dempsey_W/0/1/0/all/0/1&quot;&gt;Walter H. Dempsey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.06578">
<title>Multi-class Support Vector Machine with Maximizing Minimum Margin. (arXiv:2312.06578v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.06578</link>
<description rdf:parseType="Literal">&lt;p&gt;Support Vector Machine (SVM) stands out as a prominent machine learning
technique widely applied in practical pattern recognition tasks. It achieves
binary classification by maximizing the &quot;margin&quot;, which represents the minimum
distance between instances and the decision boundary. Although many efforts
have been dedicated to expanding SVM for multi-class case through strategies
such as one versus one and one versus the rest, satisfactory solutions remain
to be developed. In this paper, we propose a novel method for multi-class SVM
that incorporates pairwise class loss considerations and maximizes the minimum
margin. Adhering to this concept, we embrace a new formulation that imparts
heightened flexibility to multi-class SVM. Furthermore, the correlations
between the proposed method and multiple forms of multi-class SVM are analyzed.
The proposed regularizer, akin to the concept of &quot;margin&quot;, can serve as a
seamless enhancement over the softmax in deep learning, providing guidance for
network parameter learning. Empirical evaluations demonstrate the effectiveness
and superiority of our proposed method over existing multi-classification
methods.Code is available at https://github.com/zz-haooo/M3SVM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_F/0/1/0/all/0/1&quot;&gt;Feiping Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1&quot;&gt;Zhezheng Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Rong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.06942">
<title>AI Control: Improving Safety Despite Intentional Subversion. (arXiv:2312.06942v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.06942</link>
<description rdf:parseType="Literal">&lt;p&gt;As large language models (LLMs) become more powerful and are deployed more
autonomously, it will be increasingly important to prevent them from causing
harmful outcomes. Researchers have investigated a variety of safety techniques
for this purpose, e.g. using models to review the outputs of other models, or
red-teaming techniques to surface subtle failure modes. However, researchers
have not evaluated whether such techniques still ensure safety if the model is
itself intentionally trying to subvert them. In this paper, we develop and
evaluate pipelines of safety techniques (&quot;protocols&quot;) that are robust to
intentional subversion.
&lt;/p&gt;
&lt;p&gt;We investigate a scenario in which we want to solve a sequence of programming
problems, using access to a powerful but untrusted model (in our case, GPT-4),
access to a less powerful trusted model (in our case, GPT-3.5), and limited
access to human contractors who provide high-quality trusted labor. We
investigate protocols that aim to never submit solutions containing backdoors,
which we operationalize here as logical errors that are not caught by test
cases.
&lt;/p&gt;
&lt;p&gt;We investigate a range of protocols and test each against strategies that the
untrusted model could use to subvert them. One protocol is what we call trusted
editing. This protocol first asks GPT-4 to write code, and then asks GPT-3.5 to
rate the suspiciousness of that code. If the code is below some suspiciousness
threshold, it is submitted. Otherwise, GPT-3.5 edits the solution to remove
parts that seem suspicious and then submits the edited code. Another protocol
is untrusted monitoring. This protocol asks GPT-4 to write code, and then asks
another instance of GPT-4 whether the code is backdoored, using various
techniques to prevent the GPT-4 instances from colluding. These protocols
improve substantially on simple baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Greenblatt_R/0/1/0/all/0/1&quot;&gt;Ryan Greenblatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlegeris_B/0/1/0/all/0/1&quot;&gt;Buck Shlegeris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sachan_K/0/1/0/all/0/1&quot;&gt;Kshitij Sachan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roger_F/0/1/0/all/0/1&quot;&gt;Fabien Roger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.06957">
<title>Online Saddle Point Problem and Online Convex-Concave Optimization. (arXiv:2312.06957v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.06957</link>
<description rdf:parseType="Literal">&lt;p&gt;Centered around solving the Online Saddle Point problem, this paper
introduces the Online Convex-Concave Optimization (OCCO) framework, which
involves a sequence of two-player time-varying convex-concave games. We propose
the generalized duality gap (Dual-Gap) as the performance metric and establish
the parallel relationship between OCCO with Dual-Gap and Online Convex
Optimization (OCO) with regret. To demonstrate the natural extension of OCCO
from OCO, we develop two algorithms, the implicit online mirror descent-ascent
and its optimistic variant. Analysis reveals that their duality gaps share
similar expression forms with the corresponding dynamic regrets arising from
implicit updates in OCO. Empirical results further substantiate the
effectiveness of our algorithms. Simultaneously, we unveil that the dynamic
Nash equilibrium regret, which was initially introduced in a recent paper, has
inherent defects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1&quot;&gt;Qing-xin Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jian-wei Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07559">
<title>PaperQA: Retrieval-Augmented Generative Agent for Scientific Research. (arXiv:2312.07559v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.07559</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) generalize well across language tasks, but
suffer from hallucinations and uninterpretability, making it difficult to
assess their accuracy without ground-truth. Retrieval-Augmented Generation
(RAG) models have been proposed to reduce hallucinations and provide provenance
for how an answer was generated. Applying such models to the scientific
literature may enable large-scale, systematic processing of scientific
knowledge. We present PaperQA, a RAG agent for answering questions over the
scientific literature. PaperQA is an agent that performs information retrieval
across full-text scientific articles, assesses the relevance of sources and
passages, and uses RAG to provide answers. Viewing this agent as a question
answering model, we find it exceeds performance of existing LLMs and LLM agents
on current science QA benchmarks. To push the field closer to how humans
perform research on scientific literature, we also introduce LitQA, a more
complex benchmark that requires retrieval and synthesis of information from
full-text scientific papers across the literature. Finally, we demonstrate
PaperQA&apos;s matches expert human researchers on LitQA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lala_J/0/1/0/all/0/1&quot;&gt;Jakub L&amp;#xe1;la&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ODonoghue_O/0/1/0/all/0/1&quot;&gt;Odhran O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shtedritski_A/0/1/0/all/0/1&quot;&gt;Aleksandar Shtedritski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cox_S/0/1/0/all/0/1&quot;&gt;Sam Cox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriques_S/0/1/0/all/0/1&quot;&gt;Samuel G. Rodriques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1&quot;&gt;Andrew D. White&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.07577">
<title>Benchmarking Distribution Shift in Tabular Data with TableShift. (arXiv:2312.07577v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.07577</link>
<description rdf:parseType="Literal">&lt;p&gt;Robustness to distribution shift has become a growing concern for text and
image models as they transition from research subjects to deployment in the
real world. However, high-quality benchmarks for distribution shift in tabular
machine learning tasks are still lacking despite the widespread real-world use
of tabular data and differences in the models used for tabular data in
comparison to text and images. As a consequence, the robustness of tabular
models to distribution shift is poorly understood. To address this issue, we
introduce TableShift, a distribution shift benchmark for tabular data.
TableShift contains 15 binary classification tasks in total, each with an
associated shift, and includes a diverse set of data sources, prediction
targets, and distribution shifts. The benchmark covers domains including
finance, education, public policy, healthcare, and civic participation, and is
accessible using only a few lines of Python code via the TableShift API. We
conduct a large-scale study comparing several state-of-the-art tabular data
models alongside robust learning and domain generalization methods on the
benchmark tasks. Our study demonstrates (1) a linear trend between
in-distribution (ID) and out-of-distribution (OOD) accuracy; (2) domain
robustness methods can reduce shift gaps but at the cost of reduced ID
accuracy; (3) a strong relationship between shift gap (difference between ID
and OOD performance) and shifts in the label distribution.
&lt;/p&gt;
&lt;p&gt;The benchmark data, Python package, model implementations, and more
information about TableShift are available at
https://github.com/mlfoundations/tableshift and https://tableshift.org .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1&quot;&gt;Josh Gardner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popovic_Z/0/1/0/all/0/1&quot;&gt;Zoran Popovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1&quot;&gt;Ludwig Schmidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08672">
<title>CAT: A Causally Graph Attention Network for Trimming Heterophilic Graph. (arXiv:2312.08672v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.08672</link>
<description rdf:parseType="Literal">&lt;p&gt;Local Attention-guided Message Passing Mechanism (LAMP) adopted in Graph
Attention Networks (GATs) is designed to adaptively learn the importance of
neighboring nodes for better local aggregation on the graph, which can bring
the representations of similar neighbors closer effectively, thus showing
stronger discrimination ability. However, existing GATs suffer from a
significant discrimination ability decline in heterophilic graphs because the
high proportion of dissimilar neighbors can weaken the self-attention of the
central node, jointly resulting in the deviation of the central node from
similar nodes in the representation space. This kind of effect generated by
neighboring nodes is called the Distraction Effect (DE) in this paper. To
estimate and weaken the DE of neighboring nodes, we propose a Causally graph
Attention network for Trimming heterophilic graph (CAT). To estimate the DE,
since the DE are generated through two paths (grab the attention assigned to
neighbors and reduce the self-attention of the central node), we use Total
Effect to model DE, which is a kind of causal estimand and can be estimated
from intervened data; To weaken the DE, we identify the neighbors with the
highest DE (we call them Distraction Neighbors) and remove them. We adopt three
representative GATs as the base model within the proposed CAT framework and
conduct experiments on seven heterophilic datasets in three different sizes.
Comparative experiments show that CAT can improve the node classification
accuracy of all base GAT models. Ablation experiments and visualization further
validate the enhancement of discrimination ability brought by CAT. The source
code is available at https://github.com/GeoX-Lab/CAT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1&quot;&gt;Silu He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Q/0/1/0/all/0/1&quot;&gt;Qinyao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1&quot;&gt;Xinsha Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Ling Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_R/0/1/0/all/0/1&quot;&gt;Ronghua Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haifeng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08782">
<title>Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis. (arXiv:2312.08782v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2312.08782</link>
<description rdf:parseType="Literal">&lt;p&gt;Building general-purpose robots that can operate seamlessly, in any
environment, with any object, and utilizing various skills to complete diverse
tasks has been a long-standing goal in Artificial Intelligence. Unfortunately,
however, most existing robotic systems have been constrained - having been
designed for specific tasks, trained on specific datasets, and deployed within
specific environments. These systems usually require extensively-labeled data,
rely on task-specific models, have numerous generalization issues when deployed
in real-world scenarios, and struggle to remain robust to distribution shifts.
Motivated by the impressive open-set performance and content generation
capabilities of web-scale, large-capacity pre-trained models (i.e., foundation
models) in research fields such as Natural Language Processing (NLP) and
Computer Vision (CV), we devote this survey to exploring (i) how these existing
foundation models from NLP and CV can be applied to the field of robotics, and
also exploring (ii) what a robotics-specific foundation model would look like.
We begin by providing an overview of what constitutes a conventional robotic
system and the fundamental barriers to making it universally applicable. Next,
we establish a taxonomy to discuss current work exploring ways to leverage
existing foundation models for robotics and develop ones catered to robotics.
Finally, we discuss key challenges and promising future directions in using
foundation models for enabling general-purpose robotic systems. We encourage
readers to view our living GitHub repository of resources, including papers
reviewed in this survey as well as related projects and repositories for
developing foundation models for robotics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yafei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1&quot;&gt;Quanting Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1&quot;&gt;Vidhi Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Francis_J/0/1/0/all/0/1&quot;&gt;Jonathan Francis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patrikar_J/0/1/0/all/0/1&quot;&gt;Jay Patrikar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keetha_N/0/1/0/all/0/1&quot;&gt;Nikhil Keetha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seungchan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yaqi Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shibo Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chong_Y/0/1/0/all/0/1&quot;&gt;Yu Quan Chong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1&quot;&gt;Katia Sycara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_Roberson_M/0/1/0/all/0/1&quot;&gt;Matthew Johnson-Roberson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaolong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1&quot;&gt;Sebastian Scherer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1&quot;&gt;Zsolt Kira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1&quot;&gt;Fei Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1&quot;&gt;Yonatan Bisk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08820">
<title>How to Raise a Robot -- A Case for Neuro-Symbolic AI in Constrained Task Planning for Humanoid Assistive Robots. (arXiv:2312.08820v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2312.08820</link>
<description rdf:parseType="Literal">&lt;p&gt;Humanoid robots will be able to assist humans in their daily life, in
particular due to their versatile action capabilities. However, while these
robots need a certain degree of autonomy to learn and explore, they also should
respect various constraints, for access control and beyond. We explore the
novel field of incorporating privacy, security, and access control constraints
with robot task planning approaches. We report preliminary results on the
classical symbolic approach, deep-learned neural networks, and modern ideas
using large language models as knowledge base. From analyzing their trade-offs,
we conclude that a hybrid approach is necessary, and thereby present a new use
case for the emerging field of neuro-symbolic artificial intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemken_N/0/1/0/all/0/1&quot;&gt;Niklas Hemken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacob_F/0/1/0/all/0/1&quot;&gt;Florian Jacob&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peller_Konrad_F/0/1/0/all/0/1&quot;&gt;Fabian Peller-Konrad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kartmann_R/0/1/0/all/0/1&quot;&gt;Rainer Kartmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1&quot;&gt;Tamim Asfour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hartenstein_H/0/1/0/all/0/1&quot;&gt;Hannes Hartenstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08887">
<title>SpeedUpNet: A Plug-and-Play Hyper-Network for Accelerating Text-to-Image Diffusion Models. (arXiv:2312.08887v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2312.08887</link>
<description rdf:parseType="Literal">&lt;p&gt;Text-to-image diffusion models (SD) exhibit significant advancements while
requiring extensive computational resources. Though many acceleration methods
have been proposed, they suffer from generation quality degradation or extra
training cost generalizing to new fine-tuned models. To address these
limitations, we propose a novel and universal Stable-Diffusion (SD)
acceleration module called SpeedUpNet(SUN). SUN can be directly plugged into
various fine-tuned SD models without extra training. This technique utilizes
cross-attention layers to learn the relative offsets in the generated image
results between negative and positive prompts achieving classifier-free
guidance distillation with negative prompts controllable, and introduces a
Multi-Step Consistency (MSC) loss to ensure a harmonious balance between
reducing inference steps and maintaining consistency in the generated output.
Consequently, SUN significantly reduces the number of inference steps to just 4
steps and eliminates the need for classifier-free guidance. It leads to an
overall speedup of more than 10 times for SD models compared to the
state-of-the-art 25-step DPM-solver++, and offers two extra advantages: (1)
classifier-free guidance distillation with controllable negative prompts and
(2) seamless integration into various fine-tuned Stable-Diffusion models
without training. The effectiveness of the SUN has been verified through
extensive experimentation. Project Page:
https://williechai.github.io/speedup-plugin-for-stable-diffusions.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chai_W/0/1/0/all/0/1&quot;&gt;Weilong Chai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1&quot;&gt;DanDan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1&quot;&gt;Jiajiong Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhiquan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Changbao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chenguang Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08944">
<title>What&apos;s Next? Predicting Hamiltonian Dynamics from Discrete Observations of a Vector Field. (arXiv:2312.08944v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.08944</link>
<description rdf:parseType="Literal">&lt;p&gt;We present several methods for predicting the dynamics of Hamiltonian systems
from discrete observations of their vector field. Each method is either
informed or uninformed of the Hamiltonian property. We empirically and
comparatively evaluate the methods and observe that information that the system
is Hamiltonian can be effectively informed, and that different methods strike
different trade-offs between efficiency and effectiveness for different
dynamical systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoo_Z/0/1/0/all/0/1&quot;&gt;Zi-Yu Khoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Delong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bressan_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Bressan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.08948">
<title>LSTM Network Analysis of Vehicle-Type Fatalities on Great Britain&apos;s Roads. (arXiv:2312.08948v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.08948</link>
<description rdf:parseType="Literal">&lt;p&gt;This study harnesses the predictive capabilities of Long Short-Term Memory
(LSTM) networks to analyse and predict road traffic accidents in Great Britain.
It addresses the challenge of traffic accident forecasting, which is paramount
for devising effective preventive measures. We utilised an extensive dataset
encompassing reported collisions, casualties, and vehicles involvements from
1926 to 2022, provided by the Department for Transport (DfT). The data
underwent stringent processing to rectify missing values and normalise
features, ensuring robust LSTM network input.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oketunji_A/0/1/0/all/0/1&quot;&gt;Abiodun Finbarrs Oketunji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanify_J/0/1/0/all/0/1&quot;&gt;James Hanify&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heffron_Smith_S/0/1/0/all/0/1&quot;&gt;Salter Heffron-Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.09108">
<title>Greedy Shapley Client Selection for Communication-Efficient Federated Learning. (arXiv:2312.09108v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.09108</link>
<description rdf:parseType="Literal">&lt;p&gt;The standard client selection algorithms for Federated Learning (FL) are
often unbiased and involve uniform random sampling of clients. This has been
proven sub-optimal for fast convergence under practical settings characterized
by significant heterogeneity in data distribution, computing, and communication
resources across clients. For applications having timing constraints due to
limited communication opportunities with the parameter server (PS), the client
selection strategy is critical to complete model training within the fixed
budget of communication rounds. To address this, we develop a biased client
selection strategy, GreedyFed, that identifies and greedily selects the most
contributing clients in each communication round. This method builds on a fast
approximation algorithm for the Shapley Value at the PS, making the computation
tractable for real-world applications with many clients. Compared to various
client selection strategies on several real-world datasets, GreedyFed
demonstrates fast and stable convergence with high accuracy under timing
constraints and when imposing a higher degree of heterogeneity in data
distribution, systems constraints, and privacy requirements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhal_P/0/1/0/all/0/1&quot;&gt;Pranava Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1&quot;&gt;Shashi Raj Pandey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popovski_P/0/1/0/all/0/1&quot;&gt;Petar Popovski&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>