<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2024-01-02T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00857" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00859" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00867" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00873" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00876" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00883" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00885" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00894" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00900" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00902" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00907" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00909" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00910" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00953" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00955" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00961" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00964" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00965" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00972" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00973" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00974" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00981" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01004" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01010" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01013" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01021" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01023" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01047" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01048" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01054" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01056" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01077" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01083" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01084" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01085" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01099" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01100" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01119" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01124" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01145" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01148" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01155" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01160" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01165" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01168" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01172" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01176" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01179" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01192" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01199" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01218" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01232" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01233" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01242" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01243" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01259" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01268" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01270" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01273" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01280" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01294" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01303" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01326" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.01335" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.14082" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.10955" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2201.01942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.02164" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.00109" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.06950" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.09041" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.14826" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.15542" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.07175" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.00316" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.00878" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.14274" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.14374" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.02803" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06920" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.17760" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.10875" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.16164" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.13815" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.15640" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.09222" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.14496" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15224" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16741" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.17207" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.09167" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.10477" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2310.19923" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2311.15218" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.00042" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.01187" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.01479" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04021" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.04469" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.05332" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.10144" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.11460" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.12028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.17300" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2312.17353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00544" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2401.00744" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2401.00857">
<title>Emissions Reporting Maturity Model: supporting cities to leverage emissions-related processes through performance indicators and artificial intelligence. (arXiv:2401.00857v1 [cs.CY])</title>
<link>http://arxiv.org/abs/2401.00857</link>
<description rdf:parseType="Literal">&lt;p&gt;Climate change and global warming have been trending topics worldwide since
the Eco-92 conference. However, little progress has been made in reducing
greenhouse gases (GHGs). The problems and challenges related to emissions are
complex and require a concerted and comprehensive effort to address them.
Emissions reporting is a critical component of GHG reduction policy and is
therefore the focus of this work. The main goal of this work is two-fold: (i)
to propose an emission reporting evaluation model to leverage emissions
reporting overall quality and (ii) to use artificial intelligence (AI) to
support the initiatives that improve emissions reporting. Thus, this work
presents an Emissions Reporting Maturity Model (ERMM) for examining,
clustering, and analysing data from emissions reporting initiatives to help the
cities to deal with climate change and global warming challenges. The
Performance Indicator Development Process (PIDP) proposed in this work provides
ways to leverage the quality of the available data necessary for the execution
of the evaluations identified by the ERMM. Hence, the PIDP supports the
preparation of the data from emissions-related databases, the classification of
the data according to similarities highlighted by different clustering
techniques, and the identification of performance indicator candidates, which
are strengthened by a qualitative analysis of selected data samples. Thus, the
main goal of ERRM is to evaluate and classify the cities regarding the emission
reporting processes, pointing out the drawbacks and challenges faced by other
cities from different contexts, and at the end to help them to leverage the
underlying emissions-related processes and emissions mitigation initiatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xavier_V/0/1/0/all/0/1&quot;&gt;Victor de A. Xavier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franca_F/0/1/0/all/0/1&quot;&gt;Felipe M.G. Fran&amp;#xe7;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lima_P/0/1/0/all/0/1&quot;&gt;Priscila M.V. Lima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00859">
<title>Federated Multi-View Synthesizing for Metaverse. (arXiv:2401.00859v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2401.00859</link>
<description rdf:parseType="Literal">&lt;p&gt;The metaverse is expected to provide immersive entertainment, education, and
business applications. However, virtual reality (VR) transmission over wireless
networks is data- and computation-intensive, making it critical to introduce
novel solutions that meet stringent quality-of-service requirements. With
recent advances in edge intelligence and deep learning, we have developed a
novel multi-view synthesizing framework that can efficiently provide
computation, storage, and communication resources for wireless content delivery
in the metaverse. We propose a three-dimensional (3D)-aware generative model
that uses collections of single-view images. These single-view images are
transmitted to a group of users with overlapping fields of view, which avoids
massive content transmission compared to transmitting tiles or whole 3D models.
We then present a federated learning approach to guarantee an efficient
learning process. The training performance can be improved by characterizing
the vertical and horizontal data samples with a large latent feature space,
while low-latency communication can be achieved with a reduced number of
transmitted parameters during federated learning. We also propose a federated
transfer learning framework to enable fast domain adaptation to different
target domains. Simulation results have demonstrated the effectiveness of our
proposed federated multi-view synthesizing framework for VR content delivery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yiyu Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Qin_Z/0/1/0/all/0/1&quot;&gt;Zhijin Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tao_X/0/1/0/all/0/1&quot;&gt;Xiaoming Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Geoffrey Ye Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00867">
<title>Tensor Networks for Explainable Machine Learning in Cybersecurity. (arXiv:2401.00867v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00867</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we show how tensor networks help in developing explainability
of machine learning algorithms. Specifically, we develop an unsupervised
clustering algorithm based on Matrix Product States (MPS) and apply it in the
context of a real use-case of adversary-generated threat intelligence. Our
investigation proves that MPS rival traditional deep learning models such as
autoencoders and GANs in terms of performance, while providing much richer
model interpretability. Our approach naturally facilitates the extraction of
feature-wise probabilities, Von Neumann Entropy, and mutual information,
offering a compelling narrative for classification of anomalies and fostering
an unprecedented level of transparency and interpretability, something
fundamental to understand the rationale behind artificial intelligence
decisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aizpurua_B/0/1/0/all/0/1&quot;&gt;Borja Aizpurua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orus_R/0/1/0/all/0/1&quot;&gt;Roman Orus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00873">
<title>A Bayesian Unification of Self-Supervised Clustering and Energy-Based Models. (arXiv:2401.00873v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00873</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning is a popular and powerful method for utilizing large
amounts of unlabeled data, for which a wide variety of training objectives have
been proposed in the literature. In this study, we perform a Bayesian analysis
of state-of-the-art self-supervised learning objectives, elucidating the
underlying probabilistic graphical models in each class and presenting a
standardized methodology for their derivation from first principles. The
analysis also indicates a natural means of integrating self-supervised learning
with likelihood-based generative models. We instantiate this concept within the
realm of cluster-based self-supervised learning and energy models, introducing
a novel lower bound which is proven to reliably penalize the most important
failure modes. Furthermore, this newly proposed lower bound enables the
training of a standard backbone architecture without the necessity for
asymmetric elements such as stop gradients, momentum encoders, or specialized
clustering layers - typically introduced to avoid learning trivial solutions.
Our theoretical findings are substantiated through experiments on synthetic and
real-world data, including SVHN, CIFAR10, and CIFAR100, thus showing that our
objective function allows to outperform existing self-supervised learning
strategies in terms of clustering, generation and out-of-distribution detection
performance by a wide margin. We also demonstrate that GEDI can be integrated
into a neural-symbolic framework to mitigate the reasoning shortcut problem and
to learn higher quality symbolic representations thanks to the enhanced
classification performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sansone_E/0/1/0/all/0/1&quot;&gt;Emanuele Sansone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manhaeve_R/0/1/0/all/0/1&quot;&gt;Robin Manhaeve&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00876">
<title>Balanced Graph Structure Information for Brain Disease Detection. (arXiv:2401.00876v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00876</link>
<description rdf:parseType="Literal">&lt;p&gt;Analyzing connections between brain regions of interest (ROI) is vital to
detect neurological disorders such as autism or schizophrenia. Recent
advancements employ graph neural networks (GNNs) to utilize graph structures in
brains, improving detection performances. Current methods use correlation
measures between ROI&apos;s blood-oxygen-level-dependent (BOLD) signals to generate
the graph structure. Other methods use the training samples to learn the
optimal graph structure through end-to-end learning. However, implementing
those methods independently leads to some issues with noisy data for the
correlation graphs and overfitting problems for the optimal graph. In this
work, we proposed Bargrain (balanced graph structure for brains), which models
two graph structures: filtered correlation matrix and optimal sample graph
using graph convolution networks (GCNs). This approach aims to get advantages
from both graphs and address the limitations of only relying on a single type
of structure. Based on our extensive experiment, Bargrain outperforms
state-of-the-art methods in classification tasks on brain disease datasets, as
measured by average F1 scores.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Febrinanto_F/0/1/0/all/0/1&quot;&gt;Falih Gozi Febrinanto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Mujie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1&quot;&gt;Feng Xia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00883">
<title>Automating Leukemia Diagnosis with Autoencoders: A Comparative Study. (arXiv:2401.00883v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00883</link>
<description rdf:parseType="Literal">&lt;p&gt;Leukemia is one of the most common and death-threatening types of cancer that
threaten human life. Medical data from some of the patient&apos;s critical
parameters contain valuable information hidden among these data. On this
subject, deep learning can be used to extract this information. In this paper,
AutoEncoders have been used to develop valuable features to help the precision
of leukemia diagnosis. It has been attempted to get the best activation
function and optimizer to use in AutoEncoder and designed the best architecture
for this neural network. The proposed architecture is compared with this area&apos;s
classical machine learning models. Our proposed method performs better than
other machine learning in precision and f1-score metrics by more than 11%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sayyadpour_M/0/1/0/all/0/1&quot;&gt;Minoo Sayyadpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moghaddamniya_N/0/1/0/all/0/1&quot;&gt;Nasibe Moghaddamniya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banirostam_T/0/1/0/all/0/1&quot;&gt;Touraj Banirostam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00885">
<title>Attractor reconstruction with reservoir computers: The effect of the reservoir&apos;s conditional Lyapunov exponents on faithful attractor reconstruction. (arXiv:2401.00885v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00885</link>
<description rdf:parseType="Literal">&lt;p&gt;Reservoir computing is a machine learning technique which has been shown to
be able to replicate the chaotic attractor, including the fractal dimension and
the entire Lyapunov spectrum, of the dynamical system on which it is trained.
We quantitatively relate the generalized synchronization dynamics of a driven
reservoir computer during the training stage to the performance of the
autonomous reservoir computer at the attractor reconstruction task. We show
that, for successful attractor reconstruction and Lyapunov exponent estimation,
the largest conditional Lyapunov exponent of the driven reservoir must be
significantly smaller (more negative) than the smallest (most negative)
Lyapunov exponent of the true system. We find that the maximal conditional
Lyapunov exponent of the reservoir depends strongly on the spectral radius of
the reservoir adjacency matrix, and therefore, for attractor reconstruction and
Lyapunov exponent estimation, small spectral radius reservoir computers perform
better in general. Our arguments are supported by numerical examples on
well-known chaotic systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hart_J/0/1/0/all/0/1&quot;&gt;Joseph D. Hart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00894">
<title>Balanced Multi-modal Federated Learning via Cross-Modal Infiltration. (arXiv:2401.00894v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00894</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) underpins advancements in privacy-preserving
distributed computing by collaboratively training neural networks without
exposing clients&apos; raw data. Current FL paradigms primarily focus on uni-modal
data, while exploiting the knowledge from distributed multimodal data remains
largely unexplored. Existing multimodal FL (MFL) solutions are mainly designed
for statistical or modality heterogeneity from the input side, however, have
yet to solve the fundamental issue,&quot;modality imbalance&quot;, in distributed
conditions, which can lead to inadequate information exploitation and
heterogeneous knowledge aggregation on different modalities.In this paper, we
propose a novel Cross-Modal Infiltration Federated Learning (FedCMI) framework
that effectively alleviates modality imbalance and knowledge heterogeneity via
knowledge transfer from the global dominant modality. To avoid the loss of
information in the weak modality due to merely imitating the behavior of
dominant modality, we design the two-projector module to integrate the
knowledge from dominant modality while still promoting the local feature
exploitation of weak modality. In addition, we introduce a class-wise
temperature adaptation scheme to achieve fair performance across different
classes. Extensive experiments over popular datasets are conducted and give us
a gratifying confirmation of the proposed framework for fully exploring the
information of each modality in MFL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Yunfeng Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Wenchao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haozhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jiaqi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1&quot;&gt;Song Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00900">
<title>Detecting the presence of sperm whales echolocation clicks in noisy environments. (arXiv:2401.00900v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2401.00900</link>
<description rdf:parseType="Literal">&lt;p&gt;Sperm whales (Physeter macrocephalus) navigate underwater with a series of
impulsive, click-like sounds known as echolocation clicks. These clicks are
characterized by a multipulse structure (MPS) that serves as a distinctive
pattern. In this work, we use the stability of the MPS as a detection metric
for recognizing and classifying the presence of clicks in noisy environments.
To distinguish between noise transients and to handle simultaneous emissions
from multiple sperm whales, our approach clusters a time series of MPS measures
while removing potential clicks that do not fulfil the limits of inter-click
interval, duration and spectrum. As a result, our approach can handle high
noise transients and low signal-to-noise ratio. The performance of our
detection approach is examined using three datasets: seven months of recordings
from the Mediterranean Sea containing manually verified ambient noise; several
days of manually labelled data collected from the Dominica Island containing
approximately 40,000 clicks from multiple sperm whales; and a dataset from the
Bahamas containing 1,203 labelled clicks from a single sperm whale. Comparing
with the results of two benchmark detectors, a better trade-off between
precision and recall is observed as well as a significant reduction in false
detection rates, especially in noisy environments. To ensure reproducibility,
we provide our database of labelled clicks along with our implementation code.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gubnitsky_G/0/1/0/all/0/1&quot;&gt;Guy Gubnitsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Diamant_R/0/1/0/all/0/1&quot;&gt;Roee Diamant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00902">
<title>Evaluating the Fairness of the MIMIC-IV Dataset and a Baseline Algorithm: Application to the ICU Length of Stay Prediction. (arXiv:2401.00902v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00902</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper uses the MIMIC-IV dataset to examine the fairness and bias in an
XGBoost binary classification model predicting the Intensive Care Unit (ICU)
length of stay (LOS). Highlighting the critical role of the ICU in managing
critically ill patients, the study addresses the growing strain on ICU
capacity. It emphasizes the significance of LOS prediction for resource
allocation. The research reveals class imbalances in the dataset across
demographic attributes and employs data preprocessing and feature extraction.
While the XGBoost model performs well overall, disparities across race and
insurance attributes reflect the need for tailored assessments and continuous
monitoring. The paper concludes with recommendations for fairness-aware machine
learning techniques for mitigating biases and the need for collaborative
efforts among healthcare professionals and data scientists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakadiaris_A/0/1/0/all/0/1&quot;&gt;Alexandra Kakadiaris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00907">
<title>LaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models. (arXiv:2401.00907v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00907</link>
<description rdf:parseType="Literal">&lt;p&gt;Fine-tuning Large Language Models (LLMs) adapts a trained model to specific
downstream tasks, significantly improving task-specific performance. Supervised
Fine-Tuning (SFT) is a common approach, where an LLM is trained to produce
desired answers. However, LLMs trained with SFT sometimes make simple mistakes
and result in hallucinations on reasoning tasks such as question-answering.
Without external feedback, it is difficult for SFT to learn a good mapping
between the question and the desired answer, especially with a small dataset.
This paper introduces an alternative to SFT called Natural Language Feedback
for Finetuning LLMs (LaFFi). LaFFi has LLMs directly predict the feedback they
will receive from an annotator. We find that requiring such reflection can
significantly improve the accuracy in in-domain question-answering tasks,
providing a promising direction for the application of natural language
feedback in the realm of SFT LLMs. Additional ablation studies show that the
portion of human-annotated data in the annotated datasets affects the
fine-tuning performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qianxi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yingyue Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1&quot;&gt;Jikun Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1&quot;&gt;Tianpei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1&quot;&gt;Jun Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1&quot;&gt;Matthew E. Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00909">
<title>Taming Mode Collapse in Score Distillation for Text-to-3D Generation. (arXiv:2401.00909v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.00909</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the remarkable performance of score distillation in text-to-3D
generation, such techniques notoriously suffer from view inconsistency issues,
also known as &quot;Janus&quot; artifact, where the generated objects fake each view with
multiple front faces. Although empirically effective methods have approached
this problem via score debiasing or prompt engineering, a more rigorous
perspective to explain and tackle this problem remains elusive. In this paper,
we reveal that the existing score distillation-based text-to-3D generation
frameworks degenerate to maximal likelihood seeking on each view independently
and thus suffer from the mode collapse problem, manifesting as the Janus
artifact in practice. To tame mode collapse, we improve score distillation by
re-establishing in entropy term in the corresponding variational objective,
which is applied to the distribution of rendered images. Maximizing the entropy
encourages diversity among different views in generated 3D assets, thereby
mitigating the Janus problem. Based on this new objective, we derive a new
update rule for 3D score distillation, dubbed Entropic Score Distillation
(ESD). We theoretically reveal that ESD can be simplified and implemented by
just adopting the classifier-free guidance trick upon variational score
distillation. Although embarrassingly straightforward, our extensive
experiments successfully demonstrate that ESD can be an effective treatment for
Janus artifacts in score distillation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Peihao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1&quot;&gt;Dejia Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1&quot;&gt;Zhiwen Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dilin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohan_S/0/1/0/all/0/1&quot;&gt;Sreyas Mohan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iandola_F/0/1/0/all/0/1&quot;&gt;Forrest Iandola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranjan_R/0/1/0/all/0/1&quot;&gt;Rakesh Ranjan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yilei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhangyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1&quot;&gt;Vikas Chandra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00910">
<title>WoodScape Motion Segmentation for Autonomous Driving -- CVPR 2023 OmniCV Workshop Challenge. (arXiv:2401.00910v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.00910</link>
<description rdf:parseType="Literal">&lt;p&gt;Motion segmentation is a complex yet indispensable task in autonomous
driving. The challenges introduced by the ego-motion of the cameras, radial
distortion in fisheye lenses, and the need for temporal consistency make the
task more complicated, rendering traditional and standard Convolutional Neural
Network (CNN) approaches less effective. The consequent laborious data
labeling, representation of diverse and uncommon scenarios, and extensive data
capture requirements underscore the imperative of synthetic data for improving
machine learning model performance. To this end, we employ the PD-WoodScape
synthetic dataset developed by Parallel Domain, alongside the WoodScape fisheye
dataset. Thus, we present the WoodScape fisheye motion segmentation challenge
for autonomous driving, held as part of the CVPR 2023 Workshop on
Omnidirectional Computer Vision (OmniCV). As one of the first competitions
focused on fisheye motion segmentation, we aim to explore and evaluate the
potential and impact of utilizing synthetic data in this domain. In this paper,
we provide a detailed analysis on the competition which attracted the
participation of 112 global teams and a total of 234 submissions. This study
delineates the complexities inherent in the task of motion segmentation,
emphasizes the significance of fisheye datasets, articulate the necessity for
synthetic datasets and the resultant domain gap they engender, outlining the
foundational blueprint for devising successful solutions. Subsequently, we
delve into the details of the baseline experiments and winning methods
evaluating their qualitative and quantitative results, providing with useful
insights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramachandran_S/0/1/0/all/0/1&quot;&gt;Saravanabalagi Ramachandran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cibik_N/0/1/0/all/0/1&quot;&gt;Nathaniel Cibik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sistu_G/0/1/0/all/0/1&quot;&gt;Ganesh Sistu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1&quot;&gt;John McDonald&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00916">
<title>Data Assimilation in Chaotic Systems Using Deep Reinforcement Learning. (arXiv:2401.00916v1 [math.DS])</title>
<link>http://arxiv.org/abs/2401.00916</link>
<description rdf:parseType="Literal">&lt;p&gt;Data assimilation (DA) plays a pivotal role in diverse applications, ranging
from climate predictions and weather forecasts to trajectory planning for
autonomous vehicles. A prime example is the widely used ensemble Kalman filter
(EnKF), which relies on linear updates to minimize variance among the ensemble
of forecast states. Recent advancements have seen the emergence of deep
learning approaches in this domain, primarily within a supervised learning
framework. However, the adaptability of such models to untrained scenarios
remains a challenge. In this study, we introduce a novel DA strategy that
utilizes reinforcement learning (RL) to apply state corrections using full or
partial observations of the state variables. Our investigation focuses on
demonstrating this approach to the chaotic Lorenz &apos;63 system, where the agent&apos;s
objective is to minimize the root-mean-squared error between the observations
and corresponding forecast states. Consequently, the agent develops a
correction strategy, enhancing model forecasts based on available system state
observations. Our strategy employs a stochastic action policy, enabling a Monte
Carlo-based DA framework that relies on randomly sampling the policy to
generate an ensemble of assimilated realizations. Results demonstrate that the
developed RL algorithm performs favorably when compared to the EnKF.
Additionally, we illustrate the agent&apos;s capability to assimilate non-Gaussian
data, addressing a significant limitation of the EnKF.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hammoud_M/0/1/0/all/0/1&quot;&gt;Mohamad Abed El Rahman Hammoud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Raboudi_N/0/1/0/all/0/1&quot;&gt;Naila Raboudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Titi_E/0/1/0/all/0/1&quot;&gt;Edriss S. Titi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Knio_O/0/1/0/all/0/1&quot;&gt;Omar Knio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hoteit_I/0/1/0/all/0/1&quot;&gt;Ibrahim Hoteit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00950">
<title>Unsupervised Graph-based Learning Method for Sub-band Allocation in 6G Subnetworks. (arXiv:2401.00950v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2401.00950</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present an unsupervised approach for frequency sub-band
allocation in wireless networks using graph-based learning. We consider a dense
deployment of subnetworks in the factory environment with a limited number of
sub-bands which must be optimally allocated to coordinate inter-subnetwork
interference. We model the subnetwork deployment as a conflict graph and
propose an unsupervised learning approach inspired by the graph colouring
heuristic and the Potts model to optimize the sub-band allocation using graph
neural networks. The numerical evaluation shows that the proposed method
achieves close performance to the centralized greedy colouring sub-band
allocation heuristic with lower computational time complexity. In addition, it
incurs reduced signalling overhead compared to iterative optimization
heuristics that require all the mutual interfering channel information. We
further demonstrate that the method is robust to different network settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abode_D/0/1/0/all/0/1&quot;&gt;Daniel Abode&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adeogun_R/0/1/0/all/0/1&quot;&gt;Ramoni Adeogun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salaun_L/0/1/0/all/0/1&quot;&gt;Lou Sala&amp;#xfc;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abreu_R/0/1/0/all/0/1&quot;&gt;Renato Abreu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobsen_T/0/1/0/all/0/1&quot;&gt;Thomas Jacobsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berardinelli_G/0/1/0/all/0/1&quot;&gt;Gilberto Berardinelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00953">
<title>Families of costs with zero and nonnegative MTW tensor in optimal transport. (arXiv:2401.00953v1 [math.AP])</title>
<link>http://arxiv.org/abs/2401.00953</link>
<description rdf:parseType="Literal">&lt;p&gt;We compute explicitly the MTW tensor (or cross curvature) for the optimal
transport problem on $\mathbb{R}^n$ with a cost function of form $\mathsf{c}(x,
y) = \mathsf{u}(x^{\mathfrak{t}}y)$, where $\mathsf{u}$ is a scalar function
with inverse $\mathsf{s}$, $x^{\ft}y$ is a nondegenerate bilinear pairing of
vectors $x, y$ belonging to an open subset of $\mathbb{R}^n$. The condition
that the MTW-tensor vanishes on null vectors under the Kim-McCann metric is a
fourth-order nonlinear ODE, which could be reduced to a linear ODE of the form
$\mathsf{s}^{(2)} - S\mathsf{s}^{(1)} + P\mathsf{s} = 0$ with constant
coefficients $P$ and $S$. The resulting inverse functions include {\it Lambert}
and {\it generalized inverse hyperbolic\slash trigonometric} functions. The
square Euclidean metric and $\log$-type costs are equivalent to instances of
these solutions. The optimal map for the family is also explicit. For cost
functions of a similar form on a hyperboloid model of the hyperbolic space and
unit sphere, we also express this tensor in terms of algebraic expressions in
derivatives of $\mathsf{s}$ using the Gauss-Codazzi equation, obtaining new
families of strictly regular costs for these manifolds, including new families
of {\it power function costs}. We analyze the $\sinh$-type hyperbolic cost,
providing examples of $\mathsf{c}$-convex functions and divergence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Du Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00955">
<title>Learning Long Sequences in Spiking Neural Networks. (arXiv:2401.00955v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2401.00955</link>
<description rdf:parseType="Literal">&lt;p&gt;Spiking neural networks (SNNs) take inspiration from the brain to enable
energy-efficient computations. Since the advent of Transformers, SNNs have
struggled to compete with artificial networks on modern sequential tasks, as
they inherit limitations from recurrent neural networks (RNNs), with the added
challenge of training with non-differentiable binary spiking activations.
However, a recent renewed interest in efficient alternatives to Transformers
has given rise to state-of-the-art recurrent architectures named state space
models (SSMs). This work systematically investigates, for the first time, the
intersection of state-of-the-art SSMs with SNNs for long-range sequence
modelling. Results suggest that SSM-based SNNs can outperform the Transformer
on all tasks of a well-established long-range sequence modelling benchmark. It
is also shown that SSM-based SNNs can outperform current state-of-the-art SNNs
with fewer parameters on sequential image classification. Finally, a novel
feature mixing layer is introduced, improving SNN accuracy while challenging
assumptions about the role of binary activations in SNNs. This work paves the
way for deploying powerful SSM-based architectures, such as large language
models, to neuromorphic hardware for energy-efficient long-range sequence
modelling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stan_M/0/1/0/all/0/1&quot;&gt;Matei Ioan Stan&lt;/a&gt; (The University of Manchester), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rhodes_O/0/1/0/all/0/1&quot;&gt;Oliver Rhodes&lt;/a&gt; (The University of Manchester)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00961">
<title>Automated Model Selection for Tabular Data. (arXiv:2401.00961v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00961</link>
<description rdf:parseType="Literal">&lt;p&gt;Structured data in the form of tabular datasets contain features that are
distinct and discrete, with varying individual and relative importances to the
target. Combinations of one or more features may be more predictive and
meaningful than simple individual feature contributions. R&apos;s mixed effect
linear models library allows users to provide such interactive feature
combinations in the model design. However, given many features and possible
interactions to select from, model selection becomes an exponentially difficult
task. We aim to automate the model selection process for predictions on tabular
datasets incorporating feature interactions while keeping computational costs
small. The framework includes two distinct approaches for feature selection: a
Priority-based Random Grid Search and a Greedy Search method. The
Priority-based approach efficiently explores feature combinations using prior
probabilities to guide the search. The Greedy method builds the solution
iteratively by adding or removing features based on their impact. Experiments
on synthetic demonstrate the ability to effectively capture predictive feature
combinations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amballa_A/0/1/0/all/0/1&quot;&gt;Avinash Amballa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mekala_A/0/1/0/all/0/1&quot;&gt;Anmol Mekala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akkinapalli_G/0/1/0/all/0/1&quot;&gt;Gayathri Akkinapalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madine_M/0/1/0/all/0/1&quot;&gt;Manas Madine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yarrabolu_N/0/1/0/all/0/1&quot;&gt;Naga Pavana Priya Yarrabolu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grabowicz_P/0/1/0/all/0/1&quot;&gt;Przemyslaw A. Grabowicz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00964">
<title>Data Augmentation Techniques for Cross-Domain WiFi CSI-based Human Activity Recognition. (arXiv:2401.00964v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.00964</link>
<description rdf:parseType="Literal">&lt;p&gt;The recognition of human activities based on WiFi Channel State Information
(CSI) enables contactless and visual privacy-preserving sensing in indoor
environments. However, poor model generalization, due to varying environmental
conditions and sensing hardware, is a well-known problem in this space. To
address this issue, in this work, data augmentation techniques commonly used in
image-based learning are applied to WiFi CSI to investigate their effects on
model generalization performance in cross-scenario and cross-system settings.
In particular, we focus on the generalization between line-of-sight (LOS) and
non-line-of-sight (NLOS) through-wall scenarios, as well as on the
generalization between different antenna systems, which remains under-explored.
We collect and make publicly available a dataset of CSI amplitude spectrograms
of human activities. Utilizing this data, an ablation study is conducted in
which activity recognition models based on the EfficientNetV2 architecture are
trained, allowing us to assess the effects of each augmentation on model
generalization performance. The gathered results show that specific
combinations of simple data augmentation techniques applied to CSI amplitude
data can significantly improve cross-scenario and cross-system generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strohmayer_J/0/1/0/all/0/1&quot;&gt;Julian Strohmayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kampel_M/0/1/0/all/0/1&quot;&gt;Martin Kampel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00965">
<title>Improve Fidelity and Utility of Synthetic Credit Card Transaction Time Series from Data-centric Perspective. (arXiv:2401.00965v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00965</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploring generative model training for synthetic tabular data, specifically
in sequential contexts such as credit card transaction data, presents
significant challenges. This paper addresses these challenges, focusing on
attaining both high fidelity to actual data and optimal utility for machine
learning tasks. We introduce five pre-processing schemas to enhance the
training of the Conditional Probabilistic Auto-Regressive Model (CPAR),
demonstrating incremental improvements in the synthetic data&apos;s fidelity and
utility. Upon achieving satisfactory fidelity levels, our attention shifts to
training fraud detection models tailored for time-series data, evaluating the
utility of the synthetic data. Our findings offer valuable insights and
practical guidelines for synthetic data practitioners in the finance sector,
transitioning from real to synthetic datasets for training purposes, and
illuminating broader methodologies for synthesizing credit card transaction
time series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_D/0/1/0/all/0/1&quot;&gt;Din-Yin Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chi-Hua Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1&quot;&gt;Guang Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00972">
<title>Robust Meta-Model for Predicting the Need for Blood Transfusion in Non-traumatic ICU Patients. (arXiv:2401.00972v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00972</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: Blood transfusions, crucial in managing anemia and coagulopathy in
ICU settings, require accurate prediction for effective resource allocation and
patient risk assessment. However, existing clinical decision support systems
have primarily targeted a particular patient demographic with unique medical
conditions and focused on a single type of blood transfusion. This study aims
to develop an advanced machine learning-based model to predict the probability
of transfusion necessity over the next 24 hours for a diverse range of
non-traumatic ICU patients.
&lt;/p&gt;
&lt;p&gt;Methods: We conducted a retrospective cohort study on 72,072 adult
non-traumatic ICU patients admitted to a high-volume US metropolitan academic
hospital between 2016 and 2020. We developed a meta-learner and various machine
learning models to serve as predictors, training them annually with four-year
data and evaluating on the fifth, unseen year, iteratively over five years.
&lt;/p&gt;
&lt;p&gt;Results: The experimental results revealed that the meta-model surpasses the
other models in different development scenarios. It achieved notable
performance metrics, including an Area Under the Receiver Operating
Characteristic (AUROC) curve of 0.97, an accuracy rate of 0.93, and an F1-score
of 0.89 in the best scenario.
&lt;/p&gt;
&lt;p&gt;Conclusion: This study pioneers the use of machine learning models for
predicting blood transfusion needs in a diverse cohort of critically ill
patients. The findings of this evaluation confirm that our model not only
predicts transfusion requirements effectively but also identifies key
biomarkers for making transfusion decisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rafiei_A/0/1/0/all/0/1&quot;&gt;Alireza Rafiei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_R/0/1/0/all/0/1&quot;&gt;Ronald Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choudhary_T/0/1/0/all/0/1&quot;&gt;Tilendra Choudhary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marshall_C/0/1/0/all/0/1&quot;&gt;Curtis Marshall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_G/0/1/0/all/0/1&quot;&gt;Geoffrey Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roback_J/0/1/0/all/0/1&quot;&gt;John D. Roback&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_R/0/1/0/all/0/1&quot;&gt;Ravi M. Patel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Josephson_C/0/1/0/all/0/1&quot;&gt;Cassandra D. Josephson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamaleswaran_R/0/1/0/all/0/1&quot;&gt;Rishikesan Kamaleswaran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00973">
<title>Facebook Report on Privacy of fNIRS data. (arXiv:2401.00973v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00973</link>
<description rdf:parseType="Literal">&lt;p&gt;The primary goal of this project is to develop privacy-preserving machine
learning model training techniques for fNIRS data. This project will build a
local model in a centralized setting with both differential privacy (DP) and
certified robustness. It will also explore collaborative federated learning to
train a shared model between multiple clients without sharing local fNIRS
datasets. To prevent unintentional private information leakage of such clients&apos;
private datasets, we will also implement DP in the federated learning setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hossen_M/0/1/0/all/0/1&quot;&gt;Md Imran Hossen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chilukoti_S/0/1/0/all/0/1&quot;&gt;Sai Venkatesh Chilukoti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shan_L/0/1/0/all/0/1&quot;&gt;Liqun Shan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tida_V/0/1/0/all/0/1&quot;&gt;Vijay Srinivas Tida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hei_X/0/1/0/all/0/1&quot;&gt;Xiali Hei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00974">
<title>Downstream Task-Oriented Generative Model Selections on Synthetic Data Training for Fraud Detection Models. (arXiv:2401.00974v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00974</link>
<description rdf:parseType="Literal">&lt;p&gt;Devising procedures for downstream task-oriented generative model selections
is an unresolved problem of practical importance. Existing studies focused on
the utility of a single family of generative models. They provided limited
insights on how synthetic data practitioners select the best family generative
models for synthetic training tasks given a specific combination of machine
learning model class and performance metric. In this paper, we approach the
downstream task-oriented generative model selections problem in the case of
training fraud detection models and investigate the best practice given
different combinations of model interpretability and model performance
constraints. Our investigation supports that, while both Neural
Network(NN)-based and Bayesian Network(BN)-based generative models are both
good to complete synthetic training task under loose model interpretability
constrain, the BN-based generative models is better than NN-based when
synthetic training fraud detection model under strict model interpretability
constrain. Our results provides practical guidance for machine learning
practitioner who is interested in replacing their training dataset from real to
synthetic, and shed lights on more general downstream task-oriented generative
model selection problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yinan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chi-Hua Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potluru_V/0/1/0/all/0/1&quot;&gt;Vamsi K. Potluru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balch_T/0/1/0/all/0/1&quot;&gt;Tucker Balch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1&quot;&gt;Guang Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00981">
<title>Machine Learning Classification of Alzheimer&apos;s Disease Stages Using Cerebrospinal Fluid Biomarkers Alone. (arXiv:2401.00981v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.00981</link>
<description rdf:parseType="Literal">&lt;p&gt;Early diagnosis of Alzheimer&apos;s disease is a challenge because the existing
methodologies do not identify the patients in their preclinical stage, which
can last up to a decade prior to the onset of clinical symptoms. Several
research studies demonstrate the potential of cerebrospinal fluid biomarkers,
amyloid beta 1-42, T-tau, and P-tau, in early diagnosis of Alzheimer&apos;s disease
stages. In this work, we used machine learning models to classify different
stages of Alzheimer&apos;s disease based on the cerebrospinal fluid biomarker levels
alone. An electronic health record of patients from the National Alzheimer&apos;s
Coordinating Centre database was analyzed and the patients were subdivided
based on mini-mental state scores and clinical dementia ratings. Statistical
and correlation analyses were performed to identify significant differences
between the Alzheimer&apos;s stages. Afterward, machine learning classifiers
including K-Nearest Neighbors, Ensemble Boosted Tree, Ensemble Bagged Tree,
Support Vector Machine, Logistic Regression, and Naive Bayes classifiers were
employed to classify the Alzheimer&apos;s disease stages. The results demonstrate
that Ensemble Boosted Tree (84.4%) and Logistic Regression (73.4%) provide the
highest accuracy for binary classification, while Ensemble Bagged Tree (75.4%)
demonstrates better accuracy for multiclassification. The findings from this
research are expected to help clinicians in making an informed decision
regarding the early diagnosis of Alzheimer&apos;s from the cerebrospinal fluid
biomarkers alone, monitoring of the disease progression, and implementation of
appropriate intervention measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_V/0/1/0/all/0/1&quot;&gt;Vivek Kumar Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Indic_P/0/1/0/all/0/1&quot;&gt;Premananda Indic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabassum_S/0/1/0/all/0/1&quot;&gt;Shawana Tabassum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01004">
<title>Predicting the activity of chemical compounds based on machine learning approaches. (arXiv:2401.01004v1 [q-bio.BM])</title>
<link>http://arxiv.org/abs/2401.01004</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploring methods and techniques of machine learning (ML) to address specific
challenges in various fields is essential. In this work, we tackle a problem in
the domain of Cheminformatics; that is, providing a suitable solution to aid in
predicting the activity of a chemical compound to the best extent possible. To
address the problem at hand, this study conducts experiments on 100 different
combinations of existing techniques. These solutions are then selected based on
a set of criteria that includes the G-means, F1-score, and AUC metrics. The
results have been tested on a dataset of about 10,000 chemical compounds from
PubChem that have been classified according to their activity
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tu_D/0/1/0/all/0/1&quot;&gt;Do Hoang Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lang_T/0/1/0/all/0/1&quot;&gt;Tran Van Lang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Xuyen_P/0/1/0/all/0/1&quot;&gt;Pham Cong Xuyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Long_L/0/1/0/all/0/1&quot;&gt;Le Mau Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01010">
<title>Unsupervised Continual Anomaly Detection with Contrastively-learned Prompt. (arXiv:2401.01010v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.01010</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised Anomaly Detection (UAD) with incremental training is crucial in
industrial manufacturing, as unpredictable defects make obtaining sufficient
labeled data infeasible. However, continual learning methods primarily rely on
supervised annotations, while the application in UAD is limited due to the
absence of supervision. Current UAD methods train separate models for different
classes sequentially, leading to catastrophic forgetting and a heavy
computational burden. To address this issue, we introduce a novel Unsupervised
Continual Anomaly Detection framework called UCAD, which equips the UAD with
continual learning capability through contrastively-learned prompts. In the
proposed UCAD, we design a Continual Prompting Module (CPM) by utilizing a
concise key-prompt-knowledge memory bank to guide task-invariant `anomaly&apos;
model predictions using task-specific `normal&apos; knowledge. Moreover,
Structure-based Contrastive Learning (SCL) is designed with the Segment
Anything Model (SAM) to improve prompt learning and anomaly segmentation
results. Specifically, by treating SAM&apos;s masks as structure, we draw features
within the same mask closer and push others apart for general feature
representations. We conduct comprehensive experiments and set the benchmark on
unsupervised continual anomaly detection and segmentation, demonstrating that
our method is significantly better than anomaly detection methods, even with
rehearsal training. The code will be available at
https://github.com/shirowalker/UCAD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiaqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1&quot;&gt;Kai Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_Q/0/1/0/all/0/1&quot;&gt;Qiang Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Ying Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1&quot;&gt;Bin-Bin Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jinbao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chengjie Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1&quot;&gt;Feng Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01013">
<title>Boosting Transformer&apos;s Robustness and Efficacy in PPG Signal Artifact Detection with Self-Supervised Learning. (arXiv:2401.01013v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01013</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent research at CHU Sainte Justine&apos;s Pediatric Critical Care Unit (PICU)
has revealed that traditional machine learning methods, such as semi-supervised
label propagation and K-nearest neighbors, outperform Transformer-based models
in artifact detection from PPG signals, mainly when data is limited. This study
addresses the underutilization of abundant unlabeled data by employing
self-supervised learning (SSL) to extract latent features from these data,
followed by fine-tuning on labeled data. Our experiments demonstrate that SSL
significantly enhances the Transformer model&apos;s ability to learn
representations, improving its robustness in artifact classification tasks.
Among various SSL techniques, including masking, contrastive learning, and DINO
(self-distillation with no labels)-contrastive learning exhibited the most
stable and superior performance in small PPG datasets. Further, we delve into
optimizing contrastive loss functions, which are crucial for contrastive SSL.
Inspired by InfoNCE, we introduce a novel contrastive loss function that
facilitates smoother training and better convergence, thereby enhancing
performance in artifact classification. In summary, this study establishes the
efficacy of SSL in leveraging unlabeled data, particularly in enhancing the
capabilities of the Transformer model. This approach holds promise for broader
applications in PICU environments, where annotated data is often limited.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Thanh-Dung Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01021">
<title>Class Relevance Learning For Out-of-distribution Detection. (arXiv:2401.01021v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.01021</link>
<description rdf:parseType="Literal">&lt;p&gt;Image classification plays a pivotal role across diverse applications, yet
challenges persist when models are deployed in real-world scenarios. Notably,
these models falter in detecting unfamiliar classes that were not incorporated
during classifier training, a formidable hurdle for safe and effective
real-world model deployment, commonly known as out-of-distribution (OOD)
detection. While existing techniques, like max logits, aim to leverage logits
for OOD identification, they often disregard the intricate interclass
relationships that underlie effective detection. This paper presents an
innovative class relevance learning method tailored for OOD detection. Our
method establishes a comprehensive class relevance learning framework,
strategically harnessing interclass relationships within the OOD pipeline. This
framework significantly augments OOD detection capabilities. Extensive
experimentation on diverse datasets, encompassing generic image classification
datasets (Near OOD and Far OOD datasets), demonstrates the superiority of our
method over state-of-the-art alternatives for OOD detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_B/0/1/0/all/0/1&quot;&gt;Butian Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1&quot;&gt;Liguang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_T/0/1/0/all/0/1&quot;&gt;Tin Lun Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yangsheng Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01023">
<title>CautionSuicide: A Deep Learning Based Approach for Detecting Suicidal Ideation in Real Time Chatbot Conversation. (arXiv:2401.01023v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2401.01023</link>
<description rdf:parseType="Literal">&lt;p&gt;Suicide is recognized as one of the most serious concerns in the modern
society. Suicide causes tragedy that affects countries, communities, and
families. There are many factors that lead to suicidal ideations. Early
detection of suicidal ideations can help to prevent suicide occurrence by
providing the victim with the required professional support, especially when
the victim does not recognize the danger of having suicidal ideations. As
technology usage has increased, people share and express their ideations
digitally via social media, chatbots, and other digital platforms. In this
paper, we proposed a novel, simple deep learning-based model to detect suicidal
ideations in digital content, mainly focusing on chatbots as the primary data
source. In addition, we provide a framework that employs the proposed suicide
detection integration with a chatbot-based support system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elsayed_N/0/1/0/all/0/1&quot;&gt;Nelly Elsayed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ElSayed_Z/0/1/0/all/0/1&quot;&gt;Zag ElSayed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozer_M/0/1/0/all/0/1&quot;&gt;Murat Ozer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01047">
<title>Sharp Analysis of Power Iteration for Tensor PCA. (arXiv:2401.01047v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01047</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the power iteration algorithm for the tensor PCA model
introduced in Richard and Montanari (2014). Previous work studying the
properties of tensor power iteration is either limited to a constant number of
iterations, or requires a non-trivial data-independent initialization. In this
paper, we move beyond these limitations and analyze the dynamics of randomly
initialized tensor power iteration up to polynomially many steps. Our
contributions are threefold: First, we establish sharp bounds on the number of
iterations required for power method to converge to the planted signal, for a
broad range of the signal-to-noise ratios. Second, our analysis reveals that
the actual algorithmic threshold for power iteration is smaller than the one
conjectured in literature by a polylog(n) factor, where n is the ambient
dimension. Finally, we propose a simple and effective stopping criterion for
power iteration, which provably outputs a solution that is highly correlated
with the true signal. Extensive numerical experiments verify our theoretical
results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yuchen Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1&quot;&gt;Kangjie Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01048">
<title>PAC-Bayesian Domain Adaptation Bounds for Multi-view learning. (arXiv:2401.01048v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01048</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a series of new results for domain adaptation in the
multi-view learning setting. The incorporation of multiple views in the domain
adaptation was paid little attention in the previous studies. In this way, we
propose an analysis of generalization bounds with Pac-Bayesian theory to
consolidate the two paradigms, which are currently treated separately. Firstly,
building on previous work by Germain et al., we adapt the distance between
distribution proposed by Germain et al. for domain adaptation with the concept
of multi-view learning. Thus, we introduce a novel distance that is tailored
for the multi-view domain adaptation setting. Then, we give Pac-Bayesian bounds
for estimating the introduced divergence. Finally, we compare the different new
bounds with the previous studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hennequin_M/0/1/0/all/0/1&quot;&gt;Mehdi Hennequin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benabdeslem_K/0/1/0/all/0/1&quot;&gt;Khalid Benabdeslem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elghazel_H/0/1/0/all/0/1&quot;&gt;Haytham Elghazel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01054">
<title>Elastic Multi-Gradient Descent for Parallel Continual Learning. (arXiv:2401.01054v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01054</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of Continual Learning (CL) is to continuously learn from new data
streams and accomplish the corresponding tasks. Previously studied CL assumes
that data are given in sequence nose-to-tail for different tasks, thus indeed
belonging to Serial Continual Learning (SCL). This paper studies the novel
paradigm of Parallel Continual Learning (PCL) in dynamic multi-task scenarios,
where a diverse set of tasks is encountered at different time points. PCL
presents challenges due to the training of an unspecified number of tasks with
varying learning progress, leading to the difficulty of guaranteeing effective
model updates for all encountered tasks. In our previous conference work, we
focused on measuring and reducing the discrepancy among gradients in a
multi-objective optimization problem, which, however, may still contain
negative transfers in every model update. To address this issue, in the dynamic
multi-objective optimization problem, we introduce task-specific elastic
factors to adjust the descent direction towards the Pareto front. The proposed
method, called Elastic Multi-Gradient Descent (EMGD), ensures that each update
follows an appropriate Pareto descent direction, minimizing any negative impact
on previously learned tasks. To balance the training between old and new tasks,
we also propose a memory editing mechanism guided by the gradient computed
using EMGD. This editing process updates the stored data points, reducing
interference in the Pareto descent direction from previous tasks. Experiments
on public datasets validate the effectiveness of our EMGD in the PCL setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_F/0/1/0/all/0/1&quot;&gt;Fan Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1&quot;&gt;Wei Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuepan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Qing Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_F/0/1/0/all/0/1&quot;&gt;Fanhua Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_L/0/1/0/all/0/1&quot;&gt;Liang Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01056">
<title>Enhancing Automatic Modulation Recognition through Robust Global Feature Extraction. (arXiv:2401.01056v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2401.01056</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic Modulation Recognition (AMR) plays a crucial role in wireless
communication systems. Deep learning AMR strategies have achieved tremendous
success in recent years. Modulated signals exhibit long temporal dependencies,
and extracting global features is crucial in identifying modulation schemes.
Traditionally, human experts analyze patterns in constellation diagrams to
classify modulation schemes. Classical convolutional-based networks, due to
their limited receptive fields, excel at extracting local features but struggle
to capture global relationships. To address this limitation, we introduce a
novel hybrid deep framework named TLDNN, which incorporates the architectures
of the transformer and long short-term memory (LSTM). We utilize the
self-attention mechanism of the transformer to model the global correlations in
signal sequences while employing LSTM to enhance the capture of temporal
dependencies. To mitigate the impact like RF fingerprint features and channel
characteristics on model generalization, we propose data augmentation
strategies known as segment substitution (SS) to enhance the model&apos;s robustness
to modulation-related features. Experimental results on widely-used datasets
demonstrate that our method achieves state-of-the-art performance and exhibits
significant advantages in terms of complexity. Our proposed framework serves as
a foundational backbone that can be extended to different datasets. We have
verified the effectiveness of our augmentation approach in enhancing the
generalization of the models, particularly in few-shot scenarios. Code is
available at \url{https://github.com/AMR-Master/TLDNN}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Qu_Y/0/1/0/all/0/1&quot;&gt;Yunpeng Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhilin Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zeng_R/0/1/0/all/0/1&quot;&gt;Rui Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jintao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jian Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01077">
<title>Constrained Online Two-stage Stochastic Optimization: Algorithm with (and without) Predictions. (arXiv:2401.01077v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01077</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider an online two-stage stochastic optimization with long-term
constraints over a finite horizon of $T$ periods. At each period, we take the
first-stage action, observe a model parameter realization and then take the
second-stage action from a feasible set that depends both on the first-stage
decision and the model parameter. We aim to minimize the cumulative objective
value while guaranteeing that the long-term average second-stage decision
belongs to a set. We develop online algorithms for the online two-stage problem
from adversarial learning algorithms. Also, the regret bound of our algorithm
can be reduced to the regret bound of embedded adversarial learning algorithms.
Based on this framework, we obtain new results under various settings. When the
model parameters are drawn from unknown non-stationary distributions and we are
given machine-learned predictions of the distributions, we develop a new
algorithm from our framework with a regret $O(W_T+\sqrt{T})$, where $W_T$
measures the total inaccuracy of the machine-learned predictions. We then
develop another algorithm that works when no machine-learned predictions are
given and show the performances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1&quot;&gt;Piao Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jiashuo Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_G/0/1/0/all/0/1&quot;&gt;Guodong Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hao Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01083">
<title>Aircraft Landing Time Prediction with Deep Learning on Trajectory Images. (arXiv:2401.01083v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01083</link>
<description rdf:parseType="Literal">&lt;p&gt;Aircraft landing time (ALT) prediction is crucial for air traffic management,
especially for arrival aircraft sequencing on the runway. In this study, a
trajectory image-based deep learning method is proposed to predict ALTs for the
aircraft entering the research airspace that covers the Terminal Maneuvering
Area (TMA). Specifically, the trajectories of all airborne arrival aircraft
within the temporal capture window are used to generate an image with the
target aircraft trajectory labeled as red and all background aircraft
trajectory labeled as blue. The trajectory images contain various information,
including the aircraft position, speed, heading, relative distances, and
arrival traffic flows. It enables us to use state-of-the-art deep convolution
neural networks for ALT modeling. We also use real-time runway usage obtained
from the trajectory data and the external information such as aircraft types
and weather conditions as additional inputs. Moreover, a convolution neural
network (CNN) based module is designed for automatic holding-related
featurizing, which takes the trajectory images, the leading aircraft holding
status, and their time and speed gap at the research airspace boundary as its
inputs. Its output is further fed into the final end-to-end ALT prediction. The
proposed ALT prediction approach is applied to Singapore Changi Airport (ICAO
Code: WSSS) using one-month Automatic Dependent Surveillance-Broadcast (ADS-B)
data from November 1 to November 30, 2022. Experimental results show that by
integrating the holding featurization, we can reduce the mean absolute error
(MAE) from 82.23 seconds to 43.96 seconds, and achieve an average accuracy of
96.1\%, with 79.4\% of the predictions errors being less than 60 seconds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Liping Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Sheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yicheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1&quot;&gt;Yifang Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01084">
<title>Global Convergence of Natural Policy Gradient with Hessian-aided Momentum Variance Reduction. (arXiv:2401.01084v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01084</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural policy gradient (NPG) and its variants are widely-used policy search
methods in reinforcement learning. Inspired by prior work, a new NPG variant
coined NPG-HM is developed in this paper, which utilizes the Hessian-aided
momentum technique for variance reduction, while the sub-problem is solved via
the stochastic gradient descent method. It is shown that NPG-HM can achieve the
global last iterate $\epsilon$-optimality with a sample complexity of
$\mathcal{O}(\epsilon^{-2})$, which is the best known result for natural policy
gradient type methods under the generic Fisher non-degenerate policy
parameterizations. The convergence analysis is built upon a relaxed weak
gradient dominance property tailored for NPG under the compatible function
approximation framework, as well as a neat way to decompose the error when
handling the sub-problem. Moreover, numerical experiments on Mujoco-based
environments demonstrate the superior performance of NPG-HM over other
state-of-the-art policy gradient methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jie Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_K/0/1/0/all/0/1&quot;&gt;Ke Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jinchi Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01085">
<title>Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control. (arXiv:2401.01085v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.01085</link>
<description rdf:parseType="Literal">&lt;p&gt;Revolutionized by the transformer architecture, natural language processing
(NLP) has received unprecedented attention. While advancements in NLP models
have led to extensive research into their backdoor vulnerabilities, the
potential for these advancements to introduce new backdoor threats remains
unexplored. This paper proposes Imperio, which harnesses the language
understanding capabilities of NLP models to enrich backdoor attacks. Imperio
provides a new model control experience. It empowers the adversary to control
the victim model with arbitrary output through language-guided instructions.
This is achieved using a language model to fuel a conditional trigger
generator, with optimizations designed to extend its language understanding
capabilities to backdoor instruction interpretation and execution. Our
experiments across three datasets, five attacks, and nine defenses confirm
Imperio&apos;s effectiveness. It can produce contextually adaptive triggers from
text descriptions and control the victim model with desired outputs, even in
scenarios not encountered during training. The attack maintains a high success
rate across complex datasets without compromising the accuracy of clean inputs
and also exhibits resilience against representative defenses. The source code
is available at \url{https://khchow.com/Imperio}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chow_K/0/1/0/all/0/1&quot;&gt;Ka-Ho Chow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1&quot;&gt;Wenqi Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1&quot;&gt;Lei Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01099">
<title>Efficient Parallel Audio Generation using Group Masked Language Modeling. (arXiv:2401.01099v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2401.01099</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a fast and high-quality codec language model for parallel audio
generation. While SoundStorm, a state-of-the-art parallel audio generation
model, accelerates inference speed compared to autoregressive models, it still
suffers from slow inference due to iterative sampling. To resolve this problem,
we propose Group-Masked Language Modeling~(G-MLM) and Group Iterative Parallel
Decoding~(G-IPD) for efficient parallel audio generation. Both the training and
sampling schemes enable the model to synthesize high-quality audio with a small
number of iterations by effectively modeling the group-wise conditional
dependencies. In addition, our model employs a cross-attention-based
architecture to capture the speaker style of the prompt voice and improves
computational efficiency. Experimental results demonstrate that our proposed
model outperforms the baselines in prompt-based audio generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jeong_M/0/1/0/all/0/1&quot;&gt;Myeonghun Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Minchan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joun Yeop Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_N/0/1/0/all/0/1&quot;&gt;Nam Soo Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01100">
<title>Scalable manifold learning by uniform landmark sampling and constrained locally linear embedding. (arXiv:2401.01100v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01100</link>
<description rdf:parseType="Literal">&lt;p&gt;As a pivotal approach in machine learning and data science, manifold learning
aims to uncover the intrinsic low-dimensional structure within complex
nonlinear manifolds in high-dimensional space. By exploiting the manifold
hypothesis, various techniques for nonlinear dimension reduction have been
developed to facilitate visualization, classification, clustering, and gaining
key insights. Although existing manifold learning methods have achieved
remarkable successes, they still suffer from extensive distortions incurred in
the global structure, which hinders the understanding of underlying patterns.
Scalability issues also limit their applicability for handling large-scale
data. Here, we propose a scalable manifold learning (scML) method that can
manipulate large-scale and high-dimensional data in an efficient manner. It
starts by seeking a set of landmarks to construct the low-dimensional skeleton
of the entire data and then incorporates the non-landmarks into the landmark
space based on the constrained locally linear embedding (CLLE). We empirically
validated the effectiveness of scML on synthetic datasets and real-world
benchmarks of different types, and applied it to analyze the single-cell
transcriptomics and detect anomalies in electrocardiogram (ECG) signals. scML
scales well with increasing data sizes and exhibits promising performance in
preserving the global structure. The experiments demonstrate notable robustness
in embedding quality as the sample rate decreases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1&quot;&gt;Dehua Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gui_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Gui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1&quot;&gt;Wenzhang Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Huayi Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01119">
<title>Utilizing Autoregressive Networks for Full Lifecycle Data Generation of Rolling Bearings for RUL Prediction. (arXiv:2401.01119v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01119</link>
<description rdf:parseType="Literal">&lt;p&gt;The prediction of rolling bearing lifespan is of significant importance in
industrial production. However, the scarcity of high-quality, full lifecycle
data has been a major constraint in achieving precise predictions. To address
this challenge, this paper introduces the CVGAN model, a novel framework
capable of generating one-dimensional vibration signals in both horizontal and
vertical directions, conditioned on historical vibration data and remaining
useful life. In addition, we propose an autoregressive generation method that
can iteratively utilize previously generated vibration information to guide the
generation of current signals. The effectiveness of the CVGAN model is
validated through experiments conducted on the PHM 2012 dataset. Our findings
demonstrate that the CVGAN model, in terms of both MMD and FID metrics,
outperforms many advanced methods in both autoregressive and non-autoregressive
generation modes. Notably, training using the full lifecycle data generated by
the CVGAN model significantly improves the performance of the predictive model.
This result highlights the effectiveness of the data generated by CVGans in
enhancing the predictive power of these models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junliang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qinghua Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1&quot;&gt;Guanhua Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1&quot;&gt;Guoxi Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01124">
<title>Explainable Adaptive Tree-based Model Selection for Time Series Forecasting. (arXiv:2401.01124v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01124</link>
<description rdf:parseType="Literal">&lt;p&gt;Tree-based models have been successfully applied to a wide variety of tasks,
including time series forecasting. They are increasingly in demand and widely
accepted because of their comparatively high level of interpretability.
However, many of them suffer from the overfitting problem, which limits their
application in real-world decision-making. This problem becomes even more
severe in online-forecasting settings where time series observations are
incrementally acquired, and the distributions from which they are drawn may
keep changing over time. In this context, we propose a novel method for the
online selection of tree-based models using the TreeSHAP explainability method
in the task of time series forecasting. We start with an arbitrary set of
different tree-based models. Then, we outline a performance-based ranking with
a coherent design to make TreeSHAP able to specialize the tree-based
forecasters across different regions in the input time series. In this
framework, adequate model selection is performed online, adaptively following
drift detection in the time series. In addition, explainability is supported on
three levels, namely online input importance, model selection, and model output
explanation. An extensive empirical study on various real-world datasets
demonstrates that our method achieves excellent or on-par results in comparison
to the state-of-the-art approaches as well as several baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jakobs_M/0/1/0/all/0/1&quot;&gt;Matthias Jakobs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saadallah_A/0/1/0/all/0/1&quot;&gt;Amal Saadallah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01145">
<title>HAAQI-Net: A non-intrusive neural music quality assessment model for hearing aids. (arXiv:2401.01145v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2401.01145</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces HAAQI-Net, a non-intrusive deep learning model for
music quality assessment tailored to hearing aid users. In contrast to
traditional methods like the Hearing Aid Audio Quality Index (HAAQI), HAAQI-Net
utilizes a Bidirectional Long Short-Term Memory (BLSTM) with attention. It
takes an assessed music sample and a hearing loss pattern as input, generating
a predicted HAAQI score. The model employs the pre-trained Bidirectional
Encoder representation from Audio Transformers (BEATs) for acoustic feature
extraction. Comparing predicted scores with ground truth, HAAQI-Net achieves a
Longitudinal Concordance Correlation (LCC) of 0.9257, Spearman&apos;s Rank
Correlation Coefficient (SRCC) of 0.9394, and Mean Squared Error (MSE) of
0.0080. Notably, this high performance comes with a substantial reduction in
inference time: from 62.52 seconds (by HAAQI) to 2.71 seconds (by HAAQI-Net),
serving as an efficient music quality assessment model for hearing aid users.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wisnu_D/0/1/0/all/0/1&quot;&gt;Dyah A. M. G. Wisnu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pratiwi_E/0/1/0/all/0/1&quot;&gt;Epri Pratiwi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rini_S/0/1/0/all/0/1&quot;&gt;Stefano Rini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zezario_R/0/1/0/all/0/1&quot;&gt;Ryandhimas E. Zezario&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hsin-Min Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1&quot;&gt;Yu Tsao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01148">
<title>PAC-Bayes-Chernoff bounds for unbounded losses. (arXiv:2401.01148v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2401.01148</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new high-probability PAC-Bayes oracle bound for unbounded
losses. This result can be understood as a PAC-Bayes version of the Chernoff
bound. The proof technique relies on uniformly bounding the tail of certain
random variable based on the Cram\&apos;er transform of the loss. We highlight two
applications of our main result. First, we show that our bound solves the open
problem of optimizing the free parameter on many PAC-Bayes bounds. Finally, we
show that our approach allows working with flexible assumptions on the loss
function, resulting in novel bounds that generalize previous ones and can be
minimized to obtain Gibbs-like posteriors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Casado_I/0/1/0/all/0/1&quot;&gt;Ioar Casado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ortega_L/0/1/0/all/0/1&quot;&gt;Luis A. Ortega&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Masegosa_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s R. Masegosa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perez_A/0/1/0/all/0/1&quot;&gt;Aritz P&amp;#xe9;rez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01155">
<title>Deep Learning-Based Detection for Marker Codes over Insertion and Deletion Channels. (arXiv:2401.01155v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2401.01155</link>
<description rdf:parseType="Literal">&lt;p&gt;Marker code is an effective coding scheme to protect data from insertions and
deletions. It has potential applications in future storage systems, such as DNA
storage and racetrack memory. When decoding marker codes, perfect channel state
information (CSI), i.e., insertion and deletion probabilities, are required to
detect insertion and deletion errors. Sometimes, the perfect CSI is not easy to
obtain or the accurate channel model is unknown. Therefore, it is deserved to
develop detecting algorithms for marker code without the knowledge of perfect
CSI. In this paper, we propose two CSI-agnostic detecting algorithms for marker
code based on deep learning. The first one is a model-driven deep learning
method, which deep unfolds the original iterative detecting algorithm of marker
code. In this method, CSI become weights in neural networks and these weights
can be learned from training data. The second one is a data-driven method which
is an end-to-end system based on the deep bidirectional gated recurrent unit
network. Simulation results show that error performances of the proposed
methods are significantly better than that of the original detection algorithm
with CSI uncertainty. Furthermore, the proposed data-driven method exhibits
better error performances than other methods for unknown channel models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1&quot;&gt;Guochen Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_X/0/1/0/all/0/1&quot;&gt;Xiaopeng Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1&quot;&gt;Jianjun Mu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1&quot;&gt;Hui Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yaming Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01160">
<title>Train-Free Segmentation in MRI with Cubical Persistent Homology. (arXiv:2401.01160v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2401.01160</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a new general method for segmentation in MRI scans using
Topological Data Analysis (TDA), offering several advantages over traditional
machine learning approaches. It works in three steps, first identifying the
whole object to segment via automatic thresholding, then detecting a
distinctive subset whose topology is known in advance, and finally deducing the
various components of the segmentation. Although convoking classical ideas of
TDA, such an algorithm has never been proposed separately from deep learning
methods. To achieve this, our approach takes into account, in addition to the
homology of the image, the localization of representative cycles, a piece of
information that seems never to have been exploited in this context. In
particular, it offers the ability to perform segmentation without the need for
large annotated data sets. TDA also provides a more interpretable and stable
framework for segmentation by explicitly mapping topological features to
segmentation components. By adapting the geometric object to be detected, the
algorithm can be adjusted to a wide range of data segmentation challenges. We
carefully study the examples of glioblastoma segmentation in brain MRI, where a
sphere is to be detected, as well as myocardium in cardiac MRI, involving a
cylinder, and cortical plate detection in fetal brain MRI, whose 2D slices are
circles. We compare our method to state-of-the-art algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Francois_A/0/1/0/all/0/1&quot;&gt;Anton Fran&amp;#xe7;ois&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tinarrage_R/0/1/0/all/0/1&quot;&gt;Rapha&amp;#xeb;l Tinarrage&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01165">
<title>Reinforcement Learning for SAR View Angle Inversion with Differentiable SAR Renderer. (arXiv:2401.01165v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01165</link>
<description rdf:parseType="Literal">&lt;p&gt;The electromagnetic inverse problem has long been a research hotspot. This
study aims to reverse radar view angles in synthetic aperture radar (SAR)
images given a target model. Nonetheless, the scarcity of SAR data, combined
with the intricate background interference and imaging mechanisms, limit the
applications of existing learning-based approaches. To address these
challenges, we propose an interactive deep reinforcement learning (DRL)
framework, where an electromagnetic simulator named differentiable SAR render
(DSR) is embedded to facilitate the interaction between the agent and the
environment, simulating a human-like process of angle prediction. Specifically,
DSR generates SAR images at arbitrary view angles in real-time. And the
differences in sequential and semantic aspects between the view
angle-corresponding images are leveraged to construct the state space in DRL,
which effectively suppress the complex background interference, enhance the
sensitivity to temporal variations, and improve the capability to capture
fine-grained information. Additionally, in order to maintain the stability and
convergence of our method, a series of reward mechanisms, such as memory
difference, smoothing and boundary penalty, are utilized to form the final
reward function. Extensive experiments performed on both simulated and real
datasets demonstrate the effectiveness and robustness of our proposed method.
When utilized in the cross-domain area, the proposed method greatly mitigates
inconsistency between simulated and real domains, outperforming reference
methods significantly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanni Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1&quot;&gt;Hecheng Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1&quot;&gt;Shilei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Huiping Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1&quot;&gt;Feng Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01168">
<title>FedQV: Leveraging Quadratic Voting in Federated Learning. (arXiv:2401.01168v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2401.01168</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) permits different parties to collaboratively train a
global model without disclosing their respective local labels. A crucial step
of FL, that of aggregating local models to produce the global one, shares many
similarities with public decision-making, and elections in particular. In that
context, a major weakness of FL, namely its vulnerability to poisoning attacks,
can be interpreted as a consequence of the one person one vote (henceforth
1p1v) principle underpinning most contemporary aggregation rules. In this
paper, we propose FedQV, a novel aggregation algorithm built upon the quadratic
voting scheme, recently proposed as a better alternative to 1p1v-based
elections. Our theoretical analysis establishes that FedQV is a truthful
mechanism in which bidding according to one&apos;s true valuation is a dominant
strategy that achieves a convergence rate that matches those of
state-of-the-art methods. Furthermore, our empirical analysis using multiple
real-world datasets validates the superior performance of FedQV against
poisoning attacks. It also shows that combining FedQV with unequal voting
``budgets&apos;&apos; according to a reputation score increases its performance benefits
even further. Finally, we show that FedQV can be easily combined with
Byzantine-robust privacy-preserving mechanisms to enhance its robustness
against both poisoning and privacy attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1&quot;&gt;Tianyue Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laoutaris_N/0/1/0/all/0/1&quot;&gt;Nikolaos Laoutaris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01172">
<title>Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults. (arXiv:2401.01172v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01172</link>
<description rdf:parseType="Literal">&lt;p&gt;Diagnosis of bearing faults is paramount to reducing maintenance costs and
operational breakdowns. Bearing faults are primary contributors to machine
vibrations, and analyzing their signal morphology offers insights into their
health status. Unfortunately, existing approaches are optimized for controlled
environments, neglecting realistic conditions such as time-varying rotational
speeds and the vibration&apos;s non-stationary nature. This paper presents a fusion
of time-frequency analysis and deep learning techniques to diagnose bearing
faults under time-varying speeds and varying noise levels. First, we formulate
the bearing fault-induced vibrations and discuss the link between their
non-stationarity and the bearing&apos;s inherent and operational parameters. We also
elucidate quadratic time-frequency distributions and validate their
effectiveness in resolving distinctive dynamic patterns associated with
different bearing faults. Based on this, we design a time-frequency
convolutional neural network (TF-CNN) to diagnose various faults in
rolling-element bearings. Our experimental findings undeniably demonstrate the
superior performance of TF-CNN in comparison to recently developed techniques.
They also assert its versatility in capturing fault-relevant non-stationary
features that couple with speed changes and show its exceptional resilience to
noise, consistently surpassing competing methods across various signal-to-noise
ratios and performance metrics. Altogether, the TF-CNN achieves substantial
accuracy improvements up to 15%, in severe noise conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Sad_M/0/1/0/all/0/1&quot;&gt;Mohammad Al-Sa&amp;#x27;d&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jalonen_T/0/1/0/all/0/1&quot;&gt;Tuomas Jalonen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiranyaz_S/0/1/0/all/0/1&quot;&gt;Serkan Kiranyaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1&quot;&gt;Moncef Gabbouj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01176">
<title>Fundamental Limitation of Semantic Communications: Neural Estimation for Rate-Distortion. (arXiv:2401.01176v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2401.01176</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the fundamental limit of semantic communications over the
discrete memoryless channel. We consider the scenario to send a semantic source
consisting of an observation state and its corresponding semantic state, both
of which are recovered at the receiver. To derive the performance limitation,
we adopt the semantic rate-distortion function (SRDF) to study the relationship
among the minimum compression rate, observation distortion, semantic
distortion, and channel capacity. For the case with unknown semantic source
distribution, while only a set of the source samples is available, we propose a
neural-network-based method by leveraging the generative networks to learn the
semantic source distribution. Furthermore, for a special case where the
semantic state is a deterministic function of the observation, we design a
cascade neural network to estimate the SRDF. For the case with perfectly known
semantic source distribution, we propose a general Blahut-Arimoto algorithm to
effectively compute the SRDF. Finally, experimental results validate our
proposed algorithms for the scenarios with ideal Gaussian semantic source and
some practical datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Dongxu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jianhao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chuan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1&quot;&gt;Xiaoqi Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Han Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Ping Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01179">
<title>Freeze the backbones: A Parameter-Efficient Contrastive Approach to Robust Medical Vision-Language Pre-training. (arXiv:2401.01179v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.01179</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern healthcare often utilises radiographic images alongside textual
reports for diagnostics, encouraging the use of Vision-Language Self-Supervised
Learning (VL-SSL) with large pre-trained models to learn versatile medical
vision representations. However, most existing VL-SSL frameworks are trained
end-to-end, which is computation-heavy and can lose vital prior information
embedded in pre-trained encoders. To address both issues, we introduce the
backbone-agnostic Adaptor framework, which preserves medical knowledge in
pre-trained image and text encoders by keeping them frozen, and employs a
lightweight Adaptor module for cross-modal learning. Experiments on medical
image classification and segmentation tasks across three datasets reveal that
our framework delivers competitive performance while cutting trainable
parameters by over 90% compared to current pre-training approaches. Notably,
when fine-tuned with just 1% of data, Adaptor outperforms several
Transformer-based methods trained on full datasets in medical image
segmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1&quot;&gt;Jiuming Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Che Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Sibo Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yike Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arcucci_R/0/1/0/all/0/1&quot;&gt;Rossella Arcucci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01192">
<title>Deep-ELA: Deep Exploratory Landscape Analysis with Self-Supervised Pretrained Transformers for Single- and Multi-Objective Continuous Optimization Problems. (arXiv:2401.01192v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01192</link>
<description rdf:parseType="Literal">&lt;p&gt;In many recent works, the potential of Exploratory Landscape Analysis (ELA)
features to numerically characterize, in particular, single-objective
continuous optimization problems has been demonstrated. These numerical
features provide the input for all kinds of machine learning tasks on
continuous optimization problems, ranging, i.a., from High-level Property
Prediction to Automated Algorithm Selection and Automated Algorithm
Configuration. Without ELA features, analyzing and understanding the
characteristics of single-objective continuous optimization problems would be
impossible.
&lt;/p&gt;
&lt;p&gt;Yet, despite their undisputed usefulness, ELA features suffer from several
drawbacks. These include, in particular, (1.) a strong correlation between
multiple features, as well as (2.) its very limited applicability to
multi-objective continuous optimization problems. As a remedy, recent works
proposed deep learning-based approaches as alternatives to ELA. In these works,
e.g., point-cloud transformers were used to characterize an optimization
problem&apos;s fitness landscape. However, these approaches require a large amount
of labeled training data.
&lt;/p&gt;
&lt;p&gt;Within this work, we propose a hybrid approach, Deep-ELA, which combines (the
benefits of) deep learning and ELA features. Specifically, we pre-trained four
transformers on millions of randomly generated optimization problems to learn
deep representations of the landscapes of continuous single- and
multi-objective optimization problems. Our proposed framework can either be
used out-of-the-box for analyzing single- and multi-objective continuous
optimization problems, or subsequently fine-tuned to various tasks focussing on
algorithm behavior and problem understanding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seiler_M/0/1/0/all/0/1&quot;&gt;Moritz Vinzent Seiler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kerschke_P/0/1/0/all/0/1&quot;&gt;Pascal Kerschke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trautmann_H/0/1/0/all/0/1&quot;&gt;Heike Trautmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01199">
<title>JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example. (arXiv:2401.01199v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01199</link>
<description rdf:parseType="Literal">&lt;p&gt;Most of the approaches proposed so far to craft targeted adversarial examples
against Deep Learning classifiers are highly suboptimal and typically rely on
increasing the likelihood of the target class, thus implicitly focusing on
one-hot encoding settings. In this paper, we propose a more general,
theoretically sound, targeted attack that resorts to the minimization of a
Jacobian-induced MAhalanobis distance (JMA) term, taking into account the
effort (in the input space) required to move the latent space representation of
the input sample in a given direction. The minimization is solved by exploiting
the Wolfe duality theorem, reducing the problem to the solution of a
Non-Negative Least Square (NNLS) problem. The proposed algorithm provides an
optimal solution to a linearized version of the adversarial example problem
originally introduced by Szegedy et al. \cite{szegedy2013intriguing}. The
experiments we carried out confirm the generality of the proposed attack which
is proven to be effective under a wide variety of output encoding schemes.
Noticeably, the JMA attack is also effective in a multi-label classification
scenario, being capable to induce a targeted modification of up to half the
labels in a complex multilabel classification scenario with 20 labels, a
capability that is out of reach of all the attacks proposed so far. As a
further advantage, the JMA attack usually requires very few iterations, thus
resulting more efficient than existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tondi_B/0/1/0/all/0/1&quot;&gt;Benedetta Tondi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1&quot;&gt;Wei Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barni_M/0/1/0/all/0/1&quot;&gt;Mauro Barni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01201">
<title>Whole-examination AI estimation of fetal biometrics from 20-week ultrasound scans. (arXiv:2401.01201v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2401.01201</link>
<description rdf:parseType="Literal">&lt;p&gt;The current approach to fetal anomaly screening is based on biometric
measurements derived from individually selected ultrasound images. In this
paper, we introduce a paradigm shift that attains human-level performance in
biometric measurement by aggregating automatically extracted biometrics from
every frame across an entire scan, with no need for operator intervention. We
use a convolutional neural network to classify each frame of an ultrasound
video recording. We then measure fetal biometrics in every frame where
appropriate anatomy is visible. We use a Bayesian method to estimate the true
value of each biometric from a large number of measurements and
probabilistically reject outliers. We performed a retrospective experiment on
1457 recordings (comprising 48 million frames) of 20-week ultrasound scans,
estimated fetal biometrics in those scans and compared our estimates to the
measurements sonographers took during the scan. Our method achieves human-level
performance in estimating fetal biometrics and estimates well-calibrated
credible intervals in which the true biometric value is expected to lie.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venturini_L/0/1/0/all/0/1&quot;&gt;Lorenzo Venturini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budd_S/0/1/0/all/0/1&quot;&gt;Samuel Budd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farruggia_A/0/1/0/all/0/1&quot;&gt;Alfonso Farruggia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wright_R/0/1/0/all/0/1&quot;&gt;Robert Wright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matthew_J/0/1/0/all/0/1&quot;&gt;Jacqueline Matthew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Day_T/0/1/0/all/0/1&quot;&gt;Thomas G. Day&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kainz_B/0/1/0/all/0/1&quot;&gt;Bernhard Kainz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razavi_R/0/1/0/all/0/1&quot;&gt;Reza Razavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajnal_J/0/1/0/all/0/1&quot;&gt;Jo V. Hajnal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01218">
<title>Zero-Shot Position Debiasing for Large Language Models. (arXiv:2401.01218v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.01218</link>
<description rdf:parseType="Literal">&lt;p&gt;Fine-tuning has been demonstrated to be an effective method to improve the
domain performance of large language models (LLMs). However, LLMs might fit the
dataset bias and shortcuts for prediction, leading to poor generation
performance. Experimental result shows that LLMs are prone to exhibit position
bias, i.e., leveraging information positioned at the beginning or end, or
specific positional cues within the input. Existing works on mitigating
position bias require external bias knowledge or annotated non-biased samples,
which is unpractical in reality. In this work, we propose a zero-shot position
debiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages
unsupervised responses from pre-trained LLMs for debiasing, thus without any
external knowledge or datasets. To improve the quality of unsupervised
responses, we propose a master-slave alignment (MSA) module to prune these
responses. Experiments on eight datasets and five tasks show that ZOE
consistently outperforms existing methods in mitigating four types of position
biases. Besides, ZOE achieves this by sacrificing only a small performance on
biased samples, which is simple and effective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhongkun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mengqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zhaochun Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhumin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1&quot;&gt;Pengjie Ren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01232">
<title>Motif-aware Riemannian Graph Neural Network with Generative-Contrastive Learning. (arXiv:2401.01232v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01232</link>
<description rdf:parseType="Literal">&lt;p&gt;Graphs are typical non-Euclidean data of complex structures. In recent years,
Riemannian graph representation learning has emerged as an exciting alternative
to Euclidean ones. However, Riemannian methods are still in an early stage:
most of them present a single curvature (radius) regardless of structural
complexity, suffer from numerical instability due to the
exponential/logarithmic map, and lack the ability to capture motif regularity.
In light of the issues above, we propose the problem of \emph{Motif-aware
Riemannian Graph Representation Learning}, seeking a numerically stable encoder
to capture motif regularity in a diverse-curvature manifold without labels. To
this end, we present a novel Motif-aware Riemannian model with
Generative-Contrastive learning (MotifRGC), which conducts a minmax game in
Riemannian manifold in a self-supervised manner. First, we propose a new type
of Riemannian GCN (D-GCN), in which we construct a diverse-curvature manifold
by a product layer with the diversified factor, and replace the
exponential/logarithmic map by a stable kernel layer. Second, we introduce a
motif-aware Riemannian generative-contrastive learning to capture motif
regularity in the constructed manifold and learn motif-aware node
representation without external labels. Empirical results show the superiority
of MofitRGC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Li Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhenhao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zixi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Feiyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1&quot;&gt;Hao Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01233">
<title>Graph Elimination Networks. (arXiv:2401.01233v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01233</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) are widely applied across various domains, yet
they perform poorly in deep layers. Existing research typically attributes this
problem to node over-smoothing, where node representations become
indistinguishable after multiple rounds of propagation. In this paper, we delve
into the neighborhood propagation mechanism of GNNs and discover that the real
root cause of GNNs&apos; performance degradation in deep layers lies in ineffective
neighborhood feature propagation. This propagation leads to an exponential
growth of a node&apos;s current representation at every propagation step, making it
extremely challenging to capture valuable dependencies between long-distance
nodes. To address this issue, we introduce Graph Elimination Networks (GENs),
which employ a specific algorithm to eliminate redundancies during neighborhood
propagation. We demonstrate that GENs can enhance nodes&apos; perception of distant
neighborhoods and extend the depth of network propagation. Extensive
experiments show that GENs outperform the state-of-the-art methods on various
graph-level and node-level datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shuo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1&quot;&gt;Ge Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01242">
<title>Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning. (arXiv:2401.01242v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01242</link>
<description rdf:parseType="Literal">&lt;p&gt;Broadband infrastructure owners do not always know how their customers are
connected in the local networks, which are structured as rooted trees. A recent
study is able to infer the topology of a local network using discrete time
series data from the leaves of the tree (customers). In this study we propose a
contrastive approach for learning a binary event encoder from continuous time
series data. As a preliminary result, we show that our approach has some
potential in learning a valuable encoder.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasmussen_T/0/1/0/all/0/1&quot;&gt;Tobias Engelhardt Rasmussen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sorensen_S/0/1/0/all/0/1&quot;&gt;Siv S&amp;#xf8;rensen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01243">
<title>Contrastive Sequential Interaction Network Learning on Co-Evolving Riemannian Spaces. (arXiv:2401.01243v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01243</link>
<description rdf:parseType="Literal">&lt;p&gt;The sequential interaction network usually find itself in a variety of
applications, e.g., recommender system. Herein, inferring future interaction is
of fundamental importance, and previous efforts are mainly focused on the
dynamics in the classic zero-curvature Euclidean space. Despite the promising
results achieved by previous methods, a range of significant issues still
largely remains open: On the bipartite nature, is it appropriate to place user
and item nodes in one identical space regardless of their inherent difference?
On the network dynamics, instead of a fixed curvature space, will the
representation spaces evolve when new interactions arrive continuously? On the
learning paradigm, can we get rid of the label information costly to acquire?
To address the aforementioned issues, we propose a novel Contrastive model for
Sequential Interaction Network learning on Co-Evolving RiEmannian spaces,
CSINCERE. To the best of our knowledge, we are the first to introduce a couple
of co-evolving representation spaces, rather than a single or static space, and
propose a co-contrastive learning for the sequential interaction network. In
CSINCERE, we formulate a Cross-Space Aggregation for message-passing across
representation spaces of different Riemannian geometries, and design a Neural
Curvature Estimator based on Ricci curvatures for modeling the space evolvement
over time. Thereafter, we present a Reweighed Co-Contrast between the temporal
views of the sequential network, so that the couple of Riemannian spaces
interact with each other for the interaction prediction without labels.
Empirical results on 5 public datasets show the superiority of CSINCERE over
the state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Li Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Junda Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Mingsheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Feiyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S.Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01258">
<title>Towards Model-Free LQR Control over Rate-Limited Channels. (arXiv:2401.01258v1 [math.OC])</title>
<link>http://arxiv.org/abs/2401.01258</link>
<description rdf:parseType="Literal">&lt;p&gt;Given the success of model-free methods for control design in many problem
settings, it is natural to ask how things will change if realistic
communication channels are utilized for the transmission of gradients or
policies. While the resulting problem has analogies with the formulations
studied under the rubric of networked control systems, the rich literature in
that area has typically assumed that the model of the system is known. As a
step towards bridging the fields of model-free control design and networked
control systems, we ask: \textit{Is it possible to solve basic control problems
- such as the linear quadratic regulator (LQR) problem - in a model-free manner
over a rate-limited channel?} Toward answering this question, we study a
setting where a worker agent transmits quantized policy gradients (of the LQR
cost) to a server over a noiseless channel with a finite bit-rate. We propose a
new algorithm titled Adaptively Quantized Gradient Descent (\texttt{AQGD}), and
prove that above a certain finite threshold bit-rate, \texttt{AQGD} guarantees
exponentially fast convergence to the globally optimal policy, with \textit{no
deterioration of the exponent relative to the unquantized setting}. More
generally, our approach reveals the benefits of adaptive quantization in
preserving fast linear convergence rates, and, as such, may be of independent
interest to the literature on compressed optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mitra_A/0/1/0/all/0/1&quot;&gt;Aritra Mitra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ye_L/0/1/0/all/0/1&quot;&gt;Lintao Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gupta_V/0/1/0/all/0/1&quot;&gt;Vijay Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01259">
<title>Do Concept Bottleneck Models Obey Locality?. (arXiv:2401.01259v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01259</link>
<description rdf:parseType="Literal">&lt;p&gt;Concept-based learning improves a deep learning model&apos;s interpretability by
explaining its predictions via human-understandable concepts. Deep learning
models trained under this paradigm heavily rely on the assumption that neural
networks can learn to predict the presence or absence of a given concept
independently of other concepts. Recent work, however, strongly suggests that
this assumption may fail to hold in Concept Bottleneck Models (CBMs), a
quintessential family of concept-based interpretable architectures. In this
paper, we investigate whether CBMs correctly capture the degree of conditional
independence across concepts when such concepts are localised both spatially,
by having their values entirely defined by a fixed subset of features, and
semantically, by having their values correlated with only a fixed subset of
predefined concepts. To understand locality, we analyse how changes to features
outside of a concept&apos;s spatial or semantic locality impact concept predictions.
Our results suggest that even in well-defined scenarios where the presence of a
concept is localised to a fixed feature subspace, or whose semantics are
correlated to a small subset of other concepts, CBMs fail to learn this
locality. These results cast doubt upon the quality of concept representations
learnt by CBMs and strongly suggest that concept-based explanations may be
fragile to changes outside their localities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raman_N/0/1/0/all/0/1&quot;&gt;Naveen Raman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zarlenga_M/0/1/0/all/0/1&quot;&gt;Mateo Espinosa Zarlenga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heo_J/0/1/0/all/0/1&quot;&gt;Juyeon Heo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamnik_M/0/1/0/all/0/1&quot;&gt;Mateja Jamnik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01262">
<title>Fairness Certification for Natural Language Processing and Large Language Models. (arXiv:2401.01262v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.01262</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural Language Processing (NLP) plays an important role in our daily lives,
particularly due to the enormous progress of Large Language Models (LLM).
However, NLP has many fairness-critical use cases, e.g., as an expert system in
recruitment or as an LLM-based tutor in education. Since NLP is based on human
language, potentially harmful biases can diffuse into NLP systems and produce
unfair results, discriminate against minorities or generate legal issues.
Hence, it is important to develop a fairness certification for NLP approaches.
We follow a qualitative research approach towards a fairness certification for
NLP. In particular, we have reviewed a large body of literature on algorithmic
fairness, and we have conducted semi-structured expert interviews with a wide
range of experts from that area. We have systematically devised six fairness
criteria for NLP, which can be further refined into 18 sub-categories. Our
criteria offer a foundation for operationalizing and testing processes to
certify fairness, both from the perspective of the auditor and the audited
organization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freiberger_V/0/1/0/all/0/1&quot;&gt;Vincent Freiberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buchmann_E/0/1/0/all/0/1&quot;&gt;Erik Buchmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01268">
<title>$f$-Divergence Based Classification: Beyond the Use of Cross-Entropy. (arXiv:2401.01268v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01268</link>
<description rdf:parseType="Literal">&lt;p&gt;In deep learning, classification tasks are formalized as optimization
problems solved via the minimization of the cross-entropy. However, recent
advancements in the design of objective functions allow the $f$-divergence
measure to generalize the formulation of the optimization problem for
classification. With this goal in mind, we adopt a Bayesian perspective and
formulate the classification task as a maximum a posteriori probability
problem. We propose a class of objective functions based on the variational
representation of the $f$-divergence, from which we extract a list of five
posterior probability estimators leveraging well-known $f$-divergences. In
addition, driven by the challenge of improving the state-of-the-art approach,
we propose a bottom-up method that leads us to the formulation of a new
objective function (and posterior probability estimator) corresponding to a
novel $f$-divergence referred to as shifted log (SL). First, we theoretically
prove the convergence property of the posterior probability estimators. Then,
we numerically test the set of proposed objective functions in three
application scenarios: toy examples, image data sets, and signal
detection/decoding problems. The analyzed tasks demonstrate the effectiveness
of the proposed estimators and that the SL divergence achieves the highest
classification accuracy in almost all the scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Novello_N/0/1/0/all/0/1&quot;&gt;Nicola Novello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tonello_A/0/1/0/all/0/1&quot;&gt;Andrea M. Tonello&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01270">
<title>Optimal Rates of Kernel Ridge Regression under Source Condition in Large Dimensions. (arXiv:2401.01270v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01270</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the studies of neural networks (e.g.,the neural tangent kernel
theory), we perform a study on the large-dimensional behavior of kernel ridge
regression (KRR) where the sample size $n \asymp d^{\gamma}$ for some $\gamma &amp;gt;
0$. Given an RKHS $\mathcal{H}$ associated with an inner product kernel defined
on the sphere $\mathbb{S}^{d}$, we suppose that the true function $f_{\rho}^{*}
\in [\mathcal{H}]^{s}$, the interpolation space of $\mathcal{H}$ with source
condition $s&amp;gt;0$. We first determined the exact order (both upper and lower
bound) of the generalization error of kernel ridge regression for the optimally
chosen regularization parameter $\lambda$. We then further showed that when
$0&amp;lt;s\le1$, KRR is minimax optimal; and when $s&amp;gt;1$, KRR is not minimax optimal
(a.k.a. he saturation effect). Our results illustrate that the curves of rate
varying along $\gamma$ exhibit the periodic plateau behavior and the multiple
descent behavior and show how the curves evolve with $s&amp;gt;0$. Interestingly, our
work provides a unified viewpoint of several recent works on kernel regression
in the large-dimensional setting, which correspond to $s=0$ and $s=1$
respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haobo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yicheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1&quot;&gt;Weihao Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1&quot;&gt;Qian Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01273">
<title>Learning-based agricultural management in partially observable environments subject to climate variability. (arXiv:2401.01273v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01273</link>
<description rdf:parseType="Literal">&lt;p&gt;Agricultural management, with a particular focus on fertilization strategies,
holds a central role in shaping crop yield, economic profitability, and
environmental sustainability. While conventional guidelines offer valuable
insights, their efficacy diminishes when confronted with extreme weather
conditions, such as heatwaves and droughts. In this study, we introduce an
innovative framework that integrates Deep Reinforcement Learning (DRL) with
Recurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator, we train
an intelligent agent to master optimal nitrogen fertilization management.
Through a series of simulation experiments conducted on corn crops in Iowa, we
compare Partially Observable Markov Decision Process (POMDP) models with Markov
Decision Process (MDP) models. Our research underscores the advantages of
utilizing sequential observations in developing more efficient nitrogen input
policies. Additionally, we explore the impact of climate variability,
particularly during extreme weather events, on agricultural outcomes and
management. Our findings demonstrate the adaptability of fertilization policies
to varying climate conditions. Notably, a fixed policy exhibits resilience in
the face of minor climate fluctuations, leading to commendable corn yields,
cost-effectiveness, and environmental conservation. However, our study
illuminates the need for agent retraining to acquire new optimal policies under
extreme weather events. This research charts a promising course toward
adaptable fertilization strategies that can seamlessly align with dynamic
climate scenarios, ultimately contributing to the optimization of crop
management practices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaoan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1&quot;&gt;Shaoping Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Junchao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01280">
<title>GEqO: ML-Accelerated Semantic Equivalence Detection. (arXiv:2401.01280v1 [cs.DB])</title>
<link>http://arxiv.org/abs/2401.01280</link>
<description rdf:parseType="Literal">&lt;p&gt;Large scale analytics engines have become a core dependency for modern
data-driven enterprises to derive business insights and drive actions. These
engines support a large number of analytic jobs processing huge volumes of data
on a daily basis, and workloads are often inundated with overlapping
computations across multiple jobs. Reusing common computation is crucial for
efficient cluster resource utilization and reducing job execution time.
Detecting common computation is the first and key step for reducing this
computational redundancy. However, detecting equivalence on large-scale
analytics engines requires efficient and scalable solutions that are fully
automated. In addition, to maximize computation reuse, equivalence needs to be
detected at the semantic level instead of just the syntactic level (i.e., the
ability to detect semantic equivalence of seemingly different-looking queries).
Unfortunately, existing solutions fall short of satisfying these requirements.
&lt;/p&gt;
&lt;p&gt;In this paper, we take a major step towards filling this gap by proposing
GEqO, a portable and lightweight machine-learning-based framework for
efficiently identifying semantically equivalent computations at scale. GEqO
introduces two machine-learning-based filters that quickly prune out
nonequivalent subexpressions and employs a semi-supervised learning feedback
loop to iteratively improve its model with an intelligent sampling mechanism.
Further, with its novel database-agnostic featurization method, GEqO can
transfer the learning from one workload and database to another. Our extensive
empirical evaluation shows that, on TPC-DS-like queries, GEqO yields
significant performance gains-up to 200x faster than automated verifiers-and
finds up to 2x more equivalences than optimizer and signature-based equivalence
detection approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haynes_B/0/1/0/all/0/1&quot;&gt;Brandon Haynes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alotaibi_R/0/1/0/all/0/1&quot;&gt;Rana Alotaibi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavlenko_A/0/1/0/all/0/1&quot;&gt;Anna Pavlenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leeka_J/0/1/0/all/0/1&quot;&gt;Jyoti Leeka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jindal_A/0/1/0/all/0/1&quot;&gt;Alekh Jindal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yuanyuan Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01286">
<title>A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.01286</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have shown extraordinary capabilities in
understanding and generating text that closely mirrors human communication.
However, a primary limitation lies in the significant computational demands
during training, arising from their extensive parameterization. This challenge
is further intensified by the dynamic nature of the world, necessitating
frequent updates to LLMs to correct outdated information or integrate new
knowledge, thereby ensuring their continued relevance. Note that many
applications demand continual model adjustments post-training to address
deficiencies or undesirable behaviors. There is an increasing interest in
efficient, lightweight methods for on-the-fly model modifications. To this end,
recent years have seen a burgeoning in the techniques of knowledge editing for
LLMs, which aim to efficiently modify LLMs&apos; behaviors within specific domains
while preserving overall performance across various inputs. In this paper, we
first define the knowledge editing problem and then provide a comprehensive
review of cutting-edge approaches. Drawing inspiration from educational and
cognitive research theories, we propose a unified categorization criterion that
classifies knowledge editing methods into three groups: resorting to external
knowledge, merging knowledge into the model, and editing intrinsic knowledge.
Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensive
empirical evaluation of representative knowledge editing approaches.
Additionally, we provide an in-depth analysis of knowledge location, which can
provide a deeper understanding of the knowledge structures inherent within
LLMs. Finally, we discuss several potential applications of knowledge editing,
outlining its broad and impactful implications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1&quot;&gt;Ningyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yunzhi Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_B/0/1/0/all/0/1&quot;&gt;Bozhong Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Peng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1&quot;&gt;Shumin Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mengru Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1&quot;&gt;Zekun Xi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1&quot;&gt;Shengyu Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jintian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1&quot;&gt;Yuansheng Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Siyuan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Ziwen Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Xin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jia-Chen Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yong Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1&quot;&gt;Pengjun Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Fei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1&quot;&gt;Lei Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaowei Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huajun Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01294">
<title>Efficient Sparse Least Absolute Deviation Regression with Differential Privacy. (arXiv:2401.01294v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2401.01294</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, privacy-preserving machine learning algorithms have
attracted increasing attention because of their important applications in many
scientific fields. However, in the literature, most privacy-preserving
algorithms demand learning objectives to be strongly convex and Lipschitz
smooth, which thus cannot cover a wide class of robust loss functions (e.g.,
quantile/least absolute loss). In this work, we aim to develop a fast
privacy-preserving learning solution for a sparse robust regression problem.
Our learning loss consists of a robust least absolute loss and an $\ell_1$
sparse penalty term. To fast solve the non-smooth loss under a given privacy
budget, we develop a Fast Robust And Privacy-Preserving Estimation (FRAPPE)
algorithm for least absolute deviation regression. Our algorithm achieves a
fast estimation by reformulating the sparse LAD problem as a penalized least
square estimation problem and adopts a three-stage noise injection to guarantee
the $(\epsilon,\delta)$-differential privacy. We show that our algorithm can
achieve better privacy and statistical accuracy trade-off compared with the
state-of-the-art privacy-preserving regression algorithms. In the end, we
conduct experiments to verify the efficiency of our proposed FRAPPE algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weidong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mao_X/0/1/0/all/0/1&quot;&gt;Xiaojun Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaofei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xin Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01303">
<title>Integrating Edges into U-Net Models with Explainable Activation Maps for Brain Tumor Segmentation using MR Images. (arXiv:2401.01303v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2401.01303</link>
<description rdf:parseType="Literal">&lt;p&gt;Manual delineation of tumor regions from magnetic resonance (MR) images is
time-consuming, requires an expert, and is prone to human error. In recent
years, deep learning models have been the go-to approach for the segmentation
of brain tumors. U-Net and its&apos; variants for semantic segmentation of medical
images have achieved good results in the literature. However, U-Net and its&apos;
variants tend to over-segment tumor regions and may not accurately segment the
tumor edges. The edges of the tumor are as important as the tumor regions for
accurate diagnosis, surgical precision, and treatment planning. In the proposed
work, the authors aim to extract edges from the ground truth using a
derivative-like filter followed by edge reconstruction to obtain an edge ground
truth in addition to the brain tumor ground truth. Utilizing both ground
truths, the author studies several U-Net and its&apos; variant architectures with
and without tumor edges ground truth as a target along with the tumor ground
truth for brain tumor segmentation. The author used the BraTS2020 benchmark
dataset to perform the study and the results are tabulated for the dice and
Hausdorff95 metrics. The mean and median metrics are calculated for the whole
tumor (WT), tumor core (TC), and enhancing tumor (ET) regions. Compared to the
baseline U-Net and its variants, the models that learned edges along with the
tumor regions performed well in core tumor regions in both training and
validation datasets. The improved performance of edge-trained models trained on
baseline models like U-Net and V-Net achieved performance similar to baseline
state-of-the-art models like Swin U-Net and hybrid MR-U-Net. The edge-target
trained models are capable of generating edge maps that can be useful for
treatment planning. Additionally, for further explainability of the results,
the activation map generated by the hybrid MR-U-Net has been studied.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sahayam_S/0/1/0/all/0/1&quot;&gt;Subin Sahayam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jayaraman_U/0/1/0/all/0/1&quot;&gt;Umarani Jayaraman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01306">
<title>Learning solutions to some toy constrained optimization problems in infinite dimensional Hilbert spaces. (arXiv:2401.01306v1 [math.OC])</title>
<link>http://arxiv.org/abs/2401.01306</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we present deep learning implementations of two popular
theoretical constrained optimization algorithms in infinite dimensional Hilbert
spaces, namely, the penalty and the augmented Lagrangian methods. We test these
algorithms on some toy problems originating in either calculus of variations or
physics. We demonstrate that both methods are able to produce decent
approximations for the test problems and are comparable in terms of different
errors. Leveraging the common occurrence of the Lagrange multiplier update rule
being computationally less expensive than solving subproblems in the penalty
method, we achieve significant speedups in cases when the output of the
constraint function is itself a function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mandal_P/0/1/0/all/0/1&quot;&gt;Pinak Mandal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01325">
<title>LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning. (arXiv:2401.01325v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.01325</link>
<description rdf:parseType="Literal">&lt;p&gt;This work elicits LLMs&apos; inherent ability to handle long contexts without
fine-tuning. The limited length of the training sequence during training may
limit the application of Large Language Models (LLMs) on long input sequences
for inference. In this work, we argue that existing LLMs themselves have
inherent capabilities for handling long contexts. Based on this argument, we
suggest extending LLMs&apos; context window by themselves to fully utilize the
inherent ability.We propose Self-Extend to stimulate LLMs&apos; long context
handling potential. The basic idea is to construct bi-level attention
information: the group level and the neighbor level. The two levels are
computed by the original model&apos;s self-attention, which means the proposed does
not require any training. With only four lines of code modification, the
proposed method can effortlessly extend existing LLMs&apos; context window without
any fine-tuning. We conduct comprehensive experiments and the results show that
the proposed method can effectively extend existing LLMs&apos; context window&apos;s
length.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Hongye Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1&quot;&gt;Xiaotian Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jingfeng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Zhimeng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zirui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1&quot;&gt;Chia-Yuan Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huiyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01326">
<title>An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction. (arXiv:2401.01326v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2401.01326</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a novel method for joint entity and relation
extraction from unstructured text by framing it as a conditional sequence
generation problem. In contrast to conventional generative information
extraction models that are left-to-right token-level generators, our approach
is \textit{span-based}. It generates a linearized graph where nodes represent
text spans and edges represent relation triplets. Our method employs a
transformer encoder-decoder architecture with pointing mechanism on a dynamic
vocabulary of spans and relation types. Our model can capture the structural
characteristics and boundaries of entities and relations through span
representations while simultaneously grounding the generated output in the
original text thanks to the pointing mechanism. Evaluation on benchmark
datasets validates the effectiveness of our approach, demonstrating competitive
results. Code is available at https://github.com/urchade/ATG.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urchade_Z/0/1/0/all/0/1&quot;&gt;Zaratiana Urchade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomeh_N/0/1/0/all/0/1&quot;&gt;Nadi Tomeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holat_P/0/1/0/all/0/1&quot;&gt;Pierre Holat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charnois_T/0/1/0/all/0/1&quot;&gt;Thierry Charnois&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.01335">
<title>Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models. (arXiv:2401.01335v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2401.01335</link>
<description rdf:parseType="Literal">&lt;p&gt;Harnessing the power of human-annotated data through Supervised Fine-Tuning
(SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we
delve into the prospect of growing a strong LLM out of a weak one without the
need for acquiring additional human-annotated data. We propose a new
fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a
supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism,
where the LLM refines its capability by playing against instances of itself.
More specifically, the LLM generates its own training data from its previous
iterations, refining its policy by discerning these self-generated responses
from those obtained from human-annotated data. Our method progressively
elevates the LLM from a nascent model to a formidable one, unlocking the full
potential of human-annotated demonstration data for SFT. Theoretically, we
prove that the global optimum to the training objective function of our method
is achieved only when the LLM policy aligns with the target data distribution.
Empirically, we evaluate our method on several benchmark datasets including the
HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our
results show that SPIN can significantly improve the LLM&apos;s performance across a
variety of benchmarks and even outperform models trained through direct
preference optimization (DPO) supplemented with extra GPT-4 preference data.
This sheds light on the promise of self-play, enabling the achievement of
human-level performance in LLMs without the need for expert opponents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zixiang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yihe Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1&quot;&gt;Huizhuo Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_K/0/1/0/all/0/1&quot;&gt;Kaixuan Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1&quot;&gt;Quanquan Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.14082">
<title>Sample-Efficient Safety Assurances using Conformal Prediction. (arXiv:2109.14082v5 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2109.14082</link>
<description rdf:parseType="Literal">&lt;p&gt;When deploying machine learning models in high-stakes robotics applications,
the ability to detect unsafe situations is crucial. Early warning systems can
provide alerts when an unsafe situation is imminent (in the absence of
corrective action). To reliably improve safety, these warning systems should
have a provable false negative rate; i.e. of the situations that are unsafe,
fewer than $\epsilon$ will occur without an alert. In this work, we present a
framework that combines a statistical inference technique known as conformal
prediction with a simulator of robot/environment dynamics, in order to tune
warning systems to provably achieve an $\epsilon$ false negative rate using as
few as $1/\epsilon$ data points. We apply our framework to a driver warning
system and a robotic grasping application, and empirically demonstrate
guaranteed false negative rate while also observing low false detection
(positive) rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1&quot;&gt;Rachel Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shengjia Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuck_J/0/1/0/all/0/1&quot;&gt;Jonathan Kuck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivanovic_B/0/1/0/all/0/1&quot;&gt;Boris Ivanovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmerling_E/0/1/0/all/0/1&quot;&gt;Edward Schmerling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1&quot;&gt;Marco Pavone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.10955">
<title>Joint Learning of Linear Time-Invariant Dynamical Systems. (arXiv:2112.10955v6 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2112.10955</link>
<description rdf:parseType="Literal">&lt;p&gt;Linear time-invariant systems are very popular models in system theory and
applications. A fundamental problem in system identification that remains
rather unaddressed in extant literature is to leverage commonalities amongst
related linear systems to estimate their transition matrices more accurately.
To address this problem, the current paper investigates methods for jointly
estimating the transition matrices of multiple systems. It is assumed that the
transition matrices are unknown linear functions of some unknown shared basis
matrices. We establish finite-time estimation error rates that fully reflect
the roles of trajectory lengths, dimension, and number of systems under
consideration. The presented results are fairly general and show the
significant gains that can be achieved by pooling data across systems in
comparison to learning each system individually. Further, they are shown to be
robust against model misspecifications. To obtain the results, we develop novel
techniques that are of interest for addressing similar joint-learning problems.
They include tightly bounding estimation errors in terms of the
eigen-structures of transition matrices, establishing sharp high probability
bounds for singular values of dependent random matrices, and capturing effects
of misspecified transition matrices as the systems evolve over time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Modi_A/0/1/0/all/0/1&quot;&gt;Aditya Modi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Faradonbeh_M/0/1/0/all/0/1&quot;&gt;Mohamad Kazem Shirani Faradonbeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1&quot;&gt;Ambuj Tewari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Michailidis_G/0/1/0/all/0/1&quot;&gt;George Michailidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2201.01942">
<title>Efficiently Disentangle Causal Representations. (arXiv:2201.01942v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2201.01942</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes an efficient approach to learning disentangled
representations with causal mechanisms based on the difference of conditional
probabilities in original and new distributions. We approximate the difference
with models&apos; generalization abilities so that it fits in the standard machine
learning framework and can be efficiently computed. In contrast to the
state-of-the-art approach, which relies on the learner&apos;s adaptation speed to
new distribution, the proposed approach only requires evaluating the model&apos;s
generalization ability. We provide a theoretical explanation for the advantage
of the proposed method, and our experiments show that the proposed technique is
1.9--11.0$\times$ more sample efficient and 9.4--32.4 times quicker than the
previous method on various tasks. The source code is available at
\url{https://github.com/yuanpeng16/EDCR}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanpeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hestness_J/0/1/0/all/0/1&quot;&gt;Joel Hestness&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elhoseiny_M/0/1/0/all/0/1&quot;&gt;Mohamed Elhoseiny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Liang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Church_K/0/1/0/all/0/1&quot;&gt;Kenneth Church&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.02164">
<title>Estimating and Mitigating the Congestion Effect of Curbside Pick-ups and Drop-offs: A Causal Inference Approach. (arXiv:2206.02164v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.02164</link>
<description rdf:parseType="Literal">&lt;p&gt;Curb space is one of the busiest areas in urban road networks. Especially in
recent years, the rapid increase of ride-hailing trips and commercial
deliveries has induced massive pick-ups/drop-offs (PUDOs), which occupy the
limited curb space that was designed and built decades ago. These PUDOs could
jam curbside utilization and disturb the mainline traffic flow, evidently
leading to significant negative societal externalities. However, there is a
lack of an analytical framework that rigorously quantifies and mitigates the
congestion effect of PUDOs in the system view, particularly with little data
support and involvement of confounding effects. To bridge this research gap,
this paper develops a rigorous causal inference approach to estimate the
congestion effect of PUDOs on general regional networks. A causal graph is set
to represent the spatio-temporal relationship between PUDOs and traffic speed,
and a double and separated machine learning (DSML) method is proposed to
quantify how PUDOs affect traffic congestion. Additionally, a re-routing
formulation is developed and solved to encourage passenger walking and traffic
flow re-routing to achieve system optimization. Numerical experiments are
conducted using real-world data in the Manhattan area. On average, 100
additional units of PUDOs in a region could reduce the traffic speed by 3.70
and 4.54 mph on weekdays and weekends, respectively. Re-routing trips with
PUDOs on curb space could respectively reduce the system-wide total travel time
by 2.44% and 2.12% in Midtown and Central Park on weekdays. Sensitivity
analysis is also conducted to demonstrate the effectiveness and robustness of
the proposed framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaohui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1&quot;&gt;Sean Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teo_H/0/1/0/all/0/1&quot;&gt;Hock-Hai Teo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1&quot;&gt;Wei Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.00109">
<title>Ranking In Generalized Linear Bandits. (arXiv:2207.00109v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2207.00109</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the ranking problem in generalized linear bandits. At each time, the
learning agent selects an ordered list of items and observes stochastic
outcomes. In recommendation systems, displaying an ordered list of the most
attractive items is not always optimal as both position and item dependencies
result in a complex reward function. A very naive example is the lack of
diversity when all the most attractive items are from the same category. We
model the position and item dependencies in the ordered list and design UCB and
Thompson Sampling type algorithms for this problem. Our work generalizes
existing studies in several directions, including position dependencies where
position discount is a particular case, and connecting the ranking problem to
graph theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shidani_A/0/1/0/all/0/1&quot;&gt;Amitis Shidani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1&quot;&gt;George Deligiannidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1&quot;&gt;Arnaud Doucet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.06950">
<title>Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v8 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2209.06950</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper outlines an end-to-end optimized lossy image compression framework
using diffusion generative models. The approach relies on the transform coding
paradigm, where an image is mapped into a latent space for entropy coding and,
from there, mapped back to the data space for reconstruction. In contrast to
VAE-based neural compression, where the (mean) decoder is a deterministic
neural network, our decoder is a conditional diffusion model. Our approach thus
introduces an additional ``content&apos;&apos; latent variable on which the reverse
diffusion process is conditioned and uses this variable to store information
about the image. The remaining ``texture&apos;&apos; variables characterizing the
diffusion process are synthesized at decoding time. We show that the model&apos;s
performance can be tuned toward perceptual metrics of interest. Our extensive
experiments involving multiple datasets and image quality assessment metrics
show that our approach yields stronger reported FID scores than the GAN-based
model, while also yielding competitive performance with VAE-based models in
several distortion metrics. Furthermore, training the diffusion with
$\mathcal{X}$-parameterization enables high-quality reconstructions in only a
handful of decoding steps, greatly affecting the model&apos;s practicality. Our code
is available at: \url{https://github.com/buggyyang/CDC_compression}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Ruihan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mandt_S/0/1/0/all/0/1&quot;&gt;Stephan Mandt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.09041">
<title>Approximation analysis of CNNs from a feature extraction view. (arXiv:2210.09041v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.09041</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning based on deep neural networks has been very successful in many
practical applications, but it lacks enough theoretical understanding due to
the network architectures and structures. In this paper we establish some
analysis for linear feature extraction by a deep multi-channel convolutional
neural networks (CNNs), which demonstrates the power of deep learning over
traditional linear transformations, like Fourier, wavelets, redundant
dictionary coding methods. Moreover, we give an exact construction presenting
how linear features extraction can be conducted efficiently with multi-channel
CNNs. It can be applied to lower the essential dimension for approximating a
high dimensional function. Rates of function approximation by such deep
networks implemented with channels and followed by fully-connected layers are
investigated as well. Harmonic analysis for factorizing linear features into
multi-resolution convolutions plays an essential role in our work.
Nevertheless, a dedicate vectorization of matrices is constructed, which
bridges 1D CNN and 2D CNN and allows us to have corresponding 2D analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianfei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1&quot;&gt;Han Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Ding-Xuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.14826">
<title>tf.data service: A Case for Disaggregating ML Input Data Processing. (arXiv:2210.14826v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.14826</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning (ML) computations commonly execute on expensive specialized
hardware, such as GPUs and TPUs, which provide high FLOPs and
performance-per-watt. For cost efficiency, it is essential to keep these
accelerators highly utilized. This requires preprocessing input data at the
rate at which the accelerators can ingest and perform ML computations on the
data. To avoid data stalls, the host CPU and RAM required for input data
processing per accelerator core used for ML computations varies across jobs.
Hence, the traditional approach of processing input data on ML accelerator
hosts with a fixed hardware ratio leads to either under-utilizing the
accelerators or the host CPU and RAM. In this paper, we address these concerns
by building a disaggregated ML data processing system.
&lt;/p&gt;
&lt;p&gt;We present tf.data service, an open-source disaggregated input data
processing service built on top of tf.data in TensorFlow. We show that
disaggregating data preprocessing has three key advantages for large-scale ML
training jobs. First, the service can horizontally scale-out to right-size
CPU/RAM host resources for data processing in each job, saving 32x training
time and 26x cost, on average. Second, the service can share ephemeral
preprocessed data results across jobs, to optimize CPU usage and reduce
redundant computations. Finally, the service supports coordinated reads, a
technique that avoids stragglers due to different input sizes in distributed
training, reducing training time by 2.2x, on average. Our design is inspired by
lessons learned from deploying tf.data service in production, including
relaxing data visitation guarantees without impacting model accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Audibert_A/0/1/0/all/0/1&quot;&gt;Andrew Audibert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graur_D/0/1/0/all/0/1&quot;&gt;Dan Graur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klimovic_A/0/1/0/all/0/1&quot;&gt;Ana Klimovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simsa_J/0/1/0/all/0/1&quot;&gt;Jiri Simsa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thekkath_C/0/1/0/all/0/1&quot;&gt;Chandramohan A. Thekkath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.15542">
<title>Autonomous Assessment of Demonstration Sufficiency via Bayesian Inverse Reinforcement Learning. (arXiv:2211.15542v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.15542</link>
<description rdf:parseType="Literal">&lt;p&gt;We examine the problem of determining demonstration sufficiency: how can a
robot self-assess whether it has received enough demonstrations from an expert
to ensure a desired level of performance? To address this problem, we propose a
novel self-assessment approach based on Bayesian inverse reinforcement learning
and value-at-risk, enabling learning-from-demonstration (&quot;LfD&quot;) robots to
compute high-confidence bounds on their performance and use these bounds to
determine when they have a sufficient number of demonstrations. We propose and
evaluate two definitions of sufficiency: (1) normalized expected value
difference, which measures regret with respect to the human&apos;s unobserved reward
function, and (2) percent improvement over a baseline policy. We demonstrate
how to formulate high-confidence bounds on both of these metrics. We evaluate
our approach in simulation for both discrete and continuous state-space domains
and illustrate the feasibility of developing a robotic system that can
accurately evaluate demonstration sufficiency. We also show that the robot can
utilize active learning in asking for demonstrations from specific states which
results in fewer demos needed for the robot to still maintain high confidence
in its policy. Finally, via a user study, we show that our approach
successfully enables robots to perform at users&apos; desired performance levels,
without needing too many or perfectly optimal demonstrations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trinh_T/0/1/0/all/0/1&quot;&gt;Tu Trinh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Haoyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Daniel S. Brown&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.07175">
<title>Scaffold-Based Multi-Objective Drug Candidate Optimization. (arXiv:2301.07175v2 [q-bio.BM] UPDATED)</title>
<link>http://arxiv.org/abs/2301.07175</link>
<description rdf:parseType="Literal">&lt;p&gt;In therapeutic design, balancing various physiochemical properties is crucial
for molecule development, similar to how Multiparameter Optimization (MPO)
evaluates multiple variables to meet a primary goal. While many molecular
features can now be predicted using \textit{in silico} methods, aiding early
drug development, the vast data generated from high throughput virtual
screening challenges the practicality of traditional MPO approaches. Addressing
this, we introduce a scaffold focused graph-based Markov chain Monte Carlo
framework (ScaMARS) built to generate molecules with optimal properties. This
innovative framework is capable of self-training and handling a wider array of
properties, sampling different chemical spaces according to the starting
scaffold. The benchmark analysis on several properties shows that ScaMARS has a
diversity score of 84.6\% and has a much higher success rate of 99.5\% compared
to conditional models. The integration of new features into MPO significantly
enhances its adaptability and effectiveness in therapeutic design, facilitating
the discovery of candidates that efficiently optimize multiple properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kruel_A/0/1/0/all/0/1&quot;&gt;Agustin Kruel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+McNaughton_A/0/1/0/all/0/1&quot;&gt;Andrew D. McNaughton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kumar_N/0/1/0/all/0/1&quot;&gt;Neeraj Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.00316">
<title>Accelerated First-Order Optimization under Nonlinear Constraints. (arXiv:2302.00316v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2302.00316</link>
<description rdf:parseType="Literal">&lt;p&gt;We exploit analogies between first-order algorithms for constrained
optimization and non-smooth dynamical systems to design a new class of
accelerated first-order algorithms for constrained optimization. Unlike
Frank-Wolfe or projected gradients, these algorithms avoid optimization over
the entire feasible set at each iteration. We prove convergence to stationary
points even in a nonconvex setting and we derive accelerated rates for the
convex setting both in continuous time, as well as in discrete time. An
important property of these algorithms is that constraints are expressed in
terms of velocities instead of positions, which naturally leads to sparse,
local and convex approximations of the feasible set (even if the feasible set
is nonconvex). Thus, the complexity tends to grow mildly in the number of
decision variables and in the number of constraints, which makes the algorithms
suitable for machine learning applications. We apply our algorithms to a
compressed sensing and a sparse regression problem, showing that we can treat
nonconvex $\ell^p$ constraints ($p&amp;lt;1$) efficiently, while recovering
state-of-the-art performance for $p=1$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Muehlebach_M/0/1/0/all/0/1&quot;&gt;Michael Muehlebach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.00878">
<title>The Contextual Lasso: Sparse Linear Models via Deep Neural Networks. (arXiv:2302.00878v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2302.00878</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse linear models are one of several core tools for interpretable machine
learning, a field of emerging importance as predictive models permeate
decision-making in many domains. Unfortunately, sparse linear models are far
less flexible as functions of their input features than black-box models like
deep neural networks. With this capability gap in mind, we study a not-uncommon
situation where the input features dichotomize into two groups: explanatory
features, which are candidates for inclusion as variables in an interpretable
model, and contextual features, which select from the candidate variables and
determine their effects. This dichotomy leads us to the contextual lasso, a new
statistical estimator that fits a sparse linear model to the explanatory
features such that the sparsity pattern and coefficients vary as a function of
the contextual features. The fitting process learns this function
nonparametrically via a deep neural network. To attain sparse coefficients, we
train the network with a novel lasso regularizer in the form of a projection
layer that maps the network&apos;s output onto the space of $\ell_1$-constrained
linear models. An extensive suite of experiments on real and synthetic data
suggests that the learned models, which remain highly transparent, can be
sparser than the regular lasso without sacrificing the predictive power of a
standard deep neural network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thompson_R/0/1/0/all/0/1&quot;&gt;Ryan Thompson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dezfouli_A/0/1/0/all/0/1&quot;&gt;Amir Dezfouli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kohn_R/0/1/0/all/0/1&quot;&gt;Robert Kohn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.14274">
<title>When Do Graph Neural Networks Help with Node Classification? Investigating the Impact of Homophily Principle on Node Distinguishability. (arXiv:2304.14274v4 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/2304.14274</link>
<description rdf:parseType="Literal">&lt;p&gt;Homophily principle, i.e., nodes with the same labels are more likely to be
connected, has been believed to be the main reason for the performance
superiority of Graph Neural Networks (GNNs) over Neural Networks on node
classification tasks. Recent research suggests that, even in the absence of
homophily, the advantage of GNNs still exists as long as nodes from the same
class share similar neighborhood patterns. However, this argument only
considers intra-class Node Distinguishability (ND) but neglects inter-class ND,
which provides incomplete understanding of homophily on GNNs. In this paper, we
first demonstrate such deficiency with examples and argue that an ideal
situation for ND is to have smaller intra-class ND than inter-class ND. To
formulate this idea and study ND deeply, we propose Contextual Stochastic Block
Model for Homophily (CSBM-H) and define two metrics, Probabilistic Bayes Error
(PBE) and negative generalized Jeffreys divergence, to quantify ND. With the
metrics, we visualize and analyze how graph filters, node degree distributions
and class variances influence ND, and investigate the combined effect of intra-
and inter-class ND. Besides, we discovered the mid-homophily pitfall, which
occurs widely in graph datasets. Furthermore, we verified that, in real-work
tasks, the superiority of GNNs is indeed closely related to both intra- and
inter-class ND regardless of homophily levels. Grounded in this observation, we
propose a new hypothesis-testing based performance metric beyond homophily,
which is non-linear, feature-based and can provide statistical threshold value
for GNNs&apos; the superiority. Experiments indicate that it is significantly more
effective than the existing homophily metrics on revealing the advantage and
disadvantage of graph-aware modes on both synthetic and benchmark real-world
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luan_S/0/1/0/all/0/1&quot;&gt;Sitao Luan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_C/0/1/0/all/0/1&quot;&gt;Chenqing Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Minkai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1&quot;&gt;Qincheng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jiaqi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1&quot;&gt;Xiao-Wen Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jie Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1&quot;&gt;Doina Precup&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.14374">
<title>Pseudo-Hamiltonian neural networks for learning partial differential equations. (arXiv:2304.14374v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.14374</link>
<description rdf:parseType="Literal">&lt;p&gt;Pseudo-Hamiltonian neural networks (PHNN) were recently introduced for
learning dynamical systems that can be modelled by ordinary differential
equations. In this paper, we extend the method to partial differential
equations. The resulting model is comprised of up to three neural networks,
modelling terms representing conservation, dissipation and external forces, and
discrete convolution operators that can either be learned or be given as input.
We demonstrate numerically the superior performance of PHNN compared to a
baseline model that models the full dynamics by a single neural network.
Moreover, since the PHNN model consists of three parts with different physical
interpretations, these can be studied separately to gain insight into the
system, and the learned model is applicable also if external forces are removed
or changed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eidnes_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf8;lve Eidnes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lye_K/0/1/0/all/0/1&quot;&gt;Kjetil Olsen Lye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.02803">
<title>Tensor PCA from basis in tensor space. (arXiv:2305.02803v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/2305.02803</link>
<description rdf:parseType="Literal">&lt;p&gt;The aim of this paper is to present a mathematical framework for tensor PCA.
The proposed approach is able to overcome the limitations of previous methods
that extract a low dimensional subspace by iteratively solving an optimization
problem. The core of the proposed approach is the derivation of a basis in
tensor space from a real self-adjoint tensor operator, thus reducing the
problem of deriving a basis to an eigenvalue problem. Three different cases
have been studied to derive: i) a basis from a self-adjoint tensor operator;
ii) a rank-1 basis; iii) a basis in a subspace. In particular, the equivalence
between eigenvalue equation for a real self-adjoint tensor operator and
standard matrix eigenvalue equation has been proven. For all the three cases
considered, a subspace approach has been adopted to derive a tensor PCA.
Experiments on image datasets validate the proposed mathematical framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Turchetti_C/0/1/0/all/0/1&quot;&gt;Claudio Turchetti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06920">
<title>Pseudo-Hamiltonian system identification. (arXiv:2305.06920v2 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06920</link>
<description rdf:parseType="Literal">&lt;p&gt;Identifying the underlying dynamics of physical systems can be challenging
when only provided with observational data. In this work, we consider systems
that can be modelled as first-order ordinary differential equations. By
assuming a certain pseudo-Hamiltonian formulation, we are able to learn the
analytic terms of internal dynamics even if the model is trained on data where
the system is affected by unknown damping and external disturbances. In cases
where it is difficult to find analytic terms for the disturbances, a hybrid
model that uses a neural network to learn these can still accurately identify
the dynamics of the system as if under ideal conditions. This makes the models
applicable in some situations where other system identification models fail.
Furthermore, we propose to use a fourth-order symmetric integration scheme in
the loss function and avoid actual integration in the training, and demonstrate
on varied examples how this leads to increased performance on noisy data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Holmsen_S/0/1/0/all/0/1&quot;&gt;Sigurd Holmsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Eidnes_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf8;lve Eidnes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Riemer_Sorensen_S/0/1/0/all/0/1&quot;&gt;Signe Riemer-S&amp;#xf8;rensen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.17760">
<title>Language Models are Bounded Pragmatic Speakers: Understanding RLHF from a Bayesian Cognitive Modeling Perspective. (arXiv:2305.17760v6 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2305.17760</link>
<description rdf:parseType="Literal">&lt;p&gt;How do language models &quot;think&quot;? This paper formulates a probabilistic
cognitive model called the bounded pragmatic speaker, which can characterize
the operation of different variations of language models. Specifically, we
demonstrate that large language models fine-tuned with reinforcement learning
from human feedback (Ouyang et al., 2022) embody a model of thought that
conceptually resembles a fast-and-slow model (Kahneman, 2011), which
psychologists have attributed to humans. We discuss the limitations of
reinforcement learning from human feedback as a fast-and-slow model of thought
and propose avenues for expanding this framework. In essence, our research
highlights the value of adopting a cognitive probabilistic modeling approach to
gain insights into the comprehension, evaluation, and advancement of language
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1&quot;&gt;Khanh Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.10875">
<title>Risk-optimized Outlier Removal for Robust 3D Point Cloud Classification. (arXiv:2307.10875v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.10875</link>
<description rdf:parseType="Literal">&lt;p&gt;With the growth of 3D sensing technology, deep learning system for 3D point
clouds has become increasingly important, especially in applications like
autonomous vehicles where safety is a primary concern. However, there are also
growing concerns about the reliability of these systems when they encounter
noisy point clouds, whether occurring naturally or introduced with malicious
intent. This paper highlights the challenges of point cloud classification
posed by various forms of noise, from simple background noise to malicious
backdoor attacks that can intentionally skew model predictions. While there&apos;s
an urgent need for optimized point cloud denoising, current point outlier
removal approaches, an essential step for denoising, rely heavily on
handcrafted strategies and are not adapted for higher-level tasks, such as
classification. To address this issue, we introduce an innovative point outlier
cleansing method that harnesses the power of downstream classification models.
By employing gradient-based attribution analysis, we define a novel concept:
point risk. Drawing inspiration from tail risk minimization in finance, we
recast the outlier removal process as an optimization problem, named PointCVaR.
Extensive experiments show that our proposed technique not only robustly
filters diverse point cloud outliers but also consistently and significantly
enhances existing robust methods for point cloud classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xinke Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Junchi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1&quot;&gt;Henghui Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1&quot;&gt;Changsheng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Joey Tianyi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1&quot;&gt;Chee Yeow Meng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.16164">
<title>Adaptive learning of density ratios in RKHS. (arXiv:2307.16164v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.16164</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the ratio of two probability densities from finitely many
observations of the densities is a central problem in machine learning and
statistics with applications in two-sample testing, divergence estimation,
generative modeling, covariate shift adaptation, conditional density
estimation, and novelty detection. In this work, we analyze a large class of
density ratio estimation methods that minimize a regularized Bregman divergence
between the true density ratio and a model in a reproducing kernel Hilbert
space (RKHS). We derive new finite-sample error bounds, and we propose a
Lepskii type parameter choice principle that minimizes the bounds without
knowledge of the regularity of the density ratio. In the special case of
quadratic loss, our method adaptively achieves a minimax optimal error rate. A
numerical illustration is provided.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zellinger_W/0/1/0/all/0/1&quot;&gt;Werner Zellinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kindermann_S/0/1/0/all/0/1&quot;&gt;Stefan Kindermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereverzyev_S/0/1/0/all/0/1&quot;&gt;Sergei V. Pereverzyev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04365">
<title>SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2308.04365</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference is a crucial goal of science, enabling researchers to arrive
at meaningful conclusions regarding the predictions of hypothetical
interventions using observational data. Path models, Structural Equation Models
(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to
unambiguously specify assumptions regarding the causal structure underlying a
phenomenon. Unlike DAGs, which make very few assumptions about the functional
and parametric form, SEM assumes linearity. This can result in functional
misspecification which prevents researchers from undertaking reliable effect
size estimation. In contrast, we propose Super Learner Equation Modeling, a
path modeling technique integrating machine learning Super Learner ensembles.
We empirically demonstrate its ability to provide consistent and unbiased
estimates of causal effects, its competitive performance for linear models when
compared with SEM, and highlight its superiority over SEM when dealing with
non-linear relationships. We provide open-source code, and a tutorial notebook
with example usage, accentuating the easy-to-use nature of the method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vowels_M/0/1/0/all/0/1&quot;&gt;Matthew J. Vowels&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.13815">
<title>Arbitrary Distributions Mapping via SyMOT-Flow: A Flow-based Approach Integrating Maximum Mean Discrepancy and Optimal Transport. (arXiv:2308.13815v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.13815</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding a transformation between two unknown probability distributions from
finite samples is crucial for modeling complex data distributions and
performing tasks such as sample generation, domain adaptation and statistical
inference. One powerful framework for such transformations is normalizing flow,
which transforms an unknown distribution into a standard normal distribution
using an invertible network. In this paper, we introduce a novel model called
SyMOT-Flow that trains an invertible transformation by minimizing the symmetric
maximum mean discrepancy between samples from two unknown distributions, and an
optimal transport cost is incorporated as regularization to obtain a
short-distance and interpretable transformation. The resulted transformation
leads to more stable and accurate sample generation. Several theoretical
results are established for the proposed model and its effectiveness is
validated with low-dimensional illustrative examples as well as
high-dimensional bi-modality medical image generation through the forward and
reverse flows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zhe Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_Q/0/1/0/all/0/1&quot;&gt;Qiaoqiao Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaoqun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.15640">
<title>Identifying Constitutive Parameters for Complex Hyperelastic Materials using Physics-Informed Neural Networks. (arXiv:2308.15640v2 [cond-mat.mtrl-sci] UPDATED)</title>
<link>http://arxiv.org/abs/2308.15640</link>
<description rdf:parseType="Literal">&lt;p&gt;Identifying constitutive parameters in engineering and biological materials,
particularly those with intricate geometries and mechanical behaviors, remains
a longstanding challenge. The recent advent of Physics-Informed Neural Networks
(PINNs) offers promising solutions, but current frameworks are often limited to
basic constitutive laws and encounter practical constraints when combined with
experimental data. In this paper, we introduce a robust PINN-based framework
designed to identify material parameters for soft materials, specifically those
exhibiting complex constitutive behaviors, under large deformation in plane
stress conditions. Distinctively, our model emphasizes training PINNs with
multi-modal synthetic experimental datasets consisting of full-field
deformation and loading history, ensuring algorithm robustness even with noisy
data. Our results reveal that the PINNs framework can accurately identify
constitutive parameters of the incompressible Arruda-Boyce model for samples
with intricate geometries, maintaining an error below 5%, even with an
experimental noise level of 5%. We believe our framework provides a robust
modulus identification approach for complex solids, especially for those with
geometrical and constitutive complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Siyuan Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Hanxun Jin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.09222">
<title>Data-driven Modeling and Inference for Bayesian Gaussian Process ODEs via Double Normalizing Flows. (arXiv:2309.09222v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.09222</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, Gaussian processes have been used to model the vector field of
continuous dynamical systems, referred to as GPODEs, which are characterized by
a probabilistic ODE equation. Bayesian inference for these models has been
extensively studied and applied in tasks such as time series prediction.
However, the use of standard GPs with basic kernels like squared exponential
kernels has been common in GPODE research, limiting the model&apos;s ability to
represent complex scenarios. To address this limitation, we introduce
normalizing flows to reparameterize the ODE vector field, resulting in a
data-driven prior distribution, thereby increasing flexibility and expressive
power. We develop a data-driven variational learning algorithm that utilizes
analytically tractable probability density functions of normalizing flows,
enabling simultaneous learning and inference of unknown continuous dynamics.
Additionally, we also apply normalizing flows to the posterior inference of GP
ODEs to resolve the issue of strong mean-field assumptions in posterior
inference. By applying normalizing flows in both these ways, our model improves
accuracy and uncertainty estimates for Bayesian Gaussian Process ODEs. We
validate the effectiveness of our approach on simulated dynamical systems and
real-world human motion data, including time series prediction and missing data
recovery tasks. Experimental results show that our proposed method effectively
captures model uncertainty while improving accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jian Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Shian Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Junmei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1&quot;&gt;Xinghao Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paisley_J/0/1/0/all/0/1&quot;&gt;John Paisley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1&quot;&gt;Delu Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.14496">
<title>Era Splitting -- Invariant Learning for Decision Trees. (arXiv:2309.14496v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.14496</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-life machine learning problems exhibit distributional shifts in the data
from one time to another or from on place to another. This behavior is beyond
the scope of the traditional empirical risk minimization paradigm, which
assumes i.i.d. distribution of data over time and across locations. The
emerging field of out-of-distribution (OOD) generalization addresses this
reality with new theory and algorithms which incorporate environmental, or
era-wise information into the algorithms. So far, most research has been
focused on linear models and/or neural networks. In this research we develop
two new splitting criteria for decision trees, which allow us to apply ideas
from OOD generalization research to decision tree models, including random
forest and gradient-boosting decision trees. The new splitting criteria use
era-wise information associated with each data point to allow tree-based models
to find split points that are optimal across all disjoint eras in the data,
instead of optimal over the entire data set pooled together, which is the
default setting. In this paper we describe the problem setup in the context of
financial markets. We describe the new splitting criteria in detail and develop
unique experiments to showcase the benefits of these new criteria, which
improve metrics in our experiments out-of-sample. The new criteria are
incorporated into the a state-of-the-art gradient boosted decision tree model
in the Scikit-Learn code base, which is made freely available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DeLise_T/0/1/0/all/0/1&quot;&gt;Timothy DeLise&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15224">
<title>Collaborative Watermarking for Adversarial Speech Synthesis. (arXiv:2309.15224v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15224</link>
<description rdf:parseType="Literal">&lt;p&gt;Advances in neural speech synthesis have brought us technology that is not
only close to human naturalness, but is also capable of instant voice cloning
with little data, and is highly accessible with pre-trained models available.
Naturally, the potential flood of generated content raises the need for
synthetic speech detection and watermarking. Recently, considerable research
effort in synthetic speech detection has been related to the Automatic Speaker
Verification and Spoofing Countermeasure Challenge (ASVspoof), which focuses on
passive countermeasures. This paper takes a complementary view to generated
speech detection: a synthesis system should make an active effort to watermark
the generated speech in a way that aids detection by another machine, but
remains transparent to a human listener. We propose a collaborative training
scheme for synthetic speech watermarking and show that a HiFi-GAN neural
vocoder collaborating with the ASVspoof 2021 baseline countermeasure models
consistently improves detection performance over conventional classifier
training. Furthermore, we demonstrate how collaborative training can be paired
with augmentation strategies for added robustness against noise and
time-stretching. Finally, listening tests demonstrate that collaborative
training has little adverse effect on perceptual quality of vocoded speech.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Juvela_L/0/1/0/all/0/1&quot;&gt;Lauri Juvela&lt;/a&gt; (Aalto University, Finland), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt; (National Institute of Informatics, Japan)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16741">
<title>Multi-Modal Financial Time-Series Retrieval Through Latent Space Projections. (arXiv:2309.16741v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.16741</link>
<description rdf:parseType="Literal">&lt;p&gt;Financial firms commonly process and store billions of time-series data,
generated continuously and at a high frequency. To support efficient data
storage and retrieval, specialized time-series databases and systems have
emerged. These databases support indexing and querying of time-series by a
constrained Structured Query Language(SQL)-like format to enable queries like
&quot;Stocks with monthly price returns greater than 5%&quot;, and expressed in rigid
formats. However, such queries do not capture the intrinsic complexity of high
dimensional time-series data, which can often be better described by images or
language (e.g., &quot;A stock in low volatility regime&quot;). Moreover, the required
storage, computational time, and retrieval complexity to search in the
time-series space are often non-trivial. In this paper, we propose and
demonstrate a framework to store multi-modal data for financial time-series in
a lower-dimensional latent space using deep encoders, such that the latent
space projections capture not only the time series trends but also other
desirable information or properties of the financial time-series data (such as
price volatility). Moreover, our approach allows user-friendly query
interfaces, enabling natural language text or sketches of time-series, for
which we have developed intuitive interfaces. We demonstrate the advantages of
our method in terms of computational efficiency and accuracy on real historical
data as well as synthetic data, and highlight the utility of latent-space
projections in the storage and retrieval of financial time-series data with
intuitive query modalities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bamford_T/0/1/0/all/0/1&quot;&gt;Tom Bamford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coletta_A/0/1/0/all/0/1&quot;&gt;Andrea Coletta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fons_E/0/1/0/all/0/1&quot;&gt;Elizabeth Fons&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalakrishnan_S/0/1/0/all/0/1&quot;&gt;Sriram Gopalakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vyetrenko_S/0/1/0/all/0/1&quot;&gt;Svitlana Vyetrenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balch_T/0/1/0/all/0/1&quot;&gt;Tucker Balch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1&quot;&gt;Manuela Veloso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.17207">
<title>Memory Gym: Towards Endless Tasks to Benchmark Memory Capabilities of Agents. (arXiv:2309.17207v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.17207</link>
<description rdf:parseType="Literal">&lt;p&gt;Memory Gym presents a suite of 2D partially observable environments, namely
Mortar Mayhem, Mystery Path, and Searing Spotlights, designed to benchmark
memory capabilities in decision-making agents. These environments, originally
with finite tasks, are expanded into innovative, endless formats, mirroring the
escalating challenges of cumulative memory games such as ``I packed my bag&apos;&apos;.
This progression in task design shifts the focus from merely assessing sample
efficiency to also probing the levels of memory effectiveness in dynamic,
prolonged scenarios. To address the gap in available memory-based Deep
Reinforcement Learning baselines, we introduce an implementation that
integrates Transformer-XL (TrXL) with Proximal Policy Optimization. This
approach utilizes TrXL as a form of episodic memory, employing a sliding window
technique. Our comparative study between the Gated Recurrent Unit (GRU) and
TrXL reveals varied performances across different settings. TrXL, on the finite
environments, demonstrates superior sample efficiency in Mystery Path and
outperforms in Mortar Mayhem. However, GRU is more efficient on Searing
Spotlights. Most notably, in all endless tasks, GRU makes a remarkable
resurgence, consistently outperforming TrXL by significant margins. Website and
Source Code: \url{https://github.com/MarcoMeter/endless-memory-gym/}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pleines_M/0/1/0/all/0/1&quot;&gt;Marco Pleines&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pallasch_M/0/1/0/all/0/1&quot;&gt;Matthias Pallasch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zimmer_F/0/1/0/all/0/1&quot;&gt;Frank Zimmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Preuss_M/0/1/0/all/0/1&quot;&gt;Mike Preuss&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.09167">
<title>A Deep Neural Network -- Mechanistic Hybrid Model to Predict Pharmacokinetics in Rat. (arXiv:2310.09167v2 [q-bio.QM] UPDATED)</title>
<link>http://arxiv.org/abs/2310.09167</link>
<description rdf:parseType="Literal">&lt;p&gt;An important aspect in the development of small molecules as drugs or
agro-chemicals is their systemic availability after intravenous and oral
administration. The prediction of the systemic availability from the chemical
structure of a potential candidate is highly desirable, as it allows to focus
the drug or agrochemical development on compounds with a favorable kinetic
profile. However, such pre-dictions are challenging as the availability is the
result of the complex interplay between molecular properties, biology and
physiology and training data is rare. In this work we improve the hybrid model
developed earlier [1]. We reduce the median fold change error for the total
oral exposure from 2.85 to 2.35 and for intravenous administration from 1.95 to
1.62. This is achieved by training on a larger data set, improving the neural
network architecture as well as the parametrization of mechanistic model.
Further, we extend our approach to predict additional endpoints and to handle
different covariates, like sex and dosage form. In contrast to a pure machine
learning model, our model is able to predict new end points on which it has not
been trained. We demonstrate this feature by predicting the exposure over the
first 24h, while the model has only been trained on the total exposure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Fuhrer_F/0/1/0/all/0/1&quot;&gt;Florian F&amp;#xfc;hrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gruber_A/0/1/0/all/0/1&quot;&gt;Andrea Gruber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Diedam_H/0/1/0/all/0/1&quot;&gt;Holger Diedam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Goller_A/0/1/0/all/0/1&quot;&gt;Andreas H. G&amp;#xf6;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Menz_S/0/1/0/all/0/1&quot;&gt;Stephan Menz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Schneckener_S/0/1/0/all/0/1&quot;&gt;Sebastian Schneckener&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.10477">
<title>Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis. (arXiv:2310.10477v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.10477</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid development of large language models (LLMs) has not only provided
numerous opportunities but also presented significant challenges. This becomes
particularly evident when LLMs inadvertently generate harmful or toxic content,
either unintentionally or because of intentional inducement. Existing alignment
methods usually direct LLMs toward the favorable outcomes by utilizing
human-annotated, flawless instruction-response pairs. Conversely, this study
proposes a novel alignment technique based on mistake analysis, which
deliberately exposes LLMs to erroneous content to learn the reasons for
mistakes and how to avoid them. In this case, mistakes are repurposed into
valuable data for alignment, effectively helping to avoid the production of
erroneous responses. Without external models or human annotations, our method
leverages a model&apos;s intrinsic ability to discern undesirable mistakes and
improves the safety of its generated responses. Experimental results reveal
that our method outperforms existing alignment approaches in enhancing model
safety while maintaining the overall utility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kai Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chunwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1&quot;&gt;Kuo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jianhua Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1&quot;&gt;Lanqing Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1&quot;&gt;Fei Mi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhengying Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wenyong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenguo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_D/0/1/0/all/0/1&quot;&gt;Dit-Yan Yeung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1&quot;&gt;Lifeng Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1&quot;&gt;Xin Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qun Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2310.19923">
<title>Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents. (arXiv:2310.19923v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2310.19923</link>
<description rdf:parseType="Literal">&lt;p&gt;Text embedding models have emerged as powerful tools for transforming
sentences into fixed-sized feature vectors that encapsulate semantic
information. While these models are essential for tasks like information
retrieval, semantic clustering, and text re-ranking, most existing open-source
models, especially those built on architectures like BERT, struggle to
represent lengthy documents and often resort to truncation. One common approach
to mitigate this challenge involves splitting documents into smaller paragraphs
for embedding. However, this strategy results in a much larger set of vectors,
consequently leading to increased memory consumption and computationally
intensive vector searches with elevated latency.
&lt;/p&gt;
&lt;p&gt;To address these challenges, we introduce Jina Embeddings 2, an open-source
text embedding model capable of accommodating up to 8192 tokens. This model is
designed to transcend the conventional 512-token limit and adeptly process long
documents. Jina Embeddings 2 not only achieves state-of-the-art performance on
a range of embedding-related tasks in the MTEB benchmark but also matches the
performance of OpenAI&apos;s proprietary ada-002 model. Additionally, our
experiments indicate that an extended context can enhance performance in tasks
such as NarrativeQA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunther_M/0/1/0/all/0/1&quot;&gt;Michael G&amp;#xfc;nther&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ong_J/0/1/0/all/0/1&quot;&gt;Jackmin Ong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohr_I/0/1/0/all/0/1&quot;&gt;Isabelle Mohr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdessalem_A/0/1/0/all/0/1&quot;&gt;Alaeddine Abdessalem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abel_T/0/1/0/all/0/1&quot;&gt;Tanguy Abel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akram_M/0/1/0/all/0/1&quot;&gt;Mohammad Kalim Akram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzman_S/0/1/0/all/0/1&quot;&gt;Susana Guzman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mastrapas_G/0/1/0/all/0/1&quot;&gt;Georgios Mastrapas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sturua_S/0/1/0/all/0/1&quot;&gt;Saba Sturua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Werk_M/0/1/0/all/0/1&quot;&gt;Maximilian Werk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1&quot;&gt;Nan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1&quot;&gt;Han Xiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2311.15218">
<title>Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and Qualitative Analysis. (arXiv:2311.15218v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2311.15218</link>
<description rdf:parseType="Literal">&lt;p&gt;The application of Machine learning to finance has become a familiar
approach, even more so in stock market forecasting. The stock market is highly
volatile, and huge amounts of data are generated every minute globally. The
extraction of effective intelligence from this data is of critical importance.
However, a collaboration of numerical stock data with qualitative text data can
be a challenging task. In this work, we accomplish this by providing an
unprecedented, publicly available dataset with technical and fundamental data
and sentiment that we gathered from news archives, TV news captions, radio
transcripts, tweets, daily financial newspapers, etc. The text data entries
used for sentiment extraction total more than 1.4 Million. The dataset consists
of daily entries from January 2018 to December 2022 for eight companies
representing diverse industrial sectors and the Dow Jones Industrial Average
(DJIA) as a whole. Holistic Fundamental and Technical data is provided training
ready for Model learning and deployment. Most importantly, the data generated
could be used for incremental online learning with real-time data points
retrieved daily since no stagnant data was utilized. All the data was retired
from APIs or self-designed robust information retrieval technologies with
extremely low latency and zero monetary cost. These adaptable technologies
facilitate data extraction for any stock. Moreover, the utilization of
Spearman&apos;s rank correlation over real-time data, linking stock returns with
sentiment analysis has produced noteworthy results for the DJIA and the eight
other stocks, achieving accuracy levels surpassing 60%. The dataset is made
available at https://github.com/batking24/Huge-Stock-Dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bathini_S/0/1/0/all/0/1&quot;&gt;Sai Akash Bathini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cihan_D/0/1/0/all/0/1&quot;&gt;Dagli Cihan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.00042">
<title>DeepTreeGANv2: Iterative Pooling of Point Clouds. (arXiv:2312.00042v2 [physics.data-an] UPDATED)</title>
<link>http://arxiv.org/abs/2312.00042</link>
<description rdf:parseType="Literal">&lt;p&gt;In High Energy Physics, detailed and time-consuming simulations are used for
particle interactions with detectors. To bypass these simulations with a
generative model, the generation of large point clouds in a short time is
required, while the complex dependencies between the particles must be
correctly modelled. Particle showers are inherently tree-based processes, as
each particle is produced by the decay or detector interaction of a particle of
the previous generation. In this work, we present a significant extension to
DeepTreeGAN, featuring a critic, that is able to aggregate such point clouds
iteratively in a tree-based manner. We show that this model can reproduce
complex distributions, and we evaluate its performance on the public JetNet 150
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Scham_M/0/1/0/all/0/1&quot;&gt;Moritz Alfons Wilhelm Scham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Krucker_D/0/1/0/all/0/1&quot;&gt;Dirk Kr&amp;#xfc;cker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Borras_K/0/1/0/all/0/1&quot;&gt;Kerstin Borras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.01187">
<title>SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer. (arXiv:2312.01187v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2312.01187</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning relies heavily on data augmentation to extract
meaningful representations from unlabeled images. While existing
state-of-the-art augmentation pipelines incorporate a wide range of primitive
transformations, these often disregard natural image structure. Thus, augmented
samples can exhibit degraded semantic information and low stylistic diversity,
affecting downstream performance of self-supervised representations. To
overcome this, we propose SASSL: Style Augmentations for Self Supervised
Learning, a novel augmentation technique based on Neural Style Transfer. The
method decouples semantic and stylistic attributes in images and applies
transformations exclusively to the style while preserving content, generating
diverse augmented samples that better retain their semantic properties.
Experimental results show our technique achieves a top-1 classification
performance improvement of more than 2% on ImageNet compared to the
well-established MoCo v2. We also measure transfer learning performance across
five diverse datasets, observing significant improvements of up to 3.75%. Our
experiments indicate that decoupling style from content information and
transferring style across datasets to diversify augmentations can significantly
improve downstream performance of self-supervised representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rojas_Gomez_R/0/1/0/all/0/1&quot;&gt;Renan A. Rojas-Gomez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhal_K/0/1/0/all/0/1&quot;&gt;Karan Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1&quot;&gt;Ali Etemad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bijamov_A/0/1/0/all/0/1&quot;&gt;Alex Bijamov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morningstar_W/0/1/0/all/0/1&quot;&gt;Warren R. Morningstar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mansfield_P/0/1/0/all/0/1&quot;&gt;Philip Andrew Mansfield&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.01479">
<title>OpenVoice: Versatile Instant Voice Cloning. (arXiv:2312.01479v5 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2312.01479</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce OpenVoice, a versatile voice cloning approach that requires only
a short audio clip from the reference speaker to replicate their voice and
generate speech in multiple languages. OpenVoice represents a significant
advancement in addressing the following open challenges in the field: 1)
Flexible Voice Style Control. OpenVoice enables granular control over voice
styles, including emotion, accent, rhythm, pauses, and intonation, in addition
to replicating the tone color of the reference speaker. The voice styles are
not directly copied from and constrained by the style of the reference speaker.
Previous approaches lacked the ability to flexibly manipulate voice styles
after cloning. 2) Zero-Shot Cross-Lingual Voice Cloning. OpenVoice achieves
zero-shot cross-lingual voice cloning for languages not included in the
massive-speaker training set. Unlike previous approaches, which typically
require extensive massive-speaker multi-lingual (MSML) dataset for all
languages, OpenVoice can clone voices into a new language without any
massive-speaker training data for that language. OpenVoice is also
computationally efficient, costing tens of times less than commercially
available APIs that offer even inferior performance. To foster further research
in the field, we have made the source code and trained model publicly
accessible. We also provide qualitative results in our demo website. Prior to
its public release, our internal version of OpenVoice was used tens of millions
of times by users worldwide between May and October 2023, serving as the
backend of MyShell.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1&quot;&gt;Zengyi Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wenliang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xumin Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xin Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04021">
<title>A Study on the Calibration of In-context Learning. (arXiv:2312.04021v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2312.04021</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate uncertainty quantification is crucial for the safe deployment of
language models (LMs), and prior research has demonstrated improvements in the
calibration of modern LMs. Our study focuses on in-context learning (ICL), a
prevalent method for adapting static LMs through tailored prompts, and examines
the balance between performance and calibration across a broad spectrum of
natural language understanding and reasoning tasks. Through comprehensive
experiments, we observe that, with an increasing number of ICL examples, models
initially exhibit increased miscalibration before achieving better calibration
and miscalibration tends to arise in low-shot settings. Moreover, we find that
methods aimed at improving usability, such as fine-tuning and chain-of-thought
(CoT) prompting, can lead to miscalibration and unreliable natural language
explanations, suggesting that new methods may be required for scenarios where
models are expected to be reliable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hanlin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yi-Fan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1&quot;&gt;Dhruv Madeka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1&quot;&gt;Dean Foster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1&quot;&gt;Himabindu Lakkaraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.04469">
<title>On the Learnability of Watermarks for Language Models. (arXiv:2312.04469v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.04469</link>
<description rdf:parseType="Literal">&lt;p&gt;Watermarking of language model outputs enables statistical detection of
model-generated text, which has many applications in the responsible deployment
of language models. Existing watermarking strategies operate by altering the
decoder of an existing language model, and the ability for a language model to
directly learn to generate the watermark would have significant implications
for the real-world deployment of watermarks. First, learned watermarks could be
used to build open models that naturally generate watermarked text, allowing
for open models to benefit from watermarking. Second, if watermarking is used
to determine the provenance of generated text, an adversary can hurt the
reputation of a victim model by spoofing its watermark and generating damaging
watermarked text. To investigate the learnability of watermarks, we propose
watermark distillation, which trains a student model to behave like a teacher
model that uses decoding-based watermarking. We test our approach on three
distinct decoding-based watermarking strategies and various hyperparameter
settings, finding that models can learn to generate watermarked text with high
detectability. We also find limitations to learnability, including the loss of
watermarking capabilities under fine-tuning on normal text and high sample
complexity when learning low-distortion watermarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_C/0/1/0/all/0/1&quot;&gt;Chenchen Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Lisa Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1&quot;&gt;Tatsunori Hashimoto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.05332">
<title>Bridging the Gaps: Learning Verifiable Model-Free Quadratic Programming Controllers Inspired by Model Predictive Control. (arXiv:2312.05332v3 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2312.05332</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a new class of parameterized controllers, drawing
inspiration from Model Predictive Control (MPC). The controller resembles a
Quadratic Programming (QP) solver of a linear MPC problem, with the parameters
of the controller being trained via Deep Reinforcement Learning (DRL) rather
than derived from system models. This approach addresses the limitations of
common controllers with Multi-Layer Perceptron (MLP) or other general neural
network architecture used in DRL, in terms of verifiability and performance
guarantees, and the learned controllers possess verifiable properties like
persistent feasibility and asymptotic stability akin to MPC. On the other hand,
numerical examples illustrate that the proposed controller empirically matches
MPC and MLP controllers in terms of control performance and has superior
robustness against modeling uncertainty and noises. Furthermore, the proposed
controller is significantly more computationally efficient compared to MPC and
requires fewer parameters to learn than MLP controllers. Real-world experiments
on vehicle drift maneuvering task demonstrate the potential of these
controllers for robotics and other demanding control tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yiwen Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zishuo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yihan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_N/0/1/0/all/0/1&quot;&gt;Na Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mo_Y/0/1/0/all/0/1&quot;&gt;Yilin Mo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.10144">
<title>Data-Efficient Multimodal Fusion on a Single GPU. (arXiv:2312.10144v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2312.10144</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of multimodal alignment is to learn a single latent space that is
shared between multimodal inputs. The most powerful models in this space have
been trained using massive datasets of paired inputs and large-scale
computational resources, making them prohibitively expensive to train in many
practical scenarios. We surmise that existing unimodal encoders pre-trained on
large amounts of unimodal data should provide an effective bootstrap to create
multimodal models from unimodal ones at much lower costs. We therefore propose
FuseMix, a multimodal augmentation scheme that operates on the latent spaces of
arbitrary pre-trained unimodal encoders. Using FuseMix for multimodal
alignment, we achieve competitive performance -- and in certain cases
outperform state-of-the art methods -- in both image-text and audio-text
retrieval, with orders of magnitude less compute and data: for example, we
outperform CLIP on the Flickr30K text-to-image retrieval task with $\sim \!
600\times$ fewer GPU days and $\sim \! 80\times$ fewer image-text pairs.
Additionally, we show how our method can be applied to convert pre-trained
text-to-image generative models into audio-to-image ones. Code is available at:
https://github.com/layer6ai-labs/fusemix.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vouitsis_N/0/1/0/all/0/1&quot;&gt;No&amp;#xeb;l Vouitsis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhaoyan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorti_S/0/1/0/all/0/1&quot;&gt;Satya Krishna Gorti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villecroze_V/0/1/0/all/0/1&quot;&gt;Valentin Villecroze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cresswell_J/0/1/0/all/0/1&quot;&gt;Jesse C. Cresswell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1&quot;&gt;Guangwei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loaiza_Ganem_G/0/1/0/all/0/1&quot;&gt;Gabriel Loaiza-Ganem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volkovs_M/0/1/0/all/0/1&quot;&gt;Maksims Volkovs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.11460">
<title>Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response. (arXiv:2312.11460v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2312.11460</link>
<description rdf:parseType="Literal">&lt;p&gt;Robust locomotion control depends on accurate state estimations. However, the
sensors of most legged robots can only provide partial and noisy observations,
making the estimation particularly challenging, especially for external states
like terrain frictions and elevation maps. Inspired by the classical Internal
Model Control principle, we consider these external states as disturbances and
introduce Hybrid Internal Model (HIM) to estimate them according to the
response of the robot. The response, which we refer to as the hybrid internal
embedding, contains the robot&apos;s explicit velocity and implicit stability
representation, corresponding to two primary goals for locomotion tasks:
explicitly tracking velocity and implicitly maintaining stability. We use
contrastive learning to optimize the embedding to be close to the robot&apos;s
successor state, in which the response is naturally embedded. HIM has several
appealing benefits: It only needs the robot&apos;s proprioceptions, i.e., those from
joint encoders and IMU as observations. It innovatively maintains consistent
observations between simulation reference and reality that avoids information
loss in mimicking learning. It exploits batch-level information that is more
robust to noises and keeps better sample efficiency. It only requires 1 hour of
training on an RTX 4090 to enable a quadruped robot to traverse any terrain
under any disturbances. A wealth of real-world experiments demonstrates its
agility, even in high-difficulty tasks and cases never occurred during the
training process, revealing remarkable open-world generalizability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1&quot;&gt;Junfeng Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zirui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Quanyi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jiawei Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1&quot;&gt;Liu Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1&quot;&gt;Jiangmiao Pang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.12028">
<title>EyePreserve: Identity-Preserving Iris Synthesis. (arXiv:2312.12028v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2312.12028</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthesis of same-identity biometric iris images, both for existing and
non-existing identities while preserving the identity across a wide range of
pupil sizes, is complex due to intricate iris muscle constriction mechanism,
requiring a precise model of iris non-linear texture deformations to be
embedded into the synthesis pipeline. This paper presents the first method of
fully data-driven, identity-preserving, pupil size-varying s ynthesis of iris
images. This approach is capable of synthesizing images of irises with
different pupil sizes representing non-existing identities as well as
non-linearly deforming the texture of iris images of existing subjects given
the segmentation mask of the target iris image. Iris recognition experiments
suggest that the proposed deformation model not only preserves the identity
when changing the pupil size but offers better similarity between same-identity
iris samples with significant differences in pupil size, compared to
state-of-the-art linear and non-linear (bio-mechanical-based) iris deformation
models. Two immediate applications of the proposed approach are: (a) synthesis
of, or enhancement of the existing biometric datasets for iris recognition,
mimicking those acquired with iris sensors, and (b) helping forensic human
experts in examining iris image pairs with significant differences in pupil
dilation. Source codes and weights of the models are made available with the
paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Siamul Karim Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tinsley_P/0/1/0/all/0/1&quot;&gt;Patrick Tinsley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitcheff_M/0/1/0/all/0/1&quot;&gt;Mahsa Mitcheff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flynn_P/0/1/0/all/0/1&quot;&gt;Patrick Flynn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bowyer_K/0/1/0/all/0/1&quot;&gt;Kevin W. Bowyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czajka_A/0/1/0/all/0/1&quot;&gt;Adam Czajka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.17300">
<title>Improving Intrusion Detection with Domain-Invariant Representation Learning in Latent Space. (arXiv:2312.17300v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2312.17300</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain generalization focuses on leveraging knowledge from multiple related
domains with ample training data and labels to enhance inference on unseen
in-distribution (IN) and out-of-distribution (OOD) domains. In our study, we
introduce a two-phase representation learning technique using multi-task
learning. This approach aims to cultivate a latent space from features spanning
multiple domains, encompassing both native and cross-domains, to amplify
generalization to IN and OOD territories. Additionally, we attempt to
disentangle the latent space by minimizing the mutual information between the
prior and latent space, effectively de-correlating spurious feature
correlations. Collectively, the joint optimization will facilitate
domain-invariant feature learning. We assess the model&apos;s efficacy across
multiple cybersecurity datasets, using standard classification metrics on both
unseen IN and OOD sets, and juxtapose the results with contemporary domain
generalization methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_P/0/1/0/all/0/1&quot;&gt;Padmaksha Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cody_T/0/1/0/all/0/1&quot;&gt;Tyler Cody&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhal_H/0/1/0/all/0/1&quot;&gt;Himanshu Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1&quot;&gt;Kevin Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1&quot;&gt;Ming Jin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2312.17353">
<title>Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach. (arXiv:2312.17353v2 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2312.17353</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces Auto-modeling of Formal Verification with Real-world
Prompting for 5G and NextG protocols (AVRE), a novel system designed for the
formal verification of Next Generation (NextG) communication protocols,
addressing the increasing complexity and scalability challenges in network
protocol design and verification. Utilizing Large Language Models (LLMs), AVRE
transforms protocol descriptions into dependency graphs and formal models,
efficiently resolving ambiguities and capturing design intent. The system
integrates a transformer model with LLMs to autonomously establish quantifiable
dependency relationships through cross- and self-attention mechanisms. Enhanced
by iterative feedback from the HyFuzz experimental platform, AVRE significantly
advances the accuracy and relevance of formal verification in complex
communication protocols, offering a groundbreaking approach to validating
sophisticated communication systems. We compare CAL&apos;s performance with
state-of-the-art LLM-based models and traditional time sequence models,
demonstrating its superiority in accuracy and robustness, achieving an accuracy
of 95.94\% and an AUC of 0.98. This NLP-based approach enables, for the first
time, the creation of exploits directly from design documents, making
remarkable progress in scalable system verification and validation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jingda Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Ying Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00544">
<title>A Reliable Knowledge Processing Framework for Combustion Science using Foundation Models. (arXiv:2401.00544v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2401.00544</link>
<description rdf:parseType="Literal">&lt;p&gt;This research explores the integration of large language models (LLMs) into
scientific data assimilation, focusing on combustion science as a case study.
Leveraging foundational models integrated with Retrieval-Augmented Generation
(RAG) framework, the study introduces an approach to process diverse combustion
research data, spanning experimental studies, simulations, and literature. The
multifaceted nature of combustion research emphasizes the critical role of
knowledge processing in navigating and extracting valuable information from a
vast and diverse pool of sources. The developed approach minimizes
computational and economic expenses while optimizing data privacy and accuracy.
It incorporates prompt engineering and offline open-source LLMs, offering user
autonomy in selecting base models. The study provides a thorough examination of
text segmentation strategies, conducts comparative studies between LLMs, and
explores various optimized prompts to demonstrate the effectiveness of the
framework. By incorporating an external database, the framework outperforms a
conventional LLM in generating accurate responses and constructing robust
arguments. Additionally, the study delves into the investigation of optimized
prompt templates for the purpose of efficient extraction of scientific
literature. The research addresses concerns related to hallucinations and false
research articles by introducing a custom workflow developed with a detection
algorithm to filter out inaccuracies. Despite identified areas for improvement,
the framework consistently delivers accurate domain-specific responses with
minimal human oversight. The prompt-agnostic approach introduced holds promise
for future deliberations. The study underscores the significance of integrating
LLMs and knowledge processing techniques in scientific research, providing a
foundation for advancements in data assimilation and utilization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1&quot;&gt;Vansh Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raman_V/0/1/0/all/0/1&quot;&gt;Venkat Raman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00713">
<title>A Survey on Graph Neural Networks in Intelligent Transportation Systems. (arXiv:2401.00713v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2401.00713</link>
<description rdf:parseType="Literal">&lt;p&gt;Intelligent Transportation System (ITS) is vital in improving traffic
congestion, reducing traffic accidents, optimizing urban planning, etc.
However, due to the complexity of the traffic network, traditional machine
learning and statistical methods are relegated to the background. With the
advent of the artificial intelligence era, many deep learning frameworks have
made remarkable progress in various fields and are now considered effective
methods in many areas. As a deep learning method, Graph Neural Networks (GNNs)
have emerged as a highly competitive method in the ITS field since 2019 due to
their strong ability to model graph-related problems. As a result, more and
more scholars pay attention to the applications of GNNs in transportation
domains, which have shown excellent performance. However, most of the research
in this area is still concentrated on traffic forecasting, while other ITS
domains, such as autonomous vehicles and urban planning, still require more
attention. This paper aims to review the applications of GNNs in six
representative and emerging ITS domains: traffic forecasting, autonomous
vehicles, traffic signal control, transportation safety, demand prediction, and
parking management. We have reviewed extensive graph-related studies from 2018
to 2023, summarized their methods, features, and contributions, and presented
them in informative tables or lists. Finally, we have identified the challenges
of applying GNNs to ITS and suggested potential future directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hourun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yusheng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1&quot;&gt;Zhengyang Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1&quot;&gt;Yifang Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1&quot;&gt;Zhiping Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jiaqi Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1&quot;&gt;Yiyang Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ju_W/0/1/0/all/0/1&quot;&gt;Wei Ju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Ming Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2401.00744">
<title>Harmonizing Covariance and Expressiveness for Deep Hamiltonian Regression in Crystalline Material Research: a Hybrid Cascaded Regression Framework. (arXiv:2401.00744v2 [physics.comp-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2401.00744</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning for Hamiltonian regression of quantum systems in material
research necessitates satisfying the covariance laws, among which achieving
SO(3)-equivariance without sacrificing the expressiveness of networks remains
an elusive challenge due to the restriction to non-linear mappings on
guaranteeing theoretical equivariance. To alleviate the
covariance-expressiveness dilemma, we propose a hybrid framework with two
cascaded regression stages. The first stage, with a theoretically-guaranteed
covariant neural network modeling symmetry properties of 3D atom systems,
yields theoretically covariant features and baseline Hamiltonian predictions,
assisting the second stage in learning covariance. Meanwhile, the second stage,
powered by a non-linear 3D graph Transformer network we propose for structural
modeling of 3D atomic systems, refines the first stage&apos;s output as a
fine-grained prediction of Hamiltonians with better expressiveness capability.
The combination of a theoretically covariant yet inevitably less expressive
model with a highly expressive non-linear network enables precise,
generalizable predictions while maintaining robust covariance under coordinate
transformations. Our method achieves state-of-the-art performance in
Hamiltonian prediction for electronic structure calculations, confirmed through
experiments on five crystalline material databases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yin_S/0/1/0/all/0/1&quot;&gt;Shi Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xudong Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Tianyu Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haochong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Feng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Lixin He&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>