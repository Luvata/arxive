<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-08-08T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03763" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03772" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03773" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03782" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03792" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03793" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03800" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03805" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03807" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03810" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03811" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03812" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03813" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03818" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03819" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03821" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03825" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03842" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03854" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03869" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03873" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03882" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03883" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03887" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03888" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03892" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03894" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03901" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03904" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03905" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03907" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03908" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03915" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03928" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03944" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03945" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03953" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03956" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03960" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03977" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03985" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03995" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03999" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04011" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04014" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04018" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04024" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04037" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04051" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04052" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04060" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04061" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04070" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04071" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04073" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04077" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04082" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04102" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04103" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04119" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04126" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04137" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04169" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04180" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04185" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04212" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04220" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04237" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04263" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04268" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04275" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04304" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04314" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04332" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04341" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04373" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04375" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04395" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04396" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04404" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04406" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04412" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04417" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04419" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04426" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04428" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04430" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04431" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1910.06832" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2006.06926" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2101.08130" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2105.02796" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.03159" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2111.10275" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.04629" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2204.01248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.01186" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2206.11004" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2207.07271" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.05785" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.14915" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.07774" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.07909" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.04780" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.00790" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.05609" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.10227" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.00195" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.01075" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.10331" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.14353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.00286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.00500" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.16459" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.16565" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.08134" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.01160" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.02640" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.12522" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18651" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.19259" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.08325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.09345" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.03571" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.07873" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08496" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.10579" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.11661" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.12344" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.12450" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.00824" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02013" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02582" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.02632" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03629" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03735" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.00085" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2308.03763">
<title>Applications of Machine Learning to Modelling and Analysing Dynamical Systems. (arXiv:2308.03763v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03763</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the use of Physics Informed Neural Networks to analyse nonlinear
Hamiltonian Dynamical Systems with a first integral of motion. In this work, we
propose an architecture which combines existing Hamiltonian Neural Network
structures into Adaptable Symplectic Recurrent Neural Networks which preserve
Hamilton&apos;s equations as well as the symplectic structure of phase space while
predicting dynamics for the entire parameter space. This architecture is found
to significantly outperform previously proposed neural networks when predicting
Hamiltonian dynamics especially in potentials which contain multiple
parameters. We demonstrate its robustness using the nonlinear Henon-Heiles
potential under chaotic, quasiperiodic and periodic conditions.
&lt;/p&gt;
&lt;p&gt;The second problem we tackle is whether we can use the high dimensional
nonlinear capabilities of neural networks to predict the dynamics of a
Hamiltonian system given only partial information of the same. Hence we attempt
to take advantage of Long Short Term Memory networks to implement Takens&apos;
embedding theorem and construct a delay embedding of the system followed by
mapping the topologically invariant attractor to the true form. This
architecture is then layered with Adaptable Symplectic nets to allow for
predictions which preserve the structure of Hamilton&apos;s equations. We show that
this method works efficiently for single parameter potentials and provides
accurate predictions even over long periods of time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thapar_V/0/1/0/all/0/1&quot;&gt;Vedanta Thapar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03772">
<title>Improved Neural Radiance Fields Using Pseudo-depth and Fusion. (arXiv:2308.03772v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.03772</link>
<description rdf:parseType="Literal">&lt;p&gt;Since the advent of Neural Radiance Fields, novel view synthesis has received
tremendous attention. The existing approach for the generalization of radiance
field reconstruction primarily constructs an encoding volume from nearby source
images as additional inputs. However, these approaches cannot efficiently
encode the geometric information of real scenes with various scale
objects/structures. In this work, we propose constructing multi-scale encoding
volumes and providing multi-scale geometry information to NeRF models. To make
the constructed volumes as close as possible to the surfaces of objects in the
scene and the rendered depth more accurate, we propose to perform depth
prediction and radiance field reconstruction simultaneously. The predicted
depth map will be used to supervise the rendered depth, narrow the depth range,
and guide points sampling. Finally, the geometric information contained in
point volume features may be inaccurate due to occlusion, lighting, etc. To
this end, we propose enhancing the point volume feature from depth-guided
neighbor feature fusion. Experiments demonstrate the superior performance of
our method in both novel view synthesis and dense geometry modeling without
per-scene optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jingliang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1&quot;&gt;Qiang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1&quot;&gt;Chaohui Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhengda Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1&quot;&gt;Jun Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhibin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03773">
<title>Goodness-of-Fit of Attributed Probabilistic Graph Generative Models. (arXiv:2308.03773v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03773</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic generative models of graphs are important tools that enable
representation and sampling. Many recent works have created probabilistic
models of graphs that are capable of representing not only entity interactions
but also their attributes. However, given a generative model of random
attributed graph(s), the general conditions that establish goodness of fit are
not clear a-priori. In this paper, we define goodness of fit in terms of the
mean square contingency coefficient for random binary networks. For this
statistic, we outline a procedure for assessing the quality of the structure of
a learned attributed graph by ensuring that the discrepancy of the mean square
contingency coefficient (constant, or random) is minimal with high probability.
We apply these criteria to verify the representation capability of a
probabilistic generative model for various popular types of graph models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robles_Granda_P/0/1/0/all/0/1&quot;&gt;Pablo Robles-Granda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsai_K/0/1/0/all/0/1&quot;&gt;Katherine Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1&quot;&gt;Oluwasanmi Koyejo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03782">
<title>Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction. (arXiv:2308.03782v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.03782</link>
<description rdf:parseType="Literal">&lt;p&gt;The objective of this study is to develop natural language processing (NLP)
models that can analyze patients&apos; drug reviews and accurately classify their
satisfaction levels as positive, neutral, or negative. Such models would reduce
the workload of healthcare professionals and provide greater insight into
patients&apos; quality of life, which is a critical indicator of treatment
effectiveness. To achieve this, we implemented and evaluated several
classification models, including a BERT base model, Bio+Clinical BERT, and a
simpler CNN. Results indicate that the medical domain-specific Bio+Clinical
BERT model significantly outperformed the general domain base BERT model,
achieving macro f1 and recall score improvement of 11%, as shown in Table 2.
Future research could explore how to capitalize on the specific strengths of
each model. Bio+Clinical BERT excels in overall performance, particularly with
medical jargon, while the simpler CNN demonstrates the ability to identify
crucial words and accurately classify sentiment in texts with conflicting
sentiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_Y/0/1/0/all/0/1&quot;&gt;Yue Ling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03792">
<title>Multi-attacks: Many images $+$ the same adversarial attack $\to$ many target labels. (arXiv:2308.03792v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.03792</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that we can easily design a single adversarial perturbation $P$ that
changes the class of $n$ images $X_1,X_2,\dots,X_n$ from their original,
unperturbed classes $c_1, c_2,\dots,c_n$ to desired (not necessarily all the
same) classes $c^*_1,c^*_2,\dots,c^*_n$ for up to hundreds of images and target
classes at once. We call these \textit{multi-attacks}. Characterizing the
maximum $n$ we can achieve under different conditions such as image resolution,
we estimate the number of regions of high class confidence around a particular
image in the space of pixels to be around $10^{\mathcal{O}(100)}$, posing a
significant problem for exhaustive defense strategies. We show several
immediate consequences of this: adversarial attacks that change the resulting
class based on their intensity, and scale-independent adversarial examples. To
demonstrate the redundancy and richness of class decision boundaries in the
pixel space, we look for its two-dimensional sections that trace images and
spell words using particular classes. We also show that ensembling reduces
susceptibility to multi-attacks, and that classifiers trained on random labels
are more susceptible. Our code is available on GitHub.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fort_S/0/1/0/all/0/1&quot;&gt;Stanislav Fort&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03793">
<title>ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation. (arXiv:2308.03793v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.03793</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale Pre-Training Vision-Language Model such as CLIP has demonstrated
outstanding performance in zero-shot classification, e.g. achieving 76.3% top-1
accuracy on ImageNet without seeing any example, which leads to potential
benefits to many tasks that have no labeled data. However, while applying CLIP
to a downstream target domain, the presence of visual and text domain gaps and
cross-modality misalignment can greatly impact the model performance. To
address such challenges, we propose ReCLIP, the first source-free domain
adaptation method for vision-language models, which does not require any source
data or target labeled data. ReCLIP first learns a projection space to mitigate
the misaligned visual-text embeddings and learns pseudo labels, and then
deploys cross-modality self-training with the pseudo labels, to update visual
and text encoders, refine labels and reduce domain gaps and misalignments
iteratively. With extensive experiments, we demonstrate ReCLIP reduces the
average error rate of CLIP from 30.17% to 25.06% on 22 image classification
benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xuefeng_H/0/1/0/all/0/1&quot;&gt;Hu. Xuefeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_Z/0/1/0/all/0/1&quot;&gt;Zhang. Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1&quot;&gt;Xia. Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albert_C/0/1/0/all/0/1&quot;&gt;Chen. Albert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiajia_L/0/1/0/all/0/1&quot;&gt;Luo. Jiajia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuyin_S/0/1/0/all/0/1&quot;&gt;Sun. Yuyin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ken_W/0/1/0/all/0/1&quot;&gt;Wang. Ken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nan_Q/0/1/0/all/0/1&quot;&gt;Qiao. Nan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1&quot;&gt;Zeng. Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1&quot;&gt;Sun. Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Hao_K/0/1/0/all/0/1&quot;&gt;Kuo. Cheng-Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ram_N/0/1/0/all/0/1&quot;&gt;Nevatia. Ram&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03800">
<title>Textual Data Mining for Financial Fraud Detection: A Deep Learning Approach. (arXiv:2308.03800v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.03800</link>
<description rdf:parseType="Literal">&lt;p&gt;In this report, I present a deep learning approach to conduct a natural
language processing (hereafter NLP) binary classification task for analyzing
financial-fraud texts. First, I searched for regulatory announcements and
enforcement bulletins from HKEX news to define fraudulent companies and to
extract their MD&amp;amp;A reports before I organized the sentences from the reports
with labels and reporting time. My methodology involved different kinds of
neural network models, including Multilayer Perceptrons with Embedding layers,
vanilla Recurrent Neural Network (RNN), Long-Short Term Memory (LSTM), and
Gated Recurrent Unit (GRU) for the text classification task. By utilizing this
diverse set of models, I aim to perform a comprehensive comparison of their
accuracy in detecting financial fraud. My results bring significant
implications for financial fraud detection as this work contributes to the
growing body of research at the intersection of deep learning, NLP, and
finance, providing valuable insights for industry practitioners, regulators,
and researchers in the pursuit of more robust and effective fraud detection
methodologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qiuru Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03805">
<title>Weakly Supervised Multi-Task Representation Learning for Human Activity Analysis Using Wearables. (arXiv:2308.03805v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03805</link>
<description rdf:parseType="Literal">&lt;p&gt;Sensor data streams from wearable devices and smart environments are widely
studied in areas like human activity recognition (HAR), person identification,
or health monitoring. However, most of the previous works in activity and
sensor stream analysis have been focusing on one aspect of the data, e.g. only
recognizing the type of the activity or only identifying the person who
performed the activity. We instead propose an approach that uses a weakly
supervised multi-output siamese network that learns to map the data into
multiple representation spaces, where each representation space focuses on one
aspect of the data. The representation vectors of the data samples are
positioned in the space such that the data with the same semantic meaning in
that aspect are closely located to each other. Therefore, as demonstrated with
a set of experiments, the trained model can provide metrics for clustering data
based on multiple aspects, allowing it to address multiple tasks simultaneously
and even to outperform single task supervised methods in many situations. In
addition, further experiments are presented that in more detail analyze the
effect of the architecture and of using multiple tasks within this framework,
that investigate the scalability of the model to include additional tasks, and
that demonstrate the ability of the framework to combine data for which only
partial relationship information with respect to the target tasks is available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_T/0/1/0/all/0/1&quot;&gt;Taoran Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huber_M/0/1/0/all/0/1&quot;&gt;Manfred Huber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03807">
<title>Nest-DGIL: Nesterov-optimized Deep Geometric Incremental Learning for CS Image Reconstruction. (arXiv:2308.03807v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2308.03807</link>
<description rdf:parseType="Literal">&lt;p&gt;Proximal gradient-based optimization is one of the most common strategies for
solving image inverse problems as well as easy to implement. However, these
techniques often generate heavy artifacts in image reconstruction. One of the
most popular refinement methods is to fine-tune the regularization parameter to
alleviate such artifacts, but it may not always be sufficient or applicable due
to increased computational costs. In this work, we propose a deep geometric
incremental learning framework based on second Nesterov proximal gradient
optimization. The proposed end-to-end network not only has the powerful
learning ability for high/low frequency image features,but also can
theoretically guarantee that geometric texture details will be reconstructed
from preliminary linear reconstruction.Furthermore, it can avoid the risk of
intermediate reconstruction results falling outside the geometric decomposition
domains and achieve fast convergence. Our reconstruction framework is
decomposed into four modules including general linear reconstruction, cascade
geometric incremental restoration, Nesterov acceleration and post-processing.
In the image restoration step,a cascade geometric incremental learning module
is designed to compensate for the missing texture information from different
geometric spectral decomposition domains. Inspired by overlap-tile strategy, we
also develop a post-processing module to remove the block-effect in
patch-wise-based natural image reconstruction. All parameters in the proposed
model are learnable,an adaptive initialization technique of physical-parameters
is also employed to make model flexibility and ensure converging smoothly. We
compare the reconstruction performance of the proposed method with existing
state-of-the-art methods to demonstrate its superiority. Our source codes are
available at https://github.com/fanxiaohong/Nest-DGIL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fan_X/0/1/0/all/0/1&quot;&gt;Xiaohong Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Ke Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yujie Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianping Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03810">
<title>AdaER: An Adaptive Experience Replay Approach for Continual Lifelong Learning. (arXiv:2308.03810v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03810</link>
<description rdf:parseType="Literal">&lt;p&gt;Continual lifelong learning is an machine learning framework inspired by
human learning, where learners are trained to continuously acquire new
knowledge in a sequential manner. However, the non-stationary nature of
streaming training data poses a significant challenge known as catastrophic
forgetting, which refers to the rapid forgetting of previously learned
knowledge when new tasks are introduced. While some approaches, such as
experience replay (ER), have been proposed to mitigate this issue, their
performance remains limited, particularly in the class-incremental scenario
which is considered natural and highly challenging. In this paper, we present a
novel algorithm, called adaptive-experience replay (AdaER), to address the
challenge of continual lifelong learning. AdaER consists of two stages: memory
replay and memory update. In the memory replay stage, AdaER introduces a
contextually-cued memory recall (C-CMR) strategy, which selectively replays
memories that are most conflicting with the current input data in terms of both
data and task. Additionally, AdaER incorporates an entropy-balanced reservoir
sampling (E-BRS) strategy to enhance the performance of the memory buffer by
maximizing information entropy. To evaluate the effectiveness of AdaER, we
conduct experiments on established supervised continual lifelong learning
benchmarks, specifically focusing on class-incremental learning scenarios. The
results demonstrate that AdaER outperforms existing continual lifelong learning
baselines, highlighting its efficacy in mitigating catastrophic forgetting and
improving learning performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xingyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1&quot;&gt;Bo Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haifeng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03811">
<title>Non-Convex Bilevel Optimization with Time-Varying Objective Functions. (arXiv:2308.03811v1 [math.OC])</title>
<link>http://arxiv.org/abs/2308.03811</link>
<description rdf:parseType="Literal">&lt;p&gt;Bilevel optimization has become a powerful tool in a wide variety of machine
learning problems. However, the current nonconvex bilevel optimization
considers an offline dataset and static functions, which may not work well in
emerging online applications with streaming data and time-varying functions. In
this work, we study online bilevel optimization (OBO) where the functions can
be time-varying and the agent continuously updates the decisions with online
streaming data. To deal with the function variations and the unavailability of
the true hypergradients in OBO, we propose a single-loop online bilevel
optimizer with window averaging (SOBOW), which updates the outer-level decision
based on a window average of the most recent hypergradient estimations stored
in the memory. Compared to existing algorithms, SOBOW is computationally
efficient and does not need to know previous functions. To handle the unique
technical difficulties rooted in single-loop update and function variations for
OBO, we develop a novel analytical technique that disentangles the complex
couplings between decision variables, and carefully controls the hypergradient
estimation error. We show that SOBOW can achieve a sublinear bilevel local
regret under mild conditions. Extensive experiments across multiple domains
corroborate the effectiveness of SOBOW.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Sen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sow_D/0/1/0/all/0/1&quot;&gt;Daouda Sow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ji_K/0/1/0/all/0/1&quot;&gt;Kaiyi Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yingbin Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shroff_N/0/1/0/all/0/1&quot;&gt;Ness Shroff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03812">
<title>Noncompact uniform universal approximation. (arXiv:2308.03812v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03812</link>
<description rdf:parseType="Literal">&lt;p&gt;The universal approximation theorem is generalised to uniform convergence on
the (noncompact) input space $\mathbb R^n$. All continuous functions that
vanish at infinity can be uniformly approximated by neural networks with one
hidden layer, for all continuous activation functions $\varphi\neq0$ with
asymptotically linear behaviour at $\pm\infty$. When $\varphi$ is moreover
bounded, we exactly determine which functions can be uniformly approximated by
neural networks, with the following unexpected results. Let
$\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}$ denote the vector space of
functions that are uniformly approximable by neural networks with $l$ hidden
layers and $n$ inputs. For all $n$ and all $l\geq2$,
$\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}$ turns out to be an algebra
under the pointwise product. If the left limit of $\varphi$ differs from its
right limit (for instance, when $\varphi$ is sigmoidal) the algebra
$\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}$ ($l\geq2$) is independent of
$\varphi$ and $l$, and equals the closed span of products of sigmoids composed
with one-dimensional projections. If the left limit of $\varphi$ equals its
right limit, $\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}$ ($l\geq1$) equals
the (real part of the) commutative resolvent algebra, a C*-algebra which is
used in mathematical approaches to quantum theory. In the latter case, the
algebra is independent of $l\geq1$, whereas in the former case
$\overline{\mathcal{N}_\varphi^2(\mathbb R^n)}$ is strictly bigger than
$\overline{\mathcal{N}_\varphi^1(\mathbb R^n)}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nuland_T/0/1/0/all/0/1&quot;&gt;Teun D. H. van Nuland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03813">
<title>High-Resolution Cranial Defect Reconstruction by Iterative, Low-Resolution, Point Cloud Completion Transformers. (arXiv:2308.03813v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2308.03813</link>
<description rdf:parseType="Literal">&lt;p&gt;Each year thousands of people suffer from various types of cranial injuries
and require personalized implants whose manual design is expensive and
time-consuming. Therefore, an automatic, dedicated system to increase the
availability of personalized cranial reconstruction is highly desirable. The
problem of the automatic cranial defect reconstruction can be formulated as the
shape completion task and solved using dedicated deep networks. Currently, the
most common approach is to use the volumetric representation and apply deep
networks dedicated to image segmentation. However, this approach has several
limitations and does not scale well into high-resolution volumes, nor takes
into account the data sparsity. In our work, we reformulate the problem into a
point cloud completion task. We propose an iterative, transformer-based method
to reconstruct the cranial defect at any resolution while also being fast and
resource-efficient during training and inference. We compare the proposed
methods to the state-of-the-art volumetric approaches and show superior
performance in terms of GPU memory consumption while maintaining high-quality
of the reconstructed defects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wodzinski_M/0/1/0/all/0/1&quot;&gt;Marek Wodzinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Daniol_M/0/1/0/all/0/1&quot;&gt;Mateusz Daniol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hemmerling_D/0/1/0/all/0/1&quot;&gt;Daria Hemmerling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Socha_M/0/1/0/all/0/1&quot;&gt;Miroslaw Socha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03818">
<title>A sparse coding approach to inverse problems with application to microwave tomography imaging. (arXiv:2308.03818v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2308.03818</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse imaging problems that are ill-posed can be encountered across
multiple domains of science and technology, ranging from medical diagnosis to
astronomical studies. To reconstruct images from incomplete and distorted data,
it is necessary to create algorithms that can take into account both, the
physical mechanisms responsible for generating these measurements and the
intrinsic characteristics of the images being analyzed. In this work, the
sparse representation of images is reviewed, which is a realistic, compact and
effective generative model for natural images inspired by the visual system of
mammals. It enables us to address ill-posed linear inverse problems by training
the model on a vast collection of images. Moreover, we extend the application
of sparse coding to solve the non-linear and ill-posed problem in microwave
tomography imaging, which could lead to a significant improvement of the
state-of-the-arts algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Caiafa_C/0/1/0/all/0/1&quot;&gt;Cesar F. Caiafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Irastorza_R/0/1/0/all/0/1&quot;&gt;Ramiro M. Irastorza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03819">
<title>XFlow: Benchmarking Flow Behaviors over Graphs. (arXiv:2308.03819v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2308.03819</link>
<description rdf:parseType="Literal">&lt;p&gt;The occurrence of diffusion on a graph is a prevalent and significant
phenomenon, as evidenced by the spread of rumors, influenza-like viruses, smart
grid failures, and similar events. Comprehending the behaviors of flow is a
formidable task, due to the intricate interplay between the distribution of
seeds that initiate flow propagation, the propagation model, and the topology
of the graph. The study of networks encompasses a diverse range of academic
disciplines, including mathematics, physics, social science, and computer
science. This interdisciplinary nature of network research is characterized by
a high degree of specialization and compartmentalization, and the cooperation
facilitated by them is inadequate. From a machine learning standpoint, there is
a deficiency in a cohesive platform for assessing algorithms across various
domains. One of the primary obstacles to current research in this field is the
absence of a comprehensive curated benchmark suite to study the flow behaviors
under network scenarios.
&lt;/p&gt;
&lt;p&gt;To address this disparity, we propose the implementation of a novel benchmark
suite that encompasses a variety of tasks, baseline models, graph datasets, and
evaluation tools. In addition, we present a comprehensive analytical framework
that offers a generalized approach to numerous flow-related tasks across
diverse domains, serving as a blueprint and roadmap. Drawing upon the outcomes
of our empirical investigation, we analyze the advantages and disadvantages of
current foundational models, and we underscore potential avenues for further
study. The datasets, code, and baseline models have been made available for the
public at: https://github.com/XGraphing/XFlow
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zijian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zonghan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhiqian Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03821">
<title>Distributionally Robust Classification on a Data Budget. (arXiv:2308.03821v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.03821</link>
<description rdf:parseType="Literal">&lt;p&gt;Real world uses of deep learning require predictable model behavior under
distribution shifts. Models such as CLIP show emergent natural distributional
robustness comparable to humans, but may require hundreds of millions of
training samples. Can we train robust learners in a domain where data is
limited? To rigorously address this question, we introduce JANuS (Joint
Annotations and Names Set), a collection of four new training datasets with
images, labels, and corresponding captions, and perform a series of carefully
controlled investigations of factors contributing to robustness in image
classification, then compare those results to findings derived from a
large-scale meta-analysis. Using this approach, we show that standard ResNet-50
trained with the cross-entropy loss on 2.4 million image samples can attain
comparable robustness to a CLIP ResNet-50 trained on 400 million samples. To
our knowledge, this is the first result showing (near) state-of-the-art
distributional robustness on limited data budgets. Our dataset is available at
\url{https://huggingface.co/datasets/penfever/JANuS_dataset}, and the code used
to reproduce our experiments can be found at
\url{https://github.com/penfever/vlhub/}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feuer_B/0/1/0/all/0/1&quot;&gt;Benjamin Feuer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1&quot;&gt;Ameya Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_M/0/1/0/all/0/1&quot;&gt;Minh Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1&quot;&gt;Chinmay Hegde&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03825">
<title>&quot;Do Anything Now&quot;: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models. (arXiv:2308.03825v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2308.03825</link>
<description rdf:parseType="Literal">&lt;p&gt;The misuse of large language models (LLMs) has garnered significant attention
from the general public and LLM vendors. In response, efforts have been made to
align LLMs with human values and intent use. However, a particular type of
adversarial prompts, known as jailbreak prompt, has emerged and continuously
evolved to bypass the safeguards and elicit harmful content from LLMs. In this
paper, we conduct the first measurement study on jailbreak prompts in the wild,
with 6,387 prompts collected from four platforms over six months. Leveraging
natural language processing technologies and graph-based community detection
methods, we discover unique characteristics of jailbreak prompts and their
major attack strategies, such as prompt injection and privilege escalation. We
also observe that jailbreak prompts increasingly shift from public platforms to
private ones, posing new challenges for LLM vendors in proactive detection. To
assess the potential harm caused by jailbreak prompts, we create a question set
comprising 46,800 samples across 13 forbidden scenarios. Our experiments show
that current LLMs and safeguards cannot adequately defend jailbreak prompts in
all scenarios. Particularly, we identify two highly effective jailbreak prompts
which achieve 0.99 attack success rates on ChatGPT (GPT-3.5) and GPT-4, and
they have persisted online for over 100 days. Our work sheds light on the
severe and evolving threat landscape of jailbreak prompts. We hope our study
can facilitate the research community and LLM vendors in promoting safer and
regulated LLMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1&quot;&gt;Xinyue Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1&quot;&gt;Michael Backes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yun Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03842">
<title>Search Engine and Recommendation System for the Music Industry built with JinaAI. (arXiv:2308.03842v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03842</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the most intriguing debates regarding a novel task is the development
of search engines and recommendation-based systems in the music industry.
Studies have shown a drastic depression in the search engine fields, due to
concerning factors such as speed, accuracy and the format of data given for
querying. Often people face difficulty in searching for a song solely based on
the title, hence a solution is proposed to complete a search analysis through a
single query input and is matched with the lyrics of the songs present in the
database. Hence it is essential to incorporate cutting-edge technology tools
for developing a user-friendly search engine. Jina AI is an MLOps framework for
building neural search engines that are utilized, in order for the user to
obtain accurate results. Jina AI effectively helps to maintain and enhance the
quality of performance for the search engine for the query given. An effective
search engine and a recommendation system for the music industry, built with
JinaAI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalakrishnan_I/0/1/0/all/0/1&quot;&gt;Ishita Gopalakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+R_S/0/1/0/all/0/1&quot;&gt;Sanjjushri Varshini R&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+V_P/0/1/0/all/0/1&quot;&gt;Ponshriharini V&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03854">
<title>Revisiting Prompt Engineering via Declarative Crowdsourcing. (arXiv:2308.03854v1 [cs.DB])</title>
<link>http://arxiv.org/abs/2308.03854</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) are incredibly powerful at comprehending and
generating data in the form of text, but are brittle and error-prone. There has
been an advent of toolkits and recipes centered around so-called prompt
engineering-the process of asking an LLM to do something via a series of
prompts. However, for LLM-powered data processing workflows, in particular,
optimizing for quality, while keeping cost bounded, is a tedious, manual
process. We put forth a vision for declarative prompt engineering. We view LLMs
like crowd workers and leverage ideas from the declarative crowdsourcing
literature-including leveraging multiple prompting strategies, ensuring
internal consistency, and exploring hybrid-LLM-non-LLM approaches-to make
prompt engineering a more principled process. Preliminary case studies on
sorting, entity resolution, and imputation demonstrate the promise of our
approach
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parameswaran_A/0/1/0/all/0/1&quot;&gt;Aditya G. Parameswaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shankar_S/0/1/0/all/0/1&quot;&gt;Shreya Shankar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asawa_P/0/1/0/all/0/1&quot;&gt;Parth Asawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1&quot;&gt;Naman Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yujie Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03869">
<title>Semantic Equivalence of e-Commerce Queries. (arXiv:2308.03869v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2308.03869</link>
<description rdf:parseType="Literal">&lt;p&gt;Search query variation poses a challenge in e-commerce search, as equivalent
search intents can be expressed through different queries with surface-level
differences. This paper introduces a framework to recognize and leverage query
equivalence to enhance searcher and business outcomes. The proposed approach
addresses three key problems: mapping queries to vector representations of
search intent, identifying nearest neighbor queries expressing equivalent or
similar intent, and optimizing for user or business objectives. The framework
utilizes both surface similarity and behavioral similarity to determine query
equivalence. Surface similarity involves canonicalizing queries based on word
inflection, word order, compounding, and noise words. Behavioral similarity
leverages historical search behavior to generate vector representations of
query intent. An offline process is used to train a sentence similarity model,
while an online nearest neighbor approach supports processing of unseen
queries. Experimental evaluations demonstrate the effectiveness of the proposed
approach, outperforming popular sentence transformer models and achieving a
Pearson correlation of 0.85 for query similarity. The results highlight the
potential of leveraging historical behavior data and training models to
recognize and utilize query equivalence in e-commerce search, leading to
improved user experiences and business outcomes. Further advancements and
benchmark datasets are encouraged to facilitate the development of solutions
for this critical problem in the e-commerce domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandal_A/0/1/0/all/0/1&quot;&gt;Aritra Mandal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tunkelang_D/0/1/0/all/0/1&quot;&gt;Daniel Tunkelang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhe Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03873">
<title>Evaluating and Explaining Large Language Models for Code Using Syntactic Structures. (arXiv:2308.03873v1 [cs.SE])</title>
<link>http://arxiv.org/abs/2308.03873</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) for code are a family of high-parameter,
transformer-based neural networks pre-trained on massive datasets of both
natural and programming languages. These models are rapidly being employed in
commercial AI-based developer tools, such as GitHub CoPilot. However, measuring
and explaining their effectiveness on programming tasks is a challenging
proposition, given their size and complexity. The methods for evaluating and
explaining LLMs for code are inextricably linked. That is, in order to explain
a model&apos;s predictions, they must be reliably mapped to fine-grained,
understandable concepts. Once this mapping is achieved, new methods for
detailed model evaluations are possible. However, most current explainability
techniques and evaluation benchmarks focus on model robustness or individual
task performance, as opposed to interpreting model predictions.
&lt;/p&gt;
&lt;p&gt;To this end, this paper introduces ASTxplainer, an explainability method
specific to LLMs for code that enables both new methods for LLM evaluation and
visualizations of LLM predictions that aid end-users in understanding model
predictions. At its core, ASTxplainer provides an automated method for aligning
token predictions with AST nodes, by extracting and aggregating normalized
model logits within AST structures. To demonstrate the practical benefit of
ASTxplainer, we illustrate the insights that our framework can provide by
performing an empirical evaluation on 12 popular LLMs for code using a curated
dataset of the most popular GitHub projects. Additionally, we perform a user
study examining the usefulness of an ASTxplainer-derived visualization of model
predictions aimed at enabling model users to explain predictions. The results
of these studies illustrate the potential for ASTxplainer to provide insights
into LLM effectiveness, and aid end-users in understanding predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palacio_D/0/1/0/all/0/1&quot;&gt;David N Palacio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velasco_A/0/1/0/all/0/1&quot;&gt;Alejandro Velasco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_Cardenas_D/0/1/0/all/0/1&quot;&gt;Daniel Rodriguez-Cardenas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moran_K/0/1/0/all/0/1&quot;&gt;Kevin Moran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poshyvanyk_D/0/1/0/all/0/1&quot;&gt;Denys Poshyvanyk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03882">
<title>Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations. (arXiv:2308.03882v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03882</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline reinforcement learning (RL) methods strike a balance between
exploration and exploitation by conservative value estimation -- penalizing
values of unseen states and actions. Model-free methods penalize values at all
unseen actions, while model-based methods are able to further exploit unseen
states via model rollouts. However, such methods are handicapped in their
ability to find unseen states far away from the available offline data due to
two factors -- (a) very short rollout horizons in models due to cascading model
errors, and (b) model rollouts originating solely from states observed in
offline data. We relax the second assumption and present a novel unseen state
augmentation strategy to allow exploitation of unseen states where the learned
model and value estimates generalize. Our strategy finds unseen states by
value-informed perturbations of seen states followed by filtering out states
with epistemic uncertainty estimates too high (high error) or too low (too
similar to seen data). We observe improved performance in several offline RL
tasks and find that our augmentation strategy consistently leads to overall
lower average dataset Q-value estimates i.e. more conservative Q-value
estimates than a baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Modhe_N/0/1/0/all/0/1&quot;&gt;Nirbhay Modhe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1&quot;&gt;Qiaozi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1&quot;&gt;Ashwin Kalyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thattai_G/0/1/0/all/0/1&quot;&gt;Govind Thattai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1&quot;&gt;Gaurav Sukhatme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03883">
<title>Generative Benchmark Creation for Table Union Search. (arXiv:2308.03883v1 [cs.DB])</title>
<link>http://arxiv.org/abs/2308.03883</link>
<description rdf:parseType="Literal">&lt;p&gt;Data management has traditionally relied on synthetic data generators to
generate structured benchmarks, like the TPC suite, where we can control
important parameters like data size and its distribution precisely. These
benchmarks were central to the success and adoption of database management
systems. But more and more, data management problems are of a semantic nature.
An important example is finding tables that can be unioned. While any two
tables with the same cardinality can be unioned, table union search is the
problem of finding tables whose union is semantically coherent. Semantic
problems cannot be benchmarked using synthetic data. Our current methods for
creating benchmarks involve the manual curation and labeling of real data.
These methods are not robust or scalable and perhaps more importantly, it is
not clear how robust the created benchmarks are. We propose to use generative
AI models to create structured data benchmarks for table union search. We
present a novel method for using generative models to create tables with
specified properties. Using this method, we create a new benchmark containing
pairs of tables that are both unionable and non-unionable but related. We
thoroughly evaluate recent existing table union search methods over existing
benchmarks and our new benchmark. We also present and evaluate a new table
search methods based on recent large language models over all benchmarks. We
show that the new benchmark is more challenging for all methods than
hand-curated benchmarks, specifically, the top-performing method achieves a
Mean Average Precision of around 60%, over 30% less than its performance on
existing manually created benchmarks. We examine why this is the case and show
that the new benchmark permits more detailed analysis of methods, including a
study of both false positives and false negatives that were not possible with
existing benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_K/0/1/0/all/0/1&quot;&gt;Koyena Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khatiwada_A/0/1/0/all/0/1&quot;&gt;Aamod Khatiwada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shraga_R/0/1/0/all/0/1&quot;&gt;Roee Shraga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_R/0/1/0/all/0/1&quot;&gt;Ren&amp;#xe9;e J. Miller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03887">
<title>Enhancing Cell Tracking with a Time-Symmetric Deep Learning Approach. (arXiv:2308.03887v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2308.03887</link>
<description rdf:parseType="Literal">&lt;p&gt;The accurate tracking of live cells using video microscopy recordings remains
a challenging task for popular state-of-the-art image processing based object
tracking methods. In recent years, several existing and new applications have
attempted to integrate deep-learning based frameworks for this task, but most
of them still heavily rely on consecutive frame based tracking embedded in
their architecture or other premises that hinder generalized learning. To
address this issue, we aimed to develop a new deep-learning based tracking
method that relies solely on the assumption that cells can be tracked based on
their spatio-temporal neighborhood, without restricting it to consecutive
frames. The proposed method has the additional benefit that the motion patterns
of the cells can be learned completely by the predictor without any prior
assumptions, and it has the potential to handle a large number of video frames
with heavy artifacts. The efficacy of the proposed method is demonstrated
through multiple biologically motivated validation strategies and compared
against several state-of-the-art cell tracking methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Szabo_G/0/1/0/all/0/1&quot;&gt;Gergely Szab&amp;#xf3;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bonaiuti_P/0/1/0/all/0/1&quot;&gt;Paolo Bonaiuti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ciliberto_A/0/1/0/all/0/1&quot;&gt;Andrea Ciliberto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Horvath_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe1;s Horv&amp;#xe1;th&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03888">
<title>Deep neural networks from the perspective of ergodic theory. (arXiv:2308.03888v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03888</link>
<description rdf:parseType="Literal">&lt;p&gt;The design of deep neural networks remains somewhat of an art rather than
precise science. By tentatively adopting ergodic theory considerations on top
of viewing the network as the time evolution of a dynamical system, with each
layer corresponding to a temporal instance, we show that some rules of thumb,
which might otherwise appear mysterious, can be attributed heuristics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03892">
<title>Scalable and Equitable Math Problem Solving Strategy Prediction in Big Educational Data. (arXiv:2308.03892v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03892</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding a student&apos;s problem-solving strategy can have a significant
impact on effective math learning using Intelligent Tutoring Systems (ITSs) and
Adaptive Instructional Systems (AISs). For instance, the ITS/AIS can better
personalize itself to correct specific misconceptions that are indicated by
incorrect strategies, specific problems can be designed to improve strategies
and frustration can be minimized by adapting to a student&apos;s natural way of
thinking rather than trying to fit a standard strategy for all. While it may be
possible for human experts to identify strategies manually in classroom
settings with sufficient student interaction, it is not possible to scale this
up to big data. Therefore, we leverage advances in Machine Learning and AI
methods to perform scalable strategy prediction that is also fair to students
at all skill levels. Specifically, we develop an embedding called MVec where we
learn a representation based on the mastery of students. We then cluster these
embeddings with a non-parametric clustering method where we progressively learn
clusters such that we group together instances that have approximately
symmetrical strategies. The strategy prediction model is trained on instances
sampled from these clusters. This ensures that we train the model over diverse
strategies and also that strategies from a particular group do not bias the DNN
model, thus allowing it to optimize its parameters over all groups. Using real
world large-scale student interaction datasets from MATHia, we implement our
approach using transformers and Node2Vec for learning the mastery embeddings
and LSTMs for predicting strategies. We show that our approach can scale up to
achieve high accuracy by training on a small sample of a large dataset and also
has predictive equality, i.e., it can predict strategies equally well for
learners at diverse skill levels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shakya_A/0/1/0/all/0/1&quot;&gt;Anup Shakya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rus_V/0/1/0/all/0/1&quot;&gt;Vasile Rus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venugopal_D/0/1/0/all/0/1&quot;&gt;Deepak Venugopal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03894">
<title>A new approach for evaluating internal cluster validation indices. (arXiv:2308.03894v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03894</link>
<description rdf:parseType="Literal">&lt;p&gt;A vast number of different methods are available for unsupervised
classification. Since no algorithm and parameter setting performs best in all
types of data, there is a need for cluster validation to select the actually
best-performing algorithm. Several indices were proposed for this purpose
without using any additional (external) information. These internal validation
indices can be evaluated by applying them to classifications of datasets with a
known cluster structure. Evaluation approaches differ in how they use the
information on the ground-truth classification. This paper reviews these
approaches, considering their advantages and disadvantages, and then suggests a
new approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Botta_Dukat_Z/0/1/0/all/0/1&quot;&gt;Zolt&amp;#xe1;n Botta-Duk&amp;#xe1;t&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03901">
<title>FLIPS: Federated Learning using Intelligent Participant Selection. (arXiv:2308.03901v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03901</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents the design and implementation of FLIPS, a middleware
system to manage data and participant heterogeneity in federated learning (FL)
training workloads. In particular, we examine the benefits of label
distribution clustering on participant selection in federated learning. FLIPS
clusters parties involved in an FL training job based on the label distribution
of their data apriori, and during FL training, ensures that each cluster is
equitably represented in the participants selected. FLIPS can support the most
common FL algorithms, including FedAvg, FedProx, FedDyn, FedOpt and FedYogi. To
manage platform heterogeneity and dynamic resource availability, FLIPS
incorporates a straggler management mechanism to handle changing capacities in
distributed, smart community applications. Privacy of label distributions,
clustering and participant selection is ensured through a trusted execution
environment (TEE). Our comprehensive empirical evaluation compares FLIPS with
random participant selection, as well as two other &quot;smart&quot; selection mechanisms
- Oort and gradient clustering using two real-world datasets, two different
non-IID distributions and three common FL algorithms (FedYogi, FedProx and
FedAvg). We demonstrate that FLIPS significantly improves convergence,
achieving higher accuracy by 17 - 20 % with 20 - 60 % lower communication
costs, and these benefits endure in the presence of straggler participants.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhope_R/0/1/0/all/0/1&quot;&gt;Rahul Atul Bhope&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jayaram_K/0/1/0/all/0/1&quot;&gt;K. R. Jayaram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkatasubramanian_N/0/1/0/all/0/1&quot;&gt;Nalini Venkatasubramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1&quot;&gt;Ashish Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_G/0/1/0/all/0/1&quot;&gt;Gegi Thomas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03904">
<title>On genuine invariance learning without weight-tying. (arXiv:2308.03904v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03904</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we investigate properties and limitations of invariance
learned by neural networks from the data compared to the genuine invariance
achieved through invariant weight-tying. To do so, we adopt a group theoretical
perspective and analyze invariance learning in neural networks without
weight-tying constraints. We demonstrate that even when a network learns to
correctly classify samples on a group orbit, the underlying decision-making in
such a model does not attain genuine invariance. Instead, learned invariance is
strongly conditioned on the input data, rendering it unreliable if the input
distribution shifts. We next demonstrate how to guide invariance learning
toward genuine invariance by regularizing the invariance of a model at the
training. To this end, we propose several metrics to quantify learned
invariance: (i) predictive distribution invariance, (ii) logit invariance, and
(iii) saliency invariance similarity. We show that the invariance learned with
the invariance error regularization closely reassembles the genuine invariance
of weight-tying models and reliably holds even under a severe input
distribution shift. Closer analysis of the learned invariance also reveals the
spectral decay phenomenon, when a network chooses to achieve the invariance to
a specific transformation group by reducing the sensitivity to any input
perturbation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moskalev_A/0/1/0/all/0/1&quot;&gt;Artem Moskalev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sepliarskaia_A/0/1/0/all/0/1&quot;&gt;Anna Sepliarskaia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1&quot;&gt;Erik J. Bekkers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smeulders_A/0/1/0/all/0/1&quot;&gt;Arnold Smeulders&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03905">
<title>Intelligent Assistant Language Understanding On Device. (arXiv:2308.03905v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.03905</link>
<description rdf:parseType="Literal">&lt;p&gt;It has recently become feasible to run personal digital assistants on phones
and other personal devices. In this paper we describe a design for a natural
language understanding system that runs on device. In comparison to a
server-based assistant, this system is more private, more reliable, faster,
more expressive, and more accurate. We describe what led to key choices about
architecture and technologies. For example, some approaches in the dialog
systems literature are difficult to maintain over time in a deployment setting.
We hope that sharing learnings from our practical experiences may help inform
future work in the research community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aas_C/0/1/0/all/0/1&quot;&gt;Cecilia Aas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdelsalam_H/0/1/0/all/0/1&quot;&gt;Hisham Abdelsalam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belousova_I/0/1/0/all/0/1&quot;&gt;Irina Belousova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhargava_S/0/1/0/all/0/1&quot;&gt;Shruti Bhargava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;Jianpeng Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daland_R/0/1/0/all/0/1&quot;&gt;Robert Daland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Driesen_J/0/1/0/all/0/1&quot;&gt;Joris Driesen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flego_F/0/1/0/all/0/1&quot;&gt;Federico Flego&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guigue_T/0/1/0/all/0/1&quot;&gt;Tristan Guigue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johannsen_A/0/1/0/all/0/1&quot;&gt;Anders Johannsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lal_P/0/1/0/all/0/1&quot;&gt;Partha Lal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiarui Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1&quot;&gt;Joel Ruben Antony Moniz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perkins_N/0/1/0/all/0/1&quot;&gt;Nathan Perkins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piraviperumal_D/0/1/0/all/0/1&quot;&gt;Dhivya Piraviperumal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pulman_S/0/1/0/all/0/1&quot;&gt;Stephen Pulman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seaghdha_D/0/1/0/all/0/1&quot;&gt;Diarmuid &amp;#xd3; S&amp;#xe9;aghdha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1&quot;&gt;David Q. Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_J/0/1/0/all/0/1&quot;&gt;John Torr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vecchio_M/0/1/0/all/0/1&quot;&gt;Marco Del Vecchio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wacker_J/0/1/0/all/0/1&quot;&gt;Jay Wacker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1&quot;&gt;Jason D. Williams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hong Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03907">
<title>Advancements In Crowd-Monitoring System: A Comprehensive Analysis of Systematic Approaches and Automation Algorithms: State-of-The-Art. (arXiv:2308.03907v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2308.03907</link>
<description rdf:parseType="Literal">&lt;p&gt;Growing apprehensions surrounding public safety have captured the attention
of numerous governments and security agencies across the globe. These entities
are increasingly acknowledging the imperative need for reliable and secure
crowd-monitoring systems to address these concerns. Effectively managing human
gatherings necessitates proactive measures to prevent unforeseen events or
complications, ensuring a safe and well-coordinated environment. The scarcity
of research focusing on crowd monitoring systems and their security
implications has given rise to a burgeoning area of investigation, exploring
potential approaches to safeguard human congregations effectively. Crowd
monitoring systems depend on a bifurcated approach, encompassing vision-based
and non-vision-based technologies. An in-depth analysis of these two
methodologies will be conducted in this research. The efficacy of these
approaches is contingent upon the specific environment and temporal context in
which they are deployed, as they each offer distinct advantages. This paper
endeavors to present an in-depth analysis of the recent incorporation of
artificial intelligence (AI) algorithms and models into automated systems,
emphasizing their contemporary applications and effectiveness in various
contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ameen_M/0/1/0/all/0/1&quot;&gt;Mohammed Ameen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stone_R/0/1/0/all/0/1&quot;&gt;Richard Stone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03908">
<title>ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings for Video Action Recognition. (arXiv:2308.03908v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.03908</link>
<description rdf:parseType="Literal">&lt;p&gt;Video Action Recognition (VAR) is a challenging task due to its inherent
complexities. Though different approaches have been explored in the literature,
designing a unified framework to recognize a large number of human actions is
still a challenging problem. Recently, Multi-Modal Learning (MML) has
demonstrated promising results in this domain. In literature, 2D skeleton or
pose modality has often been used for this task, either independently or in
conjunction with the visual information (RGB modality) present in videos.
However, the combination of pose, visual information, and text attributes has
not been explored yet, though text and pose attributes independently have been
proven to be effective in numerous computer vision tasks. In this paper, we
present the first pose augmented Vision-language model (VLM) for VAR. Notably,
our scheme achieves an accuracy of 92.81% and 73.02% on two popular human video
action recognition benchmark datasets, UCF-101 and HMDB-51, respectively, even
without any video data pre-training, and an accuracy of 96.11% and 75.75% after
kinetics pre-training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1&quot;&gt;Soumyabrata Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1&quot;&gt;Saumik Bhattacharya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03915">
<title>Predicting and explaining nonlinear material response using deep Physically Guided Neural Networks with Internal Variables. (arXiv:2308.03915v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03915</link>
<description rdf:parseType="Literal">&lt;p&gt;Nonlinear materials are often difficult to model with classical state model
theory because they have a complex and sometimes inaccurate physical and
mathematical description or we simply do not know how to describe such
materials in terms of relations between external and internal variables. In
many disciplines, Neural Network methods have arisen as powerful tools to
identify very complex and non-linear correlations. In this work, we use the
very recently developed concept of Physically Guided Neural Networks with
Internal Variables (PGNNIV) to discover constitutive laws using a model-free
approach and training solely with measured force-displacement data. PGNNIVs
make a particular use of the physics of the problem to enforce constraints on
specific hidden layers and are able to make predictions without internal
variable data. We demonstrate that PGNNIVs are capable of predicting both
internal and external variables under unseen load scenarios, regardless of the
nature of the material considered (linear, with hardening or softening behavior
and hyperelastic), unravelling the constitutive law of the material hence
explaining its nature altogether, placing the method in what is known as
eXplainable Artificial Intelligence (XAI).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orera_Echeverria_J/0/1/0/all/0/1&quot;&gt;Javier Orera-Echeverria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ayensa_Jimenez_J/0/1/0/all/0/1&quot;&gt;Jacobo Ayensa-Jim&amp;#xe9;nez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doblare_M/0/1/0/all/0/1&quot;&gt;Manuel Doblare&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03928">
<title>Optimizing the switching operation in monoclonal antibody production: Economic MPC and reinforcement learning. (arXiv:2308.03928v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03928</link>
<description rdf:parseType="Literal">&lt;p&gt;Monoclonal antibodies (mAbs) have emerged as indispensable assets in
medicine, and are currently at the forefront of biopharmaceutical product
development. However, the growing market demand and the substantial doses
required for mAb clinical treatments necessitate significant progress in its
large-scale production. Most of the processes for industrial mAb production
rely on batch operations, which result in significant downtime. The shift
towards a fully continuous and integrated manufacturing process holds the
potential to boost product yield and quality, while eliminating the extra
expenses associated with storing intermediate products. The integrated
continuous mAb production process can be divided into the upstream and
downstream processes. One crucial aspect that ensures the continuity of the
integrated process is the switching of the capture columns, which are typically
chromatography columns operated in a fed-batch manner downstream. Due to the
discrete nature of the switching operation, advanced process control algorithms
such as economic MPC (EMPC) are computationally difficult to implement. This is
because an integer nonlinear program (INLP) needs to be solved online at each
sampling time. This paper introduces two computationally-efficient approaches
for EMPC implementation, namely, a sigmoid function approximation approach and
a rectified linear unit (ReLU) approximation approach. It also explores the
application of deep reinforcement learning (DRL). These three methods are
compared to the traditional switching approach which is based on a 1% product
breakthrough rule and which involves no optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obiri_S/0/1/0/all/0/1&quot;&gt;Sandra A. Obiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bo_S/0/1/0/all/0/1&quot;&gt;Song Bo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agyeman_B/0/1/0/all/0/1&quot;&gt;Bernard T. Agyeman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Decardi_Nelson_B/0/1/0/all/0/1&quot;&gt;Benjamin Decardi-Nelson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jinfeng Liu&lt;/a&gt; (University of Alberta)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03944">
<title>GraPhSyM: Graph Physical Synthesis Model. (arXiv:2308.03944v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03944</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we introduce GraPhSyM, a Graph Attention Network (GATv2) model
for fast and accurate estimation of post-physical synthesis circuit delay and
area metrics from pre-physical synthesis circuit netlists. Once trained,
GraPhSyM provides accurate visibility of final design metrics to early EDA
stages, such as logic synthesis, without running the slow physical synthesis
flow, enabling global co-optimization across stages. Additionally, the swift
and precise feedback provided by GraPhSym is instrumental for
machine-learning-based EDA optimization frameworks. Given a gate-level netlist
of a circuit represented as a graph, GraPhSyM utilizes graph structure,
connectivity, and electrical property features to predict the impact of
physical synthesis transformations such as buffer insertion and gate sizing.
When trained on a dataset of 6000 prefix adder designs synthesized at an
aggressive delay target, GraPhSyM can accurately predict the post-synthesis
delay (98.3%) and area (96.1%) metrics of unseen adders with a fast 0.22s
inference time. Furthermore, we illustrate the compositionality of GraPhSyM by
employing the model trained on a fixed delay target to accurately anticipate
post-synthesis metrics at a variety of unseen delay targets. Lastly, we report
promising generalization capabilities of the GraPhSyM model when it is
evaluated on circuits different from the adders it was exclusively trained on.
The results show the potential for GraPhSyM to serve as a powerful tool for
advanced optimization techniques and as an oracle for EDA machine learning
frameworks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agiza_A/0/1/0/all/0/1&quot;&gt;Ahmed Agiza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1&quot;&gt;Rajarshi Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ene_T/0/1/0/all/0/1&quot;&gt;Teodor Dumitru Ene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godil_S/0/1/0/all/0/1&quot;&gt;Saad Godil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reda_S/0/1/0/all/0/1&quot;&gt;Sherief Reda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1&quot;&gt;Bryan Catanzaro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03945">
<title>The Prospect of Enhancing Large-Scale Heterogeneous Federated Learning with Transformers. (arXiv:2308.03945v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03945</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) addresses data privacy concerns by enabling
collaborative training of AI models across distributed data owners. Wide
adoption of FL faces the fundamental challenges of data heterogeneity and the
large scale of data owners involved. In this paper, we investigate the prospect
of Transformer-based FL models for achieving generalization and personalization
in this setting. We conduct extensive comparative experiments involving FL with
Transformers, ResNet, and personalized ResNet-based FL approaches under various
scenarios. These experiments consider varying numbers of data owners to
demonstrate Transformers&apos; advantages over deep neural networks in large-scale
heterogeneous FL tasks. In addition, we analyze the superior performance of
Transformers by comparing the Centered Kernel Alignment (CKA) representation
similarity across different layers and FL models to gain insight into the
reasons behind their promising capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yulan Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Hao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zengxiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Han Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03953">
<title>PMU measurements based short-term voltage stability assessment of power systems via deep transfer learning. (arXiv:2308.03953v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03953</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has emerged as an effective solution for addressing the
challenges of short-term voltage stability assessment (STVSA) in power systems.
However, existing deep learning-based STVSA approaches face limitations in
adapting to topological changes, sample labeling, and handling small datasets.
To overcome these challenges, this paper proposes a novel phasor measurement
unit (PMU) measurements-based STVSA method by using deep transfer learning. The
method leverages the real-time dynamic information captured by PMUs to create
an initial dataset. It employs temporal ensembling for sample labeling and
utilizes least squares generative adversarial networks (LSGAN) for data
augmentation, enabling effective deep learning on small-scale datasets.
Additionally, the method enhances adaptability to topological changes by
exploring connections between different faults. Experimental results on the
IEEE 39-bus test system demonstrate that the proposed method improves model
evaluation accuracy by approximately 20% through transfer learning, exhibiting
strong adaptability to topological changes. Leveraging the self-attention
mechanism of the Transformer model, this approach offers significant advantages
over shallow learning methods and other deep learning-based approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shitu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanzheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1&quot;&gt;Jiting Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_S/0/1/0/all/0/1&quot;&gt;Shuyue Jia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03956">
<title>Fixed Inter-Neuron Covariability Induces Adversarial Robustness. (arXiv:2308.03956v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03956</link>
<description rdf:parseType="Literal">&lt;p&gt;The vulnerability to adversarial perturbations is a major flaw of Deep Neural
Networks (DNNs) that raises question about their reliability when in real-world
scenarios. On the other hand, human perception, which DNNs are supposed to
emulate, is highly robust to such perturbations, indicating that there may be
certain features of the human perception that make it robust but are not
represented in the current class of DNNs. One such feature is that the activity
of biological neurons is correlated and the structure of this correlation tends
to be rather rigid over long spans of times, even if it hampers performance and
learning. We hypothesize that integrating such constraints on the activations
of a DNN would improve its adversarial robustness, and, to test this
hypothesis, we have developed the Self-Consistent Activation (SCA) layer, which
comprises of neurons whose activations are consistent with each other, as they
conform to a fixed, but learned, covariability pattern. When evaluated on image
and sound recognition tasks, the models with a SCA layer achieved high
accuracy, and exhibited significantly greater robustness than multi-layer
perceptron models to state-of-the-art Auto-PGD adversarial attacks
\textit{without being trained on adversarially perturbed data
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1&quot;&gt;Muhammad Ahmed Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1&quot;&gt;Bhiksha Raj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03960">
<title>Amortized Global Search for Efficient Preliminary Trajectory Design with Deep Generative Models. (arXiv:2308.03960v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03960</link>
<description rdf:parseType="Literal">&lt;p&gt;Preliminary trajectory design is a global search problem that seeks multiple
qualitatively different solutions to a trajectory optimization problem. Due to
its high dimensionality and non-convexity, and the frequent adjustment of
problem parameters, the global search becomes computationally demanding. In
this paper, we exploit the clustering structure in the solutions and propose an
amortized global search (AmorGS) framework. We use deep generative models to
predict trajectory solutions that share similar structures with previously
solved problems, which accelerates the global search for unseen parameter
values. Our method is evaluated using De Jong&apos;s 5th function and a low-thrust
circular restricted three-body problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Anjian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1&quot;&gt;Amlan Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beeson_R/0/1/0/all/0/1&quot;&gt;Ryne Beeson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03977">
<title>PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning. (arXiv:2308.03977v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.03977</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthetic image datasets offer unmatched advantages for designing and
evaluating deep neural networks: they make it possible to (i) render as many
data samples as needed, (ii) precisely control each scene and yield granular
ground truth labels (and captions), (iii) precisely control distribution shifts
between training and testing to isolate variables of interest for sound
experimentation. Despite such promise, the use of synthetic image data is still
limited -- and often played down -- mainly due to their lack of realism. Most
works therefore rely on datasets of real images, which have often been scraped
from public images on the internet, and may have issues with regards to
privacy, bias, and copyright, while offering little control over how objects
precisely appear. In this work, we present a path to democratize the use of
photorealistic synthetic data: we develop a new generation of interactive
environments for representation learning research, that offer both
controllability and realism. We use the Unreal Engine, a powerful game engine
well known in the entertainment industry, to produce PUG (Photorealistic Unreal
Graphics) environments and datasets for representation learning. In this paper,
we demonstrate the potential of PUG to enable more rigorous evaluations of
vision models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bordes_F/0/1/0/all/0/1&quot;&gt;Florian Bordes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shekhar_S/0/1/0/all/0/1&quot;&gt;Shashank Shekhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1&quot;&gt;Mark Ibrahim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouchacourt_D/0/1/0/all/0/1&quot;&gt;Diane Bouchacourt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1&quot;&gt;Pascal Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1&quot;&gt;Ari S. Morcos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03985">
<title>Fourier neural operator for real-time simulation of 3D dynamic urban microclimate. (arXiv:2308.03985v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03985</link>
<description rdf:parseType="Literal">&lt;p&gt;Global urbanization has underscored the significance of urban microclimates
for human comfort, health, and building/urban energy efficiency. They
profoundly influence building design and urban planning as major environmental
impacts. Understanding local microclimates is essential for cities to prepare
for climate change and effectively implement resilience measures. However,
analyzing urban microclimates requires considering a complex array of outdoor
parameters within computational domains at the city scale over a longer period
than indoors. As a result, numerical methods like Computational Fluid Dynamics
(CFD) become computationally expensive when evaluating the impact of urban
microclimates. The rise of deep learning techniques has opened new
opportunities for accelerating the modeling of complex non-linear interactions
and system dynamics. Recently, the Fourier Neural Operator (FNO) has been shown
to be very promising in accelerating solving the Partial Differential Equations
(PDEs) and modeling fluid dynamic systems. In this work, we apply the FNO
network for real-time three-dimensional (3D) urban wind field simulation. The
training and testing data are generated from CFD simulation of the urban area,
based on the semi-Lagrangian approach and fractional stepping method to
simulate urban microclimate features for modeling large-scale urban problems.
Numerical experiments show that the FNO model can accurately reconstruct the
instantaneous spatial velocity field. We further evaluate the trained FNO model
on unseen data with different wind directions, and the results show that the
FNO model can generalize well on different wind directions. More importantly,
the FNO approach can make predictions within milliseconds on the graphics
processing unit, making real-time simulation of 3D dynamic urban microclimate
possible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1&quot;&gt;Wenhui Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_S/0/1/0/all/0/1&quot;&gt;Shaoxiang Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Senwen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianchun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liangzhu/0/1/0/all/0/1&quot;&gt;Liangzhu&lt;/a&gt; (Leon) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang/0/1/0/all/0/1&quot;&gt;Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03995">
<title>Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for Resource Management in Space-Air-Ground Integrated Networks. (arXiv:2308.03995v1 [cs.MA])</title>
<link>http://arxiv.org/abs/2308.03995</link>
<description rdf:parseType="Literal">&lt;p&gt;The Space-Air-Ground Integrated Network (SAGIN), integrating heterogeneous
devices including low earth orbit (LEO) satellites, unmanned aerial vehicles
(UAVs), and ground users (GUs), holds significant promise for advancing smart
city applications. However, resource management of the SAGIN is a challenge
requiring urgent study in that inappropriate resource management will cause
poor data transmission, and hence affect the services in smart cities. In this
paper, we develop a comprehensive SAGIN system that encompasses five distinct
communication links and propose an efficient cooperative multi-type multi-agent
deep reinforcement learning (CMT-MARL) method to address the resource
management issue. The experimental results highlight the efficacy of the
proposed CMT-MARL, as evidenced by key performance indicators such as the
overall transmission rate and transmission success rate. These results
underscore the potential value and feasibility of future implementation of the
SAGIN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hengxi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Huaze Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1&quot;&gt;Wenbo Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiao-Ping Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03999">
<title>Understanding CNN Hidden Neuron Activations using Structured Background Knowledge and Deductive Reasoning. (arXiv:2308.03999v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.03999</link>
<description rdf:parseType="Literal">&lt;p&gt;A major challenge in Explainable AI is in correctly interpreting activations
of hidden neurons: accurate interpretations would provide insights into the
question of what a deep learning system has internally detected as relevant on
the input, de-mystifying the otherwise black-box character of deep learning
systems. The state of the art indicates that hidden node activations can, in
some cases, be interpretable in a way that makes sense to humans, but
systematic automated methods that would be able to hypothesize and verify
interpretations of hidden neuron activations are underexplored. In this paper,
we provide such a method and demonstrate that it provides meaningful
interpretations. Our approach is based on using large-scale background
knowledge approximately 2 million classes curated from the Wikipedia concept
hierarchy together with a symbolic reasoning approach called Concept Induction
based on description logics, originally developed for applications in the
Semantic Web field. Our results show that we can automatically attach
meaningful labels from the background knowledge to individual neurons in the
dense layer of a Convolutional Neural Network through a hypothesis and
verification process
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_A/0/1/0/all/0/1&quot;&gt;Abhilekha Dalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarker_M/0/1/0/all/0/1&quot;&gt;Md Kamruzzaman Sarker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barua_A/0/1/0/all/0/1&quot;&gt;Adrita Barua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasserman_E/0/1/0/all/0/1&quot;&gt;Eugene Vasserman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hitzler_P/0/1/0/all/0/1&quot;&gt;Pascal Hitzler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04011">
<title>Generalization bound for estimating causal effects from observational network data. (arXiv:2308.04011v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04011</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating causal effects from observational network data is a significant
but challenging problem. Existing works in causal inference for observational
network data lack an analysis of the generalization bound, which can
theoretically provide support for alleviating the complex confounding bias and
practically guide the design of learning objectives in a principled manner. To
fill this gap, we derive a generalization bound for causal effect estimation in
network scenarios by exploiting 1) the reweighting schema based on joint
propensity score and 2) the representation learning schema based on Integral
Probability Metric (IPM). We provide two perspectives on the generalization
bound in terms of reweighting and representation learning, respectively.
Motivated by the analysis of the bound, we propose a weighting regression
method based on the joint propensity score augmented with representation
learning. Extensive experimental studies on two real-world networks with
semi-synthetic data demonstrate the effectiveness of our algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1&quot;&gt;Ruichu Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zeqin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Weilin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1&quot;&gt;Yuguang Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Hao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04014">
<title>Continual Pre-Training of Large Language Models: How to (re)warm your model?. (arXiv:2308.04014v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.04014</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) are routinely pre-trained on billions of tokens,
only to restart the process over again once new data becomes available. A much
cheaper and more efficient solution would be to enable the continual
pre-training of these models, i.e. updating pre-trained models with new data
instead of re-training them from scratch. However, the distribution shift
induced by novel data typically results in degraded performance on past data.
Taking a step towards efficient continual pre-training, in this work, we
examine the effect of different warm-up strategies. Our hypothesis is that the
learning rate must be re-increased to improve compute efficiency when training
on a new dataset. We study the warmup phase of models pre-trained on the Pile
(upstream data, 300B tokens) as we continue to pre-train on SlimPajama
(downstream data, 297B tokens), following a linear warmup and cosine decay
schedule. We conduct all experiments on the Pythia 410M language model
architecture and evaluate performance through validation perplexity. We
experiment with different pre-training checkpoints, various maximum learning
rates, and various warmup lengths. Our results show that while rewarming models
first increases the loss on upstream and downstream data, in the longer run it
improves the downstream performance, outperforming models trained from
scratch$\unicode{x2013}$even for a large downstream dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1&quot;&gt;Kshitij Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Therien_B/0/1/0/all/0/1&quot;&gt;Benjamin Th&amp;#xe9;rien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibrahim_A/0/1/0/all/0/1&quot;&gt;Adam Ibrahim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richter_M/0/1/0/all/0/1&quot;&gt;Mats L. Richter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anthony_Q/0/1/0/all/0/1&quot;&gt;Quentin Anthony&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1&quot;&gt;Eugene Belilovsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1&quot;&gt;Irina Rish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1&quot;&gt;Timoth&amp;#xe9;e Lesort&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04018">
<title>Improving Performance of Semi-Supervised Learning by Adversarial Attacks. (arXiv:2308.04018v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04018</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-supervised learning (SSL) algorithm is a setup built upon a realistic
assumption that access to a large amount of labeled data is tough. In this
study, we present a generalized framework, named SCAR, standing for Selecting
Clean samples with Adversarial Robustness, for improving the performance of
recent SSL algorithms. By adversarially attacking pre-trained models with
semi-supervision, our framework shows substantial advances in classifying
images. We introduce how adversarial attacks successfully select high-confident
unlabeled data to be labeled with current predictions. On CIFAR10, three recent
SSL algorithms with SCAR result in significantly improved image classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1&quot;&gt;Dongyoon Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kunwoong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yongdai Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04024">
<title>Scope Loss for Imbalanced Classification and RL Exploration. (arXiv:2308.04024v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04024</link>
<description rdf:parseType="Literal">&lt;p&gt;We demonstrate equivalence between the reinforcement learning problem and the
supervised classification problem. We consequently equate the exploration
exploitation trade-off in reinforcement learning to the dataset imbalance
problem in supervised classification, and find similarities in how they are
addressed. From our analysis of the aforementioned problems we derive a novel
loss function for reinforcement learning and supervised classification. Scope
Loss, our new loss function, adjusts gradients to prevent performance losses
from over-exploitation and dataset imbalances, without the need for any tuning.
We test Scope Loss against SOTA loss functions over a basket of benchmark
reinforcement learning tasks and a skewed classification dataset, and show that
Scope Loss outperforms other loss functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burhani_H/0/1/0/all/0/1&quot;&gt;Hasham Burhani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1&quot;&gt;Xiao Qi Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaegerman_J/0/1/0/all/0/1&quot;&gt;Jonathan Jaegerman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balicki_D/0/1/0/all/0/1&quot;&gt;Daniel Balicki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04028">
<title>Top K Relevant Passage Retrieval for Biomedical Question Answering. (arXiv:2308.04028v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.04028</link>
<description rdf:parseType="Literal">&lt;p&gt;Question answering is a task that answers factoid questions using a large
collection of documents. It aims to provide precise answers in response to the
user&apos;s questions in natural language. Question answering relies on efficient
passage retrieval to select candidate contexts, where traditional sparse vector
space models, such as TF-IDF or BM25, are the de facto method. On the web,
there is no single article that could provide all the possible answers
available on the internet to the question of the problem asked by the user. The
existing Dense Passage Retrieval model has been trained on Wikipedia dump from
Dec. 20, 2018, as the source documents for answering questions. Question
answering (QA) has made big strides with several open-domain and machine
comprehension systems built using large-scale annotated datasets. However, in
the clinical domain, this problem remains relatively unexplored. According to
multiple surveys, Biomedical Questions cannot be answered correctly from
Wikipedia Articles. In this work, we work on the existing DPR framework for the
biomedical domain and retrieve answers from the Pubmed articles which is a
reliable source to answer medical questions. When evaluated on a BioASQ QA
dataset, our fine-tuned dense retriever results in a 0.81 F1 score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Shashank Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04037">
<title>A Comparative Study on TF-IDF feature Weighting Method and its Analysis using Unstructured Dataset. (arXiv:2308.04037v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.04037</link>
<description rdf:parseType="Literal">&lt;p&gt;Text Classification is the process of categorizing text into the relevant
categories and its algorithms are at the core of many Natural Language
Processing (NLP). Term Frequency-Inverse Document Frequency (TF-IDF) and NLP
are the most highly used information retrieval methods in text classification.
We have investigated and analyzed the feature weighting method for text
classification on unstructured data. The proposed model considered two features
N-Grams and TF-IDF on the IMDB movie reviews and Amazon Alexa reviews dataset
for sentiment analysis. Then we have used the state-of-the-art classifier to
validate the method i.e., Support Vector Machine (SVM), Logistic Regression,
Multinomial Naive Bayes (Multinomial NB), Random Forest, Decision Tree, and
k-nearest neighbors (KNN). From those two feature extractions, a significant
increase in feature extraction with TF-IDF features rather than based on
N-Gram. TF-IDF got the maximum accuracy (93.81%), precision (94.20%), recall
(93.81%), and F1-score (91.99%) value in Random Forest classifier.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_M/0/1/0/all/0/1&quot;&gt;Mamata Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+K%2E_S/0/1/0/all/0/1&quot;&gt;Selvakumar K.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alphonse_P/0/1/0/all/0/1&quot;&gt;P.J.A. Alphonse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04051">
<title>Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization. (arXiv:2308.04051v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2308.04051</link>
<description rdf:parseType="Literal">&lt;p&gt;Our work presents a novel approach to shape optimization, that has the
twofold objective to improve the efficiency of global optimization algorithms
while promoting the generation of high-quality designs during the optimization
process free of geometrical anomalies. This is accomplished by reducing the
number of the original design variables defining a new reduced subspace where
the geometrical variance is maximized and modeling the underlying generative
process of the data via probabilistic linear latent variable models such as
Factor Analysis and Probabilistic Principal Component Analysis. We show that
the data follows approximately a Gaussian distribution when the shape
modification method is linear and the design variables are sampled uniformly at
random, due to the direct application of the central limit theorem. The model
uncertainty is measured in terms of Mahalanobis distance, and the paper
demonstrates that anomalous designs tend to exhibit a high value of this
metric. This enables the definition of a new optimization model where anomalous
geometries are penalized and consequently avoided during the optimization loop.
The procedure is demonstrated for hull shape optimization of the DTMB 5415
model, extensively used as an international benchmark for shape optimization
problems. The global optimization routine is carried out using Bayesian
Optimization and the DIRECT algorithm. From the numerical results, the new
framework improves the convergence of global optimization algorithms, while
only designs with high-quality geometrical features are generated through the
optimization routine thereby avoiding the wastage of precious computationally
expensive simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+DAgostino_D/0/1/0/all/0/1&quot;&gt;Danny D&amp;#x27;Agostino&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04052">
<title>The Five-Dollar Model: Generating Game Maps and Sprites from Sentence Embeddings. (arXiv:2308.04052v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04052</link>
<description rdf:parseType="Literal">&lt;p&gt;The five-dollar model is a lightweight text-to-image generative architecture
that generates low dimensional images from an encoded text prompt. This model
can successfully generate accurate and aesthetically pleasing content in low
dimensional domains, with limited amounts of training data. Despite the small
size of both the model and datasets, the generated images are still able to
maintain the encoded semantic meaning of the textual prompt. We apply this
model to three small datasets: pixel art video game maps, video game sprite
images, and down-scaled emoji images and apply novel augmentation strategies to
improve the performance of our model on these limited datasets. We evaluate our
models performance using cosine similarity score between text-image pairs
generated by the CLIP VIT-B/32 model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merino_T/0/1/0/all/0/1&quot;&gt;Timothy Merino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Negri_R/0/1/0/all/0/1&quot;&gt;Roman Negri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajesh_D/0/1/0/all/0/1&quot;&gt;Dipika Rajesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charity_M/0/1/0/all/0/1&quot;&gt;M Charity&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04060">
<title>Toward Improving Predictive Risk Modelling for New Zealand&apos;s Child Welfare System Using Clustering Methods. (arXiv:2308.04060v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2308.04060</link>
<description rdf:parseType="Literal">&lt;p&gt;The combination of clinical judgement and predictive risk models crucially
assist social workers to segregate children at risk of maltreatment and decide
when authorities should intervene. Predictive risk modelling to address this
matter has been initiated by several governmental welfare authorities worldwide
involving administrative data and machine learning algorithms. While previous
studies have investigated risk factors relating to child maltreatment, several
gaps remain as to understanding how such risk factors interact and whether
predictive risk models perform differently for children with different
features. By integrating Principal Component Analysis and K-Means clustering,
this paper presents initial findings of our work on the identification of such
features as well as their potential effect on current risk modelling
frameworks. This approach allows examining existent, unidentified yet, clusters
of New Zealand (NZ) children reported with care and protection concerns, as
well as to analyse their inner structure, and evaluate the performance of
prediction models trained cluster wise. We aim to discover the extent of
clustering degree required as an early step in the development of predictive
risk models for child maltreatment and so enhance the accuracy of such models
intended for use by child protection authorities. The results from testing
LASSO logistic regression models trained on identified clusters revealed no
significant difference in their performance. The models, however, performed
slightly better for two clusters including younger children. our results
suggest that separate models might need to be developed for children of certain
age to gain additional control over the error rates and to improve model
accuracy. While results are promising, more evidence is needed to draw
definitive conclusions, and further investigation is necessary.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barmomanesh_S/0/1/0/all/0/1&quot;&gt;Sahar Barmomanesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miranda_Soberanis_V/0/1/0/all/0/1&quot;&gt;Victor Miranda-Soberanis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04061">
<title>Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation. (arXiv:2308.04061v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04061</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial robustness is a research area that has recently received a lot of
attention in the quest for trustworthy artificial intelligence. However, recent
works on adversarial robustness have focused on supervised learning where it is
assumed that labeled data is plentiful. In this paper, we investigate
semi-supervised adversarial training where labeled data is scarce. We derive
two upper bounds for the robust risk and propose a regularization term for
unlabeled data motivated by these two upper bounds. Then, we develop a
semi-supervised adversarial training algorithm that combines the proposed
regularization term with knowledge distillation using a semi-supervised teacher
(i.e., a teacher model trained using a semi-supervised learning algorithm). Our
experiments show that our proposed algorithm achieves state-of-the-art
performance with significant margins compared to existing algorithms. In
particular, compared to supervised learning algorithms, performance of our
proposed algorithm is not much worse even when the amount of labeled data is
very small. For example, our algorithm with only 8\% labeled data is comparable
to supervised adversarial training algorithms that use all labeled data, both
in terms of standard and robust accuracies on CIFAR-10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1&quot;&gt;Dongyoon Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_I/0/1/0/all/0/1&quot;&gt;Insung Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yongdai Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04070">
<title>ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data. (arXiv:2308.04070v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.04070</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing a generalized segmentation model capable of simultaneously
delineating multiple organs and diseases is highly desirable. Federated
learning (FL) is a key technology enabling the collaborative development of a
model without exchanging training data. However, the limited access to fully
annotated training data poses a major challenge to training generalizable
models. We propose &quot;ConDistFL&quot;, a framework to solve this problem by combining
FL with knowledge distillation. Local models can extract the knowledge of
unlabeled organs and tumors from partially annotated data from the global model
with an adequately designed conditional probability representation. We validate
our framework on four distinct partially annotated abdominal CT datasets from
the MSD and KiTS19 challenges. The experimental results show that the proposed
framework significantly outperforms FedAvg and FedOpt baselines. Moreover, the
performance on an external test dataset demonstrates superior generalizability
compared to models trained on each dataset separately. Our ablation study
suggests that ConDistFL can perform well without frequent aggregation, reducing
the communication cost of FL. Our implementation will be available at
https://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Pochuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Chen Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weichung Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oda_M/0/1/0/all/0/1&quot;&gt;Masahiro Oda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuh_C/0/1/0/all/0/1&quot;&gt;Chiou-Shann Fuh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mori_K/0/1/0/all/0/1&quot;&gt;Kensaku Mori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_H/0/1/0/all/0/1&quot;&gt;Holger R. Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04071">
<title>Path Signatures for Diversity in Probabilistic Trajectory Optimisation. (arXiv:2308.04071v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2308.04071</link>
<description rdf:parseType="Literal">&lt;p&gt;Motion planning can be cast as a trajectory optimisation problem where a cost
is minimised as a function of the trajectory being generated. In complex
environments with several obstacles and complicated geometry, this optimisation
problem is usually difficult to solve and prone to local minima. However,
recent advancements in computing hardware allow for parallel trajectory
optimisation where multiple solutions are obtained simultaneously, each
initialised from a different starting point. Unfortunately, without a strategy
preventing two solutions to collapse on each other, naive parallel optimisation
can suffer from mode collapse diminishing the efficiency of the approach and
the likelihood of finding a global solution. In this paper we leverage on
recent advances in the theory of rough paths to devise an algorithm for
parallel trajectory optimisation that promotes diversity over the range of
solutions, therefore avoiding mode collapses and achieving better global
properties. Our approach builds on path signatures and Hilbert space
representations of trajectories, and connects parallel variational inference
for trajectory estimation with diversity promoting kernels. We empirically
demonstrate that this strategy achieves lower average costs than competing
alternatives on a range of problems, from 2D navigation to robotic manipulators
operating in cluttered environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barcelos_L/0/1/0/all/0/1&quot;&gt;Lucas Barcelos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_T/0/1/0/all/0/1&quot;&gt;Tin Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveira_R/0/1/0/all/0/1&quot;&gt;Rafael Oliveira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borges_P/0/1/0/all/0/1&quot;&gt;Paulo Borges&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1&quot;&gt;Fabio Ramos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04073">
<title>Learning Specialized Activation Functions for Physics-informed Neural Networks. (arXiv:2308.04073v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04073</link>
<description rdf:parseType="Literal">&lt;p&gt;Physics-informed neural networks (PINNs) are known to suffer from
optimization difficulty. In this work, we reveal the connection between the
optimization difficulty of PINNs and activation functions. Specifically, we
show that PINNs exhibit high sensitivity to activation functions when solving
PDEs with distinct properties. Existing works usually choose activation
functions by inefficient trial-and-error. To avoid the inefficient manual
selection and to alleviate the optimization difficulty of PINNs, we introduce
adaptive activation functions to search for the optimal function when solving
different problems. We compare different adaptive activation functions and
discuss their limitations in the context of PINNs. Furthermore, we propose to
tailor the idea of learning combinations of candidate activation functions to
the PINNs optimization, which has a higher requirement for the smoothness and
diversity on learned functions. This is achieved by removing activation
functions which cannot provide higher-order derivatives from the candidate set
and incorporating elementary functions with different properties according to
our prior knowledge about the PDE at hand. We further enhance the search space
with adaptive slopes. The proposed adaptive activation function can be used to
solve different PDE systems in an interpretable way. Its effectiveness is
demonstrated on a series of benchmarks. Code is available at
https://github.com/LeapLabTHU/AdaAFforPINNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Honghui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1&quot;&gt;Lu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Shiji Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1&quot;&gt;Gao Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04077">
<title>Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients. (arXiv:2308.04077v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04077</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated optimization, an emerging paradigm which finds wide real-world
applications such as federated learning, enables multiple clients (e.g., edge
devices) to collaboratively optimize a global function. The clients do not
share their local datasets and typically only share their local gradients.
However, the gradient information is not available in many applications of
federated optimization, which hence gives rise to the paradigm of federated
zeroth-order optimization (ZOO). Existing federated ZOO algorithms suffer from
the limitations of query and communication inefficiency, which can be
attributed to (a) their reliance on a substantial number of function queries
for gradient estimation and (b) the significant disparity between their
realized local updates and the intended global updates. To this end, we (a)
introduce trajectory-informed gradient surrogates which is able to use the
history of function queries during optimization for accurate and
query-efficient gradient estimation, and (b) develop the technique of adaptive
gradient correction using these gradient surrogates to mitigate the
aforementioned disparity. Based on these, we propose the federated zeroth-order
optimization using trajectory-informed surrogate gradients (FZooS) algorithm
for query- and communication-efficient federated ZOO. Our FZooS achieves
theoretical improvements over the existing approaches, which is supported by
our real-world experiments such as federated black-box adversarial attack and
federated non-differentiable metric optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1&quot;&gt;Yao Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xiaoqiang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1&quot;&gt;Zhongxiang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Low_B/0/1/0/all/0/1&quot;&gt;Bryan Kian Hsiang Low&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04082">
<title>Application-Oriented Benchmarking of Quantum Generative Learning Using QUARK. (arXiv:2308.04082v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2308.04082</link>
<description rdf:parseType="Literal">&lt;p&gt;Benchmarking of quantum machine learning (QML) algorithms is challenging due
to the complexity and variability of QML systems, e.g., regarding model
ansatzes, data sets, training techniques, and hyper-parameters selection. The
QUantum computing Application benchmaRK (QUARK) framework simplifies and
standardizes benchmarking studies for quantum computing applications. Here, we
propose several extensions of QUARK to include the ability to evaluate the
training and deployment of quantum generative models. We describe the updated
software architecture and illustrate its flexibility through several example
applications: (1) We trained different quantum generative models using several
circuit ansatzes, data sets, and data transformations. (2) We evaluated our
models on GPU and real quantum hardware. (3) We assessed the generalization
capabilities of our generative models using a broad set of metrics that
capture, e.g., the novelty and validity of the generated data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kiwit_F/0/1/0/all/0/1&quot;&gt;Florian J. Kiwit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Marso_M/0/1/0/all/0/1&quot;&gt;Marwa Marso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ross_P/0/1/0/all/0/1&quot;&gt;Philipp Ross&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Riofrio_C/0/1/0/all/0/1&quot;&gt;Carlos A. Riofr&amp;#xed;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Klepsch_J/0/1/0/all/0/1&quot;&gt;Johannes Klepsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Luckow_A/0/1/0/all/0/1&quot;&gt;Andre Luckow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04102">
<title>Asynchronous Evolution of Deep Neural Network Architectures. (arXiv:2308.04102v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2308.04102</link>
<description rdf:parseType="Literal">&lt;p&gt;Many evolutionary algorithms (EAs) take advantage of parallel evaluation of
candidates. However, if evaluation times vary significantly, many worker nodes
(i.e.,\ compute clients) are idle much of the time, waiting for the next
generation to be created. Evolutionary neural architecture search (ENAS), a
class of EAs that optimizes the architecture and hyperparameters of deep neural
networks, is particularly vulnerable to this issue. This paper proposes a
generic asynchronous evaluation strategy (AES) that is then adapted to work
with ENAS. AES increases throughput by maintaining a queue of upto $K$
individuals ready to be sent to the workers for evaluation and proceeding to
the next generation as soon as $M&amp;lt;&amp;lt;K$ individuals have been evaluated by the
workers. A suitable value for $M$ is determined experimentally, balancing
diversity and efficiency. To showcase the generality and power of AES, it was
first evaluated in 11-bit multiplexer design (a single-population verifiable
discovery task) and then scaled up to ENAS for image captioning (a
multi-population open-ended-optimization task). In both problems, a multifold
performance improvement was observed, suggesting that AES is a promising method
for parallelizing the evolution of complex systems with long and variable
evaluation times, such as those in ENAS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jason Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahrzad_H/0/1/0/all/0/1&quot;&gt;Hormoz Shahrzad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1&quot;&gt;Risto Miikkulainen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04103">
<title>Explainable machine learning to enable high-throughput electrical conductivity optimization of doped conjugated polymers. (arXiv:2308.04103v1 [physics.app-ph])</title>
<link>http://arxiv.org/abs/2308.04103</link>
<description rdf:parseType="Literal">&lt;p&gt;The combination of high-throughput experimentation techniques and machine
learning (ML) has recently ushered in a new era of accelerated material
discovery, enabling the identification of materials with cutting-edge
properties. However, the measurement of certain physical quantities remains
challenging to automate. Specifically, meticulous process control,
experimentation and laborious measurements are required to achieve optimal
electrical conductivity in doped polymer materials. We propose a ML approach,
which relies on readily measured absorbance spectra, to accelerate the workflow
associated with measuring electrical conductivity. The first ML model
(classification model), accurately classifies samples with a conductivity &amp;gt;~25
to 100 S/cm, achieving a maximum of 100% accuracy rate. For the subset of
highly conductive samples, we employed a second ML model (regression model), to
predict their conductivities, yielding an impressive test R2 value of 0.984. To
validate the approach, we showed that the models, neither trained on the
samples with the two highest conductivities of 498 and 506 S/cm, were able to,
in an extrapolative manner, correctly classify and predict them at satisfactory
levels of errors. The proposed ML workflow results in an improvement in the
efficiency of the conductivity measurements by 89% of the maximum achievable
using our experimental techniques. Furthermore, our approach addressed the
common challenge of the lack of explainability in ML models by exploiting
bespoke mathematical properties of the descriptors and ML model, allowing us to
gain corroborated insights into the spectral influences on conductivity.
Through this study, we offer an accelerated pathway for optimizing the
properties of doped polymer materials while showcasing the valuable insights
that can be derived from purposeful utilization of ML in experimental science.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Ji Wei Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Adithya Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kumar_P/0/1/0/all/0/1&quot;&gt;Pawan Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hippalgaonkar_K/0/1/0/all/0/1&quot;&gt;Kedar Hippalgaonkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Senthilnath_J/0/1/0/all/0/1&quot;&gt;J Senthilnath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chellappan_V/0/1/0/all/0/1&quot;&gt;Vijila Chellappan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04119">
<title>Constructing Custom Thermodynamics Using Deep Learning. (arXiv:2308.04119v1 [cond-mat.soft])</title>
<link>http://arxiv.org/abs/2308.04119</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the most exciting applications of AI is automated scientific discovery
based on previously amassed data, coupled with restrictions provided by the
known physical principles, including symmetries and conservation laws. Such
automated hypothesis creation and verification can assist scientists in
studying complex phenomena, where traditional physical intuition may fail. Of
particular importance are complex dynamic systems where their time evolution is
strongly influenced by varying external parameters. In this paper we develop a
platform based on a generalised Onsager principle to learn macroscopic
dynamical descriptions of arbitrary stochastic dissipative systems directly
from observations of their microscopic trajectories. We focus on systems whose
complexity and sheer sizes render complete microscopic description impractical,
and constructing theoretical macroscopic models requires extensive domain
knowledge or trial-and-error. Our machine learning approach addresses this by
simultaneously constructing reduced thermodynamic coordinates and interpreting
the dynamics on these coordinates. We demonstrate our method by studying
theoretically and validating experimentally, the stretching of long polymer
chains in an externally applied field. Specifically, we learn three
interpretable thermodynamic coordinates and build a dynamical landscape of
polymer stretching, including (1) the identification of stable and transition
states and (2) the control of the stretching rate. We further demonstrate the
universality of our approach by applying it to an unrelated problem in a
different domain: constructing macroscopic dynamics for spatial epidemics,
showing that our method addresses wide scientific and technological
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiaoli Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Soh_B/0/1/0/all/0/1&quot;&gt;Beatrice W. Soh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Ooi_Z/0/1/0/all/0/1&quot;&gt;Zi-En Ooi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Vissol_Gaudin_E/0/1/0/all/0/1&quot;&gt;Eleonore Vissol-Gaudin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Haijun Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Novoselov_K/0/1/0/all/0/1&quot;&gt;Kostya S. Novoselov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Hippalgaonkar_K/0/1/0/all/0/1&quot;&gt;Kedar Hippalgaonkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qianxiao Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04126">
<title>OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation. (arXiv:2308.04126v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.04126</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents OmniDataComposer, an innovative approach for multimodal
data fusion and unlimited data generation with an intent to refine and
uncomplicate interplay among diverse data modalities. Coming to the core
breakthrough, it introduces a cohesive data structure proficient in processing
and merging multimodal data inputs, which include video, audio, and text. Our
crafted algorithm leverages advancements across multiple operations such as
video/image caption extraction, dense caption extraction, Automatic Speech
Recognition (ASR), Optical Character Recognition (OCR), Recognize Anything
Model(RAM), and object tracking. OmniDataComposer is capable of identifying
over 6400 categories of objects, substantially broadening the spectrum of
visual information. It amalgamates these diverse modalities, promoting
reciprocal enhancement among modalities and facilitating cross-modal data
correction. \textbf{The final output metamorphoses each video input into an
elaborate sequential document}, virtually transmuting videos into thorough
narratives, making them easier to be processed by large language models. Future
prospects include optimizing datasets for each modality to encourage unlimited
data generation. This robust base will offer priceless insights to models like
ChatGPT, enabling them to create higher quality datasets for video captioning
and easing question-answering tasks based on video content. OmniDataComposer
inaugurates a new stage in multimodal learning, imparting enormous potential
for augmenting AI&apos;s understanding and generation of complex, real-world data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1&quot;&gt;Dongyang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shihao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1&quot;&gt;Yuan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+An_W/0/1/0/all/0/1&quot;&gt;Wangpeng An&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04137">
<title>Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness. (arXiv:2308.04137v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04137</link>
<description rdf:parseType="Literal">&lt;p&gt;Reliable and robust evaluation methods are a necessary first step towards
developing machine learning models that are themselves robust and reliable.
Unfortunately, current evaluation protocols typically used to assess
classifiers fail to comprehensively evaluate performance as they tend to rely
on limited types of test data, and ignore others. For example, using the
standard test data fails to evaluate the predictions made by the classifier to
samples from classes it was not trained on. On the other hand, testing with
data containing samples from unknown classes fails to evaluate how well the
classifier can predict the labels for known classes. This article advocates
bench-marking performance using a wide range of different types of data and
using a single metric that can be applied to all such data types to produce a
consistent evaluation of performance. Using such a benchmark it is found that
current deep neural networks, including those trained with methods that are
believed to produce state-of-the-art robustness, are extremely vulnerable to
making mistakes on certain types of data. This means that such models will be
unreliable in real-world scenarios where they may encounter data from many
different domains, and that they are insecure as they can easily be fooled into
making the wrong decisions. It is hoped that these results will motivate the
wider adoption of more comprehensive testing methods that will, in turn, lead
to the development of more robust machine learning methods in the future.
&lt;/p&gt;
&lt;p&gt;Code is available at:
\url{https://codeberg.org/mwspratling/RobustnessEvaluation}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spratling_M/0/1/0/all/0/1&quot;&gt;Michael W. Spratling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04169">
<title>Dual input neural networks for positional sound source localization. (arXiv:2308.04169v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2308.04169</link>
<description rdf:parseType="Literal">&lt;p&gt;In many signal processing applications, metadata may be advantageously used
in conjunction with a high dimensional signal to produce a desired output. In
the case of classical Sound Source Localization (SSL) algorithms, information
from a high dimensional, multichannel audio signals received by many
distributed microphones is combined with information describing acoustic
properties of the scene, such as the microphones&apos; coordinates in space, to
estimate the position of a sound source. We introduce Dual Input Neural
Networks (DI-NNs) as a simple and effective way to model these two data types
in a neural network. We train and evaluate our proposed DI-NN on scenarios of
varying difficulty and realism and compare it against an alternative
architecture, a classical Least-Squares (LS) method as well as a classical
Convolutional Recurrent Neural Network (CRNN). Our results show that the DI-NN
significantly outperforms the baselines, achieving a five times lower
localization error than the LS method and two times lower than the CRNN in a
test dataset of real recordings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grinstein_E/0/1/0/all/0/1&quot;&gt;Eric Grinstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neo_V/0/1/0/all/0/1&quot;&gt;Vincent W. Neo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naylor_P/0/1/0/all/0/1&quot;&gt;Patrick A. Naylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04180">
<title>Studying Socially Unacceptable Discourse Classification (SUD) through different eyes: &quot;Are we on the same page ?&quot;. (arXiv:2308.04180v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.04180</link>
<description rdf:parseType="Literal">&lt;p&gt;We study Socially Unacceptable Discourse (SUD) characterization and detection
in online text. We first build and present a novel corpus that contains a large
variety of manually annotated texts from different online sources used so far
in state-of-the-art Machine learning (ML) SUD detection solutions. This global
context allows us to test the generalization ability of SUD classifiers that
acquire knowledge around the same SUD categories, but from different contexts.
From this perspective, we can analyze how (possibly) different annotation
modalities influence SUD learning by discussing open challenges and open
research directions. We also provide several data insights which can support
domain experts in the annotation task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carneiro_B/0/1/0/all/0/1&quot;&gt;Bruno Machado Carneiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Linardi_M/0/1/0/all/0/1&quot;&gt;Michele Linardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Longhi_J/0/1/0/all/0/1&quot;&gt;Julien Longhi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04185">
<title>Iterative Sketching for Secure Coded Regression. (arXiv:2308.04185v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2308.04185</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose methods for speeding up linear regression
distributively, while ensuring security. We leverage randomized sketching
techniques, and improve straggler resilience in asynchronous systems.
Specifically, we apply a random orthonormal matrix and then subsample
\textit{blocks}, to simultaneously secure the information and reduce the
dimension of the regression problem. In our setup, the transformation
corresponds to an encoded encryption in an \textit{approximate gradient coding
scheme}, and the subsampling corresponds to the responses of the non-straggling
workers; in a centralized coded computing network. This results in a
distributive \textit{iterative sketching} approach for an $\ell_2$-subspace
embedding, \textit{i.e.} a new sketch is considered at each iteration. We also
focus on the special case of the \textit{Subsampled Randomized Hadamard
Transform}, which we generalize to block sampling; and discuss how it can be
modified in order to secure the data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charalambides_N/0/1/0/all/0/1&quot;&gt;Neophytos Charalambides&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahdavifar_H/0/1/0/all/0/1&quot;&gt;Hessam Mahdavifar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1&quot;&gt;Mert Pilanci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hero_A/0/1/0/all/0/1&quot;&gt;Alfred O. Hero III&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04212">
<title>Varying-coefficients for regional quantile via KNN-based LASSO with applications to health outcome study. (arXiv:2308.04212v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2308.04212</link>
<description rdf:parseType="Literal">&lt;p&gt;Health outcomes, such as body mass index and cholesterol levels, are known to
be dependent on age and exhibit varying effects with their associated risk
factors. In this paper, we propose a novel framework for dynamic modeling of
the associations between health outcomes and risk factors using
varying-coefficients (VC) regional quantile regression via K-nearest neighbors
(KNN) fused Lasso, which captures the time-varying effects of age. The proposed
method has strong theoretical properties, including a tight estimation error
bound and the ability to detect exact clustered patterns under certain
regularity conditions. To efficiently solve the resulting optimization problem,
we develop an alternating direction method of multipliers (ADMM) algorithm. Our
empirical results demonstrate the efficacy of the proposed method in capturing
the complex age-dependent associations between health outcomes and their risk
factors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Seyoung Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_E/0/1/0/all/0/1&quot;&gt;Eun Ryung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hong_H/0/1/0/all/0/1&quot;&gt;Hyokyoung G. Hong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04220">
<title>Semantic Interpretation and Validation of Graph Attention-based Explanations for GNN Models. (arXiv:2308.04220v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04220</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a methodology for investigating the application of
semantic attention to enhance the explainability of Graph Neural Network
(GNN)-based models, introducing semantically-informed perturbations and
establishing a correlation between predicted feature-importance weights and
model accuracy. Graph Deep Learning (GDL) has emerged as a promising field for
tasks like scene interpretation, leveraging flexible graph structures to
concisely describe complex features and relationships. As traditional
explainability methods used in eXplainable AI (XAI) cannot be directly applied
to such structures, graph-specific approaches are introduced. Attention
mechanisms have demonstrated their efficacy in estimating the importance of
input features in deep learning models and thus have been previously employed
to provide feature-based explanations for GNN predictions. Building upon these
insights, we extend existing attention-based graph-explainability methods
investigating the use of attention weights as importance indicators of
semantically sorted feature sets. Through analysing the behaviour of predicted
attention-weights distribution in correlation with model accuracy, we gain
valuable insights into feature importance with respect to the behaviour of the
GNN model. We apply our methodology to a lidar pointcloud estimation model
successfully identifying key semantic classes that contribute to enhanced
performance effectively generating reliable post-hoc semantic explanations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panagiotaki_E/0/1/0/all/0/1&quot;&gt;Efimia Panagiotaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martini_D/0/1/0/all/0/1&quot;&gt;Daniele De Martini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kunze_L/0/1/0/all/0/1&quot;&gt;Lars Kunze&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04226">
<title>OpinionConv: Conversational Product Search with Grounded Opinions. (arXiv:2308.04226v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2308.04226</link>
<description rdf:parseType="Literal">&lt;p&gt;When searching for products, the opinions of others play an important role in
making informed decisions. Subjective experiences about a product can be a
valuable source of information. This is also true in sales conversations, where
a customer and a sales assistant exchange facts and opinions about products.
However, training an AI for such conversations is complicated by the fact that
language models do not possess authentic opinions for their lack of real-world
experience. We address this problem by leveraging product reviews as a rich
source of product opinions to ground conversational AI in true subjective
narratives. With OpinionConv, we develop the first conversational AI for
simulating sales conversations. To validate the generated conversations, we
conduct several user studies showing that the generated opinions are perceived
as realistic. Our assessors also confirm the importance of opinions as an
informative basis for decision-making.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javadi_V/0/1/0/all/0/1&quot;&gt;Vahid Sadiri Javadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potthast_M/0/1/0/all/0/1&quot;&gt;Martin Potthast&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flek_L/0/1/0/all/0/1&quot;&gt;Lucie Flek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04237">
<title>Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction. (arXiv:2308.04237v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2308.04237</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider a setting in which devices and a server share a pre-trained model.
The server wishes to make an inference on a new input given the model. Devices
have access to data, previously not used for training, and can communicate to
the server over a common wireless channel. If the devices have no access to the
new input, can communication from devices to the server enhance the quality of
the inference decision at the server? Recent work has introduced federated
conformal prediction (CP), which leverages devices-to-server communication to
improve the reliability of the server&apos;s decision. With federated CP, devices
communicate to the server information about the loss accrued by the shared
pre-trained model on the local data, and the server leverages this information
to calibrate a decision interval, or set, so that it is guaranteed to contain
the correct answer with a pre-defined target reliability level. Previous work
assumed noise-free communication, whereby devices can communicate a single real
number to the server. In this paper, we study for the first time federated CP
in a wireless setting. We introduce a novel protocol, termed wireless federated
conformal prediction (WFCP), which builds on type-based multiple access (TBMA)
and on a novel quantile correction strategy. WFCP is proved to provide formal
reliability guarantees in terms of coverage of the predicted set produced by
the server. Using numerical results, we demonstrate the significant advantages
of WFCP against digital implementations of existing federated CP schemes,
especially in regimes with limited communication resources and/or large number
of devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Meiyi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zecchin_M/0/1/0/all/0/1&quot;&gt;Matteo Zecchin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sangwoo Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1&quot;&gt;Caili Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1&quot;&gt;Chunyan Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1&quot;&gt;Osvaldo Simeone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04258">
<title>Advancing Natural-Language Based Audio Retrieval with PaSST and Large Audio-Caption Data Sets. (arXiv:2308.04258v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2308.04258</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents a text-to-audio-retrieval system based on pre-trained text
and spectrogram transformers. Our method projects recordings and textual
descriptions into a shared audio-caption space in which related examples from
different modalities are close. Through a systematic analysis, we examine how
each component of the system influences retrieval performance. As a result, we
identify two key components that play a crucial role in driving performance:
the self-attention-based audio encoder for audio embedding and the utilization
of additional human-generated and synthetic data sets during pre-training. We
further experimented with augmenting ClothoV2 captions with available keywords
to increase their variety; however, this only led to marginal improvements. Our
system ranked first in the 2023&apos;s DCASE Challenge, and it outperforms the
current state of the art on the ClothoV2 benchmark by 5.6 pp. mAP@10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Primus_P/0/1/0/all/0/1&quot;&gt;Paul Primus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Koutini_K/0/1/0/all/0/1&quot;&gt;Khaled Koutini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Widmer_G/0/1/0/all/0/1&quot;&gt;Gerhard Widmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04262">
<title>SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction. (arXiv:2308.04262v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2308.04262</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformers have emerged as viable alternatives to convolutional neural
networks owing to their ability to learn non-local region relationships in the
spatial domain. The self-attention mechanism of the transformer enables
transformers to capture long-range dependencies in the images, which might be
desirable for accelerated MRI image reconstruction as the effect of
undersampling is non-local in the image domain. Despite its computational
efficiency, the window-based transformers suffer from restricted receptive
fields as the dependencies are limited to within the scope of the image
windows. We propose a window-based transformer network that integrates dilated
attention mechanism and convolution for accelerated MRI image reconstruction.
The proposed network consists of dilated and dense neighborhood attention
transformers to enhance the distant neighborhood pixel relationship and
introduce depth-wise convolutions within the transformer module to learn
low-level translation invariant features for accelerated MRI image
reconstruction. The proposed model is trained in a self-supervised manner. We
perform extensive experiments for multi-coil MRI acceleration for coronal PD,
coronal PDFS and axial T2 contrasts with 4x and 5x under-sampling in
self-supervised learning based on k-space splitting. We compare our method
against other reconstruction architectures and the parallel domain
self-supervised learning baseline. Results show that the proposed model
exhibits improvement margins of (i) around 1.40 dB in PSNR and around 0.028 in
SSIM on average over other architectures (ii) around 1.44 dB in PSNR and around
0.029 in SSIM over parallel domain self-supervised learning. The code is
available at https://github.com/rahul-gs-16/sdlformer.git
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+S%2E_R/0/1/0/all/0/1&quot;&gt;Rahul G.S.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ramnarayanan_S/0/1/0/all/0/1&quot;&gt;Sriprabha Ramnarayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fahim_M/0/1/0/all/0/1&quot;&gt;Mohammad Al Fahim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ram_K/0/1/0/all/0/1&quot;&gt;Keerthi Ram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+P_P/0/1/0/all/0/1&quot;&gt;Preejith S.P&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sivaprakasam_M/0/1/0/all/0/1&quot;&gt;Mohanasankar Sivaprakasam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04263">
<title>BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning. (arXiv:2308.04263v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04263</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces BarlowRL, a data-efficient reinforcement learning agent
that combines the Barlow Twins self-supervised learning framework with DER
(Data-Efficient Rainbow) algorithm. BarlowRL outperforms both DER and its
contrastive counterpart CURL on the Atari 100k benchmark. BarlowRL avoids
dimensional collapse by enforcing information spread to the whole space. This
helps RL algorithms to utilize uniformly spread state representation that
eventually results in a remarkable performance. The integration of Barlow Twins
with DER enhances data efficiency and achieves superior performance in the RL
tasks. BarlowRL demonstrates the potential of incorporating self-supervised
learning techniques to improve RL algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cagatan_O/0/1/0/all/0/1&quot;&gt;Omer Veysel Cagatan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04268">
<title>Teacher-Student Architecture for Knowledge Distillation: A Survey. (arXiv:2308.04268v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04268</link>
<description rdf:parseType="Literal">&lt;p&gt;Although Deep neural networks (DNNs) have shown a strong capacity to solve
large-scale problems in many areas, such DNNs are hard to be deployed in
real-world systems due to their voluminous parameters. To tackle this issue,
Teacher-Student architectures were proposed, where simple student networks with
a few parameters can achieve comparable performance to deep teacher networks
with many parameters. Recently, Teacher-Student architectures have been
effectively and widely embraced on various knowledge distillation (KD)
objectives, including knowledge compression, knowledge expansion, knowledge
adaptation, and knowledge enhancement. With the help of Teacher-Student
architectures, current studies are able to achieve multiple distillation
objectives through lightweight and generalized student networks. Different from
existing KD surveys that primarily focus on knowledge compression, this survey
first explores Teacher-Student architectures across multiple distillation
objectives. This survey presents an introduction to various knowledge
representations and their corresponding optimization objectives. Additionally,
we provide a systematic overview of Teacher-Student architectures with
representative learning algorithms and effective distillation schemes. This
survey also summarizes recent applications of Teacher-Student architectures
across multiple purposes, including classification, recognition, generation,
ranking, and regression. Lastly, potential research directions in KD are
investigated, focusing on architecture design, knowledge quality, and
theoretical studies of regression-based learning, respectively. Through this
comprehensive survey, industry practitioners and the academic community can
gain valuable insights and guidelines for effectively designing, learning, and
applying Teacher-Student architectures on various distillation objectives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1&quot;&gt;Chengming Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Dan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Haolun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Ju Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xue Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04275">
<title>In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning. (arXiv:2308.04275v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.04275</link>
<description rdf:parseType="Literal">&lt;p&gt;In this note, we explore inference-time alignment through in-context
learning. We consider a vanilla pretrained language model Llama-2 before any
fine-tuning and retrieve an average of 9 demonstration alignment examples when
the model is prompted to follow chat-style instructions. Compared to direct
prompting, the in-context alignment without changing model weights leads to a
7x increase in win-rate w.r.t. the text-davinci-003 model from OpenAI, making
the vanilla language model comparable to strong baselines with alignment
fine-tuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1&quot;&gt;Xiaochuang Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04286">
<title>Comparative Analysis of the wav2vec 2.0 Feature Extractor. (arXiv:2308.04286v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2308.04286</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic speech recognition (ASR) systems typically use handcrafted feature
extraction pipelines. To avoid their inherent information loss and to achieve
more consistent modeling from speech to transcribed text, neural raw waveform
feature extractors (FEs) are an appealing approach. Also the wav2vec 2.0 model,
which has recently gained large popularity, uses a convolutional FE which
operates directly on the speech waveform. However, it is not yet studied
extensively in the literature. In this work, we study its capability to replace
the standard feature extraction methods in a connectionist temporal
classification (CTC) ASR model and compare it to an alternative neural FE. We
show that both are competitive with traditional FEs on the LibriSpeech
benchmark and analyze the effect of the individual components. Furthermore, we
analyze the learned filters and show that the most important information for
the ASR system is obtained by a set of bandpass filters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Vieting_P/0/1/0/all/0/1&quot;&gt;Peter Vieting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1&quot;&gt;Ralf Schl&amp;#xfc;ter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ney_H/0/1/0/all/0/1&quot;&gt;Hermann Ney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04304">
<title>The Model Inversion Eavesdropping Attack in Semantic Communication Systems. (arXiv:2308.04304v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2308.04304</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, semantic communication has been a popular research topic for
its superiority in communication efficiency. As semantic communication relies
on deep learning to extract meaning from raw messages, it is vulnerable to
attacks targeting deep learning models. In this paper, we introduce the model
inversion eavesdropping attack (MIEA) to reveal the risk of privacy leaks in
the semantic communication system. In MIEA, the attacker first eavesdrops the
signal being transmitted by the semantic communication system and then performs
model inversion attack to reconstruct the raw message, where both the white-box
and black-box settings are considered. Evaluation results show that MIEA can
successfully reconstruct the raw message with good quality under different
channel conditions. We then propose a defense method based on random
permutation and substitution to defend against MIEA in order to achieve secure
semantic communication. Our experimental results demonstrate the effectiveness
of the proposed defense method in preventing MIEA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuhao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qianqian Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zhiguo Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiming Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04314">
<title>Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs. (arXiv:2308.04314v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04314</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, there has been extensive study of cooperative multi-agent
multi-armed bandits where a set of distributed agents cooperatively play the
same multi-armed bandit game. The goal is to develop bandit algorithms with the
optimal group and individual regrets and low communication between agents. The
prior work tackled this problem using two paradigms: leader-follower and fully
distributed algorithms. Prior algorithms in both paradigms achieve the optimal
group regret. The leader-follower algorithms achieve constant communication
costs but fail to achieve optimal individual regrets. The state-of-the-art
fully distributed algorithms achieve optimal individual regrets but fail to
achieve constant communication costs. This paper presents a simple yet
effective communication policy and integrates it into a learning algorithm for
cooperative bandits. Our algorithm achieves the best of both paradigms: optimal
individual regret and constant communication costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xuchuang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1&quot;&gt;Mohammad Hajiesmaili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lijun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1&quot;&gt;John C.S. Lui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1&quot;&gt;Don Towsley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04332">
<title>RLHF-Blender: A Configurable Interactive Interface for Learning from Diverse Human Feedback. (arXiv:2308.04332v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04332</link>
<description rdf:parseType="Literal">&lt;p&gt;To use reinforcement learning from human feedback (RLHF) in practical
applications, it is crucial to learn reward models from diverse sources of
human feedback and to consider human factors involved in providing feedback of
different types. However, the systematic study of learning from diverse types
of feedback is held back by limited standardized tooling available to
researchers. To bridge this gap, we propose RLHF-Blender, a configurable,
interactive interface for learning from human feedback. RLHF-Blender provides a
modular experimentation framework and implementation that enables researchers
to systematically investigate the properties and qualities of human feedback
for reward learning. The system facilitates the exploration of various feedback
types, including demonstrations, rankings, comparisons, and natural language
instructions, as well as studies considering the impact of human factors on
their effectiveness. We discuss a set of concrete research opportunities
enabled by RLHF-Blender. More information is available at
https://rlhfblender.info/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metz_Y/0/1/0/all/0/1&quot;&gt;Yannick Metz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindner_D/0/1/0/all/0/1&quot;&gt;David Lindner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baur_R/0/1/0/all/0/1&quot;&gt;Rapha&amp;#xeb;l Baur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keim_D/0/1/0/all/0/1&quot;&gt;Daniel Keim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Assady_M/0/1/0/all/0/1&quot;&gt;Mennatallah El-Assady&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04341">
<title>Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage. (arXiv:2308.04341v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04341</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning models are increasingly utilized across impactful domains to
predict individual outcomes. As such, many models provide algorithmic recourse
to individuals who receive negative outcomes. However, recourse can be
leveraged by adversaries to disclose private information. This work presents
the first attempt at mitigating such attacks. We present two novel methods to
generate differentially private recourse: Differentially Private Model (DPM)
and Laplace Recourse (LR). Using logistic regression classifiers and real world
and synthetic datasets, we find that DPM and LR perform well in reducing what
an adversary can infer, especially at low FPR. When training dataset size is
large enough, we find particular success in preventing privacy leakage while
maintaining model and recourse accuracy with our novel LR method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Catherine Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swoopes_C/0/1/0/all/0/1&quot;&gt;Chelse Swoopes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1&quot;&gt;Christina Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jiaqi Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1&quot;&gt;Himabindu Lakkaraju&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04365">
<title>SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2308.04365</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference is a crucial goal of science, enabling researchers to arrive
at meaningful conclusions regarding the predictions of hypothetical
interventions using observational data. Path models, Structural Equation Models
(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to
unambiguously specify assumptions regarding the causal structure underlying a
phenomenon. Unlike DAGs, which make very few assumptions about the functional
and parametric form, SEM assumes linearity. This can result in functional
misspecification which prevents researchers from undertaking reliable effect
size estimation. In contrast, we propose Super Learner Equation Modeling, a
path modeling technique integrating machine learning Super Learner ensembles.
We empirically demonstrate its ability to provide consistent and unbiased
estimates of causal effects, its competitive performance for linear models when
compared with SEM, and highlight its superiority over SEM when dealing with
non-linear relationships. We provide open-source code, and a tutorial notebook
with example usage, accentuating the easy-to-use nature of the method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vowels_M/0/1/0/all/0/1&quot;&gt;Matthew J. Vowels&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04373">
<title>Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning. (arXiv:2308.04373v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04373</link>
<description rdf:parseType="Literal">&lt;p&gt;The main premise of federated learning is that machine learning model updates
are computed locally, in particular to preserve user data privacy, as those
never leave the perimeter of their device. This mechanism supposes the general
model, once aggregated, to be broadcast to collaborating and non malicious
nodes. However, without proper defenses, compromised clients can easily probe
the model inside their local memory in search of adversarial examples. For
instance, considering image-based applications, adversarial examples consist of
imperceptibly perturbed images (to the human eye) misclassified by the local
model, which can be later presented to a victim node&apos;s counterpart model to
replicate the attack. To mitigate such malicious probing, we introduce Pelta, a
novel shielding mechanism leveraging trusted hardware. By harnessing the
capabilities of Trusted Execution Environments (TEEs), Pelta masks part of the
back-propagation chain rule, otherwise typically exploited by attackers for the
design of malicious samples. We evaluate Pelta on a state of the art ensemble
model and demonstrate its effectiveness against the Self Attention Gradient
adversarial Attack.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Queyrut_S/0/1/0/all/0/1&quot;&gt;Simon Queyrut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bromberg_Y/0/1/0/all/0/1&quot;&gt;Y&amp;#xe9;rom-David Bromberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schiavoni_V/0/1/0/all/0/1&quot;&gt;Valerio Schiavoni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04375">
<title>Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making. (arXiv:2308.04375v1 [cs.HC])</title>
<link>http://arxiv.org/abs/2308.04375</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial intelligence (AI) is increasingly being considered to assist human
decision-making in high-stake domains (e.g. health). However, researchers have
discussed an issue that humans can over-rely on wrong suggestions of the AI
model instead of achieving human AI complementary performance. In this work, we
utilized salient feature explanations along with what-if, counterfactual
explanations to make humans review AI suggestions more analytically to reduce
overreliance on AI and explored the effect of these explanations on trust and
reliance on AI during clinical decision-making. We conducted an experiment with
seven therapists and ten laypersons on the task of assessing post-stroke
survivors&apos; quality of motion, and analyzed their performance, agreement level
on the task, and reliance on AI without and with two types of AI explanations.
Our results showed that the AI model with both salient features and
counterfactual explanations assisted therapists and laypersons to improve their
performance and agreement level on the task when `right&apos; AI outputs are
presented. While both therapists and laypersons over-relied on `wrong&apos; AI
outputs, counterfactual explanations assisted both therapists and laypersons to
reduce their over-reliance on `wrong&apos; AI outputs by 21\% compared to salient
feature explanations. Specifically, laypersons had higher performance degrades
by 18.0 f1-score with salient feature explanations and 14.0 f1-score with
counterfactual explanations than therapists with performance degrades of 8.6
and 2.8 f1-scores respectively. Our work discusses the potential of
counterfactual explanations to better estimate the accuracy of an AI model and
reduce over-reliance on `wrong&apos; AI outputs and implications for improving
human-AI collaborative decision-making.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1&quot;&gt;Min Hun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chew_C/0/1/0/all/0/1&quot;&gt;Chong Jun Chew&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04395">
<title>Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging. (arXiv:2308.04395v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2308.04395</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning-based models in medical imaging often struggle to generalize
effectively to new scans due to data heterogeneity arising from differences in
hardware, acquisition parameters, population, and artifacts. This limitation
presents a significant challenge in adopting machine learning models for
clinical practice. We propose an unsupervised method for robust domain
adaptation in brain MRI segmentation by leveraging MRI-specific augmentation
techniques. To evaluate the effectiveness of our method, we conduct extensive
experiments across diverse datasets, modalities, and segmentation tasks,
comparing against the state-of-the-art methods. The results show that our
proposed approach achieves high accuracy, exhibits broad applicability, and
showcases remarkable robustness against domain shift in various tasks,
surpassing the state-of-the-art performance in the majority of cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Llambias_S/0/1/0/all/0/1&quot;&gt;Sebastian N&amp;#xf8;rgaard Llambias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nielsen_M/0/1/0/all/0/1&quot;&gt;Mads Nielsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ghazi_M/0/1/0/all/0/1&quot;&gt;Mostafa Mehdipour Ghazi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04396">
<title>Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining. (arXiv:2308.04396v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04396</link>
<description rdf:parseType="Literal">&lt;p&gt;One aim of Process Mining (PM) is the discovery of process models from event
logs of information systems. PM has been successfully applied to
process-oriented enterprise systems but is less suited for communication- and
document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are
very fine-granular and PM applied to their logs results in spaghetti models. A
common solution for this is event abstraction, i.e., converting low-level logs
into more abstract high-level logs before running discovery algorithms. ECS
logs come with special characteristics that have so far not been fully
addressed by existing event abstraction approaches. We aim to close this gap
with a tailored ECS event abstraction (ECSEA) approach that trains a model by
comparing recorded actual user activities (high-level traces) with the
system-generated low-level traces (extracted from the ECS). The model allows us
to automatically convert future low-level traces into an abstracted high-level
log that can be used for PM. Our evaluation shows that the algorithm produces
accurate results. ECSEA is a preprocessing method that is essential for the
interpretation of collaborative work activity in ECS, which we call Social
Process Mining.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blatt_J/0/1/0/all/0/1&quot;&gt;Jonas Blatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delfmann_P/0/1/0/all/0/1&quot;&gt;Patrick Delfmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schubert_P/0/1/0/all/0/1&quot;&gt;Petra Schubert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04404">
<title>Revolutionizing Wireless Networks with Federated Learning: A Comprehensive Review. (arXiv:2308.04404v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04404</link>
<description rdf:parseType="Literal">&lt;p&gt;These days with the rising computational capabilities of wireless user
equipment such as smart phones, tablets, and vehicles, along with growing
concerns about sharing private data, a novel machine learning model called
federated learning (FL) has emerged. FL enables the separation of data
acquisition and computation at the central unit, which is different from
centralized learning that occurs in a data center. FL is typically used in a
wireless edge network where communication resources are limited and unreliable.
Bandwidth constraints necessitate scheduling only a subset of UEs for updates
in each iteration, and because the wireless medium is shared, transmissions are
susceptible to interference and are not assured. The article discusses the
significance of Machine Learning in wireless communication and highlights
Federated Learning (FL) as a novel approach that could play a vital role in
future mobile networks, particularly 6G and beyond.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahdimahalleh_S/0/1/0/all/0/1&quot;&gt;Sajjad Emdadi Mahdimahalleh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04406">
<title>XGBD: Explanation-Guided Graph Backdoor Detection. (arXiv:2308.04406v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2308.04406</link>
<description rdf:parseType="Literal">&lt;p&gt;Backdoor attacks pose a significant security risk to graph learning models.
Backdoors can be embedded into the target model by inserting backdoor triggers
into the training dataset, causing the model to make incorrect predictions when
the trigger is present. To counter backdoor attacks, backdoor detection has
been proposed. An emerging detection strategy in the vision and NLP domains is
based on an intriguing phenomenon: when training models on a mixture of
backdoor and clean samples, the loss on backdoor samples drops significantly
faster than on clean samples, allowing backdoor samples to be easily detected
by selecting samples with the lowest loss values. However, the ignorance of
topological feature information on graph data limits its detection
effectiveness when applied directly to the graph domain. To this end, we
propose an explanation-guided backdoor detection method to take advantage of
the topological information. Specifically, we train a helper model on the graph
dataset, feed graph samples into the model, and then adopt explanation methods
to attribute model prediction to an important subgraph. We observe that
backdoor samples have distinct attribution distribution than clean samples, so
the explanatory subgraph could serve as more discriminative features for
detecting backdoor samples. Comprehensive experiments on multiple popular
datasets and attack methods demonstrate the effectiveness and explainability of
our method. Our code is available:
https://github.com/GuanZihan/GNN_backdoor_detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_Z/0/1/0/all/0/1&quot;&gt;Zihan Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1&quot;&gt;Mengnan Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1&quot;&gt;Ninghao Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04412">
<title>Probabilistic Invariant Learning with Randomized Linear Classifiers. (arXiv:2308.04412v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04412</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing models that are both expressive and preserve known invariances of
tasks is an increasingly hard problem. Existing solutions tradeoff invariance
for computational or memory resources. In this work, we show how to leverage
randomness and design models that are both expressive and invariant but use
less resources. Inspired by randomized algorithms, our key insight is that
accepting probabilistic notions of universal approximation and invariance can
reduce our resource requirements. More specifically, we propose a class of
binary classification models called Randomized Linear Classifiers (RLCs). We
give parameter and sample size conditions in which RLCs can, with high
probability, approximate any (smooth) function while preserving invariance to
compact group transformations. Leveraging this result, we design three RLCs
that are provably probabilistic invariant for classification tasks over sets,
graphs, and spherical data. We show how these models can achieve probabilistic
invariance and universality using less resources than (deterministic) neural
networks and their invariant counterparts. Finally, we empirically demonstrate
the benefits of this new class of models on invariant tasks where deterministic
invariant neural networks are known to struggle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotta_L/0/1/0/all/0/1&quot;&gt;Leonardo Cotta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yehuda_G/0/1/0/all/0/1&quot;&gt;Gal Yehuda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuster_A/0/1/0/all/0/1&quot;&gt;Assaf Schuster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1&quot;&gt;Chris J. Maddison&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04417">
<title>DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images. (arXiv:2308.04417v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.04417</link>
<description rdf:parseType="Literal">&lt;p&gt;Optical satellite images are a critical data source; however, cloud cover
often compromises their quality, hindering image applications and analysis.
Consequently, effectively removing clouds from optical satellite images has
emerged as a prominent research direction. While recent advancements in cloud
removal primarily rely on generative adversarial networks, which may yield
suboptimal image quality, diffusion models have demonstrated remarkable success
in diverse image-generation tasks, showcasing their potential in addressing
this challenge. This paper presents a novel framework called DiffCR, which
leverages conditional guided diffusion with deep convolutional networks for
high-performance cloud removal for optical satellite imagery. Specifically, we
introduce a decoupled encoder for conditional image feature extraction,
providing a robust color representation to ensure the close similarity of
appearance information between the conditional input and the synthesized
output. Moreover, we propose a novel and efficient time and condition fusion
block within the cloud removal model to accurately simulate the correspondence
between the appearance in the conditional image and the target image at a low
computational cost. Extensive experimental evaluations on two commonly used
benchmark datasets demonstrate that DiffCR consistently achieves
state-of-the-art performance on all metrics, with parameter and computational
complexities amounting to only 5.1% and 5.4%, respectively, of those previous
best methods. The source code, pre-trained models, and all the experimental
results will be publicly available at https://github.com/XavierJiezou/DiffCR
upon the paper&apos;s acceptance of this work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1&quot;&gt;Xuechao Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1&quot;&gt;Junliang Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shiying Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1&quot;&gt;Lei Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_P/0/1/0/all/0/1&quot;&gt;Pin Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04419">
<title>Stock Market Price Prediction: A Hybrid LSTM and Sequential Self-Attention based Approach. (arXiv:2308.04419v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2308.04419</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the most enticing research areas is the stock market, and projecting
stock prices may help investors profit by making the best decisions at the
correct time. Deep learning strategies have emerged as a critical technique in
the field of the financial market. The stock market is impacted due to two
aspects, one is the geo-political, social and global events on the bases of
which the price trends could be affected. Meanwhile, the second aspect purely
focuses on historical price trends and seasonality, allowing us to forecast
stock prices. In this paper, our aim is to focus on the second aspect and build
a model that predicts future prices with minimal errors. In order to provide
better prediction results of stock price, we propose a new model named Long
Short-Term Memory (LSTM) with Sequential Self-Attention Mechanism (LSTM-SSAM).
Finally, we conduct extensive experiments on the three stock datasets: SBIN,
HDFCBANK, and BANKBARODA. The experimental results prove the effectiveness and
feasibility of the proposed model compared to existing models. The experimental
findings demonstrate that the root-mean-squared error (RMSE), and R-square (R2)
evaluation indicators are giving the best results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pardeshi_K/0/1/0/all/0/1&quot;&gt;Karan Pardeshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gill_S/0/1/0/all/0/1&quot;&gt;Sukhpal Singh Gill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdelmoniem_A/0/1/0/all/0/1&quot;&gt;Ahmed M. Abdelmoniem&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04426">
<title>A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces. (arXiv:2308.04426v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2308.04426</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate detection of natural deterioration and man-made damage on the
surfaces of ancient stele in the first instance is essential for their
preventive conservation. Existing methods for cultural heritage preservation
are not able to achieve this goal perfectly due to the difficulty of balancing
accuracy, efficiency, timeliness, and cost. This paper presents a deep-learning
method to automatically detect above mentioned emergencies on ancient stone
stele in real time, employing autoencoder (AE) and generative adversarial
network (GAN). The proposed method overcomes the limitations of existing
methods by requiring no extensive anomaly samples while enabling comprehensive
detection of unpredictable anomalies. the method includes stages of monitoring,
data acquisition, pre-processing, model structuring, and post-processing.
Taking the Longmen Grottoes&apos; stone steles as a case study, an unsupervised
learning model based on AE and GAN architectures is proposed and validated with
a reconstruction accuracy of 99.74\%. The method&apos;s evaluation revealed the
proficient detection of seven artificially designed anomalies and demonstrated
precision and reliability without false alarms. This research provides novel
ideas and possibilities for the application of deep learning in the field of
cultural heritage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yikun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuning Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Cheng Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04428">
<title>Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2308.04428</link>
<description rdf:parseType="Literal">&lt;p&gt;A powerful concept behind much of the recent progress in machine learning is
the extraction of common features across data from heterogeneous sources or
tasks. Intuitively, using all of one&apos;s data to learn a common representation
function benefits both computational effort and statistical generalization by
leaving a smaller number of parameters to fine-tune on a given task. Toward
theoretically grounding these merits, we propose a general setting of
recovering linear operators $M$ from noisy vector measurements $y = Mx + w$,
where the covariates $x$ may be both non-i.i.d. and non-isotropic. We
demonstrate that existing isotropy-agnostic meta-learning approaches incur
biases on the representation update, which causes the scaling of the noise
terms to lose favorable dependence on the number of source tasks. This in turn
can cause the sample complexity of representation learning to be bottlenecked
by the single-task data size. We introduce an adaptation, $\texttt{De-bias &amp;amp;
Feature-Whiten}$ ($\texttt{DFW}$), of the popular alternating
minimization-descent (AMD) scheme proposed in Collins et al., (2021), and
establish linear convergence to the optimal representation with noise level
scaling down with the $\textit{total}$ source data size. This leads to
generalization bounds on the same order as an oracle empirical risk minimizer.
We verify the vital importance of $\texttt{DFW}$ on various numerical
simulations. In particular, we show that vanilla alternating-minimization
descent fails catastrophically even for iid, but mildly non-isotropic data. Our
analysis unifies and generalizes prior work, and provides a flexible framework
for a wider range of applications, such as in controls and dynamical systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Thomas T.C.K. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Toso_L/0/1/0/all/0/1&quot;&gt;Leonardo F. Toso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Anderson_J/0/1/0/all/0/1&quot;&gt;James Anderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Matni_N/0/1/0/all/0/1&quot;&gt;Nikolai Matni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04430">
<title>SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore. (arXiv:2308.04430v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2308.04430</link>
<description rdf:parseType="Literal">&lt;p&gt;The legality of training language models (LMs) on copyrighted or otherwise
restricted data is under intense debate. However, as we show, model performance
significantly degrades if trained only on low-risk text (e.g., out-of-copyright
books or government documents), due to its limited size and domain coverage. We
present SILO, a new language model that manages this risk-performance tradeoff
during inference. SILO is built by (1) training a parametric LM on Open License
Corpus (OLC), a new corpus we curate with 228B tokens of public domain and
permissively licensed text and (2) augmenting it with a more general and easily
modifiable nonparametric datastore (e.g., containing copyrighted books or news)
that is only queried during inference. The datastore allows use of high-risk
data without training on it, supports sentence-level data attribution, and
enables data producers to opt out from the model by removing content from the
store. These capabilities can foster compliance with data-use regulations such
as the fair use doctrine in the United States and the GDPR in the European
Union. Our experiments show that the parametric LM struggles on domains not
covered by OLC. However, access to the datastore greatly improves out of domain
performance, closing 90% of the performance gap with an LM trained on the Pile,
a more diverse corpus with mostly high-risk text. We also analyze which
nonparametric approach works best, where the remaining errors lie, and how
performance scales with datastore size. Our results suggest that it is possible
to build high quality language models while mitigating their legal risk.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1&quot;&gt;Sewon Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gururangan_S/0/1/0/all/0/1&quot;&gt;Suchin Gururangan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1&quot;&gt;Eric Wallace&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1&quot;&gt;Hannaneh Hajishirzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1&quot;&gt;Noah A. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1&quot;&gt;Luke Zettlemoyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04431">
<title>When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations. (arXiv:2308.04431v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2308.04431</link>
<description rdf:parseType="Literal">&lt;p&gt;In machine learning, incorporating more data is often seen as a reliable
strategy for improving model performance; this work challenges that notion by
demonstrating that the addition of external datasets in many cases can hurt the
resulting model&apos;s performance. In a large-scale empirical study across
combinations of four different open-source chest x-ray datasets and 9 different
labels, we demonstrate that in 43% of settings, a model trained on data from
two hospitals has poorer worst group accuracy over both hospitals than a model
trained on just a single hospital&apos;s data. This surprising result occurs even
though the added hospital makes the training distribution more similar to the
test distribution. We explain that this phenomenon arises from the spurious
correlation that emerges between the disease and hospital, due to
hospital-specific image artifacts. We highlight the trade-off one encounters
when training on multiple datasets, between the obvious benefit of additional
data and insidious cost of the introduced spurious correlation. In some cases,
balancing the dataset can remove the spurious correlation and improve
performance, but it is not always an effective strategy. We contextualize our
results within the literature on spurious correlations to help explain these
outcomes. Our experiments underscore the importance of exercising caution when
selecting training data for machine learning models, especially in settings
where there is a risk of spurious correlations such as with medical imaging.
The risks outlined highlight the need for careful data selection and model
evaluation in future research and practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Compton_R/0/1/0/all/0/1&quot;&gt;Rhys Compton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lily Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puli_A/0/1/0/all/0/1&quot;&gt;Aahlad Puli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1&quot;&gt;Rajesh Ranganath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1910.06832">
<title>Discriminator optimal transport. (arXiv:1910.06832v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1910.06832</link>
<description rdf:parseType="Literal">&lt;p&gt;Within a broad class of generative adversarial networks, we show that
discriminator optimization process increases a lower bound of the dual cost
function for the Wasserstein distance between the target distribution $p$ and
the generator distribution $p_G$. It implies that the trained discriminator can
approximate optimal transport (OT) from $p_G$ to $p$.Based on some experiments
and a bit of OT theory, we propose a discriminator optimal transport (DOT)
scheme to improve generated images. We show that it improves inception score
and FID calculated by un-conditional GAN trained by CIFAR-10, STL-10 and a
public pre-trained model of conditional GAN by ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tanaka_A/0/1/0/all/0/1&quot;&gt;Akinori Tanaka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2006.06926">
<title>Learning Bayesian Networks with Annealing Machine. (arXiv:2006.06926v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2006.06926</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have reported that annealing machines are capable of solving
combinatorial optimization problems with high accuracy. Annealing machines can
potentially be applied to score-based Bayesian network structure learning.
However, the bit capacity of an annealing machine is currently limited. To
utilize the annealing technology, converting score-based learning problems into
quadratic unconstrained binary optimizations within the bit capacity is
necessary. In this paper, we propose an efficient conversion method with the
advanced identification of candidate parent sets and their decomposition. We
also provide an integer programming problem to find the decomposition that
minimizes the number of required bits. Experimental results on $7$ benchmark
datasets with variables from $75$ to $223$ show that our approach requires less
bits than the $100$K bit capacity of the fourth-generation Fujitsu Digital
Annealer, a fully coupled annealing machine developed with semiconductor
technology. Moreover, we demonstrate that the Digital Annealer with our
conversion method outperforms existing algorithms on score maximization. These
results highlight the utility of annealing processors in learning Bayesian
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shikuri_Y/0/1/0/all/0/1&quot;&gt;Yuta Shikuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2101.08130">
<title>Machine learning for rapid discovery of laminar flow channel wall modifications that enhance heat transfer. (arXiv:2101.08130v2 [physics.flu-dyn] UPDATED)</title>
<link>http://arxiv.org/abs/2101.08130</link>
<description rdf:parseType="Literal">&lt;p&gt;Numerical simulation of fluids plays an essential role in modeling many
physical phenomena, which enables technological advancements, contributes to
sustainable practices, and expands our understanding of various natural and
engineered systems. The calculation of heat transfer in fluid flow in simple
flat channels is a relatively easy task for various simulation methods.
However, once the channel geometry becomes more complex, numerical simulations
become a bottleneck in optimizing wall geometries. We present a combination of
accurate numerical simulations of arbitrary, flat, and non-flat channels and
machine learning models predicting drag coefficient and Stanton number. We show
that convolutional neural networks (CNN) can accurately predict the target
properties at a fraction of the time of numerical simulations. We use the CNN
models in a virtual high-throughput screening approach to explore a large
number of possible, randomly generated wall architectures. Data Augmentation
was applied to existing geometries data to add generated new training data
which have the same number of parameters of heat transfer to improve the
model&apos;s generalization. The general approach is not only applicable to simple
flow setups as presented here but can be extended to more complex tasks, such
as multiphase or even reactive unit operations in chemical engineering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Koide_Y/0/1/0/all/0/1&quot;&gt;Yuri Koide&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kaithakkal_A/0/1/0/all/0/1&quot;&gt;Arjun J. Kaithakkal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Schniewind_M/0/1/0/all/0/1&quot;&gt;Matthias Schniewind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ladewig_B/0/1/0/all/0/1&quot;&gt;Bradley P. Ladewig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Stroh_A/0/1/0/all/0/1&quot;&gt;Alexander Stroh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Friederich_P/0/1/0/all/0/1&quot;&gt;Pascal Friederich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2105.02796">
<title>Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression. (arXiv:2105.02796v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2105.02796</link>
<description rdf:parseType="Literal">&lt;p&gt;Gaussian Process Regression is a popular nonparametric regression method
based on Bayesian principles that provides uncertainty estimates for its
predictions. However, these estimates are of a Bayesian nature, whereas for
some important applications, like learning-based control with safety
guarantees, frequentist uncertainty bounds are required. Although such rigorous
bounds are available for Gaussian Processes, they are too conservative to be
useful in applications. This often leads practitioners to replacing these
bounds by heuristics, thus breaking all theoretical guarantees. To address this
problem, we introduce new uncertainty bounds that are rigorous, yet practically
useful at the same time. In particular, the bounds can be explicitly evaluated
and are much less conservative than state of the art results. Furthermore, we
show that certain model misspecifications lead to only graceful degradation. We
demonstrate these advantages and the usefulness of our results for
learning-based control with numerical examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiedler_C/0/1/0/all/0/1&quot;&gt;Christian Fiedler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scherer_C/0/1/0/all/0/1&quot;&gt;Carsten W. Scherer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trimpe_S/0/1/0/all/0/1&quot;&gt;Sebastian Trimpe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.03159">
<title>Analysis of Regularized Learning for Linear-functional Data in Banach Spaces. (arXiv:2109.03159v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2109.03159</link>
<description rdf:parseType="Literal">&lt;p&gt;In this article, we study the whole theory of regularized learning for
linear-functional data in Banach spaces including representer theorems,
pseudo-approximation theorems, and convergence theorems. The input training
data are composed of linear functionals in the predual space of the Banach
space to represent the discrete local information of multimodel data and
multiscale models. The training data and the multi-loss functions are used to
compute the empirical risks to approximate the expected risks, and the
regularized learning is to minimize the regularized empirical risks over the
Banach spaces. The exact solutions of the original problems are approximated
globally by the regularized learning even if the original problems are unknown
or unformulated. In the convergence theorems, we show the convergence of the
approximate solutions to the exact solutions by the weak* topology of the
Banach space. Moreover, the theorems of the regularized learning are applied to
solve many problems of machine learning such as support vector machines and
artificial neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1&quot;&gt;Qi Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2111.10275">
<title>Composite Goodness-of-fit Tests with Kernels. (arXiv:2111.10275v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2111.10275</link>
<description rdf:parseType="Literal">&lt;p&gt;Model misspecification can create significant challenges for the
implementation of probabilistic models, and this has led to development of a
range of robust methods which directly account for this issue. However, whether
these more involved methods are required will depend on whether the model is
really misspecified, and there is a lack of generally applicable methods to
answer this question. In this paper, we propose one such method. More
precisely, we propose kernel-based hypothesis tests for the challenging
composite testing problem, where we are interested in whether the data comes
from any distribution in some parametric family. Our tests make use of minimum
distance estimators based on the maximum mean discrepancy and the kernel Stein
discrepancy. They are widely applicable, including whenever the density of the
parametric model is known up to normalisation constant, or if the model takes
the form of a simulator. As our main result, we show that we are able to
estimate the parameter and conduct our test on the same data (without data
splitting), while maintaining a correct test level. Our approach is illustrated
on a range of problems, including testing for goodness-of-fit of an
unnormalised non-parametric density model, and an intractable generative model
of a biological cellular network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Key_O/0/1/0/all/0/1&quot;&gt;Oscar Key&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1&quot;&gt;Arthur Gretton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Briol_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois-Xavier Briol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fernandez_T/0/1/0/all/0/1&quot;&gt;Tamara Fernandez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.04629">
<title>Transferability Properties of Graph Neural Networks. (arXiv:2112.04629v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2112.04629</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks (GNNs) are composed of layers consisting of graph
convolutions and pointwise nonlinearities. Due to their invariance and
stability properties, GNNs are provably successful at learning representations
from data supported on moderate-scale graphs. However, they are difficult to
learn on large-scale graphs. In this paper, we study the problem of training
GNNs on graphs of moderate size and transferring them to large-scale graphs. We
use graph limits called graphons to define limit objects for graph filters and
GNNs -- graphon filters and graphon neural networks (WNNs) -- which we
interpret as generative models for graph filters and GNNs. We then show that
graphon filters and WNNs can be approximated by graph filters and GNNs sampled
from them on weighted and stochastic graphs. Because the error of these
approximations can be upper bounded, by a triangle inequality argument we can
further bound the error of transferring a graph filter or a GNN across graphs.
Our results show that (i) the transference error decreases with the graph size,
and (ii) that graph filters have a transferability-discriminability tradeoff
that in GNNs is alleviated by the scattering behavior of the nonlinearity.
These findings are demonstrated empirically in a movie recommendation problem
and in a decentralized control task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruiz_L/0/1/0/all/0/1&quot;&gt;Luana Ruiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chamon_L/0/1/0/all/0/1&quot;&gt;Luiz F. O. Chamon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Alejandro Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2204.01248">
<title>Differentiable Rendering for Synthetic Aperture Radar Imagery. (arXiv:2204.01248v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2204.01248</link>
<description rdf:parseType="Literal">&lt;p&gt;There is rising interest in differentiable rendering, which allows explicitly
modeling geometric priors and constraints in optimization pipelines using
first-order methods such as backpropagation. Incorporating such domain
knowledge can lead to deep neural networks that are trained more robustly and
with limited data, as well as the capability to solve ill-posed inverse
problems. Existing efforts in differentiable rendering have focused on imagery
from electro-optical sensors, particularly conventional RGB-imagery. In this
work, we propose an approach for differentiable rendering of Synthetic Aperture
Radar (SAR) imagery, which combines methods from 3D computer graphics with
neural rendering. We demonstrate the approach on the inverse graphics problem
of 3D Object Reconstruction from limited SAR imagery using high-fidelity
simulated SAR data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wilmanski_M/0/1/0/all/0/1&quot;&gt;Michael Wilmanski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tamir_J/0/1/0/all/0/1&quot;&gt;Jonathan Tamir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.01186">
<title>ORC: Network Group-based Knowledge Distillation using Online Role Change. (arXiv:2206.01186v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.01186</link>
<description rdf:parseType="Literal">&lt;p&gt;In knowledge distillation, since a single, omnipotent teacher network cannot
solve all problems, multiple teacher-based knowledge distillations have been
studied recently. However, sometimes their improvements are not as good as
expected because some immature teachers may transfer the false knowledge to the
student. In this paper, to overcome this limitation and take the efficacy of
the multiple networks, we divide the multiple networks into teacher and student
groups, respectively. That is, the student group is a set of immature networks
that require learning the teacher&apos;s knowledge, while the teacher group consists
of the selected networks that are capable of teaching successfully. We propose
our online role change strategy where the top-ranked networks in the student
group are able to promote to the teacher group at every iteration. After
training the teacher group using the error samples of the student group to
refine the teacher group&apos;s knowledge, we transfer the collaborative knowledge
from the teacher group to the student group successfully. We verify the
superiority of the proposed method on CIFAR-10, CIFAR-100, and ImageNet which
achieves high performance. We further show the generality of our method with
various backbone architectures such as ResNet, WRN, VGG, Mobilenet, and
Shufflenet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Junyong Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1&quot;&gt;Hyeon Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_S/0/1/0/all/0/1&quot;&gt;Seokhwa Cheung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1&quot;&gt;Wonjun Hwang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2206.11004">
<title>Auto-Encoding Adversarial Imitation Learning. (arXiv:2206.11004v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2206.11004</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) provides a powerful framework for
decision-making, but its application in practice often requires a carefully
designed reward function. Adversarial Imitation Learning (AIL) sheds light on
automatic policy acquisition without access to the reward signal from the
environment. In this work, we propose Auto-Encoding Adversarial Imitation
Learning (AEAIL), a robust and scalable AIL framework. To induce expert
policies from demonstrations, AEAIL utilizes the reconstruction error of an
auto-encoder as a reward signal, which provides more information for optimizing
policies than the prior discriminator-based ones. Subsequently, we use the
derived objective functions to train the auto-encoder and the agent policy.
Experiments show that our AEAIL performs superior compared to state-of-the-art
methods on both state and image based environments. More importantly, AEAIL
shows much better robustness when the expert demonstrations are noisy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kaifeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1&quot;&gt;Rui Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Ziming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yang Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2207.07271">
<title>Set-based value operators for non-stationary Markovian environments. (arXiv:2207.07271v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2207.07271</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper analyzes finite state Markov Decision Processes (MDPs) with
uncertain parameters in compact sets and re-examines results from robust MDP
via set-based fixed point theory. To this end, we generalize the Bellman and
policy evaluation operators to contracting operators on the value function
space and denote them as \emph{value operators}. We lift these value operators
to act on \emph{sets} of value functions and denote them as \emph{set-based
value operators}. We prove that the set-based value operators are
\emph{contractions} in the space of compact value function sets. Leveraging
insights from set theory, we generalize the rectangularity condition in classic
robust MDP literature to a containment condition for all value operators, which
is weaker and can be applied to a larger set of parameter-uncertain MDPs and
contracting operators in dynamic programming. We prove that both the
rectangularity condition and the containment condition sufficiently ensure that
the set-based value operator&apos;s fixed point set contains its own extrema
elements. For convex and compact sets of uncertain MDP parameters, we show
equivalence between the classic robust value function and the supremum of the
fixed point set of the set-based Bellman operator. Under dynamically changing
MDP parameters in compact sets, we prove a set convergence result for value
iteration, which otherwise may not converge to a single value function.
Finally, we derive novel guarantees for probabilistic path-planning problems in
planet exploration and stratospheric station-keeping.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Sarah H.Q. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adje_A/0/1/0/all/0/1&quot;&gt;Assal&amp;#xe9; Adj&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garoche_P/0/1/0/all/0/1&quot;&gt;Pierre-Lo&amp;#xef;c Garoche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acikmese_B/0/1/0/all/0/1&quot;&gt;Beh&amp;#xe7;et A&amp;#xe7;&amp;#x131;kme&amp;#x15f;e&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.05785">
<title>Adversarial Coreset Selection for Efficient Robust Training. (arXiv:2209.05785v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.05785</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are vulnerable to adversarial attacks: adding well-crafted,
imperceptible perturbations to their input can modify their output. Adversarial
training is one of the most effective approaches to training robust models
against such attacks. Unfortunately, this method is much slower than vanilla
training of neural networks since it needs to construct adversarial examples
for the entire training data at every iteration. By leveraging the theory of
coreset selection, we show how selecting a small subset of training data
provides a principled approach to reducing the time complexity of robust
training. To this end, we first provide convergence guarantees for adversarial
coreset selection. In particular, we show that the convergence bound is
directly related to how well our coresets can approximate the gradient computed
over the entire training data. Motivated by our theoretical analysis, we
propose using this gradient approximation error as our adversarial coreset
selection objective to reduce the training set size effectively. Once built, we
run adversarial training over this subset of the training data. Unlike existing
methods, our approach can be adapted to a wide variety of training objectives,
including TRADES, $\ell_p$-PGD, and Perceptual Adversarial Training. We conduct
extensive experiments to demonstrate that our approach speeds up adversarial
training by 2-3 times while experiencing a slight degradation in the clean and
robust accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dolatabadi_H/0/1/0/all/0/1&quot;&gt;Hadi M. Dolatabadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erfani_S/0/1/0/all/0/1&quot;&gt;Sarah Erfani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leckie_C/0/1/0/all/0/1&quot;&gt;Christopher Leckie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.14915">
<title>Spiking Neural Networks for event-based action recognition: A new task to understand their advantage. (arXiv:2209.14915v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2209.14915</link>
<description rdf:parseType="Literal">&lt;p&gt;Spiking Neural Networks (SNN) are characterised by their unique temporal
dynamics, but the properties and advantages of such computations are still not
well understood. In order to provide answers, in this work we demonstrate how
Spiking neurons can enable temporal feature extraction in feed-forward neural
networks without the need for recurrent synapses, showing how their
bio-inspired computing principles can be successfully exploited beyond energy
efficiency gains and evidencing their differences with respect to conventional
neurons. This is demonstrated by proposing a new task, DVS-Gesture-Chain
(DVS-GC), which allows, for the first time, to evaluate the perception of
temporal dependencies in a real event-based action recognition dataset. Our
study proves how the widely used DVS Gesture benchmark could be solved by
networks without temporal feature extraction, unlike the new DVS-GC which
demands an understanding of the ordering of the events. Furthermore, this setup
allowed us to unveil the role of the leakage rate in spiking neurons for
temporal processing tasks and demonstrated the benefits of &quot;hard reset&quot;
mechanisms. Additionally, we also show how time-dependent weights and
normalization can lead to understanding order by means of temporal attention.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vicente_Sola_A/0/1/0/all/0/1&quot;&gt;Alex Vicente-Sola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manna_D/0/1/0/all/0/1&quot;&gt;Davide L. Manna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirkland_P/0/1/0/all/0/1&quot;&gt;Paul Kirkland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caterina_G/0/1/0/all/0/1&quot;&gt;Gaetano Di Caterina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bihl_T/0/1/0/all/0/1&quot;&gt;Trevor Bihl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.07774">
<title>Learning To Rank Diversely At Airbnb. (arXiv:2210.07774v3 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2210.07774</link>
<description rdf:parseType="Literal">&lt;p&gt;Airbnb is a two-sided marketplace, bringing together hosts who own listings
for rent, with prospective guests from around the globe. Applying neural
network-based learning to rank techniques has led to significant improvements
in matching guests with hosts. These improvements in ranking were driven by a
core strategy: order the listings by their estimated booking probabilities,
then iterate on techniques to make these booking probability estimates more and
more accurate. Embedded implicitly in this strategy was an assumption that the
booking probability of a listing could be determined independently of other
listings in search results. In this paper we discuss how this assumption,
pervasive throughout the commonly-used learning to rank frameworks, is false.
We provide a theoretical foundation correcting this assumption, followed by
efficient neural network architectures based on the theory. Explicitly
accounting for possible similarities between listings, and reducing them to
diversify the search results generated strong positive impact. We discuss these
metric wins as part of the online A/B tests of the theory. Our method provides
a practical way to diversify search results for large-scale production ranking
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haldar_M/0/1/0/all/0/1&quot;&gt;Malay Haldar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdool_M/0/1/0/all/0/1&quot;&gt;Mustafa Abdool&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Liwei He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_D/0/1/0/all/0/1&quot;&gt;Dillon Davis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1&quot;&gt;Huiji Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katariya_S/0/1/0/all/0/1&quot;&gt;Sanjeev Katariya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.07909">
<title>Selective Memory Recursive Least Squares: Recast Forgetting into Memory in RBF Neural Network Based Real-Time Learning. (arXiv:2211.07909v2 [eess.SY] UPDATED)</title>
<link>http://arxiv.org/abs/2211.07909</link>
<description rdf:parseType="Literal">&lt;p&gt;In radial basis function neural network (RBFNN) based real-time learning
tasks, forgetting mechanisms are widely used such that the neural network can
keep its sensitivity to new data. However, with forgetting mechanisms, some
useful knowledge will get lost simply because they are learned a long time ago,
which we refer to as the passive knowledge forgetting phenomenon. To address
this problem, this paper proposes a real-time training method named selective
memory recursive least squares (SMRLS) in which the classical forgetting
mechanisms are recast into a memory mechanism. Different from the forgetting
mechanism, which mainly evaluates the importance of samples according to the
time when samples are collected, the memory mechanism evaluates the importance
of samples through both temporal and spatial distribution of samples. With
SMRLS, the input space of the RBFNN is evenly divided into a finite number of
partitions and a synthesized objective function is developed using synthesized
samples from each partition. In addition to the current approximation error,
the neural network also updates its weights according to the recorded data from
the partition being visited. Compared with classical training methods including
the forgetting factor recursive least squares (FFRLS) and stochastic gradient
descent (SGD) methods, SMRLS achieves improved learning speed and
generalization capability, which are demonstrated by corresponding simulation
results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fei_Y/0/1/0/all/0/1&quot;&gt;Yiming Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiangang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yanan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.04780">
<title>Genie: Show Me the Data for Quantization. (arXiv:2212.04780v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.04780</link>
<description rdf:parseType="Literal">&lt;p&gt;Zero-shot quantization is a promising approach for developing lightweight
deep neural networks when data is inaccessible owing to various reasons,
including cost and issues related to privacy. By exploiting the learned
parameters ($\mu$ and $\sigma$) of batch normalization layers in an
FP32-pre-trained model, zero-shot quantization schemes focus on generating
synthetic data. Subsequently, they distill knowledge from the pre-trained model
(teacher) to the quantized model (student) such that the quantized model can be
optimized with the synthetic dataset. However, thus far, zero-shot quantization
has primarily been discussed in the context of quantization-aware training
methods, which require task-specific losses and long-term optimization as much
as retraining. We thus introduce a post-training quantization scheme for
zero-shot quantization that produces high-quality quantized networks within a
few hours. Furthermore, we propose a framework called Genie~that generates data
suited for quantization. With the data synthesized by Genie, we can produce
robust quantized models without real datasets, which is comparable to few-shot
quantization. We also propose a post-training quantization algorithm to enhance
the performance of quantized models. By combining them, we can bridge the gap
between zero-shot and few-shot quantization while significantly improving the
quantization performance compared to that of existing approaches. In other
words, we can obtain a unique state-of-the-art zero-shot quantization approach.
The code is available at \url{https://github.com/SamsungLabs/Genie}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeon_Y/0/1/0/all/0/1&quot;&gt;Yongkweon Jeon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chungman Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Ho-young Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.00790">
<title>Online learning techniques for prediction of temporal tabular datasets with regime changes. (arXiv:2301.00790v3 [q-fin.CP] UPDATED)</title>
<link>http://arxiv.org/abs/2301.00790</link>
<description rdf:parseType="Literal">&lt;p&gt;The application of deep learning to non-stationary temporal datasets can lead
to overfitted models that underperform under regime changes. In this work, we
propose a modular machine learning pipeline for ranking predictions on temporal
panel datasets which is robust under regime changes. The modularity of the
pipeline allows the use of different models, including Gradient Boosting
Decision Trees (GBDTs) and Neural Networks, with and without feature
engineering. We evaluate our framework on financial data for stock portfolio
prediction, and find that GBDT models with dropout display high performance,
robustness and generalisability with reduced complexity and computational cost.
We then demonstrate how online learning techniques, which require no retraining
of models, can be used post-prediction to enhance the results. First, we show
that dynamic feature projection improves robustness by reducing drawdown in
regime changes. Second, we demonstrate that dynamical model ensembling based on
selection of models with good recent performance leads to improved Sharpe and
Calmar ratios of out-of-sample predictions. We also evaluate the robustness of
our pipeline across different data splits and random seeds with good
reproducibility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Wong_T/0/1/0/all/0/1&quot;&gt;Thomas Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Barahona_M/0/1/0/all/0/1&quot;&gt;Mauricio Barahona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.05609">
<title>Co-manipulation of soft-materials estimating deformation from depth images. (arXiv:2301.05609v4 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2301.05609</link>
<description rdf:parseType="Literal">&lt;p&gt;Human-robot co-manipulation of soft materials, such as fabrics, composites,
and sheets of paper/cardboard, is a challenging operation that presents several
relevant industrial applications. Estimating the deformation state of the
co-manipulated material is one of the main challenges. Viable methods provide
the indirect measure by calculating the human-robot relative distance. In this
paper, we develop a data-driven model to estimate the deformation state of the
material from a depth image through a Convolutional Neural Network (CNN).
First, we define the deformation state of the material as the relative
roto-translation from the current robot pose and a human grasping position. The
model estimates the current deformation state through a Convolutional Neural
Network, specifically a DenseNet-121 pretrained on ImageNet.The delta between
the current and the desired deformation state is fed to the robot controller
that outputs twist commands. The paper describes the developed approach to
acquire, preprocess the dataset and train the model. The model is compared with
the current state-of-the-art method based on a skeletal tracker from cameras.
Results show that our approach achieves better performances and avoids the
various drawbacks caused by using a skeletal tracker.Finally, we also studied
the model performance according to different architectures and dataset
dimensions to minimize the time required for dataset acquisition
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicola_G/0/1/0/all/0/1&quot;&gt;Giorgio Nicola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villagrossi_E/0/1/0/all/0/1&quot;&gt;Enrico Villagrossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedrocchi_N/0/1/0/all/0/1&quot;&gt;Nicola Pedrocchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.10227">
<title>Denoising Diffusion Probabilistic Models for Generation of Realistic Fully-Annotated Microscopy Image Data Sets. (arXiv:2301.10227v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/2301.10227</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in computer vision have led to significant progress in the
generation of realistic image data, with denoising diffusion probabilistic
models proving to be a particularly effective method. In this study, we
demonstrate that diffusion models can effectively generate fully-annotated
microscopy image data sets through an unsupervised and intuitive approach,
using rough sketches of desired structures as the starting point. The proposed
pipeline helps to reduce the reliance on manual annotations when training deep
learning-based segmentation approaches and enables the segmentation of diverse
datasets without the need for human annotations. This approach holds great
promise in streamlining the data generation process and enabling a more
efficient and scalable training of segmentation models, as we show in the
example of different practical experiments involving various organisms and cell
types.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Eschweiler_D/0/1/0/all/0/1&quot;&gt;Dennis Eschweiler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yilmaz_R/0/1/0/all/0/1&quot;&gt;R&amp;#xfc;veyda Yilmaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Baumann_M/0/1/0/all/0/1&quot;&gt;Matisse Baumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Laube_I/0/1/0/all/0/1&quot;&gt;Ina Laube&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Roy_R/0/1/0/all/0/1&quot;&gt;Rijo Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jose_A/0/1/0/all/0/1&quot;&gt;Abin Jose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bruckner_D/0/1/0/all/0/1&quot;&gt;Daniel Br&amp;#xfc;ckner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Stegmaier_J/0/1/0/all/0/1&quot;&gt;Johannes Stegmaier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.00195">
<title>Weight Prediction Boosts the Convergence of AdamW. (arXiv:2302.00195v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.00195</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce weight prediction into the AdamW optimizer to
boost its convergence when training the deep neural network (DNN) models. In
particular, ahead of each mini-batch training, we predict the future weights
according to the update rule of AdamW and then apply the predicted future
weights to do both forward pass and backward propagation. In this way, the
AdamW optimizer always utilizes the gradients w.r.t. the future weights instead
of current weights to update the DNN parameters, making the AdamW optimizer
achieve better convergence. Our proposal is simple and straightforward to
implement but effective in boosting the convergence of DNN training. We
performed extensive experimental evaluations on image classification and
language modeling tasks to verify the effectiveness of our proposal. The
experimental results validate that our proposal can boost the convergence of
AdamW and achieve better accuracy than AdamW when training the DNN models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_L/0/1/0/all/0/1&quot;&gt;Lei Guan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.01075">
<title>MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein Gradient Flows. (arXiv:2302.01075v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2302.01075</link>
<description rdf:parseType="Literal">&lt;p&gt;The conventional understanding of adversarial training in generative
adversarial networks (GANs) is that the discriminator is trained to estimate a
divergence, and the generator learns to minimize this divergence. We argue that
despite the fact that many variants of GANs were developed following this
paradigm, the current theoretical understanding of GANs and their practical
algorithms are inconsistent. In this paper, we leverage Wasserstein gradient
flows which characterize the evolution of particles in the sample space, to
gain theoretical insights and algorithmic inspiration of GANs. We introduce a
unified generative modeling framework - MonoFlow: the particle evolution is
rescaled via a monotonically increasing mapping of the log density ratio. Under
our framework, adversarial training can be viewed as a procedure first
obtaining MonoFlow&apos;s vector field via training the discriminator and the
generator learns to draw the particle flow defined by the corresponding vector
field. We also reveal the fundamental difference between variational divergence
minimization and adversarial training. This analysis helps us to identify what
types of generator loss functions can lead to the successful training of GANs
and suggest that GANs may have more loss designs beyond the literature (e.g.,
non-saturated loss), as long as they realize MonoFlow. Consistent empirical
studies are included to validate the effectiveness of our framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yi_M/0/1/0/all/0/1&quot;&gt;Mingxuan Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhanxing Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Song Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.10331">
<title>Causal Razors. (arXiv:2302.10331v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.10331</link>
<description rdf:parseType="Literal">&lt;p&gt;When performing causal discovery, assumptions have to be made on how the true
causal mechanism corresponds to the underlying joint probability distribution.
These assumptions are labeled as causal razors in this work. We review numerous
causal razors that appeared in the literature, and offer a comprehensive
logical comparison of them. In particular, we scrutinize an unpopular causal
razor, namely parameter minimality, in multinomial causal models and its
logical relations with other well-studied causal razors. Our logical result
poses a dilemma in selecting a reasonable scoring criterion for score-based
casual search algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1&quot;&gt;Wai-yin Lam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.14353">
<title>A semantic backdoor attack against Graph Convolutional Networks. (arXiv:2302.14353v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.14353</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph convolutional networks (GCNs) have been very effective in addressing
the issue of various graph-structured related tasks, such as node
classification and graph classification. However, recent research has shown
that GCNs are vulnerable to a new type of threat called a backdoor attack,
where the adversary can inject a hidden backdoor into GCNs so that the attacked
model performs well on benign samples, but its prediction will be maliciously
changed to the attacker-specified target label if the hidden backdoor is
activated by the attacker-defined trigger. In this paper, we investigate
whether such semantic backdoor attacks are possible for GCNs and propose a
semantic backdoor attack against GCNs (SBAG) under the context of graph
classification to reveal the existence of this security vulnerability in GCNs.
SBAG uses a certain type of node in the samples as a backdoor trigger and
injects a hidden backdoor into GCN models by poisoning training data. The
backdoor will be activated, and the GCN models will give malicious
classification results specified by the attacker even on unmodified samples as
long as the samples contain enough trigger nodes. We evaluate SBAG on four
graph datasets. The experimental results indicate that SBAG can achieve attack
success rates of approximately 99.9% and over 82% for two kinds of attack
samples, respectively, with poisoning rates of less than 5%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1&quot;&gt;Jiazhu Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.00286">
<title>Treat Different Negatives Differently: Enriching Loss Functions with Domain and Range Constraints for Link Prediction. (arXiv:2303.00286v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.00286</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graph embedding models (KGEMs) are used for various tasks related
to knowledge graphs (KGs), including link prediction. They are trained with
loss functions that are computed considering a batch of scored triples and
their corresponding labels. Traditional approaches consider the label of a
triple to be either true or false. However, recent works suggest that all
negative triples should not be valued equally. In line with this recent
assumption, we posit that negative triples that are semantically valid w.r.t.
domain and range constraints might be high-quality negative triples. As such,
loss functions should treat them differently from semantically invalid negative
ones. To this aim, we propose semantic-driven versions for the three main loss
functions for link prediction. In an extensive and controlled experimental
setting, we show that the proposed loss functions systematically provide
satisfying results on three public benchmark KGs underpinned with different
schemas, which demonstrates both the generality and superiority of our proposed
approach. In fact, the proposed loss functions do (1) lead to better MRR and
Hits@10 values, (2) drive KGEMs towards better semantic awareness as measured
by the Sem@K metric. This highlights that semantic information globally
improves KGEMs, and thus should be incorporated into loss functions. Domains
and ranges of relations being largely available in schema-defined KGs, this
makes our approach both beneficial and widely usable in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubert_N/0/1/0/all/0/1&quot;&gt;Nicolas Hubert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monnin_P/0/1/0/all/0/1&quot;&gt;Pierre Monnin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brun_A/0/1/0/all/0/1&quot;&gt;Armelle Brun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monticolo_D/0/1/0/all/0/1&quot;&gt;Davy Monticolo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.00500">
<title>Inherently Interpretable Multi-Label Classification Using Class-Specific Counterfactuals. (arXiv:2303.00500v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.00500</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretability is essential for machine learning algorithms in high-stakes
application fields such as medical image analysis. However, high-performing
black-box neural networks do not provide explanations for their predictions,
which can lead to mistrust and suboptimal human-ML collaboration. Post-hoc
explanation techniques, which are widely used in practice, have been shown to
suffer from severe conceptual problems. Furthermore, as we show in this paper,
current explanation techniques do not perform adequately in the multi-label
scenario, in which multiple medical findings may co-occur in a single image. We
propose Attri-Net, an inherently interpretable model for multi-label
classification. Attri-Net is a powerful classifier that provides transparent,
trustworthy, and human-understandable explanations. The model first generates
class-specific attribution maps based on counterfactuals to identify which
image regions correspond to certain medical findings. Then a simple logistic
regression classifier is used to make predictions based solely on these
attribution maps. We compare Attri-Net to five post-hoc explanation techniques
and one inherently interpretable classifier on three chest X-ray datasets. We
find that Attri-Net produces high-quality multi-label explanations consistent
with clinical knowledge and has comparable classification performance to
state-of-the-art classification models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Susu Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woerner_S/0/1/0/all/0/1&quot;&gt;Stefano Woerner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1&quot;&gt;Andreas Maier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koch_L/0/1/0/all/0/1&quot;&gt;Lisa M. Koch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baumgartner_C/0/1/0/all/0/1&quot;&gt;Christian F. Baumgartner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.16459">
<title>GNNBuilder: An Automated Framework for Generic Graph Neural Network Accelerator Generation, Simulation, and Optimization. (arXiv:2303.16459v2 [cs.AR] UPDATED)</title>
<link>http://arxiv.org/abs/2303.16459</link>
<description rdf:parseType="Literal">&lt;p&gt;There are plenty of graph neural network (GNN) accelerators being proposed.
However, they highly rely on users&apos; hardware expertise and are usually
optimized for one specific GNN model, making them challenging for practical
use. Therefore, in this work, we propose GNNBuilder, the first automated,
generic, end-to-end GNN accelerator generation framework. It features four
advantages: (1) GNNBuilder can automatically generate GNN accelerators for a
wide range of GNN models arbitrarily defined by users; (2) GNNBuilder takes
standard PyTorch programming interface, introducing zero overhead for algorithm
developers; (3) GNNBuilder supports end-to-end code generation, simulation,
accelerator optimization, and hardware deployment, realizing a push-button
fashion for GNN accelerator design; (4) GNNBuilder is equipped with accurate
performance models of its generated accelerator, enabling fast and flexible
design space exploration (DSE). In the experiments, first, we show that our
accelerator performance model has errors within $36\%$ for latency prediction
and $18\%$ for BRAM count prediction. Second, we show that our generated
accelerators can outperform CPU by $6.33\times$ and GPU by $6.87\times$. This
framework is open-source, and the code is available at
https://github.com/sharc-lab/gnn-builder.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abi_Karam_S/0/1/0/all/0/1&quot;&gt;Stefan Abi-Karam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_C/0/1/0/all/0/1&quot;&gt;Cong Hao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.16565">
<title>PMAA: A Progressive Multi-scale Attention Autoencoder Model for High-performance Cloud Removal from Multi-temporal Satellite Imagery. (arXiv:2303.16565v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.16565</link>
<description rdf:parseType="Literal">&lt;p&gt;Satellite imagery analysis plays a pivotal role in remote sensing; however,
information loss due to cloud cover significantly impedes its application.
Although existing deep cloud removal models have achieved notable outcomes,
they scarcely consider contextual information. This study introduces a
high-performance cloud removal architecture, termed Progressive Multi-scale
Attention Autoencoder (PMAA), which concurrently harnesses global and local
information to construct robust contextual dependencies using a novel
Multi-scale Attention Module (MAM) and a novel Local Interaction Module (LIM).
PMAA establishes long-range dependencies of multi-scale features using MAM and
modulates the reconstruction of fine-grained details utilizing LIM, enabling
simultaneous representation of fine- and coarse-grained features at the same
level. With the help of diverse and multi-scale features, PMAA consistently
outperforms the previous state-of-the-art model CTGAN on two benchmark
datasets. Moreover, PMAA boasts considerable efficiency advantages, with only
0.5% and 14.6% of the parameters and computational complexity of CTGAN,
respectively. These comprehensive results underscore PMAA&apos;s potential as a
lightweight cloud removal network suitable for deployment on edge devices to
accomplish large-scale cloud removal tasks. Our source code and pre-trained
models are available at https://github.com/XavierJiezou/PMAA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1&quot;&gt;Xuechao Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1&quot;&gt;Junliang Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_P/0/1/0/all/0/1&quot;&gt;Pin Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1&quot;&gt;Yachao Cui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.08134">
<title>Tackling Face Verification Edge Cases: In-Depth Analysis and Human-Machine Fusion Approach. (arXiv:2304.08134v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2304.08134</link>
<description rdf:parseType="Literal">&lt;p&gt;Nowadays, face recognition systems surpass human performance on several
datasets. However, there are still edge cases that the machine can&apos;t correctly
classify. This paper investigates the effect of a combination of machine and
human operators in the face verification task. First, we look closer at the
edge cases for several state-of-the-art models to discover common datasets&apos;
challenging settings. Then, we conduct a study with 60 participants on these
selected tasks with humans and provide an extensive analysis. Finally, we
demonstrate that combining machine and human decisions can further improve the
performance of state-of-the-art face verification systems on various benchmark
datasets. Code and data are publicly available on GitHub.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knoche_M/0/1/0/all/0/1&quot;&gt;Martin Knoche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1&quot;&gt;Gerhard Rigoll&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.01160">
<title>Long-Tailed Recognition by Mutual Information Maximization between Latent Features and Ground-Truth Labels. (arXiv:2305.01160v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.01160</link>
<description rdf:parseType="Literal">&lt;p&gt;Although contrastive learning methods have shown prevailing performance on a
variety of representation learning tasks, they encounter difficulty when the
training dataset is long-tailed. Many researchers have combined contrastive
learning and a logit adjustment technique to address this problem, but the
combinations are done ad-hoc and a theoretical background has not yet been
provided. The goal of this paper is to provide the background and further
improve the performance. First, we show that the fundamental reason contrastive
learning methods struggle with long-tailed tasks is that they try to maximize
the mutual information maximization between latent features and input data. As
ground-truth labels are not considered in the maximization, they are not able
to address imbalances between class labels. Rather, we interpret the
long-tailed recognition task as a mutual information maximization between
latent features and ground-truth labels. This approach integrates contrastive
learning and logit adjustment seamlessly to derive a loss function that shows
state-of-the-art performance on long-tailed recognition benchmarks. It also
demonstrates its efficacy in image segmentation tasks, verifying its
versatility beyond image classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suh_M/0/1/0/all/0/1&quot;&gt;Min-Kook Suh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1&quot;&gt;Seung-Woo Seo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.02640">
<title>Towards Causal Representation Learning and Deconfounding from Indefinite Data. (arXiv:2305.02640v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.02640</link>
<description rdf:parseType="Literal">&lt;p&gt;We redefine causal data from two novel perspectives: the number of causal
skeletons and the dimension of causal variables, thereby proposing three data
paradigms. Among them, the indefinite data (like dialogues or video sources) is
characterized by multi-skeleton structures and multi-value variables. Multi
skeletons induce low sample utilization, and multi values induce incapability
of the distribution assumption, both leading to the fact that learning causal
representation from indefinite data is, as of yet, largely unexplored. We
design the causal strength variational model to settle down these two problems.
Specifically, we leverage the causal strength instead of independent noise as
the latent variable to construct evidence lower bound. By this design ethos,
The causal strengths of different skeletons are regarded as a distribution and
can be expressed as a single-valued causal graph matrix. Moreover, considering
the latent confounders, we disentangle the causal graph G into two relation
subgraphs O and C. O contains pure relations between observed variables, while
C represents the relations from latent variables to observed variables. We
implement the above designs as a dynamic variational inference model, tailored
to learn causal representation from indefinite data under latent confounding.
Finally, we conduct comprehensive experiments on synthetic and real-world data
to demonstrate the effectiveness of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xinyu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qing Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.12522">
<title>P-NOC: Adversarial CAM Generation for Weakly Supervised Semantic Segmentation. (arXiv:2305.12522v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.12522</link>
<description rdf:parseType="Literal">&lt;p&gt;To mitigate the necessity for large amounts of supervised segmentation
annotation sets, multiple Weakly Supervised Semantic Segmentation (WSSS)
strategies have been devised. These will often rely on advanced data and model
regularization strategies to instigate the development of useful properties
(e.g., prediction completeness and fidelity to semantic boundaries) in
segmentation priors, notwithstanding the lack of annotated information. In this
work, we first create a strong baseline by analyzing complementary WSSS
techniques and regularizing strategies, considering their strengths and
limitations. We then propose a new Class-specific Adversarial Erasing strategy,
comprising two adversarial CAM generating networks being gradually refined to
produce robust semantic segmentation proposals. Empirical results suggest that
our approach induces substantial improvement in the effectiveness of the
baseline, resulting in a noticeable improvement over both Pascal VOC 2012 and
MS COCO 2014 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+David_L/0/1/0/all/0/1&quot;&gt;Lucas David&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedrini_H/0/1/0/all/0/1&quot;&gt;Helio Pedrini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dias_Z/0/1/0/all/0/1&quot;&gt;Zanoni Dias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13452">
<title>Measuring and Modeling Physical Intrinsic Motivation. (arXiv:2305.13452v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13452</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans are interactive agents driven to seek out situations with interesting
physical dynamics. Here we formalize the functional form of physical intrinsic
motivation. We first collect ratings of how interesting humans find a variety
of physics scenarios. We then model human interestingness responses by
implementing various hypotheses of intrinsic motivation including models that
rely on simple scene features to models that depend on forward physics
prediction. We find that the single best predictor of human responses is
adversarial reward, a model derived from physical prediction loss. We also find
that simple scene feature models do not generalize their prediction of human
responses across all scenarios. Finally, linearly combining the adversarial
model with the number of collisions in a scene leads to the greatest
improvement in predictivity of human responses, suggesting humans are driven
towards scenarios that result in high information gain and physical activity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinez_J/0/1/0/all/0/1&quot;&gt;Julio Martinez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binder_F/0/1/0/all/0/1&quot;&gt;Felix Binder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haoliang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haber_N/0/1/0/all/0/1&quot;&gt;Nick Haber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1&quot;&gt;Judith Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1&quot;&gt;Daniel L. K. Yamins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18651">
<title>UMD: Unsupervised Model Detection for X2X Backdoor Attacks. (arXiv:2305.18651v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18651</link>
<description rdf:parseType="Literal">&lt;p&gt;Backdoor (Trojan) attack is a common threat to deep neural networks, where
samples from one or more source classes embedded with a backdoor trigger will
be misclassified to adversarial target classes. Existing methods for detecting
whether a classifier is backdoor attacked are mostly designed for attacks with
a single adversarial target (e.g., all-to-one attack). To the best of our
knowledge, without supervision, no existing methods can effectively address the
more general X2X attack with an arbitrary number of source classes, each paired
with an arbitrary target class. In this paper, we propose UMD, the first
Unsupervised Model Detection method that effectively detects X2X backdoor
attacks via a joint inference of the adversarial (source, target) class pairs.
In particular, we first define a novel transferability statistic to measure and
select a subset of putative backdoor class pairs based on a proposed clustering
approach. Then, these selected class pairs are jointly assessed based on an
aggregation of their reverse-engineered trigger size for detection inference,
using a robust and unsupervised anomaly detector we proposed. We conduct
comprehensive evaluations on CIFAR-10, GTSRB, and Imagenette dataset, and show
that our unsupervised UMD outperforms SOTA detectors (even with supervision) by
17%, 4%, and 8%, respectively, in terms of the detection accuracy against
diverse X2X attacks. We also show the strong detection performance of UMD
against several strong adaptive attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_Z/0/1/0/all/0/1&quot;&gt;Zhen Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1&quot;&gt;Zidi Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.19259">
<title>Shuffle SGD is Always Better than SGD: Improved Analysis of SGD with Arbitrary Data Orders. (arXiv:2305.19259v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.19259</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic Gradient Descent (SGD) algorithms are widely used in optimizing
neural networks, with Random Reshuffling (RR) and Single Shuffle (SS) being
popular choices for cycling through random or single permutations of the
training data. However, the convergence properties of these algorithms in the
non-convex case are not fully understood. Existing results suggest that, in
realistic training scenarios where the number of epochs is smaller than the
training set size, RR may perform worse than SGD.
&lt;/p&gt;
&lt;p&gt;In this paper, we analyze a general SGD algorithm that allows for arbitrary
data orderings and show improved convergence rates for non-convex functions.
Specifically, our analysis reveals that SGD with random and single shuffling is
always faster or at least as good as classical SGD with replacement, regardless
of the number of iterations. Overall, our study highlights the benefits of
using SGD with random/single shuffling and provides new insights into its
convergence properties for non-convex optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koloskova_A/0/1/0/all/0/1&quot;&gt;Anastasia Koloskova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doikov_N/0/1/0/all/0/1&quot;&gt;Nikita Doikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1&quot;&gt;Sebastian U. Stich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1&quot;&gt;Martin Jaggi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.08325">
<title>GCformer: An Efficient Framework for Accurate and Scalable Long-Term Multivariate Time Series Forecasting. (arXiv:2306.08325v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.08325</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer-based models have emerged as promising tools for time series
forecasting.
&lt;/p&gt;
&lt;p&gt;However, these model cannot make accurate prediction for long input time
series. On the one hand, they failed to capture global dependencies within time
series data. On the other hand, the long input sequence usually leads to large
model size and high time complexity.
&lt;/p&gt;
&lt;p&gt;To address these limitations, we present GCformer, which combines a
structured global convolutional branch for processing long input sequences with
a local Transformer-based branch for capturing short, recent signals. A
cohesive framework for a global convolution kernel has been introduced,
utilizing three distinct parameterization methods. The selected structured
convolutional kernel in the global branch has been specifically crafted with
sublinear complexity, thereby allowing for the efficient and effective
processing of lengthy and noisy input signals. Empirical studies on six
benchmark datasets demonstrate that GCformer outperforms state-of-the-art
methods, reducing MSE error in multivariate time series benchmarks by 4.38% and
model parameters by 61.92%. In particular, the global convolutional branch can
serve as a plug-in block to enhance the performance of other models, with an
average improvement of 31.93\%, including various recently published
Transformer-based models. Our code is publicly available at
https://github.com/zyj-111/GCformer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;YanJun Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Ziqing Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tian Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Liang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1&quot;&gt;Mengni Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1&quot;&gt;Yi Qian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.09345">
<title>Evaluating Data Attribution for Text-to-Image Models. (arXiv:2306.09345v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2306.09345</link>
<description rdf:parseType="Literal">&lt;p&gt;While large text-to-image models are able to synthesize &quot;novel&quot; images, these
images are necessarily a reflection of the training data. The problem of data
attribution in such models -- which of the images in the training set are most
responsible for the appearance of a given generated image -- is a difficult yet
important one. As an initial step toward this problem, we evaluate attribution
through &quot;customization&quot; methods, which tune an existing large-scale model
toward a given exemplar object or style. Our key insight is that this allows us
to efficiently create synthetic images that are computationally influenced by
the exemplar by construction. With our new dataset of such exemplar-influenced
images, we are able to evaluate various data attribution algorithms and
different possible feature spaces. Furthermore, by training on our dataset, we
can tune standard models, such as DINO, CLIP, and ViT, toward the attribution
problem. Even though the procedure is tuned towards small exemplar sets, we
show generalization to larger sets. Finally, by taking into account the
inherent uncertainty of the problem, we can assign soft attribution scores over
a set of training images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sheng-Yu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efros_A/0/1/0/all/0/1&quot;&gt;Alexei A. Efros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun-Yan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Richard Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.03571">
<title>Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization. (arXiv:2307.03571v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.03571</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a framework for smooth optimization of objectives with
$\ell_q$ and $\ell_{p,q}$ regularization for (structured) sparsity. Finding
solutions to these non-smooth and possibly non-convex problems typically relies
on specialized optimization routines. In contrast, the method studied here is
compatible with off-the-shelf (stochastic) gradient descent that is ubiquitous
in deep learning, thereby enabling differentiable sparse regularization without
approximations. The proposed optimization transfer comprises an
overparametrization of selected model parameters followed by a change of
penalties. In the overparametrized problem, smooth and convex $\ell_2$
regularization induces non-smooth and non-convex regularization in the original
parametrization. We show that the resulting surrogate problem not only has an
identical global optimum but also exactly preserves the local minima. This is
particularly useful in non-convex regularization, where finding global
solutions is NP-hard and local minima often generalize well. We provide an
integrative overview that consolidates various literature strands on
sparsity-inducing parametrizations in a general setting and meaningfully extend
existing approaches. The feasibility of our approach is evaluated through
numerical experiments, demonstrating its effectiveness by matching or
outperforming common implementations of convex and non-convex regularizers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolb_C/0/1/0/all/0/1&quot;&gt;Chris Kolb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_C/0/1/0/all/0/1&quot;&gt;Christian L. M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1&quot;&gt;Bernd Bischl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1&quot;&gt;David R&amp;#xfc;gamer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06713">
<title>Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models. (arXiv:2307.06713v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06713</link>
<description rdf:parseType="Literal">&lt;p&gt;A wide variety of natural language tasks are currently being addressed with
large-scale language models (LLMs). These models are usually trained with a
very large amount of unsupervised text data and adapted to perform a downstream
natural language task using methods like fine-tuning, calibration or in-context
learning. In this work, we propose an approach to adapt the prior class
distribution to perform text classification tasks without the need for labelled
samples and only few in-domain sample queries. The proposed approach treats the
LLM as a black box, adding a stage where the model posteriors are calibrated to
the task. Results show that these methods outperform the un-adapted model for
different number of training shots in the prompt and a previous approach were
calibration is performed without using any adaptation data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Estienne_L/0/1/0/all/0/1&quot;&gt;Lautaro Estienne&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.07873">
<title>Why Does Little Robustness Help? Understanding Adversarial Transferability From Surrogate Training. (arXiv:2307.07873v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.07873</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples (AEs) for DNNs have been shown to be transferable: AEs
that successfully fool white-box surrogate models can also deceive other
black-box models with different architectures. Although a bunch of empirical
studies have provided guidance on generating highly transferable AEs, many of
these findings lack explanations and even lead to inconsistent advice. In this
paper, we take a further step towards understanding adversarial
transferability, with a particular focus on surrogate aspects. Starting from
the intriguing little robustness phenomenon, where models adversarially trained
with mildly perturbed adversarial samples can serve as better surrogates, we
attribute it to a trade-off between two predominant factors: model smoothness
and gradient similarity. Our investigations focus on their joint effects,
rather than their separate correlations with transferability. Through a series
of theoretical and empirical analyses, we conjecture that the data distribution
shift in adversarial training explains the degradation of gradient similarity.
Building on these insights, we explore the impacts of data augmentation and
gradient regularization on transferability and identify that the trade-off
generally exists in the various training mechanisms, thus building a
comprehensive blueprint for the regulation mechanism behind transferability.
Finally, we provide a general route for constructing better surrogates to boost
transferability which optimizes both model smoothness and gradient similarity
simultaneously, e.g., the combination of input gradient regularization and
sharpness-aware minimization (SAM), validated by extensive experiments. In
summary, we call for attention to the united impacts of these two factors for
launching effective transfer attacks, rather than optimizing one while ignoring
the other, and emphasize the crucial role of manipulating surrogate models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yechao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1&quot;&gt;Shengshan Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Leo Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Junyu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Minghui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaogeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1&quot;&gt;Wei Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Hai Jin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08496">
<title>Can We Trust Race Prediction?. (arXiv:2307.08496v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08496</link>
<description rdf:parseType="Literal">&lt;p&gt;In the absence of sensitive race and ethnicity data, researchers, regulators,
and firms alike turn to proxies. In this paper, I train a Bidirectional Long
Short-Term Memory (BiLSTM) model on a novel dataset of voter registration data
from all 50 US states and create an ensemble that achieves up to 36.8% higher
out of sample (OOS) F1 scores than the best performing machine learning models
in the literature. Additionally, I construct the most comprehensive database of
first and surname distributions in the US in order to improve the coverage and
accuracy of Bayesian Improved Surname Geocoding (BISG) and Bayesian Improved
Firstname Surname Geocoding (BIFSG). Finally, I provide the first high-quality
benchmark dataset in order to fairly compare existing models and aid future
model developers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Cangyuan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.10579">
<title>SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning. (arXiv:2307.10579v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.10579</link>
<description rdf:parseType="Literal">&lt;p&gt;SecureBoost is a tree-boosting algorithm leveraging homomorphic encryption to
protect data privacy in vertical federated learning setting. It is widely used
in fields such as finance and healthcare due to its interpretability,
effectiveness, and privacy-preserving capability. However, SecureBoost suffers
from high computational complexity and risk of label leakage. To harness the
full potential of SecureBoost, hyperparameters of SecureBoost should be
carefully chosen to strike an optimal balance between utility, efficiency, and
privacy. Existing methods either set hyperparameters empirically or
heuristically, which are far from optimal. To fill this gap, we propose a
Constrained Multi-Objective SecureBoost (CMOSB) algorithm to find Pareto
optimal solutions that each solution is a set of hyperparameters achieving
optimal tradeoff between utility loss, training cost, and privacy leakage. We
design measurements of the three objectives. In particular, the privacy leakage
is measured using our proposed instance clustering attack. Experimental results
demonstrate that the CMOSB yields not only hyperparameters superior to the
baseline but also optimal sets of hyperparameters that can support the flexible
requirements of FL participants.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Ziyao Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1&quot;&gt;Yan Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Lixin Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Linghua Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1&quot;&gt;Yongxin Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.11661">
<title>Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts. (arXiv:2307.11661v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.11661</link>
<description rdf:parseType="Literal">&lt;p&gt;Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have
revolutionized visual representation learning by providing good performance on
downstream datasets. VLMs are 0-shot adapted to a downstream dataset by
designing prompts that are relevant to the dataset. Such prompt engineering
makes use of domain expertise and a validation dataset. Meanwhile, recent
developments in generative pretrained models like GPT-4 mean they can be used
as advanced internet search tools. They can also be manipulated to provide
visual information in any structure. In this work, we show that GPT-4 can be
used to generate text that is visually descriptive and how this can be used to
adapt CLIP to downstream tasks. We show considerable improvements in 0-shot
transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD
(~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP&apos;s default prompt.
We also design a simple few-shot adapter that learns to choose the best
possible sentences to construct generalizable classifiers that outperform the
recently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized
fine-grained datasets. The code, prompts, and auxiliary text dataset is
available at https://github.com/mayug/VDT-Adapter.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maniparambil_M/0/1/0/all/0/1&quot;&gt;Mayug Maniparambil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vorster_C/0/1/0/all/0/1&quot;&gt;Chris Vorster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molloy_D/0/1/0/all/0/1&quot;&gt;Derek Molloy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murphy_N/0/1/0/all/0/1&quot;&gt;Noel Murphy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGuinness_K/0/1/0/all/0/1&quot;&gt;Kevin McGuinness&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1&quot;&gt;Noel E. O&amp;#x27;Connor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.12344">
<title>Right for the Wrong Reason: Can Interpretable ML Techniques Detect Spurious Correlations?. (arXiv:2307.12344v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.12344</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep neural network models offer unmatched classification performance,
they are prone to learning spurious correlations in the data. Such dependencies
on confounding information can be difficult to detect using performance metrics
if the test data comes from the same distribution as the training data.
Interpretable ML methods such as post-hoc explanations or inherently
interpretable classifiers promise to identify faulty model reasoning. However,
there is mixed evidence whether many of these techniques are actually able to
do so. In this paper, we propose a rigorous evaluation strategy to assess an
explanation technique&apos;s ability to correctly identify spurious correlations.
Using this strategy, we evaluate five post-hoc explanation techniques and one
inherently interpretable method for their ability to detect three types of
artificially added confounders in a chest x-ray diagnosis task. We find that
the post-hoc technique SHAP, as well as the inherently interpretable Attri-Net
provide the best performance and can be used to reliably identify faulty model
behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Susu Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koch_L/0/1/0/all/0/1&quot;&gt;Lisa M. Koch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baumgartner_C/0/1/0/all/0/1&quot;&gt;Christian F. Baumgartner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.12450">
<title>ProtoFL: Unsupervised Federated Learning via Prototypical Distillation. (arXiv:2307.12450v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2307.12450</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning (FL) is a promising approach for enhancing data privacy
preservation, particularly for authentication systems. However, limited round
communications, scarce representation, and scalability pose significant
challenges to its deployment, hindering its full potential. In this paper, we
propose &apos;ProtoFL&apos;, Prototypical Representation Distillation based unsupervised
Federated Learning to enhance the representation power of a global model and
reduce round communication costs. Additionally, we introduce a local one-class
classifier based on normalizing flows to improve performance with limited data.
Our study represents the first investigation of using FL to improve one-class
classification performance. We conduct extensive experiments on five widely
used benchmarks, namely MNIST, CIFAR-10, CIFAR-100, ImageNet-30, and
Keystroke-Dynamics, to demonstrate the superior performance of our proposed
framework over previous methods in the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hansol Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwak_Y/0/1/0/all/0/1&quot;&gt;Youngjun Kwak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_M/0/1/0/all/0/1&quot;&gt;Minyoung Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jinho Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Youngsung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1&quot;&gt;Changick Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.00824">
<title>An Exact Kernel Equivalence for Finite Classification Models. (arXiv:2308.00824v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.00824</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the equivalence between neural networks and kernel methods by
deriving the first exact representation of any finite-size parametric
classification model trained with gradient descent as a kernel machine. We
compare our exact representation to the well-known Neural Tangent Kernel (NTK)
and discuss approximation error relative to the NTK and other non-exact path
kernel formulations. We experimentally demonstrate that the kernel can be
computed for realistic networks up to machine precision. We use this exact
kernel to show that our theoretical contribution can provide useful insights
into the predictions made by neural networks, particularly the way in which
they generalize.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bell_B/0/1/0/all/0/1&quot;&gt;Brian Bell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geyer_M/0/1/0/all/0/1&quot;&gt;Michael Geyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glickenstein_D/0/1/0/all/0/1&quot;&gt;David Glickenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_A/0/1/0/all/0/1&quot;&gt;Amanda Fernandez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_J/0/1/0/all/0/1&quot;&gt;Juston Moore&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02013">
<title>Federated Representation Learning for Automatic Speech Recognition. (arXiv:2308.02013v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2308.02013</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) is a privacy-preserving paradigm, allowing edge
devices to learn collaboratively without sharing data. Edge devices like Alexa
and Siri are prospective sources of unlabeled audio data that can be tapped to
learn robust audio representations. In this work, we bring Self-supervised
Learning (SSL) and FL together to learn representations for Automatic Speech
Recognition respecting data privacy constraints. We use the speaker and chapter
information in the unlabeled speech dataset, Libri-Light, to simulate non-IID
speaker-siloed data distributions and pre-train an LSTM encoder with the
Contrastive Predictive Coding framework with FedSGD. We show that the
pre-trained ASR encoder in FL performs as well as a centrally pre-trained model
and produces an improvement of 12-15% (WER) compared to no pre-training. We
further adapt the federated pre-trained models to a new language, French, and
show a 20% (WER) improvement over no pre-training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramesh_G/0/1/0/all/0/1&quot;&gt;Guruprasad V Ramesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chennupati_G/0/1/0/all/0/1&quot;&gt;Gopinath Chennupati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_M/0/1/0/all/0/1&quot;&gt;Milind Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahu_A/0/1/0/all/0/1&quot;&gt;Anit Kumar Sahu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastrow_A/0/1/0/all/0/1&quot;&gt;Ariya Rastrow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Droppo_J/0/1/0/all/0/1&quot;&gt;Jasha Droppo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02582">
<title>Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting. (arXiv:2308.02582v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.02582</link>
<description rdf:parseType="Literal">&lt;p&gt;Cross-domain and cross-compositional generalization of Text-to-SQL semantic
parsing is a challenging task. Existing Large Language Model (LLM) based
solutions rely on inference-time retrieval of few-shot exemplars from the
training set to synthesize a run-time prompt for each Natural Language (NL)
test query. In contrast, we devise an algorithm which performs offline sampling
of a minimal set-of few-shots from the training data, with complete coverage of
SQL clauses, operators and functions, and maximal domain coverage within the
allowed token length. This allows for synthesis of a fixed Generic Prompt (GP),
with a diverse set-of exemplars common across NL test queries, avoiding
expensive test time exemplar retrieval. We further auto-adapt the GP to the
target database domain (DA-GP), to better handle cross-domain generalization;
followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle
cross-compositional generalization. The synthesis of LTMP-DA-GP is an offline
task, to be performed one-time per new database with minimal human
intervention. Our approach demonstrates superior performance on the KaggleDBQA
dataset, designed to evaluate generalizability for the Text-to-SQL task. We
further showcase consistent performance improvement of LTMP-DA-GP over GP,
across LLMs and databases of KaggleDBQA, highlighting the efficacy and model
agnostic benefits of our prompt based adapt and decompose approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1&quot;&gt;Aseem Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhaisaheb_S/0/1/0/all/0/1&quot;&gt;Shabbirhussain Bhaisaheb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patwardhan_M/0/1/0/all/0/1&quot;&gt;Manasi Patwardhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vig_L/0/1/0/all/0/1&quot;&gt;Lovekesh Vig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shroff_G/0/1/0/all/0/1&quot;&gt;Gautam Shroff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.02632">
<title>Generation of Realistic Synthetic Raw Radar Data for Automated Driving Applications using Generative Adversarial Networks. (arXiv:2308.02632v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.02632</link>
<description rdf:parseType="Literal">&lt;p&gt;The main approaches for simulating FMCW radar are based on ray tracing, which
is usually computationally intensive and do not account for background noise.
This work proposes a faster method for FMCW radar simulation capable of
generating synthetic raw radar data using generative adversarial networks
(GAN). The code and pre-trained weights are open-source and available on
GitHub. This method generates 16 simultaneous chirps, which allows the
generated data to be used for the further development of algorithms for
processing radar data (filtering and clustering). This can increase the
potential for data augmentation, e.g., by generating data in non-existent or
safety-critical scenarios that are not reproducible in real life. In this work,
the GAN was trained with radar measurements of a motorcycle and used to
generate synthetic raw radar data of a motorcycle traveling in a straight line.
For generating this data, the distance of the motorcycle and Gaussian noise are
used as input to the neural network. The synthetic generated radar chirps were
evaluated using the Frechet Inception Distance (FID). Then, the Range-Azimuth
(RA) map is calculated twice: first, based on synthetic data using this GAN
and, second, based on real data. Based on these RA maps, an algorithm with
adaptive threshold and edge detection is used for object detection. The results
have shown that the data is realistic in terms of coherent radar reflections of
the motorcycle and background noise based on the comparison of chirps, the RA
maps and the object detection results. Thus, the proposed method in this work
has shown to minimize the simulation-to-reality gap for the generation of radar
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fidelis_E/0/1/0/all/0/1&quot;&gt;Eduardo C. Fidelis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reway_F/0/1/0/all/0/1&quot;&gt;Fabio Reway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_H/0/1/0/all/0/1&quot;&gt;Herick Y. S. Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campos_P/0/1/0/all/0/1&quot;&gt;Pietro L. Campos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huber_W/0/1/0/all/0/1&quot;&gt;Werner Huber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Icking_C/0/1/0/all/0/1&quot;&gt;Christian Icking&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faria_L/0/1/0/all/0/1&quot;&gt;Lester A. Faria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1&quot;&gt;Torsten Sch&amp;#xf6;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03629">
<title>MedMine: Examining Pre-trained Language Models on Medication Mining. (arXiv:2308.03629v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03629</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic medication mining from clinical and biomedical text has become a
popular topic due to its real impact on healthcare applications and the recent
development of powerful language models (LMs). However, fully-automatic
extraction models still face obstacles to be overcome such that they can be
deployed directly into clinical practice for better impacts. Such obstacles
include their imbalanced performances on different entity types and clinical
events. In this work, we examine current state-of-the-art pre-trained language
models (PLMs) on such tasks, via fine-tuning including the monolingual model
Med7 and multilingual large language model (LLM) XLM-RoBERTa. We compare their
advantages and drawbacks using historical medication mining shared task data
sets from n2c2-2018 challenges. We report the findings we get from these
fine-tuning experiments such that they can facilitate future research on
addressing them, for instance, how to combine their outputs, merge such models,
or improve their overall accuracy by ensemble learning and data augmentation.
MedMine is part of the M3 Initiative \url{https://github.com/HECTA-UoM/M3}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alrdahi_H/0/1/0/all/0/1&quot;&gt;Haifa Alrdahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1&quot;&gt;Lifeng Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suvalov_H/0/1/0/all/0/1&quot;&gt;Hendrik &amp;#x160;uvalov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1&quot;&gt;Goran Nenadic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03713">
<title>Communication-Efficient Framework for Distributed Image Semantic Wireless Transmission. (arXiv:2308.03713v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03713</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-node communication, which refers to the interaction among multiple
devices, has attracted lots of attention in many Internet-of-Things (IoT)
scenarios. However, its huge amounts of data flows and inflexibility for task
extension have triggered the urgent requirement of communication-efficient
distributed data transmission frameworks. In this paper, inspired by the great
superiorities on bandwidth reduction and task adaptation of semantic
communications, we propose a federated learning-based semantic communication
(FLSC) framework for multi-task distributed image transmission with IoT
devices. Federated learning enables the design of independent semantic
communication link of each user while further improves the semantic extraction
and task performance through global aggregation. Each link in FLSC is composed
of a hierarchical vision transformer (HVT)-based extractor and a task-adaptive
translator for coarse-to-fine semantic extraction and meaning translation
according to specific tasks. In order to extend the FLSC into more realistic
conditions, we design a channel state information-based multiple-input
multiple-output transmission module to combat channel fading and noise.
Simulation results show that the coarse semantic information can deal with a
range of image-level tasks. Moreover, especially in low signal-to-noise ratio
and channel bandwidth ratio regimes, FLSC evidently outperforms the traditional
scheme, e.g. about 10 peak signal-to-noise ratio gain in the 3 dB channel
condition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_B/0/1/0/all/0/1&quot;&gt;Bingyan Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yongpeng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yuxuan Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ng_D/0/1/0/all/0/1&quot;&gt;Derrick Wing Kwan Ng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wenjun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03735">
<title>Randomized algorithms for precise measurement of differentially-private, personalized recommendations. (arXiv:2308.03735v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03735</link>
<description rdf:parseType="Literal">&lt;p&gt;Personalized recommendations form an important part of today&apos;s internet
ecosystem, helping artists and creators to reach interested users, and helping
users to discover new and engaging content. However, many users today are
skeptical of platforms that personalize recommendations, in part due to
historically careless treatment of personal data and data privacy. Now,
businesses that rely on personalized recommendations are entering a new
paradigm, where many of their systems must be overhauled to be privacy-first.
In this article, we propose an algorithm for personalized recommendations that
facilitates both precise and differentially-private measurement. We consider
advertising as an example application, and conduct offline experiments to
quantify how the proposed privacy-preserving algorithm affects key metrics
related to user experience, advertiser value, and platform revenue compared to
the extremes of both (private) non-personalized and non-private, personalized
implementations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laro_A/0/1/0/all/0/1&quot;&gt;Allegra Laro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yanqing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1&quot;&gt;Hao He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aghazadeh_B/0/1/0/all/0/1&quot;&gt;Babak Aghazadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.00085">
<title>Machine Learning and Computer Vision Techniques in Bee Monitoring Applications. (arXiv:2208.00085v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2208.00085</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning and computer vision are dynamically growing fields, which
have proven to be able to solve very complex tasks. They could also be used for
the monitoring of the honeybee colonies and for the inspection of their health
state, which could identify potentially dangerous states before the situation
is critical, or to better plan periodic bee colony inspections and therefore
save significant costs. In this paper, we present an overview of the
state-of-the-art computer vision and machine learning applications used for bee
monitoring. We also demonstrate the potential of those methods as an example of
an automated bee counter algorithm. The paper is aimed at veterinary and
apidology professionals and experts, who might not be familiar with machine
learning to introduce to them its possibilities, therefore each family of
applications is opened by a brief theoretical introduction and motivation
related to its base method. We hope that this paper will inspire other
scientists to use the machine learning techniques for other applications in bee
monitoring.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilik_S/0/1/0/all/0/1&quot;&gt;Simon Bilik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bostik_O/0/1/0/all/0/1&quot;&gt;Ondrej Bostik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kratochvila_L/0/1/0/all/0/1&quot;&gt;Lukas Kratochvila&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ligocki_A/0/1/0/all/0/1&quot;&gt;Adam Ligocki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poncak_M/0/1/0/all/0/1&quot;&gt;Matej Poncak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zemcik_T/0/1/0/all/0/1&quot;&gt;Tomas Zemcik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richter_M/0/1/0/all/0/1&quot;&gt;Milos Richter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janakova_I/0/1/0/all/0/1&quot;&gt;Ilona Janakova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honec_P/0/1/0/all/0/1&quot;&gt;Petr Honec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horak_K/0/1/0/all/0/1&quot;&gt;Karel Horak&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>