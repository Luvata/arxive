<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-09-28T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15867" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15871" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15875" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15877" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15881" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15886" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15889" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15938" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15946" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15954" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15963" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15965" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15985" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15990" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15995" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16014" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16020" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16022" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16025" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16032" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16034" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16042" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16044" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16055" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16058" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16059" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16064" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16066" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16074" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16077" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16096" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16105" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16108" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16109" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16114" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16115" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16117" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16118" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16119" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16131" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16139" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16143" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16155" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16173" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16175" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16177" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16188" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16200" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16210" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16220" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16235" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16240" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16269" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16274" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16289" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16291" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16299" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16314" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16316" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16318" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16335" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16338" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16342" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16347" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16353" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16354" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16357" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16369" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16374" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16382" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16384" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16391" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16397" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16398" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16401" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16409" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16412" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16414" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16428" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16429" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16448" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16456" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16457" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16459" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16465" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16467" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16476" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16487" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16495" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16512" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16519" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16521" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16534" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16536" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16540" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16546" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16561" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16563" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16571" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16577" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16578" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16584" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16592" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16593" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16595" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16597" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16598" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16603" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16604" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16620" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16630" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16631" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16633" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16645" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16656" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16662" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16663" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16668" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.16672" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.00029" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1911.09307" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2108.12547" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2109.03890" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2112.00723" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2202.05135" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2202.09134" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.00147" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.05625" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.06308" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.14708" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.05856" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.07403" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.09916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.12814" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.16808" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.02941" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.03559" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.10538" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.01253" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.11562" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.06807" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.09976" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.00031" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.12414" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.16296" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.04934" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.06366" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.12405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.12586" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.03942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.04811" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.04866" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.10775" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.16912" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.18471" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.05805" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.15891" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.01026" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02245" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.04870" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.06822" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.08079" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.12499" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.16735" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.03666" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.04412" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.05034" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.10425" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.13104" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.13978" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.16900" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03847" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.05516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.05525" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.05832" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.06612" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.07461" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.09175" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.09979" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.10003" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11475" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11657" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12041" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.13405" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.13752" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15123" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15128" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15253" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15639" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.15757" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2309.15867">
<title>Identifying factors associated with fast visual field progression in patients with ocular hypertension based on unsupervised machine learning. (arXiv:2309.15867v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15867</link>
<description rdf:parseType="Literal">&lt;p&gt;Purpose: To identify ocular hypertension (OHT) subtypes with different trends
of visual field (VF) progression based on unsupervised machine learning and to
discover factors associated with fast VF progression. Participants: A total of
3133 eyes of 1568 ocular hypertension treatment study (OHTS) participants with
at least five follow-up VF tests were included in the study. Methods: We used a
latent class mixed model (LCMM) to identify OHT subtypes using standard
automated perimetry (SAP) mean deviation (MD) trajectories. We characterized
the subtypes based on demographic, clinical, ocular, and VF factors at the
baseline. We then identified factors driving fast VF progression using
generalized estimating equation (GEE) and justified findings qualitatively and
quantitatively. Results: The LCMM model discovered four clusters (subtypes) of
eyes with different trajectories of MD worsening. The number of eyes in
clusters were 794 (25%), 1675 (54%), 531 (17%) and 133 (4%). We labelled the
clusters as Improvers, Stables, Slow progressors, and Fast progressors based on
their mean of MD decline, which were 0.08, -0.06, -0.21, and -0.45 dB/year,
respectively. Eyes with fast VF progression had higher baseline age,
intraocular pressure (IOP), pattern standard deviation (PSD) and refractive
error (RE), but lower central corneal thickness (CCT). Fast progression was
associated with calcium channel blockers, being male, heart disease history,
diabetes history, African American race, stroke history, and migraine
headaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xiaoqin Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poursoroush_A/0/1/0/all/0/1&quot;&gt;Asma Poursoroush&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jian Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boland_M/0/1/0/all/0/1&quot;&gt;Michael V. Boland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_C/0/1/0/all/0/1&quot;&gt;Chris Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yousefi_S/0/1/0/all/0/1&quot;&gt;Siamak Yousefi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15871">
<title>Telescope: An Automated Hybrid Forecasting Approach on a Level-Playing Field. (arXiv:2309.15871v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15871</link>
<description rdf:parseType="Literal">&lt;p&gt;In many areas of decision-making, forecasting is an essential pillar.
Consequently, many different forecasting methods have been proposed. From our
experience, recently presented forecasting methods are computationally
intensive, poorly automated, tailored to a particular data set, or they lack a
predictable time-to-result. To this end, we introduce Telescope, a novel
machine learning-based forecasting approach that automatically retrieves
relevant information from a given time series and splits it into parts,
handling each of them separately. In contrast to deep learning methods, our
approach doesn&apos;t require parameterization or the need to train and fit a
multitude of parameters. It operates with just one time series and provides
forecasts within seconds without any additional setup. Our experiments show
that Telescope outperforms recent methods by providing accurate and reliable
forecasts while making no assumptions about the analyzed time series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bauer_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leznik_M/0/1/0/all/0/1&quot;&gt;Mark Leznik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stenger_M/0/1/0/all/0/1&quot;&gt;Michael Stenger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leppich_R/0/1/0/all/0/1&quot;&gt;Robert Leppich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herbst_N/0/1/0/all/0/1&quot;&gt;Nikolas Herbst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kounev_S/0/1/0/all/0/1&quot;&gt;Samuel Kounev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1&quot;&gt;Ian Foster&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15875">
<title>STAG: Enabling Low Latency and Low Staleness of GNN-based Services with Dynamic Graphs. (arXiv:2309.15875v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15875</link>
<description rdf:parseType="Literal">&lt;p&gt;Many emerging user-facing services adopt Graph Neural Networks (GNNs) to
improve serving accuracy. When the graph used by a GNN model changes,
representations (embedding) of nodes in the graph should be updated
accordingly. However, the node representation update is too slow, resulting in
either long response latency of user queries (the inference is performed after
the update completes) or high staleness problem (the inference is performed
based on stale data). Our in-depth analysis shows that the slow update is
mainly due to neighbor explosion problem in graphs and duplicated computation.
Based on such findings, we propose STAG, a GNN serving framework that enables
low latency and low staleness of GNN-based services. It comprises a
collaborative serving mechanism and an additivity-based incremental propagation
strategy. With the collaborative serving mechanism, only part of node
representations are updated during the update phase, and the final
representations are calculated in the inference phase. It alleviates the
neighbor explosion problem. The additivity-based incremental propagation
strategy reuses intermediate data during the update phase, eliminating
duplicated computation problem. Experimental results show that STAG accelerates
the update phase by 1.3x~90.1x, and greatly reduces staleness time with a
slight increase in response latency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiawen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Quan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1&quot;&gt;Deze Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhuo Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1&quot;&gt;Minyi Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15877">
<title>Neuro-Inspired Hierarchical Multimodal Learning. (arXiv:2309.15877v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15877</link>
<description rdf:parseType="Literal">&lt;p&gt;Integrating and processing information from various sources or modalities are
critical for obtaining a comprehensive and accurate perception of the real
world. Drawing inspiration from neuroscience, we develop the
Information-Theoretic Hierarchical Perception (ITHP) model, which utilizes the
concept of information bottleneck. Distinct from most traditional fusion models
that aim to incorporate all modalities as input, our model designates the prime
modality as input, while the remaining modalities act as detectors in the
information pathway. Our proposed perception model focuses on constructing an
effective and compact information flow by achieving a balance between the
minimization of mutual information between the latent state and the input modal
state, and the maximization of mutual information between the latent states and
the remaining modal states. This approach leads to compact latent state
representations that retain relevant information while minimizing redundancy,
thereby substantially enhancing the performance of downstream tasks.
Experimental evaluations on both the MUStARD and CMU-MOSI datasets demonstrate
that our model consistently distills crucial information in multimodal learning
scenarios, outperforming state-of-the-art benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1&quot;&gt;Xiongye Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Gengshuo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1&quot;&gt;Gaurav Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1&quot;&gt;Defu Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shixuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yaxing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1&quot;&gt;Tianqing Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1&quot;&gt;Mingxi Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bogdan_P/0/1/0/all/0/1&quot;&gt;Paul Bogdan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15881">
<title>Enhancing Cross-Category Learning in Recommendation Systems with Multi-Layer Embedding Training. (arXiv:2309.15881v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15881</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern DNN-based recommendation systems rely on training-derived embeddings
of sparse features. Input sparsity makes obtaining high-quality embeddings for
rarely-occurring categories harder as their representations are updated
infrequently. We demonstrate a training-time technique to produce superior
embeddings via effective cross-category learning and theoretically explain its
surprising effectiveness. The scheme, termed the multi-layer embeddings
training (MLET), trains embeddings using factorization of the embedding layer,
with an inner dimension higher than the target embedding dimension. For
inference efficiency, MLET converts the trained two-layer embedding into a
single-layer one thus keeping inference-time model size unchanged.
&lt;/p&gt;
&lt;p&gt;Empirical superiority of MLET is puzzling as its search space is not larger
than that of the single-layer embedding. The strong dependence of MLET on the
inner dimension is even more surprising. We develop a theory that explains both
of these behaviors by showing that MLET creates an adaptive update mechanism
modulated by the singular vectors of embeddings. When tested on multiple
state-of-the-art recommendation models for click-through rate (CTR) prediction
tasks, MLET consistently produces better models, especially for rare items. At
constant model quality, MLET allows embedding dimension, and model size,
reduction by up to 16x, and 5.8x on average, across the models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1&quot;&gt;Zihao Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghaemmaghami_B/0/1/0/all/0/1&quot;&gt;Benjamin Ghaemmaghami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Ashish Kumar Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_B/0/1/0/all/0/1&quot;&gt;Benjamin Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orshansky_L/0/1/0/all/0/1&quot;&gt;Leo Orshansky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erez_M/0/1/0/all/0/1&quot;&gt;Mattan Erez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orshansky_M/0/1/0/all/0/1&quot;&gt;Michael Orshansky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15886">
<title>Projection based fuzzy least squares twin support vector machine for class imbalance problems. (arXiv:2309.15886v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15886</link>
<description rdf:parseType="Literal">&lt;p&gt;Class imbalance is a major problem in many real world classification tasks.
Due to the imbalance in the number of samples, the support vector machine (SVM)
classifier gets biased toward the majority class. Furthermore, these samples
are often observed with a certain degree of noise. Therefore, to remove these
problems we propose a novel fuzzy based approach to deal with class imbalanced
as well noisy datasets. We propose two approaches to address these problems.
The first approach is based on the intuitionistic fuzzy membership, termed as
robust energy-based intuitionistic fuzzy least squares twin support vector
machine (IF-RELSTSVM). Furthermore, we introduce the concept of
hyperplane-based fuzzy membership in our second approach, where the final
classifier is termed as robust energy-based fuzzy least square twin support
vector machine (F-RELSTSVM). By using this technique, the membership values are
based on a projection based approach, where the data points are projected on
the hyperplanes. The performance of the proposed algorithms is evaluated on
several benchmark and synthetic datasets. The experimental results show that
the proposed IF-RELSTSVM and F-RELSTSVM models outperform the baseline
algorithms. Statistical tests are performed to check the significance of the
proposed algorithms. The results show the applicability of the proposed
algorithms on noisy as well as imbalanced datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanveer_M/0/1/0/all/0/1&quot;&gt;M. Tanveer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_R/0/1/0/all/0/1&quot;&gt;Ritik Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richhariya_B/0/1/0/all/0/1&quot;&gt;Bharat Richhariya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15889">
<title>High Perceptual Quality Wireless Image Delivery with Denoising Diffusion Models. (arXiv:2309.15889v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.15889</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the image transmission problem over a noisy wireless channel via
deep learning-based joint source-channel coding (DeepJSCC) along with a
denoising diffusion probabilistic model (DDPM) at the receiver. Specifically,
we are interested in the perception-distortion trade-off in the practical
finite block length regime, in which separate source and channel coding can be
highly suboptimal. We introduce a novel scheme that utilizes the range-null
space decomposition of the target image. We transmit the range-space of the
image after encoding and employ DDPM to progressively refine its null space
contents. Through extensive experiments, we demonstrate significant
improvements in distortion and perceptual quality of reconstructed images
compared to standard DeepJSCC and the state-of-the-art generative
learning-based method. We will publicly share our source code to facilitate
further research and reproducibility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yilmaz_S/0/1/0/all/0/1&quot;&gt;Selim F. Yilmaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Niu_X/0/1/0/all/0/1&quot;&gt;Xueyan Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bai_B/0/1/0/all/0/1&quot;&gt;Bo Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Han_W/0/1/0/all/0/1&quot;&gt;Wei Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Deng_L/0/1/0/all/0/1&quot;&gt;Lei Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gunduz_D/0/1/0/all/0/1&quot;&gt;Deniz Gunduz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15938">
<title>Exploring Self-Supervised Contrastive Learning of Spatial Sound Event Representation. (arXiv:2309.15938v1 [eess.AS])</title>
<link>http://arxiv.org/abs/2309.15938</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we present a simple multi-channel framework for contrastive
learning (MC-SimCLR) to encode &apos;what&apos; and &apos;where&apos; of spatial audios. MC-SimCLR
learns joint spectral and spatial representations from unlabeled spatial
audios, thereby enhancing both event classification and sound localization in
downstream tasks. At its core, we propose a multi-level data augmentation
pipeline that augments different levels of audio features, including waveforms,
Mel spectrograms, and generalized cross-correlation (GCC) features. In
addition, we introduce simple yet effective channel-wise augmentation methods
to randomly swap the order of the microphones and mask Mel and GCC channels. By
using these augmentations, we find that linear layers on top of the learned
representation significantly outperform supervised models in terms of both
event classification accuracy and localization error. We also perform a
comprehensive analysis of the effect of each augmentation method and a
comparison of the fine-tuning performance using different amounts of labeled
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jiang_X/0/1/0/all/0/1&quot;&gt;Xilin Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1&quot;&gt;Cong Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yinghao Aaron Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mesgarani_N/0/1/0/all/0/1&quot;&gt;Nima Mesgarani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15946">
<title>Unified Long-Term Time-Series Forecasting Benchmark. (arXiv:2309.15946v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15946</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to support the advancement of machine learning methods for
predicting time-series data, we present a comprehensive dataset designed
explicitly for long-term time-series forecasting. We incorporate a collection
of datasets obtained from diverse, dynamic systems and real-life records. Each
dataset is standardized by dividing it into training and test trajectories with
predetermined lookback lengths. We include trajectories of length up to $2000$
to ensure a reliable evaluation of long-term forecasting capabilities. To
determine the most effective model in diverse scenarios, we conduct an
extensive benchmarking analysis using classical and state-of-the-art models,
namely LSTM, DeepAR, NLinear, N-Hits, PatchTST, and LatentODE. Our findings
reveal intriguing performance comparisons among these models, highlighting the
dataset-dependent nature of model effectiveness. Notably, we introduce a custom
latent NLinear model and enhance DeepAR with a curriculum learning phase. Both
consistently outperform their vanilla counterparts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cyranka_J/0/1/0/all/0/1&quot;&gt;Jacek Cyranka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haponiuk_S/0/1/0/all/0/1&quot;&gt;Szymon Haponiuk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15954">
<title>The Devil is in the Details: A Deep Dive into the Rabbit Hole of Data Filtering. (arXiv:2309.15954v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.15954</link>
<description rdf:parseType="Literal">&lt;p&gt;The quality of pre-training data plays a critical role in the performance of
foundation models. Popular foundation models often design their own recipe for
data filtering, which makes it hard to analyze and compare different data
filtering approaches. DataComp is a new benchmark dedicated to evaluating
different methods for data filtering. This paper describes our learning and
solution when participating in the DataComp challenge. Our filtering strategy
includes three stages: single-modality filtering, cross-modality filtering, and
data distribution alignment. We integrate existing methods and propose new
solutions, such as computing CLIP score on horizontally flipped images to
mitigate the interference of scene text, using vision and language models to
retrieve training samples for target downstream tasks, rebalancing the data
distribution to improve the efficiency of allocating the computational budget,
etc. We slice and dice our design choices, provide in-depth analysis, and
discuss open questions. Our approach outperforms the best method from the
DataComp paper by over 4% on the average performance of 38 tasks and by over 2%
on ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Haichao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yu Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Sateesh Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Linjie Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Heng Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15963">
<title>An Uncertainty-Aware Pseudo-Label Selection Framework using Regularized Conformal Prediction. (arXiv:2309.15963v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15963</link>
<description rdf:parseType="Literal">&lt;p&gt;Consistency regularization-based methods are prevalent in semi-supervised
learning (SSL) algorithms due to their exceptional performance. However, they
mainly depend on domain-specific data augmentations, which are not usable in
domains where data augmentations are less practicable. On the other hand,
Pseudo-labeling (PL) is a general and domain-agnostic SSL approach that, unlike
consistency regularization-based methods, does not rely on the domain. PL
underperforms due to the erroneous high-confidence predictions from poorly
calibrated models. This paper proposes an uncertainty-aware pseudo-label
selection framework that employs uncertainty sets yielded by the conformal
regularization algorithm to fix the poor calibration neural networks, reducing
noisy training data. The codes of this work are available at:
https://github.com/matinmoezzi/ups conformal classification
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moezzi_M/0/1/0/all/0/1&quot;&gt;Matin Moezzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15965">
<title>TraCE: Trajectory Counterfactual Explanation Scores. (arXiv:2309.15965v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15965</link>
<description rdf:parseType="Literal">&lt;p&gt;Counterfactual explanations, and their associated algorithmic recourse, are
typically leveraged to understand, explain, and potentially alter a prediction
coming from a black-box classifier. In this paper, we propose to extend the use
of counterfactuals to evaluate progress in sequential decision making tasks. To
this end, we introduce a model-agnostic modular framework, TraCE (Trajectory
Counterfactual Explanation) scores, which is able to distill and condense
progress in highly complex scenarios into a single value. We demonstrate
TraCE&apos;s utility across domains by showcasing its main properties in two case
studies spanning healthcare and climate change.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1&quot;&gt;Jeffrey N. Clark&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Small_E/0/1/0/all/0/1&quot;&gt;Edward A. Small&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keshtmand_N/0/1/0/all/0/1&quot;&gt;Nawid Keshtmand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_M/0/1/0/all/0/1&quot;&gt;Michelle W.L. Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mayoral_E/0/1/0/all/0/1&quot;&gt;Elena Fillola Mayoral&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Werner_E/0/1/0/all/0/1&quot;&gt;Enrico Werner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bourdeaux_C/0/1/0/all/0/1&quot;&gt;Christopher P. Bourdeaux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1&quot;&gt;Raul Santos-Rodriguez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15985">
<title>Open Source Infrastructure for Differentiable Density Functional Theory. (arXiv:2309.15985v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15985</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning exchange correlation functionals, used in quantum chemistry
calculations, from data has become increasingly important in recent years, but
training such a functional requires sophisticated software infrastructure. For
this reason, we build open source infrastructure to train neural exchange
correlation functionals. We aim to standardize the processing pipeline by
adapting state-of-the-art techniques from work done by multiple groups. We have
open sourced the model in the DeepChem library to provide a platform for
additional research on differentiable quantum chemistry methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vidhyadhiraja_A/0/1/0/all/0/1&quot;&gt;Advika Vidhyadhiraja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiagarajan_A/0/1/0/all/0/1&quot;&gt;Arun Pa Thiagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1&quot;&gt;Venkat Viswanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramsundar_B/0/1/0/all/0/1&quot;&gt;Bharath Ramsundar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15990">
<title>Machine Learning Based Analytics for the Significance of Gait Analysis in Monitoring and Managing Lower Extremity Injuries. (arXiv:2309.15990v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15990</link>
<description rdf:parseType="Literal">&lt;p&gt;This study explored the potential of gait analysis as a tool for assessing
post-injury complications, e.g., infection, malunion, or hardware irritation,
in patients with lower extremity fractures. The research focused on the
proficiency of supervised machine learning models predicting complications
using consecutive gait datasets. We identified patients with lower extremity
fractures at an academic center. Patients underwent gait analysis with a
chest-mounted IMU device. Using software, raw gait data was preprocessed,
emphasizing 12 essential gait variables. Machine learning models including
XGBoost, Logistic Regression, SVM, LightGBM, and Random Forest were trained,
tested, and evaluated. Attention was given to class imbalance, addressed using
SMOTE. We introduced a methodology to compute the Rate of Change (ROC) for gait
variables, independent of the time difference between gait analyses. XGBoost
was the optimal model both before and after applying SMOTE. Prior to SMOTE, the
model achieved an average test AUC of 0.90 (95% CI: [0.79, 1.00]) and test
accuracy of 86% (95% CI: [75%, 97%]). Feature importance analysis attributed
importance to the duration between injury and gait analysis. Data patterns
showed early physiological compensations, followed by stabilization phases,
emphasizing prompt gait analysis. This study underscores the potential of
machine learning, particularly XGBoost, in gait analysis for orthopedic care.
Predicting post-injury complications, early gait assessment becomes vital,
revealing intervention points. The findings support a shift in orthopedics
towards a data-informed approach, enhancing patient outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezapour_M/0/1/0/all/0/1&quot;&gt;Mostafa Rezapour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seymour_R/0/1/0/all/0/1&quot;&gt;Rachel B. Seymour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sims_S/0/1/0/all/0/1&quot;&gt;Stephen H. Sims&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karunakar_M/0/1/0/all/0/1&quot;&gt;Madhav A. Karunakar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habet_N/0/1/0/all/0/1&quot;&gt;Nahir Habet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurcan_M/0/1/0/all/0/1&quot;&gt;Metin Nafi Gurcan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15995">
<title>Digital Twin-based Anomaly Detection with Curriculum Learning in Cyber-physical Systems. (arXiv:2309.15995v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.15995</link>
<description rdf:parseType="Literal">&lt;p&gt;Anomaly detection is critical to ensure the security of cyber-physical
systems (CPS). However, due to the increasing complexity of attacks and CPS
themselves, anomaly detection in CPS is becoming more and more challenging. In
our previous work, we proposed a digital twin-based anomaly detection method,
called ATTAIN, which takes advantage of both historical and real-time data of
CPS. However, such data vary significantly in terms of difficulty. Therefore,
similar to human learning processes, deep learning models (e.g., ATTAIN) can
benefit from an easy-to-difficult curriculum. To this end, in this paper, we
present a novel approach, named digitaL twin-based Anomaly deTecTion wIth
Curriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculum
learning to optimize its learning paradigm. LATTICE attributes each sample with
a difficulty score, before being fed into a training scheduler. The training
scheduler samples batches of training data based on these difficulty scores
such that learning from easy to difficult data can be performed. To evaluate
LATTICE, we use five publicly available datasets collected from five real-world
CPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-art
anomaly detectors. Evaluation results show that LATTICE outperforms the three
baselines and ATTAIN by 0.906%-2.367% in terms of the F1 score. LATTICE also,
on average, reduces the training time of ATTAIN by 4.2% on the five datasets
and is on par with the baselines in terms of detection delay time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1&quot;&gt;Qinghua Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1&quot;&gt;Shaukat Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_T/0/1/0/all/0/1&quot;&gt;Tao Yue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16014">
<title>Graph-level Representation Learning with Joint-Embedding Predictive Architectures. (arXiv:2309.16014v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16014</link>
<description rdf:parseType="Literal">&lt;p&gt;Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a
novel and powerful technique for self-supervised representation learning. They
aim to learn an energy-based model by predicting the latent representation of a
target signal $y$ from a context signal $x$. JEPAs bypass the need for data
augmentation and negative samples, which are typically required by contrastive
learning, while avoiding the overfitting issues associated with
generative-based pretraining. In this paper, we show that graph-level
representations can be effectively modeled using this paradigm and propose
Graph-JEPA, the first JEPA for the graph domain. In particular, we employ
masked modeling to learn embeddings for different subgraphs of the input graph.
To endow the representations with the implicit hierarchy that is often present
in graph-level concepts, we devise an alternative training objective that
consists of predicting the coordinates of the encoded subgraphs on the unit
hyperbola in the 2D plane. Extensive validation shows that Graph-JEPA can learn
representations that are expressive and competitive in both graph
classification and regression problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skenderi_G/0/1/0/all/0/1&quot;&gt;Geri Skenderi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jiliang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cristani_M/0/1/0/all/0/1&quot;&gt;Marco Cristani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16020">
<title>GeoCLIP: Clip-Inspired Alignment between Locations and Images for Effective Worldwide Geo-localization. (arXiv:2309.16020v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16020</link>
<description rdf:parseType="Literal">&lt;p&gt;Worldwide Geo-localization aims to pinpoint the precise location of images
taken anywhere on Earth. This task has considerable challenges due to immense
variation in geographic landscapes. The image-to-image retrieval-based
approaches fail to solve this problem on a global scale as it is not feasible
to construct a large gallery of images covering the entire world. Instead,
existing approaches divide the globe into discrete geographic cells,
transforming the problem into a classification task. However, their performance
is limited by the predefined classes and often results in inaccurate
localizations when an image&apos;s location significantly deviates from its class
center. To overcome these limitations, we propose GeoCLIP, a novel
CLIP-inspired Image-to-GPS retrieval approach that enforces alignment between
the image and its corresponding GPS locations. GeoCLIP&apos;s location encoder
models the Earth as a continuous function by employing positional encoding
through random Fourier features and constructing a hierarchical representation
that captures information at varying resolutions to yield a semantically rich
high-dimensional feature suitable to use even beyond geo-localization. To the
best of our knowledge, this is the first work employing GPS encoding for
geo-localization. We demonstrate the efficacy of our method via extensive
experiments and ablations on benchmark datasets. We achieve competitive
performance with just 20% of training data, highlighting its effectiveness even
in limited-data settings. Furthermore, we qualitatively demonstrate
geo-localization using a text query by leveraging CLIP backbone of our image
encoder.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cepeda_V/0/1/0/all/0/1&quot;&gt;Vicente Vivanco Cepeda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1&quot;&gt;Gaurav Kumar Nayak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1&quot;&gt;Mubarak Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16022">
<title>GNNHLS: Evaluating Graph Neural Network Inference via High-Level Synthesis. (arXiv:2309.16022v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16022</link>
<description rdf:parseType="Literal">&lt;p&gt;With the ever-growing popularity of Graph Neural Networks (GNNs), efficient
GNN inference is gaining tremendous attention. Field-Programming Gate Arrays
(FPGAs) are a promising execution platform due to their fine-grained
parallelism, low-power consumption, reconfigurability, and concurrent
execution. Even better, High-Level Synthesis (HLS) tools bridge the gap between
the non-trivial FPGA development efforts and rapid emergence of new GNN models.
In this paper, we propose GNNHLS, an open-source framework to comprehensively
evaluate GNN inference acceleration on FPGAs via HLS, containing a software
stack for data generation and baseline deployment, and FPGA implementations of
6 well-tuned GNN HLS kernels. We evaluate GNNHLS on 4 graph datasets with
distinct topologies and scales. The results show that GNNHLS achieves up to
50.8x speedup and 423x energy reduction relative to the CPU baselines. Compared
with the GPU baselines, GNNHLS achieves up to 5.16x speedup and 74.5x energy
reduction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1&quot;&gt;Chenfeng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1&quot;&gt;Zehao Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yixin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chamberlain_R/0/1/0/all/0/1&quot;&gt;Roger D. Chamberlain&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16025">
<title>Symbolic Imitation Learning: From Black-Box to Explainable Driving Policies. (arXiv:2309.16025v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16025</link>
<description rdf:parseType="Literal">&lt;p&gt;Current methods of imitation learning (IL), primarily based on deep neural
networks, offer efficient means for obtaining driving policies from real-world
data but suffer from significant limitations in interpretability and
generalizability. These shortcomings are particularly concerning in
safety-critical applications like autonomous driving. In this paper, we address
these limitations by introducing Symbolic Imitation Learning (SIL), a
groundbreaking method that employs Inductive Logic Programming (ILP) to learn
driving policies which are transparent, explainable and generalisable from
available datasets. Utilizing the real-world highD dataset, we subject our
method to a rigorous comparative analysis against prevailing
neural-network-based IL methods. Our results demonstrate that SIL not only
enhances the interpretability of driving policies but also significantly
improves their applicability across varied driving situations. Hence, this work
offers a novel pathway to more reliable and safer autonomous driving systems,
underscoring the potential of integrating ILP into the domain of IL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharifi_I/0/1/0/all/0/1&quot;&gt;Iman Sharifi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fallah_S/0/1/0/all/0/1&quot;&gt;Saber Fallah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16032">
<title>Learning Dissipative Neural Dynamical Systems. (arXiv:2309.16032v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16032</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider an unknown nonlinear dynamical system that is known to be
dissipative. The objective of this paper is to learn a neural dynamical model
that approximates this system, while preserving the dissipativity property in
the model. In general, imposing dissipativity constraints during neural network
training is a hard problem for which no known techniques exist. In this work,
we address the problem of learning a dissipative neural dynamical system model
in two stages. First, we learn an unconstrained neural dynamical model that
closely approximates the system dynamics. Next, we derive sufficient conditions
to perturb the weights of the neural dynamical model to ensure dissipativity,
followed by perturbation of the biases to retain the fit of the model to the
trajectories of the nonlinear system. We show that these two perturbation
problems can be solved independently to obtain a neural dynamical model that is
guaranteed to be dissipative while closely approximating the nonlinear system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yuezhu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sivaranjani_S/0/1/0/all/0/1&quot;&gt;S. Sivaranjani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16034">
<title>Analytical Modelling of Raw Data for Flow-Guided In-body Nanoscale Localization. (arXiv:2309.16034v1 [cs.ET])</title>
<link>http://arxiv.org/abs/2309.16034</link>
<description rdf:parseType="Literal">&lt;p&gt;Advancements in nanotechnology and material science are paving the way toward
nanoscale devices that combine sensing, computing, data and energy storage, and
wireless communication. In precision medicine, these nanodevices show promise
for disease diagnostics, treatment, and monitoring from within the patients&apos;
bloodstreams. Assigning the location of a sensed biological event with the
event itself, which is the main proposition of flow-guided in-body nanoscale
localization, would be immensely beneficial from the perspective of precision
medicine. The nanoscale nature of the nanodevices and the challenging
environment that the bloodstream represents, result in current flow-guided
localization approaches being constrained in their communication and
energy-related capabilities. The communication and energy constraints of the
nanodevices result in different features of raw data for flow-guided
localization, in turn affecting its performance. An analytical modeling of the
effects of imperfect communication and constrained energy causing intermittent
operation of the nanodevices on the raw data produced by the nanodevices would
be beneficial. Hence, we propose an analytical model of raw data for
flow-guided localization, where the raw data is modeled as a function of
communication and energy-related capabilities of the nanodevice. We evaluate
the model by comparing its output with the one obtained through the utilization
of a simulator for objective evaluation of flow-guided localization, featuring
comparably higher level of realism. Our results across a number of scenarios
and heterogeneous performance metrics indicate high similarity between the
model and simulator-generated raw datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pascual_G/0/1/0/all/0/1&quot;&gt;Guillem Pascual&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lemic_F/0/1/0/all/0/1&quot;&gt;Filip Lemic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delgado_C/0/1/0/all/0/1&quot;&gt;Carmen Delgado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_Perez_X/0/1/0/all/0/1&quot;&gt;Xavier Costa-Perez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16042">
<title>Towards Best Practices of Activation Patching in Language Models: Metrics and Methods. (arXiv:2309.16042v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16042</link>
<description rdf:parseType="Literal">&lt;p&gt;Mechanistic interpretability seeks to understand the internal mechanisms of
machine learning models, where localization -- identifying the important model
components -- is a key step. Activation patching, also known as causal tracing
or interchange intervention, is a standard technique for this task (Vig et al.,
2020), but the literature contains many variants with little consensus on the
choice of hyperparameters or methodology. In this work, we systematically
examine the impact of methodological details in activation patching, including
evaluation metrics and corruption methods. In several settings of localization
and circuit discovery in language models, we find that varying these
hyperparameters could lead to disparate interpretability results. Backed by
empirical observations, we give conceptual arguments for why certain metrics or
methods may be preferred. Finally, we provide recommendations for the best
practices of activation patching going forwards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fred Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nanda_N/0/1/0/all/0/1&quot;&gt;Neel Nanda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16044">
<title>Improving Adaptive Online Learning Using Refined Discretization. (arXiv:2309.16044v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16044</link>
<description rdf:parseType="Literal">&lt;p&gt;We study unconstrained Online Linear Optimization with Lipschitz losses. The
goal is to simultaneously achieve ($i$) second order gradient adaptivity; and
($ii$) comparator norm adaptivity also known as &quot;parameter freeness&quot; in the
literature. Existing regret bounds (Cutkosky and Orabona, 2018; Mhammedi and
Koolen, 2020; Jacobsen and Cutkosky, 2022) have the suboptimal $O(\sqrt{V_T\log
V_T})$ dependence on the gradient variance $V_T$, while the present work
improves it to the optimal rate $O(\sqrt{V_T})$ using a novel
continuous-time-inspired algorithm, without any impractical doubling trick.
This result can be extended to the setting with unknown Lipschitz constant,
eliminating the range ratio problem from prior works (Mhammedi and Koolen,
2020).
&lt;/p&gt;
&lt;p&gt;Concretely, we first show that the aimed simultaneous adaptivity can be
achieved fairly easily in a continuous time analogue of the problem, where the
environment is modeled by an arbitrary continuous semimartingale. Then, our key
innovation is a new discretization argument that preserves such adaptivity in
the discrete time adversarial setting. This refines a non-gradient-adaptive
discretization argument from (Harvey et al., 2023), both algorithmically and
analytically, which could be of independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Heng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1&quot;&gt;Ashok Cutkosky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1&quot;&gt;Ioannis Ch. Paschalidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16055">
<title>Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A Machine Learning Perspective. (arXiv:2309.16055v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16055</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we leveraged machine learning techniques to identify risk
factors associated with post-COVID-19 mental health disorders. Our analysis,
based on data collected from 669 patients across various provinces in Iraq,
yielded valuable insights. We found that age, gender, and geographical region
of residence were significant demographic factors influencing the likelihood of
developing mental health disorders in post-COVID-19 patients. Additionally,
comorbidities and the severity of COVID-19 illness were important clinical
predictors. Psychosocial factors, such as social support, coping strategies,
and perceived stress levels, also played a substantial role. Our findings
emphasize the complex interplay of multiple factors in the development of
mental health disorders following COVID-19 recovery. Healthcare providers and
policymakers should consider these risk factors when designing targeted
interventions and support systems for individuals at risk. Machine
learning-based approaches can provide a valuable tool for predicting and
preventing adverse mental health outcomes in post-COVID-19 patients. Further
research and prospective studies are needed to validate these findings and
enhance our understanding of the long-term psychological impact of the COVID-19
pandemic. This study contributes to the growing body of knowledge regarding the
mental health consequences of the COVID-19 pandemic and underscores the
importance of a multidisciplinary approach to address the diverse needs of
individuals on the path to recovery. Keywords: COVID-19, mental health, risk
factors, machine learning, Iraq
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yousif_M/0/1/0/all/0/1&quot;&gt;Maitham G. Yousif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Amran_F/0/1/0/all/0/1&quot;&gt;Fadhil G. Al-Amran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castro_H/0/1/0/all/0/1&quot;&gt;Hector J. Castro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16058">
<title>AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model. (arXiv:2309.16058v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16058</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Any-Modality Augmented Language Model (AnyMAL), a unified model
that reasons over diverse input modality signals (i.e. text, image, video,
audio, IMU motion sensor), and generates textual responses. AnyMAL inherits the
powerful text-based reasoning abilities of the state-of-the-art LLMs including
LLaMA-2 (70B), and converts modality-specific signals to the joint textual
space through a pre-trained aligner module. To further strengthen the
multimodal LLM&apos;s capabilities, we fine-tune the model with a multimodal
instruction set manually collected to cover diverse topics and tasks beyond
simple QAs. We conduct comprehensive empirical analysis comprising both human
and automatic evaluations, and demonstrate state-of-the-art performance on
various multimodal tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1&quot;&gt;Seungwhan Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1&quot;&gt;Andrea Madotto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhaojiang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagarajan_T/0/1/0/all/0/1&quot;&gt;Tushar Nagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1&quot;&gt;Matt Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1&quot;&gt;Shashank Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1&quot;&gt;Chun-Fu Yeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murugesan_P/0/1/0/all/0/1&quot;&gt;Prakash Murugesan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heidari_P/0/1/0/all/0/1&quot;&gt;Peyman Heidari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinet_K/0/1/0/all/0/1&quot;&gt;Kavya Srinet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damavandi_B/0/1/0/all/0/1&quot;&gt;Babak Damavandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Anuj Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16059">
<title>Predicting Cardiovascular Complications in Post-COVID-19 Patients Using Data-Driven Machine Learning Models. (arXiv:2309.16059v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16059</link>
<description rdf:parseType="Literal">&lt;p&gt;The COVID-19 pandemic has globally posed numerous health challenges, notably
the emergence of post-COVID-19 cardiovascular complications. This study
addresses this by utilizing data-driven machine learning models to predict such
complications in 352 post-COVID-19 patients from Iraq. Clinical data, including
demographics, comorbidities, lab results, and imaging, were collected and used
to construct predictive models. These models, leveraging various machine
learning algorithms, demonstrated commendable performance in identifying
patients at risk. Early detection through these models promises timely
interventions and improved outcomes. In conclusion, this research underscores
the potential of data-driven machine learning for predicting post-COVID-19
cardiovascular complications, emphasizing the need for continued validation and
research in diverse clinical settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yousif_M/0/1/0/all/0/1&quot;&gt;Maitham G. Yousif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castro_H/0/1/0/all/0/1&quot;&gt;Hector J. Castro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16064">
<title>Masked autoencoders are scalable learners of cellular morphology. (arXiv:2309.16064v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16064</link>
<description rdf:parseType="Literal">&lt;p&gt;Inferring biological relationships from cellular phenotypes in high-content
microscopy screens provides significant opportunity and challenge in biological
research. Prior results have shown that deep vision models can capture
biological signal better than hand-crafted features. This work explores how
weakly supervised and self-supervised deep learning approaches scale when
training larger models on larger datasets. Our results show that both CNN- and
ViT-based masked autoencoders significantly outperform weakly supervised
models. At the high-end of our scale, a ViT-L/8 trained on over 3.5-billion
unique crops sampled from 95-million microscopy images achieves relative
improvements as high as 28% over our best weakly supervised models at inferring
known biological relationships curated from public databases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kraus_O/0/1/0/all/0/1&quot;&gt;Oren Kraus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kenyon_Dean_K/0/1/0/all/0/1&quot;&gt;Kian Kenyon-Dean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saberian_S/0/1/0/all/0/1&quot;&gt;Saber Saberian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fallah_M/0/1/0/all/0/1&quot;&gt;Maryam Fallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McLean_P/0/1/0/all/0/1&quot;&gt;Peter McLean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leung_J/0/1/0/all/0/1&quot;&gt;Jess Leung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1&quot;&gt;Vasudev Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1&quot;&gt;Ayla Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balakrishnan_J/0/1/0/all/0/1&quot;&gt;Jia Balakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celik_S/0/1/0/all/0/1&quot;&gt;Safiye Celik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sypetkowski_M/0/1/0/all/0/1&quot;&gt;Maciej Sypetkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Chi Vicky Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morse_K/0/1/0/all/0/1&quot;&gt;Kristen Morse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makes_M/0/1/0/all/0/1&quot;&gt;Maureen Makes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mabey_B/0/1/0/all/0/1&quot;&gt;Ben Mabey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Earnshaw_B/0/1/0/all/0/1&quot;&gt;Berton Earnshaw&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16066">
<title>Label Augmentation Method for Medical Landmark Detection in Hip Radiograph Images. (arXiv:2309.16066v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16066</link>
<description rdf:parseType="Literal">&lt;p&gt;This work reports the empirical performance of an automated medical landmark
detection method for predict clinical markers in hip radiograph images.
Notably, the detection method was trained using a label-only augmentation
scheme; our results indicate that this form of augmentation outperforms
traditional data augmentation and produces highly sample efficient estimators.
We train a generic U-Net-based architecture under a curriculum consisting of
two phases: initially relaxing the landmarking task by enlarging the label
points to regions, then gradually eroding these label regions back to the base
task. We measure the benefits of this approach on six datasets of radiographs
with gold-standard expert annotations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suh_Y/0/1/0/all/0/1&quot;&gt;Yehyun Suh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_P/0/1/0/all/0/1&quot;&gt;Peter Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1&quot;&gt;J.Ryan Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moyer_D/0/1/0/all/0/1&quot;&gt;Daniel Moyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16074">
<title>Infer and Adapt: Bipedal Locomotion Reward Learning from Demonstrations via Inverse Reinforcement Learning. (arXiv:2309.16074v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.16074</link>
<description rdf:parseType="Literal">&lt;p&gt;Enabling bipedal walking robots to learn how to maneuver over highly uneven,
dynamically changing terrains is challenging due to the complexity of robot
dynamics and interacted environments. Recent advancements in learning from
demonstrations have shown promising results for robot learning in complex
environments. While imitation learning of expert policies has been
well-explored, the study of learning expert reward functions is largely
under-explored in legged locomotion. This paper brings state-of-the-art Inverse
Reinforcement Learning (IRL) techniques to solving bipedal locomotion problems
over complex terrains. We propose algorithms for learning expert reward
functions, and we subsequently analyze the learned functions. Through nonlinear
function approximation, we uncover meaningful insights into the expert&apos;s
locomotion strategies. Furthermore, we empirically demonstrate that training a
bipedal locomotion policy with the inferred reward functions enhances its
walking performance on unseen terrains, highlighting the adaptability offered
by reward learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Feiyang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1&quot;&gt;Zhaoyuan Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hanran Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1&quot;&gt;Anqi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Ye Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16077">
<title>Task-Oriented Koopman-Based Control with Contrastive Encoder. (arXiv:2309.16077v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.16077</link>
<description rdf:parseType="Literal">&lt;p&gt;We present task-oriented Koopman-based control that utilizes end-to-end
reinforcement learning and contrastive encoder to simultaneously learn the
Koopman latent embedding, operator and associated linear controller within an
iterative loop. By prioritizing the task cost as main objective for controller
learning, we reduce the reliance of controller design on a well-identified
model, which extends Koopman control beyond low-dimensional systems to
high-dimensional, complex nonlinear systems, including pixel-based scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1&quot;&gt;Xubo Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Hanyang Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siriya_S/0/1/0/all/0/1&quot;&gt;Seth Siriya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Ye Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Mo Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16096">
<title>Adversarial Examples Might be Avoidable: The Role of Data Concentration in Adversarial Robustness. (arXiv:2309.16096v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16096</link>
<description rdf:parseType="Literal">&lt;p&gt;The susceptibility of modern machine learning classifiers to adversarial
examples has motivated theoretical results suggesting that these might be
unavoidable. However, these results can be too general to be applicable to
natural data distributions. Indeed, humans are quite robust for tasks involving
vision. This apparent conflict motivates a deeper dive into the question: Are
adversarial examples truly unavoidable? In this work, we theoretically
demonstrate that a key property of the data distribution -- concentration on
small-volume subsets of the input space -- determines whether a robust
classifier exists. We further demonstrate that, for a data distribution
concentrated on a union of low-dimensional linear subspaces, exploiting data
structure naturally leads to classifiers that enjoy good robustness guarantees,
improving upon methods for provable certification in certain regimes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_A/0/1/0/all/0/1&quot;&gt;Ambar Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sulam_J/0/1/0/all/0/1&quot;&gt;Jeremias Sulam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1&quot;&gt;Ren&amp;#xe9; Vidal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16105">
<title>Differentially Private Secure Multiplication: Hiding Information in the Rubble of Noise. (arXiv:2309.16105v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2309.16105</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of private distributed multi-party multiplication. It
is well-established that Shamir secret-sharing coding strategies can enable
perfect information-theoretic privacy in distributed computation via the
celebrated algorithm of Ben Or, Goldwasser and Wigderson (the &quot;BGW algorithm&quot;).
However, perfect privacy and accuracy require an honest majority, that is, $N
\geq 2t+1$ compute nodes are required to ensure privacy against any $t$
colluding adversarial nodes. By allowing for some controlled amount of
information leakage and approximate multiplication instead of exact
multiplication, we study coding schemes for the setting where the number of
honest nodes can be a minority, that is $N&amp;lt; 2t+1.$ We develop a tight
characterization privacy-accuracy trade-off for cases where $N &amp;lt; 2t+1$ by
measuring information leakage using {differential} privacy instead of perfect
privacy, and using the mean squared error metric for accuracy. A novel
technical aspect is an intricately layered noise distribution that merges ideas
from differential privacy and Shamir secret-sharing at different layers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cadambe_V/0/1/0/all/0/1&quot;&gt;Viveck R. Cadambe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devulapalli_A/0/1/0/all/0/1&quot;&gt;Ateet Devulapalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1&quot;&gt;Haewon Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1&quot;&gt;Flavio P. Calmon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16108">
<title>Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words. (arXiv:2309.16108v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16108</link>
<description rdf:parseType="Literal">&lt;p&gt;Vision Transformer (ViT) has emerged as a powerful architecture in the realm
of modern computer vision. However, its application in certain imaging fields,
such as microscopy and satellite imaging, presents unique challenges. In these
domains, images often contain multiple channels, each carrying semantically
distinct and independent information. Furthermore, the model must demonstrate
robustness to sparsity in input channels, as they may not be densely available
during training or testing. In this paper, we propose a modification to the ViT
architecture that enhances reasoning across the input channels and introduce
Hierarchical Channel Sampling (HCS) as an additional regularization technique
to ensure robustness when only partial channels are presented during test time.
Our proposed model, ChannelViT, constructs patch tokens independently from each
input channel and utilizes a learnable channel embedding that is added to the
patch tokens, similar to positional embeddings. We evaluate the performance of
ChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat
(satellite imaging). Our results show that ChannelViT outperforms ViT on
classification tasks and generalizes well, even when a subset of input channels
is used during testing. Across our experiments, HCS proves to be a powerful
regularizer, independent of the architecture employed, suggesting itself as a
straightforward technique for robust ViT training. Lastly, we find that
ChannelViT generalizes effectively even when there is limited access to all
channels during training, highlighting its potential for multi-channel imaging
under real-world conditions with sparse sensors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1&quot;&gt;Yujia Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sivanandan_S/0/1/0/all/0/1&quot;&gt;Srinivasan Sivanandan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karaletsos_T/0/1/0/all/0/1&quot;&gt;Theofanis Karaletsos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16109">
<title>Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics. (arXiv:2309.16109v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16109</link>
<description rdf:parseType="Literal">&lt;p&gt;Contrastive learning is a self-supervised representation learning framework,
where two positive views generated through data augmentation are made similar
by an attraction force in a data representation space, while a repulsive force
makes them far from negative examples. Non-contrastive learning, represented by
BYOL and SimSiam, further gets rid of negative examples and improves
computational efficiency. While learned representations may collapse into a
single point due to the lack of the repulsive force at first sight, Tian et al.
(2021) revealed through the learning dynamics analysis that the representations
can avoid collapse if data augmentation is sufficiently stronger than
regularization. However, their analysis does not take into account
commonly-used feature normalization, a normalizer before measuring the
similarity of representations, and hence excessively strong regularization may
collapse the dynamics, which is an unnatural behavior under the presence of
feature normalization. Therefore, we extend the previous theory based on the L2
loss by considering the cosine loss, which involves feature normalization. We
show that the cosine loss induces sixth-order dynamics (while the L2 loss
induces a third-order one), in which a stable equilibrium dynamically emerges
even if there are only collapsed solutions with given initial parameters. Thus,
we offer a new understanding that feature normalization plays an important role
in robustly preventing the dynamics collapse.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1&quot;&gt;Han Bao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16114">
<title>Comparing Active Learning Performance Driven by Gaussian Processes or Bayesian Neural Networks for Constrained Trajectory Exploration. (arXiv:2309.16114v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.16114</link>
<description rdf:parseType="Literal">&lt;p&gt;Robots with increasing autonomy progress our space exploration capabilities,
particularly for in-situ exploration and sampling to stand in for human
explorers. Currently, humans drive robots to meet scientific objectives, but
depending on the robot&apos;s location, the exchange of information and driving
commands between the human operator and robot may cause undue delays in mission
fulfillment. An autonomous robot encoded with a scientific objective and an
exploration strategy incurs no communication delays and can fulfill missions
more quickly. Active learning algorithms offer this capability of intelligent
exploration, but the underlying model structure varies the performance of the
active learning algorithm in accurately forming an understanding of the
environment. In this paper, we investigate the performance differences between
active learning algorithms driven by Gaussian processes or Bayesian neural
networks for exploration strategies encoded on agents that are constrained in
their trajectories, like planetary surface rovers. These two active learning
strategies were tested in a simulation environment against science-blind
strategies to predict the spatial distribution of a variable of interest along
multiple datasets. The performance metrics of interest are model accuracy in
root mean squared (RMS) error, training time, model convergence, total distance
traveled until convergence, and total samples until convergence. Active
learning strategies encoded with Gaussian processes require less computation to
train, converge to an accurate model more quickly, and propose trajectories of
shorter distance, except in a few complex environments in which Bayesian neural
networks achieve a more accurate model in the large data regime due to their
more expressive functional bases. The paper concludes with advice on when and
how to implement either exploration strategy for future space missions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akins_S/0/1/0/all/0/1&quot;&gt;Sapphira Akins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1&quot;&gt;Frances Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16115">
<title>Compositional Sculpting of Iterative Generative Processes. (arXiv:2309.16115v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16115</link>
<description rdf:parseType="Literal">&lt;p&gt;High training costs of generative models and the need to fine-tune them for
specific tasks have created a strong interest in model reuse and composition. A
key challenge in composing iterative generative processes, such as GFlowNets
and diffusion models, is that to realize the desired target distribution, all
steps of the generative process need to be coordinated, and satisfy delicate
balance conditions. In this work, we propose Compositional Sculpting: a general
approach for defining compositions of iterative generative processes. We then
introduce a method for sampling from these compositions built on classifier
guidance. We showcase ways to accomplish compositional sculpting in both
GFlowNets and diffusion models. We highlight two binary operations
$\unicode{x2014}$ the harmonic mean ($p_1 \otimes p_2$) and the contrast ($p_1
\unicode{x25D1}\,p_2$) between pairs, and the generalization of these
operations to multiple component distributions. We offer empirical results on
image and molecular generation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garipov_T/0/1/0/all/0/1&quot;&gt;Timur Garipov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peuter_S/0/1/0/all/0/1&quot;&gt;Sebastiaan De Peuter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Ge Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_V/0/1/0/all/0/1&quot;&gt;Vikas Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1&quot;&gt;Samuel Kaski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1&quot;&gt;Tommi Jaakkola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16117">
<title>E2Net: Resource-Efficient Continual Learning with Elastic Expansion Network. (arXiv:2309.16117v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16117</link>
<description rdf:parseType="Literal">&lt;p&gt;Continual Learning methods are designed to learn new tasks without erasing
previous knowledge. However, Continual Learning often requires massive
computational power and storage capacity for satisfactory performance. In this
paper, we propose a resource-efficient continual learning method called the
Elastic Expansion Network (E2Net). Leveraging core subnet distillation and
precise replay sample selection, E2Net achieves superior average accuracy and
diminished forgetting within the same computational and storage constraints,
all while minimizing processing time. In E2Net, we propose Representative
Network Distillation to identify the representative core subnet by assessing
parameter quantity and output similarity with the working network, distilling
analogous subnets within the working network to mitigate reliance on rehearsal
buffers and facilitating knowledge transfer across previous tasks. To enhance
storage resource utilization, we then propose Subnet Constraint Experience
Replay to optimize rehearsal efficiency through a sample storage strategy based
on the structures of representative networks. Extensive experiments conducted
predominantly on cloud environments with diverse datasets and also spanning the
edge environment demonstrate that E2Net consistently outperforms
state-of-the-art methods. In addition, our method outperforms competitors in
terms of both storage and computational requirements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;RuiQi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diao_B/0/1/0/all/0/1&quot;&gt;Boyu Diao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Libo Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1&quot;&gt;Zhulin An&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yongjun Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16118">
<title>D$^3$Fields: Dynamic 3D Descriptor Fields for Zero-Shot Generalizable Robotic Manipulation. (arXiv:2309.16118v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.16118</link>
<description rdf:parseType="Literal">&lt;p&gt;Scene representation has been a crucial design choice in robotic manipulation
systems. An ideal representation should be 3D, dynamic, and semantic to meet
the demands of diverse manipulation tasks. However, previous works often lack
all three properties simultaneously. In this work, we introduce D$^3$Fields -
dynamic 3D descriptor fields. These fields capture the dynamics of the
underlying 3D environment and encode both semantic features and instance masks.
Specifically, we project arbitrary 3D points in the workspace onto multi-view
2D visual observations and interpolate features derived from foundational
models. The resulting fused descriptor fields allow for flexible goal
specifications using 2D images with varied contexts, styles, and instances. To
evaluate the effectiveness of these descriptor fields, we apply our
representation to a wide range of robotic manipulation tasks in a zero-shot
manner. Through extensive evaluation in both real-world scenarios and
simulations, we demonstrate that D$^3$Fields are both generalizable and
effective for zero-shot robotic manipulation tasks. In quantitative comparisons
with state-of-the-art dense descriptors, such as Dense Object Nets and DINO,
D$^3$Fields exhibit significantly better generalization abilities and
manipulation accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yixuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mingtong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1&quot;&gt;Katherine Driggs-Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1&quot;&gt;Li Fei-Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yunzhu Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16119">
<title>ModuLoRA: Finetuning 3-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers. (arXiv:2309.16119v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16119</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a memory-efficient finetuning algorithm for large language models
(LLMs) that supports finetuning LLMs with 65B parameters in 3-bit or 4-bit
precision on as little as one 48GB GPU. Our method, modular low-rank adaptation
(ModuLoRA), integrates any user-specified weight quantizer with finetuning via
low-rank adapters (LoRAs). Our approach relies on a simple
quantization-agnostic backward pass that adaptively materializes low-precision
LLM weights from a custom black-box quantization module. This approach enables
finetuning 3-bit LLMs for the first time--leveraging state-of-the-art 3-bit
OPTQ quantization often outperforms finetuning that relies on less
sophisticated 4-bit and 8-bit methods. In our experiments, ModuLoRA attains
competitive performance on text classification, natural language infernece, and
instruction following tasks using significantly less memory than existing
approaches, and we also surpass the state-of-the-art ROUGE score on a popular
summarization task. We release ModuLoRA together with a series of low-precision
models--including the first family of 3-bit instruction following Alpaca
LLMs--as part of LLMTOOLS, a user-friendly library for quantizing, running, and
finetuning LLMs on consumer GPUs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1&quot;&gt;Junjie Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1&quot;&gt;Jiahao Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yingheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1&quot;&gt;Christopher De Sa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuleshov_V/0/1/0/all/0/1&quot;&gt;Volodymyr Kuleshov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16131">
<title>A Spectral Approach for Learning Spatiotemporal Neural Differential Equations. (arXiv:2309.16131v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16131</link>
<description rdf:parseType="Literal">&lt;p&gt;Rapidly developing machine learning methods has stimulated research interest
in computationally reconstructing differential equations (DEs) from
observational data which may provide additional insight into underlying
causative mechanisms. In this paper, we propose a novel neural-ODE based method
that uses spectral expansions in space to learn spatiotemporal DEs. The major
advantage of our spectral neural DE learning approach is that it does not rely
on spatial discretization, thus allowing the target spatiotemporal equations to
contain long range, nonlocal spatial interactions that act on unbounded spatial
domains. Our spectral approach is shown to be as accurate as some of the latest
machine learning approaches for learning PDEs operating on bounded domains. By
developing a spectral framework for learning both PDEs and integro-differential
equations, we extend machine learning methods to apply to unbounded DEs and a
larger class of problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1&quot;&gt;Mingtao Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiangting Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Q/0/1/0/all/0/1&quot;&gt;Qijing Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chou_T/0/1/0/all/0/1&quot;&gt;Tom Chou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16139">
<title>Two-Step Active Learning for Instance Segmentation with Uncertainty and Diversity Sampling. (arXiv:2309.16139v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16139</link>
<description rdf:parseType="Literal">&lt;p&gt;Training high-quality instance segmentation models requires an abundance of
labeled images with instance masks and classifications, which is often
expensive to procure. Active learning addresses this challenge by striving for
optimum performance with minimal labeling cost by selecting the most
informative and representative images for labeling. Despite its potential,
active learning has been less explored in instance segmentation compared to
other tasks like image classification, which require less labeling. In this
study, we propose a post-hoc active learning algorithm that integrates
uncertainty-based sampling with diversity-based sampling. Our proposed
algorithm is not only simple and easy to implement, but it also delivers
superior performance on various datasets. Its practical application is
demonstrated on a real-world overhead imagery dataset, where it increases the
labeling efficiency fivefold.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1&quot;&gt;Ke Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albro_S/0/1/0/all/0/1&quot;&gt;Stephen Albro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DeSalvo_G/0/1/0/all/0/1&quot;&gt;Giulia DeSalvo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothawade_S/0/1/0/all/0/1&quot;&gt;Suraj Kothawade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashwan_A/0/1/0/all/0/1&quot;&gt;Abdullah Rashwan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tavakkol_S/0/1/0/all/0/1&quot;&gt;Sasan Tavakkol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batmanghelich_K/0/1/0/all/0/1&quot;&gt;Kayhan Batmanghelich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1&quot;&gt;Xiaoqi Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16143">
<title>Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples. (arXiv:2309.16143v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16143</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-supervised learning (SSL) is a promising approach for training deep
classification models using labeled and unlabeled datasets. However, existing
SSL methods rely on a large unlabeled dataset, which may not always be
available in many real-world applications due to legal constraints (e.g.,
GDPR). In this paper, we investigate the research question: Can we train SSL
models without real unlabeled datasets? Instead of using real unlabeled
datasets, we propose an SSL method using synthetic datasets generated from
generative foundation models trained on datasets containing millions of samples
in diverse domains (e.g., ImageNet). Our main concepts are identifying
synthetic samples that emulate unlabeled samples from generative foundation
models and training classifiers using these synthetic samples. To achieve this,
our method is formulated as an alternating optimization problem: (i)
meta-learning of generative foundation models and (ii) SSL of classifiers using
real labeled and synthetic unlabeled samples. For (i), we propose a
meta-learning objective that optimizes latent variables to generate samples
that resemble real labeled samples and minimize the validation loss. For (ii),
we propose a simple unsupervised loss function that regularizes the feature
extractors of classifiers to maximize the performance improvement obtained from
synthetic samples. We confirm that our method outperforms baselines using
generative foundation models on SSL. We also demonstrate that our methods
outperform SSL using real unlabeled datasets in scenarios with extremely small
amounts of labeled datasets. This suggests that synthetic samples have the
potential to provide improvement gains more efficiently than real unlabeled
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1&quot;&gt;Shin&amp;#x27;ya Yamaguchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16155">
<title>The Trickle-down Impact of Reward (In-)consistency on RLHF. (arXiv:2309.16155v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.16155</link>
<description rdf:parseType="Literal">&lt;p&gt;Standard practice within Reinforcement Learning from Human Feedback (RLHF)
involves optimizing against a Reward Model (RM), which itself is trained to
reflect human preferences for desirable generations. A notable subject that is
understudied is the (in-)consistency of RMs -- whether they can recognize the
semantic changes to different prompts and appropriately adapt their reward
assignments -- and their impact on the downstream RLHF model.
&lt;/p&gt;
&lt;p&gt;In this paper, we visit a series of research questions relevant to RM
inconsistency: (1) How can we measure the consistency of reward models? (2) How
consistent are the existing RMs and how can we improve them? (3) In what ways
does reward inconsistency influence the chatbots resulting from the RLHF model
training?
&lt;/p&gt;
&lt;p&gt;We propose Contrast Instructions -- a benchmarking strategy for the
consistency of RM. Each example in Contrast Instructions features a pair of
lexically similar instructions with different ground truth responses. A
consistent RM is expected to rank the corresponding instruction and response
higher than other combinations. We observe that current RMs trained with the
standard ranking objective fail miserably on Contrast Instructions compared to
average humans. To show that RM consistency can be improved efficiently without
using extra training budget, we propose two techniques ConvexDA and
RewardFusion, which enhance reward consistency through extrapolation during the
RM training and inference stage, respectively. We show that RLHF models trained
with a more consistent RM yield more useful responses, suggesting that reward
inconsistency exhibits a trickle-down effect on the downstream RLHF process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1&quot;&gt;Lingfeng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Sihao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Linfeng Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1&quot;&gt;Lifeng Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1&quot;&gt;Baolin Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1&quot;&gt;Haitao Mi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1&quot;&gt;Daniel Khashabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1&quot;&gt;Dong Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16173">
<title>Distill to Delete: Unlearning in Graph Networks with Knowledge Distillation. (arXiv:2309.16173v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16173</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph unlearning has emerged as a pivotal method to delete information from a
pre-trained graph neural network (GNN). One may delete nodes, a class of nodes,
edges, or a class of edges. An unlearning method enables the GNN model to
comply with data protection regulations (i.e., the right to be forgotten),
adapt to evolving data distributions, and reduce the GPU-hours carbon footprint
by avoiding repetitive retraining. Existing partitioning and aggregation-based
methods have limitations due to their poor handling of local graph dependencies
and additional overhead costs. More recently, GNNDelete offered a
model-agnostic approach that alleviates some of these issues. Our work takes a
novel approach to address these challenges in graph unlearning through
knowledge distillation, as it distills to delete in GNN (D2DGN). It is a
model-agnostic distillation framework where the complete graph knowledge is
divided and marked for retention and deletion. It performs distillation with
response-based soft targets and feature-based node embedding while minimizing
KL divergence. The unlearned model effectively removes the influence of deleted
graph elements while preserving knowledge about the retained graph elements.
D2DGN surpasses the performance of existing methods when evaluated on various
real-world graph datasets by up to $43.1\%$ (AUC) in edge and node unlearning
tasks. Other notable advantages include better efficiency, better performance
in removing target elements, preservation of performance for the retained
elements, and zero overhead costs. Notably, our D2DGN surpasses the
state-of-the-art GNNDelete in AUC by $2.4\%$, improves membership inference
ratio by $+1.3$, requires $10.2\times10^6$ fewer FLOPs per forward pass and up
to $\mathbf{3.2}\times$ faster.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_Y/0/1/0/all/0/1&quot;&gt;Yash Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandal_M/0/1/0/all/0/1&quot;&gt;Murari Mandal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kankanhalli_M/0/1/0/all/0/1&quot;&gt;Mohan Kankanhalli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16175">
<title>Using Weak Supervision and Data Augmentation in Question Answering. (arXiv:2309.16175v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.16175</link>
<description rdf:parseType="Literal">&lt;p&gt;The onset of the COVID-19 pandemic accentuated the need for access to
biomedical literature to answer timely and disease-specific questions. During
the early days of the pandemic, one of the biggest challenges we faced was the
lack of peer-reviewed biomedical articles on COVID-19 that could be used to
train machine learning models for question answering (QA). In this paper, we
explore the roles weak supervision and data augmentation play in training deep
neural network QA models. First, we investigate whether labels generated
automatically from the structured abstracts of scholarly papers using an
information retrieval algorithm, BM25, provide a weak supervision signal to
train an extractive QA model. We also curate new QA pairs using information
retrieval techniques, guided by the clinicaltrials.gov schema and the
structured abstracts of articles, in the absence of annotated data from
biomedical domain experts. Furthermore, we explore augmenting the training data
of a deep neural network model with linguistic features from external sources
such as lexical databases to account for variations in word morphology and
meaning. To better utilize our training data, we apply curriculum learning to
domain adaptation, fine-tuning our QA model in stages based on characteristics
of the QA pairs. We evaluate our methods in the context of QA models at the
core of a system to answer questions about COVID-19.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basu_C/0/1/0/all/0/1&quot;&gt;Chumki Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_H/0/1/0/all/0/1&quot;&gt;Himanshu Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McIntosh_A/0/1/0/all/0/1&quot;&gt;Allen McIntosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sablak_S/0/1/0/all/0/1&quot;&gt;Sezai Sablak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wullert_J/0/1/0/all/0/1&quot;&gt;John R. Wullert II&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16177">
<title>Systematic Sampling and Validation of Machine Learning-Parameterizations in Climate Models. (arXiv:2309.16177v1 [physics.ao-ph])</title>
<link>http://arxiv.org/abs/2309.16177</link>
<description rdf:parseType="Literal">&lt;p&gt;Progress in hybrid physics-machine learning (ML) climate simulations has been
limited by the difficulty of obtaining performant coupled (i.e. online)
simulations. While evaluating hundreds of ML parameterizations of subgrid
closures (here of convection and radiation) offline is straightforward, online
evaluation at the same scale is technically challenging. Our software
automation achieves an order-of-magnitude larger sampling of online modeling
errors than has previously been examined. Using this, we evaluate the hybrid
climate model performance and define strategies to improve it. We show that
model online performance improves when incorporating memory, a relative
humidity input feature transformation, and additional input variables. We also
reveal substantial variation in online error and inconsistencies between
offline vs. online error statistics. The implication is that hundreds of
candidate ML models should be evaluated online to detect the effects of
parameterization design choices. This is considerably more sampling than tends
to be reported in the current literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jerry Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Sungduk Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Beucler_T/0/1/0/all/0/1&quot;&gt;Tom Beucler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gentine_P/0/1/0/all/0/1&quot;&gt;Pierre Gentine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Walling_D/0/1/0/all/0/1&quot;&gt;David Walling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Pritchard_M/0/1/0/all/0/1&quot;&gt;Mike Pritchard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16188">
<title>Stackelberg Batch Policy Learning. (arXiv:2309.16188v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16188</link>
<description rdf:parseType="Literal">&lt;p&gt;Batch reinforcement learning (RL) defines the task of learning from a fixed
batch of data lacking exhaustive exploration. Worst-case optimality algorithms,
which calibrate a value-function model class from logged experience and perform
some type of pessimistic evaluation under the learned model, have emerged as a
promising paradigm for batch RL. However, contemporary works on this stream
have commonly overlooked the hierarchical decision-making structure hidden in
the optimization landscape. In this paper, we adopt a game-theoretical
viewpoint and model the policy learning diagram as a two-player general-sum
game with a leader-follower structure. We propose a novel stochastic
gradient-based learning algorithm: StackelbergLearner, in which the leader
player updates according to the total derivative of its objective instead of
the usual individual gradient, and the follower player makes individual updates
and ensures transition-consistent pessimistic reasoning. The derived learning
dynamic naturally lends StackelbergLearner to a game-theoretic interpretation
and provides a convergence guarantee to differentiable Stackelberg equilibria.
From a theoretical standpoint, we provide instance-dependent regret bounds with
general function approximation, which shows that our algorithm can learn a
best-effort policy that is able to compete against any comparator policy that
is covered by batch data. Notably, our theoretical regret guarantees only
require realizability without any data coverage and strong function
approximation conditions, e.g., Bellman closedness, which is in contrast to
prior works lacking such guarantees. Through comprehensive experiments, we find
that our algorithm consistently performs as well or better as compared to
state-of-the-art methods in batch RL benchmark and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wenzhuo Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qu_A/0/1/0/all/0/1&quot;&gt;Annie Qu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16200">
<title>Max-Sliced Mutual Information. (arXiv:2309.16200v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16200</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantifying the dependence between high-dimensional random variables is
central to statistical learning and inference. Two classical methods are
canonical correlation analysis (CCA), which identifies maximally correlated
projected versions of the original variables, and Shannon&apos;s mutual information,
which is a universal dependence measure that also captures high-order
dependencies. However, CCA only accounts for linear dependence, which may be
insufficient for certain applications, while mutual information is often
infeasible to compute/estimate in high dimensions. This work proposes a middle
ground in the form of a scalable information-theoretic generalization of CCA,
termed max-sliced mutual information (mSMI). mSMI equals the maximal mutual
information between low-dimensional projections of the high-dimensional
variables, which reduces back to CCA in the Gaussian case. It enjoys the best
of both worlds: capturing intricate dependencies in the data while being
amenable to fast computation and scalable estimation from samples. We show that
mSMI retains favorable structural properties of Shannon&apos;s mutual information,
like variational forms and identification of independence. We then study
statistical estimation of mSMI, propose an efficiently computable neural
estimator, and couple it with formal non-asymptotic error bounds. We present
experiments that demonstrate the utility of mSMI for several tasks,
encompassing independence testing, multi-view representation learning,
algorithmic fairness, and generative modeling. We observe that mSMI
consistently outperforms competing methods with little-to-no computational
overhead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsur_D/0/1/0/all/0/1&quot;&gt;Dor Tsur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldfeld_Z/0/1/0/all/0/1&quot;&gt;Ziv Goldfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1&quot;&gt;Kristjan Greenewald&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16210">
<title>Abdominal multi-organ segmentation in CT using Swinunter. (arXiv:2309.16210v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.16210</link>
<description rdf:parseType="Literal">&lt;p&gt;Abdominal multi-organ segmentation in computed tomography (CT) is crucial for
many clinical applications including disease detection and treatment planning.
Deep learning methods have shown unprecedented performance in this perspective.
However, it is still quite challenging to accurately segment different organs
utilizing a single network due to the vague boundaries of organs, the complex
background, and the substantially different organ size scales. In this work we
used make transformer-based model for training. It was found through previous
years&apos; competitions that basically all of the top 5 methods used CNN-based
methods, which is likely due to the lack of data volume that prevents
transformer-based methods from taking full advantage. The thousands of samples
in this competition may enable the transformer-based model to have more
excellent results. The results on the public validation set also show that the
transformer-based model can achieve an acceptable result and inference time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Mingjin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yongkang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yongyi Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16220">
<title>Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection in Medical Tabular Data. (arXiv:2309.16220v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16220</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their success, Machine Learning (ML) models do not generalize
effectively to data not originating from the training distribution. To reliably
employ ML models in real-world healthcare systems and avoid inaccurate
predictions on out-of-distribution (OOD) data, it is crucial to detect OOD
samples. Numerous OOD detection approaches have been suggested in other fields
- especially in computer vision - but it remains unclear whether the challenge
is resolved when dealing with medical tabular data. To answer this pressing
need, we propose an extensive reproducible benchmark to compare different
methods across a suite of tests including both near and far OODs. Our benchmark
leverages the latest versions of eICU and MIMIC-IV, two public datasets
encompassing tens of thousands of ICU patients in several hospitals. We
consider a wide array of density-based methods and SOTA post-hoc detectors
across diverse predictive architectures, including MLP, ResNet, and
Transformer. Our findings show that i) the problem appears to be solved for
far-OODs, but remains open for near-OODs; ii) post-hoc methods alone perform
poorly, but improve substantially when coupled with distance-based mechanisms;
iii) the transformer architecture is far less overconfident compared to MLP and
ResNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizmalayeri_M/0/1/0/all/0/1&quot;&gt;Mohammad Azizmalayeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abu_Hanna_A/0/1/0/all/0/1&quot;&gt;Ameen Abu-Hanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cina_G/0/1/0/all/0/1&quot;&gt;Giovanni Cin&amp;#xe1;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16223">
<title>GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations. (arXiv:2309.16223v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.16223</link>
<description rdf:parseType="Literal">&lt;p&gt;Diverse explainability methods of graph neural networks (GNN) have recently
been developed to highlight the edges and nodes in the graph that contribute
the most to the model predictions. However, it is not clear yet how to evaluate
the correctness of those explanations, whether it is from a human or a model
perspective. One unaddressed bottleneck in the current evaluation procedure is
the problem of out-of-distribution explanations, whose distribution differs
from those of the training data. This important issue affects existing
evaluation metrics such as the popular faithfulness or fidelity score. In this
paper, we show the limitations of faithfulness metrics. We propose GInX-Eval
(Graph In-distribution eXplanation Evaluation), an evaluation procedure of
graph explanations that overcomes the pitfalls of faithfulness and offers new
insights on explainability methods. Using a retraining strategy, the GInX score
measures how informative removed edges are for the model and the EdgeRank score
evaluates if explanatory edges are correctly ordered by their importance.
GInX-Eval verifies if ground-truth explanations are instructive to the GNN
model. In addition, it shows that many popular methods, including
gradient-based methods, produce explanations that are not better than a random
designation of edges as important subgraphs, challenging the findings of
current works in the area. Results with GInX-Eval are consistent across
multiple datasets and align with human evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amara_K/0/1/0/all/0/1&quot;&gt;Kenza Amara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Assady_M/0/1/0/all/0/1&quot;&gt;Mennatallah El-Assady&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1&quot;&gt;Rex Ying&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16235">
<title>Language models in molecular discovery. (arXiv:2309.16235v1 [physics.chem-ph])</title>
<link>http://arxiv.org/abs/2309.16235</link>
<description rdf:parseType="Literal">&lt;p&gt;The success of language models, especially transformer-based architectures,
has trickled into other domains giving rise to &quot;scientific language models&quot;
that operate on small molecules, proteins or polymers. In chemistry, language
models contribute to accelerating the molecule discovery cycle as evidenced by
promising recent findings in early-stage drug discovery. Here, we review the
role of language models in molecular discovery, underlining their strength in
de novo drug design, property prediction and reaction chemistry. We highlight
valuable open-source software assets thus lowering the entry barrier to the
field of scientific language modeling. Last, we sketch a vision for future
molecular design that combines a chatbot interface with access to computational
chemistry tools. Our contribution serves as a valuable resource for
researchers, chemists, and AI enthusiasts interested in understanding how
language models can and will be used to accelerate chemical discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Janakarajan_N/0/1/0/all/0/1&quot;&gt;Nikita Janakarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Erdmann_T/0/1/0/all/0/1&quot;&gt;Tim Erdmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Swaminathan_S/0/1/0/all/0/1&quot;&gt;Sarath Swaminathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Laino_T/0/1/0/all/0/1&quot;&gt;Teodoro Laino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Born_J/0/1/0/all/0/1&quot;&gt;Jannis Born&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16240">
<title>Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints. (arXiv:2309.16240v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16240</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing capabilities of large language models (LLMs) raise
opportunities for artificial general intelligence but concurrently amplify
safety concerns, such as potential misuse of AI systems, necessitating
effective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has
emerged as a promising pathway towards AI alignment but brings forth challenges
due to its complexity and dependence on a separate reward model. Direct
Preference Optimization (DPO) has been proposed as an alternative, and it
remains equivalent to RLHF under the reverse KL regularization constraint. This
paper presents $f$-DPO, a generalized approach to DPO by incorporating diverse
divergence constraints. We show that under certain $f$-divergences, including
Jensen-Shannon divergence, forward KL divergences and $\alpha$-divergences, the
complex relationship between the reward and optimal policy can also be
simplified by addressing the Karush-Kuhn-Tucker conditions. This eliminates the
need for estimating the normalizing constant in the Bradley-Terry model and
enables a tractable mapping between the reward function and the optimal policy.
Our approach optimizes LLMs to align with human preferences in a more efficient
and supervised manner under a broad set of divergence constraints. Empirically,
adopting these divergences ensures a balance between alignment performance and
generation diversity. Importantly, $f$-DPO outperforms PPO-based methods in
divergence efficiency, and divergence constraints directly influence expected
calibration error (ECE).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chaoqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yibo Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chenghao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16269">
<title>Hierarchical Network Data Analytics Framework for B5G Network Automation: Design and Implementation. (arXiv:2309.16269v1 [cs.NI])</title>
<link>http://arxiv.org/abs/2309.16269</link>
<description rdf:parseType="Literal">&lt;p&gt;5G introduced modularized network functions (NFs) to support emerging
services in a more flexible and elastic manner. To mitigate the complexity in
such modularized NF management, automated network operation and management are
indispensable, and thus the 3rd generation partnership project (3GPP) has
introduced a network data analytics function (NWDAF). However, a conventional
NWDAF needs to conduct both inference and training tasks, and thus it is
difficult to provide the analytics results to NFs in a timely manner for an
increased number of analytics requests. In this article, we propose a
hierarchical network data analytics framework (H-NDAF) where inference tasks
are distributed to multiple leaf NWDAFs and training tasks are conducted at the
root NWDAF. Extensive simulation results using open-source software (i.e.,
free5GC) demonstrate that H-NDAF can provide sufficiently accurate analytics
and faster analytics provision time compared to the conventional NWDAF.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeon_Y/0/1/0/all/0/1&quot;&gt;Youbin Jeon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pack_S/0/1/0/all/0/1&quot;&gt;Sangheon Pack&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16274">
<title>A framework for paired-sample hypothesis testing for high-dimensional data. (arXiv:2309.16274v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16274</link>
<description rdf:parseType="Literal">&lt;p&gt;The standard paired-sample testing approach in the multidimensional setting
applies multiple univariate tests on the individual features, followed by
p-value adjustments. Such an approach suffers when the data carry numerous
features. A number of studies have shown that classification accuracy can be
seen as a proxy for two-sample testing. However, neither theoretical
foundations nor practical recipes have been proposed so far on how this
strategy could be extended to multidimensional paired-sample testing. In this
work, we put forward the idea that scoring functions can be produced by the
decision rules defined by the perpendicular bisecting hyperplanes of the line
segments connecting each pair of instances. Then, the optimal scoring function
can be obtained by the pseudomedian of those rules, which we estimate by
extending naturally the Hodges-Lehmann estimator. We accordingly propose a
framework of a two-step testing procedure. First, we estimate the bisecting
hyperplanes for each pair of instances and an aggregated rule derived through
the Hodges-Lehmann estimator. The paired samples are scored by this aggregated
rule to produce a unidimensional representation. Second, we perform a Wilcoxon
signed-rank test on the obtained representation. Our experiments indicate that
our approach has substantial performance gains in testing accuracy compared to
the traditional multivariate and multiple testing, while at the same time
estimates each feature&apos;s contribution to the final result.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bargiotas_I/0/1/0/all/0/1&quot;&gt;Ioannis Bargiotas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kalogeratos_A/0/1/0/all/0/1&quot;&gt;Argyris Kalogeratos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vayatis_N/0/1/0/all/0/1&quot;&gt;Nicolas Vayatis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16286">
<title>Generalizable Heterogeneous Federated Cross-Correlation and Instance Similarity Learning. (arXiv:2309.16286v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16286</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning is an important privacy-preserving multi-party learning
paradigm, involving collaborative learning with others and local updating on
private data. Model heterogeneity and catastrophic forgetting are two crucial
challenges, which greatly limit the applicability and generalizability. This
paper presents a novel FCCL+, federated correlation and similarity learning
with non-target distillation, facilitating the both intra-domain
discriminability and inter-domain generalization. For heterogeneity issue, we
leverage irrelevant unlabeled public data for communication between the
heterogeneous participants. We construct cross-correlation matrix and align
instance similarity distribution on both logits and feature levels, which
effectively overcomes the communication barrier and improves the generalizable
ability. For catastrophic forgetting in local updating stage, FCCL+ introduces
Federated Non Target Distillation, which retains inter-domain knowledge while
avoiding the optimization conflict issue, fulling distilling privileged
inter-domain information through depicting posterior classes relation.
Considering that there is no standard benchmark for evaluating existing
heterogeneous federated learning under the same setting, we present a
comprehensive benchmark with extensive representative methods under four domain
shift scenarios, supporting both heterogeneous and homogeneous federated
settings. Empirical results demonstrate the superiority of our method and the
efficiency of modules on various scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wenke Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1&quot;&gt;Mang Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zekun Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1&quot;&gt;Bo Du&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16289">
<title>LawBench: Benchmarking Legal Knowledge of Large Language Models. (arXiv:2309.16289v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.16289</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) have demonstrated strong capabilities in various
aspects. However, when applying them to the highly specialized, safe-critical
legal domain, it is unclear how much legal knowledge they possess and whether
they can reliably perform legal-related tasks. To address this gap, we propose
a comprehensive evaluation benchmark LawBench. LawBench has been meticulously
crafted to have precise assessment of the LLMs&apos; legal capabilities from three
cognitive levels: (1) Legal knowledge memorization: whether LLMs can memorize
needed legal concepts, articles and facts; (2) Legal knowledge understanding:
whether LLMs can comprehend entities, events and relationships within legal
text; (3) Legal knowledge applying: whether LLMs can properly utilize their
legal knowledge and make necessary reasoning steps to solve realistic legal
tasks. LawBench contains 20 diverse tasks covering 5 task types: single-label
classification (SLC), multi-label classification (MLC), regression, extraction
and generation. We perform extensive evaluations of 51 LLMs on LawBench,
including 20 multilingual LLMs, 22 Chinese-oriented LLMs and 9 legal specific
LLMs. The results show that GPT-4 remains the best-performing LLM in the legal
domain, surpassing the others by a significant margin. While fine-tuning LLMs
on legal specific text brings certain improvements, we are still a long way
from obtaining usable and reliable LLMs in legal tasks. All data, model
predictions and evaluation code are released in
https://github.com/open-compass/LawBench/. We hope this benchmark provides
in-depth understanding of the LLMs&apos; domain-specified capabilities and speed up
the development of LLMs in the legal domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1&quot;&gt;Dawei Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1&quot;&gt;Fengzhe Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1&quot;&gt;Zhuo Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Songyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kai Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zongwen Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1&quot;&gt;Jidong Ge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16291">
<title>Efficiency Separation between RL Methods: Model-Free, Model-Based and Goal-Conditioned. (arXiv:2309.16291v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16291</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove a fundamental limitation on the efficiency of a wide class of
Reinforcement Learning (RL) algorithms. This limitation applies to model-free
RL methods as well as a broad range of model-based methods, such as planning
with tree search.
&lt;/p&gt;
&lt;p&gt;Under an abstract definition of this class, we provide a family of RL
problems for which these methods suffer a lower bound exponential in the
horizon for their interactions with the environment to find an optimal
behavior. However, there exists a method, not tailored to this specific family
of problems, which can efficiently solve the problems in the family.
&lt;/p&gt;
&lt;p&gt;In contrast, our limitation does not apply to several types of methods
proposed in the literature, for instance, goal-conditioned methods or other
algorithms that construct an inverse dynamics model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinon_B/0/1/0/all/0/1&quot;&gt;Brieuc Pinon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jungers_R/0/1/0/all/0/1&quot;&gt;Rapha&amp;#xeb;l Jungers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delvenne_J/0/1/0/all/0/1&quot;&gt;Jean-Charles Delvenne&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16299">
<title>CasIL: Cognizing and Imitating Skills via a Dual Cognition-Action Architecture. (arXiv:2309.16299v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.16299</link>
<description rdf:parseType="Literal">&lt;p&gt;Enabling robots to effectively imitate expert skills in longhorizon tasks
such as locomotion, manipulation, and more, poses a long-standing challenge.
Existing imitation learning (IL) approaches for robots still grapple with
sub-optimal performance in complex tasks. In this paper, we consider how this
challenge can be addressed within the human cognitive priors. Heuristically, we
extend the usual notion of action to a dual Cognition (high-level)-Action
(low-level) architecture by introducing intuitive human cognitive priors, and
propose a novel skill IL framework through human-robot interaction, called
Cognition-Action-based Skill Imitation Learning (CasIL), for the robotic agent
to effectively cognize and imitate the critical skills from raw visual
demonstrations. CasIL enables both cognition and action imitation, while
high-level skill cognition explicitly guides low-level primitive actions,
providing robustness and reliability to the entire skill IL process. We
evaluated our method on MuJoCo and RLBench benchmarks, as well as on the
obstacle avoidance and point-goal navigation tasks for quadrupedal robot
locomotion. Experimental results show that our CasIL consistently achieves
competitive and robust skill imitation capability compared to other
counterparts in a variety of long-horizon robotic tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zixuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1&quot;&gt;Ze Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shuyang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huo_J/0/1/0/all/0/1&quot;&gt;Jing Huo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yang Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16314">
<title>A Primer on Bayesian Neural Networks: Review and Debates. (arXiv:2309.16314v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16314</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks have achieved remarkable performance across various problem
domains, but their widespread applicability is hindered by inherent limitations
such as overconfidence in predictions, lack of interpretability, and
vulnerability to adversarial attacks. To address these challenges, Bayesian
neural networks (BNNs) have emerged as a compelling extension of conventional
neural networks, integrating uncertainty estimation into their predictive
capabilities.
&lt;/p&gt;
&lt;p&gt;This comprehensive primer presents a systematic introduction to the
fundamental concepts of neural networks and Bayesian inference, elucidating
their synergistic integration for the development of BNNs. The target audience
comprises statisticians with a potential background in Bayesian methods but
lacking deep learning expertise, as well as machine learners proficient in deep
neural networks but with limited exposure to Bayesian statistics. We provide an
overview of commonly employed priors, examining their impact on model behavior
and performance. Additionally, we delve into the practical considerations
associated with training and inference in BNNs.
&lt;/p&gt;
&lt;p&gt;Furthermore, we explore advanced topics within the realm of BNN research,
acknowledging the existence of ongoing debates and controversies. By offering
insights into cutting-edge developments, this primer not only equips
researchers and practitioners with a solid foundation in BNNs, but also
illuminates the potential applications of this dynamic field. As a valuable
resource, it fosters an understanding of BNNs and their promising prospects,
facilitating further advancements in the pursuit of knowledge and innovation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arbel_J/0/1/0/all/0/1&quot;&gt;Julyan Arbel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pitas_K/0/1/0/all/0/1&quot;&gt;Konstantinos Pitas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vladimirova_M/0/1/0/all/0/1&quot;&gt;Mariia Vladimirova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1&quot;&gt;Vincent Fortuin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16316">
<title>Astroconformer: The Prospects of Analyzing Stellar Light Curves with Transformer-Based Deep Learning Models. (arXiv:2309.16316v1 [astro-ph.SR])</title>
<link>http://arxiv.org/abs/2309.16316</link>
<description rdf:parseType="Literal">&lt;p&gt;Light curves of stars encapsulate a wealth of information about stellar
oscillations and granulation, thereby offering key insights into the internal
structure and evolutionary state of stars. Conventional asteroseismic
techniques have been largely confined to power spectral analysis, neglecting
the valuable phase information contained within light curves. While recent
machine learning applications in asteroseismology utilizing Convolutional
Neural Networks (CNNs) have successfully inferred stellar attributes from light
curves, they are often limited by the local feature extraction inherent in
convolutional operations. To circumvent these constraints, we present
$\textit{Astroconformer}$, a Transformer-based deep learning framework designed
to capture long-range dependencies in stellar light curves. Our empirical
analysis, which focuses on estimating surface gravity ($\log g$), is grounded
in a carefully curated dataset derived from $\textit{Kepler}$ light curves.
These light curves feature asteroseismic $\log g$ values spanning from 0.2 to
4.4. Our results underscore that, in the regime where the training data is
abundant, $\textit{Astroconformer}$ attains a root-mean-square-error (RMSE) of
0.017 dex around $\log g \approx 3 $. Even in regions where training data are
sparse, the RMSE can reach 0.1 dex. It outperforms not only the K-nearest
neighbor-based model ($\textit{The SWAN}$) but also state-of-the-art CNNs.
Ablation studies confirm that the efficacy of the models in this particular
task is strongly influenced by the size of their receptive fields, with larger
receptive fields correlating with enhanced performance. Moreover, we find that
the attention mechanisms within $\textit{Astroconformer}$ are well-aligned with
the inherent characteristics of stellar oscillations and granulation present in
the light curves.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Pan_J/0/1/0/all/0/1&quot;&gt;Jia-Shu Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Ting_Y/0/1/0/all/0/1&quot;&gt;Yuan-Sen Ting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jie Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16318">
<title>DeepPCR: Parallelizing Sequential Operations in Neural Networks. (arXiv:2309.16318v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16318</link>
<description rdf:parseType="Literal">&lt;p&gt;Parallelization techniques have become ubiquitous for accelerating inference
and training of deep neural networks. Despite this, several operations are
still performed in a sequential manner. For instance, the forward and backward
passes are executed layer-by-layer, and the output of diffusion models is
produced by applying a sequence of denoising steps. This sequential approach
results in a computational cost proportional to the number of steps involved,
presenting a potential bottleneck as the number of steps increases. In this
work, we introduce DeepPCR, a novel algorithm which parallelizes typically
sequential operations used in inference and training of neural networks.
DeepPCR is based on interpreting a sequence of $L$ steps as the solution of a
specific system of equations, which we recover using the Parallel Cyclic
Reduction algorithm. This reduces the complexity of computing the sequential
operations from $\mathcal{O}(L)$ to $\mathcal{O}(\log_2L)$, thus yielding a
speedup for large $L$. To verify the theoretical lower complexity of the
algorithm, and to identify regimes for speedup, we test the effectiveness of
DeepPCR in parallelizing the forward and backward pass in multi-layer
perceptrons, and reach speedups of up to $30\times$ for forward and $200\times$
for backward pass. We additionally showcase the flexibility of DeepPCR by
parallelizing training of ResNets with as many as 1024 layers, and generation
in diffusion models, enabling up to $7\times$ faster training and $11\times$
faster generation, respectively, when compared to the sequential approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Danieli_F/0/1/0/all/0/1&quot;&gt;Federico Danieli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarabia_M/0/1/0/all/0/1&quot;&gt;Miguel Sarabia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suau_X/0/1/0/all/0/1&quot;&gt;Xavier Suau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1&quot;&gt;Pau Rodr&amp;#xed;guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zappella_L/0/1/0/all/0/1&quot;&gt;Luca Zappella&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16335">
<title>End-to-end Risk Prediction of Atrial Fibrillation from the 12-Lead ECG by Deep Neural Networks. (arXiv:2309.16335v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16335</link>
<description rdf:parseType="Literal">&lt;p&gt;Background: Atrial fibrillation (AF) is one of the most common cardiac
arrhythmias that affects millions of people each year worldwide and it is
closely linked to increased risk of cardiovascular diseases such as stroke and
heart failure. Machine learning methods have shown promising results in
evaluating the risk of developing atrial fibrillation from the
electrocardiogram. We aim to develop and evaluate one such algorithm on a large
CODE dataset collected in Brazil.
&lt;/p&gt;
&lt;p&gt;Results: The deep neural network model identified patients without indication
of AF in the presented ECG but who will develop AF in the future with an AUC
score of 0.845. From our survival model, we obtain that patients in the
high-risk group (i.e. with the probability of a future AF case being greater
than 0.7) are 50% more likely to develop AF within 40 weeks, while patients
belonging to the minimal-risk group (i.e. with the probability of a future AF
case being less than or equal to 0.1) have more than 85% chance of remaining AF
free up until after seven years.
&lt;/p&gt;
&lt;p&gt;Conclusion: We developed and validated a model for AF risk prediction. If
applied in clinical practice, the model possesses the potential of providing
valuable and useful information in decision-making and patient management
processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habineza_T/0/1/0/all/0/1&quot;&gt;Theogene Habineza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Ant&amp;#xf4;nio H. Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gedon_D/0/1/0/all/0/1&quot;&gt;Daniel Gedon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behar_J/0/1/0/all/0/1&quot;&gt;Joachim A. Behar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Antonio Luiz P. Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1&quot;&gt;Thomas B. Sch&amp;#xf6;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16338">
<title>EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew Effect. (arXiv:2309.16338v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16338</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in federated learning (FL) enable collaborative training of
machine learning (ML) models from large-scale and widely dispersed clients
while protecting their privacy. However, when different clients&apos; datasets are
heterogeneous, traditional FL mechanisms produce a global model that does not
adequately represent the poorer clients with limited data resources, resulting
in lower accuracy and higher bias on their local data. According to the Matthew
effect, which describes how the advantaged gain more advantage and the
disadvantaged lose more over time, deploying such a global model in client
applications may worsen the resource disparity among the clients and harm the
principles of social welfare and fairness. To mitigate the Matthew effect, we
propose Egalitarian Fairness Federated Learning (EFFL), where egalitarian
fairness refers to the global model learned from FL has: (1) equal accuracy
among clients; (2) equal decision bias among clients. Besides achieving
egalitarian fairness among the clients, EFFL also aims for performance
optimality, minimizing the empirical risk loss and the bias for each client;
both are essential for any ML model training, whether centralized or
decentralized. We formulate EFFL as a constrained multi-constrained
multi-objectives optimization (MCMOO) problem, with the decision bias and
egalitarian fairness as constraints and the minimization of the empirical risk
losses on all clients as multiple objectives to be optimized. We propose a
gradient-based three-stage algorithm to obtain the Pareto optimal solutions
within the constraint space. Extensive experiments demonstrate that EFFL
outperforms other state-of-the-art FL algorithms in achieving a
high-performance global model with enhanced egalitarian fairness among all
clients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jiashi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Changwu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1&quot;&gt;Ming Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1&quot;&gt;Shin Hwei Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1&quot;&gt;Xin Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1&quot;&gt;Xuetao Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16342">
<title>LagrangeBench: A Lagrangian Fluid Mechanics Benchmarking Suite. (arXiv:2309.16342v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16342</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning has been successfully applied to grid-based PDE modeling in
various scientific applications. However, learned PDE solvers based on
Lagrangian particle discretizations, which are the preferred approach to
problems with free surfaces or complex physics, remain largely unexplored. We
present LagrangeBench, the first benchmarking suite for Lagrangian particle
problems, focusing on temporal coarse-graining. In particular, our contribution
is: (a) seven new fluid mechanics datasets (four in 2D and three in 3D)
generated with the Smoothed Particle Hydrodynamics (SPH) method including the
Taylor-Green vortex, lid-driven cavity, reverse Poiseuille flow, and dam break,
each of which includes different physics like solid wall interactions or free
surface, (b) efficient JAX-based API with various recent training strategies
and neighbors search routine, and (c) JAX implementation of established Graph
Neural Networks (GNNs) like GNS and SEGNN with baseline results. Finally, to
measure the performance of learned surrogates we go beyond established position
errors and introduce physical metrics like kinetic energy MSE and Sinkhorn
distance for the particle distribution. Our codebase is available under the
URL: https://github.com/tumaer/lagrangebench
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toshev_A/0/1/0/all/0/1&quot;&gt;Artur P. Toshev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galletti_G/0/1/0/all/0/1&quot;&gt;Gianluca Galletti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fritz_F/0/1/0/all/0/1&quot;&gt;Fabian Fritz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adami_S/0/1/0/all/0/1&quot;&gt;Stefan Adami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adams_N/0/1/0/all/0/1&quot;&gt;Nikolaus A. Adams&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16347">
<title>Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic Manipulation Tasks. (arXiv:2309.16347v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.16347</link>
<description rdf:parseType="Literal">&lt;p&gt;Current reinforcement learning algorithms struggle in sparse and complex
environments, most notably in long-horizon manipulation tasks entailing a
plethora of different sequences. In this work, we propose the Intrinsically
Guided Exploration from Large Language Models (IGE-LLMs) framework. By
leveraging LLMs as an assistive intrinsic reward, IGE-LLMs guides the
exploratory process in reinforcement learning to address intricate long-horizon
with sparse rewards robotic manipulation tasks. We evaluate our framework and
related intrinsic learning methods in an environment challenged with
exploration, and a complex robotic manipulation task challenged by both
exploration and long-horizons. Results show IGE-LLMs (i) exhibit notably higher
performance over related intrinsic methods and the direct use of LLMs in
decision-making, (ii) can be combined and complement existing learning methods
highlighting its modularity, (iii) are fairly insensitive to different
intrinsic scaling parameters, and (iv) maintain robustness against increased
levels of uncertainty and horizons.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Triantafyllidis_E/0/1/0/all/0/1&quot;&gt;Eleftherios Triantafyllidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1&quot;&gt;Filippos Christianos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhibin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16353">
<title>ShapeDBA: Generating Effective Time Series Prototypes using ShapeDTW Barycenter Averaging. (arXiv:2309.16353v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16353</link>
<description rdf:parseType="Literal">&lt;p&gt;Time series data can be found in almost every domain, ranging from the
medical field to manufacturing and wireless communication. Generating realistic
and useful exemplars and prototypes is a fundamental data analysis task. In
this paper, we investigate a novel approach to generating realistic and useful
exemplars and prototypes for time series data. Our approach uses a new form of
time series average, the ShapeDTW Barycentric Average. We therefore turn our
attention to accurately generating time series prototypes with a novel
approach. The existing time series prototyping approaches rely on the Dynamic
Time Warping (DTW) similarity measure such as DTW Barycentering Average (DBA)
and SoftDBA. These last approaches suffer from a common problem of generating
out-of-distribution artifacts in their prototypes. This is mostly caused by the
DTW variant used and its incapability of detecting neighborhood similarities,
instead it detects absolute similarities. Our proposed method, ShapeDBA, uses
the ShapeDTW variant of DTW, that overcomes this issue. We chose time series
clustering, a popular form of time series analysis to evaluate the outcome of
ShapeDBA compared to the other prototyping approaches. Coupled with the k-means
clustering algorithm, and evaluated on a total of 123 datasets from the UCR
archive, our proposed averaging approach is able to achieve new
state-of-the-art results in terms of Adjusted Rand Index.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ismail_Fawaz_A/0/1/0/all/0/1&quot;&gt;Ali Ismail-Fawaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fawaz_H/0/1/0/all/0/1&quot;&gt;Hassan Ismail Fawaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petitjean_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Petitjean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devanne_M/0/1/0/all/0/1&quot;&gt;Maxime Devanne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_J/0/1/0/all/0/1&quot;&gt;Jonathan Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berretti_S/0/1/0/all/0/1&quot;&gt;Stefano Berretti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1&quot;&gt;Geoffrey I. Webb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forestier_G/0/1/0/all/0/1&quot;&gt;Germain Forestier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16354">
<title>Transformer-VQ: Linear-Time Transformers via Vector Quantization. (arXiv:2309.16354v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16354</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Transformer-VQ, a decoder-only transformer computing
softmax-based dense self-attention in linear time. Transformer-VQ&apos;s efficient
attention is enabled by vector-quantized keys and a novel caching mechanism. In
large-scale experiments, Transformer-VQ is shown highly competitive in quality,
with strong results on Enwik8 (0.99 bpb), PG-19 (26.6 ppl), and ImageNet64
(3.16 bpb). Code: https://github.com/transformer-vq/transformer_vq
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lingle_L/0/1/0/all/0/1&quot;&gt;Lucas D. Lingle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16357">
<title>Leveraging Pre-trained Language Models for Time Interval Prediction in Text-Enhanced Temporal Knowledge Graphs. (arXiv:2309.16357v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16357</link>
<description rdf:parseType="Literal">&lt;p&gt;Most knowledge graph completion (KGC) methods learn latent representations of
entities and relations of a given graph by mapping them into a vector space.
Although the majority of these methods focus on static knowledge graphs, a
large number of publicly available KGs contain temporal information stating the
time instant/period over which a certain fact has been true. Such graphs are
often known as temporal knowledge graphs. Furthermore, knowledge graphs may
also contain textual descriptions of entities and relations. Both temporal
information and textual descriptions are not taken into account during
representation learning by static KGC methods, and only structural information
of the graph is leveraged. Recently, some studies have used temporal
information to improve link prediction, yet they do not exploit textual
descriptions and do not support inductive inference (prediction on entities
that have not been seen in training).
&lt;/p&gt;
&lt;p&gt;We propose a novel framework called TEMT that exploits the power of
pre-trained language models (PLMs) for text-enhanced temporal knowledge graph
completion. The knowledge stored in the parameters of a PLM allows TEMT to
produce rich semantic representations of facts and to generalize on previously
unseen entities. TEMT leverages textual and temporal information available in a
KG, treats them separately, and fuses them to get plausibility scores of facts.
Unlike previous approaches, TEMT effectively captures dependencies across
different time points and enables predictions on unseen entities. To assess the
performance of TEMT, we carried out several experiments including time interval
prediction, both in transductive and inductive settings, and triple
classification. The experimental results show that TEMT is competitive with the
state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islakoglu_D/0/1/0/all/0/1&quot;&gt;Duygu Sezen Islakoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chekol_M/0/1/0/all/0/1&quot;&gt;Mel Chekol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velegrakis_Y/0/1/0/all/0/1&quot;&gt;Yannis Velegrakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16369">
<title>Bringing the Discussion of Minima Sharpness to the Audio Domain: a Filter-Normalised Evaluation for Acoustic Scene Classification. (arXiv:2309.16369v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.16369</link>
<description rdf:parseType="Literal">&lt;p&gt;The correlation between the sharpness of loss minima and generalisation in
the context of deep neural networks has been subject to discussion for a long
time. Whilst mostly investigated in the context of selected benchmark data sets
in the area of computer vision, we explore this aspect for the audio scene
classification task of the DCASE2020 challenge data. Our analysis is based on
twodimensional filter-normalised visualisations and a derived sharpness
measure. Our exploratory analysis shows that sharper minima tend to show better
generalisation than flat minima -even more so for out-of-domain data, recorded
from previously unseen devices-, thus adding to the dispute about better
generalisation capabilities of flat minima. We further find that, in
particular, the choice of optimisers is a main driver of the sharpness of
minima and we discuss resulting limitations with respect to comparability. Our
code, trained model states and loss landscape visualisations are publicly
available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milling_M/0/1/0/all/0/1&quot;&gt;Manuel Milling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Triantafyllopoulos_A/0/1/0/all/0/1&quot;&gt;Andreas Triantafyllopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsangko_I/0/1/0/all/0/1&quot;&gt;Iosif Tsangko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rampp_S/0/1/0/all/0/1&quot;&gt;Simon David Noel Rampp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn Wolfgang Schuller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16374">
<title>MHG-GNN: Combination of Molecular Hypergraph Grammar with Graph Neural Network. (arXiv:2309.16374v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16374</link>
<description rdf:parseType="Literal">&lt;p&gt;Property prediction plays an important role in material discovery. As an
initial step to eventually develop a foundation model for material science, we
introduce a new autoencoder called the MHG-GNN, which combines graph neural
network (GNN) with Molecular Hypergraph Grammar (MHG). Results on a variety of
property prediction tasks with diverse materials show that MHG-GNN is
promising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kishimoto_A/0/1/0/all/0/1&quot;&gt;Akihiro Kishimoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kajino_H/0/1/0/all/0/1&quot;&gt;Hiroshi Kajino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hirose_M/0/1/0/all/0/1&quot;&gt;Masataka Hirose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuchiwaki_J/0/1/0/all/0/1&quot;&gt;Junta Fuchiwaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Priyadarsini_I/0/1/0/all/0/1&quot;&gt;Indra Priyadarsini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamada_L/0/1/0/all/0/1&quot;&gt;Lisa Hamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shinohara_H/0/1/0/all/0/1&quot;&gt;Hajime Shinohara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakano_D/0/1/0/all/0/1&quot;&gt;Daiju Nakano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takeda_S/0/1/0/all/0/1&quot;&gt;Seiji Takeda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16382">
<title>RLLTE: Long-Term Evolution Project of Reinforcement Learning. (arXiv:2309.16382v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.16382</link>
<description rdf:parseType="Literal">&lt;p&gt;We present RLLTE: a long-term evolution, extremely modular, and open-source
framework for reinforcement learning (RL) research and application. Beyond
delivering top-notch algorithm implementations, RLLTE also serves as a toolkit
for developing algorithms. More specifically, RLLTE decouples the RL algorithms
completely from the exploitation-exploration perspective, providing a large
number of components to accelerate algorithm development and evolution. In
particular, RLLTE is the first RL framework to build a complete and luxuriant
ecosystem, which includes model training, evaluation, deployment, benchmark
hub, and large language model (LLM)-empowered copilot. RLLTE is expected to set
standards for RL engineering practice and be highly stimulative for industry
and academia.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1&quot;&gt;Mingqi Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zequn Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1&quot;&gt;Shihao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1&quot;&gt;Xin Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1&quot;&gt;Wenjun Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16384">
<title>Multi-Swap $k$-Means++. (arXiv:2309.16384v1 [cs.CG])</title>
<link>http://arxiv.org/abs/2309.16384</link>
<description rdf:parseType="Literal">&lt;p&gt;The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often
the practitioners&apos; choice algorithm for optimizing the popular $k$-means
clustering objective and is known to give an $O(\log k)$-approximation in
expectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML
2019) proposed augmenting $k$-means++ with $O(k \log \log k)$ local search
steps obtained through the $k$-means++ sampling distribution to yield a
$c$-approximation to the $k$-means clustering problem, where $c$ is a large
absolute constant. Here we generalize and extend their local search algorithm
by considering larger and more sophisticated local search neighborhoods hence
allowing to swap multiple centers at the same time. Our algorithm achieves a $9
+ \varepsilon$ approximation ratio, which is the best possible for local
search. Importantly we show that our approach yields substantial practical
improvements, we show significant quality improvements over the approach of
Lattanzi and Sohler (ICML 2019) on several datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beretta_L/0/1/0/all/0/1&quot;&gt;Lorenzo Beretta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1&quot;&gt;Vincent Cohen-Addad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1&quot;&gt;Silvio Lattanzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parotsidis_N/0/1/0/all/0/1&quot;&gt;Nikos Parotsidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16391">
<title>Differential 2D Copula Approximating Transforms via Sobolev Training: 2-Cats Networks. (arXiv:2309.16391v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16391</link>
<description rdf:parseType="Literal">&lt;p&gt;Copulas are a powerful statistical tool that captures dependencies across
data dimensions. When applying Copulas, we can estimate multivariate
distribution functions by initially estimating independent marginals, an easy
task, and then a single copulating function, $C$, to connect the marginals, a
hard task. For two-dimensional data, a copula is a two-increasing function of
the form $C: (u,v)\in \mathbf{I}^2 \rightarrow \mathbf{I}$, where $\mathbf{I} =
[0, 1]$. In this paper, we show how Neural Networks (NNs) can approximate any
two-dimensional copula non-parametrically. Our approach, denoted as 2-Cats, is
inspired by the Physics-Informed Neural Networks and Sobolev Training
literature. Not only do we show that we can estimate the output of a 2d Copula
better than the state-of-the-art, our approach is non-parametric and respects
the mathematical properties of a Copula $C$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Figueiredo_F/0/1/0/all/0/1&quot;&gt;Flavio Figueiredo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandes_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Geraldo Fernandes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1&quot;&gt;Jackson Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assuncao_R/0/1/0/all/0/1&quot;&gt;Renato M. Assun&amp;#xe7;&amp;#xe3;o&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16397">
<title>Uncertainty-Aware Decision Transformer for Stochastic Driving Environments. (arXiv:2309.16397v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16397</link>
<description rdf:parseType="Literal">&lt;p&gt;Offline Reinforcement Learning (RL) has emerged as a promising framework for
learning policies without active interactions, making it especially appealing
for autonomous driving tasks. Recent successes of Transformers inspire casting
offline RL as sequence modeling, which performs well in long-horizon tasks.
However, they are overly optimistic in stochastic environments with incorrect
assumptions that the same goal can be consistently achieved by identical
actions. In this paper, we introduce an UNcertainty-awaRE deciSion Transformer
(UNREST) for planning in stochastic driving environments without introducing
additional transition or complex generative models. Specifically, UNREST
estimates state uncertainties by the conditional mutual information between
transitions and returns, and segments sequences accordingly. Discovering the
`uncertainty accumulation&apos; and `temporal locality&apos; properties of driving
environments, UNREST replaces the global returns in decision transformers with
less uncertain truncated returns, to learn from true outcomes of agent actions
rather than environment transitions. We also dynamically evaluate environmental
uncertainty during inference for cautious planning. Extensive experimental
results demonstrate UNREST&apos;s superior performance in various driving scenarios
and the power of our uncertainty estimation strategy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zenan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_F/0/1/0/all/0/1&quot;&gt;Fan Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Qiao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Da_F/0/1/0/all/0/1&quot;&gt;Fang Da&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Hang Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16398">
<title>Recent Advances of Differential Privacy in Centralized Deep Learning: A Systematic Survey. (arXiv:2309.16398v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16398</link>
<description rdf:parseType="Literal">&lt;p&gt;Differential Privacy has become a widely popular method for data protection
in machine learning, especially since it allows formulating strict mathematical
privacy guarantees. This survey provides an overview of the state-of-the-art of
differentially private centralized deep learning, thorough analyses of recent
advances and open problems, as well as a discussion of potential future
developments in the field. Based on a systematic literature review, the
following topics are addressed: auditing and evaluation methods for private
models, improvements of privacy-utility trade-offs, protection against a broad
range of threats and attacks, differentially private generative models, and
emerging application domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demelius_L/0/1/0/all/0/1&quot;&gt;Lea Demelius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kern_R/0/1/0/all/0/1&quot;&gt;Roman Kern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trugler_A/0/1/0/all/0/1&quot;&gt;Andreas Tr&amp;#xfc;gler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16401">
<title>VAE-based latent-space classification of RNO-G data. (arXiv:2309.16401v1 [astro-ph.HE])</title>
<link>http://arxiv.org/abs/2309.16401</link>
<description rdf:parseType="Literal">&lt;p&gt;The Radio Neutrino Observatory in Greenland (RNO-G) is a radio-based
ultra-high energy neutrino detector located at Summit Station, Greenland. It is
still being constructed, with 7 stations currently operational. Neutrino
detection works by measuring Askaryan radiation produced by neutrino-nucleon
interactions. A neutrino candidate must be found amidst other backgrounds which
are recorded at much higher rates -- including cosmic-rays and anthropogenic
noise -- the origins of which are sometimes unknown. Here we describe a method
to classify different noise classes using the latent space of a variational
autoencoder. The latent space forms a compact representation that makes
classification tractable. We analyze data from a noisy and a silent station.
The method automatically detects and allows us to qualitatively separate
multiple event classes, including physical wind-induced signals, for both the
noisy and the quiet station.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Glusenkamp_T/0/1/0/all/0/1&quot;&gt;Thorsten Gl&amp;#xfc;senkamp&lt;/a&gt; (for the RNO-G collaboration)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16409">
<title>Constructing Synthetic Treatment Groups without the Mean Exchangeability Assumption. (arXiv:2309.16409v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16409</link>
<description rdf:parseType="Literal">&lt;p&gt;The purpose of this work is to transport the information from multiple
randomized controlled trials to the target population where we only have the
control group data. Previous works rely critically on the mean exchangeability
assumption. However, as pointed out by many current studies, the mean
exchangeability assumption might be violated. Motivated by the synthetic
control method, we construct a synthetic treatment group for the target
population by a weighted mixture of treatment groups of source populations. We
estimate the weights by minimizing the conditional maximum mean discrepancy
between the weighted control groups of source populations and the target
population. We establish the asymptotic normality of the synthetic treatment
group estimator based on the sieve semiparametric theory. Our method can serve
as a novel complementary approach when the mean exchangeability assumption is
violated. Experiments are conducted on synthetic and real-world datasets to
demonstrate the effectiveness of our methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuhang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhihua Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16412">
<title>Selective Nonparametric Regression via Testing. (arXiv:2309.16412v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16412</link>
<description rdf:parseType="Literal">&lt;p&gt;Prediction with the possibility of abstention (or selective prediction) is an
important problem for error-critical machine learning applications. While
well-studied in the classification setup, selective approaches to regression
are much less developed. In this work, we consider the nonparametric
heteroskedastic regression problem and develop an abstention procedure via
testing the hypothesis on the value of the conditional variance at a given
point. Unlike existing methods, the proposed one allows to account not only for
the value of the variance itself but also for the uncertainty of the
corresponding variance predictor. We prove non-asymptotic bounds on the risk of
the resulting estimator and show the existence of several different convergence
regimes. Theoretical analysis is illustrated with a series of experiments on
simulated and real-world data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Noskov_F/0/1/0/all/0/1&quot;&gt;Fedor Noskov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fishkov_A/0/1/0/all/0/1&quot;&gt;Alexander Fishkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1&quot;&gt;Maxim Panov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16414">
<title>AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models. (arXiv:2309.16414v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16414</link>
<description rdf:parseType="Literal">&lt;p&gt;Classifiers built upon vision-language models such as CLIP have shown
remarkable zero-shot performance across a broad range of image classification
tasks. Prior work has studied different ways of automatically creating
descriptor sets for every class based on prompt templates, ranging from
manually engineered templates over templates obtained from a large language
model to templates built from random words and characters. In contrast,
deriving zero-shot classifiers from the respective encoded class descriptors
has remained nearly unchanged, that is: classify to the class that maximizes
the cosine similarity between its averaged encoded class descriptors and the
encoded image. However, weighting all class descriptors equally can be
suboptimal when certain descriptors match visual clues on a given image better
than others. In this work, we propose AutoCLIP, a method for auto-tuning
zero-shot classifiers. AutoCLIP assigns to each prompt template per-image
weights, which are derived from statistics of class descriptor-image
similarities at inference time. AutoCLIP is fully unsupervised, has very low
overhead, and can be easily implemented in few lines of code. We show that for
a broad range of vision-language models, datasets, and prompt templates,
AutoCLIP outperforms baselines consistently and by up to 3 percent point
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metzen_J/0/1/0/all/0/1&quot;&gt;Jan Hendrik Metzen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saranrittichai_P/0/1/0/all/0/1&quot;&gt;Piyapat Saranrittichai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mummadi_C/0/1/0/all/0/1&quot;&gt;Chaithanya Kumar Mummadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16428">
<title>Nonlinear MPC design for incrementally ISS systems with application to GRU networks. (arXiv:2309.16428v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2309.16428</link>
<description rdf:parseType="Literal">&lt;p&gt;This brief addresses the design of a Nonlinear Model Predictive Control
(NMPC) strategy for exponentially incremental Input-to-State Stable (ISS)
systems. In particular, a novel formulation is devised, which does not
necessitate the onerous computation of terminal ingredients, but rather relies
on the explicit definition of a minimum prediction horizon ensuring closed-loop
stability. The designed methodology is particularly suited for the control of
systems learned by Recurrent Neural Networks (RNNs), which are known for their
enhanced modeling capabilities and for which the incremental ISS properties can
be studied thanks to simple algebraic conditions. The approach is applied to
Gated Recurrent Unit (GRU) networks, providing also a method for the design of
a tailored state observer with convergence guarantees. The resulting control
architecture is tested on a benchmark system, demonstrating its good control
performances and efficient applicability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bonassi_F/0/1/0/all/0/1&quot;&gt;Fabio Bonassi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bella_A/0/1/0/all/0/1&quot;&gt;Alessio La Bella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Farina_M/0/1/0/all/0/1&quot;&gt;Marcello Farina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Scattolini_R/0/1/0/all/0/1&quot;&gt;Riccardo Scattolini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16429">
<title>Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model Adaptation. (arXiv:2309.16429v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16429</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the task of generating diverse and realistic videos guided by
natural audio samples from a wide variety of semantic classes. For this task,
the videos are required to be aligned both globally and temporally with the
input audio: globally, the input audio is semantically associated with the
entire output video, and temporally, each segment of the input audio is
associated with a corresponding segment of that video. We utilize an existing
text-conditioned video generation model and a pre-trained audio encoder model.
The proposed method is based on a lightweight adaptor network, which learns to
map the audio-based representation to the input representation expected by the
text-to-video generation model. As such, it also enables video generation
conditioned on text, audio, and, for the first time as far as we can ascertain,
on both text and audio. We validate our method extensively on three datasets
demonstrating significant semantic diversity of audio-video samples and further
propose a novel evaluation metric (AV-Align) to assess the alignment of
generated videos with input audio samples. AV-Align is based on the detection
and comparison of energy peaks in both modalities. In comparison to recent
state-of-the-art approaches, our method generates videos that are better
aligned with the input sound, both with respect to content and temporal axis.
We also show that videos produced by our method present higher visual quality
and are more diverse.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yariv_G/0/1/0/all/0/1&quot;&gt;Guy Yariv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1&quot;&gt;Itai Gat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benaim_S/0/1/0/all/0/1&quot;&gt;Sagie Benaim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1&quot;&gt;Lior Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_I/0/1/0/all/0/1&quot;&gt;Idan Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1&quot;&gt;Yossi Adi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16448">
<title>A parsimonious, computationally efficient machine learning method for spatial regression. (arXiv:2309.16448v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16448</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the modified planar rotator method (MPRS), a physically inspired
machine learning method for spatial/temporal regression. MPRS is a
non-parametric model which incorporates spatial or temporal correlations via
short-range, distance-dependent ``interactions&apos;&apos; without assuming a specific
form for the underlying probability distribution. Predictions are obtained by
means of a fully autonomous learning algorithm which employs equilibrium
conditional Monte Carlo simulations. MPRS is able to handle scattered data and
arbitrary spatial dimensions. We report tests on various synthetic and
real-word data in one, two and three dimensions which demonstrate that the MPRS
prediction performance (without parameter tuning) is competitive with standard
interpolation methods such as ordinary kriging and inverse distance weighting.
In particular, MPRS is a particularly effective gap-filling method for rough
and non-Gaussian data (e.g., daily precipitation time series). MPRS shows
superior computational efficiency and scalability for large samples. Massive
data sets involving millions of nodes can be processed in a few seconds on a
standard personal computer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zukovic_M/0/1/0/all/0/1&quot;&gt;Milan &amp;#x17d;ukovi&amp;#x10d;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hristopulos_D/0/1/0/all/0/1&quot;&gt;Dionissios T. Hristopulos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16452">
<title>On the Trade-offs between Adversarial Robustness and Actionable Explanations. (arXiv:2309.16452v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16452</link>
<description rdf:parseType="Literal">&lt;p&gt;As machine learning models are increasingly being employed in various
high-stakes settings, it becomes important to ensure that predictions of these
models are not only adversarially robust, but also readily explainable to
relevant stakeholders. However, it is unclear if these two notions can be
simultaneously achieved or if there exist trade-offs between them. In this
work, we make one of the first attempts at studying the impact of adversarially
robust models on actionable explanations which provide end users with a means
for recourse. We theoretically and empirically analyze the cost (ease of
implementation) and validity (probability of obtaining a positive model
prediction) of recourses output by state-of-the-art algorithms when the
underlying models are adversarially robust vs. non-robust. More specifically,
we derive theoretical bounds on the differences between the cost and the
validity of the recourses generated by state-of-the-art algorithms for
adversarially robust vs. non-robust linear and non-linear models. Our empirical
results with multiple real-world datasets validate our theoretical results and
show the impact of varying degrees of model robustness on the cost and validity
of the resulting recourses. Our analyses demonstrate that adversarially robust
models significantly increase the cost and reduce the validity of the resulting
recourses, thus shedding light on the inherent trade-offs between adversarial
robustness and actionable explanations
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1&quot;&gt;Satyapriya Krishna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1&quot;&gt;Chirag Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1&quot;&gt;Himabindu Lakkaraju&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16456">
<title>Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective. (arXiv:2309.16456v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16456</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing approaches defend against backdoor attacks in federated learning
(FL) mainly through a) mitigating the impact of infected models, or b)
excluding infected models. The former negatively impacts model accuracy, while
the latter usually relies on globally clear boundaries between benign and
infected model updates. However, model updates are easy to be mixed and
scattered throughout in reality due to the diverse distributions of local data.
This work focuses on excluding infected models in FL. Unlike previous
perspectives from a global view, we propose Snowball, a novel anti-backdoor FL
framework through bidirectional elections from an individual perspective
inspired by one principle deduced by us and two principles in FL and deep
learning. It is characterized by a) bottom-up election, where each candidate
model update votes to several peer ones such that a few model updates are
elected as selectees for aggregation; and b) top-down election, where selectees
progressively enlarge themselves through picking up from the candidates. We
compare Snowball with state-of-the-art defenses to backdoor attacks in FL on
five real-world datasets, demonstrating its superior resistance to backdoor
attacks and slight impact on the accuracy of the global model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1&quot;&gt;Zhen Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1&quot;&gt;Feiyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhi_C/0/1/0/all/0/1&quot;&gt;Chen Zhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1&quot;&gt;Xueqiang Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1&quot;&gt;Shuiguang Deng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16457">
<title>Universal Sleep Decoder: Aligning awake and sleep neural representation across subjects. (arXiv:2309.16457v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16457</link>
<description rdf:parseType="Literal">&lt;p&gt;Decoding memory content from brain activity during sleep has long been a goal
in neuroscience. While spontaneous reactivation of memories during sleep in
rodents is known to support memory consolidation and offline learning,
capturing memory replay in humans is challenging due to the absence of
well-annotated sleep datasets and the substantial differences in neural
patterns between wakefulness and sleep. To address these challenges, we
designed a novel cognitive neuroscience experiment and collected a
comprehensive, well-annotated electroencephalography (EEG) dataset from 52
subjects during both wakefulness and sleep. Leveraging this benchmark dataset,
we developed the Universal Sleep Decoder (USD) to align neural representations
between wakefulness and sleep across subjects. Our model achieves up to 16.6%
top-1 zero-shot accuracy on unseen subjects, comparable to decoding
performances using individual sleep data. Furthermore, fine-tuning USD on test
subjects enhances decoding accuracy to 25.9% top-1 accuracy, a substantial
improvement over the baseline chance of 6.7%. Model comparison and ablation
analyses reveal that our design choices, including the use of (i) an additional
contrastive objective to integrate awake and sleep neural signals and (ii) the
pretrain-finetune paradigm to incorporate different subjects, significantly
contribute to these performances. Collectively, our findings and methodologies
represent a significant advancement in the field of sleep decoding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1&quot;&gt;Hui Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhongtao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haiteng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jianyang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Lin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yunzhe Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16459">
<title>Augmenting LLMs with Knowledge: A survey on hallucination prevention. (arXiv:2309.16459v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.16459</link>
<description rdf:parseType="Literal">&lt;p&gt;Large pre-trained language models have demonstrated their proficiency in
storing factual knowledge within their parameters and achieving remarkable
results when fine-tuned for downstream natural language processing tasks.
Nonetheless, their capacity to access and manipulate knowledge with precision
remains constrained, resulting in performance disparities on
knowledge-intensive tasks when compared to task-specific architectures.
Additionally, the challenges of providing provenance for model decisions and
maintaining up-to-date world knowledge persist as open research frontiers. To
address these limitations, the integration of pre-trained models with
differentiable access mechanisms to explicit non-parametric memory emerges as a
promising solution. This survey delves into the realm of language models (LMs)
augmented with the ability to tap into external knowledge sources, including
external knowledge bases and search engines. While adhering to the standard
objective of predicting missing tokens, these augmented LMs leverage diverse,
possibly non-parametric external modules to augment their contextual processing
capabilities, departing from the conventional language modeling paradigm.
Through an exploration of current advancements in augmenting large language
models with knowledge, this work concludes that this emerging research
direction holds the potential to address prevalent issues in traditional LMs,
such as hallucinations, un-grounded responses, and scalability challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andriopoulos_K/0/1/0/all/0/1&quot;&gt;Konstantinos Andriopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pouwelse_J/0/1/0/all/0/1&quot;&gt;Johan Pouwelse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16465">
<title>A Metaheuristic for Amortized Search in High-Dimensional Parameter Spaces. (arXiv:2309.16465v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/2309.16465</link>
<description rdf:parseType="Literal">&lt;p&gt;Parameter inference for dynamical models of (bio)physical systems remains a
challenging problem. Intractable gradients, high-dimensional spaces, and
non-linear model functions are typically problematic without large
computational budgets. A recent body of work in that area has focused on
Bayesian inference methods, which consider parameters under their statistical
distributions and therefore, do not derive point estimates of optimal parameter
values. Here we propose a new metaheuristic that drives dimensionality
reductions from feature-informed transformations (DR-FFIT) to address these
bottlenecks. DR-FFIT implements an efficient sampling strategy that facilitates
a gradient-free parameter search in high-dimensional spaces. We use artificial
neural networks to obtain differentiable proxies for the model&apos;s features of
interest. The resulting gradients enable the estimation of a local active
subspace of the model within a defined sampling region. This approach enables
efficient dimensionality reductions of highly non-linear search spaces at a low
computational cost. Our test data show that DR-FFIT boosts the performances of
random-search and simulated-annealing against well-established metaheuristics,
and improves the goodness-of-fit of the model, all within contained run-time
costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Boutet_D/0/1/0/all/0/1&quot;&gt;Dominic Boutet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Baillet_S/0/1/0/all/0/1&quot;&gt;Sylvain Baillet&lt;/a&gt; (Montreal Neurological Institute, McGill University, Montreal QC, Canada)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16467">
<title>Compositional Program Generation for Systematic Generalization. (arXiv:2309.16467v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16467</link>
<description rdf:parseType="Literal">&lt;p&gt;Compositional generalization is a key ability of humans that enables us to
learn new concepts from only a handful examples. Machine learning models,
including the now ubiquitous transformers, struggle to generalize in this way,
and typically require thousands of examples of a concept during training in
order to generalize meaningfully. This difference in ability between humans and
artificial neural architectures, motivates this study on a neuro-symbolic
architecture called the Compositional Program Generator (CPG). CPG has three
key features: modularity, type abstraction, and recursive composition, that
enable it to generalize both systematically to new concepts in a few-shot
manner, as well as productively by length on various sequence-to-sequence
language tasks. For each input, CPG uses a grammar of the input domain and a
parser to generate a type hierarchy in which each grammar rule is assigned its
own unique semantic module, a probabilistic copy or substitution program.
Instances with the same hierarchy are processed with the same composed program,
while those with different hierarchies may be processed with different
programs. CPG learns parameters for the semantic modules and is able to learn
the semantics for new types incrementally. Given a context-free grammar of the
input language and a dictionary mapping each word in the source language to its
interpretation in the output language, CPG can achieve perfect generalization
on the SCAN and COGS benchmarks, in both standard and extreme few-shot
settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klinger_T/0/1/0/all/0/1&quot;&gt;Tim Klinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Luke Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1&quot;&gt;Soham Dan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crouse_M/0/1/0/all/0/1&quot;&gt;Maxwell Crouse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1&quot;&gt;Parikshit Ram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gray_A/0/1/0/all/0/1&quot;&gt;Alexander Gray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16476">
<title>High-dimensional robust regression under heavy-tailed data: Asymptotics and Universality. (arXiv:2309.16476v1 [math.ST])</title>
<link>http://arxiv.org/abs/2309.16476</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the high-dimensional properties of robust regression
estimators in the presence of heavy-tailed contamination of both the covariates
and response functions. In particular, we provide a sharp asymptotic
characterisation of M-estimators trained on a family of elliptical covariate
and noise data distributions including cases where second and higher moments do
not exist. We show that, despite being consistent, the Huber loss with
optimally tuned location parameter $\delta$ is suboptimal in the
high-dimensional regime in the presence of heavy-tailed noise, highlighting the
necessity of further regularisation to achieve optimal performance. This result
also uncovers the existence of a curious transition in $\delta$ as a function
of the sample complexity and contamination. Moreover, we derive the decay rates
for the excess risk of ridge regression. We show that, while it is both optimal
and universal for noise distributions with finite second moment, its decay rate
can be considerably faster when the covariates&apos; second moment does not exist.
Finally, we show that our formulas readily generalise to a richer family of
models and data distributions, such as generalised linear estimation with
arbitrary convex regularisation trained on mixture models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Adomaityte_U/0/1/0/all/0/1&quot;&gt;Urte Adomaityte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Defilippis_L/0/1/0/all/0/1&quot;&gt;Leonardo Defilippis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Loureiro_B/0/1/0/all/0/1&quot;&gt;Bruno Loureiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sicuro_G/0/1/0/all/0/1&quot;&gt;Gabriele Sicuro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16487">
<title>Towards Poisoning Fair Representations. (arXiv:2309.16487v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16487</link>
<description rdf:parseType="Literal">&lt;p&gt;Fair machine learning seeks to mitigate model prediction bias against certain
demographic subgroups such as elder and female. Recently, fair representation
learning (FRL) trained by deep neural networks has demonstrated superior
performance, whereby representations containing no demographic information are
inferred from the data and then used as the input to classification or other
downstream tasks. Despite the development of FRL methods, their vulnerability
under data poisoning attack, a popular protocol to benchmark model robustness
under adversarial scenarios, is under-explored. Data poisoning attacks have
been developed for classical fair machine learning methods which incorporate
fairness constraints into shallow-model classifiers. Nonetheless, these attacks
fall short in FRL due to notably different fairness goals and model
architectures. This work proposes the first data poisoning framework attacking
FRL. We induce the model to output unfair representations that contain as much
demographic information as possible by injecting carefully crafted poisoning
samples into the training data. This attack entails a prohibitive bilevel
optimization, wherefore an effective approximated solution is proposed. A
theoretical analysis on the needed number of poisoning samples is derived and
sheds light on defending against the attack. Experiments on benchmark fairness
datasets and state-of-the-art fair representation learning models demonstrate
the superiority of our attack.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tianci Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haoyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Feijie Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hengtong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Pan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1&quot;&gt;Lu Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jing Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16495">
<title>Deep Single Models vs. Ensembles: Insights for a Fast Deployment of Parking Monitoring Systems. (arXiv:2309.16495v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16495</link>
<description rdf:parseType="Literal">&lt;p&gt;Searching for available parking spots in high-density urban centers is a
stressful task for drivers that can be mitigated by systems that know in
advance the nearest parking space available.
&lt;/p&gt;
&lt;p&gt;To this end, image-based systems offer cost advantages over other
sensor-based alternatives (e.g., ultrasonic sensors), requiring less physical
infrastructure for installation and maintenance.
&lt;/p&gt;
&lt;p&gt;Despite recent deep learning advances, deploying intelligent parking
monitoring is still a challenge since most approaches involve collecting and
labeling large amounts of data, which is laborious and time-consuming. Our
study aims to uncover the challenges in creating a global framework, trained
using publicly available labeled parking lot images, that performs accurately
across diverse scenarios, enabling the parking space monitoring as a
ready-to-use system to deploy in a new environment. Through exhaustive
experiments involving different datasets and deep learning architectures,
including fusion strategies and ensemble methods, we found that models trained
on diverse datasets can achieve 95\% accuracy without the burden of data
annotation and model training on the target parking lot
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hochuli_A/0/1/0/all/0/1&quot;&gt;Andre Gustavo Hochuli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barddal_J/0/1/0/all/0/1&quot;&gt;Jean Paul Barddal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palhano_G/0/1/0/all/0/1&quot;&gt;Gillian Cezar Palhano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendes_L/0/1/0/all/0/1&quot;&gt;Leonardo Matheus Mendes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Almeida_P/0/1/0/all/0/1&quot;&gt;Paulo Ricardo Lisboa de Almeida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16512">
<title>From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford&apos;s Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16512</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a novel analysis of neural networks based on
geometric (Clifford) algebra and convex optimization. We show that optimal
weights of deep ReLU neural networks are given by the wedge product of training
samples when trained with standard regularized loss. Furthermore, the training
problem reduces to convex optimization over wedge product features, which
encode the geometric structure of the training dataset. This structure is given
in terms of signed volumes of triangles and parallelotopes generated by data
vectors. The convex problem finds a small subset of samples via $\ell_1$
regularization to discover only relevant wedge product features. Our analysis
provides a novel perspective on the inner workings of deep neural networks and
sheds light on the role of the hidden layers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1&quot;&gt;Mert Pilanci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16519">
<title>AtomSurf : Surface Representation for Learning on Protein Structures. (arXiv:2309.16519v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16519</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advancements in Cryo-EM and protein structure prediction algorithms
have made large-scale protein structures accessible, paving the way for machine
learning-based functional annotations.The field of geometric deep learning
focuses on creating methods working on geometric data. An essential aspect of
learning from protein structures is representing these structures as a
geometric object (be it a grid, graph, or surface) and applying a learning
method tailored to this representation. The performance of a given approach
will then depend on both the representation and its corresponding learning
method.
&lt;/p&gt;
&lt;p&gt;In this paper, we investigate representing proteins as $\textit{3D mesh
surfaces}$ and incorporate them into an established representation benchmark.
Our first finding is that despite promising preliminary results, the surface
representation alone does not seem competitive with 3D grids. Building on this,
we introduce a synergistic approach, combining surface representations with
graph-based methods, resulting in a general framework that incorporates both
representations in learning. We show that using this combination, we are able
to obtain state-of-the-art results across $\textit{all tested tasks}$. Our code
and data can be found online: https://github.com/Vincentx15/atom2D .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mallet_V/0/1/0/all/0/1&quot;&gt;Vincent Mallet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Attaiki_S/0/1/0/all/0/1&quot;&gt;Souhaib Attaiki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ovsjanikov_M/0/1/0/all/0/1&quot;&gt;Maks Ovsjanikov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16521">
<title>Generating Personalized Insulin Treatments Strategies with Deep Conditional Generative Time Series Models. (arXiv:2309.16521v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16521</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel framework that combines deep generative time series models
with decision theory for generating personalized treatment strategies. It
leverages historical patient trajectory data to jointly learn the generation of
realistic personalized treatment and future outcome trajectories through deep
generative time series models. In particular, our framework enables the
generation of novel multivariate treatment strategies tailored to the
personalized patient history and trained for optimal expected future outcomes
based on conditional expected utility maximization. We demonstrate our
framework by generating personalized insulin treatment strategies and blood
glucose predictions for hospitalized diabetes patients, showcasing the
potential of our approach for generating improved personalized treatment
strategies. Keywords: deep generative model, probabilistic decision support,
personalized treatment generation, insulin and blood glucose prediction
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schurch_M/0/1/0/all/0/1&quot;&gt;Manuel Sch&amp;#xfc;rch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Allam_A/0/1/0/all/0/1&quot;&gt;Ahmed Allam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rathmes_G/0/1/0/all/0/1&quot;&gt;Giulia Rathmes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mollaysa_A/0/1/0/all/0/1&quot;&gt;Amina Mollaysa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cavelti_Weder_C/0/1/0/all/0/1&quot;&gt;Claudia Cavelti-Weder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krauthammer_M/0/1/0/all/0/1&quot;&gt;Michael Krauthammer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16534">
<title>MotionLM: Multi-Agent Motion Forecasting as Language Modeling. (arXiv:2309.16534v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16534</link>
<description rdf:parseType="Literal">&lt;p&gt;Reliable forecasting of the future behavior of road agents is a critical
component to safe planning in autonomous vehicles. Here, we represent
continuous trajectories as sequences of discrete motion tokens and cast
multi-agent motion prediction as a language modeling task over this domain. Our
model, MotionLM, provides several advantages: First, it does not require
anchors or explicit latent variable optimization to learn multimodal
distributions. Instead, we leverage a single standard language modeling
objective, maximizing the average log probability over sequence tokens. Second,
our approach bypasses post-hoc interaction heuristics where individual agent
trajectory generation is conducted prior to interactive scoring. Instead,
MotionLM produces joint distributions over interactive agent futures in a
single autoregressive decoding process. In addition, the model&apos;s sequential
factorization enables temporally causal conditional rollouts. The proposed
approach establishes new state-of-the-art performance for multi-agent motion
prediction on the Waymo Open Motion Dataset, ranking 1st on the interactive
challenge leaderboard.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seff_A/0/1/0/all/0/1&quot;&gt;Ari Seff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cera_B/0/1/0/all/0/1&quot;&gt;Brian Cera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Dian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ng_M/0/1/0/all/0/1&quot;&gt;Mason Ng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Aurick Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nayakanti_N/0/1/0/all/0/1&quot;&gt;Nigamaa Nayakanti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Refaat_K/0/1/0/all/0/1&quot;&gt;Khaled S. Refaat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Rfou_R/0/1/0/all/0/1&quot;&gt;Rami Al-Rfou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sapp_B/0/1/0/all/0/1&quot;&gt;Benjamin Sapp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16536">
<title>Uncertainty Quantification for Eosinophil Segmentation. (arXiv:2309.16536v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.16536</link>
<description rdf:parseType="Literal">&lt;p&gt;Eosinophilic Esophagitis (EoE) is an allergic condition increasing in
prevalence. To diagnose EoE, pathologists must find 15 or more eosinophils
within a single high-power field (400X magnification). Determining whether or
not a patient has EoE can be an arduous process and any medical imaging
approaches used to assist diagnosis must consider both efficiency and
precision. We propose an improvement of Adorno et al&apos;s approach for quantifying
eosinphils using deep image segmentation. Our new approach leverages Monte
Carlo Dropout, a common approach in deep learning to reduce overfitting, to
provide uncertainty quantification on current deep learning models. The
uncertainty can be visualized in an output image to evaluate model performance,
provide insight to how deep learning algorithms function, and assist
pathologists in identifying eosinophils.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lin_K/0/1/0/all/0/1&quot;&gt;Kevin Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Donald Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Syed_S/0/1/0/all/0/1&quot;&gt;Sana Syed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Greene_A/0/1/0/all/0/1&quot;&gt;Adam Greene&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16540">
<title>Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.16540</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised fact verification aims to verify a claim using evidence from a
trustworthy knowledge base without any kind of data annotation. To address this
challenge, algorithms must produce features for every claim that are both
semantically meaningful, and compact enough to find a semantic alignment with
the source information. In contrast to previous work, which tackled the
alignment problem by learning over annotated corpora of claims and their
corresponding labels, we propose SFAVEL (Self-supervised Fact Verification via
Language Model Distillation), a novel unsupervised framework that leverages
pre-trained language models to distil self-supervised features into
high-quality claim-fact alignments without the need for annotations. This is
enabled by a novel contrastive loss function that encourages features to attain
high-quality claim and evidence alignments whilst preserving the semantic
relationships across the corpora. Notably, we present results that achieve a
new state-of-the-art on the standard FEVER fact verification benchmark (+8%
accuracy) with linear evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bazaga_A/0/1/0/all/0/1&quot;&gt;Adri&amp;#xe1;n Bazaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1&quot;&gt;Pietro Li&amp;#xf2;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Micklem_G/0/1/0/all/0/1&quot;&gt;Gos Micklem&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16546">
<title>Correcting for heterogeneity in real-time epidemiological indicators. (arXiv:2309.16546v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16546</link>
<description rdf:parseType="Literal">&lt;p&gt;Auxiliary data sources have become increasingly important in epidemiological
surveillance, as they are often available at a finer spatial and temporal
resolution, larger coverage, and lower latency than traditional surveillance
signals. We describe the problem of spatial and temporal heterogeneity in these
signals derived from these data sources, where spatial and/or temporal biases
are present. We present a method to use a ``guiding&apos;&apos; signal to correct for
these biases and produce a more reliable signal that can be used for modeling
and forecasting. The method assumes that the heterogeneity can be approximated
by a low-rank matrix and that the temporal heterogeneity is smooth over time.
We also present a hyperparameter selection algorithm to choose the parameters
representing the matrix rank and degree of temporal smoothness of the
corrections. In the absence of ground truth, we use maps and plots to argue
that this method does indeed reduce heterogeneity. Reducing heterogeneity from
auxiliary data sources greatly increases their utility in modeling and
forecasting epidemics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rumack_A/0/1/0/all/0/1&quot;&gt;Aaron Rumack&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenfeld_R/0/1/0/all/0/1&quot;&gt;Roni Rosenfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Townes_F/0/1/0/all/0/1&quot;&gt;F. William Townes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16561">
<title>Voting Network for Contour Levee Farmland Segmentation and Classification. (arXiv:2309.16561v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16561</link>
<description rdf:parseType="Literal">&lt;p&gt;High-resolution aerial imagery allows fine details in the segmentation of
farmlands. However, small objects and features introduce distortions to the
delineation of object boundaries, and larger contextual views are needed to
mitigate class confusion. In this work, we present an end-to-end trainable
network for segmenting farmlands with contour levees from high-resolution
aerial imagery. A fusion block is devised that includes multiple voting blocks
to achieve image segmentation and classification. We integrate the fusion block
with a backbone and produce both semantic predictions and segmentation slices.
The segmentation slices are used to perform majority voting on the predictions.
The network is trained to assign the most likely class label of a segment to
its pixels, learning the concept of farmlands rather than analyzing
constitutive pixels separately. We evaluate our method using images from the
National Agriculture Imagery Program. Our method achieved an average accuracy
of 94.34\%. Compared to the state-of-the-art methods, the proposed method
obtains an improvement of 6.96% and 2.63% in the F1 score on average.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyarian_A/0/1/0/all/0/1&quot;&gt;Abolfazl Meyarian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xiaohui Yuan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16563">
<title>CRIMED: Lower and Upper Bounds on Regret for Bandits with Unbounded Stochastic Corruption. (arXiv:2309.16563v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16563</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the regret-minimisation problem in a multi-armed bandit
setting with arbitrary corruptions. Similar to the classical setup, the agent
receives rewards generated independently from the distribution of the arm
chosen at each time. However, these rewards are not directly observed. Instead,
with a fixed $\varepsilon\in (0,\frac{1}{2})$, the agent observes a sample from
the chosen arm&apos;s distribution with probability $1-\varepsilon$, or from an
arbitrary corruption distribution with probability $\varepsilon$. Importantly,
we impose no assumptions on these corruption distributions, which can be
unbounded. In this setting, accommodating potentially unbounded corruptions, we
establish a problem-dependent lower bound on regret for a given family of arm
distributions. We introduce CRIMED, an asymptotically-optimal algorithm that
achieves the exact lower bound on regret for bandits with Gaussian
distributions with known variance. Additionally, we provide a finite-sample
analysis of CRIMED&apos;s regret performance. Notably, CRIMED can effectively handle
corruptions with $\varepsilon$ values as high as $\frac{1}{2}$. Furthermore, we
develop a tight concentration result for medians in the presence of arbitrary
corruptions, even with $\varepsilon$ values up to $\frac{1}{2}$, which may be
of independent interest. We also discuss an extension of the algorithm for
handling misspecification in Gaussian model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agrawal_S/0/1/0/all/0/1&quot;&gt;Shubhada Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mathieu_T/0/1/0/all/0/1&quot;&gt;Timoth&amp;#xe9;e Mathieu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Basu_D/0/1/0/all/0/1&quot;&gt;Debabrota Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maillard_O/0/1/0/all/0/1&quot;&gt;Odalric-Ambrym Maillard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16564">
<title>Augment to Interpret: Unsupervised and Inherently Interpretable Graph Embeddings. (arXiv:2309.16564v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16564</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised learning allows us to leverage unlabelled data, which has become
abundantly available, and to create embeddings that are usable on a variety of
downstream tasks. However, the typical lack of interpretability of unsupervised
representation learning has become a limiting factor with regard to recent
transparent-AI regulations. In this paper, we study graph representation
learning and we show that data augmentation that preserves semantics can be
learned and used to produce interpretations. Our framework, which we named
INGENIOUS, creates inherently interpretable embeddings and eliminates the need
for costly additional post-hoc analysis. We also introduce additional metrics
addressing the lack of formalism and metrics in the understudied area of
unsupervised-representation learning interpretability. Our results are
supported by an experimental study applied to both graph-level and node-level
tasks and show that interpretable embeddings provide state-of-the-art
performance on subsequent downstream tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scafarto_G/0/1/0/all/0/1&quot;&gt;Gregory Scafarto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciortan_M/0/1/0/all/0/1&quot;&gt;Madalina Ciortan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tihon_S/0/1/0/all/0/1&quot;&gt;Simon Tihon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferre_Q/0/1/0/all/0/1&quot;&gt;Quentin Ferre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16571">
<title>Review of Machine Learning Methods for Additive Manufacturing of Functionally Graded Materials. (arXiv:2309.16571v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16571</link>
<description rdf:parseType="Literal">&lt;p&gt;Additive manufacturing has revolutionized the manufacturing of complex parts
by enabling direct material joining and offers several advantages such as
cost-effective manufacturing of complex parts, reducing manufacturing waste,
and opening new possibilities for manufacturing automation. One group of
materials for which additive manufacturing holds great potential for enhancing
component performance and properties is Functionally Graded Materials (FGMs).
FGMs are advanced composite materials that exhibit smoothly varying properties
making them desirable for applications in aerospace, automobile, biomedical,
and defense industries. Such composition differs from traditional composite
materials, since the location-dependent composition changes gradually in FGMs,
leading to enhanced properties. Recently, machine learning techniques have
emerged as a promising means for fabrication of FGMs through optimizing
processing parameters, improving product quality, and detecting manufacturing
defects. This paper first provides a brief literature review of works related
to FGM fabrication, followed by reviewing works on employing machine learning
in additive manufacturing, Afterward, we provide an overview of published works
in the literature related to the application of machine learning methods in
Directed Energy Deposition and for fabrication of FGMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karimzadeh_M/0/1/0/all/0/1&quot;&gt;Mohammad Karimzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vakanski_A/0/1/0/all/0/1&quot;&gt;Aleksandar Vakanski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1&quot;&gt;Fei Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinchang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16577">
<title>Compilation as a Defense: Enhancing DL Model Attack Robustness via Tensor Optimization. (arXiv:2309.16577v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16577</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial Machine Learning (AML) is a rapidly growing field of security
research, with an often overlooked area being model attacks through
side-channels. Previous works show such attacks to be serious threats, though
little progress has been made on efficient remediation strategies that avoid
costly model re-engineering. This work demonstrates a new defense against AML
side-channel attacks using model compilation techniques, namely tensor
optimization. We show relative model attack effectiveness decreases of up to
43% using tensor optimization, discuss the implications, and direction of
future work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trawicki_S/0/1/0/all/0/1&quot;&gt;Stefan Trawicki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hackett_W/0/1/0/all/0/1&quot;&gt;William Hackett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Birch_L/0/1/0/all/0/1&quot;&gt;Lewis Birch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suri_N/0/1/0/all/0/1&quot;&gt;Neeraj Suri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garraghan_P/0/1/0/all/0/1&quot;&gt;Peter Garraghan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16578">
<title>M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning. (arXiv:2309.16578v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16578</link>
<description rdf:parseType="Literal">&lt;p&gt;Orbital-free density functional theory (OFDFT) is a quantum chemistry
formulation that has a lower cost scaling than the prevailing Kohn-Sham DFT,
which is increasingly desired for contemporary molecular research. However, its
accuracy is limited by the kinetic energy density functional, which is
notoriously hard to approximate for non-periodic molecular systems. In this
work, we propose M-OFDFT, an OFDFT approach capable of solving molecular
systems using a deep-learning functional model. We build the essential
nonlocality into the model, which is made affordable by the concise density
representation as expansion coefficients under an atomic basis. With techniques
to address unconventional learning challenges therein, M-OFDFT achieves a
comparable accuracy with Kohn-Sham DFT on a wide range of molecules untouched
by OFDFT before. More attractively, M-OFDFT extrapolates well to molecules much
larger than those in training, which unleashes the appealing scaling for
studying large molecules including proteins, representing an advancement of the
accuracy-efficiency trade-off frontier in quantum chemistry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;He Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Siyuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+You_J/0/1/0/all/0/1&quot;&gt;Jiacheng You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Shuxin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Ziheng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_N/0/1/0/all/0/1&quot;&gt;Nanning Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shao_B/0/1/0/all/0/1&quot;&gt;Bin Shao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16584">
<title>A Design Toolbox for the Development of Collaborative Distributed Machine Learning Systems. (arXiv:2309.16584v1 [cs.MA])</title>
<link>http://arxiv.org/abs/2309.16584</link>
<description rdf:parseType="Literal">&lt;p&gt;To leverage training data for the sufficient training of ML models from
multiple parties in a confidentiality-preserving way, various collaborative
distributed machine learning (CDML) system designs have been developed, for
example, to perform assisted learning, federated learning, and split learning.
CDML system designs show different traits, for example, high agent autonomy,
machine learning (ML) model confidentiality, and fault tolerance. Facing a wide
variety of CDML system designs with different traits, it is difficult for
developers to design CDML systems with traits that match use case requirements
in a targeted way. However, inappropriate CDML system designs may result in
CDML systems failing their envisioned purposes. We developed a CDML design
toolbox that can guide the development of CDML systems. Based on the CDML
design toolbox, we present CDML system archetypes with distinct key traits that
can support the design of CDML systems to meet use case requirements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1&quot;&gt;David Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannengiesser_N/0/1/0/all/0/1&quot;&gt;Niclas Kannengie&amp;#xdf;er&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rank_S/0/1/0/all/0/1&quot;&gt;Sascha Rank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sunyaev_A/0/1/0/all/0/1&quot;&gt;Ali Sunyaev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16592">
<title>Tensor Factorization for Leveraging Cross-Modal Knowledge in Data-Constrained Infrared Object Detection. (arXiv:2309.16592v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16592</link>
<description rdf:parseType="Literal">&lt;p&gt;The primary bottleneck towards obtaining good recognition performance in IR
images is the lack of sufficient labeled training data, owing to the cost of
acquiring such data. Realizing that object detection methods for the RGB
modality are quite robust (at least for some commonplace classes, like person,
car, etc.), thanks to the giant training sets that exist, in this work we seek
to leverage cues from the RGB modality to scale object detectors to the IR
modality, while preserving model performance in the RGB modality. At the core
of our method, is a novel tensor decomposition method called TensorFact which
splits the convolution kernels of a layer of a Convolutional Neural Network
(CNN) into low-rank factor matrices, with fewer parameters than the original
CNN. We first pretrain these factor matrices on the RGB modality, for which
plenty of training data are assumed to exist and then augment only a few
trainable parameters for training on the IR modality to avoid over-fitting,
while encouraging them to capture complementary cues from those trained only on
the RGB modality. We validate our approach empirically by first assessing how
well our TensorFact decomposed network performs at the task of detecting
objects in RGB images vis-a-vis the original network and then look at how well
it adapts to IR images of the FLIR ADAS v1 dataset. For the latter, we train
models under scenarios that pose challenges stemming from data paucity. From
the experiments, we observe that: (i) TensorFact shows performance gains on RGB
images; (ii) further, this pre-trained model, when fine-tuned, outperforms a
standard state-of-the-art object detector on the FLIR ADAS v1 dataset by about
4% in terms of mAP 50 score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1&quot;&gt;Manish Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_M/0/1/0/all/0/1&quot;&gt;Moitreya Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1&quot;&gt;Kuan-Chuan Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lohit_S/0/1/0/all/0/1&quot;&gt;Suhas Lohit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1&quot;&gt;Michael Jones&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16593">
<title>Navigating Healthcare Insights: A Birds Eye View of Explainability with Knowledge Graphs. (arXiv:2309.16593v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.16593</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graphs (KGs) are gaining prominence in Healthcare AI, especially in
drug discovery and pharmaceutical research as they provide a structured way to
integrate diverse information sources, enhancing AI system interpretability.
This interpretability is crucial in healthcare, where trust and transparency
matter, and eXplainable AI (XAI) supports decision making for healthcare
professionals. This overview summarizes recent literature on the impact of KGs
in healthcare and their role in developing explainable AI models. We cover KG
workflow, including construction, relationship extraction, reasoning, and their
applications in areas like Drug-Drug Interactions (DDI), Drug Target
Interactions (DTI), Drug Development (DD), Adverse Drug Reactions (ADR), and
bioinformatics. We emphasize the importance of making KGs more interpretable
through knowledge-infused learning in healthcare. Finally, we highlight
research challenges and provide insights for future directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Satvik Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parikh_S/0/1/0/all/0/1&quot;&gt;Shivam Parikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Somya Garg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16595">
<title>Can LLMs Effectively Leverage Structural Information for Graph Learning: When and Why. (arXiv:2309.16595v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16595</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies Large Language Models (LLMs) for structured
data--particularly graphs--a crucial data modality that remains underexplored
in the LLM literature. We aim to understand when and why the incorporation of
structural information inherent in graph data can improve the prediction
performance of LLMs on node classification tasks. To address the ``when&apos;&apos;
question, we examine a variety of prompting methods for encoding structural
information, in settings where textual node features are either rich or scarce.
For the ``why&apos;&apos; questions, we probe into two potential contributing factors to
the LLM performance: data leakage and homophily. Our exploration of these
questions reveals that (i) LLMs can benefit from structural information,
especially when textual node features are scarce; (ii) there is no substantial
evidence indicating that the performance of LLMs is significantly attributed to
data leakage; and (iii) the performance of LLMs on a target node is strongly
positively related to the local homophily ratio of the node.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jin Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xingjian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1&quot;&gt;Qiaozhu Mei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jiaqi Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16597">
<title>Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16597</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian optimization (BO) is a popular black-box function optimization
method, which makes sequential decisions based on a Bayesian model, typically a
Gaussian process (GP), of the function. To ensure the quality of the model,
transfer learning approaches have been developed to automatically design GP
priors by learning from observations on &quot;training&quot; functions. These training
functions are typically required to have the same domain as the &quot;test&quot; function
(black-box function to be optimized). In this paper, we introduce MPHD, a model
pre-training method on heterogeneous domains, which uses a neural net mapping
from domain-specific contexts to specifications of hierarchical GPs. MPHD can
be seamlessly integrated with BO to transfer knowledge across heterogeneous
search spaces. Our theoretical and empirical results demonstrate the validity
of MPHD and its superior performance on challenging black-box function
optimization tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1&quot;&gt;Zhou Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1&quot;&gt;Xinran Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16598">
<title>Cross-Prediction-Powered Inference. (arXiv:2309.16598v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16598</link>
<description rdf:parseType="Literal">&lt;p&gt;While reliable data-driven decision-making hinges on high-quality labeled
data, the acquisition of quality labels often involves laborious human
annotations or slow and expensive scientific measurements. Machine learning is
becoming an appealing alternative as sophisticated predictive techniques are
being used to quickly and cheaply produce large amounts of predicted labels;
e.g., predicted protein structures are used to supplement experimentally
derived structures, predictions of socioeconomic indicators from satellite
imagery are used to supplement accurate survey data, and so on. Since
predictions are imperfect and potentially biased, this practice brings into
question the validity of downstream inferences. We introduce cross-prediction:
a method for valid inference powered by machine learning. With a small labeled
dataset and a large unlabeled dataset, cross-prediction imputes the missing
labels via machine learning and applies a form of debiasing to remedy the
prediction inaccuracies. The resulting inferences achieve the desired error
probability and are more powerful than those that only leverage the labeled
data. Closely related is the recent proposal of prediction-powered inference,
which assumes that a good pre-trained model is already available. We show that
cross-prediction is consistently more powerful than an adaptation of
prediction-powered inference in which a fraction of the labeled data is split
off and used to train the model. Finally, we observe that cross-prediction
gives more stable conclusions than its competitors; its confidence intervals
typically have significantly lower variability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zrnic_T/0/1/0/all/0/1&quot;&gt;Tijana Zrnic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Candes_E/0/1/0/all/0/1&quot;&gt;Emmanuel J. Cand&amp;#xe8;s&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16603">
<title>Deep Learning Based Uplink Multi-User SIMO Beamforming Design. (arXiv:2309.16603v1 [cs.IT])</title>
<link>http://arxiv.org/abs/2309.16603</link>
<description rdf:parseType="Literal">&lt;p&gt;The advancement of fifth generation (5G) wireless communication networks has
created a greater demand for wireless resource management solutions that offer
high data rates, extensive coverage, minimal latency and energy-efficient
performance. Nonetheless, traditional approaches have shortcomings when it
comes to computational complexity and their ability to adapt to dynamic
conditions, creating a gap between theoretical analysis and the practical
execution of algorithmic solutions for managing wireless resources. Deep
learning-based techniques offer promising solutions for bridging this gap with
their substantial representation capabilities. We propose a novel unsupervised
deep learning framework, which is called NNBF, for the design of uplink receive
multi-user single input multiple output (MU-SIMO) beamforming. The primary
objective is to enhance the throughput by focusing on maximizing the sum-rate
while also offering computationally efficient solution, in contrast to
established conventional methods. We conduct experiments for several antenna
configurations. Our experimental results demonstrate that NNBF exhibits
superior performance compared to our baseline methods, namely, zero-forcing
beamforming (ZFBF) and minimum mean square error (MMSE) equalizer.
Additionally, NNBF is scalable to the number of single-antenna user equipments
(UEs) while baseline methods have significant computational burden due to
matrix pseudo-inverse operation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vahapoglu_C/0/1/0/all/0/1&quot;&gt;Cemil Vahapoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OShea_T/0/1/0/all/0/1&quot;&gt;Timothy J. O&amp;#x27;Shea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_T/0/1/0/all/0/1&quot;&gt;Tamoghna Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ulukus_S/0/1/0/all/0/1&quot;&gt;Sennur Ulukus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16604">
<title>Exploiting Edge Features in Graphs with Fused Network Gromov-Wasserstein Distance. (arXiv:2309.16604v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16604</link>
<description rdf:parseType="Literal">&lt;p&gt;Pairwise comparison of graphs is key to many applications in Machine learning
ranging from clustering, kernel-based classification/regression and more
recently supervised graph prediction. Distances between graphs usually rely on
informative representations of these structured objects such as bag of
substructures or other graph embeddings. A recently popular solution consists
in representing graphs as metric measure spaces, allowing to successfully
leverage Optimal Transport, which provides meaningful distances allowing to
compare them: the Gromov-Wasserstein distances. However, this family of
distances overlooks edge attributes, which are essential for many structured
objects. In this work, we introduce an extension of Gromov-Wasserstein distance
for comparing graphs whose both nodes and edges have features. We propose novel
algorithms for distance and barycenter computation. We empirically show the
effectiveness of the novel distance in learning tasks where graphs occur in
either input space or output space, such as classification and graph
prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Junjie Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Labeau_M/0/1/0/all/0/1&quot;&gt;Matthieu Labeau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+dAlche_Buc_F/0/1/0/all/0/1&quot;&gt;Florence d&amp;#x27;Alch&amp;#xe9;-Buc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16620">
<title>Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit. (arXiv:2309.16620v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.16620</link>
<description rdf:parseType="Literal">&lt;p&gt;The cost of hyperparameter tuning in deep learning has been rising with model
sizes, prompting practitioners to find new tuning methods using a proxy of
smaller networks. One such proposal uses $\mu$P parameterized networks, where
the optimal hyperparameters for small width networks transfer to networks with
arbitrarily large width. However, in this scheme, hyperparameters do not
transfer across depths. As a remedy, we study residual networks with a residual
branch scale of $1/\sqrt{\text{depth}}$ in combination with the $\mu$P
parameterization. We provide experiments demonstrating that residual
architectures including convolutional ResNets and Vision Transformers trained
with this parameterization exhibit transfer of optimal hyperparameters across
width and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings
are supported and motivated by theory. Using recent developments in the
dynamical mean field theory (DMFT) description of neural network learning
dynamics, we show that this parameterization of ResNets admits a well-defined
feature learning joint infinite-width and infinite-depth limit and show
convergence of finite-size network dynamics towards this limit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1&quot;&gt;Blake Bordelon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Noci_L/0/1/0/all/0/1&quot;&gt;Lorenzo Noci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mufan Bill Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hanin_B/0/1/0/all/0/1&quot;&gt;Boris Hanin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1&quot;&gt;Cengiz Pehlevan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16630">
<title>On Learning with LAD. (arXiv:2309.16630v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16630</link>
<description rdf:parseType="Literal">&lt;p&gt;The logical analysis of data, LAD, is a technique that yields two-class
classifiers based on Boolean functions having disjunctive normal form (DNF)
representation. Although LAD algorithms employ optimization techniques, the
resulting binary classifiers or binary rules do not lead to overfitting. We
propose a theoretical justification for the absence of overfitting by
estimating the Vapnik-Chervonenkis dimension (VC dimension) for LAD models
where hypothesis sets consist of DNFs with a small number of cubic monomials.
We illustrate and confirm our observations empirically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jothishwaran_C/0/1/0/all/0/1&quot;&gt;C. A. Jothishwaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_B/0/1/0/all/0/1&quot;&gt;Biplav Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singla_J/0/1/0/all/0/1&quot;&gt;Jitin Singla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gangopadhyay_S/0/1/0/all/0/1&quot;&gt;Sugata Gangopadhyay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16631">
<title>Robust Offline Reinforcement Learning -- Certify the Confidence Interval. (arXiv:2309.16631v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16631</link>
<description rdf:parseType="Literal">&lt;p&gt;Currently, reinforcement learning (RL), especially deep RL, has received more
and more attention in the research area. However, the security of RL has been
an obvious problem due to the attack manners becoming mature. In order to
defend against such adversarial attacks, several practical approaches are
developed, such as adversarial training, data filtering, etc. However, these
methods are mostly based on empirical algorithms and experiments, without
rigorous theoretical analysis of the robustness of the algorithms. In this
paper, we develop an algorithm to certify the robustness of a given policy
offline with random smoothing, which could be proven and conducted as
efficiently as ones without random smoothing. Experiments on different
environments confirm the correctness of our algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jiarui Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon Shaolei Du&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16633">
<title>Mixup Your Own Pairs. (arXiv:2309.16633v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16633</link>
<description rdf:parseType="Literal">&lt;p&gt;In representation learning, regression has traditionally received less
attention than classification. Directly applying representation learning
techniques designed for classification to regression often results in
fragmented representations in the latent space, yielding sub-optimal
performance. In this paper, we argue that the potential of contrastive learning
for regression has been overshadowed due to the neglect of two crucial aspects:
ordinality-awareness and hardness. To address these challenges, we advocate
&quot;mixup your own contrastive pairs for supervised contrastive regression&quot;,
instead of relying solely on real/augmented samples. Specifically, we propose
Supervised Contrastive Learning for Regression with Mixup (SupReMix). It takes
anchor-inclusive mixtures (mixup of the anchor and a distinct negative sample)
as hard negative pairs and anchor-exclusive mixtures (mixup of two distinct
negative samples) as hard positive pairs at the embedding level. This strategy
formulates harder contrastive pairs by integrating richer ordinal information.
Through extensive experiments on six regression datasets including 2D images,
volumetric images, text, tabular data, and time-series signals, coupled with
theoretical analysis, we demonstrate that SupReMix pre-training fosters
continuous ordered representations of regression data, resulting in significant
improvement in regression performance. Furthermore, SupReMix is superior to
other approaches in a range of regression challenges including transfer
learning, imbalanced training data, and scenarios with fewer training samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yilei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1&quot;&gt;Zijian Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chongyao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wangchunshu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Juan Helen Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16645">
<title>Reusability report: Prostate cancer stratification with diverse biologically-informed neural architectures. (arXiv:2309.16645v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.16645</link>
<description rdf:parseType="Literal">&lt;p&gt;In, Elmarakeby et al., &quot;Biologically informed deep neural network for
prostate cancer discovery&quot;, a feedforward neural network with biologically
informed, sparse connections (P-NET) was presented to model the state of
prostate cancer. We verified the reproducibility of the study conducted by
Elmarakeby et al., using both their original codebase, and our own
re-implementation using more up-to-date libraries. We quantified the
contribution of network sparsification by Reactome biological pathways, and
confirmed its importance to P-NET&apos;s superior performance. Furthermore, we
explored alternative neural architectures and approaches to incorporating
biological information into the networks. We experimented with three types of
graph neural networks on the same training data, and investigated the clinical
prediction agreement between different models. Our analyses demonstrated that
deep neural networks with distinct architectures make incorrect predictions for
individual patient that are persistent across different initializations of a
specific neural architecture. This suggests that different neural architectures
are sensitive to different aspects of the data, an important yet under-explored
challenge for clinical prediction tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedersen_C/0/1/0/all/0/1&quot;&gt;Christian Pedersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tesileanu_T/0/1/0/all/0/1&quot;&gt;Tiberiu Tesileanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tinghui Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golkar_S/0/1/0/all/0/1&quot;&gt;Siavash Golkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cranmer_M/0/1/0/all/0/1&quot;&gt;Miles Cranmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zijun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_S/0/1/0/all/0/1&quot;&gt;Shirley Ho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16656">
<title>Visual In-Context Learning for Few-Shot Eczema Segmentation. (arXiv:2309.16656v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16656</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated diagnosis of eczema from digital camera images is crucial for
developing applications that allow patients to self-monitor their recovery. An
important component of this is the segmentation of eczema region from such
images. Current methods for eczema segmentation rely on deep neural networks
such as convolutional (CNN)-based U-Net or transformer-based Swin U-Net. While
effective, these methods require high volume of annotated data, which can be
difficult to obtain. Here, we investigate the capabilities of visual in-context
learning that can perform few-shot eczema segmentation with just a handful of
examples and without any need for retraining models. Specifically, we propose a
strategy for applying in-context learning for eczema segmentation with a
generalist vision model called SegGPT. When benchmarked on a dataset of
annotated eczema images, we show that SegGPT with just 2 representative example
images from the training dataset performs better (mIoU: 36.69) than a CNN U-Net
trained on 428 images (mIoU: 32.60). We also discover that using more number of
examples for SegGPT may in fact be harmful to its performance. Our result
highlights the importance of visual in-context learning in developing faster
and better solutions to skin imaging tasks. Our result also paves the way for
developing inclusive solutions that can cater to minorities in the demographics
who are typically heavily under-represented in the training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1&quot;&gt;Neelesh Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aran_O/0/1/0/all/0/1&quot;&gt;Oya Aran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1&quot;&gt;Venugopal Vasudevan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16662">
<title>Geodesic Regression Characterizes 3D Shape Changes in the Female Brain During Menstruation. (arXiv:2309.16662v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16662</link>
<description rdf:parseType="Literal">&lt;p&gt;Women are at higher risk of Alzheimer&apos;s and other neurological diseases after
menopause, and yet research connecting female brain health to sex hormone
fluctuations is limited. We seek to investigate this connection by developing
tools that quantify 3D shape changes that occur in the brain during sex hormone
fluctuations. Geodesic regression on the space of 3D discrete surfaces offers a
principled way to characterize the evolution of a brain&apos;s shape. However, in
its current form, this approach is too computationally expensive for practical
use. In this paper, we propose approximation schemes that accelerate geodesic
regression on shape spaces of 3D discrete surfaces. We also provide rules of
thumb for when each approximation can be used. We test our approach on
synthetic data to quantify the speed-accuracy trade-off of these approximations
and show that practitioners can expect very significant speed-up while only
sacrificing little accuracy. Finally, we apply the method to real brain shape
data and produce the first characterization of how the female hippocampus
changes shape during the menstrual cycle as a function of progesterone: a
characterization made (practically) possible by our approximation schemes. Our
work paves the way for comprehensive, practical shape analyses in the fields of
bio-medicine and computer vision. Our implementation is publicly available on
GitHub: https://github.com/bioshape-lab/my28brains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Myers_A/0/1/0/all/0/1&quot;&gt;Adele Myers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_C/0/1/0/all/0/1&quot;&gt;Caitlin Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobs_E/0/1/0/all/0/1&quot;&gt;Emily Jacobs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miolane_N/0/1/0/all/0/1&quot;&gt;Nina Miolane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16663">
<title>HyperPPO: A scalable method for finding small policies for robotic control. (arXiv:2309.16663v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.16663</link>
<description rdf:parseType="Literal">&lt;p&gt;Models with fewer parameters are necessary for the neural control of
memory-limited, performant robots. Finding these smaller neural network
architectures can be time-consuming. We propose HyperPPO, an on-policy
reinforcement learning algorithm that utilizes graph hypernetworks to estimate
the weights of multiple neural architectures simultaneously. Our method
estimates weights for networks that are much smaller than those in common-use
networks yet encode highly performant policies. We obtain multiple trained
policies at the same time while maintaining sample efficiency and provide the
user the choice of picking a network architecture that satisfies their
computational constraints. We show that our method scales well - more training
resources produce faster convergence to higher-performing architectures. We
demonstrate that the neural policies estimated by HyperPPO are capable of
decentralized control of a Crazyflie2.1 quadrotor. Website:
https://sites.google.com/usc.edu/hyperppo
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hegde_S/0/1/0/all/0/1&quot;&gt;Shashank Hegde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhehui Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1&quot;&gt;Gaurav S. Sukhatme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16668">
<title>RealFill: Reference-Driven Generation for Authentic Image Completion. (arXiv:2309.16668v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16668</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in generative imagery have brought forth outpainting and
inpainting models that can produce high-quality, plausible image content in
unknown regions, but the content these models hallucinate is necessarily
inauthentic, since the models lack sufficient context about the true scene. In
this work, we propose RealFill, a novel generative approach for image
completion that fills in missing regions of an image with the content that
should have been there. RealFill is a generative inpainting model that is
personalized using only a few reference images of a scene. These reference
images do not have to be aligned with the target image, and can be taken with
drastically varying viewpoints, lighting conditions, camera apertures, or image
styles. Once personalized, RealFill is able to complete a target image with
visually compelling contents that are faithful to the original scene. We
evaluate RealFill on a new image completion benchmark that covers a set of
diverse and challenging scenarios, and find that it outperforms existing
approaches by a large margin. See more results on our project page:
https://realfill.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1&quot;&gt;Luming Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1&quot;&gt;Nataniel Ruiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_Q/0/1/0/all/0/1&quot;&gt;Qinghao Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanzhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holynski_A/0/1/0/all/0/1&quot;&gt;Aleksander Holynski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1&quot;&gt;David E. Jacobs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hariharan_B/0/1/0/all/0/1&quot;&gt;Bharath Hariharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pritch_Y/0/1/0/all/0/1&quot;&gt;Yael Pritch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wadhwa_N/0/1/0/all/0/1&quot;&gt;Neal Wadhwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aberman_K/0/1/0/all/0/1&quot;&gt;Kfir Aberman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubinstein_M/0/1/0/all/0/1&quot;&gt;Michael Rubinstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.16672">
<title>Learning to Transform for Generalizable Instance-wise Invariance. (arXiv:2309.16672v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.16672</link>
<description rdf:parseType="Literal">&lt;p&gt;Computer vision research has long aimed to build systems that are robust to
spatial transformations found in natural data. Traditionally, this is done
using data augmentation or hard-coding invariances into the architecture.
However, too much or too little invariance can hurt, and the correct amount is
unknown a priori and dependent on the instance. Ideally, the appropriate
invariance would be learned from data and inferred at test-time.
&lt;/p&gt;
&lt;p&gt;We treat invariance as a prediction problem. Given any image, we use a
normalizing flow to predict a distribution over transformations and average the
predictions over them. Since this distribution only depends on the instance, we
can align instances before classifying them and generalize invariance across
classes. The same distribution can also be used to adapt to out-of-distribution
poses. This normalizing flow is trained end-to-end and can learn a much larger
range of transformations than Augerino and InstaAug. When used as data
augmentation, our method shows accuracy and robustness gains on CIFAR 10,
CIFAR10-LT, and TinyImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhal_U/0/1/0/all/0/1&quot;&gt;Utkarsh Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esteves_C/0/1/0/all/0/1&quot;&gt;Carlos Esteves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1&quot;&gt;Ameesh Makadia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Stella X. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.00029">
<title>Learning Interpretable Characteristic Kernels via Decision Forests. (arXiv:1812.00029v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1812.00029</link>
<description rdf:parseType="Literal">&lt;p&gt;Decision forests are widely used for classification and regression tasks. A
lesser known property of tree-based methods is that one can construct a
proximity matrix from the tree(s), and these proximity matrices are induced
kernels. While there has been extensive research on the applications and
properties of kernels, there is relatively little research on kernels induced
by decision forests. We construct Kernel Mean Embedding Random Forests (KMERF),
which induce kernels from random trees and/or forests using leaf-node
proximity. We introduce the notion of an asymptotically characteristic kernel,
and prove that KMERF kernels are asymptotically characteristic for both
discrete and continuous data. Because KMERF is data-adaptive, we suspected it
would outperform kernels selected a priori on finite sample data. We illustrate
that KMERF nearly dominates current state-of-the-art kernel-based tests across
a diverse range of high-dimensional two-sample and independence testing
settings. Furthermore, our forest-based approach is interpretable, and provides
feature importance metrics that readily distinguish important dimensions,
unlike other high-dimensional non-parametric testing procedures. Hence, this
work demonstrates the decision forest-based kernel can be more powerful and
more interpretable than existing methods, flying in the face of conventional
wisdom of the trade-off between the two.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Panda_S/0/1/0/all/0/1&quot;&gt;Sambit Panda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Cencheng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1&quot;&gt;Joshua T. Vogelstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1911.09307">
<title>Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy. (arXiv:1911.09307v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1911.09307</link>
<description rdf:parseType="Literal">&lt;p&gt;Regularization plays a crucial role in machine learning models, especially
for deep neural networks. The existing regularization techniques mainly rely on
the i.i.d. assumption and only consider the knowledge from the current sample,
without the leverage of the neighboring relationship between samples. In this
work, we propose a general regularizer called \textbf{Patch-level Neighborhood
Interpolation~(Pani)} that conducts a non-local representation in the
computation of networks. Our proposal explicitly constructs patch-level graphs
in different layers and then linearly interpolates neighborhood patch features,
serving as a general and effective regularization strategy. Further, we
customize our approach into two kinds of popular regularization methods, namely
Virtual Adversarial Training (VAT) and MixUp as well as its variants. The first
derived \textbf{Pani VAT} presents a novel way to construct non-local
adversarial smoothness by employing patch-level interpolated perturbations. The
second derived \textbf{Pani MixUp} method extends the MixUp, and achieves
superiority over MixUp and competitive performance over state-of-the-art
variants of MixUp method with a significant advantage in computational
efficiency. Extensive experiments have verified the effectiveness of our Pani
approach in both supervised and semi-supervised settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1&quot;&gt;Ke Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Bing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhouchen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhanxing Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2108.12547">
<title>Dynamic Selection in Algorithmic Decision-making. (arXiv:2108.12547v3 [econ.EM] UPDATED)</title>
<link>http://arxiv.org/abs/2108.12547</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper identifies and addresses dynamic selection problems in online
learning algorithms with endogenous data. In a contextual multi-armed bandit
model, a novel bias (self-fulfilling bias) arises because the endogeneity of
the data influences the choices of decisions, affecting the distribution of
future data to be collected and analyzed. We propose an
instrumental-variable-based algorithm to correct for the bias. It obtains true
parameter values and attains low (logarithmic-like) regret levels. We also
prove a central limit theorem for statistical inference. To establish the
theoretical properties, we develop a general technique that untangles the
interdependence between data and actions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Ye Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaowei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2109.03890">
<title>Axiomatic Aggregations of Abductive Explanations. (arXiv:2109.03890v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2109.03890</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent criticisms of the robustness of post hoc model approximation
explanation methods (like LIME and SHAP) have led to the rise of model-precise
abductive explanations. For each data point, abductive explanations provide a
minimal subset of features that are sufficient to generate the outcome. While
theoretically sound and rigorous, abductive explanations suffer from a major
issue -- there can be several valid abductive explanations for the same data
point. In such cases, providing a single abductive explanation can be
insufficient; on the other hand, providing all valid abductive explanations can
be incomprehensible due to their size. In this work, we solve this issue by
aggregating the many possible abductive explanations into feature importance
scores. We propose three aggregation methods: two based on power indices from
cooperative game theory and a third based on a well-known measure of causal
strength. We characterize these three methods axiomatically, showing that each
of them uniquely satisfies a set of desirable properties. We also evaluate them
on multiple datasets and show that these explanations are robust to the attacks
that fool SHAP and LIME.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biradar_G/0/1/0/all/0/1&quot;&gt;Gagan Biradar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izza_Y/0/1/0/all/0/1&quot;&gt;Yacine Izza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lobo_E/0/1/0/all/0/1&quot;&gt;Elita Lobo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1&quot;&gt;Vignesh Viswanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zick_Y/0/1/0/all/0/1&quot;&gt;Yair Zick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2112.00723">
<title>Infinite Neural Network Quantum States: Entanglement and Training Dynamics. (arXiv:2112.00723v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2112.00723</link>
<description rdf:parseType="Literal">&lt;p&gt;We study infinite limits of neural network quantum states ($\infty$-NNQS),
which exhibit representation power through ensemble statistics, and also
tractable gradient descent dynamics. Ensemble averages of Renyi entropies are
expressed in terms of neural network correlators, and architectures that
exhibit volume-law entanglement are presented. A general framework is developed
for studying the gradient descent dynamics of neural network quantum states
(NNQS), using a quantum state neural tangent kernel (QS-NTK). For $\infty$-NNQS
the training dynamics is simplified, since the QS-NTK becomes deterministic and
constant. An analytic solution is derived for quantum state supervised
learning, which allows an $\infty$-NNQS to recover any target wavefunction.
Numerical experiments on finite and infinite NNQS in the transverse field Ising
model and Fermi Hubbard model demonstrate excellent agreement with theory.
$\infty$-NNQS opens up new opportunities for studying entanglement and training
dynamics in other physics applications, such as in finding ground states.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Luo_D/0/1/0/all/0/1&quot;&gt;Di Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Halverson_J/0/1/0/all/0/1&quot;&gt;James Halverson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2202.05135">
<title>Group-Agent Reinforcement Learning. (arXiv:2202.05135v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2202.05135</link>
<description rdf:parseType="Literal">&lt;p&gt;It can largely benefit the reinforcement learning (RL) process of each agent
if multiple geographically distributed agents perform their separate RL tasks
cooperatively. Different from multi-agent reinforcement learning (MARL) where
multiple agents are in a common environment and should learn to cooperate or
compete with each other, in this case each agent has its separate environment
and only communicates with others to share knowledge without any cooperative or
competitive behaviour as a learning outcome. In fact, this scenario exists
widely in real life whose concept can be utilised in many applications, but is
not well understood yet and not well formulated. As the first effort, we
propose group-agent system for RL as a formulation of this scenario and the
third type of RL system with respect to single-agent and multi-agent systems.
We then propose a distributed RL framework called DDAL (Decentralised
Distributed Asynchronous Learning) designed for group-agent reinforcement
learning (GARL). We show through experiments that DDAL achieved desirable
performance with very stable training and has good scalability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1&quot;&gt;Kaiyue Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1&quot;&gt;Xiao-Jun Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2202.09134">
<title>Data Augmentation in the Underparameterized and Overparameterized Regimes. (arXiv:2202.09134v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2202.09134</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide results that exactly quantify how data augmentation affects the
variance and limiting distribution of estimates, and analyze several specific
models in detail. The results confirm some observations made in machine
learning practice, but also lead to unexpected findings: Data augmentation may
increase rather than decrease the uncertainty of estimates, such as the
empirical prediction risk. It can act as a regularizer, but fails to do so in
certain high-dimensional problems, and it may shift the double-descent peak of
an empirical risk. Overall, the analysis shows that several properties data
augmentation has been attributed with are not either true or false, but rather
depend on a combination of factors -- notably the data distribution, the
properties of the estimator, and the interplay of sample size, number of
augmentations, and dimension. Our main theoretical tool is a limit theorem for
functions of randomly transformed, high-dimensional random vectors. The proof
draws on work in probability on noise stability of functions of many variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kevin Han Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orbanz_P/0/1/0/all/0/1&quot;&gt;Peter Orbanz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Austern_M/0/1/0/all/0/1&quot;&gt;Morgane Austern&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.00147">
<title>DIRA: Dynamic Domain Incremental Regularised Adaptation. (arXiv:2205.00147v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.00147</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous systems (AS) often use Deep Neural Network (DNN) classifiers to
allow them to operate in complex, high-dimensional, non-linear, and dynamically
changing environments. Due to the complexity of these environments, DNN
classifiers may output misclassifications during operation when they face
domains not identified during development. Removing a system from operation for
retraining becomes impractical as the number of such AS increases. To increase
AS reliability and overcome this limitation, DNN classifiers need to have the
ability to adapt during operation when faced with different operational domains
using a few samples (e.g. 100 samples). However, retraining DNNs on a few
samples is known to cause catastrophic forgetting. In this paper, we introduce
Dynamic Incremental Regularised Adaptation (DIRA), a framework for operational
domain adaption of DNN classifiers using regularisation techniques to overcome
catastrophic forgetting and achieve adaptation when retraining using a few
samples of the target domain. Our approach shows improvements on different
image classification benchmarks aimed at evaluating robustness to distribution
shifts (e.g.CIFAR-10C/100C, ImageNet-C), and produces state-of-the-art
performance in comparison with other frameworks from the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghobrial_A/0/1/0/all/0/1&quot;&gt;Abanoub Ghobrial&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1&quot;&gt;Xuan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hond_D/0/1/0/all/0/1&quot;&gt;Darryl Hond&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asgari_H/0/1/0/all/0/1&quot;&gt;Hamid Asgari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eder_K/0/1/0/all/0/1&quot;&gt;Kerstin Eder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.05625">
<title>Quantum Self-Attention Neural Networks for Text Classification. (arXiv:2205.05625v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2205.05625</link>
<description rdf:parseType="Literal">&lt;p&gt;An emerging direction of quantum computing is to establish meaningful quantum
applications in various fields of artificial intelligence, including natural
language processing (NLP). Although some efforts based on syntactic analysis
have opened the door to research in Quantum NLP (QNLP), limitations such as
heavy syntactic preprocessing and syntax-dependent network architecture make
them impracticable on larger and real-world data sets. In this paper, we
propose a new simple network architecture, called the quantum self-attention
neural network (QSANN), which can compensate for these limitations.
Specifically, we introduce the self-attention mechanism into quantum neural
networks and then utilize a Gaussian projected quantum self-attention serving
as a sensible quantum version of self-attention. As a result, QSANN is
effective and scalable on larger data sets and has the desirable property of
being implementable on near-term quantum devices. In particular, our QSANN
outperforms the best existing QNLP model based on syntactic analysis as well as
a simple classical self-attention neural network in numerical experiments of
text classification tasks on public data sets. We further show that our method
exhibits robustness to low-level quantum noises and showcases resilience to
quantum neural network architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guangxi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xuanqiang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.06308">
<title>Developing a Philosophical Framework for Fair Machine Learning: Lessons From The Case of Algorithmic Collusion. (arXiv:2208.06308v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2208.06308</link>
<description rdf:parseType="Literal">&lt;p&gt;Fair machine learning research has been primarily concerned with
classification tasks that result in discrimination. However, as machine
learning algorithms are applied in new contexts the harms and injustices that
result are qualitatively different than those presently studied. The existing
research paradigm in machine learning which develops metrics and definitions of
fairness cannot account for these qualitatively different types of injustice.
One example of this is the problem of algorithmic collusion and market
fairness. The negative consequences of algorithmic collusion affect all
consumers, not only particular members of a protected class. Drawing on this
case study, I propose an ethical framework for researchers and practitioners in
machine learning seeking to develop and apply fairness metrics that extends to
new domains. This contribution ties the development of formal metrics of
fairness to specifically scoped normative principles. This enables fairness
metrics to reflect different concerns from discrimination. I conclude with the
limitations of my proposal and discuss promising avenues for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michelson_J/0/1/0/all/0/1&quot;&gt;James Michelson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.14708">
<title>Classical-to-quantum convolutional neural network transfer learning. (arXiv:2208.14708v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2208.14708</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning using quantum convolutional neural networks (QCNNs) has
demonstrated success in both quantum and classical data classification. In
previous studies, QCNNs attained a higher classification accuracy than their
classical counterparts under the same training conditions in the few-parameter
regime. However, the general performance of large-scale quantum models is
difficult to examine because of the limited size of quantum circuits, which can
be reliably implemented in the near future. We propose transfer learning as an
effective strategy for utilizing small QCNNs in the noisy intermediate-scale
quantum era to the full extent. In the classical-to-quantum transfer learning
framework, a QCNN can solve complex classification problems without requiring a
large-scale quantum circuit by utilizing a pre-trained classical convolutional
neural network (CNN). We perform numerical simulations of QCNN models with
various sets of quantum convolution and pooling operations for MNIST data
classification under transfer learning, in which a classical CNN is trained
with Fashion-MNIST data. The results show that transfer learning from classical
to quantum CNN performs considerably better than purely classical transfer
learning models under similar training conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Juhyeon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Huh_J/0/1/0/all/0/1&quot;&gt;Joonsuk Huh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Park_D/0/1/0/all/0/1&quot;&gt;Daniel K. Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.05856">
<title>Just Noticeable Difference Modeling for Face Recognition System. (arXiv:2209.05856v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2209.05856</link>
<description rdf:parseType="Literal">&lt;p&gt;High-quality face images are required to guarantee the stability and
reliability of automatic face recognition (FR) systems in surveillance and
security scenarios. However, a massive amount of face data is usually
compressed before being analyzed due to limitations on transmission or storage.
The compressed images may lose the powerful identity information, resulting in
the performance degradation of the FR system. Herein, we make the first attempt
to study just noticeable difference (JND) for the FR system, which can be
defined as the maximum distortion that the FR system cannot notice. More
specifically, we establish a JND dataset including 3530 original images and
137,670 compressed images generated by advanced reference encoding/decoding
software based on the Versatile Video Coding (VVC) standard (VTM-15.0).
Subsequently, we develop a novel JND prediction model to directly infer JND
images for the FR system. In particular, in order to maximum redundancy removal
without impairment of robust identity information, we apply the encoder with
multiple feature extraction and attention-based feature decomposition modules
to progressively decompose face features into two uncorrelated components,
i.e., identity and residual features, via self-supervised learning. Then, the
residual feature is fed into the decoder to generate the residual map. Finally,
the predicted JND map is obtained by subtracting the residual map from the
original image. Experimental results have demonstrated that the proposed model
achieves higher accuracy of JND map prediction compared with the
state-of-the-art JND models, and is capable of saving more bits while
maintaining the performance of the FR system compared with VTM-15.0.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yu Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1&quot;&gt;Zhangkai Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Baoliang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shurun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shiqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hanli Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwong_S/0/1/0/all/0/1&quot;&gt;Sam Kwong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.07403">
<title>Private Stochastic Optimization With Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses. (arXiv:2209.07403v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.07403</link>
<description rdf:parseType="Literal">&lt;p&gt;We study differentially private (DP) stochastic optimization (SO) with loss
functions whose worst-case Lipschitz parameter over all data points may be
extremely large. To date, the vast majority of work on DP SO assumes that the
loss is uniformly Lipschitz continuous over data (i.e. stochastic gradients are
uniformly bounded over all data points). While this assumption is convenient,
it often leads to pessimistic excess risk bounds. In many practical problems,
the worst-case (uniform) Lipschitz parameter of the loss over all data points
may be extremely large due to outliers. In such cases, the error bounds for DP
SO, which scale with the worst-case Lipschitz parameter of the loss, are
vacuous. To address these limitations, this work provides near-optimal excess
risk bounds that do not depend on the uniform Lipschitz parameter of the loss.
Building on a recent line of work (Wang et al., 2020; Kamath et al., 2022), we
assume that stochastic gradients have bounded $k$-th order moments for some $k
\geq 2$. Compared with works on uniformly Lipschitz DP SO, our excess risk
scales with the $k$-th moment bound instead of the uniform Lipschitz parameter
of the loss, allowing for significantly faster rates in the presence of
outliers and/or heavy-tailed data. For convex and strongly convex loss
functions, we provide the first asymptotically optimal excess risk bounds (up
to a logarithmic factor). In contrast to (Wang et al., 2020; Kamath et al.,
2022), our bounds do not require the loss function to be differentiable/smooth.
We also devise a linear-time algorithm for smooth losses that has excess risk
that is tight in certain practical parameter regimes. Additionally, our work is
the first to address non-convex non-uniformly Lipschitz loss functions
satisfying the Proximal-PL inequality; this covers some practical machine
learning models. Our Proximal-PL algorithm has near-optimal excess risk.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lowy_A/0/1/0/all/0/1&quot;&gt;Andrew Lowy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1&quot;&gt;Meisam Razaviyayn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.09916">
<title>Online Distribution Shift Detection via Recency Prediction. (arXiv:2211.09916v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2211.09916</link>
<description rdf:parseType="Literal">&lt;p&gt;When deploying modern machine learning-enabled robotic systems in high-stakes
applications, detecting distribution shift is critical. However, most existing
methods for detecting distribution shift are not well-suited to robotics
settings, where data often arrives in a streaming fashion and may be very
high-dimensional. In this work, we present an online method for detecting
distribution shift with guarantees on the false positive rate - i.e., when
there is no distribution shift, our system is very unlikely (with probability
$&amp;lt; \epsilon$) to falsely issue an alert; any alerts that are issued should
therefore be heeded. Our method is specifically designed for efficient
detection even with high dimensional data, and it empirically achieves up to
11x faster detection on realistic robotics settings compared to prior work
while maintaining a low false negative rate in practice (whenever there is a
distribution shift in our experiments, our method indeed emits an alert). We
demonstrate our approach in both simulation and hardware for a visual servoing
task, and show that our method indeed issues an alert before a failure occurs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1&quot;&gt;Rachel Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_R/0/1/0/all/0/1&quot;&gt;Rohan Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yixiao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hindy_A/0/1/0/all/0/1&quot;&gt;Ali Hindy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shengjia Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmerling_E/0/1/0/all/0/1&quot;&gt;Edward Schmerling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1&quot;&gt;Marco Pavone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.12814">
<title>Vertical Federated Learning: Concepts, Advances and Challenges. (arXiv:2211.12814v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.12814</link>
<description rdf:parseType="Literal">&lt;p&gt;Vertical Federated Learning (VFL) is a federated learning setting where
multiple parties with different features about the same set of users jointly
train machine learning models without exposing their raw data or model
parameters. Motivated by the rapid growth in VFL research and real-world
applications, we provide a comprehensive review of the concept and algorithms
of VFL, as well as current advances and challenges in various aspects,
including effectiveness, efficiency, and privacy. We provide an exhaustive
categorization for VFL settings and privacy-preserving protocols and
comprehensively analyze the privacy attacks and defense strategies for each
protocol. In the end, we propose a unified framework, termed VFLow, which
considers the VFL problem under communication, computation, privacy, as well as
effectiveness and fairness constraints. Finally, we review the most recent
advances in industrial applications, highlighting open challenges and future
directions for VFL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1&quot;&gt;Yan Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_T/0/1/0/all/0/1&quot;&gt;Tianyuan Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yanhong Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yuanqin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1&quot;&gt;Xiaozhou Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_Y/0/1/0/all/0/1&quot;&gt;Ye Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Ya-Qin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.16808">
<title>Efficient Adversarial Input Generation via Neural Net Patching. (arXiv:2211.16808v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.16808</link>
<description rdf:parseType="Literal">&lt;p&gt;The generation of adversarial inputs has become a crucial issue in
establishing the robustness and trustworthiness of deep neural nets, especially
when they are used in safety-critical application domains such as autonomous
vehicles and precision medicine. However, the problem poses multiple practical
challenges, including scalability issues owing to large-sized networks, and the
generation of adversarial inputs that lack important qualities such as
naturalness and output-impartiality. This problem shares its end goal with the
task of patching neural nets where small changes in some of the network&apos;s
weights need to be discovered so that upon applying these changes, the modified
net produces the desirable output for a given set of inputs. We exploit this
connection by proposing to obtain an adversarial input from a patch, with the
underlying observation that the effect of changing the weights can also be
brought about by changing the inputs instead. Thus, this paper presents a novel
way to generate input perturbations that are adversarial for a given network by
using an efficient network patching technique. We note that the proposed method
is significantly more effective than the prior state-of-the-art techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1&quot;&gt;Tooba Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madhukar_K/0/1/0/all/0/1&quot;&gt;Kumar Madhukar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1&quot;&gt;Subodh Vishnu Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.02941">
<title>Safe Imitation Learning of Nonlinear Model Predictive Control for Flexible Robots. (arXiv:2212.02941v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2212.02941</link>
<description rdf:parseType="Literal">&lt;p&gt;Flexible robots may overcome some of the industry&apos;s major challenges, such as
enabling intrinsically safe human-robot collaboration and achieving a higher
load-to-mass ratio. However, controlling flexible robots is complicated due to
their complex dynamics, which include oscillatory behavior and a
high-dimensional state space. NMPC offers an effective means to control such
robots, but its extensive computational demands often limit its application in
real-time scenarios. To enable fast control of flexible robots, we propose a
framework for a safe approximation of NMPC using imitation learning and a
predictive safety filter. Our framework significantly reduces computation time
while incurring a slight loss in performance. Compared to NMPC, our framework
shows more than a eightfold improvement in computation time when controlling a
three-dimensional flexible robot arm in simulation, all while guaranteeing
safety constraints. Notably, our approach outperforms conventional
reinforcement learning methods. The development of fast and safe approximate
NMPC holds the potential to accelerate the adoption of flexible robots in
industry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mamedov_S/0/1/0/all/0/1&quot;&gt;Shamil Mamedov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reiter_R/0/1/0/all/0/1&quot;&gt;Rudolf Reiter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azad_S/0/1/0/all/0/1&quot;&gt;Seyed Mahdi Basiri Azad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1&quot;&gt;Joschka Boedecker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diehl_M/0/1/0/all/0/1&quot;&gt;Moritz Diehl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swevers_J/0/1/0/all/0/1&quot;&gt;Jan Swevers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.03559">
<title>Attribute Graph Clustering via Learnable Augmentation. (arXiv:2212.03559v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.03559</link>
<description rdf:parseType="Literal">&lt;p&gt;Contrastive deep graph clustering (CDGC) utilizes contrastive learning to
group nodes into different clusters. Better augmentation techniques benefit the
quality of the contrastive samples, thus being one of key factors to improve
performance. However, the augmentation samples in existing methods are always
predefined by human experiences, and agnostic from the downstream task
clustering, thus leading to high human resource costs and poor performance. To
this end, we propose an Attribute Graph Clustering method via Learnable
Augmentation (\textbf{AGCLA}), which introduces learnable augmentors for
high-quality and suitable augmented samples for CDGC. Specifically, we design
two learnable augmentors for attribute and structure information, respectively.
Besides, two refinement matrices, including the high-confidence pseudo-label
matrix and the cross-view sample similarity matrix, are generated to improve
the reliability of the learned affinity matrix. During the training procedure,
we notice that there exist differences between the optimization goals for
training learnable augmentors and contrastive learning networks. In other
words, we should both guarantee the consistency of the embeddings as well as
the diversity of the augmented samples. Thus, an adversarial learning mechanism
is designed in our method. Moreover, a two-stage training strategy is leveraged
for the high-confidence refinement matrices. Extensive experimental results
demonstrate the effectiveness of AGCLA on six benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xihong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1&quot;&gt;Ke Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sihang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xinwang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_E/0/1/0/all/0/1&quot;&gt;En Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.10538">
<title>HyperBO+: Pre-training a universal prior for Bayesian optimization with hierarchical Gaussian processes. (arXiv:2212.10538v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.10538</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian optimization (BO), while proved highly effective for many black-box
function optimization tasks, requires practitioners to carefully select priors
that well model their functions of interest. Rather than specifying by hand,
researchers have investigated transfer learning based methods to automatically
learn the priors, e.g. multi-task BO (Swersky et al., 2013), few-shot BO
(Wistuba and Grabocka, 2021) and HyperBO (Wang et al., 2022). However, those
prior learning methods typically assume that the input domains are the same for
all tasks, weakening their ability to use observations on functions with
different domains or generalize the learned priors to BO on different search
spaces. In this work, we present HyperBO+: a pre-training approach for
hierarchical Gaussian processes that enables the same prior to work universally
for Bayesian optimization on functions with different domains. We propose a
two-step pre-training method and analyze its appealing asymptotic properties
and benefits to BO both theoretically and empirically. On real-world
hyperparameter tuning tasks that involve multiple search spaces, we demonstrate
that HyperBO+ is able to generalize to unseen search spaces and achieves lower
regrets than competitive baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1&quot;&gt;Zhou Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1&quot;&gt;Xinran Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.01253">
<title>Deep learning for bias-correcting CMIP6-class Earth system models. (arXiv:2301.01253v3 [physics.ao-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2301.01253</link>
<description rdf:parseType="Literal">&lt;p&gt;The accurate representation of precipitation in Earth system models (ESMs) is
crucial for reliable projections of the ecological and socioeconomic impacts in
response to anthropogenic global warming. The complex cross-scale interactions
of processes that produce precipitation are challenging to model, however,
inducing potentially strong biases in ESM fields, especially regarding
extremes. State-of-the-art bias correction methods only address errors in the
simulated frequency distributions locally at every individual grid cell.
Improving unrealistic spatial patterns of the ESM output, which would require
spatial context, has not been possible so far. Here, we show that a
post-processing method based on physically constrained generative adversarial
networks (cGANs) can correct biases of a state-of-the-art, CMIP6-class ESM both
in local frequency distributions and in the spatial patterns at once. While our
method improves local frequency distributions equally well as gold-standard
bias-adjustment frameworks, it strongly outperforms any existing methods in the
correction of spatial patterns, especially in terms of the characteristic
spatial intermittency of precipitation extremes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hess_P/0/1/0/all/0/1&quot;&gt;Philipp Hess&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lange_S/0/1/0/all/0/1&quot;&gt;Stefan Lange&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Schotz_C/0/1/0/all/0/1&quot;&gt;Christof Sch&amp;#xf6;tz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Boers_N/0/1/0/all/0/1&quot;&gt;Niklas Boers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.11562">
<title>Is My Prediction Arbitrary? Confounding Effects of Variance in Fair Classification. (arXiv:2301.11562v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.11562</link>
<description rdf:parseType="Literal">&lt;p&gt;Variance in predictions across different trained models is a significant,
under-explored source of error in fair classification. In practice, the
variance on some data examples is so large that decisions can be effectively
arbitrary. To investigate this problem, we take an experimental approach and
make four overarching contributions: We 1) Define a metric called
self-consistency, derived from variance, which we use as a proxy for measuring
and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains
from classification when a prediction would be arbitrary; 3) Conduct the
largest to-date empirical study of the role of variance (vis-a-vis
self-consistency and arbitrariness) in fair classification; and, 4) Release a
toolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily
usable for future research. Altogether, our experiments reveal shocking
insights about the reliability of conclusions on benchmark datasets. Most
fairness classification benchmarks are close-to-fair when taking into account
the amount of arbitrariness present in predictions -- before we even try to
apply common fairness interventions. This finding calls into question the
practical utility of common algorithmic fairness methods, and in turn suggests
that we should fundamentally reconsider how we choose to measure fairness in
machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1&quot;&gt;A. Feder Cooper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Katherine Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choksi_M/0/1/0/all/0/1&quot;&gt;Madiha Choksi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barocas_S/0/1/0/all/0/1&quot;&gt;Solon Barocas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1&quot;&gt;Christopher De Sa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grimmelmann_J/0/1/0/all/0/1&quot;&gt;James Grimmelmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1&quot;&gt;Jon Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1&quot;&gt;Siddhartha Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Baobao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.06807">
<title>Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space. (arXiv:2302.06807v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2302.06807</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperbolic spaces have been quite popular in the recent past for representing
hierarchically organized data. Further, several classification algorithms for
data in these spaces have been proposed in the literature. These algorithms
mainly use either hyperplanes or geodesics for decision boundaries in a large
margin classifiers setting leading to a non-convex optimization problem. In
this paper, we propose a novel large margin classifier based on horospherical
decision boundaries that leads to a geodesically convex optimization problem
that can be optimized using any Riemannian gradient descent technique
guaranteeing a globally optimal solution. We present several experiments
depicting the competitive performance of our classifier in comparison to SOTA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_X/0/1/0/all/0/1&quot;&gt;Xiran Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chun-Hao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vemuri_B/0/1/0/all/0/1&quot;&gt;Baba C. Vemuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.09976">
<title>Discouraging posterior collapse in hierarchical Variational Autoencoders using context. (arXiv:2302.09976v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.09976</link>
<description rdf:parseType="Literal">&lt;p&gt;Hierarchical Variational Autoencoders (VAEs) are among the most popular
likelihood-based generative models. There is a consensus that the top-down
hierarchical VAEs allow effective learning of deep latent structures and avoid
problems like posterior collapse. Here, we show that this is not necessarily
the case, and the problem of collapsing posteriors remains. To discourage this
issue, we propose a deep hierarchical VAE with a context on top. Specifically,
we use a Discrete Cosine Transform to obtain the last latent variable. In a
series of experiments, we observe that the proposed modification allows us to
achieve better utilization of the latent space and does not harm the model&apos;s
generative abilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuzina_A/0/1/0/all/0/1&quot;&gt;Anna Kuzina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1&quot;&gt;Jakub M. Tomczak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.00031">
<title>Tiny Classifier Circuits: Evolving Accelerators for Tabular Data. (arXiv:2303.00031v2 [cs.AR] UPDATED)</title>
<link>http://arxiv.org/abs/2303.00031</link>
<description rdf:parseType="Literal">&lt;p&gt;A typical machine learning (ML) development cycle for edge computing is to
maximise the performance during model training and then minimise the
memory/area footprint of the trained model for deployment on edge devices
targeting CPUs, GPUs, microcontrollers, or custom hardware accelerators. This
paper proposes a methodology for automatically generating predictor circuits
for classification of tabular data with comparable prediction performance to
conventional ML techniques while using substantially fewer hardware resources
and power. The proposed methodology uses an evolutionary algorithm to search
over the space of logic gates and automatically generates a classifier circuit
with maximised training prediction accuracy. Classifier circuits are so tiny
(i.e., consisting of no more than 300 logic gates) that they are called &quot;Tiny
Classifier&quot; circuits, and can efficiently be implemented in ASIC or on an FPGA.
We empirically evaluate the automatic Tiny Classifier circuit generation
methodology or &quot;Auto Tiny Classifiers&quot; on a wide range of tabular datasets, and
compare it against conventional ML techniques such as Amazon&apos;s AutoGluon,
Google&apos;s TabNet and a neural search over Multi-Layer Perceptrons. Despite Tiny
Classifiers being constrained to a few hundred logic gates, we observe no
statistically significant difference in prediction performance in comparison to
the best-performing ML baseline. When synthesised as a Silicon chip, Tiny
Classifiers use 8-18x less area and 4-8x less power. When implemented as an
ultra-low cost chip on a flexible substrate (i.e., FlexIC), they occupy 10-75x
less area and consume 13-75x less power compared to the most hardware-efficient
ML baseline. On an FPGA, Tiny Classifiers consume 3-11x fewer resources.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iordanou_K/0/1/0/all/0/1&quot;&gt;Konstantinos Iordanou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atkinson_T/0/1/0/all/0/1&quot;&gt;Timothy Atkinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozer_E/0/1/0/all/0/1&quot;&gt;Emre Ozer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kufel_J/0/1/0/all/0/1&quot;&gt;Jedrzej Kufel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biggs_J/0/1/0/all/0/1&quot;&gt;John Biggs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_G/0/1/0/all/0/1&quot;&gt;Gavin Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lujan_M/0/1/0/all/0/1&quot;&gt;Mikel Lujan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.12414">
<title>Delay-Aware Hierarchical Federated Learning. (arXiv:2303.12414v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.12414</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning has gained popularity as a means of training models
distributed across the wireless edge. The paper introduces delay-aware
hierarchical federated learning (DFL) to improve the efficiency of distributed
machine learning (ML) model training by accounting for communication delays
between edge and cloud. Different from traditional federated learning, DFL
leverages multiple stochastic gradient descent iterations on local datasets
within each global aggregation period and intermittently aggregates model
parameters through edge servers in local subnetworks. During global
synchronization, the cloud server consolidates local models with the outdated
global model using a local-global combiner, thus preserving crucial elements of
both, enhancing learning efficiency under the presence of delay. A set of
conditions is obtained to achieve the sub-linear convergence rate of O(1/k) for
strongly convex and smooth loss functions. Based on these findings, an adaptive
control algorithm is developed for DFL, implementing policies to mitigate
energy consumption and communication latency while aiming for sublinear
convergence. Numerical evaluations show DFL&apos;s superior performance in terms of
faster global model convergence, reduced resource consumption, and robustness
against communication delays compared to existing FL algorithms. In summary,
this proposed method offers improved efficiency and results when dealing with
both convex and non-convex loss functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1&quot;&gt;Frank Po-Chen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1&quot;&gt;Seyyedali Hosseinalipour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michelusi_N/0/1/0/all/0/1&quot;&gt;Nicol&amp;#xf2; Michelusi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1&quot;&gt;Christopher Brinton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.16296">
<title>Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels. (arXiv:2303.16296v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.16296</link>
<description rdf:parseType="Literal">&lt;p&gt;The soft Dice loss (SDL) has taken a pivotal role in numerous automated
segmentation pipelines in the medical imaging community. Over the last years,
some reasons behind its superior functioning have been uncovered and further
optimizations have been explored. However, there is currently no implementation
that supports its direct utilization in scenarios involving soft labels. Hence,
a synergy between the use of SDL and research leveraging the use of soft
labels, also in the context of model calibration, is still missing. In this
work, we introduce Dice semimetric losses (DMLs), which (i) are by design
identical to SDL in a standard setting with hard labels, but (ii) can be
employed in settings with soft labels. Our experiments on the public QUBIQ,
LiTS and KiTS benchmarks confirm the potential synergy of DMLs with soft labels
(e.g.\ averaging, label smoothing, and knowledge distillation) over hard labels
(e.g.\ majority voting and random selection). As a result, we obtain superior
Dice scores and model calibration, which supports the wider adoption of DMLs in
practice. The code is available at
\href{https://github.com/zifuwanggg/JDTLosses}{https://github.com/zifuwanggg/JDTLosses}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zifu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popordanoska_T/0/1/0/all/0/1&quot;&gt;Teodora Popordanoska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertels_J/0/1/0/all/0/1&quot;&gt;Jeroen Bertels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lemmens_R/0/1/0/all/0/1&quot;&gt;Robin Lemmens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blaschko_M/0/1/0/all/0/1&quot;&gt;Matthew B. Blaschko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.04934">
<title>Model Sparsity Can Simplify Machine Unlearning. (arXiv:2304.04934v8 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.04934</link>
<description rdf:parseType="Literal">&lt;p&gt;In response to recent data regulation requirements, machine unlearning (MU)
has emerged as a critical process to remove the influence of specific examples
from a given model. Although exact unlearning can be achieved through complete
model retraining using the remaining dataset, the associated computational
costs have driven the development of efficient, approximate unlearning
techniques. Moving beyond data-centric MU approaches, our study introduces a
novel model-based perspective: model sparsification via weight pruning, which
is capable of reducing the gap between exact unlearning and approximate
unlearning. We show in both theory and practice that model sparsity can boost
the multi-criteria unlearning performance of an approximate unlearner, closing
the approximation gap, while continuing to be efficient. This leads to a new MU
paradigm, termed prune first, then unlearn, which infuses a sparse model prior
into the unlearning process. Building on this insight, we also develop a
sparsity-aware unlearning method that utilizes sparsity regularization to
enhance the training process of approximate unlearning. Extensive experiments
show that our proposals consistently benefit MU in various unlearning
scenarios. A notable highlight is the 77% unlearning efficacy gain of
fine-tuning (one of the simplest unlearning methods) when using sparsity-aware
unlearning. Furthermore, we demonstrate the practical impact of our proposed MU
methods in addressing other machine learning challenges, such as defending
against backdoor attacks and enhancing transfer learning. Codes are available
at https://github.com/OPTML-Group/Unlearn-Sparse.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1&quot;&gt;Jinghan Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiancheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1&quot;&gt;Parikshit Ram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yuguang Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Gaowen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1&quot;&gt;Pranay Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.06366">
<title>IBIA: An Incremental Build-Infer-Approximate Framework for Approximate Inference of Partition Function. (arXiv:2304.06366v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2304.06366</link>
<description rdf:parseType="Literal">&lt;p&gt;Exact computation of the partition function is known to be intractable,
necessitating approximate inference techniques. Existing methods for
approximate inference are slow to converge for many benchmarks. The control of
accuracy-complexity trade-off is also non-trivial in many of these methods. We
propose a novel incremental build-infer-approximate (IBIA) framework for
approximate inference that addresses these issues. In this framework, the
probabilistic graphical model is converted into a sequence of clique tree
forests (SCTF) with bounded clique sizes. We show that the SCTF can be used to
efficiently compute the partition function. We propose two new algorithms which
are used to construct the SCTF and prove the correctness of both. The first is
an algorithm for incremental construction of CTFs that is guaranteed to give a
valid CTF with bounded clique sizes and the second is an approximation
algorithm that takes a calibrated CTF as input and yields a valid and
calibrated CTF with reduced clique sizes as the output. We have evaluated our
method using several benchmark sets from recent UAI competitions and our
results show good accuracies with competitive runtimes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bathla_S/0/1/0/all/0/1&quot;&gt;Shivani Bathla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1&quot;&gt;Vinita Vasudevan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.12405">
<title>Synthesizing Stable Reduced-Order Visuomotor Policies for Nonlinear Systems via Sums-of-Squares Optimization. (arXiv:2304.12405v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2304.12405</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for synthesizing dynamic, reduced-order output-feedback
polynomial control policies for control-affine nonlinear systems which
guarantees runtime stability to a goal state, when using visual observations
and a learned perception module in the feedback control loop. We leverage
Lyapunov analysis to formulate the problem of synthesizing such policies. This
problem is nonconvex in the policy parameters and the Lyapunov function that is
used to prove the stability of the policy. To solve this problem approximately,
we propose two approaches: the first solves a sequence of sum-of-squares
optimization problems to iteratively improve a policy which is provably-stable
by construction, while the second directly performs gradient-based optimization
on the parameters of the polynomial policy, and its closed-loop stability is
verified a posteriori. We extend our approach to provide stability guarantees
in the presence of observation noise, which realistically arises due to errors
in the learned perception module. We evaluate our approach on several
underactuated nonlinear systems, including pendula and quadrotors, showing that
our guarantees translate to empirical stability when controlling these systems
from images, while baseline approaches can fail to reliably stabilize the
system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chou_G/0/1/0/all/0/1&quot;&gt;Glen Chou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tedrake_R/0/1/0/all/0/1&quot;&gt;Russ Tedrake&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.12586">
<title>Unsupervised Discovery of Extreme Weather Events Using Universal Representations of Emergent Organization. (arXiv:2304.12586v2 [physics.comp-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2304.12586</link>
<description rdf:parseType="Literal">&lt;p&gt;Spontaneous self-organization is ubiquitous in systems far from thermodynamic
equilibrium. While organized structures that emerge dominate transport
properties, universal representations that identify and describe these key
objects remain elusive. Here, we introduce a theoretically-grounded framework
for describing emergent organization that, via data-driven algorithms, is
constructive in practice. Its building blocks are spacetime lightcones that
embody how information propagates across a system through local interactions.
We show that predictive equivalence classes of lightcones -- local causal
states -- capture organized behaviors and coherent structures in complex
spatiotemporal systems. Employing an unsupervised physics-informed machine
learning algorithm and a high-performance computing implementation, we
demonstrate automatically discovering coherent structures in two real world
domain science problems. We show that local causal states identify vortices and
track their power-law decay behavior in two-dimensional fluid turbulence. We
then show how to detect and track familiar extreme weather events -- hurricanes
and atmospheric rivers -- and discover other novel coherent structures
associated with precipitation extremes in high-resolution climate data at the
grid-cell level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rupe_A/0/1/0/all/0/1&quot;&gt;Adam Rupe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kashinath_K/0/1/0/all/0/1&quot;&gt;Karthik Kashinath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kumar_N/0/1/0/all/0/1&quot;&gt;Nalini Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Crutchfield_J/0/1/0/all/0/1&quot;&gt;James P. Crutchfield&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.03942">
<title>HACMan: Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation. (arXiv:2305.03942v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2305.03942</link>
<description rdf:parseType="Literal">&lt;p&gt;Manipulating objects without grasping them is an essential component of human
dexterity, referred to as non-prehensile manipulation. Non-prehensile
manipulation may enable more complex interactions with the objects, but also
presents challenges in reasoning about gripper-object interactions. In this
work, we introduce Hybrid Actor-Critic Maps for Manipulation (HACMan), a
reinforcement learning approach for 6D non-prehensile manipulation of objects
using point cloud observations. HACMan proposes a temporally-abstracted and
spatially-grounded object-centric action representation that consists of
selecting a contact location from the object point cloud and a set of motion
parameters describing how the robot will move after making contact. We modify
an existing off-policy RL algorithm to learn in this hybrid discrete-continuous
action representation. We evaluate HACMan on a 6D object pose alignment task in
both simulation and in the real world. On the hardest version of our task, with
randomized initial poses, randomized 6D goals, and diverse object categories,
our policy demonstrates strong generalization to unseen object categories
without a performance drop, achieving an 89% success rate on unseen objects in
simulation and 50% success rate with zero-shot transfer in the real world.
Compared to alternative action representations, HACMan achieves a success rate
more than three times higher than the best baseline. With zero-shot sim2real
transfer, our policy can successfully manipulate unseen objects in the real
world for challenging non-planar goals, using dynamic and contact-rich
non-prehensile skills. Videos can be found on the project website:
https://hacman-2023.github.io.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wenxuan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1&quot;&gt;Bowen Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Fan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1&quot;&gt;Chris Paxton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1&quot;&gt;David Held&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.04811">
<title>Deep learning models for price forecasting of financial time series: A review of recent advancements: 2020-2022. (arXiv:2305.04811v2 [q-fin.ST] UPDATED)</title>
<link>http://arxiv.org/abs/2305.04811</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurately predicting the prices of financial time series is essential and
challenging for the financial sector. Owing to recent advancements in deep
learning techniques, deep learning models are gradually replacing traditional
statistical and machine learning models as the first choice for price
forecasting tasks. This shift in model selection has led to a notable rise in
research related to applying deep learning models to price forecasting,
resulting in a rapid accumulation of new knowledge. Therefore, we conducted a
literature review of relevant studies over the past three years with a view to
aiding researchers and practitioners in the field. This review delves deeply
into deep learning-based forecasting models, presenting information on model
architectures, practical applications, and their respective advantages and
disadvantages. In particular, detailed information is provided on advanced
models for price forecasting, such as Transformers, generative adversarial
networks (GANs), graph neural networks (GNNs), and deep quantum neural networks
(DQNNs). The present contribution also includes potential directions for future
research, such as examining the effectiveness of deep learning models with
complex structures for price forecasting, extending from point prediction to
interval prediction using deep learning models, scrutinising the reliability
and validity of decomposition ensembles, and exploring the influence of data
volume on model performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Sjarif_N/0/1/0/all/0/1&quot;&gt;Nilam Nur Amir Sjarif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Ibrahim_R/0/1/0/all/0/1&quot;&gt;Roslina Ibrahim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.04866">
<title>Causal Policy Gradient for Whole-Body Mobile Manipulation. (arXiv:2305.04866v4 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2305.04866</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing the next generation of household robot helpers requires combining
locomotion and interaction capabilities, which is generally referred to as
mobile manipulation (MoMa). MoMa tasks are difficult due to the large action
space of the robot and the common multi-objective nature of the task, e.g.,
efficiently reaching a goal while avoiding obstacles. Current approaches often
segregate tasks into navigation without manipulation and stationary
manipulation without locomotion by manually matching parts of the action space
to MoMa sub-objectives (e.g. learning base actions for locomotion objectives
and learning arm actions for manipulation). This solution prevents simultaneous
combinations of locomotion and interaction degrees of freedom and requires
human domain knowledge for both partitioning the action space and matching the
action parts to the sub-objectives. In this paper, we introduce Causal MoMa, a
new reinforcement learning framework to train policies for typical MoMa tasks
that makes use of the most favorable subspace of the robot&apos;s action space to
address each sub-objective. Causal MoMa automatically discovers the causal
dependencies between actions and terms of the reward function and exploits
these dependencies through causal policy gradient that reduces gradient
variance compared to previous state-of-the-art reinforcement learning
algorithms, improving convergence and results. We evaluate the performance of
Causal MoMa on three types of simulated robots across different MoMa tasks and
demonstrate success in transferring the policies trained in simulation directly
to a real robot, where our agent is able to follow moving goals and react to
dynamic obstacles while simultaneously and synergistically controlling the
whole-body: base, arm, and head. More information at
https://sites.google.com/view/causal-moma.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jiaheng Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1&quot;&gt;Peter Stone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1&quot;&gt;Roberto Mart&amp;#xed;n-Mart&amp;#xed;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.10775">
<title>Enhancing Speech Articulation Analysis using a Geometric Transformation of the X-ray Microbeam Dataset. (arXiv:2305.10775v3 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/2305.10775</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate analysis of speech articulation is crucial for speech analysis.
However, X-Y coordinates of articulators strongly depend on the anatomy of the
speakers and the variability of pellet placements, and existing methods for
mapping anatomical landmarks in the X-ray Microbeam Dataset (XRMB) fail to
capture the entire anatomy of the vocal tract. In this paper, we propose a new
geometric transformation that improves the accuracy of these measurements. Our
transformation maps anatomical landmarks&apos; X-Y coordinates along the midsagittal
plane onto six relative measures: Lip Aperture (LA), Lip Protusion (LP), Tongue
Body Constriction Location (TTCL), Degree (TBCD), Tongue Tip Constriction
Location (TTCL) and Degree (TTCD). Our novel contribution is the extension of
the palate trace towards the inferred anterior pharyngeal line, which improves
measurements of tongue body constriction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Attia_A/0/1/0/all/0/1&quot;&gt;Ahmed Adel Attia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tiede_M/0/1/0/all/0/1&quot;&gt;Mark Tiede&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Espy_Wilson_C/0/1/0/all/0/1&quot;&gt;Carol Y. Espy-Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.16912">
<title>Disambiguated Attention Embedding for Multi-Instance Partial-Label Learning. (arXiv:2305.16912v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.16912</link>
<description rdf:parseType="Literal">&lt;p&gt;In many real-world tasks, the concerned objects can be represented as a
multi-instance bag associated with a candidate label set, which consists of one
ground-truth label and several false positive labels. Multi-instance
partial-label learning (MIPL) is a learning paradigm to deal with such tasks
and has achieved favorable performances. Existing MIPL approach follows the
instance-space paradigm by assigning augmented candidate label sets of bags to
each instance and aggregating bag-level labels from instance-level labels.
However, this scheme may be suboptimal as global bag-level information is
ignored and the predicted labels of bags are sensitive to predictions of
negative instances. In this paper, we study an alternative scheme where a
multi-instance bag is embedded into a single vector representation.
Accordingly, an intuitive algorithm named DEMIPL, i.e., Disambiguated attention
Embedding for Multi-Instance Partial-Label learning, is proposed. DEMIPL
employs a disambiguation attention mechanism to aggregate a multi-instance bag
into a single vector representation, followed by a momentum-based
disambiguation strategy to identify the ground-truth label from the candidate
label set. Furthermore, we introduce a real-world MIPL dataset for colorectal
cancer classification. Experimental results on benchmark and real-world
datasets validate the superiority of DEMIPL against the compared MIPL and
partial-label learning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1&quot;&gt;Wei Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weijia Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Min-Ling Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.18471">
<title>Convergence of AdaGrad for Non-convex Objectives: Simple Proofs and Relaxed Assumptions. (arXiv:2305.18471v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.18471</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide a simple convergence proof for AdaGrad optimizing non-convex
objectives under only affine noise variance and bounded smoothness assumptions.
The proof is essentially based on a novel auxiliary function $\xi$ that helps
eliminate the complexity of handling the correlation between the numerator and
denominator of AdaGrad&apos;s update. Leveraging simple proofs, we are able to
obtain tighter results than existing results \citep{faw2022power} and extend
the analysis to several new and important cases. Specifically, for the
over-parameterized regime, we show that AdaGrad needs only
$\mathcal{O}(\frac{1}{\varepsilon^2})$ iterations to ensure the gradient norm
smaller than $\varepsilon$, which matches the rate of SGD and significantly
tighter than existing rates $\mathcal{O}(\frac{1}{\varepsilon^4})$ for AdaGrad.
We then discard the bounded smoothness assumption and consider a realistic
assumption on smoothness called $(L_0,L_1)$-smooth condition, which allows
local smoothness to grow with the gradient norm. Again based on the auxiliary
function $\xi$, we prove that AdaGrad succeeds in converging under
$(L_0,L_1)$-smooth condition as long as the learning rate is lower than a
threshold. Interestingly, we further show that the requirement on learning rate
under the $(L_0,L_1)$-smooth condition is necessary via proof by contradiction,
in contrast with the case of uniform smoothness conditions where convergence is
guaranteed regardless of learning rate choices. Together, our analyses broaden
the understanding of AdaGrad and demonstrate the power of the new auxiliary
function in the investigations of AdaGrad.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bohan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huishuai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zhi-Ming Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.05805">
<title>DynaBench: A benchmark dataset for learning dynamical systems from low-resolution data. (arXiv:2306.05805v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.05805</link>
<description rdf:parseType="Literal">&lt;p&gt;Previous work on learning physical systems from data has focused on
high-resolution grid-structured measurements. However, real-world knowledge of
such systems (e.g. weather data) relies on sparsely scattered measuring
stations. In this paper, we introduce a novel simulated benchmark dataset,
DynaBench, for learning dynamical systems directly from sparsely scattered data
without prior knowledge of the equations. The dataset focuses on predicting the
evolution of a dynamical system from low-resolution, unstructured measurements.
We simulate six different partial differential equations covering a variety of
physical systems commonly used in the literature and evaluate several machine
learning models, including traditional graph neural networks and point cloud
processing models, with the task of predicting the evolution of the system. The
proposed benchmark dataset is expected to advance the state of art as an
out-of-the-box easy-to-use tool for evaluating models in a setting where only
unstructured low-resolution observations are available. The benchmark is
available at https://anonymous.4open.science/r/code-2022-dynabench/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dulny_A/0/1/0/all/0/1&quot;&gt;Andrzej Dulny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hotho_A/0/1/0/all/0/1&quot;&gt;Andreas Hotho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Anna Krause&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.15891">
<title>Capturing the Diffusive Behavior of the Multiscale Linear Transport Equations by Asymptotic-Preserving Convolutional DeepONets. (arXiv:2306.15891v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.15891</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce two types of novel Asymptotic-Preserving
Convolutional Deep Operator Networks (APCONs) designed to address the
multiscale time-dependent linear transport problem. We observe that the vanilla
physics-informed DeepONets with modified MLP may exhibit instability in
maintaining the desired limiting macroscopic behavior. Therefore, this
necessitates the utilization of an asymptotic-preserving loss function. Drawing
inspiration from the heat kernel in the diffusion equation, we propose a new
architecture called Convolutional Deep Operator Networks, which employ multiple
local convolution operations instead of a global heat kernel, along with
pooling and activation operations in each filter layer. Our APCON methods
possess a parameter count that is independent of the grid size and are capable
of capturing the diffusive behavior of the linear transport problem. Finally,
we validate the effectiveness of our methods through several numerical
examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1&quot;&gt;Keke Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1&quot;&gt;Xiong-bin Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1&quot;&gt;Shi Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zheng Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.01026">
<title>Temporal Graph Benchmark for Machine Learning on Temporal Graphs. (arXiv:2307.01026v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.01026</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the Temporal Graph Benchmark (TGB), a collection of challenging
and diverse benchmark datasets for realistic, reproducible, and robust
evaluation of machine learning models on temporal graphs. TGB datasets are of
large scale, spanning years in duration, incorporate both node and edge-level
prediction tasks and cover a diverse set of domains including social, trade,
transaction, and transportation networks. For both tasks, we design evaluation
protocols based on realistic use-cases. We extensively benchmark each dataset
and find that the performance of common models can vary drastically across
datasets. In addition, on dynamic node property prediction tasks, we show that
simple methods often achieve superior performance compared to existing temporal
graph models. We believe that these findings open up opportunities for future
research on temporal graphs. Finally, TGB provides an automated machine
learning pipeline for reproducible and accessible temporal graph research,
including data loading, experiment setup and performance evaluation. TGB will
be maintained and updated on a regular basis and welcomes community feedback.
TGB datasets, data loaders, example codes, evaluation setup, and leaderboards
are publicly available at https://tgb.complexdatalab.com/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shenyang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poursafaei_F/0/1/0/all/0/1&quot;&gt;Farimah Poursafaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Danovitch_J/0/1/0/all/0/1&quot;&gt;Jacob Danovitch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fey_M/0/1/0/all/0/1&quot;&gt;Matthias Fey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Weihua Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossi_E/0/1/0/all/0/1&quot;&gt;Emanuele Rossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1&quot;&gt;Michael Bronstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1&quot;&gt;Guillaume Rabusseau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabbany_R/0/1/0/all/0/1&quot;&gt;Reihaneh Rabbany&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02245">
<title>Set Learning for Accurate and Calibrated Models. (arXiv:2307.02245v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02245</link>
<description rdf:parseType="Literal">&lt;p&gt;Model overconfidence and poor calibration are common in machine learning and
difficult to account for when applying standard empirical risk minimization. In
this work, we propose a novel method to alleviate these problems that we call
odd-$k$-out learning (OKO), which minimizes the cross-entropy error for sets
rather than for single examples. This naturally allows the model to capture
correlations across data examples and achieves both better accuracy and
calibration, especially in limited training data and class-imbalanced regimes.
Perhaps surprisingly, OKO often yields better calibration even when training
with hard labels and dropping any additional calibration parameter tuning, such
as temperature scaling. We provide theoretical justification, establishing that
OKO naturally yields better calibration, and provide extensive experimental
analyses that corroborate our theoretical findings. We emphasize that OKO is a
general framework that can be easily adapted to many settings and the trained
model can be applied to single examples at inference time, without introducing
significant run-time overhead or architecture changes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muttenthaler_L/0/1/0/all/0/1&quot;&gt;Lukas Muttenthaler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vandermeulen_R/0/1/0/all/0/1&quot;&gt;Robert A. Vandermeulen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qiuyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1&quot;&gt;Thomas Unterthiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1&quot;&gt;Klaus-Robert M&amp;#xfc;ller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.04870">
<title>RACH-Space: Reconstructing Adaptive Convex Hull Space with applications in weak supervision. (arXiv:2307.04870v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.04870</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce RACH-Space, a novel classification method in ensemble learning.
In particular, we show its applicability as a label model for weakly supervised
learning. RACH-Space offers simplicity in implementation with minimal
assumptions on the data or weak signals. The model is well suited for scenarios
where fully labeled data is not available. Our method is built upon geometrical
interpretation of the space spanned by weak signals. Our analysis of the high
dimensional convex hull structure underlying general set of weak signals
bridges geometry with machine learning. Empirical results also demonstrate that
RACH-Space works well in practice and compares favorably to best existing label
models for weakly supervised learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Na_W/0/1/0/all/0/1&quot;&gt;Woojoo Na&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.06822">
<title>TinyMetaFed: Efficient Federated Meta-Learning for TinyML. (arXiv:2307.06822v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.06822</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of Tiny Machine Learning (TinyML) has made substantial advancements
in democratizing machine learning on low-footprint devices, such as
microcontrollers. The prevalence of these miniature devices raises the question
of whether aggregating their knowledge can benefit TinyML applications.
Federated meta-learning is a promising answer to this question, as it addresses
the scarcity of labeled data and heterogeneous data distribution across devices
in the real world. However, deploying TinyML hardware faces unique resource
constraints, making existing methods impractical due to energy, privacy, and
communication limitations. We introduce TinyMetaFed, a model-agnostic
meta-learning framework suitable for TinyML. TinyMetaFed facilitates
collaborative training of a neural network initialization that can be quickly
fine-tuned on new devices. It offers communication savings and privacy
protection through partial local reconstruction and Top-P% selective
communication, computational efficiency via online learning, and robustness to
client heterogeneity through few-shot learning. The evaluations on three TinyML
use cases demonstrate that TinyMetaFed can significantly reduce energy
consumption and communication overhead, accelerate convergence, and stabilize
the training process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1&quot;&gt;Haoyu Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xue Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anicic_D/0/1/0/all/0/1&quot;&gt;Darko Anicic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Runkler_T/0/1/0/all/0/1&quot;&gt;Thomas A. Runkler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.08079">
<title>Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2307.08079</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world processes have complex tail dependence structures that cannot
be characterized using classical Gaussian processes. More flexible spatial
extremes models exhibit appealing extremal dependence properties but are often
exceedingly prohibitive to fit and simulate from in high dimensions. In this
paper, we develop a new spatial extremes model that has flexible and
non-stationary dependence properties, and we integrate it in the
encoding-decoding structure of a variational autoencoder (XVAE), whose
parameters are estimated via variational Bayes combined with deep learning. The
XVAE can be used as a spatio-temporal emulator that characterizes the
distribution of potential mechanistic model output states and produces outputs
that have the same statistical properties as the inputs, especially in the
tail. As an aside, our approach also provides a novel way of making fast
inference with complex extreme-value processes. Through extensive simulation
studies, we show that our XVAE is substantially more time-efficient than
traditional Bayesian inference while also outperforming many spatial extremes
models with a stationary dependence structure. To further demonstrate the
computational power of the XVAE, we analyze a high-resolution satellite-derived
dataset of sea surface temperature in the Red Sea, which includes 30 years of
daily measurements at 16703 grid cells. We find that the extremal dependence
strength is weaker in the interior of Red Sea and it has decreased slightly
over time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Likun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wikle_C/0/1/0/all/0/1&quot;&gt;Christopher K. Wikle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huser_R/0/1/0/all/0/1&quot;&gt;Rapha&amp;#xeb;l Huser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.12499">
<title>AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion Models. (arXiv:2307.12499v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.12499</link>
<description rdf:parseType="Literal">&lt;p&gt;Unrestricted adversarial attacks present a serious threat to deep learning
models and adversarial defense techniques. They pose severe security problems
for deep learning applications because they can effectively bypass defense
mechanisms. However, previous attack methods often utilize Generative
Adversarial Networks (GANs), which are not theoretically provable and thus
generate unrealistic examples by incorporating adversarial objectives,
especially for large-scale datasets like ImageNet. In this paper, we propose a
new method, called AdvDiff, to generate unrestricted adversarial examples with
diffusion models. We design two novel adversarial guidance techniques to
conduct adversarial sampling in the reverse generation process of diffusion
models. These two techniques are effective and stable to generate high-quality,
realistic adversarial examples by integrating gradients of the target
classifier interpretably. Experimental results on MNIST and ImageNet datasets
demonstrate that AdvDiff is effective to generate unrestricted adversarial
examples, which outperforms GAN-based methods in terms of attack performance
and generation quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1&quot;&gt;Xuelong Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1&quot;&gt;Kaisheng Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1&quot;&gt;Bin Xiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.16735">
<title>Lossless Transformations and Excess Risk Bounds in Statistical Inference. (arXiv:2307.16735v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/2307.16735</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the excess minimum risk in statistical inference, defined as the
difference between the minimum expected loss in estimating a random variable
from an observed feature vector and the minimum expected loss in estimating the
same random variable from a transformation (statistic) of the feature vector.
After characterizing lossless transformations, i.e., transformations for which
the excess risk is zero for all loss functions, we construct a partitioning
test statistic for the hypothesis that a given transformation is lossless and
show that for i.i.d. data the test is strongly consistent. More generally, we
develop information-theoretic upper bounds on the excess risk that uniformly
hold over fairly general classes of loss functions. Based on these bounds, we
introduce the notion of a delta-lossless transformation and give sufficient
conditions for a given transformation to be universally delta-lossless.
Applications to classification, nonparametric regression, portfolio strategies,
information bottleneck, and deep learning, are also surveyed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gyorfi_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe1;szl&amp;#xf3; Gy&amp;#xf6;rfi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Linder_T/0/1/0/all/0/1&quot;&gt;Tam&amp;#xe1;s Linder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walk_H/0/1/0/all/0/1&quot;&gt;Harro Walk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.03666">
<title>Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2308.03666</link>
<description rdf:parseType="Literal">&lt;p&gt;As researchers strive to narrow the gap between machine intelligence and
human through the development of artificial intelligence technologies, it is
imperative that we recognize the critical importance of trustworthiness in
open-world, which has become ubiquitous in all aspects of daily life for
everyone. However, several challenges may create a crisis of trust in current
artificial intelligence systems that need to be bridged: 1) Insufficient
explanation of predictive results; 2) Inadequate generalization for learning
models; 3) Poor adaptability to uncertain environments. Consequently, we
explore a neural program to bridge trustworthiness and open-world learning,
extending from single-modal to multi-modal scenarios for readers. 1) To enhance
design-level interpretability, we first customize trustworthy networks with
specific physical meanings; 2) We then design environmental well-being
task-interfaces via flexible learning regularizers for improving the
generalization of trustworthy learning; 3) We propose to increase the
robustness of trustworthy learning by integrating open-world recognition losses
with agent mechanisms. Eventually, we enhance various trustworthy properties
through the establishment of design-level explainability, environmental
well-being task-interfaces and open-world recognition programs. These designed
open-world protocols are applicable across a wide range of surroundings, under
open-world multimedia recognition scenarios with significant performance
improvements observed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Shide Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fang_Z/0/1/0/all/0/1&quot;&gt;Zihan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lan_S/0/1/0/all/0/1&quot;&gt;Shiyang Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tan_Y/0/1/0/all/0/1&quot;&gt;Yanchao Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gunther_M/0/1/0/all/0/1&quot;&gt;Manuel G&amp;#xfc;nther&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shiping Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guo_W/0/1/0/all/0/1&quot;&gt;Wenzhong Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.04412">
<title>Probabilistic Invariant Learning with Randomized Linear Classifiers. (arXiv:2308.04412v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.04412</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing models that are both expressive and preserve known invariances of
tasks is an increasingly hard problem. Existing solutions tradeoff invariance
for computational or memory resources. In this work, we show how to leverage
randomness and design models that are both expressive and invariant but use
less resources. Inspired by randomized algorithms, our key insight is that
accepting probabilistic notions of universal approximation and invariance can
reduce our resource requirements. More specifically, we propose a class of
binary classification models called Randomized Linear Classifiers (RLCs). We
give parameter and sample size conditions in which RLCs can, with high
probability, approximate any (smooth) function while preserving invariance to
compact group transformations. Leveraging this result, we design three RLCs
that are provably probabilistic invariant for classification tasks over sets,
graphs, and spherical data. We show how these models can achieve probabilistic
invariance and universality using less resources than (deterministic) neural
networks and their invariant counterparts. Finally, we empirically demonstrate
the benefits of this new class of models on invariant tasks where deterministic
invariant neural networks are known to struggle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotta_L/0/1/0/all/0/1&quot;&gt;Leonardo Cotta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yehuda_G/0/1/0/all/0/1&quot;&gt;Gal Yehuda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuster_A/0/1/0/all/0/1&quot;&gt;Assaf Schuster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1&quot;&gt;Chris J. Maddison&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.05034">
<title>Kairos: Practical Intrusion Detection and Investigation using Whole-system Provenance. (arXiv:2308.05034v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2308.05034</link>
<description rdf:parseType="Literal">&lt;p&gt;Provenance graphs are structured audit logs that describe the history of a
system&apos;s execution. Recent studies have explored a variety of techniques to
analyze provenance graphs for automated host intrusion detection, focusing
particularly on advanced persistent threats. Sifting through their design
documents, we identify four common dimensions that drive the development of
provenance-based intrusion detection systems (PIDSes): scope (can PIDSes detect
modern attacks that infiltrate across application boundaries?), attack
agnosticity (can PIDSes detect novel attacks without a priori knowledge of
attack characteristics?), timeliness (can PIDSes efficiently monitor host
systems as they run?), and attack reconstruction (can PIDSes distill attack
activity from large provenance graphs so that sysadmins can easily understand
and quickly respond to system intrusion?). We present KAIROS, the first PIDS
that simultaneously satisfies the desiderata in all four dimensions, whereas
existing approaches sacrifice at least one and struggle to achieve comparable
detection performance.
&lt;/p&gt;
&lt;p&gt;Kairos leverages a novel graph neural network-based encoder-decoder
architecture that learns the temporal evolution of a provenance graph&apos;s
structural changes to quantify the degree of anomalousness for each system
event. Then, based on this fine-grained information, Kairos reconstructs attack
footprints, generating compact summary graphs that accurately describe
malicious activity over a stream of system audit logs. Using state-of-the-art
benchmark datasets, we demonstrate that Kairos outperforms previous approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1&quot;&gt;Zijun Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_Q/0/1/0/all/0/1&quot;&gt;Qiujian Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jinyuan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1&quot;&gt;Degang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasquier_T/0/1/0/all/0/1&quot;&gt;Thomas Pasquier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1&quot;&gt;Xueyuan Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.10425">
<title>STAEformer: Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting. (arXiv:2308.10425v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.10425</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid development of the Intelligent Transportation System (ITS),
accurate traffic forecasting has emerged as a critical challenge. The key
bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In
recent years, numerous neural networks with complicated architectures have been
proposed to address this issue. However, the advancements in network
architectures have encountered diminishing performance gains. In this study, we
present a novel component called spatio-temporal adaptive embedding that can
yield outstanding results with vanilla transformers. Our proposed
Spatio-Temporal Adaptive Embedding transformer (STAEformer) achieves
state-of-the-art performance on five real-world traffic forecasting datasets.
Further experiments demonstrate that spatio-temporal adaptive embedding plays a
crucial role in traffic forecasting by effectively capturing intrinsic
spatio-temporal relations and chronological information in traffic time series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hangchen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1&quot;&gt;Zheng Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Renhe Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1&quot;&gt;Jiewen Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1&quot;&gt;Jinliang Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Quanjun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1&quot;&gt;Xuan Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.13104">
<title>Contrastive Learning of Temporal Distinctiveness for Survival Analysis in Electronic Health Records. (arXiv:2308.13104v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.13104</link>
<description rdf:parseType="Literal">&lt;p&gt;Survival analysis plays a crucial role in many healthcare decisions, where
the risk prediction for the events of interest can support an informative
outlook for a patient&apos;s medical journey. Given the existence of data censoring,
an effective way of survival analysis is to enforce the pairwise temporal
concordance between censored and observed data, aiming to utilize the time
interval before censoring as partially observed time-to-event labels for
supervised learning. Although existing studies mostly employed ranking methods
to pursue an ordering objective, contrastive methods which learn a
discriminative embedding by having data contrast against each other, have not
been explored thoroughly for survival analysis. Therefore, in this paper, we
propose a novel Ontology-aware Temporality-based Contrastive Survival (OTCSurv)
analysis framework that utilizes survival durations from both censored and
observed data to define temporal distinctiveness and construct negative sample
pairs with adjustable hardness for contrastive learning. Specifically, we first
use an ontological encoder and a sequential self-attention encoder to represent
the longitudinal EHR data with rich contexts. Second, we design a temporal
contrastive loss to capture varying survival durations in a supervised setting
through a hardness-aware negative sampling mechanism. Last, we incorporate the
contrastive task into the time-to-event predictive task with multiple loss
components. We conduct extensive experiments using a large EHR dataset to
forecast the risk of hospitalized patients who are in danger of developing
acute kidney injury (AKI), a critical and urgent medical condition. The
effectiveness and explainability of the proposed model are validated through
comprehensive quantitative and qualitative studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kerdabadi_M/0/1/0/all/0/1&quot;&gt;Mohsen Nayebi Kerdabadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moghaddam_A/0/1/0/all/0/1&quot;&gt;Arya Hadizadeh Moghaddam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Mei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1&quot;&gt;Zijun Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.13978">
<title>A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss Function for Combinatorial Optimization using Reinforcement Learning. (arXiv:2308.13978v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/2308.13978</link>
<description rdf:parseType="Literal">&lt;p&gt;Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to
model various NP-hard combinatorial optimization problems in the form of binary
variables. The Hamiltonian function is often used to formulate QUBO problems
where it is used as the objective function in the context of optimization.
Recently, PI-GNN, a generic scalable framework, has been proposed to address
the Combinatorial Optimization (CO) problems over graphs based on a simple
Graph Neural Network (GNN) architecture. Their novel contribution was a generic
QUBO-formulated Hamiltonian-inspired loss function that was optimized using
GNN. In this study, we address a crucial issue related to the aforementioned
setup especially observed in denser graphs. The reinforcement learning-based
paradigm has also been widely used to address numerous CO problems. Here we
also formulate and empirically evaluate the compatibility of the
QUBO-formulated Hamiltonian as the generic reward function in the Reinforcement
Learning paradigm to directly integrate the actual node projection status
during training as the form of rewards. In our experiments, we observed up to
44% improvement in the RL-based setup compared to the PI-GNN algorithm. Our
implementation can be found in
https://github.com/rizveeredwan/learning-graph-structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizvee_R/0/1/0/all/0/1&quot;&gt;Redwan Ahmed Rizvee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Md. Mosaddek Khan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.16900">
<title>Learning to Taste: A Multimodal Wine Dataset. (arXiv:2308.16900v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.16900</link>
<description rdf:parseType="Literal">&lt;p&gt;We present WineSensed, a large multimodal wine dataset for studying the
relations between visual perception, language, and flavor. The dataset
encompasses 897k images of wine labels and 824k reviews of wines curated from
the Vivino platform. It has over 350k unique vintages, annotated with year,
region, rating, alcohol percentage, price, and grape composition. We obtained
fine-grained flavor annotations on a subset by conducting a wine-tasting
experiment with 256 participants who were asked to rank wines based on their
similarity in flavor, resulting in more than 5k pairwise flavor distances. We
propose a low-dimensional concept embedding algorithm that combines human
experience with automatic machine similarity kernels. We demonstrate that this
shared concept embedding space improves upon separate embedding spaces for
coarse flavor classification (alcohol percentage, country, grape, price,
rating) and aligns with the intricate human perception of flavor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bender_T/0/1/0/all/0/1&quot;&gt;Thoranna Bender&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sorensen_S/0/1/0/all/0/1&quot;&gt;Simon Moe S&amp;#xf8;rensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kashani_A/0/1/0/all/0/1&quot;&gt;Alireza Kashani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hjorleifsson_K/0/1/0/all/0/1&quot;&gt;K. Eldjarn Hjorleifsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hyldig_G/0/1/0/all/0/1&quot;&gt;Grethe Hyldig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf8;ren Hauberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1&quot;&gt;Serge Belongie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Warburg_F/0/1/0/all/0/1&quot;&gt;Frederik Warburg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03847">
<title>Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples. (arXiv:2309.03847v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2309.03847</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of estimating mixtures of Gaussians under the constraint
of differential privacy (DP). Our main result is that $\tilde{O}(k^2 d^4
\log(1/\delta) / \alpha^2 \varepsilon)$ samples are sufficient to estimate a
mixture of $k$ Gaussians up to total variation distance $\alpha$ while
satisfying $(\varepsilon, \delta)$-DP. This is the first finite sample
complexity upper bound for the problem that does not make any structural
assumptions on the GMMs.
&lt;/p&gt;
&lt;p&gt;To solve the problem, we devise a new framework which may be useful for other
tasks. On a high level, we show that if a class of distributions (such as
Gaussians) is (1) list decodable and (2) admits a &quot;locally small&apos;&apos; cover (Bun
et al., 2021) with respect to total variation distance, then the class of its
mixtures is privately learnable. The proof circumvents a known barrier
indicating that, unlike Gaussians, GMMs do not admit a locally small cover
(Aden-Ali et al., 2021b).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Afzali_M/0/1/0/all/0/1&quot;&gt;Mohammad Afzali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ashtiani_H/0/1/0/all/0/1&quot;&gt;Hassan Ashtiani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liaw_C/0/1/0/all/0/1&quot;&gt;Christopher Liaw&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.05516">
<title>Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs. (arXiv:2309.05516v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.05516</link>
<description rdf:parseType="Literal">&lt;p&gt;Large Language Models (LLMs) have proven their exceptional capabilities in
performing language-related tasks. However, their deployment poses significant
challenges due to their considerable memory and storage requirements. In
response to this issue, weight-only quantization, particularly 3 and 4-bit
weight-only quantization, has emerged as one of the most viable solutions. As
the number of bits decreases, the quantization grid broadens, thus emphasizing
the importance of up and down rounding. While previous studies have
demonstrated that fine-tuning up and down rounding with the addition of
perturbations can enhance accuracy in some scenarios, our study is driven by
the precise and limited boundary of these perturbations, where only the
threshold for altering the rounding value is of significance. Consequently, we
propose a concise and highly effective approach for optimizing the weight
rounding task. Our method, named SignRound, involves lightweight block-wise
tuning using signed gradient descent, enabling us to achieve outstanding
results within 400 steps. SignRound competes impressively against recent
methods without introducing additional inference overhead. The source code will
be publicly available at \url{https://github.com/intel/neural-compressor} soon.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1&quot;&gt;Wenhua Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weiwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Haihao Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1&quot;&gt;Yiyang Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_K/0/1/0/all/0/1&quot;&gt;Kaokao Lv&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.05525">
<title>Advancing Federated Learning in 6G: A Trusted Architecture with Graph-based Analysis. (arXiv:2309.05525v3 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/2309.05525</link>
<description rdf:parseType="Literal">&lt;p&gt;Integrating native AI support into the network architecture is an essential
objective of 6G. Federated Learning (FL) emerges as a potential paradigm,
facilitating decentralized AI model training across a diverse range of devices
under the coordination of a central server. However, several challenges hinder
its wide application in the 6G context, such as malicious attacks and privacy
snooping on local model updates, and centralization pitfalls. This work
proposes a trusted architecture for supporting FL, which utilizes Distributed
Ledger Technology (DLT) and Graph Neural Network (GNN), including three key
features. First, a pre-processing layer employing homomorphic encryption is
incorporated to securely aggregate local models, preserving the privacy of
individual models. Second, given the distributed nature and graph structure
between clients and nodes in the pre-processing layer, GNN is leveraged to
identify abnormal local models, enhancing system security. Third, DLT is
utilized to decentralize the system by selecting one of the candidates to
perform the central server&apos;s functions. Additionally, DLT ensures reliable data
management by recording data exchanges in an immutable and transparent ledger.
The feasibility of the novel architecture is validated through simulations,
demonstrating improved performance in anomalous model detection and global
model accuracy compared to relevant baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1&quot;&gt;Wenxuan Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1&quot;&gt;Chendi Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+An_X/0/1/0/all/0/1&quot;&gt;Xueli An&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1&quot;&gt;Xueqiang Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carle_G/0/1/0/all/0/1&quot;&gt;Georg Carle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.05832">
<title>Instance-Agnostic Geometry and Contact Dynamics Learning. (arXiv:2309.05832v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.05832</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents an instance-agnostic learning framework that fuses vision
with dynamics to simultaneously learn shape, pose trajectories, and physical
properties via the use of geometry as a shared representation. Unlike many
contact learning approaches that assume motion capture input and a known shape
prior for the collision model, our proposed framework learns an object&apos;s
geometric and dynamic properties from RGBD video, without requiring either
category-level or instance-level shape priors. We integrate a vision system,
BundleSDF, with a dynamics system, ContactNets, and propose a cyclic training
pipeline to use the output from the dynamics module to refine the poses and the
geometry from the vision module, using perspective reprojection. Experiments
demonstrate our framework&apos;s ability to learn the geometry and dynamics of rigid
and convex objects and improve upon the current tracking framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Mengti Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1&quot;&gt;Bowen Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bianchini_B/0/1/0/all/0/1&quot;&gt;Bibit Bianchini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_C/0/1/0/all/0/1&quot;&gt;Camillo Jose Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Posa_M/0/1/0/all/0/1&quot;&gt;Michael Posa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.06612">
<title>Harmonic-NAS: Hardware-Aware Multimodal Neural Architecture Search on Resource-constrained Devices. (arXiv:2309.06612v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.06612</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent surge of interest surrounding Multimodal Neural Networks (MM-NN)
is attributed to their ability to effectively process and integrate multiscale
information from diverse data sources. MM-NNs extract and fuse features from
multiple modalities using adequate unimodal backbones and specific fusion
networks. Although this helps strengthen the multimodal information
representation, designing such networks is labor-intensive. It requires tuning
the architectural parameters of the unimodal backbones, choosing the fusing
point, and selecting the operations for fusion. Furthermore, multimodality AI
is emerging as a cutting-edge option in Internet of Things (IoT) systems where
inference latency and energy consumption are critical metrics in addition to
accuracy. In this paper, we propose Harmonic-NAS, a framework for the joint
optimization of unimodal backbones and multimodal fusion networks with hardware
awareness on resource-constrained devices. Harmonic-NAS involves a two-tier
optimization approach for the unimodal backbone architectures and fusion
strategy and operators. By incorporating the hardware dimension into the
optimization, evaluation results on various devices and multimodal datasets
have demonstrated the superiority of Harmonic-NAS over state-of-the-art
approaches achieving up to 10.9% accuracy improvement, 1.91x latency reduction,
and 2.14x energy efficiency gain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghebriout_M/0/1/0/all/0/1&quot;&gt;Mohamed Imed Eddine Ghebriout&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouzidi_H/0/1/0/all/0/1&quot;&gt;Halima Bouzidi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niar_S/0/1/0/all/0/1&quot;&gt;Smail Niar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouarnoughi_H/0/1/0/all/0/1&quot;&gt;Hamza Ouarnoughi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.07461">
<title>Detecting Unknown Attacks in IoT Environments: An Open Set Classifier for Enhanced Network Intrusion Detection. (arXiv:2309.07461v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2309.07461</link>
<description rdf:parseType="Literal">&lt;p&gt;The widespread integration of Internet of Things (IoT) devices across all
facets of life has ushered in an era of interconnectedness, creating new
avenues for cybersecurity challenges and underscoring the need for robust
intrusion detection systems. However, traditional security systems are designed
with a closed-world perspective and often face challenges in dealing with the
ever-evolving threat landscape, where new and unfamiliar attacks are constantly
emerging. In this paper, we introduce a framework aimed at mitigating the open
set recognition (OSR) problem in the realm of Network Intrusion Detection
Systems (NIDS) tailored for IoT environments. Our framework capitalizes on
image-based representations of packet-level data, extracting spatial and
temporal patterns from network traffic. Additionally, we integrate stacking and
sub-clustering techniques, enabling the identification of unknown attacks by
effectively modeling the complex and diverse nature of benign behavior. The
empirical results prominently underscore the framework&apos;s efficacy, boasting an
impressive 88\% detection rate for previously unseen attacks when compared
against existing approaches and recent advancements. Future work will perform
extensive experimentation across various openness levels and attack scenarios,
further strengthening the adaptability and performance of our proposed solution
in safeguarding IoT environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farrukh_Y/0/1/0/all/0/1&quot;&gt;Yasir Ali Farrukh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wali_S/0/1/0/all/0/1&quot;&gt;Syed Wali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_I/0/1/0/all/0/1&quot;&gt;Irfan Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastian_N/0/1/0/all/0/1&quot;&gt;Nathaniel D. Bastian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.09175">
<title>Imbalanced Data Stream Classification using Dynamic Ensemble Selection. (arXiv:2309.09175v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.09175</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern streaming data categorization faces significant challenges from
concept drift and class imbalanced data. This negatively impacts the output of
the classifier, leading to improper classification. Furthermore, other factors
such as the overlapping of multiple classes limit the extent of the correctness
of the output. This work proposes a novel framework for integrating data
pre-processing and dynamic ensemble selection, by formulating the
classification framework for the nonstationary drifting imbalanced data stream,
which employs the data pre-processing and dynamic ensemble selection
techniques. The proposed framework was evaluated using six artificially
generated data streams with differing imbalance ratios in combination with two
different types of concept drifts. Each stream is composed of 200 chunks of 500
objects described by eight features and contains five concept drifts. Seven
pre-processing techniques and two dynamic ensemble selection methods were
considered. According to experimental results, data pre-processing combined
with Dynamic Ensemble Selection techniques significantly delivers more accuracy
when dealing with imbalanced data streams.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+S_P/0/1/0/all/0/1&quot;&gt;Priya.S&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sivakumar_H/0/1/0/all/0/1&quot;&gt;Haribharathi Sivakumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+R_V/0/1/0/all/0/1&quot;&gt;Vijay Arvind.R&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.09979">
<title>General In-Hand Object Rotation with Vision and Touch. (arXiv:2309.09979v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2309.09979</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce RotateIt, a system that enables fingertip-based object rotation
along multiple axes by leveraging multimodal sensory inputs. Our system is
trained in simulation, where it has access to ground-truth object shapes and
physical properties. Then we distill it to operate on realistic yet noisy
simulated visuotactile and proprioceptive sensory inputs. These multimodal
inputs are fused via a visuotactile transformer, enabling online inference of
object shapes and physical properties during deployment. We show significant
performance improvements over prior methods and the importance of visual and
tactile sensing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1&quot;&gt;Haozhi Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_B/0/1/0/all/0/1&quot;&gt;Brent Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1&quot;&gt;Sudharshan Suresh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lambeta_M/0/1/0/all/0/1&quot;&gt;Mike Lambeta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yi Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1&quot;&gt;Roberto Calandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1&quot;&gt;Jitendra Malik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.10003">
<title>A novel approach to measuring patent claim scope based on probabilities obtained from (large) language models. (arXiv:2309.10003v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.10003</link>
<description rdf:parseType="Literal">&lt;p&gt;This work proposes to measure the scope of a patent claim as the reciprocal
of the self-information contained in this claim. A probability of occurrence of
the claim is obtained from a language model and this probability is used to
compute the self-information. Grounded in information theory, this approach is
based on the assumption that an unlikely concept is more informative than a
usual concept, insofar as it is more surprising. In turn, the more surprising
the information required to defined the claim, the narrower its scope. Five
language models are considered, ranging from simplest models (each word or
character is assigned an identical probability) to intermediate models (using
average word or character frequencies), to a large language model (GPT2).
Interestingly, the scope resulting from the simplest language models is
proportional to the reciprocal of the number of words or characters involved in
the claim, a metric already used in previous works. Application is made to
multiple series of patent claims directed to distinct inventions, where each
series consists of claims devised to have a gradually decreasing scope. The
performance of the language models is assessed with respect to several ad hoc
tests. The more sophisticated the model, the better the results. I.e., the GPT2
probability model outperforms models based on word and character frequencies,
which themselves outdo the simplest models based on word or character counts.
Still, the character count appears to be a more reliable indicator than the
word count.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ragot_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Ragot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11475">
<title>Creating walls to avoid unwanted points in root finding and optimization. (arXiv:2309.11475v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2309.11475</link>
<description rdf:parseType="Literal">&lt;p&gt;In root finding and optimization, there are many cases where there is a
closed set $A$ one likes that the sequence constructed by one&apos;s favourite
method will not converge to A (here, we do not assume extra properties on $A$
such as being convex or connected). For example, if one wants to find roots,
and one chooses initial points in the basin of attraction for 1 root $x^*$ (a
fact which one may not know before hand), then one will always end up in that
root. In this case, one would like to have a mechanism to avoid this point
$z^*$ in the next runs of one&apos;s algorithm.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose two new methods aiming to achieve this. In the
first method, we divide the cost function by an appropriate power of the
distance function to $A$. This idea is inspired by how one would try to find
all roots of a function in 1 variable. In the second method, which is more
suitable for constrained optimization, we redefine the value of the function to
be a big constant on $A$. We also propose, based on this, an algorithm to
escape the basin of attraction of a component of positive dimension to reach
another component. As an application, we prove a rigorous guarantee for finding
roots of a meromorphic function of 1 complex variable in a given domain.
&lt;/p&gt;
&lt;p&gt;Along the way, we compare with main existing relevant methods in the current
literature. We provide several examples in various different settings to
illustrate the usefulness of the new approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Truong_T/0/1/0/all/0/1&quot;&gt;Tuyen Trung Truong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11657">
<title>Distribution-Independent Regression for Generalized Linear Models with Oblivious Corruptions. (arXiv:2309.11657v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/2309.11657</link>
<description rdf:parseType="Literal">&lt;p&gt;We demonstrate the first algorithms for the problem of regression for
generalized linear models (GLMs) in the presence of additive oblivious noise.
We assume we have sample access to examples $(x, y)$ where $y$ is a noisy
measurement of $g(w^* \cdot x)$. In particular, \new{the noisy labels are of
the form} $y = g(w^* \cdot x) + \xi + \epsilon$, where $\xi$ is the oblivious
noise drawn independently of $x$ \new{and satisfies} $\Pr[\xi = 0] \geq o(1)$,
and $\epsilon \sim \mathcal N(0, \sigma^2)$. Our goal is to accurately recover
a \new{parameter vector $w$ such that the} function $g(w \cdot x)$ \new{has}
arbitrarily small error when compared to the true values $g(w^* \cdot x)$,
rather than the noisy measurements $y$.
&lt;/p&gt;
&lt;p&gt;We present an algorithm that tackles \new{this} problem in its most general
distribution-independent setting, where the solution may not \new{even} be
identifiable. \new{Our} algorithm returns \new{an accurate estimate of} the
solution if it is identifiable, and otherwise returns a small list of
candidates, one of which is close to the true solution. Furthermore, we
\new{provide} a necessary and sufficient condition for identifiability, which
holds in broad settings. \new{Specifically,} the problem is identifiable when
the quantile at which $\xi + \epsilon = 0$ is known, or when the family of
hypotheses does not contain candidates that are nearly equal to a translated
$g(w^* \cdot x) + A$ for some real number $A$, while also having large error
when compared to $g(w^* \cdot x)$.
&lt;/p&gt;
&lt;p&gt;This is the first \new{algorithmic} result for GLM regression \new{with
oblivious noise} which can handle more than half the samples being arbitrarily
corrupted. Prior work focused largely on the setting of linear regression, and
gave algorithms under restrictive assumptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1&quot;&gt;Ilias Diakonikolas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karmalkar_S/0/1/0/all/0/1&quot;&gt;Sushrut Karmalkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jongho Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1&quot;&gt;Christos Tzamos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12041">
<title>S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees. (arXiv:2309.12041v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/2309.12041</link>
<description rdf:parseType="Literal">&lt;p&gt;Privacy-preserving learning of gradient boosting decision trees (GBDT) has
the potential for strong utility-privacy tradeoffs for tabular data, such as
census data or medical meta data: classical GBDT learners can extract
non-linear patterns from small sized datasets. The state-of-the-art notion for
provable privacy-properties is differential privacy, which requires that the
impact of single data points is limited and deniable. We introduce a novel
differentially private GBDT learner and utilize four main techniques to improve
the utility-privacy tradeoff. (1) We use an improved noise scaling approach
with tighter accounting of privacy leakage of a decision tree leaf compared to
prior work, resulting in noise that in expectation scales with $O(1/n)$, for
$n$ data points. (2) We integrate individual R\&apos;enyi filters to our method to
learn from data points that have been underutilized during an iterative
training process, which -- potentially of independent interest -- results in a
natural yet effective insight to learning streams of non-i.i.d. data. (3) We
incorporate the concept of random decision tree splits to concentrate privacy
budget on learning leaves. (4) We deploy subsampling for privacy amplification.
Our evaluation shows for the Abalone dataset ($&amp;lt;4k$ training data points) a
$R^2$-score of $0.39$ for $\varepsilon=0.15$, which the closest prior work only
achieved for $\varepsilon=10.0$. On the Adult dataset ($50k$ training data
points) we achieve test error of $18.7\,\%$ for $\varepsilon=0.07$ which the
closest prior work only achieved for $\varepsilon=1.0$. For the Abalone dataset
for $\varepsilon=0.54$ we achieve $R^2$-score of $0.47$ which is very close to
the $R^2$-score of $0.54$ for the nonprivate version of GBDT. For the Adult
dataset for $\varepsilon=0.54$ we achieve test error $17.1\,\%$ which is very
close to the test error $13.7\,\%$ of the nonprivate version of GBDT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirschte_M/0/1/0/all/0/1&quot;&gt;Moritz Kirschte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peinemann_T/0/1/0/all/0/1&quot;&gt;Thorsten Peinemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stock_J/0/1/0/all/0/1&quot;&gt;Joshua Stock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotrini_C/0/1/0/all/0/1&quot;&gt;Carlos Cotrini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammadi_E/0/1/0/all/0/1&quot;&gt;Esfandiar Mohammadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.13405">
<title>Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block Decomposition. (arXiv:2309.13405v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.13405</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of learning the large-scale Gaussian graphical
models that are multivariate totally positive of order two ($\text{MTP}_2$). By
introducing the concept of bridge, which commonly exists in large-scale sparse
graphs, we show that the entire problem can be equivalently optimized through
(1) several smaller-scaled sub-problems induced by a \emph{bridge-block
decomposition} on the thresholded sample covariance graph and (2) a set of
explicit solutions on entries corresponding to \emph{bridges}. From practical
aspect, this simple and provable discipline can be applied to break down a
large problem into small tractable ones, leading to enormous reduction on the
computational complexity and substantial improvements for all existing
algorithms. The synthetic and real-world experiments demonstrate that our
proposed method presents a significant speed-up compared to the
state-of-the-art benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiwen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_J/0/1/0/all/0/1&quot;&gt;Jiaxi Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palomar_D/0/1/0/all/0/1&quot;&gt;Daniel P. Palomar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.13752">
<title>Improving Robustness of Deep Convolutional Neural Networks via Multiresolution Learning. (arXiv:2309.13752v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.13752</link>
<description rdf:parseType="Literal">&lt;p&gt;The current learning process of deep learning, regardless of any deep neural
network (DNN) architecture and/or learning algorithm used, is essentially a
single resolution training. We explore multiresolution learning and show that
multiresolution learning can significantly improve robustness of DNN models for
both 1D signal and 2D signal (image) prediction problems. We demonstrate this
improvement in terms of both noise and adversarial robustness as well as with
small training dataset size. Our results also suggest that it may not be
necessary to trade standard accuracy for robustness with multiresolution
learning, which is, interestingly, contrary to the observation obtained from
the traditional single resolution learning setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hongyan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yao Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15123">
<title>Uncovering Neural Scaling Laws in Molecular Representation Learning. (arXiv:2309.15123v2 [physics.chem-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15123</link>
<description rdf:parseType="Literal">&lt;p&gt;Molecular Representation Learning (MRL) has emerged as a powerful tool for
drug and materials discovery in a variety of tasks such as virtual screening
and inverse design. While there has been a surge of interest in advancing
model-centric techniques, the influence of both data quantity and quality on
molecular representations is not yet clearly understood within this field. In
this paper, we delve into the neural scaling behaviors of MRL from a
data-centric viewpoint, examining four key dimensions: (1) data modalities, (2)
dataset splitting, (3) the role of pre-training, and (4) model capacity. Our
empirical studies confirm a consistent power-law relationship between data
volume and MRL performance across these dimensions. Additionally, through
detailed analysis, we identify potential avenues for improving learning
efficiency. To challenge these scaling laws, we adapt seven popular data
pruning strategies to molecular data and benchmark their performance. Our
findings underline the importance of data-centric MRL and highlight possible
directions for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Dingshuo Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yanqiao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jieyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yuanqi Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhixun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wu_S/0/1/0/all/0/1&quot;&gt;Shu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15128">
<title>DPA-WNO: A gray box model for a class of stochastic mechanics problem. (arXiv:2309.15128v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15128</link>
<description rdf:parseType="Literal">&lt;p&gt;The well-known governing physics in science and engineering is often based on
certain assumptions and approximations. Therefore, analyses and designs carried
out based on these equations are also approximate. The emergence of data-driven
models has, to a certain degree, addressed this challenge; however, the purely
data-driven models often (a) lack interpretability, (b) are data-hungry, and
(c) do not generalize beyond the training window. Operator learning has
recently been proposed as a potential alternative to address the aforementioned
challenges; however, the challenges are still persistent. We here argue that
one of the possible solutions resides in data-physics fusion, where the
data-driven model is used to correct/identify the missing physics. To that end,
we propose a novel Differentiable Physics Augmented Wavelet Neural Operator
(DPA-WNO). The proposed DPA-WNO blends a differentiable physics solver with the
Wavelet Neural Operator (WNO), where the role of WNO is to model the missing
physics. This empowers the proposed framework to exploit the capability of WNO
to learn from data while retaining the interpretability and generalizability
associated with physics-based solvers. We illustrate the applicability of the
proposed approach in solving time-dependent uncertainty quantification problems
due to randomness in the initial condition. Four benchmark uncertainty
quantification and reliability analysis examples from various fields of science
and engineering are solved using the proposed approach. The results presented
illustrate interesting features of the proposed approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tushar/0/1/0/all/0/1&quot;&gt;Tushar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1&quot;&gt;Souvik Chakraborty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15253">
<title>Method and Validation for Optimal Lineup Creation for Daily Fantasy Football Using Machine Learning and Linear Programming. (arXiv:2309.15253v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15253</link>
<description rdf:parseType="Literal">&lt;p&gt;Daily fantasy sports (DFS) are weekly or daily online contests where
real-game performances of individual players are converted to fantasy points
(FPTS). Users select players for their lineup to maximize their FPTS within a
set player salary cap. This paper focuses on (1) the development of a method to
forecast NFL player performance under uncertainty and (2) determining an
optimal lineup to maximize FPTS under a set salary limit. A supervised learning
neural network was created and used to project FPTS based on past player
performance (2018 NFL regular season for this work) prior to the upcoming week.
These projected FPTS were used in a mixed integer linear program to find the
optimal lineup. The performance of resultant lineups was compared to
randomly-created lineups. On average, the optimal lineups outperformed the
random lineups. The generated lineups were then compared to real-world lineups
from users on DraftKings. The generated lineups generally fell in approximately
the 31st percentile (median). The FPTS methods and predictions presented here
can be further improved using this study as a baseline comparison.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahoney_J/0/1/0/all/0/1&quot;&gt;Joseph M. Mahoney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paniak_T/0/1/0/all/0/1&quot;&gt;Tomasz B. Paniak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15564">
<title>Jointly Training Large Autoregressive Multimodal Models. (arXiv:2309.15564v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15564</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, advances in the large-scale pretraining of language and
text-to-image models have revolutionized the field of machine learning. Yet,
integrating these two modalities into a single, robust model capable of
generating seamless multimodal outputs remains a significant challenge. To
address this gap, we present the Joint Autoregressive Mixture (JAM) framework,
a modular approach that systematically fuses existing text and image generation
models. We also introduce a specialized, data-efficient instruction-tuning
strategy, tailored for mixed-modal generation tasks. Our final instruct-tuned
model demonstrates unparalleled performance in generating high-quality
multimodal outputs and represents the first model explicitly designed for this
purpose.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aiello_E/0/1/0/all/0/1&quot;&gt;Emanuele Aiello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1&quot;&gt;Lili Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1&quot;&gt;Yixin Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aghajanyan_A/0/1/0/all/0/1&quot;&gt;Armen Aghajanyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1&quot;&gt;Barlas Oguz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15639">
<title>Enhancing Sharpness-Aware Optimization Through Variance Suppression. (arXiv:2309.15639v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15639</link>
<description rdf:parseType="Literal">&lt;p&gt;Sharpness-aware minimization (SAM) has well documented merits in enhancing
generalization of deep neural networks, even without sizable data augmentation.
Embracing the geometry of the loss function, where neighborhoods of &apos;flat
minima&apos; heighten generalization ability, SAM seeks &apos;flat valleys&apos; by minimizing
the maximum loss caused by an adversary perturbing parameters within the
neighborhood. Although critical to account for sharpness of the loss function,
such an &apos;over-friendly adversary&apos; can curtail the outmost level of
generalization. The novel approach of this contribution fosters stabilization
of adversaries through variance suppression (VaSSO) to avoid such friendliness.
VaSSO&apos;s provable stability safeguards its numerical improvement over SAM in
model-agnostic tasks, including image classification and machine translation.
In addition, experiments confirm that VaSSO endows SAM with robustness against
high levels of label noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bingcong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giannakis_G/0/1/0/all/0/1&quot;&gt;Georgios B. Giannakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.15757">
<title>Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data. (arXiv:2309.15757v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.15757</link>
<description rdf:parseType="Literal">&lt;p&gt;In the domain of semi-supervised learning, the current approaches
insufficiently exploit the potential of considering inter-instance
relationships among (un)labeled data. In this work, we address this limitation
by providing an approach for inferring latent graphs that capture the intrinsic
data relationships. By leveraging graph-based representations, our approach
facilitates the seamless propagation of information throughout the graph,
enabling the effective incorporation of global and local knowledge. Through
evaluations on biomedical tabular datasets, we compare the capabilities of our
approach to other contemporary methods. Our work demonstrates the significance
of inter-instance relationship discovery as practical means for constructing
robust latent graphs to enhance semi-supervised learning techniques. Our method
achieves state-of-the-art results on three biomedical datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koloski_B/0/1/0/all/0/1&quot;&gt;Boshko Koloski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skrlj_B/0/1/0/all/0/1&quot;&gt;Bla&amp;#x17e; &amp;#x160;krlj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pollak_S/0/1/0/all/0/1&quot;&gt;Senja Pollak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lavrac_N/0/1/0/all/0/1&quot;&gt;Nada Lavra&amp;#x10d;&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>