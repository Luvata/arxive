<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs.LG updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science -- Machine Learning (cs.LG) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2023-09-21T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Computer Science -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11503" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11507" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11509" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11512" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11515" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11518" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11526" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11527" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11531" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11568" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11575" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11587" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11601" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11623" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11638" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11646" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11647" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11648" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11651" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11657" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11671" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11680" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11682" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11687" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11702" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11705" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11714" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11722" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11726" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11741" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11745" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11758" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11765" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11766" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11782" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11798" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11845" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11856" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11875" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11930" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11932" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11942" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11955" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11963" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11979" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11983" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11987" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11994" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11995" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12004" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12025" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12028" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12032" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12033" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12036" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12041" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12058" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12067" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12078" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12095" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12111" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12128" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12134" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12140" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12158" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12162" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12193" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12200" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12201" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12202" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12204" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12207" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12211" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12212" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12215" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12217" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12218" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12236" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12237" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12242" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12245" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12250" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12252" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12253" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12259" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12267" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12273" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12279" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12283" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12288" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12295" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12300" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12301" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12307" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12311" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.12312" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2102.11941" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2203.09879" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2205.02998" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2208.03392" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2209.05355" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.00997" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.01918" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2210.03269" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2211.02900" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.03414" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2212.11278" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.03044" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.11734" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2301.13019" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2302.08661" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.01682" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.10310" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2303.13773" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.03398" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.06104" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.12654" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.04281" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.05237" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.06908" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.10424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.13706" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2305.14129" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.03303" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.06101" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.16524" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2306.17366" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.00215" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.02108" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2307.15299" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.06424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.07037" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.07929" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.10457" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2308.10792" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.03992" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.04474" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.08228" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.08587" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.08617" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.09517" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.10280" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.10505" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.10688" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.10916" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11052" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11354" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11489" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2304.00216" />
  <rdf:li rdf:resource="http://arxiv.org/abs/2309.11132" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/2309.11503">
<title>Fairness Vs. Personalization: Towards Equity in Epistemic Utility. (arXiv:2309.11503v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2309.11503</link>
<description rdf:parseType="Literal">&lt;p&gt;The applications of personalized recommender systems are rapidly expanding:
encompassing social media, online shopping, search engine results, and more.
These systems offer a more efficient way to navigate the vast array of items
available. However, alongside this growth, there has been increased recognition
of the potential for algorithmic systems to exhibit and perpetuate biases,
risking unfairness in personalized domains. In this work, we explicate the
inherent tension between personalization and conventional implementations of
fairness. As an alternative, we propose equity to achieve fairness in the
context of epistemic utility. We provide a mapping between goals and practical
implementations and detail policy recommendations across key stakeholders to
forge a path towards achieving fairness in personalized systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chien_J/0/1/0/all/0/1&quot;&gt;Jennifer Chien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Danks_D/0/1/0/all/0/1&quot;&gt;David Danks&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11507">
<title>AdBooster: Personalized Ad Creative Generation using Stable Diffusion Outpainting. (arXiv:2309.11507v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2309.11507</link>
<description rdf:parseType="Literal">&lt;p&gt;In digital advertising, the selection of the optimal item (recommendation)
and its best creative presentation (creative optimization) have traditionally
been considered separate disciplines. However, both contribute significantly to
user satisfaction, underpinning our assumption that it relies on both an item&apos;s
relevance and its presentation, particularly in the case of visual creatives.
In response, we introduce the task of {\itshape Generative Creative
Optimization (GCO)}, which proposes the use of generative models for creative
generation that incorporate user interests, and {\itshape AdBooster}, a model
for personalized ad creatives based on the Stable Diffusion outpainting
architecture. This model uniquely incorporates user interests both during
fine-tuning and at generation time. To further improve AdBooster&apos;s performance,
we also introduce an automated data augmentation pipeline. Through our
experiments on simulated data, we validate AdBooster&apos;s effectiveness in
generating more relevant creatives than default product images, showing its
potential of enhancing user engagement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shilova_V/0/1/0/all/0/1&quot;&gt;Veronika Shilova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_L/0/1/0/all/0/1&quot;&gt;Ludovic Dos Santos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasile_F/0/1/0/all/0/1&quot;&gt;Flavian Vasile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Racic_G/0/1/0/all/0/1&quot;&gt;Ga&amp;#xeb;tan Racic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanielian_U/0/1/0/all/0/1&quot;&gt;Ugo Tanielian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11509">
<title>Using causal inference to avoid fallouts in data-driven parametric analysis: a case study in the architecture, engineering, and construction industry. (arXiv:2309.11509v1 [cs.CE])</title>
<link>http://arxiv.org/abs/2309.11509</link>
<description rdf:parseType="Literal">&lt;p&gt;The decision-making process in real-world implementations has been affected
by a growing reliance on data-driven models. We investigated the synergetic
pattern between the data-driven methods, empirical domain knowledge, and
first-principles simulations. We showed the potential risk of biased results
when using data-driven models without causal analysis. Using a case study
assessing the implication of several design solutions on the energy consumption
of a building, we proved the necessity of causal analysis during the
data-driven modeling process. We concluded that: (a) Data-driven models&apos;
accuracy assessment or domain knowledge screening may not rule out biased and
spurious results; (b) Data-driven models&apos; feature selection should involve
careful consideration of causal relationships, especially colliders; (c) Causal
analysis results can be used as an aid to first-principles simulation design
and parameter checking to avoid cognitive biases. We proved the benefits of
causal analysis when applied to data-driven models in building engineering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xia Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1&quot;&gt;Ruiji Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saluz_U/0/1/0/all/0/1&quot;&gt;Ueli Saluz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schiavon_S/0/1/0/all/0/1&quot;&gt;Stefano Schiavon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geyer_P/0/1/0/all/0/1&quot;&gt;Philipp Geyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11512">
<title>Multidimensional well-being of US households at a fine spatial scale using fused household surveys: fusionACS. (arXiv:2309.11512v1 [stat.AP])</title>
<link>http://arxiv.org/abs/2309.11512</link>
<description rdf:parseType="Literal">&lt;p&gt;Social science often relies on surveys of households and individuals. Dozens
of such surveys are regularly administered by the U.S. government. However,
they field independent, unconnected samples with specialized questions,
limiting research questions to those that can be answered by a single survey.
The fusionACS project seeks to integrate data from multiple U.S. household
surveys by statistically &quot;fusing&quot; variables from &quot;donor&quot; surveys onto American
Community Survey (ACS) microdata. This results in an integrated microdataset of
household attributes and well-being dimensions that can be analyzed to address
research questions in ways that are not currently possible. The presented data
comprise the fusion onto the ACS of select donor variables from the Residential
Energy Consumption Survey (RECS) of 2015, the National Household Transportation
Survey (NHTS) of 2017, the American Housing Survey (AHS) of 2019, and the
Consumer Expenditure Survey - Interview (CEI) for the years 2015-2019. The
underlying statistical techniques are included in an open-source $R$ package,
fusionModel, that provides generic tools for the creation, analysis, and
validation of fused microdata.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ummel_K/0/1/0/all/0/1&quot;&gt;Kevin Ummel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Poblete_Cazenave_M/0/1/0/all/0/1&quot;&gt;Miguel Poblete-Cazenave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Akkiraju_K/0/1/0/all/0/1&quot;&gt;Karthik Akkiraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Graetz_N/0/1/0/all/0/1&quot;&gt;Nick Graetz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ashman_H/0/1/0/all/0/1&quot;&gt;Hero Ashman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kingdon_C/0/1/0/all/0/1&quot;&gt;Cora Kingdon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tenorio_S/0/1/0/all/0/1&quot;&gt;Steven Herrera Tenorio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singhal_A/0/1/0/all/0/1&quot;&gt;Aaryaman &amp;quot;Sunny&amp;quot; Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cohen_D/0/1/0/all/0/1&quot;&gt;Daniel Aldana Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rao_N/0/1/0/all/0/1&quot;&gt;Narasimha D. Rao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11515">
<title>Towards Differential Privacy in Sequential Recommendation: A Noisy Graph Neural Network Approach. (arXiv:2309.11515v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2309.11515</link>
<description rdf:parseType="Literal">&lt;p&gt;With increasing frequency of high-profile privacy breaches in various online
platforms, users are becoming more concerned about their privacy. And
recommender system is the core component of online platforms for providing
personalized service, consequently, its privacy preservation has attracted
great attention. As the gold standard of privacy protection, differential
privacy has been widely adopted to preserve privacy in recommender systems.
However, existing differentially private recommender systems only consider
static and independent interactions, so they cannot apply to sequential
recommendation where behaviors are dynamic and dependent. Meanwhile, little
attention has been paid on the privacy risk of sensitive user features, most of
them only protect user feedbacks. In this work, we propose a novel
DIfferentially Private Sequential recommendation framework with a noisy Graph
Neural Network approach (denoted as DIPSGNN) to address these limitations. To
the best of our knowledge, we are the first to achieve differential privacy in
sequential recommendation with dependent interactions. Specifically, in
DIPSGNN, we first leverage piecewise mechanism to protect sensitive user
features. Then, we innovatively add calibrated noise into aggregation step of
graph neural network based on aggregation perturbation mechanism. And this
noisy graph neural network can protect sequentially dependent interactions and
capture user preferences simultaneously. Extensive experiments demonstrate the
superiority of our method over state-of-the-art differentially private
recommender systems in terms of better balance between privacy and accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Wentao Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1&quot;&gt;Hui Fang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11516">
<title>Private Matrix Factorization with Public Item Features. (arXiv:2309.11516v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2309.11516</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of training private recommendation models with access
to public item features. Training with Differential Privacy (DP) offers strong
privacy guarantees, at the expense of loss in recommendation quality. We show
that incorporating public item features during training can help mitigate this
loss in quality. We propose a general approach based on collective matrix
factorization (CMF), that works by simultaneously factorizing two matrices: the
user feedback matrix (representing sensitive data) and an item feature matrix
that encodes publicly available (non-sensitive) item information.
&lt;/p&gt;
&lt;p&gt;The method is conceptually simple, easy to tune, and highly scalable. It can
be applied to different types of public item data, including: (1) categorical
item features; (2) item-item similarities learned from public sources; and (3)
publicly available user feedback. Furthermore, these data modalities can be
collectively utilized to fully leverage public data.
&lt;/p&gt;
&lt;p&gt;Evaluating our method on a standard DP recommendation benchmark, we find that
using public item features significantly narrows the quality gap between
private models and their non-private counterparts. As privacy constraints
become more stringent, models rely more heavily on public side features for
recommendation. This results in a smooth transition from collaborative
filtering to item-based contextual recommendations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Curmei_M/0/1/0/all/0/1&quot;&gt;Mihaela Curmei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krichene_W/0/1/0/all/0/1&quot;&gt;Walid Krichene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Li Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sundararajan_M/0/1/0/all/0/1&quot;&gt;Mukund Sundararajan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11518">
<title>Ad-load Balancing via Off-policy Learning in a Content Marketplace. (arXiv:2309.11518v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2309.11518</link>
<description rdf:parseType="Literal">&lt;p&gt;Ad-load balancing is a critical challenge in online advertising systems,
particularly in the context of social media platforms, where the goal is to
maximize user engagement and revenue while maintaining a satisfactory user
experience. This requires the optimization of conflicting objectives, such as
user satisfaction and ads revenue. Traditional approaches to ad-load balancing
rely on static allocation policies, which fail to adapt to changing user
preferences and contextual factors. In this paper, we present an approach that
leverages off-policy learning and evaluation from logged bandit feedback. We
start by presenting a motivating analysis of the ad-load balancing problem,
highlighting the conflicting objectives between user satisfaction and ads
revenue. We emphasize the nuances that arise due to user heterogeneity and the
dependence on the user&apos;s position within a session. Based on this analysis, we
define the problem as determining the optimal ad-load for a particular feed
fetch. To tackle this problem, we propose an off-policy learning framework that
leverages unbiased estimators such as Inverse Propensity Scoring (IPS) and
Doubly Robust (DR) to learn and estimate the policy values using offline
collected stochastic data. We present insights from online A/B experiments
deployed at scale across over 80 million users generating over 200 million
sessions, where we find statistically significant improvements in both user
satisfaction metrics and ads revenue for the platform.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagtani_H/0/1/0/all/0/1&quot;&gt;Hitesh Sagtani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jhawar_M/0/1/0/all/0/1&quot;&gt;Madan Jhawar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehrotra_R/0/1/0/all/0/1&quot;&gt;Rishabh Mehrotra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeunen_O/0/1/0/all/0/1&quot;&gt;Olivier Jeunen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11526">
<title>Likelihood-based Sensor Calibration for Expert-Supported Distributed Learning Algorithms in IoT Systems. (arXiv:2309.11526v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11526</link>
<description rdf:parseType="Literal">&lt;p&gt;An important task in the field of sensor technology is the efficient
implementation of adaptation procedures of measurements from one sensor to
another sensor of identical design. One idea is to use the estimation of an
affine transformation between different systems, which can be improved by the
knowledge of experts. This paper presents an improved solution from Glacier
Research that was published back in 1973. It is shown that this solution can be
adapted for software calibration of sensors, implementation of expert-based
adaptation, and federated learning methods. We evaluate our research with
simulations and also with real measured data of a multi-sensor board with 8
identical sensors. The results show an improvement for both the simulation and
the experiments with real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Machhamer_R/0/1/0/all/0/1&quot;&gt;R&amp;#xfc;diger Machhamer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fazlic_L/0/1/0/all/0/1&quot;&gt;Lejla Begic Fazlic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guven_E/0/1/0/all/0/1&quot;&gt;Eray Guven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Junk_D/0/1/0/all/0/1&quot;&gt;David Junk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurt_G/0/1/0/all/0/1&quot;&gt;Gunes Karabulut Kurt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naumann_S/0/1/0/all/0/1&quot;&gt;Stefan Naumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Didas_S/0/1/0/all/0/1&quot;&gt;Stephan Didas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gollmer_K/0/1/0/all/0/1&quot;&gt;Klaus-Uwe Gollmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergmann_R/0/1/0/all/0/1&quot;&gt;Ralph Bergmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Timm_I/0/1/0/all/0/1&quot;&gt;Ingo J. Timm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dartmann_G/0/1/0/all/0/1&quot;&gt;Guido Dartmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11527">
<title>TrueLearn: A Python Library for Personalised Informational Recommendations with (Implicit) Feedback. (arXiv:2309.11527v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2309.11527</link>
<description rdf:parseType="Literal">&lt;p&gt;This work describes the TrueLearn Python library, which contains a family of
online learning Bayesian models for building educational (or more generally,
informational) recommendation systems. This family of models was designed
following the &quot;open learner&quot; concept, using humanly-intuitive user
representations. For the sake of interpretability and putting the user in
control, the TrueLearn library also contains different representations to help
end-users visualise the learner models, which may in the future facilitate user
interaction with their own models. Together with the library, we include a
previously publicly released implicit feedback educational dataset with
evaluation metrics to measure the performance of the models. The extensive
documentation and coding examples make the library highly accessible to both
machine learning developers and educational data mining and learning analytic
practitioners. The library and the support documentation with examples are
available at https://truelearn.readthedocs.io/en/latest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1&quot;&gt;Yuxiang Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Djemili_K/0/1/0/all/0/1&quot;&gt;Karim Djemili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elezi_D/0/1/0/all/0/1&quot;&gt;Denis Elezi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shalman_A/0/1/0/all/0/1&quot;&gt;Aaneel Shalman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Ortiz_M/0/1/0/all/0/1&quot;&gt;Mar&amp;#xed;a P&amp;#xe9;rez-Ortiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bulathwela_S/0/1/0/all/0/1&quot;&gt;Sahan Bulathwela&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11531">
<title>EPTQ: Enhanced Post-Training Quantization via Label-Free Hessian. (arXiv:2309.11531v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.11531</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantization of deep neural networks (DNN) has become a key element in the
efforts of embedding such networks on end-user devices. However, current
quantization methods usually suffer from costly accuracy degradation. In this
paper, we propose a new method for Enhanced Post Training Quantization named
EPTQ. The method is based on knowledge distillation with an adaptive weighting
of layers. In addition, we introduce a new label-free technique for
approximating the Hessian trace of the task loss, named Label-Free Hessian.
This technique removes the requirement of a labeled dataset for computing the
Hessian. The adaptive knowledge distillation uses the Label-Free Hessian
technique to give greater attention to the sensitive parts of the model while
performing the optimization. Empirically, by employing EPTQ we achieve
state-of-the-art results on a wide variety of models, tasks, and datasets,
including ImageNet classification, COCO object detection, and Pascal-VOC for
semantic segmentation. We demonstrate the performance and compatibility of EPTQ
on an extended set of architectures, including CNNs, Transformers, hybrid, and
MLP-only models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gordon_O/0/1/0/all/0/1&quot;&gt;Ofir Gordon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habi_H/0/1/0/all/0/1&quot;&gt;Hai Victor Habi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Netzer_A/0/1/0/all/0/1&quot;&gt;Arnon Netzer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11564">
<title>Hierarchical reinforcement learning with natural language subgoals. (arXiv:2309.11564v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11564</link>
<description rdf:parseType="Literal">&lt;p&gt;Hierarchical reinforcement learning has been a compelling approach for
achieving goal directed behavior over long sequences of actions. However, it
has been challenging to implement in realistic or open-ended environments. A
main challenge has been to find the right space of sub-goals over which to
instantiate a hierarchy. We present a novel approach where we use data from
humans solving these tasks to softly supervise the goal space for a set of long
range tasks in a 3D embodied environment. In particular, we use unconstrained
natural language to parameterize this space. This has two advantages: first, it
is easy to generate this data from naive human participants; second, it is
flexible enough to represent a vast range of sub-goals in human-relevant tasks.
Our approach outperforms agents that clone expert behavior on these tasks, as
well as HRL from scratch without this supervised sub-goal space. Our work
presents a novel approach to combining human expert supervision with the
benefits and flexibility of reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_A/0/1/0/all/0/1&quot;&gt;Arun Ahuja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kopparapu_K/0/1/0/all/0/1&quot;&gt;Kavya Kopparapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fergus_R/0/1/0/all/0/1&quot;&gt;Rob Fergus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_I/0/1/0/all/0/1&quot;&gt;Ishita Dasgupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11568">
<title>BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model. (arXiv:2309.11568v1 [cs.AI])</title>
<link>http://arxiv.org/abs/2309.11568</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the Bittensor Language Model, called &quot;BTLM-3B-8K&quot;, a new
state-of-the-art 3 billion parameter open-source language model. BTLM-3B-8K was
trained on 627B tokens from the SlimPajama dataset with a mixture of 2,048 and
8,192 context lengths. BTLM-3B-8K outperforms all existing 3B parameter models
by 2-5.5% across downstream tasks. BTLM-3B-8K is even competitive with some 7B
parameter models. Additionally, BTLM-3B-8K provides excellent long context
performance, outperforming MPT-7B-8K and XGen-7B-8K on tasks up to 8,192
context length. We trained the model on a cleaned and deduplicated SlimPajama
dataset; aggressively tuned the \textmu P hyperparameters and schedule; used
ALiBi position embeddings; and adopted the SwiGLU nonlinearity.
&lt;/p&gt;
&lt;p&gt;On Hugging Face, the most popular models have 7B parameters, indicating that
users prefer the quality-size ratio of 7B models. Compacting the 7B parameter
model to one with 3B parameters, with little performance impact, is an
important milestone. BTLM-3B-8K needs only 3GB of memory with 4-bit precision
and takes 2.5x less inference compute than 7B models, helping to open up access
to a powerful language model on mobile and edge devices. BTLM-3B-8K is
available under an Apache 2.0 license on Hugging Face:
https://huggingface.co/cerebras/btlm-3b-8k-base.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dey_N/0/1/0/all/0/1&quot;&gt;Nolan Dey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soboleva_D/0/1/0/all/0/1&quot;&gt;Daria Soboleva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Khateeb_F/0/1/0/all/0/1&quot;&gt;Faisal Al-Khateeb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bowen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathria_R/0/1/0/all/0/1&quot;&gt;Ribhu Pathria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khachane_H/0/1/0/all/0/1&quot;&gt;Hemant Khachane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muhammad_S/0/1/0/all/0/1&quot;&gt;Shaheer Muhammad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhiming/0/1/0/all/0/1&quot;&gt;Zhiming&lt;/a&gt; (Charles) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen/0/1/0/all/0/1&quot;&gt;Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Myers_R/0/1/0/all/0/1&quot;&gt;Robert Myers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steeves_J/0/1/0/all/0/1&quot;&gt;Jacob Robert Steeves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vassilieva_N/0/1/0/all/0/1&quot;&gt;Natalia Vassilieva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tom_M/0/1/0/all/0/1&quot;&gt;Marvin Tom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hestness_J/0/1/0/all/0/1&quot;&gt;Joel Hestness&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11575">
<title>Distilling Adversarial Prompts from Safety Benchmarks: Report for the Adversarial Nibbler Challenge. (arXiv:2309.11575v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.11575</link>
<description rdf:parseType="Literal">&lt;p&gt;Text-conditioned image generation models have recently achieved astonishing
image quality and alignment results. Consequently, they are employed in a
fast-growing number of applications. Since they are highly data-driven, relying
on billion-sized datasets randomly scraped from the web, they also produce
unsafe content. As a contribution to the Adversarial Nibbler challenge, we
distill a large set of over 1,000 potential adversarial inputs from existing
safety benchmarks. Our analysis of the gathered prompts and corresponding
images demonstrates the fragility of input filters and provides further
insights into systematic safety issues in current generative image models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brack_M/0/1/0/all/0/1&quot;&gt;Manuel Brack&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schramowski_P/0/1/0/all/0/1&quot;&gt;Patrick Schramowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1&quot;&gt;Kristian Kersting&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11587">
<title>CATS: Conditional Adversarial Trajectory Synthesis for Privacy-Preserving Trajectory Data Publication Using Deep Learning Approaches. (arXiv:2309.11587v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11587</link>
<description rdf:parseType="Literal">&lt;p&gt;The prevalence of ubiquitous location-aware devices and mobile Internet
enables us to collect massive individual-level trajectory dataset from users.
Such trajectory big data bring new opportunities to human mobility research but
also raise public concerns with regard to location privacy. In this work, we
present the Conditional Adversarial Trajectory Synthesis (CATS), a
deep-learning-based GeoAI methodological framework for privacy-preserving
trajectory data generation and publication. CATS applies K-anonymity to the
underlying spatiotemporal distributions of human movements, which provides a
distributional-level strong privacy guarantee. By leveraging conditional
adversarial training on K-anonymized human mobility matrices, trajectory global
context learning using the attention-based mechanism, and recurrent bipartite
graph matching of adjacent trajectory points, CATS is able to reconstruct
trajectory topology from conditionally sampled locations and generate
high-quality individual-level synthetic trajectory data, which can serve as
supplements or alternatives to raw data for privacy-preserving trajectory data
publication. The experiment results on over 90k GPS trajectories show that our
method has a better performance in privacy preservation, spatiotemporal
characteristic preservation, and downstream utility compared with baseline
methods, which brings new insights into privacy-preserving human mobility
research using generative AI techniques and explores data ethics issues in
GIScience.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1&quot;&gt;Jinmeng Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Song Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Sijia Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11601">
<title>Latent Diffusion Models for Structural Component Design. (arXiv:2309.11601v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11601</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in generative modeling, namely Diffusion models, have
revolutionized generative modeling, enabling high-quality image generation
tailored to user needs. This paper proposes a framework for the generative
design of structural components. Specifically, we employ a Latent Diffusion
model to generate potential designs of a component that can satisfy a set of
problem-specific loading conditions. One of the distinct advantages our
approach offers over other generative approaches, such as generative
adversarial networks (GANs), is that it permits the editing of existing
designs. We train our model using a dataset of geometries obtained from
structural topology optimization utilizing the SIMP algorithm. Consequently,
our framework generates inherently near-optimal designs. Our work presents
quantitative results that support the structural performance of the generated
designs and the variability in potential candidate designs. Furthermore, we
provide evidence of the scalability of our framework by operating over voxel
domains with resolutions varying from $32^3$ to $128^3$. Our framework can be
used as a starting point for generating novel near-optimal designs similar to
topology-optimized designs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herron_E/0/1/0/all/0/1&quot;&gt;Ethan Herron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rade_J/0/1/0/all/0/1&quot;&gt;Jaydeep Rade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jignasu_A/0/1/0/all/0/1&quot;&gt;Anushrut Jignasu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganapathysubramanian_B/0/1/0/all/0/1&quot;&gt;Baskar Ganapathysubramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balu_A/0/1/0/all/0/1&quot;&gt;Aditya Balu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1&quot;&gt;Soumik Sarkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Adarsh Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11623">
<title>Leveraging Negative Signals with Self-Attention for Sequential Music Recommendation. (arXiv:2309.11623v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2309.11623</link>
<description rdf:parseType="Literal">&lt;p&gt;Music streaming services heavily rely on their recommendation engines to
continuously provide content to their consumers. Sequential recommendation
consequently has seen considerable attention in current literature, where state
of the art approaches focus on self-attentive models leveraging contextual
information such as long and short-term user history and item features;
however, most of these studies focus on long-form content domains (retail,
movie, etc.) rather than short-form, such as music. Additionally, many do not
explore incorporating negative session-level feedback during training. In this
study, we investigate the use of transformer-based self-attentive architectures
to learn implicit session-level information for sequential music
recommendation. We additionally propose a contrastive learning task to
incorporate negative feedback (e.g skipped tracks) to promote positive hits and
penalize negative hits. This task is formulated as a simple loss term that can
be incorporated into a variety of deep learning architectures for sequential
recommendation. Our experiments show that this results in consistent
performance gains over the baseline architectures ignoring negative user
feedback.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seshadri_P/0/1/0/all/0/1&quot;&gt;Pavan Seshadri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knees_P/0/1/0/all/0/1&quot;&gt;Peter Knees&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11638">
<title>A survey on the semantics of sequential patterns with negation. (arXiv:2309.11638v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11638</link>
<description rdf:parseType="Literal">&lt;p&gt;A sequential pattern with negation, or negative sequential pattern, takes the
form of a sequential pattern for which the negation symbol may be used in front
of some of the pattern&apos;s itemsets. Intuitively, such a pattern occurs in a
sequence if negated itemsets are absent in the sequence. Recent work has shown
that different semantics can be attributed to these pattern forms, and that
state-of-the-art algorithms do not extract the same sets of patterns. This
raises the important question of the interpretability of sequential pattern
with negation. In this study, our focus is on exploring how potential users
perceive negation in sequential patterns. Our aim is to determine whether
specific semantics are more &quot;intuitive&quot; than others and whether these align
with the semantics employed by one or more state-of-the-art algorithms. To
achieve this, we designed a questionnaire to reveal the semantics&apos; intuition of
each user. This article presents both the design of the questionnaire and an
in-depth analysis of the 124 responses obtained. The outcomes indicate that two
of the semantics are predominantly intuitive; however, neither of them aligns
with the semantics of the primary state-of-the-art algorithms. As a result, we
provide recommendations to account for this disparity in the conclusions drawn.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guyet_T/0/1/0/all/0/1&quot;&gt;Thomas Guyet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11646">
<title>Early diagnosis of autism spectrum disorder using machine learning approaches. (arXiv:2309.11646v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11646</link>
<description rdf:parseType="Literal">&lt;p&gt;Autistic Spectrum Disorder (ASD) is a neurological disease characterized by
difficulties with social interaction, communication, and repetitive activities.
The severity of these difficulties varies, and those with this diagnosis face
unique challenges. While its primary origin lies in genetics, identifying and
addressing it early can contribute to the enhancement of the condition. In
recent years, machine learning-driven intelligent diagnosis has emerged as a
supplement to conventional clinical approaches, aiming to address the potential
drawbacks of time-consuming and costly traditional methods. In this work, we
utilize different machine learning algorithms to find the most significant
traits responsible for ASD and to automate the diagnostic process. We study six
classification models to see which model works best to identify ASD and also
study five popular clustering methods to get a meaningful insight of these ASD
datasets. To find the best classifier for these binary datasets, we evaluate
the models using accuracy, precision, recall, specificity, F1-score, AUC, kappa
and log loss metrics. Our evaluation demonstrates that five out of the six
selected models perform exceptionally, achieving a 100% accuracy rate on the
ASD datasets when hyperparameters are meticulously tuned for each model. As
almost all classification models are able to get 100% accuracy, we become
interested in observing the underlying insights of the datasets by implementing
some popular clustering algorithms on these datasets. We calculate Normalized
Mutual Information (NMI), Adjusted Rand Index (ARI) &amp;amp; Silhouette Coefficient
(SC) metrics to select the best clustering models. Our evaluation finds that
spectral clustering outperforms all other benchmarking clustering models in
terms of NMI &amp;amp; ARI metrics and it also demonstrates comparability to the
optimal SC achieved by k-means.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasul_R/0/1/0/all/0/1&quot;&gt;Rownak Ara Rasul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_P/0/1/0/all/0/1&quot;&gt;Promy Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bala_D/0/1/0/all/0/1&quot;&gt;Diponkor Bala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karim_S/0/1/0/all/0/1&quot;&gt;S M Rakib Ul Karim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdullah_I/0/1/0/all/0/1&quot;&gt;Ibrahim Abdullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_B/0/1/0/all/0/1&quot;&gt;Bishwajit Saha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11647">
<title>Potential and limitations of random Fourier features for dequantizing quantum machine learning. (arXiv:2309.11647v1 [quant-ph])</title>
<link>http://arxiv.org/abs/2309.11647</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum machine learning is arguably one of the most explored applications of
near-term quantum devices. Much focus has been put on notions of variational
quantum machine learning where parameterized quantum circuits (PQCs) are used
as learning models. These PQC models have a rich structure which suggests that
they might be amenable to efficient dequantization via random Fourier features
(RFF). In this work, we establish necessary and sufficient conditions under
which RFF does indeed provide an efficient dequantization of variational
quantum machine learning for regression. We build on these insights to make
concrete suggestions for PQC architecture design, and to identify structures
which are necessary for a regression problem to admit a potential quantum
advantage via PQC based optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sweke_R/0/1/0/all/0/1&quot;&gt;Ryan Sweke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Recio_E/0/1/0/all/0/1&quot;&gt;Erik Recio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jerbi_S/0/1/0/all/0/1&quot;&gt;Sofiene Jerbi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gil_Fuster_E/0/1/0/all/0/1&quot;&gt;Elies Gil-Fuster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Fuller_B/0/1/0/all/0/1&quot;&gt;Bryce Fuller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Eisert_J/0/1/0/all/0/1&quot;&gt;Jens Eisert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Meyer_J/0/1/0/all/0/1&quot;&gt;Johannes Jakob Meyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11648">
<title>Orbital AI-based Autonomous Refuelling Solution. (arXiv:2309.11648v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.11648</link>
<description rdf:parseType="Literal">&lt;p&gt;Cameras are rapidly becoming the choice for on-board sensors towards space
rendezvous due to their small form factor and inexpensive power, mass, and
volume costs. When it comes to docking, however, they typically serve a
secondary role, whereas the main work is done by active sensors such as lidar.
This paper documents the development of a proposed AI-based (artificial
intelligence) navigation algorithm intending to mature the use of on-board
visible wavelength cameras as a main sensor for docking and on-orbit servicing
(OOS), reducing the dependency on lidar and greatly reducing costs.
Specifically, the use of AI enables the expansion of the relative navigation
solution towards multiple classes of scenarios, e.g., in terms of targets or
illumination conditions, which would otherwise have to be crafted on a
case-by-case manner using classical image processing methods. Multiple
convolutional neural network (CNN) backbone architectures are benchmarked on
synthetically generated data of docking manoeuvres with the International Space
Station (ISS), achieving position and attitude estimates close to 1%
range-normalised and 1 deg, respectively. The integration of the solution with
a physical prototype of the refuelling mechanism is validated in laboratory
using a robotic arm to simulate a berthing procedure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rondao_D/0/1/0/all/0/1&quot;&gt;Duarte Rondao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Lei He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aouf_N/0/1/0/all/0/1&quot;&gt;Nabil Aouf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11651">
<title>Drift Control of High-Dimensional RBM: A Computational Method Based on Neural Networks. (arXiv:2309.11651v1 [eess.SY])</title>
<link>http://arxiv.org/abs/2309.11651</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by applications in queueing theory, we consider a stochastic
control problem whose state space is the $d$-dimensional positive orthant. The
controlled process $Z$ evolves as a reflected Brownian motion whose covariance
matrix is exogenously specified, as are its directions of reflection from the
orthant&apos;s boundary surfaces. A system manager chooses a drift vector
$\theta(t)$ at each time $t$ based on the history of $Z$, and the cost rate at
time $t$ depends on both $Z(t)$ and $\theta(t)$. In our initial problem
formulation, the objective is to minimize expected discounted cost over an
infinite planning horizon, after which we treat the corresponding ergodic
control problem. Extending earlier work by Han et al. (Proceedings of the
National Academy of Sciences, 2018, 8505-8510), we develop and illustrate a
simulation-based computational method that relies heavily on deep neural
network technology. For test problems studied thus far, our method is accurate
to within a fraction of one percent, and is computationally feasible in
dimensions up to at least $d=30$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ata_B/0/1/0/all/0/1&quot;&gt;Baris Ata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Harrison_J/0/1/0/all/0/1&quot;&gt;J. Michael Harrison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Si_N/0/1/0/all/0/1&quot;&gt;Nian Si&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11657">
<title>GLM Regression with Oblivious Corruptions. (arXiv:2309.11657v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2309.11657</link>
<description rdf:parseType="Literal">&lt;p&gt;We demonstrate the first algorithms for the problem of regression for
generalized linear models (GLMs) in the presence of additive oblivious noise.
We assume we have sample access to examples $(x, y)$ where $y$ is a noisy
measurement of $g(w^* \cdot x)$. In particular, \new{the noisy labels are of
the form} $y = g(w^* \cdot x) + \xi + \epsilon$, where $\xi$ is the oblivious
noise drawn independently of $x$ \new{and satisfies} $\Pr[\xi = 0] \geq o(1)$,
and $\epsilon \sim \mathcal N(0, \sigma^2)$. Our goal is to accurately recover
a \new{parameter vector $w$ such that the} function $g(w \cdot x)$ \new{has}
arbitrarily small error when compared to the true values $g(w^* \cdot x)$,
rather than the noisy measurements $y$.
&lt;/p&gt;
&lt;p&gt;We present an algorithm that tackles \new{this} problem in its most general
distribution-independent setting, where the solution may not \new{even} be
identifiable. \new{Our} algorithm returns \new{an accurate estimate of} the
solution if it is identifiable, and otherwise returns a small list of
candidates, one of which is close to the true solution. Furthermore, we
\new{provide} a necessary and sufficient condition for identifiability, which
holds in broad settings. \new{Specifically,} the problem is identifiable when
the quantile at which $\xi + \epsilon = 0$ is known, or when the family of
hypotheses does not contain candidates that are nearly equal to a translated
$g(w^* \cdot x) + A$ for some real number $A$, while also having large error
when compared to $g(w^* \cdot x)$.
&lt;/p&gt;
&lt;p&gt;This is the first \new{algorithmic} result for GLM regression \new{with
oblivious noise} which can handle more than half the samples being arbitrarily
corrupted. Prior work focused largely on the setting of linear regression, and
gave algorithms under restrictive assumptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1&quot;&gt;Ilias Diakonikolas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karmalkar_S/0/1/0/all/0/1&quot;&gt;Sushrut Karmalkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jongho Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1&quot;&gt;Christos Tzamos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11671">
<title>Popularity Degradation Bias in Local Music Recommendation. (arXiv:2309.11671v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2309.11671</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the effect of popularity degradation bias in the
context of local music recommendations. Specifically, we examine how accurate
two top-performing recommendation algorithms, Weight Relevance Matrix
Factorization (WRMF) and Multinomial Variational Autoencoder (Mult-VAE), are at
recommending artists as a function of artist popularity. We find that both
algorithms improve recommendation performance for more popular artists and, as
such, exhibit popularity degradation bias. While both algorithms produce a
similar level of performance for more popular artists, Mult-VAE shows better
relative performance for less popular artists. This suggests that this
algorithm should be preferred for local (long-tail) music artist
recommendation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trainor_A/0/1/0/all/0/1&quot;&gt;April Trainor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turnbull_D/0/1/0/all/0/1&quot;&gt;Douglas Turnbull&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11680">
<title>Federated Learning with Neural Graphical Models. (arXiv:2309.11680v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11680</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) addresses the need to create models based on
proprietary data in such a way that multiple clients retain exclusive control
over their data, while all benefit from improved model accuracy due to pooled
resources. Recently proposed Neural Graphical Models (NGMs) are Probabilistic
Graphical models that utilize the expressive power of neural networks to learn
complex non-linear dependencies between the input features. They learn to
capture the underlying data distribution and have efficient algorithms for
inference and sampling. We develop a FL framework which maintains a global NGM
model that learns the averaged information from the local NGM models while
keeping the training data within the client&apos;s environment. Our design, FedNGMs,
avoids the pitfalls and shortcomings of neuron matching frameworks like
Federated Matched Averaging that suffers from model parameter explosion. Our
global model size remains constant throughout the process. In the cases where
clients have local variables that are not part of the combined global
distribution, we propose a `Stitching&apos; algorithm, which personalizes the global
NGM models by merging the additional variables using the client&apos;s data. FedNGM
is robust to data heterogeneity, large number of participants, and limited
communication bandwidth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chajewska_U/0/1/0/all/0/1&quot;&gt;Urszula Chajewska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrivastava_H/0/1/0/all/0/1&quot;&gt;Harsh Shrivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11682">
<title>Dr. FERMI: A Stochastic Distributionally Robust Fair Empirical Risk Minimization Framework. (arXiv:2309.11682v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11682</link>
<description rdf:parseType="Literal">&lt;p&gt;While training fair machine learning models has been studied extensively in
recent years, most developed methods rely on the assumption that the training
and test data have similar distributions. In the presence of distribution
shifts, fair models may behave unfairly on test data. There have been some
developments for fair learning robust to distribution shifts to address this
shortcoming. However, most proposed solutions are based on the assumption of
having access to the causal graph describing the interaction of different
features. Moreover, existing algorithms require full access to data and cannot
be used when small batches are used (stochastic/batch implementation). This
paper proposes the first stochastic distributionally robust fairness framework
with convergence guarantees that do not require knowledge of the causal graph.
More specifically, we formulate the fair inference in the presence of the
distribution shift as a distributionally robust optimization problem under
$L_p$ norm uncertainty sets with respect to the Exponential Renyi Mutual
Information (ERMI) as the measure of fairness violation. We then discuss how
the proposed method can be implemented in a stochastic fashion. We have
evaluated the presented framework&apos;s performance and efficiency through
extensive experiments on real datasets consisting of distribution shifts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baharlouei_S/0/1/0/all/0/1&quot;&gt;Sina Baharlouei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1&quot;&gt;Meisam Razaviyayn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11687">
<title>Large-scale Pretraining Improves Sample Efficiency of Active Learning based Molecule Virtual Screening. (arXiv:2309.11687v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11687</link>
<description rdf:parseType="Literal">&lt;p&gt;Virtual screening of large compound libraries to identify potential hit
candidates is one of the earliest steps in drug discovery. As the size of
commercially available compound collections grows exponentially to the scale of
billions, brute-force virtual screening using traditional tools such as docking
becomes infeasible in terms of time and computational resources. Active
learning and Bayesian optimization has recently been proven as effective
methods of narrowing down the search space. An essential component in those
methods is a surrogate machine learning model that is trained with a small
subset of the library to predict the desired properties of compounds. Accurate
model can achieve high sample efficiency by finding the most promising
compounds with only a fraction of the whole library being virtually screened.
In this study, we examined the performance of pretrained transformer-based
language model and graph neural network in Bayesian optimization active
learning framework. The best pretrained models identifies 58.97% of the
top-50000 by docking score after screening only 0.6% of an ultra-large library
containing 99.5 million compounds, improving 8% over previous state-of-the-art
baseline. Through extensive benchmarks, we show that the superior performance
of pretrained models persists in both structure-based and ligand-based drug
discovery. Such model can serve as a boost to the accuracy and sample
efficiency of active learning based molecule virtual screening.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1&quot;&gt;Zhonglin Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sciabola_S/0/1/0/all/0/1&quot;&gt;Simone Sciabola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Ye Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11702">
<title>Incentivized Communication for Federated Bandits. (arXiv:2309.11702v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11702</link>
<description rdf:parseType="Literal">&lt;p&gt;Most existing works on federated bandits take it for granted that all clients
are altruistic about sharing their data with the server for the collective good
whenever needed. Despite their compelling theoretical guarantee on performance
and communication efficiency, this assumption is overly idealistic and
oftentimes violated in practice, especially when the algorithm is operated over
self-interested clients, who are reluctant to share data without explicit
benefits. Negligence of such self-interested behaviors can significantly affect
the learning efficiency and even the practical operability of federated bandit
learning. In light of this, we aim to spark new insights into this
under-explored research area by formally introducing an incentivized
communication problem for federated bandits, where the server shall motivate
clients to share data by providing incentives. Without loss of generality, we
instantiate this bandit problem with the contextual linear setting and propose
the first incentivized communication protocol, namely, Inc-FedUCB, that
achieves near-optimal regret with provable communication and incentive cost
guarantees. Extensive empirical experiments on both synthetic and real-world
datasets further validate the effectiveness of the proposed method across
various environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1&quot;&gt;Zhepei Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chuanhao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Haifeng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongning Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11705">
<title>Meta OOD Learning for Continuously Adaptive OOD Detection. (arXiv:2309.11705v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11705</link>
<description rdf:parseType="Literal">&lt;p&gt;Out-of-distribution (OOD) detection is crucial to modern deep learning
applications by identifying and alerting about the OOD samples that should not
be tested or used for making predictions. Current OOD detection methods have
made significant progress when in-distribution (ID) and OOD samples are drawn
from static distributions. However, this can be unrealistic when applied to
real-world systems which often undergo continuous variations and shifts in ID
and OOD distributions over time. Therefore, for an effective application in
real-world systems, the development of OOD detection methods that can adapt to
these dynamic and evolving distributions is essential. In this paper, we
propose a novel and more realistic setting called continuously adaptive
out-of-distribution (CAOOD) detection which targets on developing an OOD
detection model that enables dynamic and quick adaptation to a new arriving
distribution, with insufficient ID samples during deployment time. To address
CAOOD, we develop meta OOD learning (MOL) by designing a learning-to-adapt
diagram such that a good initialized OOD detection model is learned during the
training process. In the testing process, MOL ensures OOD detection performance
over shifting distributions by quickly adapting to new distributions with a few
adaptations. Extensive experiments on several OOD benchmarks endorse the
effectiveness of our method in preserving both ID classification accuracy and
OOD detection performance on continuously shifting distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xinheng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jie Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1&quot;&gt;Zhen Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Guangquan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11713">
<title>Quasi-Monte Carlo for 3D Sliced Wasserstein. (arXiv:2309.11713v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.11713</link>
<description rdf:parseType="Literal">&lt;p&gt;Monte Carlo (MC) approximation has been used as the standard computation
approach for the Sliced Wasserstein (SW) distance, which has an intractable
expectation in its analytical form. However, the MC method is not optimal in
terms of minimizing the absolute approximation error. To provide a better class
of empirical SW, we propose quasi-sliced Wasserstein (QSW) approximations that
rely on Quasi-Monte Carlo (QMC) methods. For a comprehensive investigation of
QMC for SW, we focus on the 3D setting, specifically computing the SW between
probability measures in three dimensions. In greater detail, we empirically
verify various ways of constructing QMC points sets on the 3D unit-hypersphere,
including Gaussian-based mapping, equal area mapping, generalized spiral
points, and optimizing discrepancy energies. Furthermore, to obtain an unbiased
estimation for stochastic optimization, we extend QSW into Randomized
Quasi-Sliced Wasserstein (RQSW) by introducing randomness to the discussed
low-discrepancy sequences. For theoretical properties, we prove the asymptotic
convergence of QSW and the unbiasedness of RQSW. Finally, we conduct
experiments on various 3D tasks, such as point-cloud comparison, point-cloud
interpolation, image style transfer, and training deep point-cloud
autoencoders, to demonstrate the favorable performance of the proposed QSW and
RQSW variants.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nguyen_K/0/1/0/all/0/1&quot;&gt;Khai Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bariletto_N/0/1/0/all/0/1&quot;&gt;Nicola Bariletto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1&quot;&gt;Nhat Ho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11714">
<title>A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification. (arXiv:2309.11714v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2309.11714</link>
<description rdf:parseType="Literal">&lt;p&gt;There is a correlation between adjacent channels of electroencephalogram
(EEG), and how to represent this correlation is an issue that is currently
being explored. In addition, due to inter-individual differences in EEG
signals, this discrepancy results in new subjects need spend a amount of
calibration time for EEG-based motor imagery brain-computer interface. In order
to solve the above problems, we propose a Dynamic Domain Adaptation Based Deep
Learning Network (DADL-Net). First, the EEG data is mapped to the
three-dimensional geometric space and its temporal-spatial features are learned
through the 3D convolution module, and then the spatial-channel attention
mechanism is used to strengthen the features, and the final convolution module
can further learn the spatial-temporal information of the features. Finally, to
account for inter-subject and cross-sessions differences, we employ a dynamic
domain-adaptive strategy, the distance between features is reduced by
introducing a Maximum Mean Discrepancy loss function, and the classification
layer is fine-tuned by using part of the target domain data. We verify the
performance of the proposed method on BCI competition IV 2a and OpenBMI
datasets. Under the intra-subject experiment, the accuracy rates of 70.42% and
73.91% were achieved on the OpenBMI and BCIC IV 2a datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jie Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Meiyan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Qingqing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hefan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wangliang Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11722">
<title>Efficient Core-selecting Incentive Mechanism for Data Sharing in Federated Learning. (arXiv:2309.11722v1 [cs.GT])</title>
<link>http://arxiv.org/abs/2309.11722</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning is a distributed machine learning system that uses
participants&apos; data to train an improved global model. In federated learning,
participants cooperatively train a global model, and they will receive the
global model and payments. Rational participants try to maximize their
individual utility, and they will not input their high-quality data truthfully
unless they are provided with satisfactory payments based on their data
quality. Furthermore, federated learning benefits from the cooperative
contributions of participants. Accordingly, how to establish an incentive
mechanism that both incentivizes inputting data truthfully and promotes stable
cooperation has become an important issue to consider. In this paper, we
introduce a data sharing game model for federated learning and employ
game-theoretic approaches to design a core-selecting incentive mechanism by
utilizing a popular concept in cooperative games, the core. In federated
learning, the core can be empty, resulting in the core-selecting mechanism
becoming infeasible. To address this, our core-selecting mechanism employs a
relaxation method and simultaneously minimizes the benefits of inputting false
data for all participants. However, this mechanism is computationally expensive
because it requires aggregating exponential models for all possible coalitions,
which is infeasible in federated learning. To address this, we propose an
efficient core-selecting mechanism based on sampling approximation that only
aggregates models on sampled coalitions to approximate the exact result.
Extensive experiments verify that the efficient core-selecting mechanism can
incentivize inputting high-quality data and stable cooperation, while it
reduces computational overhead compared to the core-selecting mechanism.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_M/0/1/0/all/0/1&quot;&gt;Mengda Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1&quot;&gt;Genjiu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1&quot;&gt;Jianjun Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mingqiang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11726">
<title>Turaco: Complexity-Guided Data Sampling for Training Neural Surrogates of Programs. (arXiv:2309.11726v1 [cs.PL])</title>
<link>http://arxiv.org/abs/2309.11726</link>
<description rdf:parseType="Literal">&lt;p&gt;Programmers and researchers are increasingly developing surrogates of
programs, models of a subset of the observable behavior of a given program, to
solve a variety of software development challenges. Programmers train
surrogates from measurements of the behavior of a program on a dataset of input
examples. A key challenge of surrogate construction is determining what
training data to use to train a surrogate of a given program.
&lt;/p&gt;
&lt;p&gt;We present a methodology for sampling datasets to train neural-network-based
surrogates of programs. We first characterize the proportion of data to sample
from each region of a program&apos;s input space (corresponding to different
execution paths of the program) based on the complexity of learning a surrogate
of the corresponding execution path. We next provide a program analysis to
determine the complexity of different paths in a program. We evaluate these
results on a range of real-world programs, demonstrating that complexity-guided
sampling results in empirical improvements in accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renda_A/0/1/0/all/0/1&quot;&gt;Alex Renda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1&quot;&gt;Yi Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carbin_M/0/1/0/all/0/1&quot;&gt;Michael Carbin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11741">
<title>Unveiling Optimal SDG Pathways: An Innovative Approach Leveraging Graph Pruning and Intent Graph for Effective Recommendations. (arXiv:2309.11741v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2309.11741</link>
<description rdf:parseType="Literal">&lt;p&gt;The recommendation of appropriate development pathways, also known as
ecological civilization patterns for achieving Sustainable Development Goals
(namely, sustainable development patterns), are of utmost importance for
promoting ecological, economic, social, and resource sustainability in a
specific region. To achieve this, the recommendation process must carefully
consider the region&apos;s natural, environmental, resource, and economic
characteristics. However, current recommendation algorithms in the field of
computer science fall short in adequately addressing the spatial heterogeneity
related to environment and sparsity of regional historical interaction data,
which limits their effectiveness in recommending sustainable development
patterns. To overcome these challenges, this paper proposes a method called
User Graph after Pruning and Intent Graph (UGPIG). Firstly, we utilize the
high-density linking capability of the pruned User Graph to address the issue
of spatial heterogeneity neglect in recommendation algorithms. Secondly, we
construct an Intent Graph by incorporating the intent network, which captures
the preferences for attributes including environmental elements of target
regions. This approach effectively alleviates the problem of sparse historical
interaction data in the region. Through extensive experiments, we demonstrate
that UGPIG outperforms state-of-the-art recommendation algorithms like KGCN,
KGAT, and KGIN in sustainable development pattern recommendations, with a
maximum improvement of 9.61% in Top-3 recommendation performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhihang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yunqiang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1&quot;&gt;Wen Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1&quot;&gt;Xiaoliang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Zou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11745">
<title>PIE: Simulating Disease Progression via Progressive Image Editing. (arXiv:2309.11745v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.11745</link>
<description rdf:parseType="Literal">&lt;p&gt;Disease progression simulation is a crucial area of research that has
significant implications for clinical diagnosis, prognosis, and treatment. One
major challenge in this field is the lack of continuous medical imaging
monitoring of individual patients over time. To address this issue, we develop
a novel framework termed Progressive Image Editing (PIE) that enables
controlled manipulation of disease-related image features, facilitating precise
and realistic disease progression simulation. Specifically, we leverage recent
advancements in text-to-image generative models to simulate disease progression
accurately and personalize it for each patient. We theoretically analyze the
iterative refining process in our framework as a gradient descent with an
exponentially decayed learning rate. To validate our framework, we conduct
experiments in three medical imaging domains. Our results demonstrate the
superiority of PIE over existing methods such as Stable Diffusion Walk and
Style-Based Manifold Extrapolation based on CLIP score (Realism) and Disease
Classification Confidence (Alignment). Our user study collected feedback from
35 veteran physicians to assess the generated progressions. Remarkably, 76.2%
of the feedback agrees with the fidelity of the generated progressions. To our
best knowledge, PIE is the first of its kind to generate disease progression
images meeting real-world standards. It is a promising tool for medical
research and clinical practice, potentially allowing healthcare providers to
model disease trajectories over time, predict future treatment responses, and
improve patient outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liang_K/0/1/0/all/0/1&quot;&gt;Kaizhao Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cao_X/0/1/0/all/0/1&quot;&gt;Xu Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liao_K/0/1/0/all/0/1&quot;&gt;Kuei-Da Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Tianren Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhengyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nama_T/0/1/0/all/0/1&quot;&gt;Tejas Nama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11751">
<title>How Robust is Google&apos;s Bard to Adversarial Image Attacks?. (arXiv:2309.11751v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.11751</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal Large Language Models (MLLMs) that integrate text and other
modalities (especially vision) have achieved unprecedented performance in
various multimodal tasks. However, due to the unsolved adversarial robustness
problem of vision models, MLLMs can have more severe safety and security risks
by introducing the vision inputs. In this work, we study the adversarial
robustness of Google&apos;s Bard, a competitive chatbot to ChatGPT that released its
multimodal capability recently, to better understand the vulnerabilities of
commercial MLLMs. By attacking white-box surrogate vision encoders or MLLMs,
the generated adversarial examples can mislead Bard to output wrong image
descriptions with a 22% success rate based solely on the transferability. We
show that the adversarial examples can also attack other MLLMs, e.g., a 26%
attack success rate against Bing Chat and a 86% attack success rate against
ERNIE bot. Moreover, we identify two defense mechanisms of Bard, including face
detection and toxicity detection of images. We design corresponding attacks to
evade these defenses, demonstrating that the current defenses of Bard are also
vulnerable. We hope this work can deepen our understanding on the robustness of
MLLMs and facilitate future research on defenses. Our code is available at
https://github.com/thu-ml/Attack-Bard.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yinpeng Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huanran Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiawei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1&quot;&gt;Zhengwei Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xiao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yichi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yu Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11758">
<title>SAM-OCTA: A Fine-Tuning Strategy for Applying Foundation Model to OCTA Image Segmentation Tasks. (arXiv:2309.11758v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.11758</link>
<description rdf:parseType="Literal">&lt;p&gt;In the analysis of optical coherence tomography angiography (OCTA) images,
the operation of segmenting specific targets is necessary. Existing methods
typically train on supervised datasets with limited samples (approximately a
few hundred), which can lead to overfitting. To address this, the low-rank
adaptation technique is adopted for foundation model fine-tuning and proposed
corresponding prompt point generation strategies to process various
segmentation tasks on OCTA datasets. This method is named SAM-OCTA and has been
experimented on the publicly available OCTA-500 dataset. While achieving
state-of-the-art performance metrics, this method accomplishes local vessel
segmentation as well as effective artery-vein segmentation, which was not
well-solved in previous works. The code is available at:
https://github.com/ShellRedia/SAM-OCTA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chengliang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinrun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_H/0/1/0/all/0/1&quot;&gt;Haojian Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shiying Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11765">
<title>Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation. (arXiv:2309.11765v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11765</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of in-context learning (ICL) with large language models
(LLMs) on private datasets. This scenario poses privacy risks, as LLMs may leak
or regurgitate the private examples demonstrated in the prompt. We propose a
novel algorithm that generates synthetic few-shot demonstrations from the
private dataset with formal differential privacy (DP) guarantees, and show
empirically that it can achieve effective ICL. We conduct extensive experiments
on standard benchmarks and compare our algorithm with non-private ICL and
zero-shot solutions. Our results demonstrate that our algorithm can achieve
competitive performance with strong privacy levels. These results open up new
possibilities for ICL with privacy protection for a broad range of
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1&quot;&gt;Xinyu Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_R/0/1/0/all/0/1&quot;&gt;Richard Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inan_H/0/1/0/all/0/1&quot;&gt;Huseyin A. Inan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manoel_A/0/1/0/all/0/1&quot;&gt;Andre Manoel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mireshghallah_F/0/1/0/all/0/1&quot;&gt;Fatemehsadat Mireshghallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zinan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1&quot;&gt;Sivakanth Gopi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1&quot;&gt;Janardhan Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1&quot;&gt;Robert Sim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11766">
<title>Dictionary Attack on IMU-based Gait Authentication. (arXiv:2309.11766v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2309.11766</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel adversarial model for authentication systems that use gait
patterns recorded by the inertial measurement unit (IMU) built into
smartphones. The attack idea is inspired by and named after the concept of a
dictionary attack on knowledge (PIN or password) based authentication systems.
In particular, this work investigates whether it is possible to build a
dictionary of IMUGait patterns and use it to launch an attack or find an
imitator who can actively reproduce IMUGait patterns that match the target&apos;s
IMUGait pattern. Nine physically and demographically diverse individuals walked
at various levels of four predefined controllable and adaptable gait factors
(speed, step length, step width, and thigh-lift), producing 178 unique IMUGait
patterns. Each pattern attacked a wide variety of user authentication models.
The deeper analysis of error rates (before and after the attack) challenges the
belief that authentication systems based on IMUGait patterns are the most
difficult to spoof; further research is needed on adversarial models and
associated countermeasures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Rajesh Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isik_C/0/1/0/all/0/1&quot;&gt;Can Isik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohan_C/0/1/0/all/0/1&quot;&gt;Chilukuri K. Mohan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11782">
<title>DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning. (arXiv:2309.11782v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.11782</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised learning (SSL) has gained remarkable success, for which
contrastive learning (CL) plays a key role. However, the recent development of
new non-CL frameworks has achieved comparable or better performance with high
improvement potential, prompting researchers to enhance these frameworks
further. Assimilating CL into non-CL frameworks has been thought to be
beneficial, but empirical evidence indicates no visible improvements. In view
of that, this paper proposes a strategy of performing CL along the dimensional
direction instead of along the batch direction as done in conventional
contrastive learning, named Dimensional Contrastive Learning (DimCL). DimCL
aims to enhance the feature diversity, and it can serve as a regularizer to
prior SSL frameworks. DimCL has been found to be effective, and the
hardness-aware property is identified as a critical reason for its success.
Extensive experimental results reveal that assimilating DimCL into SSL
frameworks leads to performance improvement by a non-trivial margin on various
datasets and backbone architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thanh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1&quot;&gt;Trung Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chaoning Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luu_T/0/1/0/all/0/1&quot;&gt;Tung Luu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1&quot;&gt;Thang Vu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1&quot;&gt;Chang D. Yoo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11798">
<title>A Comprehensive Review of Community Detection in Graphs. (arXiv:2309.11798v1 [cs.SI])</title>
<link>http://arxiv.org/abs/2309.11798</link>
<description rdf:parseType="Literal">&lt;p&gt;The study of complex networks has significantly advanced our understanding of
community structures which serves as a crucial feature of real-world graphs.
Detecting communities in graphs is a challenging problem with applications in
sociology, biology, and computer science. Despite the efforts of an
interdisciplinary community of scientists, a satisfactory solution to this
problem has not yet been achieved. This review article delves into the topic of
community detection in graphs, which serves as a crucial role in understanding
the organization and functioning of complex systems. We begin by introducing
the concept of community structure, which refers to the arrangement of vertices
into clusters, with strong internal connections and weaker connections between
clusters. Then, we provide a thorough exposition of various community detection
methods, including a new method designed by us. Additionally, we explore
real-world applications of community detection in diverse networks. In
conclusion, this comprehensive review provides a deep understanding of
community detection in graphs. It serves as a valuable resource for researchers
and practitioners in multiple disciplines, offering insights into the
challenges, methodologies, and applications of community detection in complex
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_S/0/1/0/all/0/1&quot;&gt;Songlai Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiakang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yonggang Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11845">
<title>TMac: Temporal Multi-Modal Graph Learning for Acoustic Event Classification. (arXiv:2309.11845v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.11845</link>
<description rdf:parseType="Literal">&lt;p&gt;Audiovisual data is everywhere in this digital age, which raises higher
requirements for the deep learning models developed on them. To well handle the
information of the multi-modal data is the key to a better audiovisual modal.
We observe that these audiovisual data naturally have temporal attributes, such
as the time information for each frame in the video. More concretely, such data
is inherently multi-modal according to both audio and visual cues, which
proceed in a strict chronological order. It indicates that temporal information
is important in multi-modal acoustic event modeling for both intra- and
inter-modal. However, existing methods deal with each modal feature
independently and simply fuse them together, which neglects the mining of
temporal relation and thus leads to sub-optimal performance. With this
motivation, we propose a Temporal Multi-modal graph learning method for
Acoustic event Classification, called TMac, by modeling such temporal
information via graph learning techniques. In particular, we construct a
temporal graph for each acoustic event, dividing its audio data and video data
into multiple segments. Each segment can be considered as a node, and the
temporal relationships between nodes can be considered as timestamps on their
edges. In this case, we can smoothly capture the dynamic information in
intra-modal and inter-modal. Several experiments are conducted to demonstrate
TMac outperforms other SOTA models in performance. Our code is available at
https://github.com/MGitHubL/TMac.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Meng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1&quot;&gt;Ke Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1&quot;&gt;Dayu Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1&quot;&gt;Lingyuan Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_W/0/1/0/all/0/1&quot;&gt;Wenxuan Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Sihang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xinwang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11856">
<title>Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization. (arXiv:2309.11856v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.11856</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient training of large-scale graph neural networks (GNNs) has been
studied with a specific focus on reducing their memory consumption. Work by Liu
et al. (2022) proposed extreme activation compression (EXACT) which
demonstrated drastic reduction in memory consumption by performing quantization
of the intermediate activation maps down to using INT2 precision. They showed
little to no reduction in performance while achieving large reductions in GPU
memory consumption. In this work, we present an improvement to the EXACT
strategy by using block-wise quantization of the intermediate activation maps.
We experimentally analyze different block sizes and show further reduction in
memory consumption (&amp;gt;15%), and runtime speedup per epoch (about 5%) even when
performing extreme extents of quantization with similar performance trade-offs
as with the original EXACT. Further, we present a correction to the assumptions
on the distribution of intermediate activation maps in EXACT (assumed to be
uniform) and show improved variance estimations of the quantization and
dequantization steps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Eliassen_S/0/1/0/all/0/1&quot;&gt;Sebastian Eliassen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Selvan_R/0/1/0/all/0/1&quot;&gt;Raghavendra Selvan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11875">
<title>Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes. (arXiv:2309.11875v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11875</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning models trained with structural health monitoring data have
become a powerful tool for system identification. This paper presents a
physics-informed Gaussian process (GP) model for Timoshenko beam elements. The
model is constructed as a multi-output GP with covariance and cross-covariance
kernels analytically derived based on the differential equations for
deflections, rotations, strains, bending moments, shear forces and applied
loads. Stiffness identification is performed in a Bayesian format by maximising
a posterior model through a Markov chain Monte Carlo method, yielding a
stochastic model for the structural parameters. The optimised GP model is
further employed for probabilistic predictions of unobserved responses.
Additionally, an entropy-based method for physics-informed sensor placement
optimisation is presented, exploiting heterogeneous sensor position information
and structural boundary conditions built into the GP model. Results demonstrate
that the proposed approach is effective at identifying structural parameters
and is capable of fusing data from heterogeneous and multi-fidelity sensors.
Probabilistic predictions of structural responses and internal forces are in
closer agreement with measured data. We validate our model with an experimental
setup and discuss the quality and uncertainty of the obtained results. The
proposed approach has potential applications in the field of structural health
monitoring (SHM) for both mechanical and structural systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tondo_G/0/1/0/all/0/1&quot;&gt;Gledson Rodrigo Tondo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rau_S/0/1/0/all/0/1&quot;&gt;Sebastian Rau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kavrakov_I/0/1/0/all/0/1&quot;&gt;Igor Kavrakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morgenthal_G/0/1/0/all/0/1&quot;&gt;Guido Morgenthal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11930">
<title>Bridging the Gap: Learning Pace Synchronization for Open-World Semi-Supervised Learning. (arXiv:2309.11930v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11930</link>
<description rdf:parseType="Literal">&lt;p&gt;In open-world semi-supervised learning, a machine learning model is tasked
with uncovering novel categories from unlabeled data while maintaining
performance on seen categories from labeled data. The central challenge is the
substantial learning gap between seen and novel categories, as the model learns
the former faster due to accurate supervisory information. To address this, we
introduce 1) an adaptive margin loss based on estimated class distribution,
which encourages a large negative margin for samples in seen classes, to
synchronize learning paces, and 2) pseudo-label contrastive clustering, which
pulls together samples which are likely from the same class in the output
space, to enhance novel class discovery. Our extensive evaluations on multiple
datasets demonstrate that existing models still hinder novel class learning,
whereas our approach strikingly balances both seen and novel classes, achieving
a remarkable 3% average accuracy increase on the ImageNet dataset compared to
the prior state-of-the-art. Additionally, we find that fine-tuning the
self-supervised pre-trained backbone significantly boosts performance over the
default in prior literature. After our paper is accepted, we will release the
code.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_B/0/1/0/all/0/1&quot;&gt;Bo Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gan_K/0/1/0/all/0/1&quot;&gt;Kai Gan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1&quot;&gt;Tong Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Min-Ling Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11932">
<title>A Machine Learning-oriented Survey on Tiny Machine Learning. (arXiv:2309.11932v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11932</link>
<description rdf:parseType="Literal">&lt;p&gt;The emergence of Tiny Machine Learning (TinyML) has positively revolutionized
the field of Artificial Intelligence by promoting the joint design of
resource-constrained IoT hardware devices and their learning-based software
architectures. TinyML carries an essential role within the fourth and fifth
industrial revolutions in helping societies, economies, and individuals employ
effective AI-infused computing technologies (e.g., smart cities, automotive,
and medical robotics). Given its multidisciplinary nature, the field of TinyML
has been approached from many different angles: this comprehensive survey
wishes to provide an up-to-date overview focused on all the learning algorithms
within TinyML-based solutions. The survey is based on the Preferred Reporting
Items for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow,
allowing for a systematic and complete literature survey. In particular,
firstly we will examine the three different workflows for implementing a
TinyML-based system, i.e., ML-oriented, HW-oriented, and co-design. Secondly,
we propose a taxonomy that covers the learning panorama under the TinyML lens,
examining in detail the different families of model optimization and design, as
well as the state-of-the-art learning techniques. Thirdly, this survey will
present the distinct features of hardware devices and software tools that
represent the current state-of-the-art for TinyML intelligent edge
applications. Finally, we discuss the challenges and future directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Capogrosso_L/0/1/0/all/0/1&quot;&gt;Luigi Capogrosso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cunico_F/0/1/0/all/0/1&quot;&gt;Federico Cunico&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1&quot;&gt;Dong Seon Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fummi_F/0/1/0/all/0/1&quot;&gt;Franco Fummi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+cristani_M/0/1/0/all/0/1&quot;&gt;Marco cristani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11942">
<title>On the Probability of Immunity. (arXiv:2309.11942v1 [stat.ME])</title>
<link>http://arxiv.org/abs/2309.11942</link>
<description rdf:parseType="Literal">&lt;p&gt;This work is devoted to the study of the probability of immunity, i.e. the
effect occurs whether exposed or not. We derive necessary and sufficient
conditions for non-immunity and $\epsilon$-bounded immunity, i.e. the
probability of immunity is zero and $\epsilon$-bounded, respectively. The
former allows us to estimate the probability of benefit (i.e., the effect
occurs if and only if exposed) from a randomized controlled trial, and the
latter allows us to produce bounds of the probability of benefit that are
tighter than the existing ones. We also introduce the concept of indirect
immunity (i.e., through a mediator) and repeat our previous analysis for it.
Finally, we propose a method for sensitivity analysis of the probability of
immunity under unmeasured confounding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1&quot;&gt;Jose M. Pe&amp;#xf1;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11955">
<title>A Study of Forward-Forward Algorithm for Self-Supervised Learning. (arXiv:2309.11955v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.11955</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-supervised representation learning has seen remarkable progress in the
last few years, with some of the recent methods being able to learn useful
image representations without labels. These methods are trained using
backpropagation, the de facto standard. Recently, Geoffrey Hinton proposed the
forward-forward algorithm as an alternative training method. It utilizes two
forward passes and a separate loss function for each layer to train the network
without backpropagation.
&lt;/p&gt;
&lt;p&gt;In this study, for the first time, we study the performance of
forward-forward vs. backpropagation for self-supervised representation learning
and provide insights into the learned representation spaces. Our benchmark
employs four standard datasets, namely MNIST, F-MNIST, SVHN and CIFAR-10, and
three commonly used self-supervised representation learning techniques, namely
rotation, flip and jigsaw.
&lt;/p&gt;
&lt;p&gt;Our main finding is that while the forward-forward algorithm performs
comparably to backpropagation during (self-)supervised training, the transfer
performance is significantly lagging behind in all the studied settings. This
may be caused by a combination of factors, including having a loss function for
each layer and the way the supervised training is realized in the
forward-forward paradigm. In comparison to backpropagation, the forward-forward
algorithm focuses more on the boundaries and drops part of the information
unnecessary for making decisions which harms the representation learning goal.
Further investigation and research are necessary to stabilize the
forward-forward strategy for self-supervised learning, to work beyond the
datasets and configurations demonstrated by Geoffrey Hinton.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brenig_J/0/1/0/all/0/1&quot;&gt;Jonas Brenig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1&quot;&gt;Radu Timofte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11963">
<title>Generating Hierarchical Structures for Improved Time Series Classification Using Stochastic Splitting Functions. (arXiv:2309.11963v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11963</link>
<description rdf:parseType="Literal">&lt;p&gt;This study introduces a novel hierarchical divisive clustering approach with
stochastic splitting functions (SSFs) to enhance classification performance in
multi-class datasets through hierarchical classification (HC). The method has
the unique capability of generating hierarchy without requiring explicit
information, making it suitable for datasets lacking prior knowledge of
hierarchy. By systematically dividing classes into two subsets based on their
discriminability according to the classifier, the proposed approach constructs
a binary tree representation of hierarchical classes. The approach is evaluated
on 46 multi-class time series datasets using popular classifiers (svm and
rocket) and SSFs (potr, srtr, and lsoo). The results reveal that the approach
significantly improves classification performance in approximately half and a
third of the datasets when using rocket and svm as the classifier,
respectively. The study also explores the relationship between dataset features
and HC performance. While the number of classes and flat classification (FC)
score show consistent significance, variations are observed with different
splitting functions. Overall, the proposed approach presents a promising
strategy for enhancing classification by generating hierarchical structure in
multi-class time series datasets. Future research directions involve exploring
different splitting functions, classifiers, and hierarchy structures, as well
as applying the approach to diverse domains beyond time series data. The source
code is made openly available to facilitate reproducibility and further
exploration of the method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alagoz_C/0/1/0/all/0/1&quot;&gt;Celal Alagoz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11979">
<title>Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT. (arXiv:2309.11979v1 [q-fin.CP])</title>
<link>http://arxiv.org/abs/2309.11979</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid development of big data and computing devices, low-latency
automatic trading platforms based on real-time information acquisition have
become the main components of the stock trading market, so the topic of
quantitative trading has received widespread attention. And for non-strongly
efficient trading markets, human emotions and expectations always dominate
market trends and trading decisions. Therefore, this paper starts from the
theory of emotion, taking East Money as an example, crawling user comment
titles data from its corresponding stock bar and performing data cleaning.
Subsequently, a natural language processing model BERT was constructed, and the
BERT model was fine-tuned using existing annotated data sets. The experimental
results show that the fine-tuned model has different degrees of performance
improvement compared to the original model and the baseline model.
Subsequently, based on the above model, the user comment data crawled is
labeled with emotional polarity, and the obtained label information is combined
with the Alpha191 model to participate in regression, and significant
regression results are obtained. Subsequently, the regression model is used to
predict the average price change for the next five days, and use it as a signal
to guide automatic trading. The experimental results show that the
incorporation of emotional factors increased the return rate by 73.8\% compared
to the baseline during the trading period, and by 32.41\% compared to the
original alpha191 model. Finally, we discuss the advantages and disadvantages
of incorporating emotional factors into quantitative trading, and give possible
directions for further research in the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Lou_J/0/1/0/all/0/1&quot;&gt;Jiashu Lou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11983">
<title>Variational Connectionist Temporal Classification for Order-Preserving Sequence Modeling. (arXiv:2309.11983v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11983</link>
<description rdf:parseType="Literal">&lt;p&gt;Connectionist temporal classification (CTC) is commonly adopted for sequence
modeling tasks like speech recognition, where it is necessary to preserve order
between the input and target sequences. However, CTC is only applied to
deterministic sequence models, where the latent space is discontinuous and
sparse, which in turn makes them less capable of handling data variability when
compared to variational models. In this paper, we integrate CTC with a
variational model and derive loss functions that can be used to train more
generalizable sequence models that preserve order. Specifically, we derive two
versions of the novel variational CTC based on two reasonable assumptions, the
first being that the variational latent variables at each time step are
conditionally independent; and the second being that these latent variables are
Markovian. We show that both loss functions allow direct optimization of the
variational lower bound for the model log-likelihood, and present
computationally tractable forms for implementing them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nan_Z/0/1/0/all/0/1&quot;&gt;Zheng Nan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1&quot;&gt;Ting Dang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sethu_V/0/1/0/all/0/1&quot;&gt;Vidhyasaharan Sethu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_B/0/1/0/all/0/1&quot;&gt;Beena Ahmed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11987">
<title>Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis. (arXiv:2309.11987v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.11987</link>
<description rdf:parseType="Literal">&lt;p&gt;Post-hoc explainability methods aim to clarify predictions of black-box
machine learning models. However, it is still largely unclear how well users
comprehend the provided explanations and whether these increase the users
ability to predict the model behavior. We approach this question by conducting
a user study to evaluate comprehensibility and predictability in two widely
used tools: LIME and SHAP. Moreover, we investigate the effect of
counterfactual explanations and misclassifications on users ability to
understand and predict the model behavior. We find that the comprehensibility
of SHAP is significantly reduced when explanations are provided for samples
near a model&apos;s decision boundary. Furthermore, we find that counterfactual
explanations and misclassifications can significantly increase the users
understanding of how a machine learning model is making decisions. Based on our
findings, we also derive design recommendations for future post-hoc
explainability methods with increased comprehensibility and predictability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jalali_A/0/1/0/all/0/1&quot;&gt;Anahid Jalali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haslhofer_B/0/1/0/all/0/1&quot;&gt;Bernhard Haslhofer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kriglstein_S/0/1/0/all/0/1&quot;&gt;Simone Kriglstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rauber_A/0/1/0/all/0/1&quot;&gt;Andreas Rauber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11994">
<title>Enhancing SAEAs with Unevaluated Solutions: A Case Study of Relation Model for Expensive Optimization. (arXiv:2309.11994v1 [cs.NE])</title>
<link>http://arxiv.org/abs/2309.11994</link>
<description rdf:parseType="Literal">&lt;p&gt;Surrogate-assisted evolutionary algorithms (SAEAs) hold significant
importance in resolving expensive optimization problems~(EOPs). Extensive
efforts have been devoted to improving the efficacy of SAEAs through the
development of proficient model-assisted selection methods. However, generating
high-quality solutions is a prerequisite for selection. The fundamental
paradigm of evaluating a limited number of solutions in each generation within
SAEAs reduces the variance of adjacent populations, thus impacting the quality
of offspring solutions. This is a frequently encountered issue, yet it has not
gained widespread attention. This paper presents a framework using unevaluated
solutions to enhance the efficiency of SAEAs. The surrogate model is employed
to identify high-quality solutions for direct generation of new solutions
without evaluation. To ensure dependable selection, we have introduced two
tailored relation models for the selection of the optimal solution and the
unevaluated population. A comprehensive experimental analysis is performed on
two test suites, which showcases the superiority of the relation model over
regression and classification models in the selection phase. Furthermore, the
surrogate-selected unevaluated solutions with high potential have been shown to
significantly enhance the efficiency of the algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_H/0/1/0/all/0/1&quot;&gt;Hao Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaoqun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Aimin Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11995">
<title>Identification of pneumonia on chest x-ray images through machine learning. (arXiv:2309.11995v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.11995</link>
<description rdf:parseType="Literal">&lt;p&gt;Pneumonia is the leading infectious cause of infant death in the world. When
identified early, it is possible to alter the prognosis of the patient, one
could use imaging exams to help in the diagnostic confirmation. Performing and
interpreting the exams as soon as possible is vital for a good treatment, with
the most common exam for this pathology being chest X-ray. The objective of
this study was to develop a software that identify the presence or absence of
pneumonia in chest radiographs. The software was developed as a computational
model based on machine learning using transfer learning technique. For the
training process, images were collected from a database available online with
children&apos;s chest X-rays images taken at a hospital in China. After training,
the model was then exposed to new images, achieving relevant results on
identifying such pathology, reaching 98% sensitivity and 97.3% specificity for
the sample used for testing. It can be concluded that it is possible to develop
a software that identifies pneumonia in chest X-ray images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Roeder_E/0/1/0/all/0/1&quot;&gt;Eduardo Augusto Roeder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12004">
<title>Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption. (arXiv:2309.12004v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12004</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a Hierarchical Reinforcement Learning methodology
tailored for optimizing CubeSat task scheduling in Low Earth Orbits (LEO).
Incorporating a high-level policy for global task distribution and a low-level
policy for real-time adaptations as a safety mechanism, our approach integrates
the Similarity Attention-based Encoder (SABE) for task prioritization and an
MLP estimator for energy consumption forecasting. Integrating this mechanism
creates a safe and fault-tolerant system for CubeSat task scheduling.
Simulation results validate the Hierarchical Reinforcement Learning superior
convergence and task success rate, outperforming both the MADDPG model and
traditional random scheduling across multiple CubeSat configurations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramezani_M/0/1/0/all/0/1&quot;&gt;Mahya Ramezani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alandihallaj_M/0/1/0/all/0/1&quot;&gt;M. Amin Alandihallaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_Lopez_J/0/1/0/all/0/1&quot;&gt;Jose Luis Sanchez-Lopez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_A/0/1/0/all/0/1&quot;&gt;Andreas Hein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12025">
<title>Robust Approximation Algorithms for Non-monotone $k$-Submodular Maximization under a Knapsack Constraint. (arXiv:2309.12025v1 [cs.DS])</title>
<link>http://arxiv.org/abs/2309.12025</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of non-monotone $k$-submodular maximization under a knapsack
constraint ($\kSMK$) over the ground set size $n$ has been raised in many
applications in machine learning, such as data summarization, information
propagation, etc. However, existing algorithms for the problem are facing
questioning of how to overcome the non-monotone case and how to fast return a
good solution in case of the big size of data. This paper introduces two
deterministic approximation algorithms for the problem that competitively
improve the query complexity of existing algorithms.
&lt;/p&gt;
&lt;p&gt;Our first algorithm, $\LAA$, returns an approximation ratio of $1/19$ within
$O(nk)$ query complexity. The second one, $\RLA$, improves the approximation
ratio to $1/5-\epsilon$ in $O(nk)$ queries, where $\epsilon$ is an input
parameter.
&lt;/p&gt;
&lt;p&gt;Our algorithms are the first ones that provide constant approximation ratios
within only $O(nk)$ query complexity for the non-monotone objective. They,
therefore, need fewer the number of queries than state-of-the-the-art ones by a
factor of $\Omega(\log n)$.
&lt;/p&gt;
&lt;p&gt;Besides the theoretical analysis, we have evaluated our proposed ones with
several experiments in some instances: Influence Maximization and Sensor
Placement for the problem. The results confirm that our algorithms ensure
theoretical quality as the cutting-edge techniques and significantly reduce the
number of queries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_D/0/1/0/all/0/1&quot;&gt;Dung T.K. Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_C/0/1/0/all/0/1&quot;&gt;Canh V. Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Tan D. Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_H/0/1/0/all/0/1&quot;&gt;Huan X. Hoang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12028">
<title>Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting. (arXiv:2309.12028v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12028</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of traffic flow forecasting, which aims to
predict future traffic conditions on the basis of road networks and traffic
conditions in the past. The problem is typically solved by modeling complex
spatio-temporal correlations in traffic data using spatio-temporal graph neural
networks (GNNs). However, the performance of these methods is still far from
satisfactory since GNNs usually have limited representation capacity when it
comes to complex traffic networks. Graphs, by nature, fall short in capturing
non-pairwise relations. Even worse, existing methods follow the paradigm of
message passing that aggregates neighborhood information linearly, which fails
to capture complicated spatio-temporal high-order interactions. To tackle these
issues, in this paper, we propose a novel model named Dynamic Hypergraph
Structure Learning (DyHSL) for traffic flow prediction. To learn non-pairwise
relationships, our DyHSL extracts hypergraph structural information to model
dynamics in the traffic networks, and updates each node representation by
aggregating messages from its associated hyperedges. Additionally, to capture
high-order spatio-temporal relations in the road network, we introduce an
interactive graph convolution block, which further models the neighborhood
interaction for each node. Finally, we integrate these two views into a
holistic multi-scale correlation extraction module, which conducts temporal
pooling with different scales to model different temporal patterns. Extensive
experiments on four popular traffic benchmark datasets demonstrate the
effectiveness of our proposed DyHSL compared with a broad range of competing
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yusheng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ju_W/0/1/0/all/0/1&quot;&gt;Wei Ju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1&quot;&gt;Xian-Sheng Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Ming Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12032">
<title>Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets. (arXiv:2309.12032v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12032</link>
<description rdf:parseType="Literal">&lt;p&gt;Structure learning is the crux of causal inference. Notably, causal discovery
(CD) algorithms are brittle when data is scarce, possibly inferring imprecise
causal relations that contradict expert knowledge -- especially when
considering latent confounders. To aggravate the issue, most CD methods do not
provide uncertainty estimates, making it hard for users to interpret results
and improve the inference process. Surprisingly, while CD is a human-centered
affair, no works have focused on building methods that both 1) output
uncertainty estimates that can be verified by experts and 2) interact with
those experts to iteratively refine CD. To solve these issues, we start by
proposing to sample (causal) ancestral graphs proportionally to a belief
distribution based on a score function, such as the Bayesian information
criterion (BIC), using generative flow networks. Then, we leverage the
diversity in candidate graphs and introduce an optimal experimental design to
iteratively probe the expert about the relations among variables, effectively
reducing the uncertainty of our belief over ancestral graphs. Finally, we
update our samples to incorporate human feedback via importance sampling.
Importantly, our method does not require causal sufficiency (i.e., unobserved
confounders may exist). Experiments with synthetic observational data show that
our method can accurately sample from distributions over ancestral graphs and
that we can greatly improve inference quality with human aid.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_T/0/1/0/all/0/1&quot;&gt;Tiago da Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_E/0/1/0/all/0/1&quot;&gt;Eliezer Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Ad&amp;#xe8;le Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gois_A/0/1/0/all/0/1&quot;&gt;Ant&amp;#xf3;nio G&amp;#xf3;is&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heider_D/0/1/0/all/0/1&quot;&gt;Dominik Heider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1&quot;&gt;Samuel Kaski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mesquita_D/0/1/0/all/0/1&quot;&gt;Diego Mesquita&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12033">
<title>Face Identity-Aware Disentanglement in StyleGAN. (arXiv:2309.12033v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.12033</link>
<description rdf:parseType="Literal">&lt;p&gt;Conditional GANs are frequently used for manipulating the attributes of face
images, such as expression, hairstyle, pose, or age. Even though the
state-of-the-art models successfully modify the requested attributes, they
simultaneously modify other important characteristics of the image, such as a
person&apos;s identity. In this paper, we focus on solving this problem by
introducing PluGeN4Faces, a plugin to StyleGAN, which explicitly disentangles
face attributes from a person&apos;s identity. Our key idea is to perform training
on images retrieved from movie frames, where a given person appears in various
poses and with different attributes. By applying a type of contrastive loss, we
encourage the model to group images of the same person in similar regions of
latent space. Our experiments demonstrate that the modifications of face
attributes performed by PluGeN4Faces are significantly less invasive on the
remaining characteristics of the image than in the existing state-of-the-art
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suwala_A/0/1/0/all/0/1&quot;&gt;Adrian Suwa&amp;#x142;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wojcik_B/0/1/0/all/0/1&quot;&gt;Bartosz W&amp;#xf3;jcik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Proszewska_M/0/1/0/all/0/1&quot;&gt;Magdalena Proszewska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1&quot;&gt;Jacek Tabor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spurek_P/0/1/0/all/0/1&quot;&gt;Przemys&amp;#x142;aw Spurek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1&quot;&gt;Marek &amp;#x15a;mieja&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12036">
<title>Uplift vs. predictive modeling: a theoretical analysis. (arXiv:2309.12036v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12036</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the growing popularity of machine-learning techniques in
decision-making, the added value of causal-oriented strategies with respect to
pure machine-learning approaches has rarely been quantified in the literature.
These strategies are crucial for practitioners in various domains, such as
marketing, telecommunications, health care and finance. This paper presents a
comprehensive treatment of the subject, starting from firm theoretical
foundations and highlighting the parameters that influence the performance of
the uplift and predictive approaches. The focus of the paper is on a binary
outcome case and a binary action, and the paper presents a theoretical analysis
of uplift modeling, comparing it with the classical predictive approach. The
main research contributions of the paper include a new formulation of the
measure of profit, a formal proof of the convergence of the uplift curve to the
measure of profit ,and an illustration, through simulations, of the conditions
under which predictive approaches still outperform uplift modeling. We show
that the mutual information between the features and the outcome plays a
significant role, along with the variance of the estimators, the distribution
of the potential outcomes and the underlying costs and benefits of the
treatment and the outcome.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verhelst_T/0/1/0/all/0/1&quot;&gt;Th&amp;#xe9;o Verhelst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petit_R/0/1/0/all/0/1&quot;&gt;Robin Petit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verbeke_W/0/1/0/all/0/1&quot;&gt;Wouter Verbeke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bontempi_G/0/1/0/all/0/1&quot;&gt;Gianluca Bontempi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12041">
<title>S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees. (arXiv:2309.12041v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2309.12041</link>
<description rdf:parseType="Literal">&lt;p&gt;Privacy-preserving learning of gradient boosting decision trees (GBDT) has
the potential for strong utility-privacy tradeoffs for tabular data, such as
census data or medical meta data: classical GBDT learners can extract
non-linear patterns from small sized datasets. The state-of-the-art notion for
provable privacy-properties is differential privacy, which requires that the
impact of single data points is limited and deniable. We introduce a novel
differentially private GBDT learner and utilize four main techniques to improve
the utility-privacy tradeoff. (1) We use an improved noise scaling approach
with tighter accounting of privacy leakage of a decision tree leaf compared to
prior work, resulting in noise that in expectation scales with $O(1/n)$, for
$n$ data points. (2) We integrate individual R\&apos;enyi filters to our method to
learn from data points that have been underutilized during an iterative
training process, which -- potentially of independent interest -- results in a
natural yet effective insight to learning streams of non-i.i.d. data. (3) We
incorporate the concept of random decision tree splits to concentrate privacy
budget on learning leaves. (4) We deploy subsampling for privacy amplification.
Our evaluation shows for the Abalone dataset ($&amp;lt;4k$ training data points) a
$R^2$-score of $0.39$ for $\varepsilon=0.15$, which the closest prior work only
achieved for $\varepsilon=10.0$. On the Adult dataset ($50k$ training data
points) we achieve test error of $18.7\,\%$ for $\varepsilon=0.07$ which the
closest prior work only achieved for $\varepsilon=1.0$. For the Abalone dataset
for $\varepsilon=0.54$ we achieve $R^2$-score of $0.47$ which is very close to
the $R^2$-score of $0.54$ for the nonprivate version of GBDT. For the Adult
dataset for $\varepsilon=0.54$ we achieve test error $17.1\,\%$ which is very
close to the test error $13.7\,\%$ of the nonprivate version of GBDT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirsche_M/0/1/0/all/0/1&quot;&gt;Moritz Kirsche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peinemann_T/0/1/0/all/0/1&quot;&gt;Thorsten Peinemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stock_J/0/1/0/all/0/1&quot;&gt;Joshua Stock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotrini_C/0/1/0/all/0/1&quot;&gt;Carlos Cotrini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammadi_E/0/1/0/all/0/1&quot;&gt;Esfandiar Mohammadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12058">
<title>An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM. (arXiv:2309.12058v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12058</link>
<description rdf:parseType="Literal">&lt;p&gt;Anticancer peptides (ACPs) are a group of peptides that exhibite
antineoplastic properties. The utilization of ACPs in cancer prevention can
present a viable substitute for conventional cancer therapeutics, as they
possess a higher degree of selectivity and safety. Recent scientific
advancements generate an interest in peptide-based therapies which offer the
advantage of efficiently treating intended cells without negatively impacting
normal cells. However, as the number of peptide sequences continues to increase
rapidly, developing a reliable and precise prediction model becomes a
challenging task. In this work, our motivation is to advance an efficient model
for categorizing anticancer peptides employing the consolidation of word
embedding and deep learning models. First, Word2Vec and FastText are evaluated
as word embedding techniques for the purpose of extracting peptide sequences.
Then, the output of word embedding models are fed into deep learning approaches
CNN, LSTM, BiLSTM. To demonstrate the contribution of proposed framework,
extensive experiments are carried on widely-used datasets in the literature,
ACPs250 and Independent. Experiment results show the usage of proposed model
enhances classification accuracy when compared to the state-of-the-art studies.
The proposed combination, FastText+BiLSTM, exhibits 92.50% of accuracy for
ACPs250 dataset, and 96.15% of accuracy for Independent dataset, thence
determining new state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karakaya_O/0/1/0/all/0/1&quot;&gt;Onur Karakaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kilimci_Z/0/1/0/all/0/1&quot;&gt;Zeynep Hilal Kilimci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12067">
<title>Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer -- Current Trends and Research Perspectives. (arXiv:2309.12067v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.12067</link>
<description rdf:parseType="Literal">&lt;p&gt;Action scene understanding in soccer is a challenging task due to the complex
and dynamic nature of the game, as well as the interactions between players.
This article provides a comprehensive overview of this task divided into action
recognition, spotting, and spatio-temporal action localization, with a
particular emphasis on the modalities used and multimodal methods. We explore
the publicly available data sources and metrics used to evaluate models&apos;
performance. The article reviews recent state-of-the-art methods that leverage
deep learning techniques and traditional methods. We focus on multimodal
methods, which integrate information from multiple sources, such as video and
audio data, and also those that represent one source in various ways. The
advantages and limitations of methods are discussed, along with their potential
for improving the accuracy and robustness of models. Finally, the article
highlights some of the open research questions and future directions in the
field of soccer action recognition, including the potential for multimodal
methods to advance this field. Overall, this survey provides a valuable
resource for researchers interested in the field of action scene understanding
in soccer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seweryn_K/0/1/0/all/0/1&quot;&gt;Karolina Seweryn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wroblewska_A/0/1/0/all/0/1&quot;&gt;Anna Wr&amp;#xf3;blewska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lukasik_S/0/1/0/all/0/1&quot;&gt;Szymon &amp;#x141;ukasik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12078">
<title>Clustering-based Domain-Incremental Learning. (arXiv:2309.12078v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12078</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of learning multiple tasks in a continual learning
setting in which data from different tasks is presented to the learner in a
streaming fashion. A key challenge in this setting is the so-called
&quot;catastrophic forgetting problem&quot;, in which the performance of the learner in
an &quot;old task&quot; decreases when subsequently trained on a &quot;new task&quot;. Existing
continual learning methods, such as Averaged Gradient Episodic Memory (A-GEM)
and Orthogonal Gradient Descent (OGD), address catastrophic forgetting by
minimizing the loss for the current task without increasing the loss for
previous tasks. However, these methods assume the learner knows when the task
changes, which is unrealistic in practice. In this paper, we alleviate the need
to provide the algorithm with information about task changes by using an online
clustering-based approach on a dynamically updated finite pool of samples or
gradients. We thereby successfully counteract catastrophic forgetting in one of
the hardest settings, namely: domain-incremental learning, a setting for which
the problem was previously unsolved. We showcase the benefits of our approach
by applying these ideas to projection-based methods, such as A-GEM and OGD,
which lead to task-agnostic versions of them. Experiments on real datasets
demonstrate the effectiveness of the proposed strategy and its promising
performance compared to state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamers_C/0/1/0/all/0/1&quot;&gt;Christiaan Lamers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1&quot;&gt;Rene Vidal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belbachir_N/0/1/0/all/0/1&quot;&gt;Nabil Belbachir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stein_N/0/1/0/all/0/1&quot;&gt;Niki van Stein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baeck_T/0/1/0/all/0/1&quot;&gt;Thomas Baeck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giampouras_P/0/1/0/all/0/1&quot;&gt;Paris Giampouras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12095">
<title>Bayesian sparsification for deep neural networks with Bayesian model reduction. (arXiv:2309.12095v1 [stat.ML])</title>
<link>http://arxiv.org/abs/2309.12095</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning&apos;s immense capabilities are often constrained by the complexity
of its models, leading to an increasing demand for effective sparsification
techniques. Bayesian sparsification for deep learning emerges as a crucial
approach, facilitating the design of models that are both computationally
efficient and competitive in terms of performance across various deep learning
applications. The state-of-the-art -- in Bayesian sparsification of deep neural
networks -- combines structural shrinkage priors on model weights with an
approximate inference scheme based on black-box stochastic variational
inference. However, model inversion of the full generative model is
exceptionally computationally demanding, especially when compared to standard
deep learning of point estimates. In this context, we advocate for the use of
Bayesian model reduction (BMR) as a more efficient alternative for pruning of
model weights. As a generalization of the Savage-Dickey ratio, BMR allows a
post-hoc elimination of redundant model weights based on the posterior
estimates under a straightforward (non-hierarchical) generative model. Our
comparative study highlights the computational efficiency and the pruning rate
of the BMR method relative to the established stochastic variational inference
(SVI) scheme, when applied to the full hierarchical generative model. We
illustrate the potential of BMR to prune model parameters across various deep
learning architectures, from classical networks like LeNet to modern frameworks
such as Vision Transformers and MLP-Mixers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Markovic_D/0/1/0/all/0/1&quot;&gt;Dimitrije Markovi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Friston_K/0/1/0/all/0/1&quot;&gt;Karl J. Friston&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kiebel_S/0/1/0/all/0/1&quot;&gt;Stefan J. Kiebel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12111">
<title>Passage Summarization with Recurrent Models for Audio-Sheet Music Retrieval. (arXiv:2309.12111v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.12111</link>
<description rdf:parseType="Literal">&lt;p&gt;Many applications of cross-modal music retrieval are related to connecting
sheet music images to audio recordings. A typical and recent approach to this
is to learn, via deep neural networks, a joint embedding space that correlates
short fixed-size snippets of audio and sheet music by means of an appropriate
similarity structure. However, two challenges that arise out of this strategy
are the requirement of strongly aligned data to train the networks, and the
inherent discrepancies of musical content between audio and sheet music
snippets caused by local and global tempo differences. In this paper, we
address these two shortcomings by designing a cross-modal recurrent network
that learns joint embeddings that can summarize longer passages of
corresponding audio and sheet music. The benefits of our method are that it
only requires weakly aligned audio-sheet music pairs, as well as that the
recurrent network handles the non-linearities caused by tempo variations
between audio and sheet music. We conduct a number of experiments on synthetic
and real piano data and scores, showing that our proposed recurrent method
leads to more accurate retrieval in all possible configurations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_L/0/1/0/all/0/1&quot;&gt;Luis Carvalho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1&quot;&gt;Gerhard Widmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12128">
<title>Convergence and Recovery Guarantees of Unsupervised Neural Networks for Inverse Problems. (arXiv:2309.12128v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12128</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks have become a prominent approach to solve inverse problems in
recent years. While a plethora of such methods was developed to solve inverse
problems empirically, we are still lacking clear theoretical guarantees for
these methods. On the other hand, many works proved convergence to optimal
solutions of neural networks in a more general setting using
overparametrization as a way to control the Neural Tangent Kernel. In this work
we investigate how to bridge these two worlds and we provide deterministic
convergence and recovery guarantees for the class of unsupervised feedforward
multilayer neural networks trained to solve inverse problems. We also derive
overparametrization bounds under which a two-layers Deep Inverse Prior network
with smooth activation function will benefit from our guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buskulic_N/0/1/0/all/0/1&quot;&gt;Nathan Buskulic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fadili_J/0/1/0/all/0/1&quot;&gt;Jalal Fadili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Queau_Y/0/1/0/all/0/1&quot;&gt;Yvain Qu&amp;#xe9;au&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12134">
<title>Self-Supervised Contrastive Learning for Robust Audio-Sheet Music Retrieval Systems. (arXiv:2309.12134v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.12134</link>
<description rdf:parseType="Literal">&lt;p&gt;Linking sheet music images to audio recordings remains a key problem for the
development of efficient cross-modal music retrieval systems. One of the
fundamental approaches toward this task is to learn a cross-modal embedding
space via deep neural networks that is able to connect short snippets of audio
and sheet music. However, the scarcity of annotated data from real musical
content affects the capability of such methods to generalize to real retrieval
scenarios. In this work, we investigate whether we can mitigate this limitation
with self-supervised contrastive learning, by exposing a network to a large
amount of real music data as a pre-training step, by contrasting randomly
augmented views of snippets of both modalities, namely audio and sheet images.
Through a number of experiments on synthetic and real piano data, we show that
pre-trained models are able to retrieve snippets with better precision in all
scenarios and pre-training configurations. Encouraged by these results, we
employ the snippet embeddings in the higher-level task of cross-modal piece
identification and conduct more experiments on several retrieval
configurations. In this task, we observe that the retrieval quality improves
from 30% up to 100% when real music data is present. We then conclude by
arguing for the potential of self-supervised contrastive learning for
alleviating the annotated data scarcity in multi-modal music retrieval models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_L/0/1/0/all/0/1&quot;&gt;Luis Carvalho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Washuttl_T/0/1/0/all/0/1&quot;&gt;Tobias Wash&amp;#xfc;ttl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1&quot;&gt;Gerhard Widmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12140">
<title>Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features. (arXiv:2309.12140v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.12140</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid development of 3D object detection systems for self-driving cars
has significantly improved accuracy. However, these systems struggle to
generalize across diverse driving environments, which can lead to
safety-critical failures in detecting traffic participants. To address this, we
propose a method that utilizes unlabeled repeated traversals of multiple
locations to adapt object detectors to new driving environments. By
incorporating statistics computed from repeated LiDAR scans, we guide the
adaptation process effectively. Our approach enhances LiDAR-based detection
models using spatial quantized historical features and introduces a lightweight
regression head to leverage the statistics for feature regularization.
Additionally, we leverage the statistics for a novel self-training process to
stabilize the training. The framework is detector model-agnostic and
experiments on real-world datasets demonstrate significant improvements,
achieving up to a 20-point performance gain, especially in detecting
pedestrians and distant objects. Code is available at
https://github.com/zhangtravis/Hist-DA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Travis Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1&quot;&gt;Katie Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phoo_C/0/1/0/all/0/1&quot;&gt;Cheng Perng Phoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1&quot;&gt;Yurong You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1&quot;&gt;Wei-Lun Chao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hariharan_B/0/1/0/all/0/1&quot;&gt;Bharath Hariharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1&quot;&gt;Mark Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1&quot;&gt;Kilian Q. Weinberger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12158">
<title>Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval. (arXiv:2309.12158v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.12158</link>
<description rdf:parseType="Literal">&lt;p&gt;A range of applications of multi-modal music information retrieval is centred
around the problem of connecting large collections of sheet music (images) to
corresponding audio recordings, that is, identifying pairs of audio and score
excerpts that refer to the same musical content. One of the typical and most
recent approaches to this task employs cross-modal deep learning architectures
to learn joint embedding spaces that link the two distinct modalities - audio
and sheet music images. While there has been steady improvement on this front
over the past years, a number of open problems still prevent large-scale
employment of this methodology. In this article we attempt to provide an
insightful examination of the current developments on audio-sheet music
retrieval via deep learning methods. We first identify a set of main challenges
on the road towards robust and large-scale cross-modal music retrieval in real
scenarios. We then highlight the steps we have taken so far to address some of
these challenges, documenting step-by-step improvement along several
dimensions. We conclude by analysing the remaining challenges and present ideas
for solving these, in order to pave the way to a unified and robust methodology
for cross-modal music retrieval.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_L/0/1/0/all/0/1&quot;&gt;Luis Carvalho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1&quot;&gt;Gerhard Widmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12162">
<title>Optimal Conditional Inference in Adaptive Experiments. (arXiv:2309.12162v1 [stat.ME])</title>
<link>http://arxiv.org/abs/2309.12162</link>
<description rdf:parseType="Literal">&lt;p&gt;We study batched bandit experiments and consider the problem of inference
conditional on the realized stopping time, assignment probabilities, and target
parameter, where all of these may be chosen adaptively using information up to
the last batch of the experiment. Absent further restrictions on the
experiment, we show that inference using only the results of the last batch is
optimal. When the adaptive aspects of the experiment are known to be
location-invariant, in the sense that they are unchanged when we shift all
batch-arm means by a constant, we show that there is additional information in
the data, captured by one additional linear function of the batch-arm means. In
the more restrictive case where the stopping time, assignment probabilities,
and target parameter are known to depend on the data only through a collection
of polyhedral events, we derive computationally tractable and optimal
conditional inference procedures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiafeng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Andrews_I/0/1/0/all/0/1&quot;&gt;Isaiah Andrews&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12193">
<title>Brain Tumor Detection Using Deep Learning Approaches. (arXiv:2309.12193v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.12193</link>
<description rdf:parseType="Literal">&lt;p&gt;Brain tumors are collections of abnormal cells that can develop into masses
or clusters. Because they have the potential to infiltrate other tissues, they
pose a risk to the patient. The main imaging technique used, MRI, may be able
to identify a brain tumor with accuracy. The fast development of Deep Learning
methods for use in computer vision applications has been facilitated by a vast
amount of training data and improvements in model construction that offer
better approximations in a supervised setting. The need for these approaches
has been the main driver of this expansion. Deep learning methods have shown
promise in improving the precision of brain tumor detection and classification
using magnetic resonance imaging (MRI). The study on the use of deep learning
techniques, especially ResNet50, for brain tumor identification is presented in
this abstract. As a result, this study investigates the possibility of
automating the detection procedure using deep learning techniques. In this
study, I utilized five transfer learning models which are VGG16, VGG19,
DenseNet121, ResNet50 and YOLO V4 where ResNet50 provide the best or highest
accuracy 99.54%. The goal of the study is to guide researchers and medical
professionals toward powerful brain tumor detecting systems by employing deep
learning approaches by way of this evaluation and analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Misu_R/0/1/0/all/0/1&quot;&gt;Razia Sultana Misu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12200">
<title>A Variational Auto-Encoder Enabled Multi-Band Channel Prediction Scheme for Indoor Localization. (arXiv:2309.12200v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2309.12200</link>
<description rdf:parseType="Literal">&lt;p&gt;Indoor localization is getting increasing demands for various cutting-edged
technologies, like Virtual/Augmented reality and smart home. Traditional
model-based localization suffers from significant computational overhead, so
fingerprint localization is getting increasing attention, which needs lower
computation cost after the fingerprint database is built. However, the accuracy
of indoor localization is limited by the complicated indoor environment which
brings the multipath signal refraction. In this paper, we provided a scheme to
improve the accuracy of indoor fingerprint localization from the frequency
domain by predicting the channel state information (CSI) values from another
transmitting channel and spliced the multi-band information together to get
more precise localization results. We tested our proposed scheme on COST 2100
simulation data and real time orthogonal frequency division multiplexing (OFDM)
WiFi data collected from an office scenario.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yuan_R/0/1/0/all/0/1&quot;&gt;Ruihao Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kaixuan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_P/0/1/0/all/0/1&quot;&gt;Pan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shunqing Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12201">
<title>Electroencephalogram Sensor Data Compression Using An Asymmetrical Sparse Autoencoder With A Discrete Cosine Transform Layer. (arXiv:2309.12201v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2309.12201</link>
<description rdf:parseType="Literal">&lt;p&gt;Electroencephalogram (EEG) data compression is necessary for wireless
recording applications to reduce the amount of data that needs to be
transmitted. In this paper, an asymmetrical sparse autoencoder with a discrete
cosine transform (DCT) layer is proposed to compress EEG signals. The encoder
module of the autoencoder has a combination of a fully connected linear layer
and the DCT layer to reduce redundant data using hard-thresholding
nonlinearity. Furthermore, the DCT layer includes trainable hard-thresholding
parameters and scaling layers to give emphasis or de-emphasis on individual DCT
coefficients. Finally, the one-by-one convolutional layer generates the latent
space. The sparsity penalty-based cost function is employed to keep the feature
map as sparse as possible in the latent space. The latent space data is
transmitted to the receiver. The decoder module of the autoencoder is designed
using the inverse DCT and two fully connected linear layers to improve the
accuracy of data reconstruction. In comparison to other state-of-the-art
methods, the proposed method significantly improves the average quality score
in various data compression experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xin Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pan_H/0/1/0/all/0/1&quot;&gt;Hongyi Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rong_S/0/1/0/all/0/1&quot;&gt;Shuaiang Rong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cetin_A/0/1/0/all/0/1&quot;&gt;Ahmet Enis Cetin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12202">
<title>Empowering Precision Medicine: AI-Driven Schizophrenia Diagnosis via EEG Signals: A Comprehensive Review from 2002-2023. (arXiv:2309.12202v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2309.12202</link>
<description rdf:parseType="Literal">&lt;p&gt;Schizophrenia (SZ) is a prevalent mental disorder characterized by cognitive,
emotional, and behavioral changes. Symptoms of SZ include hallucinations,
illusions, delusions, lack of motivation, and difficulties in concentration.
Diagnosing SZ involves employing various tools, including clinical interviews,
physical examinations, psychological evaluations, the Diagnostic and
Statistical Manual of Mental Disorders (DSM), and neuroimaging techniques.
Electroencephalography (EEG) recording is a significant functional neuroimaging
modality that provides valuable insights into brain function during SZ.
However, EEG signal analysis poses challenges for neurologists and scientists
due to the presence of artifacts, long-term recordings, and the utilization of
multiple channels. To address these challenges, researchers have introduced
artificial intelligence (AI) techniques, encompassing conventional machine
learning (ML) and deep learning (DL) methods, to aid in SZ diagnosis. This
study reviews papers focused on SZ diagnosis utilizing EEG signals and AI
methods. The introduction section provides a comprehensive explanation of SZ
diagnosis methods and intervention techniques. Subsequently, review papers in
this field are discussed, followed by an introduction to the AI methods
employed for SZ diagnosis and a summary of relevant papers presented in tabular
form. Additionally, this study reports on the most significant challenges
encountered in SZ diagnosis, as identified through a review of papers in this
field. Future directions to overcome these challenges are also addressed. The
discussion section examines the specific details of each paper, culminating in
the presentation of conclusions and findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jafari_M/0/1/0/all/0/1&quot;&gt;Mahboobeh Jafari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sadeghi_D/0/1/0/all/0/1&quot;&gt;Delaram Sadeghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Shoeibi_A/0/1/0/all/0/1&quot;&gt;Afshin Shoeibi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Alinejad_Rokny_H/0/1/0/all/0/1&quot;&gt;Hamid Alinejad-Rokny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Beheshti_A/0/1/0/all/0/1&quot;&gt;Amin Beheshti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Garcia_D/0/1/0/all/0/1&quot;&gt;David L&amp;#xf3;pez Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhaolin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Acharya_U/0/1/0/all/0/1&quot;&gt;U. Rajendra Acharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gorriz_J/0/1/0/all/0/1&quot;&gt;Juan M. Gorriz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12204">
<title>PrNet: A Neural Network for Correcting Pseudoranges to Improve Positioning with Android Raw GNSS Measurements. (arXiv:2309.12204v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12204</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a neural network for mitigating pseudorange bias to improve
localization performance with data collected from Android smartphones. We
represent pseudorange bias using a pragmatic satellite-wise Multiple Layer
Perceptron (MLP), the inputs of which are six
satellite-receiver-context-related features derived from Android raw Global
Navigation Satellite System (GNSS) measurements. To supervise the training
process, we carefully calculate the target values of pseudorange bias using
location ground truth and smoothing techniques and optimize a loss function
containing the estimation residuals of smartphone clock bias. During the
inference process, we employ model-based localization engines to compute
locations with pseudoranges corrected by the neural network. Consequently, this
hybrid pipeline can attend to both pseudorange bias and noise. We evaluate the
framework on an open dataset and consider four application scenarios for
investigating fingerprinting and cross-trace localization in rural and urban
areas. Extensive experiments demonstrate that the proposed framework
outperforms model-based and state-of-the-art data-driven approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_X/0/1/0/all/0/1&quot;&gt;Xu Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_K/0/1/0/all/0/1&quot;&gt;Keck Voon Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haochen Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12207">
<title>Boolformer: Symbolic Regression of Logic Functions with Transformers. (arXiv:2309.12207v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12207</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we introduce Boolformer, the first Transformer architecture
trained to perform end-to-end symbolic regression of Boolean functions. First,
we show that it can predict compact formulas for complex functions which were
not seen during training, when provided a clean truth table. Then, we
demonstrate its ability to find approximate expressions when provided
incomplete and noisy observations. We evaluate the Boolformer on a broad set of
real-world binary classification datasets, demonstrating its potential as an
interpretable alternative to classic machine learning methods. Finally, we
apply it to the widespread task of modelling the dynamics of gene regulatory
networks. Using a recent benchmark, we show that Boolformer is competitive with
state-of-the art genetic algorithms with a speedup of several orders of
magnitude. Our code and models are available publicly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane d&amp;#x27;Ascoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1&quot;&gt;Samy Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1&quot;&gt;Josh Susskind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbe_E/0/1/0/all/0/1&quot;&gt;Emmanuel Abb&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12211">
<title>Physics-informed State-space Neural Networks for Transport Phenomena. (arXiv:2309.12211v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12211</link>
<description rdf:parseType="Literal">&lt;p&gt;This work introduces Physics-informed State-space neural network Models
(PSMs), a novel solution to achieving real-time optimization, flexibility, and
fault tolerance in autonomous systems, particularly in transport-dominated
systems such as chemical, biomedical, and power plants. Traditional data-driven
methods fall short due to a lack of physical constraints like mass
conservation; PSMs address this issue by training deep neural networks with
sensor data and physics-informing using components&apos; Partial Differential
Equations (PDEs), resulting in a physics-constrained, end-to-end differentiable
forward dynamics model. Through two in silico experiments - a heated channel
and a cooling system loop - we demonstrate that PSMs offer a more accurate
approach than purely data-driven models.
&lt;/p&gt;
&lt;p&gt;Beyond accuracy, there are several compelling use cases for PSMs. In this
work, we showcase two: the creation of a nonlinear supervisory controller
through a sequentially updated state-space representation and the proposal of a
diagnostic algorithm using residuals from each of the PDEs. The former
demonstrates the ability of PSMs to handle both constant and time-dependent
constraints, while the latter illustrates their value in system diagnostics and
fault detection. We further posit that PSMs could serve as a foundation for
Digital Twins, constantly updated digital representations of physical systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dave_A/0/1/0/all/0/1&quot;&gt;Akshay J Dave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vilim_R/0/1/0/all/0/1&quot;&gt;Richard B. Vilim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12212">
<title>SupeRBNN: Randomized Binary Neural Network Using Adiabatic Superconductor Josephson Devices. (arXiv:2309.12212v1 [cs.ET])</title>
<link>http://arxiv.org/abs/2309.12212</link>
<description rdf:parseType="Literal">&lt;p&gt;Adiabatic Quantum-Flux-Parametron (AQFP) is a superconducting logic with
extremely high energy efficiency. By employing the distinct polarity of current
to denote logic `0&apos; and `1&apos;, AQFP devices serve as excellent carriers for
binary neural network (BNN) computations. Although recent research has made
initial strides toward developing an AQFP-based BNN accelerator, several
critical challenges remain, preventing the design from being a comprehensive
solution. In this paper, we propose SupeRBNN, an AQFP-based randomized BNN
acceleration framework that leverages software-hardware co-optimization to
eventually make the AQFP devices a feasible solution for BNN acceleration.
Specifically, we investigate the randomized behavior of the AQFP devices and
analyze the impact of crossbar size on current attenuation, subsequently
formulating the current amplitude into the values suitable for use in BNN
computation. To tackle the accumulation problem and improve overall hardware
performance, we propose a stochastic computing-based accumulation module and a
clocking scheme adjustment-based circuit optimization method. We validate our
SupeRBNN framework across various datasets and network architectures, comparing
it with implementations based on different technologies, including CMOS, ReRAM,
and superconducting RSFQ/ERSFQ. Experimental results demonstrate that our
design achieves an energy efficiency of approximately 7.8x10^4 times higher
than that of the ReRAM-based BNN framework while maintaining a similar level of
model accuracy. Furthermore, when compared with superconductor-based
counterparts, our framework demonstrates at least two orders of magnitude
higher energy efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhengang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1&quot;&gt;Geng Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamauchi_T/0/1/0/all/0/1&quot;&gt;Tomoharu Yamauchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masoud_Z/0/1/0/all/0/1&quot;&gt;Zabihi Masoud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yanyue Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_P/0/1/0/all/0/1&quot;&gt;Peiyan Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1&quot;&gt;Xulong Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoshikawa_N/0/1/0/all/0/1&quot;&gt;Nobuyuki Yoshikawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_D/0/1/0/all/0/1&quot;&gt;Devesh Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_O/0/1/0/all/0/1&quot;&gt;Olivia Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12215">
<title>Regionally Additive Models: Explainable-by-design models minimizing feature interactions. (arXiv:2309.12215v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12215</link>
<description rdf:parseType="Literal">&lt;p&gt;Generalized Additive Models (GAMs) are widely used explainable-by-design
models in various applications. GAMs assume that the output can be represented
as a sum of univariate functions, referred to as components. However, this
assumption fails in ML problems where the output depends on multiple features
simultaneously. In these cases, GAMs fail to capture the interaction terms of
the underlying function, leading to subpar accuracy. To (partially) address
this issue, we propose Regionally Additive Models (RAMs), a novel class of
explainable-by-design models. RAMs identify subregions within the feature space
where interactions are minimized. Within these regions, it is more accurate to
express the output as a sum of univariate functions (components). Consequently,
RAMs fit one component per subregion of each feature instead of one component
per feature. This approach yields a more expressive model compared to GAMs
while retaining interpretability. The RAM framework consists of three steps.
Firstly, we train a black-box model. Secondly, using Regional Effect Plots, we
identify subregions where the black-box model exhibits near-local additivity.
Lastly, we fit a GAM component for each identified subregion. We validate the
effectiveness of RAMs through experiments on both synthetic and real-world
datasets. The results confirm that RAMs offer improved expressiveness compared
to GAMs while maintaining interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gkolemis_V/0/1/0/all/0/1&quot;&gt;Vasilis Gkolemis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzerefos_A/0/1/0/all/0/1&quot;&gt;Anargiros Tzerefos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalamagas_T/0/1/0/all/0/1&quot;&gt;Theodore Dalamagas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1&quot;&gt;Eirini Ntoutsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diou_C/0/1/0/all/0/1&quot;&gt;Christos Diou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12217">
<title>A Multi-label Classification Approach to Increase Expressivity of EMG-based Gesture Recognition. (arXiv:2309.12217v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2309.12217</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: The objective of the study is to efficiently increase the
expressivity of surface electromyography-based (sEMG) gesture recognition
systems. Approach: We use a problem transformation approach, in which actions
were subset into two biomechanically independent components - a set of wrist
directions and a set of finger modifiers. To maintain fast calibration time, we
train models for each component using only individual gestures, and extrapolate
to the full product space of combination gestures by generating synthetic data.
We collected a supervised dataset with high-confidence ground truth labels in
which subjects performed combination gestures while holding a joystick, and
conducted experiments to analyze the impact of model architectures, classifier
algorithms, and synthetic data generation strategies on the performance of the
proposed approach. Main Results: We found that a problem transformation
approach using a parallel model architecture in combination with a non-linear
classifier, along with restricted synthetic data generation, shows promise in
increasing the expressivity of sEMG-based gestures with a short calibration
time. Significance: sEMG-based gesture recognition has applications in
human-computer interaction, virtual reality, and the control of robotic and
prosthetic devices. Existing approaches require exhaustive model calibration.
The proposed approach increases expressivity without requiring users to
demonstrate all combination gesture classes. Our results may be extended to
larger gesture vocabularies and more complicated model architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Smedemark_Margulies_N/0/1/0/all/0/1&quot;&gt;Niklas Smedemark-Margulies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bicer_Y/0/1/0/all/0/1&quot;&gt;Yunus Bicer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sunger_E/0/1/0/all/0/1&quot;&gt;Elifnur Sunger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Naufel_S/0/1/0/all/0/1&quot;&gt;Stephanie Naufel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Imbiriba_T/0/1/0/all/0/1&quot;&gt;Tales Imbiriba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tunik_E/0/1/0/all/0/1&quot;&gt;Eugene Tunik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Erdogmus_D/0/1/0/all/0/1&quot;&gt;Deniz Erdo&amp;#x11f;mu&amp;#x15f;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yarossi_M/0/1/0/all/0/1&quot;&gt;Mathew Yarossi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12218">
<title>SR-PredictAO: Session-based Recommendation with High-Capability Predictor Add-On. (arXiv:2309.12218v1 [cs.IR])</title>
<link>http://arxiv.org/abs/2309.12218</link>
<description rdf:parseType="Literal">&lt;p&gt;Session-based recommendation, aiming at making the prediction of the user&apos;s
next item click based on the information in a single session only even in the
presence of some random user&apos;s behavior, is a complex problem. This complex
problem requires a high-capability model of predicting the user&apos;s next action.
Most (if not all) existing models follow the encoder-predictor paradigm where
all studies focus on how to optimize the encoder module extensively in the
paradigm but they ignore how to optimize the predictor module. In this paper,
we discover the existing critical issue of the low-capability predictor module
among existing models. Motivated by this, we propose a novel framework called
\emph{\underline{S}ession-based \underline{R}ecommendation with
\underline{Pred}ictor \underline{A}dd-\underline{O}n} (SR-PredictAO). In this
framework, we propose a high-capability predictor module which could alleviate
the effect of random user&apos;s behavior for prediction. It is worth mentioning
that this framework could be applied to any existing models, which could give
opportunities for further optimizing the framework. Extensive experiments on
two real benchmark datasets for three state-of-the-art models show that
\emph{SR-PredictAO} out-performs the current state-of-the-art model by up to
2.9\% in HR@20 and 2.3\% in MRR@20. More importantly, the improvement is
consistent across almost all the existing models on all datasets, which could
be regarded as a significant contribution in the field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruida Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_R/0/1/0/all/0/1&quot;&gt;Raymond Chi-Wing Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1&quot;&gt;Weile Tan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12223">
<title>Model-based Deep Learning for High-Dimensional Periodic Structures. (arXiv:2309.12223v1 [eess.SP])</title>
<link>http://arxiv.org/abs/2309.12223</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents a deep learning surrogate model for the fast simulation of
high-dimensional frequency selective surfaces. We consider unit-cells which are
built as multiple concatenated stacks of screens and their design requires the
control over many geometrical degrees of freedom. Thanks to the introduction of
physical insight into the model, it can produce accurate predictions of the
S-parameters of a certain structure after training with a reduced dataset.The
proposed model is highly versatile and it can be used with any kind of
frequency selective surface, based on either perforations or patches of any
arbitrary geometry. Numeric examples are presented here for the case of
frequency selective surfaces composed of screens with rectangular perforations,
showing an excellent agreement between the predicted performance and such
obtained with a full-wave simulator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Polo_Lopez_L/0/1/0/all/0/1&quot;&gt;Lucas Polo-L&amp;#xf3;pez&lt;/a&gt; (IETR, INSA Rennes), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Magoarou_L/0/1/0/all/0/1&quot;&gt;Luc Le Magoarou&lt;/a&gt; (INSA Rennes, IETR), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Contreres_R/0/1/0/all/0/1&quot;&gt;Romain Contreres&lt;/a&gt; (CNES), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Garcia_Vigueras_M/0/1/0/all/0/1&quot;&gt;Mar&amp;#xed;a Garc&amp;#xed;a-Vigueras&lt;/a&gt; (IETR, INSA Rennes)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12226">
<title>Smooth Nash Equilibria: Algorithms and Complexity. (arXiv:2309.12226v1 [cs.GT])</title>
<link>http://arxiv.org/abs/2309.12226</link>
<description rdf:parseType="Literal">&lt;p&gt;A fundamental shortcoming of the concept of Nash equilibrium is its
computational intractability: approximating Nash equilibria in normal-form
games is PPAD-hard. In this paper, inspired by the ideas of smoothed analysis,
we introduce a relaxed variant of Nash equilibrium called $\sigma$-smooth Nash
equilibrium, for a smoothness parameter $\sigma$. In a $\sigma$-smooth Nash
equilibrium, players only need to achieve utility at least as high as their
best deviation to a $\sigma$-smooth strategy, which is a distribution that does
not put too much mass (as parametrized by $\sigma$) on any fixed action. We
distinguish two variants of $\sigma$-smooth Nash equilibria: strong
$\sigma$-smooth Nash equilibria, in which players are required to play
$\sigma$-smooth strategies under equilibrium play, and weak $\sigma$-smooth
Nash equilibria, where there is no such requirement.
&lt;/p&gt;
&lt;p&gt;We show that both weak and strong $\sigma$-smooth Nash equilibria have
superior computational properties to Nash equilibria: when $\sigma$ as well as
an approximation parameter $\epsilon$ and the number of players are all
constants, there is a constant-time randomized algorithm to find a weak
$\epsilon$-approximate $\sigma$-smooth Nash equilibrium in normal-form games.
In the same parameter regime, there is a polynomial-time deterministic
algorithm to find a strong $\epsilon$-approximate $\sigma$-smooth Nash
equilibrium in a normal-form game. These results stand in contrast to the
optimal algorithm for computing $\epsilon$-approximate Nash equilibria, which
cannot run in faster than quasipolynomial-time. We complement our upper bounds
by showing that when either $\sigma$ or $\epsilon$ is an inverse polynomial,
finding a weak $\epsilon$-approximate $\sigma$-smooth Nash equilibria becomes
computationally intractable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1&quot;&gt;Constantinos Daskalakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golowich_N/0/1/0/all/0/1&quot;&gt;Noah Golowich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haghtalab_N/0/1/0/all/0/1&quot;&gt;Nika Haghtalab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shetty_A/0/1/0/all/0/1&quot;&gt;Abhishek Shetty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12236">
<title>Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing. (arXiv:2309.12236v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12236</link>
<description rdf:parseType="Literal">&lt;p&gt;Calibration measures and reliability diagrams are two fundamental tools for
measuring and interpreting the calibration of probabilistic predictors.
Calibration measures quantify the degree of miscalibration, and reliability
diagrams visualize the structure of this miscalibration. However, the most
common constructions of reliability diagrams and calibration measures --
binning and ECE -- both suffer from well-known flaws (e.g. discontinuity). We
show that a simple modification fixes both constructions: first smooth the
observations using an RBF kernel, then compute the Expected Calibration Error
(ECE) of this smoothed function. We prove that with a careful choice of
bandwidth, this method yields a calibration measure that is well-behaved in the
sense of (B{\l}asiok, Gopalan, Hu, and Nakkiran 2023a) -- a consistent
calibration measure. We call this measure the SmoothECE. Moreover, the
reliability diagram obtained from this smoothed function visually encodes the
SmoothECE, just as binned reliability diagrams encode the BinnedECE.
&lt;/p&gt;
&lt;p&gt;We also provide a Python package with simple, hyperparameter-free methods for
measuring and plotting calibration: `pip install relplot\`.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1&quot;&gt;Jaros&amp;#x142;aw B&amp;#x142;asiok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1&quot;&gt;Preetum Nakkiran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12237">
<title>t-EER: Parameter-Free Tandem Evaluation of Countermeasures and Biometric Comparators. (arXiv:2309.12237v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2309.12237</link>
<description rdf:parseType="Literal">&lt;p&gt;Presentation attack (spoofing) detection (PAD) typically operates alongside
biometric verification to improve reliablity in the face of spoofing attacks.
Even though the two sub-systems operate in tandem to solve the single task of
reliable biometric verification, they address different detection tasks and are
hence typically evaluated separately. Evidence shows that this approach is
suboptimal. We introduce a new metric for the joint evaluation of PAD solutions
operating in situ with biometric verification. In contrast to the tandem
detection cost function proposed recently, the new tandem equal error rate
(t-EER) is parameter free. The combination of two classifiers nonetheless leads
to a \emph{set} of operating points at which false alarm and miss rates are
equal and also dependent upon the prevalence of attacks. We therefore introduce
the \emph{concurrent} t-EER, a unique operating point which is invariable to
the prevalence of attacks. Using both modality (and even application) agnostic
simulated scores, as well as real scores for a voice biometrics application, we
demonstrate application of the t-EER to a wide range of biometric system
evaluations under attack. The proposed approach is a strong candidate metric
for the tandem evaluation of PAD systems and biometric comparators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kinnunen_T/0/1/0/all/0/1&quot;&gt;Tomi Kinnunen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kong Aik Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tak_H/0/1/0/all/0/1&quot;&gt;Hemlata Tak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_N/0/1/0/all/0/1&quot;&gt;Nicholas Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nautsch_A/0/1/0/all/0/1&quot;&gt;Andreas Nautsch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12242">
<title>Weakly-supervised Automated Audio Captioning via text only training. (arXiv:2309.12242v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.12242</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, datasets of paired audio and captions have enabled
remarkable success in automatically generating descriptions for audio clips,
namely Automated Audio Captioning (AAC). However, it is labor-intensive and
time-consuming to collect a sufficient number of paired audio and captions.
Motivated by the recent advances in Contrastive Language-Audio Pretraining
(CLAP), we propose a weakly-supervised approach to train an AAC model assuming
only text data and a pre-trained CLAP model, alleviating the need for paired
target data. Our approach leverages the similarity between audio and text
embeddings in CLAP. During training, we learn to reconstruct the text from the
CLAP text embedding, and during inference, we decode using the audio
embeddings. To mitigate the modality gap between the audio and text embeddings
we employ strategies to bridge the gap during training and inference stages. We
evaluate our proposed method on Clotho and AudioCaps datasets demonstrating its
ability to achieve a relative performance of up to ~$83\%$ compared to fully
supervised approaches trained with paired target data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kouzelis_T/0/1/0/all/0/1&quot;&gt;Theodoros Kouzelis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katsouros_V/0/1/0/all/0/1&quot;&gt;Vassilis Katsouros&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12245">
<title>Adaptive Input-image Normalization for Solving Mode Collapse Problem in GAN-based X-ray Images. (arXiv:2309.12245v1 [eess.IV])</title>
<link>http://arxiv.org/abs/2309.12245</link>
<description rdf:parseType="Literal">&lt;p&gt;Biomedical image datasets can be imbalanced due to the rarity of targeted
diseases. Generative Adversarial Networks play a key role in addressing this
imbalance by enabling the generation of synthetic images to augment datasets.
It is important to generate synthetic images that incorporate a diverse range
of features to accurately represent the distribution of features present in the
training imagery. Furthermore, the absence of diverse features in synthetic
images can degrade the performance of machine learning classifiers. The mode
collapse problem impacts Generative Adversarial Networks&apos; capacity to generate
diversified images. Mode collapse comes in two varieties: intra-class and
inter-class. In this paper, both varieties of the mode collapse problem are
investigated, and their subsequent impact on the diversity of synthetic X-ray
images is evaluated. This work contributes an empirical demonstration of the
benefits of integrating the adaptive input-image normalization with the Deep
Convolutional GAN and Auxiliary Classifier GAN to alleviate the mode collapse
problems. Synthetically generated images are utilized for data augmentation and
training a Vision Transformer model. The classification performance of the
model is evaluated using accuracy, recall, and precision scores. Results
demonstrate that the DCGAN and the ACGAN with adaptive input-image
normalization outperform the DCGAN and ACGAN with un-normalized X-ray images as
evidenced by the superior diversity scores and classification scores.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Saad_M/0/1/0/all/0/1&quot;&gt;Muhammad Muneeb Saad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rehmani_M/0/1/0/all/0/1&quot;&gt;Mubashir Husain Rehmani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+OReilly_R/0/1/0/all/0/1&quot;&gt;Ruairi O&amp;#x27;Reilly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12250">
<title>SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References. (arXiv:2309.12250v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.12250</link>
<description rdf:parseType="Literal">&lt;p&gt;Evaluation of QA systems is very challenging and expensive, with the most
reliable approach being human annotations of correctness of answers for
questions. Recent works (AVA, BEM) have shown that transformer LM encoder based
similarity metrics transfer well for QA evaluation, but they are limited by the
usage of a single correct reference answer. We propose a new evaluation metric:
SQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference
answers (combining multiple correct and incorrect references) for sentence-form
QA. We evaluate SQuArE on both sentence-level extractive (Answer Selection) and
generative (GenQA) QA systems, across multiple academic and industrial
datasets, and show that it outperforms previous baselines and obtains the
highest correlation with human annotations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabburo_M/0/1/0/all/0/1&quot;&gt;Matteo Gabburo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Siddhant Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kedziorski_R/0/1/0/all/0/1&quot;&gt;Rik Koncel Kedziorski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moschitti_A/0/1/0/all/0/1&quot;&gt;Alessandro Moschitti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12252">
<title>Parallelizing non-linear sequential models over the sequence length. (arXiv:2309.12252v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12252</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequential models, such as Recurrent Neural Networks and Neural Ordinary
Differential Equations, have long suffered from slow training due to their
inherent sequential nature. For many years this bottleneck has persisted, as
many thought sequential models could not be parallelized. We challenge this
long-held belief with our parallel algorithm that accelerates GPU evaluation of
sequential models by up to 3 orders of magnitude faster without compromising
output accuracy. The algorithm does not need any special structure in the
sequential models&apos; architecture, making it applicable to a wide range of
architectures. Using our method, training sequential models can be more than 10
times faster than the common sequential method without any meaningful
difference in the training results. Leveraging this accelerated training, we
discovered the efficacy of the Gated Recurrent Unit in a long time series
classification problem with 17k time samples. By overcoming the training
bottleneck, our work serves as the first step to unlock the potential of
non-linear sequential models for long sequence problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_Y/0/1/0/all/0/1&quot;&gt;Yi Heng Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1&quot;&gt;Qi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Selfridge_J/0/1/0/all/0/1&quot;&gt;Joshua Selfridge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasim_M/0/1/0/all/0/1&quot;&gt;Muhammad Firmansyah Kasim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12253">
<title>SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning. (arXiv:2309.12253v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12253</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce an extension to the CLRS algorithmic learning benchmark,
prioritizing scalability and the utilization of sparse representations. Many
algorithms in CLRS require global memory or information exchange, mirrored in
its execution model, which constructs fully connected (not sparse) graphs based
on the underlying problem. Despite CLRS&apos;s aim of assessing how effectively
learned algorithms can generalize to larger instances, the existing execution
model becomes a significant constraint due to its demanding memory requirements
and runtime (hard to scale). However, many important algorithms do not demand a
fully connected graph; these algorithms, primarily distributed in nature, align
closely with the message-passing paradigm employed by Graph Neural Networks.
Hence, we propose SALSA-CLRS, an extension of the current CLRS benchmark
specifically with scalability and sparseness in mind. Our approach includes
adapted algorithms from the original CLRS benchmark and introduces new problems
from distributed and randomized algorithms. Moreover, we perform a thorough
empirical evaluation of our benchmark. Code is publicly available at
https://github.com/jkminder/SALSA-CLRS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minder_J/0/1/0/all/0/1&quot;&gt;Julian Minder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grotschla_F/0/1/0/all/0/1&quot;&gt;Florian Gr&amp;#xf6;tschla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathys_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xeb;l Mathys&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1&quot;&gt;Roger Wattenhofer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12259">
<title>Soft Merging: A Flexible and Robust Soft Model Merging Approach for Enhanced Neural Network Performance. (arXiv:2309.12259v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12259</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic Gradient Descent (SGD), a widely used optimization algorithm in
deep learning, is often limited to converging to local optima due to the
non-convex nature of the problem. Leveraging these local optima to improve
model performance remains a challenging task. Given the inherent complexity of
neural networks, the simple arithmetic averaging of the obtained local optima
models in undesirable results. This paper proposes a {\em soft merging} method
that facilitates rapid merging of multiple models, simplifies the merging of
specific parts of neural networks, and enhances robustness against malicious
models with extreme values. This is achieved by learning gate parameters
through a surrogate of the $l_0$ norm using hard concrete distribution without
modifying the model weights of the given local optima models. This merging
process not only enhances the model performance by converging to a better local
optimum, but also minimizes computational costs, offering an efficient and
explicit learning process integrated with stochastic gradient descent. Thorough
experiments underscore the effectiveness and superior performance of the merged
neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yusen Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Phuong Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yesha_Y/0/1/0/all/0/1&quot;&gt;Yelena Yesha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12267">
<title>Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications. (arXiv:2309.12267v1 [cs.CR])</title>
<link>http://arxiv.org/abs/2309.12267</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) has revolutionized how we train deep neural networks
by enabling decentralized collaboration while safeguarding sensitive data and
improving model performance. However, FL faces two crucial challenges: the
diverse nature of data held by individual clients and the vulnerability of the
FL system to security breaches. This paper introduces an innovative solution
named Estimated Mean Aggregation (EMA) that not only addresses these challenges
but also provides a fundamental reference point as a $\mathsf{baseline}$ for
advanced aggregation techniques in FL systems. EMA&apos;s significance lies in its
dual role: enhancing model security by effectively handling malicious outliers
through trimmed means and uncovering data heterogeneity to ensure that trained
models are adaptable across various client datasets. Through a wealth of
experiments, EMA consistently demonstrates high accuracy and area under the
curve (AUC) compared to alternative methods, establishing itself as a robust
baseline for evaluating the effectiveness and security of FL aggregation
methods. EMA&apos;s contributions thus offer a crucial step forward in advancing the
efficiency, security, and versatility of decentralized deep learning in the
context of FL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yusen Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1&quot;&gt;Jamie Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Phuong Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yesha_Y/0/1/0/all/0/1&quot;&gt;Yelena Yesha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12273">
<title>Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports. (arXiv:2309.12273v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.12273</link>
<description rdf:parseType="Literal">&lt;p&gt;Rapid and accurate identification of Venous thromboembolism (VTE), a severe
cardiovascular condition including deep vein thrombosis (DVT) and pulmonary
embolism (PE), is important for effective treatment. Leveraging Natural
Language Processing (NLP) on radiology reports, automated methods have shown
promising advancements in identifying VTE events from retrospective data
cohorts or aiding clinical experts in identifying VTE events from radiology
reports. However, effectively training Deep Learning (DL) and the NLP models is
challenging due to limited labeled medical text data, the complexity and
heterogeneity of radiology reports, and data imbalance. This study proposes
novel method combinations of DL methods, along with data augmentation, adaptive
pre-trained NLP model selection, and a clinical expert NLP rule-based
classifier, to improve the accuracy of VTE identification in unstructured
(free-text) radiology reports. Our experimental results demonstrate the model&apos;s
efficacy, achieving an impressive 97\% accuracy and 97\% F1 score in predicting
DVT, and an outstanding 98.3\% accuracy and 98.4\% F1 score in predicting PE.
These findings emphasize the model&apos;s robustness and its potential to
significantly contribute to VTE research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1&quot;&gt;Jamie Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yusen Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayssen_H/0/1/0/all/0/1&quot;&gt;Hilary Hayssen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Englum_B/0/1/0/all/0/1&quot;&gt;Brain Englum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kankaria_A/0/1/0/all/0/1&quot;&gt;Aman Kankaria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mayorga_Carlin_M/0/1/0/all/0/1&quot;&gt;Minerva Mayorga-Carlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahoo_S/0/1/0/all/0/1&quot;&gt;Shalini Sahoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sorkin_J/0/1/0/all/0/1&quot;&gt;John Sorkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lal_B/0/1/0/all/0/1&quot;&gt;Brajesh Lal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yesha_Y/0/1/0/all/0/1&quot;&gt;Yelena Yesha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Phuong Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12279">
<title>The Broad Impact of Feature Imitation: Neural Enhancements Across Financial, Speech, and Physiological Domains. (arXiv:2309.12279v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12279</link>
<description rdf:parseType="Literal">&lt;p&gt;Initialization of neural network weights plays a pivotal role in determining
their performance. Feature Imitating Networks (FINs) offer a novel strategy by
initializing weights to approximate specific closed-form statistical features,
setting a promising foundation for deep learning architectures. While the
applicability of FINs has been chiefly tested in biomedical domains, this study
extends its exploration into other time series datasets. Three different
experiments are conducted in this study to test the applicability of imitating
Tsallis entropy for performance enhancement: Bitcoin price prediction, speech
emotion recognition, and chronic neck pain detection. For the Bitcoin price
prediction, models embedded with FINs reduced the root mean square error by
around 1000 compared to the baseline. In the speech emotion recognition task,
the FIN-augmented model increased classification accuracy by over 3 percent.
Lastly, in the CNP detection experiment, an improvement of about 7 percent was
observed compared to established classifiers. These findings validate the broad
utility and potency of FINs in diverse applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khanmohammadi_R/0/1/0/all/0/1&quot;&gt;Reza Khanmohammadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alhanai_T/0/1/0/all/0/1&quot;&gt;Tuka Alhanai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1&quot;&gt;Mohammad M. Ghassemi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12283">
<title>Performance Conditioning for Diffusion-Based Multi-Instrument Music Synthesis. (arXiv:2309.12283v1 [cs.SD])</title>
<link>http://arxiv.org/abs/2309.12283</link>
<description rdf:parseType="Literal">&lt;p&gt;Generating multi-instrument music from symbolic music representations is an
important task in Music Information Retrieval (MIR). A central but still
largely unsolved problem in this context is musically and acoustically informed
control in the generation process. As the main contribution of this work, we
propose enhancing control of multi-instrument synthesis by conditioning a
generative model on a specific performance and recording environment, thus
allowing for better guidance of timbre and style. Building on state-of-the-art
diffusion-based music generative models, we introduce performance conditioning
- a simple tool indicating the generative model to synthesize music with style
and timbre of specific instruments taken from specific performances. Our
prototype is evaluated using uncurated performances with diverse
instrumentation and achieves state-of-the-art FAD realism scores while allowing
novel timbre and style control. Our project page, including samples and
demonstrations, is available at benadar293.github.io/midipm
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maman_B/0/1/0/all/0/1&quot;&gt;Ben Maman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeitler_J/0/1/0/all/0/1&quot;&gt;Johannes Zeitler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1&quot;&gt;Meinard M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1&quot;&gt;Amit H. Bermano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12288">
<title>The Reversal Curse: LLMs trained on &quot;A is B&quot; fail to learn &quot;B is A&quot;. (arXiv:2309.12288v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.12288</link>
<description rdf:parseType="Literal">&lt;p&gt;We expose a surprising failure of generalization in auto-regressive large
language models (LLMs). If a model is trained on a sentence of the form &quot;A is
B&quot;, it will not automatically generalize to the reverse direction &quot;B is A&quot;.
This is the Reversal Curse. For instance, if a model is trained on &quot;Olaf Scholz
was the ninth Chancellor of Germany&quot;, it will not automatically be able to
answer the question, &quot;Who was the ninth Chancellor of Germany?&quot;. Moreover, the
likelihood of the correct answer (&quot;Olaf Scholz&quot;) will not be higher than for a
random name. Thus, models exhibit a basic failure of logical deduction and do
not generalize a prevalent pattern in their training set (i.e. if &quot;A is B&apos;&apos;
occurs, &quot;B is A&quot; is more likely to occur). We provide evidence for the Reversal
Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as &quot;Uriah
Hawthorne is the composer of &apos;Abyssal Melodies&apos;&quot; and showing that they fail to
correctly answer &quot;Who composed &apos;Abyssal Melodies?&apos;&quot;. The Reversal Curse is
robust across model sizes and model families and is not alleviated by data
augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about
real-world celebrities, such as &quot;Who is Tom Cruise&apos;s mother? [A: Mary Lee
Pfeiffer]&quot; and the reverse &quot;Who is Mary Lee Pfeiffer&apos;s son?&quot;. GPT-4 correctly
answers questions like the former 79% of the time, compared to 33% for the
latter. This shows a failure of logical deduction that we hypothesize is caused
by the Reversal Curse. Code is available at
https://github.com/lukasberglund/reversal_curse.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berglund_L/0/1/0/all/0/1&quot;&gt;Lukas Berglund&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_M/0/1/0/all/0/1&quot;&gt;Meg Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaufmann_M/0/1/0/all/0/1&quot;&gt;Max Kaufmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balesni_M/0/1/0/all/0/1&quot;&gt;Mikita Balesni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stickland_A/0/1/0/all/0/1&quot;&gt;Asa Cooper Stickland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1&quot;&gt;Tomasz Korbak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_O/0/1/0/all/0/1&quot;&gt;Owain Evans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12295">
<title>Learning to Drive Anywhere. (arXiv:2309.12295v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.12295</link>
<description rdf:parseType="Literal">&lt;p&gt;Human drivers can seamlessly adapt their driving decisions across
geographical locations with diverse conditions and rules of the road, e.g.,
left vs. right-hand traffic. In contrast, existing models for autonomous
driving have been thus far only deployed within restricted operational domains,
i.e., without accounting for varying driving behaviors across locations or
model scalability. In this work, we propose AnyD, a single geographically-aware
conditional imitation learning (CIL) model that can efficiently learn from
heterogeneous and globally distributed data with dynamic environmental,
traffic, and social characteristics. Our key insight is to introduce a
high-capacity geo-location-based channel attention mechanism that effectively
adapts to local nuances while also flexibly modeling similarities among regions
in a data-driven manner. By optimizing a contrastive imitation objective, our
proposed approach can efficiently scale across inherently imbalanced data
distributions and location-dependent events. We demonstrate the benefits of our
AnyD agent across multiple datasets, cities, and scalable deployment paradigms,
i.e., centralized, semi-supervised, and distributed agent training.
Specifically, AnyD outperforms CIL baselines by over 14% in open-loop
evaluation and 30% in closed-loop testing on CARLA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1&quot;&gt;Ruizhao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1&quot;&gt;Peng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ohn_Bar_E/0/1/0/all/0/1&quot;&gt;Eshed Ohn-Bar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saligrama_V/0/1/0/all/0/1&quot;&gt;Venkatesh Saligrama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12300">
<title>See to Touch: Learning Tactile Dexterity through Visual Incentives. (arXiv:2309.12300v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.12300</link>
<description rdf:parseType="Literal">&lt;p&gt;Equipping multi-fingered robots with tactile sensing is crucial for achieving
the precise, contact-rich, and dexterous manipulation that humans excel at.
However, relying solely on tactile sensing fails to provide adequate cues for
reasoning about objects&apos; spatial configurations, limiting the ability to
correct errors and adapt to changing situations. In this paper, we present
Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances
tactile-based dexterity by optimizing dexterous policies using vision-based
rewards. First, we use a contrastive-based objective to learn visual
representations. Next, we construct a reward function using these visual
representations through optimal-transport based matching on one human
demonstration. Finally, we use online reinforcement learning on our robot to
optimize tactile-based policies that maximize the visual reward. On six
challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping
slender objects, TAVI achieves a success rate of 73% using our four-fingered
Allegro robot hand. The increase in performance is 108% higher than policies
using tactile and vision-based rewards and 135% higher than policies without
tactile observational input. Robot videos are best viewed on our project
website: https://see-to-touch.github.io/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzey_I/0/1/0/all/0/1&quot;&gt;Irmak Guzey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1&quot;&gt;Yinlong Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_B/0/1/0/all/0/1&quot;&gt;Ben Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chintala_S/0/1/0/all/0/1&quot;&gt;Soumith Chintala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinto_L/0/1/0/all/0/1&quot;&gt;Lerrel Pinto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12301">
<title>Environment-biased Feature Ranking for Novelty Detection Robustness. (arXiv:2309.12301v1 [cs.LG])</title>
<link>http://arxiv.org/abs/2309.12301</link>
<description rdf:parseType="Literal">&lt;p&gt;We tackle the problem of robust novelty detection, where we aim to detect
novelties in terms of semantic content while being invariant to changes in
other, irrelevant factors. Specifically, we operate in a setup with multiple
environments, where we determine the set of features that are associated more
with the environments, rather than to the content relevant for the task. Thus,
we propose a method that starts with a pretrained embedding and a multi-env
setup and manages to rank the features based on their environment-focus. First,
we compute a per-feature score based on the feature distribution variance
between envs. Next, we show that by dropping the highly scored ones, we manage
to remove spurious correlations and improve the overall performance by up to
6%, both in covariance and sub-population shift cases, both for a real and a
synthetic benchmark, that we introduce for this task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smeu_S/0/1/0/all/0/1&quot;&gt;Stefan Smeu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burceanu_E/0/1/0/all/0/1&quot;&gt;Elena Burceanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haller_E/0/1/0/all/0/1&quot;&gt;Emanuela Haller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicolicioiu_A/0/1/0/all/0/1&quot;&gt;Andrei Liviu Nicolicioiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12307">
<title>LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models. (arXiv:2309.12307v1 [cs.CL])</title>
<link>http://arxiv.org/abs/2309.12307</link>
<description rdf:parseType="Literal">&lt;p&gt;We present LongLoRA, an efficient fine-tuning approach that extends the
context sizes of pre-trained large language models (LLMs), with limited
computation cost. Typically, training LLMs with long context sizes is
computationally expensive, requiring extensive training hours and GPU
resources. For example, training on the context length of 8192 needs 16x
computational costs in self-attention layers as that of 2048. In this paper, we
speed up the context extension of LLMs in two aspects. On the one hand,
although dense global attention is needed during inference, fine-tuning the
model can be effectively and efficiently done by sparse local attention. The
proposed shift short attention effectively enables context extension, leading
to non-trivial computation saving with similar performance to fine-tuning with
vanilla attention. Particularly, it can be implemented with only two lines of
code in training, while being optional in inference. On the other hand, we
revisit the parameter-efficient fine-tuning regime for context expansion.
Notably, we find that LoRA for context extension works well under the premise
of trainable embedding and normalization. LongLoRA demonstrates strong
empirical results on various tasks on LLaMA2 models from 7B/13B to 70B.
LongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a
single 8x A100 machine. LongLoRA extends models&apos; context while retaining their
original architectures, and is compatible with most existing techniques, like
FlashAttention-2. In addition, to make LongLoRA practical, we collect a
dataset, LongQA, for supervised fine-tuning. It contains more than 3k long
context question-answer pairs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yukang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1&quot;&gt;Shengju Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Haotian Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_X/0/1/0/all/0/1&quot;&gt;Xin Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhijian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Song Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1&quot;&gt;Jiaya Jia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12311">
<title>LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent. (arXiv:2309.12311v1 [cs.CV])</title>
<link>http://arxiv.org/abs/2309.12311</link>
<description rdf:parseType="Literal">&lt;p&gt;3D visual grounding is a critical skill for household robots, enabling them
to navigate, manipulate objects, and answer questions based on their
environment. While existing approaches often rely on extensive labeled data or
exhibit limitations in handling complex language queries, we propose
LLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model
(LLM)-based 3D visual grounding pipeline. LLM-Grounder utilizes an LLM to
decompose complex natural language queries into semantic constituents and
employs a visual grounding tool, such as OpenScene or LERF, to identify objects
in a 3D scene. The LLM then evaluates the spatial and commonsense relations
among the proposed objects to make a final grounding decision. Our method does
not require any labeled training data and can generalize to novel 3D scenes and
arbitrary text queries. We evaluate LLM-Grounder on the ScanRefer benchmark and
demonstrate state-of-the-art zero-shot grounding accuracy. Our findings
indicate that LLMs significantly improve the grounding capability, especially
for complex language queries, making LLM-Grounder an effective approach for 3D
vision-language tasks in robotics. Videos and interactive demos can be found on
the project website https://chat-with-nerf.github.io/ .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianing Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xuweiyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1&quot;&gt;Shengyi Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madaan_N/0/1/0/all/0/1&quot;&gt;Nikhil Madaan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iyengar_M/0/1/0/all/0/1&quot;&gt;Madhavan Iyengar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fouhey_D/0/1/0/all/0/1&quot;&gt;David F. Fouhey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chai_J/0/1/0/all/0/1&quot;&gt;Joyce Chai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.12312">
<title>ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals. (arXiv:2309.12312v1 [cs.RO])</title>
<link>http://arxiv.org/abs/2309.12312</link>
<description rdf:parseType="Literal">&lt;p&gt;We present ForceSight, a system for text-guided mobile manipulation that
predicts visual-force goals using a deep neural network. Given a single RGBD
image combined with a text prompt, ForceSight determines a target end-effector
pose in the camera frame (kinematic goal) and the associated forces (force
goal). Together, these two components form a visual-force goal. Prior work has
demonstrated that deep models outputting human-interpretable kinematic goals
can enable dexterous manipulation by real robots. Forces are critical to
manipulation, yet have typically been relegated to lower-level execution in
these systems. When deployed on a mobile manipulator equipped with an
eye-in-hand RGBD camera, ForceSight performed tasks such as precision grasps,
drawer opening, and object handovers with an 81% success rate in unseen
environments with object instances that differed significantly from the
training data. In a separate experiment, relying exclusively on visual servoing
and ignoring force goals dropped the success rate from 90% to 45%,
demonstrating that force goals can significantly enhance performance. The
appendix, videos, code, and trained models are available at
https://force-sight.github.io/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collins_J/0/1/0/all/0/1&quot;&gt;Jeremy A. Collins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houff_C/0/1/0/all/0/1&quot;&gt;Cody Houff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1&quot;&gt;You Liang Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kemp_C/0/1/0/all/0/1&quot;&gt;Charles C. Kemp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2102.11941">
<title>State Augmented Constrained Reinforcement Learning: Overcoming the Limitations of Learning with Rewards. (arXiv:2102.11941v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2102.11941</link>
<description rdf:parseType="Literal">&lt;p&gt;A common formulation of constrained reinforcement learning involves multiple
rewards that must individually accumulate to given thresholds. In this class of
problems, we show a simple example in which the desired optimal policy cannot
be induced by any weighted linear combination of rewards. Hence, there exist
constrained reinforcement learning problems for which neither regularized nor
classical primal-dual methods yield optimal policies. This work addresses this
shortcoming by augmenting the state with Lagrange multipliers and
reinterpreting primal-dual methods as the portion of the dynamics that drives
the multipliers evolution. This approach provides a systematic state
augmentation procedure that is guaranteed to solve reinforcement learning
problems with constraints. Thus, as we illustrate by an example, while previous
methods can fail at finding optimal policies, running the dual dynamics while
executing the augmented policy yields an algorithm that provably samples
actions from the optimal policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calvo_Fullana_M/0/1/0/all/0/1&quot;&gt;Miguel Calvo-Fullana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paternain_S/0/1/0/all/0/1&quot;&gt;Santiago Paternain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chamon_L/0/1/0/all/0/1&quot;&gt;Luiz F. O. Chamon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Alejandro Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2203.09879">
<title>Class-wise Classifier Design Capable of Continual Learning using Adaptive Resonance Theory-based Topological Clustering. (arXiv:2203.09879v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2203.09879</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a supervised classification algorithm capable of
continual learning by utilizing an Adaptive Resonance Theory (ART)-based
growing self-organizing clustering algorithm. The ART-based clustering
algorithm is theoretically capable of continual learning, and the proposed
algorithm independently applies it to each class of training data for
generating classifiers. Whenever an additional training data set from a new
class is given, a new ART-based clustering will be defined in a different
learning space. Thanks to the above-mentioned features, the proposed algorithm
realizes continual learning capability. Simulation experiments showed that the
proposed algorithm has superior classification performance compared with
state-of-the-art clustering-based classification algorithms capable of
continual learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masuyama_N/0/1/0/all/0/1&quot;&gt;Naoki Masuyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nojima_Y/0/1/0/all/0/1&quot;&gt;Yusuke Nojima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dawood_F/0/1/0/all/0/1&quot;&gt;Farhan Dawood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zongying Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2205.02998">
<title>Optimal Propagation for Graph Neural Networks. (arXiv:2205.02998v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2205.02998</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Neural Networks (GNNs) have achieved tremendous success in a variety of
real-world applications by relying on the fixed graph data as input. However,
the initial input graph might not be optimal in terms of specific downstream
tasks, because of information scarcity, noise, adversarial attacks, or
discrepancies between the distribution in graph topology, features, and
groundtruth labels. In this paper, we propose a bi-level optimization approach
for learning the optimal graph structure via directly learning the Personalized
PageRank propagation matrix as well as the downstream semi-supervised node
classification simultaneously. We also explore a low-rank approximation model
for further reducing the time complexity. Empirical evaluations show the
superior efficacy and robustness of the proposed model over all baseline
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1&quot;&gt;Beidi Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1&quot;&gt;Boxin Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhe Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Liangyue Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1&quot;&gt;Hanghang Tong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2208.03392">
<title>Federated Learning for Medical Applications: A Taxonomy, Current Trends, Challenges, and Future Research Directions. (arXiv:2208.03392v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2208.03392</link>
<description rdf:parseType="Literal">&lt;p&gt;With the advent of the IoT, AI and ML/DL algorithms, the landscape of
data-driven medical applications has emerged as a promising avenue for
designing robust and scalable diagnostic and prognostic models from medical
data. Consequently, the realm of data-driven medical applications has garnered
significant attention spanning academia and industry, ushering in marked
enhancements in healthcare delivery quality. Despite these strides, the
adoption of AI-driven medical applications remains hindered by formidable
challenges, including the arduous task of meeting security, privacy, and
quality of service (QoS) standards. Recent developments in federated learning
have made it possible to train complex machine-learned models in a distributed
manner and has become an active research domain, particularly processing the
medical data at the edge of the network in a decentralized way to preserve
privacy and address security concerns. To this end, this survey paper
highlights the current and future of FL technology in medical applications
where data sharing is a significant burden. We delve into the contemporary
research trends and their outcomes, unravelling the intricacies of designing
reliable and scalable FL models. Our survey outlines the foundational
statistical predicaments of FL, confronts device-related obstacles, delves into
security challenges, and navigates the intricate terrain of privacy concerns,
all while spotlighting its transformative potential within the medical domain.
A primary focus of our study rests on medical applications, where we underscore
the weighty burden of global cancer and illuminate the potency of FL in
engendering computer-aided diagnosis tools that address this challenge with
heightened efficacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rauniyar_A/0/1/0/all/0/1&quot;&gt;Ashish Rauniyar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hagos_D/0/1/0/all/0/1&quot;&gt;Desta Haileselassie Hagos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_D/0/1/0/all/0/1&quot;&gt;Debesh Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haakegaard_J/0/1/0/all/0/1&quot;&gt;Jan Erik H&amp;#xe5;keg&amp;#xe5;rd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagci_U/0/1/0/all/0/1&quot;&gt;Ulas Bagci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rawat_D/0/1/0/all/0/1&quot;&gt;Danda B. Rawat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vlassov_V/0/1/0/all/0/1&quot;&gt;Vladimir Vlassov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2209.05355">
<title>Analysis and Comparison of Classification Metrics. (arXiv:2209.05355v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2209.05355</link>
<description rdf:parseType="Literal">&lt;p&gt;A variety of different performance metrics are commonly used in the machine
learning literature for the evaluation of classification systems. Some of the
most common ones for measuring quality of hard decisions are standard and
balanced accuracy, standard and balanced error rate, F-beta score, and Matthews
correlation coefficient (MCC). In this document, we review the definition of
these and other metrics and compare them with the expected cost (EC), a metric
introduced in every statistical learning course but rarely used in the machine
learning literature. We show that both the standard and balanced error rates
are special cases of the EC. Further, we show its relation with F-beta score
and MCC and argue that EC is superior to these traditional metrics for being
based on first principles from statistics, and for being more general,
interpretable, and adaptable to any application scenario. The metrics mentioned
above measure the quality of hard decisions. Yet, most modern classification
systems output continuous scores for the classes which we may want to evaluate
directly. Metrics for measuring the quality of system scores include the area
under the ROC curve, equal error rate, cross-entropy, Brier score, and Bayes EC
or Bayes risk, among others. The last three metrics are special cases of a
family of metrics given by the expected value of proper scoring rules (PSRs).
We review the theory behind these metrics, showing that they are a principled
way to measure the quality of the posterior probabilities produced by a system.
Finally, we show how to use these metrics to compute a system&apos;s calibration
loss and compare this metric with the widely-used expected calibration error
(ECE), arguing that calibration loss based on PSRs is superior to the ECE for
being more interpretable, more general, and directly applicable to the
multi-class case, among other reasons.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrer_L/0/1/0/all/0/1&quot;&gt;Luciana Ferrer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.00997">
<title>Online Self-Concordant and Relatively Smooth Minimization, With Applications to Online Portfolio Selection and Learning Quantum States. (arXiv:2210.00997v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2210.00997</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider an online convex optimization problem where the loss functions are
self-concordant barriers, smooth relative to a convex function $h$, and
possibly non-Lipschitz. We analyze the regret of online mirror descent with
$h$. Then, based on the result, we prove the following in a unified manner.
Denote by $T$ the time horizon and $d$ the parameter dimension. 1. For online
portfolio selection, the regret of $\widetilde{\text{EG}}$, a variant of
exponentiated gradient due to Helmbold et al., is $\tilde{O} ( T^{2/3} d^{1/3}
)$ when $T &amp;gt; 4 d / \log d$. This improves on the original $\tilde{O} ( T^{3/4}
d^{1/2} )$ regret bound for $\widetilde{\text{EG}}$. 2. For online portfolio
selection, the regret of online mirror descent with the logarithmic barrier is
$\tilde{O}(\sqrt{T d})$. The regret bound is the same as that of Soft-Bayes due
to Orseau et al. up to logarithmic terms. 3. For online learning quantum states
with the logarithmic loss, the regret of online mirror descent with the
log-determinant function is also $\tilde{O} ( \sqrt{T d} )$. Its per-iteration
time is shorter than all existing algorithms we know.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsai_C/0/1/0/all/0/1&quot;&gt;Chung-En Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_H/0/1/0/all/0/1&quot;&gt;Hao-Chung Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yen-Huan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.01918">
<title>Nonparametric and Regularized Dynamical Wasserstein Barycenters for Sequential Observations. (arXiv:2210.01918v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.01918</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider probabilistic models for sequential observations which exhibit
gradual transitions among a finite number of states. We are particularly
motivated by applications such as human activity analysis where observed
accelerometer time series contains segments representing distinct activities,
which we call pure states, as well as periods characterized by continuous
transition among these pure states. To capture this transitory behavior, the
dynamical Wasserstein barycenter (DWB) model of Cheng et al. in 2021 [1]
associates with each pure state a data-generating distribution and models the
continuous transitions among these states as a Wasserstein barycenter of these
distributions with dynamically evolving weights. Focusing on the univariate
case where Wasserstein distances and barycenters can be computed in closed
form, we extend [1] specifically relaxing the parameterization of the pure
states as Gaussian distributions. We highlight issues related to the uniqueness
in identifying the model parameters as well as uncertainties induced when
estimating a dynamically evolving distribution from a limited number of
samples. To ameliorate non-uniqueness, we introduce regularization that imposes
temporal smoothness on the dynamics of the barycentric weights. A
quantile-based approximation of the pure state distributions yields a finite
dimensional estimation problem which we numerically solve using cyclic descent
alternating between updates to the pure-state quantile functions and the
barycentric weights. We demonstrate the utility of the proposed algorithm in
segmenting both simulated and real world human activity time series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1&quot;&gt;Kevin C. Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aeron_S/0/1/0/all/0/1&quot;&gt;Shuchin Aeron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hughes_M/0/1/0/all/0/1&quot;&gt;Michael C. Hughes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_E/0/1/0/all/0/1&quot;&gt;Eric L. Miller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2210.03269">
<title>Multi-agent Deep Covering Skill Discovery. (arXiv:2210.03269v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2210.03269</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of skills (a.k.a., options) can greatly accelerate exploration in
reinforcement learning, especially when only sparse reward signals are
available. While option discovery methods have been proposed for individual
agents, in multi-agent reinforcement learning settings, discovering
collaborative options that can coordinate the behavior of multiple agents and
encourage them to visit the under-explored regions of their joint state space
has not been considered. In this case, we propose Multi-agent Deep Covering
Option Discovery, which constructs the multi-agent options through minimizing
the expected cover time of the multiple agents&apos; joint state space. Also, we
propose a novel framework to adopt the multi-agent options in the MARL process.
In practice, a multi-agent task can usually be divided into some sub-tasks,
each of which can be completed by a sub-group of the agents. Therefore, our
algorithm framework first leverages an attention mechanism to find
collaborative agent sub-groups that would benefit most from coordinated
actions. Then, a hierarchical algorithm, namely HA-MSAC, is developed to learn
the multi-agent options for each sub-group to complete their sub-tasks first,
and then to integrate them through a high-level policy as the solution of the
whole task. This hierarchical option construction allows our framework to
strike a balance between scalability and effective collaboration among the
agents. The evaluation based on multi-agent collaborative tasks shows that the
proposed algorithm can effectively capture the agent interactions with the
attention mechanism, successfully identify multi-agent options, and
significantly outperforms prior works using single-agent options or no options,
in terms of both faster exploration and higher task rewards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiayu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haliem_M/0/1/0/all/0/1&quot;&gt;Marina Haliem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_T/0/1/0/all/0/1&quot;&gt;Tian Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1&quot;&gt;Vaneet Aggarwal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2211.02900">
<title>Grassmann Manifold Flows for Stable Shape Generation. (arXiv:2211.02900v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2211.02900</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, studies on machine learning have focused on methods that use
symmetry implicit in a specific manifold as an inductive bias. Grassmann
manifolds provide the ability to handle fundamental shapes represented as shape
spaces, enabling stable shape analysis. In this paper, we present a novel
approach in which we establish the theoretical foundations for learning
distributions on the Grassmann manifold via continuous normalization flows,
with the explicit goal of generating stable shapes. Our approach facilitates
more robust generation by effectively eliminating the influence of extraneous
transformations, such as rotations and inversions, through learning and
generating within a Grassmann manifolds designed to accommodate the essential
shape information of the object. The experimental results indicated that the
proposed method can generate high-quality samples by capturing the data
structure. Furthermore, the proposed method significantly outperformed
state-of-the-art methods in terms of the log-likelihood or evidence lower
bound. The results obtained are expected to stimulate further research in this
field, leading to advances for stable shape generation and analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yataka_R/0/1/0/all/0/1&quot;&gt;Ryoma Yataka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shiraishi_M/0/1/0/all/0/1&quot;&gt;Masashi Shiraishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hirashima_K/0/1/0/all/0/1&quot;&gt;Kazuki Hirashima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.03414">
<title>DREAM: A Dynamic Scheduler for Dynamic Real-time Multi-model ML Workloads. (arXiv:2212.03414v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/2212.03414</link>
<description rdf:parseType="Literal">&lt;p&gt;Emerging real-time multi-model ML (RTMM) workloads such as AR/VR and drone
control involve dynamic behaviors in various granularity; task, model, and
layers within a model. Such dynamic behaviors introduce new challenges to the
system software in an ML system since the overall system load is not completely
predictable, unlike traditional ML workloads. In addition, RTMM workloads
require real-time processing, involve highly heterogeneous models, and target
resource-constrained devices. Under such circumstances, developing an effective
scheduler gains more importance to better utilize underlying hardware
considering the unique characteristics of RTMM workloads. Therefore, we propose
a new scheduler, DREAM, which effectively handles various dynamicity in RTMM
workloads targeting multi-accelerator systems. DREAM quantifies the unique
requirements for RTMM workloads and utilizes the quantified scores to drive
scheduling decisions, considering the current system load and other inference
jobs on different models and input frames. DREAM utilizes tunable parameters
that provide fast and effective adaptivity to dynamic workload changes. In our
evaluation of five scenarios of RTMM workload, DREAM reduces the overall
UXCost, which is an equivalent metric of the energy-delay product (EDP) for
RTMM defined in the paper, by 32.2% and 50.0% in the geometric mean (up to
80.8% and 97.6%) compared to state-of-the-art baselines, which shows the
efficacy of our scheduling methodology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seah Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwon_H/0/1/0/all/0/1&quot;&gt;Hyoukjun Kwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jinook Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1&quot;&gt;Jihyuck Jo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yu-Hsin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1&quot;&gt;Liangzhen Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1&quot;&gt;Vikas Chandra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2212.11278">
<title>Decision-making and control with diffractive optical networks. (arXiv:2212.11278v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2212.11278</link>
<description rdf:parseType="Literal">&lt;p&gt;The ultimate goal of artificial intelligence is to mimic the human brain to
perform decision-making and control directly from high-dimensional sensory
input. Diffractive optical networks provide a promising solution for
implementing artificial intelligence with high-speed and low-power consumption.
Most of the reported diffractive optical networks focus on single or multiple
tasks that do not involve environmental interaction, such as object recognition
and image classification. In contrast, the networks capable of performing
decision-making and control have not yet been developed to our knowledge. Here,
we propose using deep reinforcement learning to implement diffractive optical
networks that imitate human-level decision-making and control capability. Such
networks taking advantage of a residual architecture, allow for finding optimal
control policies through interaction with the environment and can be readily
implemented with existing optical devices. The superior performance of these
networks is verified by engaging three types of classic games, Tic-Tac-Toe,
Super Mario Bros., and Car Racing. Finally, we present an experimental
demonstration of playing Tic-Tac-Toe by leveraging diffractive optical networks
based on a spatial light modulator. Our work represents a solid step forward in
advancing diffractive optical networks, which promises a fundamental shift from
the target-driven control of a pre-designed state for simple recognition or
classification tasks to the high-level sensory capability of artificial
intelligence. It may find exciting applications in autonomous driving,
intelligent robots, and intelligent manufacturing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1&quot;&gt;Jumin Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1&quot;&gt;Shuyuan Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lujun Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miroshnichenko_A/0/1/0/all/0/1&quot;&gt;Andrey Miroshnichenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dejian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tingting Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1&quot;&gt;Tianbao Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.03044">
<title>A Survey on Transformers in Reinforcement Learning. (arXiv:2301.03044v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.03044</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformer has been considered the dominating neural architecture in NLP and
CV, mostly under supervised settings. Recently, a similar surge of using
Transformers has appeared in the domain of reinforcement learning (RL), but it
is faced with unique design choices and challenges brought by the nature of RL.
However, the evolution of Transformers in RL has not yet been well unraveled.
In this paper, we seek to systematically review motivations and progress on
using Transformers in RL, provide a taxonomy on existing works, discuss each
sub-field, and summarize future prospects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenzhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Hao Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zichuan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chongjie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zongqing Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1&quot;&gt;Deheng Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.11734">
<title>Improving Behavioural Cloning with Positive Unlabeled Learning. (arXiv:2301.11734v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2301.11734</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning control policies offline from pre-recorded datasets is a promising
avenue for solving challenging real-world problems. However, available datasets
are typically of mixed quality, with a limited number of the trajectories that
we would consider as positive examples; i.e., high-quality demonstrations.
Therefore, we propose a novel iterative learning algorithm for identifying
expert trajectories in unlabeled mixed-quality robotics datasets given a
minimal set of positive examples, surpassing existing algorithms in terms of
accuracy. We show that applying behavioral cloning to the resulting filtered
dataset outperforms several competitive offline reinforcement learning and
imitation learning baselines. We perform experiments on a range of simulated
locomotion tasks and on two challenging manipulation tasks on a real robotic
system; in these experiments, our method showcases state-of-the-art
performance. Our website:
\url{https://sites.google.com/view/offline-policy-learning-pubc}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCarthy_R/0/1/0/all/0/1&quot;&gt;Robert McCarthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bulens_D/0/1/0/all/0/1&quot;&gt;David Cordova Bulens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGuinness_K/0/1/0/all/0/1&quot;&gt;Kevin McGuinness&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1&quot;&gt;Noel E. O&amp;#x27;Connor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurtler_N/0/1/0/all/0/1&quot;&gt;Nico G&amp;#xfc;rtler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Widmaier_F/0/1/0/all/0/1&quot;&gt;Felix Widmaier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_F/0/1/0/all/0/1&quot;&gt;Francisco Roldan Sanchez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Redmond_S/0/1/0/all/0/1&quot;&gt;Stephen J. Redmond&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2301.13019">
<title>Identifying Expert Behavior in Offline Training Datasets Improves Behavioral Cloning of Robotic Manipulation Policies. (arXiv:2301.13019v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/2301.13019</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents our solution for the Real Robot Challenge (RRC) III, a
competition featured in the NeurIPS 2022 Competition Track, aimed at addressing
dexterous robotic manipulation tasks through learning from pre-collected
offline data. Participants were provided with two types of datasets for each
task: expert and mixed datasets with varying skill levels. While the simplest
offline policy learning algorithm, Behavioral Cloning (BC), performed
remarkably well when trained on expert datasets, it outperformed even the most
advanced offline reinforcement learning (RL) algorithms. However, BC&apos;s
performance deteriorated when applied to mixed datasets, and the performance of
offline RL algorithms was also unsatisfactory. Upon examining the mixed
datasets, we observed that they contained a significant amount of expert data,
although this data was unlabeled. To address this issue, we proposed a
semi-supervised learning-based classifier to identify the underlying expert
behavior within mixed datasets, effectively isolating the expert data. To
further enhance BC&apos;s performance, we leveraged the geometric symmetry of the
RRC arena to augment the training dataset through mathematical transformations.
In the end, our submission surpassed that of all other participants, even those
who employed complex offline RL algorithms and intricate data processing and
feature engineering techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCarthy_R/0/1/0/all/0/1&quot;&gt;Robert McCarthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bulens_D/0/1/0/all/0/1&quot;&gt;David Cordova Bulens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_F/0/1/0/all/0/1&quot;&gt;Francisco Roldan Sanchez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGuinness_K/0/1/0/all/0/1&quot;&gt;Kevin McGuinness&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1&quot;&gt;Noel E. O&amp;#x27;Connor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Redmond_S/0/1/0/all/0/1&quot;&gt;Stephen J. Redmond&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2302.08661">
<title>Subsampling Suffices for Adaptive Data Analysis. (arXiv:2302.08661v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2302.08661</link>
<description rdf:parseType="Literal">&lt;p&gt;Ensuring that analyses performed on a dataset are representative of the
entire population is one of the central problems in statistics. Most classical
techniques assume that the dataset is independent of the analyst&apos;s query and
break down in the common setting where a dataset is reused for multiple,
adaptively chosen, queries. This problem of \emph{adaptive data analysis} was
formalized in the seminal works of Dwork et al. (STOC, 2015) and Hardt and
Ullman (FOCS, 2014).
&lt;/p&gt;
&lt;p&gt;We identify a remarkably simple set of assumptions under which the queries
will continue to be representative even when chosen adaptively: The only
requirements are that each query takes as input a random subsample and outputs
few bits. This result shows that the noise inherent in subsampling is
sufficient to guarantee that query responses generalize. The simplicity of this
subsampling-based framework allows it to model a variety of real-world
scenarios not covered by prior work.
&lt;/p&gt;
&lt;p&gt;In addition to its simplicity, we demonstrate the utility of this framework
by designing mechanisms for two foundational tasks, statistical queries and
median finding. In particular, our mechanism for answering the broadly
applicable class of statistical queries is both extremely simple and state of
the art in many parameter regimes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blanc_G/0/1/0/all/0/1&quot;&gt;Guy Blanc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.01682">
<title>Neural-BO: A Black-box Optimization Algorithm using Deep Neural Networks. (arXiv:2303.01682v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.01682</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian Optimization (BO) is an effective approach for global optimization
of black-box functions when function evaluations are expensive. Most prior
works use Gaussian processes to model the black-box function, however, the use
of kernels in Gaussian processes leads to two problems: first, the kernel-based
methods scale poorly with the number of data points and second, kernel methods
are usually not effective on complex structured high dimensional data due to
curse of dimensionality. Therefore, we propose a novel black-box optimization
algorithm where the black-box function is modeled using a neural network. Our
algorithm does not need a Bayesian neural network to estimate predictive
uncertainty and is therefore computationally favorable. We analyze the
theoretical behavior of our algorithm in terms of regret bound using advances
in NTK theory showing its efficient convergence. We perform experiments with
both synthetic and real-world optimization tasks and show that our algorithm is
more sample efficient compared to existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_Trong_D/0/1/0/all/0/1&quot;&gt;Dat Phan-Trong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_The_H/0/1/0/all/0/1&quot;&gt;Hung Tran-The&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Sunil Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.10310">
<title>Domain-knowledge Inspired Pseudo Supervision (DIPS) for Unsupervised Image-to-Image Translation Models to Support Cross-Domain Classification. (arXiv:2303.10310v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2303.10310</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to classify images is dependent on having access to large labeled
datasets and testing on data from the same domain that the model can train on.
Classification becomes more challenging when dealing with new data from a
different domain, where gathering and especially labeling a larger image
dataset for retraining a classification model requires a labor-intensive human
effort. Cross-domain classification frameworks were developed to handle this
data domain shift problem by utilizing unsupervised image-to-image translation
models to translate an input image from the unlabeled domain to the labeled
domain. The problem with these unsupervised models lies in their unsupervised
nature. For lack of annotations, it is not possible to use the traditional
supervised metrics to evaluate these translation models to pick the best-saved
checkpoint model. This paper introduces a new method called Domain-knowledge
Inspired Pseudo Supervision (DIPS) which utilizes domain-informed Gaussian
Mixture Models to generate pseudo annotations to enable the use of traditional
supervised metrics. This method was designed specifically to support
cross-domain classification applications contrary to other typically used
metrics such as the FID which were designed to evaluate the model in terms of
the quality of the generated image from a human-eye perspective. DIPS proves
its effectiveness by outperforming various GAN evaluation metrics, including
FID, when selecting the optimal saved checkpoint model. It is also evaluated
against truly supervised metrics. Furthermore, DIPS showcases its robustness
and interpretability by demonstrating a strong correlation with truly
supervised metrics, highlighting its superiority over existing state-of-the-art
alternatives. The code and data to replicate the results can be found on the
official Github repository: https://github.com/Hindawi91/DIPS
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Hindawi_F/0/1/0/all/0/1&quot;&gt;Firas Al-Hindawi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siddiquee_M/0/1/0/all/0/1&quot;&gt;Md Mahfuzur Rahman Siddiquee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Teresa Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Han Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Ying Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2303.13773">
<title>Graph Neural Networks for the Offline Nanosatellite Task Scheduling Problem. (arXiv:2303.13773v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2303.13773</link>
<description rdf:parseType="Literal">&lt;p&gt;This study investigates how to schedule nanosatellite tasks more efficiently
using Graph Neural Networks (GNNs). In the Offline Nanosatellite Task
Scheduling (ONTS) problem, the goal is to find the optimal schedule for tasks
to be carried out in orbit while taking into account Quality-of-Service (QoS)
considerations such as priority, minimum and maximum activation events,
execution time-frames, periods, and execution windows, as well as constraints
on the satellite&apos;s power resources and the complexity of energy harvesting and
management. The ONTS problem has been approached using conventional
mathematical formulations and exact methods, but their applicability to
challenging cases of the problem is limited. This study examines the use of
GNNs in this context, which has been effectively applied to optimization
problems such as the traveling salesman, scheduling, and facility placement
problems. More specifically, we investigate whether GNNs can learn the complex
structure of the ONTS problem with respect to feasibility and optimality of
candidate solutions. Furthermore, we evaluate using GNN-based heuristic
solutions to provide better solutions (w.r.t. the objective value) to the ONTS
problem and reduce the optimization cost. Our experiments show that GNNs are
not only able to learn feasibility and optimality for instances of the ONTS
problem, but they can generalize to harder instances than those seen during
training. Furthermore, the GNN-based heuristics improved the expected objective
value of the best solution found under the time limit in 45%, and reduced the
expected time to find a feasible solution in 35%, when compared to the SCIP
(Solving Constraint Integer Programs) solver in its off-the-shelf configuration
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pacheco_B/0/1/0/all/0/1&quot;&gt;Bruno Machado Pacheco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seman_L/0/1/0/all/0/1&quot;&gt;Laio Oriel Seman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigo_C/0/1/0/all/0/1&quot;&gt;Cezar Antonio Rigo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camponogara_E/0/1/0/all/0/1&quot;&gt;Eduardo Camponogara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bezerra_E/0/1/0/all/0/1&quot;&gt;Eduardo Augusto Bezerra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coelho_L/0/1/0/all/0/1&quot;&gt;Leandro dos Santos Coelho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.03398">
<title>Quantum Conformal Prediction for Reliable Uncertainty Quantification in Quantum Machine Learning. (arXiv:2304.03398v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/2304.03398</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum machine learning is a promising programming paradigm for the
optimization of quantum algorithms in the current era of noisy intermediate
scale quantum (NISQ) computers. A fundamental challenge in quantum machine
learning is generalization, as the designer targets performance under testing
conditions, while having access only to limited training data. Existing
generalization analyses, while identifying important general trends and scaling
laws, cannot be used to assign reliable and informative &quot;error bars&quot; to the
decisions made by quantum models. In this article, we propose a general
methodology that can reliably quantify the uncertainty of quantum models,
irrespective of the amount of training data, of the number of shots, of the
ansatz, of the training algorithm, and of the presence of quantum hardware
noise. The approach, which builds on probabilistic conformal prediction, turns
an arbitrary, possibly small, number of shots from a pre-trained quantum model
into a set prediction, e.g., an interval, that provably contains the true
target with any desired coverage level. Experimental results confirm the
theoretical calibration guarantees of the proposed framework, referred to as
quantum conformal prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sangwoo Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Simeone_O/0/1/0/all/0/1&quot;&gt;Osvaldo Simeone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.06104">
<title>Primal-Dual Contextual Bayesian Optimization for Control System Online Optimization with Time-Average Constraints. (arXiv:2304.06104v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.06104</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of online performance optimization of
constrained closed-loop control systems, where both the objective and the
constraints are unknown black-box functions affected by exogenous time-varying
contextual disturbances. A primal-dual contextual Bayesian optimization
algorithm is proposed that achieves sublinear cumulative regret with respect to
the dynamic optimal solution under certain regularity conditions. Furthermore,
the algorithm achieves zero time-average constraint violation, ensuring that
the average value of the constraint function satisfies the desired constraint.
The method is applied to both sampled instances from Gaussian processes and a
continuous stirred tank reactor parameter tuning problem; simulation results
show that the method simultaneously provides close-to-optimal performance and
maintains constraint feasibility on average. This contrasts current
state-of-the-art methods, which either suffer from large cumulative regret or
severe constraint violations for the case studies presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Wenjie Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yuning Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svetozarevic_B/0/1/0/all/0/1&quot;&gt;Bratislav Svetozarevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_C/0/1/0/all/0/1&quot;&gt;Colin N. Jones&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.12654">
<title>CoDi: Co-evolving Contrastive Diffusion Models for Mixed-type Tabular Synthesis. (arXiv:2304.12654v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2304.12654</link>
<description rdf:parseType="Literal">&lt;p&gt;With growing attention to tabular data these days, the attempt to apply a
synthetic table to various tasks has been expanded toward various scenarios.
Owing to the recent advances in generative modeling, fake data generated by
tabular data synthesis models become sophisticated and realistic. However,
there still exists a difficulty in modeling discrete variables (columns) of
tabular data. In this work, we propose to process continuous and discrete
variables separately (but being conditioned on each other) by two diffusion
models. The two diffusion models are co-evolved during training by reading
conditions from each other. In order to further bind the diffusion models,
moreover, we introduce a contrastive learning method with a negative sampling
method. In our experiments with 11 real-world tabular datasets and 8 baseline
methods, we prove the efficacy of the proposed method, called CoDi.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chaejeong Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jayoung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1&quot;&gt;Noseong Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.04281">
<title>Persistent Homology of the Multiscale Clustering Filtration. (arXiv:2305.04281v2 [math.AT] UPDATED)</title>
<link>http://arxiv.org/abs/2305.04281</link>
<description rdf:parseType="Literal">&lt;p&gt;In many applications in data clustering, it is desirable to find not just a
single partition into clusters but a sequence of partitions describing the data
at different scales, or levels of coarseness. A natural problem then is to
analyse and compare the (not necessarily hierarchical) sequences of partitions
that underpin such multiscale descriptions of data. Here, we introduce a
filtration of abstract simplicial complexes, denoted the Multiscale Clustering
Filtration (MCF), which encodes arbitrary patterns of cluster assignments
across scales, and we prove that the MCF produces stable persistence diagrams.
We then show that the zero-dimensional persistent homology of the MCF measures
the degree of hierarchy in the sequence of partitions, and that the
higher-dimensional persistent homology tracks the emergence and resolution of
conflicts between cluster assignments across the sequence of partitions. To
broaden the theoretical foundations of the MCF, we also provide an equivalent
construction via a nerve complex filtration, and we show that in the
hierarchical case, the MCF reduces to a Vietoris-Rips filtration of an
ultrametric space. We briefly illustrate how the MCF can serve to characterise
multiscale clustering structures in numerical experiments on synthetic data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schindler_D/0/1/0/all/0/1&quot;&gt;Dominik J. Schindler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Barahona_M/0/1/0/all/0/1&quot;&gt;Mauricio Barahona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.05237">
<title>Traffic Forecasting on New Roads Using Spatial Contrastive Pre-Training (SCPT). (arXiv:2305.05237v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.05237</link>
<description rdf:parseType="Literal">&lt;p&gt;New roads are being constructed all the time. However, the capabilities of
previous deep forecasting models to generalize to new roads not seen in the
training data (unseen roads) are rarely explored. In this paper, we introduce a
novel setup called a spatio-temporal (ST) split to evaluate the models&apos;
capabilities to generalize to unseen roads. In this setup, the models are
trained on data from a sample of roads, but tested on roads not seen in the
training data. Moreover, we also present a novel framework called Spatial
Contrastive Pre-Training (SCPT) where we introduce a spatial encoder module to
extract latent features from unseen roads during inference time. This spatial
encoder is pre-trained using contrastive learning. During inference, the
spatial encoder only requires two days of traffic data on the new roads and
does not require any re-training. We also show that the output from the spatial
encoder can be used effectively to infer latent node embeddings on unseen roads
during inference time. The SCPT framework also incorporates a new layer, named
the spatially gated addition (SGA) layer, to effectively combine the latent
features from the output of the spatial encoder to existing backbones.
Additionally, since there is limited data on the unseen roads, we argue that it
is better to decouple traffic signals to trivial-to-capture periodic signals
and difficult-to-capture Markovian signals, and for the spatial encoder to only
learn the Markovian signals. Finally, we empirically evaluated SCPT using the
ST split setup on four real-world datasets. The results showed that adding SCPT
to a backbone consistently improves forecasting performance on unseen roads.
More importantly, the improvements are greater when forecasting further into
the future. The codes are available on GitHub:
https://github.com/cruiseresearchgroup/forecasting-on-new-roads .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prabowo_A/0/1/0/all/0/1&quot;&gt;Arian Prabowo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1&quot;&gt;Hao Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1&quot;&gt;Wei Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1&quot;&gt;Piotr Koniusz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1&quot;&gt;Flora D. Salim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.06908">
<title>CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model. (arXiv:2305.06908v3 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2305.06908</link>
<description rdf:parseType="Literal">&lt;p&gt;Denoising diffusion probabilistic models (DDPMs) have shown promising
performance for speech synthesis. However, a large number of iterative steps
are required to achieve high sample quality, which restricts the inference
speed. Maintaining sample quality while increasing sampling speed has become a
challenging task. In this paper, we propose a &quot;Co&quot;nsistency &quot;Mo&quot;del-based
&quot;Speech&quot; synthesis method, CoMoSpeech, which achieve speech synthesis through a
single diffusion sampling step while achieving high audio quality. The
consistency constraint is applied to distill a consistency model from a
well-designed diffusion-based teacher model, which ultimately yields superior
performances in the distilled CoMoSpeech. Our experiments show that by
generating audio recordings by a single sampling step, the CoMoSpeech achieves
an inference speed more than 150 times faster than real-time on a single NVIDIA
A100 GPU, which is comparable to FastSpeech2, making diffusion-sampling based
speech synthesis truly practical. Meanwhile, objective and subjective
evaluations on text-to-speech and singing voice synthesis show that the
proposed teacher models yield the best audio quality, and the one-step sampling
based CoMoSpeech achieves the best inference speed with better or comparable
audio quality to other conventional multi-step diffusion model baselines. Audio
samples are available at https://comospeech.github.io/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1&quot;&gt;Zhen Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1&quot;&gt;Wei Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1&quot;&gt;Xu Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jie Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qifeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yike Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.10424">
<title>ZeroFlow: Fast, Zero Label, Scalable Scene Flow via Distillation. (arXiv:2305.10424v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2305.10424</link>
<description rdf:parseType="Literal">&lt;p&gt;Scene flow estimation is the task of describing the 3D motion field between
temporally successive point clouds. State-of-the-art methods use strong priors
and test-time optimization techniques, but require on the order of tens of
seconds to process large-scale point clouds, making them unusable as computer
vision primitives for real-time applications such as open world object
detection. Feed forward methods are considerably faster, running on the order
of tens to hundreds of milliseconds for large-scale point clouds, but require
expensive human supervision. To address both limitations, we propose Scene Flow
via Distillation, a simple, scalable distillation framework that uses a
label-free optimization method to produce pseudo-labels to supervise a feed
forward model. Our instantiation of this framework, ZeroFlow, achieves
state-of-the-art performance on the Argoverse 2 Self-Supervised Scene Flow
Challenge while using zero human labels by simply training on large-scale,
diverse unlabeled data. At test-time, ZeroFlow is over 1000$\times$ faster than
label-free state-of-the-art optimization-based methods on large-scale point
clouds and over 1000$\times$ cheaper to train on unlabeled data compared to the
cost of human annotation of that data. To facilitate further research, we will
release our code, trained model weights, and high quality pseudo-labels for the
Argoverse 2 and Waymo Open datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vedder_K/0/1/0/all/0/1&quot;&gt;Kyle Vedder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peri_N/0/1/0/all/0/1&quot;&gt;Neehar Peri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chodosh_N/0/1/0/all/0/1&quot;&gt;Nathaniel Chodosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khatri_I/0/1/0/all/0/1&quot;&gt;Ishan Khatri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1&quot;&gt;Eric Eaton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1&quot;&gt;Dinesh Jayaraman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1&quot;&gt;Deva Ramanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hays_J/0/1/0/all/0/1&quot;&gt;James Hays&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.13706">
<title>Semantic-aware Transmission Scheduling: a Monotonicity-driven Deep Reinforcement Learning Approach. (arXiv:2305.13706v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2305.13706</link>
<description rdf:parseType="Literal">&lt;p&gt;For cyber-physical systems in the 6G era, semantic communications connecting
distributed devices for dynamic control and remote state estimation are
required to guarantee application-level performance, not merely focus on
communication-centric performance. Semantics here is a measure of the
usefulness of information transmissions. Semantic-aware transmission scheduling
of a large system often involves a large decision-making space, and the optimal
policy cannot be obtained by existing algorithms effectively. In this paper, we
first investigate the fundamental properties of the optimal semantic-aware
scheduling policy and then develop advanced deep reinforcement learning (DRL)
algorithms by leveraging the theoretical guidelines. Our numerical results show
that the proposed algorithms can substantially reduce training time and enhance
training performance compared to benchmark algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiazheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wanchun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quevedo_D/0/1/0/all/0/1&quot;&gt;Daniel Quevedo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yonghui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vucetic_B/0/1/0/all/0/1&quot;&gt;Branka Vucetic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2305.14129">
<title>GrACE: Generation using Associated Code Edits. (arXiv:2305.14129v3 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/2305.14129</link>
<description rdf:parseType="Literal">&lt;p&gt;Developers expend a significant amount of time in editing code for a variety
of reasons such as bug fixing or adding new features. Designing effective
methods to predict code edits has been an active yet challenging area of
research due to the diversity of code edits and the difficulty of capturing the
developer intent. In this work, we address these challenges by endowing
pre-trained large language models (LLMs) of code with the knowledge of prior,
relevant edits. The generative capability of the LLMs helps address the
diversity in code changes and conditioning code generation on prior edits helps
capture the latent developer intent. We evaluate two well-known LLMs, Codex and
CodeT5, in zero-shot and fine-tuning settings respectively. In our experiments
with two datasets, the knowledge of prior edits boosts the performance of the
LLMs significantly and enables them to generate 29% and 54% more correctly
edited code in top-1 suggestions relative to the current state-of-the-art
symbolic and neural approaches, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1&quot;&gt;Priyanshu Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khare_A/0/1/0/all/0/1&quot;&gt;Avishree Khare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajpai_Y/0/1/0/all/0/1&quot;&gt;Yasharth Bajpai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1&quot;&gt;Saikat Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1&quot;&gt;Sumit Gulwani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanade_A/0/1/0/all/0/1&quot;&gt;Aditya Kanade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radhakrishna_A/0/1/0/all/0/1&quot;&gt;Arjun Radhakrishna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soares_G/0/1/0/all/0/1&quot;&gt;Gustavo Soares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1&quot;&gt;Ashish Tiwari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.03303">
<title>Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/2306.03303</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce so-called functional input neural networks defined on a possibly
infinite dimensional weighted space with values also in a possibly infinite
dimensional output space. To this end, we use an additive family as hidden
layer maps and a non-linear activation function applied to each hidden layer.
Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global
universal approximation result for generalizations of continuous functions
going beyond the usual approximation on compact sets. This then applies in
particular to approximation of (non-anticipative) path space functionals via
functional input neural networks. As a further application of the weighted
Stone-Weierstrass theorem we prove a global universal approximation result for
linear functions of the signature. We also introduce the viewpoint of Gaussian
process regression in this setting and show that the reproducing kernel Hilbert
space of the signature kernels are Cameron-Martin spaces of certain Gaussian
processes. This paves the way towards uncertainty quantification for signature
kernel regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cuchiero_C/0/1/0/all/0/1&quot;&gt;Christa Cuchiero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schmocker_P/0/1/0/all/0/1&quot;&gt;Philipp Schmocker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teichmann_J/0/1/0/all/0/1&quot;&gt;Josef Teichmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.06101">
<title>Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.06101</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of estimating the learning rate in adaptive methods,
such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to
provably estimate the distance to the solution $D$, which is needed to set the
learning rate optimally. Our techniques are modifications of the D-Adaptation
method for learning-rate-free learning. Our methods improve upon the
convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where
$d_0$ is the initial estimate of $D$. We test our methods on 12 common
logistic-regression benchmark datasets, VGG11 and ResNet-50 training on
CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on
Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT
transformer training on BookWiki. Our experimental results show that our
approaches consistently outperform D-Adaptation and reach test accuracy values
close to that of hand-tuned Adam.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1&quot;&gt;Konstantin Mishchenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Defazio_A/0/1/0/all/0/1&quot;&gt;Aaron Defazio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.16524">
<title>Hyena Neural Operator for Partial Differential Equations. (arXiv:2306.16524v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.16524</link>
<description rdf:parseType="Literal">&lt;p&gt;Numerically solving partial differential equations typically requires fine
discretization to resolve necessary spatiotemporal scales, which can be
computationally expensive. Recent advances in deep learning have provided a new
approach to solving partial differential equations that involves the use of
neural operators. Neural operators are neural network architectures that learn
mappings between function spaces and have the capability to solve partial
differential equations based on data. This study utilizes a novel neural
operator called Hyena, which employs a long convolutional filter that is
parameterized by a multilayer perceptron. The Hyena operator is an operation
that enjoys sub-quadratic complexity and state space model to parameterize long
convolution that enjoys a global receptive field. This mechanism enhances the
model&apos;s comprehension of the input&apos;s context and enables data-dependent weight
for different partial differential equations instances. To measure how
effective the layers are in solving partial differential equations, we conduct
experiments on Diffusion-Reaction equation and Navier Stokes equation. Our
findings indicate Hyena Neural operator can serve as an efficient and accurate
model for learning partial differential equations solution operator. The data
and code used can be found at:
https://github.com/Saupatil07/Hyena-Neural-Operator
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patil_S/0/1/0/all/0/1&quot;&gt;Saurabh Patil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zijie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1&quot;&gt;Amir Barati Farimani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2306.17366">
<title>$\lambda$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces. (arXiv:2306.17366v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2306.17366</link>
<description rdf:parseType="Literal">&lt;p&gt;The idea of decision-aware model learning, that models should be accurate
where it matters for decision-making, has gained prominence in model-based
reinforcement learning. While promising theoretical results have been
established, the empirical performance of algorithms leveraging a
decision-aware loss has been lacking, especially in continuous control
problems. In this paper, we present a study on the necessary components for
decision-aware reinforcement learning models and we showcase design choices
that enable well-performing algorithms. To this end, we provide a theoretical
and empirical investigation into prominent algorithmic ideas in the field. We
highlight that empirical design decisions established in the MuZero line of
works are vital to achieving good performance for related algorithms, and we
showcase differences in behavior between different instantiations of
value-aware algorithms in stochastic environments. Using these insights, we
propose the Latent Model-Based Decision-Aware Actor-Critic framework
($\lambda$-AC) for decision-aware model-based reinforcement learning in
continuous state-spaces and highlight important design choices in different
environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Voelcker_C/0/1/0/all/0/1&quot;&gt;Claas A Voelcker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmadian_A/0/1/0/all/0/1&quot;&gt;Arash Ahmadian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abachi_R/0/1/0/all/0/1&quot;&gt;Romina Abachi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilitschenski_I/0/1/0/all/0/1&quot;&gt;Igor Gilitschenski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farahmand_A/0/1/0/all/0/1&quot;&gt;Amir-massoud Farahmand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.00215">
<title>A Constructive Approach to Function Realization by Neural Stochastic Differential Equations. (arXiv:2307.00215v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/2307.00215</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of function approximation by neural dynamical systems has
typically been approached in a top-down manner: Any continuous function can be
approximated to an arbitrary accuracy by a sufficiently complex model with a
given architecture. This can lead to high-complexity controls which are
impractical in applications. In this paper, we take the opposite, constructive
approach: We impose various structural restrictions on system dynamics and
consequently characterize the class of functions that can be realized by such a
system. The systems are implemented as a cascade interconnection of a neural
stochastic differential equation (Neural SDE), a deterministic dynamical
system, and a readout map. Both probabilistic and geometric (Lie-theoretic)
methods are used to characterize the classes of functions realized by such
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Veeravalli_T/0/1/0/all/0/1&quot;&gt;Tanya Veeravalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Raginsky_M/0/1/0/all/0/1&quot;&gt;Maxim Raginsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.02108">
<title>Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2307.02108</link>
<description rdf:parseType="Literal">&lt;p&gt;Simple regret minimization is a critical problem in learning optimal
treatment assignment policies across various domains, including healthcare and
e-commerce. However, it remains understudied in the contextual bandit setting.
We propose a new family of computationally efficient bandit algorithms for the
stochastic contextual bandit settings, with the flexibility to be adapted for
cumulative regret minimization (with near-optimal minimax guarantees) and
simple regret minimization (with SOTA guarantees). Furthermore, our algorithms
adapt to model misspecification and extend to the continuous arm settings.
These advantages come from constructing and relying on &quot;conformal arm sets&quot;
(CASs), which provide a set of arms at every context that encompass the
context-specific optimal arm with some probability across the context
distribution. Our positive results on simple and cumulative regret guarantees
are contrasted by a negative result, which shows that an algorithm can&apos;t
achieve instance-dependent simple regret guarantees while simultaneously
achieving minimax optimal cumulative regret guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1&quot;&gt;Sanath Kumar Krishnamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_R/0/1/0/all/0/1&quot;&gt;Ruohan Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1&quot;&gt;Susan Athey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2307.15299">
<title>Differential Evolution Algorithm based Hyper-Parameters Selection of Transformer Neural Network Model for Load Forecasting. (arXiv:2307.15299v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/2307.15299</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate load forecasting plays a vital role in numerous sectors, but
accurately capturing the complex dynamics of dynamic power systems remains a
challenge for traditional statistical models. For these reasons, time-series
models (ARIMA) and deep-learning models (ANN, LSTM, GRU, etc.) are commonly
deployed and often experience higher success. In this paper, we analyze the
efficacy of the recently developed Transformer-based Neural Network model in
Load forecasting. Transformer models have the potential to improve Load
forecasting because of their ability to learn long-range dependencies derived
from their Attention Mechanism. We apply several metaheuristics namely
Differential Evolution to find the optimal hyperparameters of the
Transformer-based Neural Network to produce accurate forecasts. Differential
Evolution provides scalable, robust, global solutions to non-differentiable,
multi-objective, or constrained optimization problems. Our work compares the
proposed Transformer based Neural Network model integrated with different
metaheuristic algorithms by their performance in Load forecasting based on
numerical metrics such as Mean Squared Error (MSE) and Mean Absolute Percentage
Error (MAPE). Our findings demonstrate the potential of metaheuristic-enhanced
Transformer-based Neural Network models in Load forecasting accuracy and
provide optimal hyperparameters for each model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_A/0/1/0/all/0/1&quot;&gt;Anuvab Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazumder_A/0/1/0/all/0/1&quot;&gt;Arul Rhik Mazumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_U/0/1/0/all/0/1&quot;&gt;Udayon Sen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.06424">
<title>Multiclass Learnability Does Not Imply Sample Compression. (arXiv:2308.06424v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.06424</link>
<description rdf:parseType="Literal">&lt;p&gt;A hypothesis class admits a sample compression scheme, if for every sample
labeled by a hypothesis from the class, it is possible to retain only a small
subsample, using which the labels on the entire sample can be inferred. The
size of the compression scheme is an upper bound on the size of the subsample
produced. Every learnable binary hypothesis class (which must necessarily have
finite VC dimension) admits a sample compression scheme of size only a finite
function of its VC dimension, independent of the sample size. For multiclass
hypothesis classes, the analog of VC dimension is the DS dimension. We show
that the analogous statement pertaining to sample compression is not true for
multiclass hypothesis classes: every learnable multiclass hypothesis class,
which must necessarily have finite DS dimension, does not admit a sample
compression scheme of size only a finite function of its DS dimension.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pabbaraju_C/0/1/0/all/0/1&quot;&gt;Chirag Pabbaraju&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.07037">
<title>Bayesian Flow Networks. (arXiv:2308.07037v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.07037</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces Bayesian Flow Networks (BFNs), a new class of
generative model in which the parameters of a set of independent distributions
are modified with Bayesian inference in the light of noisy data samples, then
passed as input to a neural network that outputs a second, interdependent
distribution. Starting from a simple prior and iteratively updating the two
distributions yields a generative procedure similar to the reverse process of
diffusion models; however it is conceptually simpler in that no forward process
is required. Discrete and continuous-time loss functions are derived for
continuous, discretised and discrete data, along with sample generation
procedures. Notably, the network inputs for discrete data lie on the
probability simplex, and are therefore natively differentiable, paving the way
for gradient-based sample guidance and few-step generation in discrete domains
such as language modelling. The loss function directly optimises data
compression and places no restrictions on the network architecture. In our
experiments BFNs achieve competitive log-likelihoods for image modelling on
dynamically binarized MNIST and CIFAR-10, and outperform all known discrete
diffusion models on the text8 character-level language modelling task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graves_A/0/1/0/all/0/1&quot;&gt;Alex Graves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_R/0/1/0/all/0/1&quot;&gt;Rupesh Kumar Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atkinson_T/0/1/0/all/0/1&quot;&gt;Timothy Atkinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_F/0/1/0/all/0/1&quot;&gt;Faustino Gomez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.07929">
<title>Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation. (arXiv:2308.07929v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2308.07929</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, large multimodal models, such as CLIP and Stable Diffusion have
experimented tremendous successes in both foundations and applications.
However, as these models increase in parameter size and computational
requirements, it becomes more challenging for users to personalize them for
specific tasks or preferences. In this work, we address the problem of adapting
the previous models towards sets of particular human preferences, aligning the
retrieved or generated images with the preferences of the user. We leverage the
Bradley-Terry preference model to develop a fast adaptation method that
efficiently fine-tunes the original model, with few examples and with minimal
computing resources. Extensive evidence of the capabilities of this framework
is provided through experiments in different domains related to multimodal text
and image understanding, including preference prediction as a reward model, and
generation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallego_V/0/1/0/all/0/1&quot;&gt;Victor Gallego&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.10457">
<title>ALI-DPFL: Differentially Private Federated Learning with Adaptive Local Iterations. (arXiv:2308.10457v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2308.10457</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated Learning (FL) is a distributed machine learning technique that
allows model training among multiple devices or organizations by sharing
training parameters instead of raw data. However, adversaries can still infer
individual information through inference attacks (e.g. differential attacks) on
these training parameters. As a result, Differential Privacy (DP) has been
widely used in FL to prevent such attacks. We consider differentially private
federated learning in a resource-constrained scenario, where both privacy
budget and communication round are constrained. By theoretically analyzing the
convergence, we can find the optimal number of differentially private local
iterations for clients between any two sequential global updates. Based on
this, we design an algorithm of differentially private federated learning with
adaptive local iterations (ALI-DPFL). We experiment our algorithm on the
FashionMNIST and CIFAR10 datasets, and demonstrate significantly better
performances than previous work in the resource-constraint scenario.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1&quot;&gt;Xinpeng Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jie Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Kuncan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haitao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhili Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2308.10792">
<title>Instruction Tuning for Large Language Models: A Survey. (arXiv:2308.10792v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2308.10792</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper surveys research works in the quickly advancing field of
instruction tuning (IT), a crucial technique to enhance the capabilities and
controllability of large language models (LLMs). Instruction tuning refers to
the process of further training LLMs on a dataset consisting of
\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the
gap between the next-word prediction objective of LLMs and the users&apos; objective
of having LLMs adhere to human instructions. In this work, we make a systematic
review of the literature, including the general methodology of IT, the
construction of IT datasets, the training of IT models, and applications to
different modalities, domains and applications, along with an analysis on
aspects that influence the outcome of IT (e.g., generation of instruction
outputs, size of the instruction dataset, etc). We also review the potential
pitfalls of IT along with criticism against it, along with efforts pointing out
current deficiencies of existing strategies and suggest some avenues for
fruitful research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shengyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1&quot;&gt;Linfeng Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoya Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Sen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xiaofei Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shuhe Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1&quot;&gt;Runyi Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Guoyin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.03992">
<title>ConDA: Contrastive Domain Adaptation for AI-generated Text Detection. (arXiv:2309.03992v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.03992</link>
<description rdf:parseType="Literal">&lt;p&gt;Large language models (LLMs) are increasingly being used for generating text
in a variety of use cases, including journalistic news articles. Given the
potential malicious nature in which these LLMs can be used to generate
disinformation at scale, it is important to build effective detectors for such
AI-generated text. Given the surge in development of new LLMs, acquiring
labeled training data for supervised detectors is a bottleneck. However, there
might be plenty of unlabeled text data available, without information on which
generator it came from. In this work we tackle this data problem, in detecting
AI-generated news text, and frame the problem as an unsupervised domain
adaptation task. Here the domains are the different text generators, i.e. LLMs,
and we assume we have access to only the labeled source data and unlabeled
target data. We develop a Contrastive Domain Adaptation framework, called
ConDA, that blends standard domain adaptation techniques with the
representation power of contrastive learning to learn domain invariant
representations that are effective for the final unsupervised detection task.
Our experiments demonstrate the effectiveness of our framework, resulting in
average performance gains of 31.7% from the best performing baselines, and
within 0.8% margin of a fully supervised detector. All our code and data is
available at https://github.com/AmritaBh/ConDA-gen-text-detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharjee_A/0/1/0/all/0/1&quot;&gt;Amrita Bhattacharjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumarage_T/0/1/0/all/0/1&quot;&gt;Tharindu Kumarage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moraffah_R/0/1/0/all/0/1&quot;&gt;Raha Moraffah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Huan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.04474">
<title>Weakly supervised learning for pattern classification in serial femtosecond crystallography. (arXiv:2309.04474v2 [cond-mat.mtrl-sci] UPDATED)</title>
<link>http://arxiv.org/abs/2309.04474</link>
<description rdf:parseType="Literal">&lt;p&gt;Serial femtosecond crystallography at X-ray free electron laser facilities
opens a new era for the determination of crystal structure. However, the data
processing of those experiments is facing unprecedented challenge, because the
total number of diffraction patterns needed to determinate a high-resolution
structure is huge. Machine learning methods are very likely to play important
roles in dealing with such a large volume of data. Convolutional neural
networks have made a great success in the field of pattern classification,
however, training of the networks need very large datasets with labels. Th is
heavy dependence on labeled datasets will seriously restrict the application of
networks, because it is very costly to annotate a large number of diffraction
patterns. In this article we present our job on the classification of
diffraction pattern by weakly supervised algorithms, with the aim of reducing
as much as possible the size of the labeled dataset required for training. Our
result shows that weakly supervised methods can significantly reduce the need
for the number of labeled patterns while achieving comparable accuracy to fully
supervised methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Xie_J/0/1/0/all/0/1&quot;&gt;Jianan Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xihui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Huai_P/0/1/0/all/0/1&quot;&gt;Ping Huai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jie Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaofeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.08228">
<title>Ensuring Topological Data-Structure Preservation under Autoencoder Compression due to Latent Space Regularization in Gauss--Legendre nodes. (arXiv:2309.08228v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.08228</link>
<description rdf:parseType="Literal">&lt;p&gt;We formulate a data independent latent space regularisation constraint for
general unsupervised autoencoders. The regularisation rests on sampling the
autoencoder Jacobian in Legendre nodes, being the centre of the Gauss-Legendre
quadrature. Revisiting this classic enables to prove that regularised
autoencoders ensure a one-to-one re-embedding of the initial data manifold to
its latent representation. Demonstrations show that prior proposed
regularisation strategies, such as contractive autoencoding, cause topological
defects already for simple examples, and so do convolutional based
(variational) autoencoders. In contrast, topological preservation is ensured
already by standard multilayer perceptron neural networks when being
regularised due to our contribution. This observation extends through the
classic FashionMNIST dataset up to real world encoding problems for MRI brain
scans, suggesting that, across disciplines, reliable low dimensional
representations of complex high-dimensional datasets can be delivered due to
this regularisation technique.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramanaik_C/0/1/0/all/0/1&quot;&gt;Chethan Krishnamurthy Ramanaik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardona_J/0/1/0/all/0/1&quot;&gt;Juan-Esteban Suarez Cardona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Willmann_A/0/1/0/all/0/1&quot;&gt;Anna Willmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanfeld_P/0/1/0/all/0/1&quot;&gt;Pia Hanfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoffmann_N/0/1/0/all/0/1&quot;&gt;Nico Hoffmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hecht_M/0/1/0/all/0/1&quot;&gt;Michael Hecht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.08587">
<title>Compositional Foundation Models for Hierarchical Planning. (arXiv:2309.08587v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.08587</link>
<description rdf:parseType="Literal">&lt;p&gt;To make effective decisions in novel environments with long-horizon goals, it
is crucial to engage in hierarchical reasoning across spatial and temporal
scales. This entails planning abstract subgoal sequences, visually reasoning
about the underlying plans, and executing actions in accordance with the
devised plan through visual-motor control. We propose Compositional Foundation
Models for Hierarchical Planning (HiP), a foundation model which leverages
multiple expert foundation model trained on language, vision and action data
individually jointly together to solve long-horizon tasks. We use a large
language model to construct symbolic plans that are grounded in the environment
through a large video diffusion model. Generated video plans are then grounded
to visual-motor control, through an inverse dynamics model that infers actions
from generated videos. To enable effective reasoning within this hierarchy, we
enforce consistency between the models via iterative refinement. We illustrate
the efficacy and adaptability of our approach in three different long-horizon
table-top manipulation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ajay_A/0/1/0/all/0/1&quot;&gt;Anurag Ajay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Seungwook Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Yilun Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhi Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1&quot;&gt;Tommi Jaakkola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Josh Tenenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie Kaelbling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1&quot;&gt;Akash Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1&quot;&gt;Pulkit Agrawal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.08617">
<title>Drifter: Efficient Online Feature Monitoring for Improved Data Integrity in Large-Scale Recommendation Systems. (arXiv:2309.08617v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/2309.08617</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-world production systems often grapple with maintaining data quality in
large-scale, dynamic streams. We introduce Drifter, an efficient and
lightweight system for online feature monitoring and verification in
recommendation use cases. Drifter addresses limitations of existing methods by
delivering agile, responsive, and adaptable data quality monitoring, enabling
real-time root cause analysis, drift detection and insights into problematic
production events. Integrating state-of-the-art online feature ranking for
sparse data and anomaly detection ideas, Drifter is highly scalable and
resource-efficient, requiring only two threads and less than a gigabyte of RAM
per production deployments that handle millions of instances per minute.
Evaluation on real-world data sets demonstrates Drifter&apos;s effectiveness in
alerting and mitigating data quality issues, substantially improving
reliability and performance of real-time live recommender systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skrlj_B/0/1/0/all/0/1&quot;&gt;Bla&amp;#x17e; &amp;#x160;krlj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ki_Tov_N/0/1/0/all/0/1&quot;&gt;Nir Ki-Tov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edelist_L/0/1/0/all/0/1&quot;&gt;Lee Edelist&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silberstein_N/0/1/0/all/0/1&quot;&gt;Natalia Silberstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weisman_Zohar_H/0/1/0/all/0/1&quot;&gt;Hila Weisman-Zohar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mramor_B/0/1/0/all/0/1&quot;&gt;Bla&amp;#x17e; Mramor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kopic_D/0/1/0/all/0/1&quot;&gt;Davorin Kopi&amp;#x10d;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ziporin_N/0/1/0/all/0/1&quot;&gt;Naama Ziporin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.09517">
<title>FedGKD: Unleashing the Power of Collaboration in Federated Graph Neural Networks. (arXiv:2309.09517v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.09517</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated training of Graph Neural Networks (GNN) has become popular in
recent years due to its ability to perform graph-related tasks under data
isolation scenarios while preserving data privacy. However, graph heterogeneity
issues in federated GNN systems continue to pose challenges. Existing
frameworks address the problem by representing local tasks using different
statistics and relating them through a simple aggregation mechanism. However,
these approaches suffer from limited efficiency from two aspects: low quality
of task-relatedness quantification and inefficacy of exploiting the
collaboration structure. To address these issues, we propose FedGKD, a novel
federated GNN framework that utilizes a novel client-side graph dataset
distillation method to extract task features that better describe
task-relatedness, and introduces a novel server-side aggregation mechanism that
is aware of the global collaboration structure. We conduct extensive
experiments on six real-world datasets of different scales, demonstrating our
framework&apos;s outperformance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1&quot;&gt;Qiying Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1&quot;&gt;Ruofan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tengfei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yifei Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weiqiang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.10280">
<title>Crowdotic: A Privacy-Preserving Hospital Waiting Room Crowd Density Estimation with Non-speech Audio. (arXiv:2309.10280v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/2309.10280</link>
<description rdf:parseType="Literal">&lt;p&gt;Privacy-preserving crowd density analysis finds application across a wide
range of scenarios, substantially enhancing smart building operation and
management while upholding privacy expectations in various spaces. We propose a
non-speech audio-based approach for crowd analytics, leveraging a
transformer-based model. Our results demonstrate that non-speech audio alone
can be used to conduct such analysis with remarkable accuracy. To the best of
our knowledge, this is the first time when non-speech audio signals are
proposed for predicting occupancy. As far as we know, there has been no other
similar approach of its kind prior to this. To accomplish this, we deployed our
sensor-based platform in the waiting room of a large hospital with IRB approval
over a period of several months to capture non-speech audio and thermal images
for the training and evaluation of our models. The proposed non-speech-based
approach outperformed the thermal camera-based model and all other baselines.
In addition to demonstrating superior performance without utilizing speech
audio, we conduct further analysis using differential privacy techniques to
provide additional privacy guarantees. Overall, our work demonstrates the
viability of employing non-speech audio data for accurate occupancy estimation,
while also ensuring the exclusion of speech-related content and providing
robust privacy protections through differential privacy guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hossain_F/0/1/0/all/0/1&quot;&gt;Forsad Al Hossain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tonmoy_T/0/1/0/all/0/1&quot;&gt;Tanjid Hasan Tonmoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lover_A/0/1/0/all/0/1&quot;&gt;Andrew A. Lover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corey_G/0/1/0/all/0/1&quot;&gt;George A. Corey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1&quot;&gt;Mohammad Arif Ul Alam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1&quot;&gt;Tauhidur Rahman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.10505">
<title>Learning End-to-End Channel Coding with Diffusion Models. (arXiv:2309.10505v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/2309.10505</link>
<description rdf:parseType="Literal">&lt;p&gt;The training of neural encoders via deep learning necessitates a
differentiable channel model due to the backpropagation algorithm. This
requirement can be sidestepped by approximating either the channel distribution
or its gradient through pilot signals in real-world scenarios. The initial
approach draws upon the latest advancements in image generation, utilizing
generative adversarial networks (GANs) or their enhanced variants to generate
channel distributions. In this paper, we address this channel approximation
challenge with diffusion models, which have demonstrated high sample quality in
image generation. We offer an end-to-end channel coding framework underpinned
by diffusion models and propose an efficient training algorithm. Our
simulations with various channel models establish that our diffusion models
learn the channel distribution accurately, thereby achieving near-optimal
end-to-end symbol error rates (SERs). We also note a significant advantage of
diffusion models: A robust generalization capability in high signal-to-noise
ratio regions, in contrast to GAN variants that suffer from error floor.
Furthermore, we examine the trade-off between sample quality and sampling
speed, when an accelerated sampling algorithm is deployed, and investigate the
effect of the noise scheduling on this trade-off. With an apt choice of noise
scheduling, sampling time can be significantly reduced with a minor increase in
SER.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Muah Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fritschek_R/0/1/0/all/0/1&quot;&gt;Rick Fritschek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaefer_R/0/1/0/all/0/1&quot;&gt;Rafael F. Schaefer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.10688">
<title>On the different regimes of Stochastic Gradient Descent. (arXiv:2309.10688v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.10688</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern deep networks are trained with stochastic gradient descent (SGD) whose
key parameters are the number of data considered at each step or batch size
$B$, and the step size or learning rate $\eta$. For small $B$ and large $\eta$,
SGD corresponds to a stochastic evolution of the parameters, whose noise
amplitude is governed by the `temperature&apos; $T\equiv \eta/B$. Yet this
description is observed to break down for sufficiently large batches $B\geq
B^*$, or simplifies to gradient descent (GD) when the temperature is
sufficiently small. Understanding where these cross-overs take place remains a
central challenge. Here we resolve these questions for a teacher-student
perceptron classification model, and show empirically that our key predictions
still apply to deep networks. Specifically, we obtain a phase diagram in the
$B$-$\eta$ plane that separates three dynamical phases: $\textit{(i)}$ a
noise-dominated SGD governed by temperature, $\textit{(ii)}$ a
large-first-step-dominated SGD and $\textit{(iii)}$ GD. These different phases
also corresponds to different regimes of generalization error. Remarkably, our
analysis reveals that the batch size $B^*$ separating regimes $\textit{(i)}$
and $\textit{(ii)}$ scale with the size $P$ of the training set, with an
exponent that characterizes the hardness of the classification problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sclocchi_A/0/1/0/all/0/1&quot;&gt;Antonio Sclocchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1&quot;&gt;Matthieu Wyart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.10916">
<title>What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples. (arXiv:2309.10916v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.10916</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples, deliberately crafted using small perturbations to fool
deep neural networks, were first studied in image processing and more recently
in NLP. While approaches to detecting adversarial examples in NLP have largely
relied on search over input perturbations, image processing has seen a range of
techniques that aim to characterise adversarial subspaces over the learned
representations.
&lt;/p&gt;
&lt;p&gt;In this paper, we adapt two such approaches to NLP, one based on nearest
neighbors and influence functions and one on Mahalanobis distances. The former
in particular produces a state-of-the-art detector when compared against
several strong baselines; moreover, the novel use of influence functions
provides insight into how the nature of adversarial example subspaces in NLP
relate to those in image processing, and also how they differ depending on the
kind of NLP task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tonni_S/0/1/0/all/0/1&quot;&gt;Shakila Mahjabin Tonni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dras_M/0/1/0/all/0/1&quot;&gt;Mark Dras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11052">
<title>fakenewsbr: A Fake News Detection Platform for Brazilian Portuguese. (arXiv:2309.11052v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/2309.11052</link>
<description rdf:parseType="Literal">&lt;p&gt;The proliferation of fake news has become a significant concern in recent
times due to its potential to spread misinformation and manipulate public
opinion. This paper presents a comprehensive study on detecting fake news in
Brazilian Portuguese, focusing on journalistic-type news. We propose a machine
learning-based approach that leverages natural language processing techniques,
including TF-IDF and Word2Vec, to extract features from textual data. We
evaluate the performance of various classification algorithms, such as logistic
regression, support vector machine, random forest, AdaBoost, and LightGBM, on a
dataset containing both true and fake news articles. The proposed approach
achieves high accuracy and F1-Score, demonstrating its effectiveness in
identifying fake news. Additionally, we developed a user-friendly web platform,
fakenewsbr.com, to facilitate the verification of news articles&apos; veracity. Our
platform provides real-time analysis, allowing users to assess the likelihood
of fake news articles. Through empirical analysis and comparative studies, we
demonstrate the potential of our approach to contribute to the fight against
the spread of fake news and promote more informed media consumption.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giordani_L/0/1/0/all/0/1&quot;&gt;Luiz Giordani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daru_G/0/1/0/all/0/1&quot;&gt;Gilsiley Dar&amp;#xfa;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Queiroz_R/0/1/0/all/0/1&quot;&gt;Rhenan Queiroz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buzinaro_V/0/1/0/all/0/1&quot;&gt;Vitor Buzinaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neiva_D/0/1/0/all/0/1&quot;&gt;Davi Keglevich Neiva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzman_D/0/1/0/all/0/1&quot;&gt;Daniel Camilo Fuentes Guzm&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henriques_M/0/1/0/all/0/1&quot;&gt;Marcos Jardel Henriques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Junior_O/0/1/0/all/0/1&quot;&gt;Oilson Alberto Gonzatto Junior&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Louzada_F/0/1/0/all/0/1&quot;&gt;Francisco Louzada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11354">
<title>Self-supervised learning unveils change in urban housing from street-level images. (arXiv:2309.11354v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/2309.11354</link>
<description rdf:parseType="Literal">&lt;p&gt;Cities around the world face a critical shortage of affordable and decent
housing. Despite its critical importance for policy, our ability to effectively
monitor and track progress in urban housing is limited. Deep learning-based
computer vision methods applied to street-level images have been successful in
the measurement of socioeconomic and environmental inequalities but did not
fully utilize temporal images to track urban change as time-varying labels are
often unavailable. We used self-supervised methods to measure change in London
using 15 million street images taken between 2008 and 2021. Our novel
adaptation of Barlow Twins, Street2Vec, embeds urban structure while being
invariant to seasonal and daily changes without manual annotations. It
outperformed generic embeddings, successfully identified point-level change in
London&apos;s housing supply from street-level images, and distinguished between
major and minor change. This capability can provide timely information for
urban planning and policy decisions toward more liveable, equitable, and
sustainable cities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stalder_S/0/1/0/all/0/1&quot;&gt;Steven Stalder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volpi_M/0/1/0/all/0/1&quot;&gt;Michele Volpi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buttner_N/0/1/0/all/0/1&quot;&gt;Nicolas B&amp;#xfc;ttner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Law_S/0/1/0/all/0/1&quot;&gt;Stephen Law&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harttgen_K/0/1/0/all/0/1&quot;&gt;Kenneth Harttgen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suel_E/0/1/0/all/0/1&quot;&gt;Esra Suel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11489">
<title>Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning. (arXiv:2309.11489v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/2309.11489</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing reward functions is a longstanding challenge in reinforcement
learning (RL); it requires specialized knowledge or domain data, leading to
high costs for development. To address this, we introduce Text2Reward, a
data-free framework that automates the generation of dense reward functions
based on large language models (LLMs). Given a goal described in natural
language, Text2Reward generates dense reward functions as an executable program
grounded in a compact representation of the environment. Unlike inverse RL and
recent work that uses LLMs to write sparse reward codes, Text2Reward produces
interpretable, free-form dense reward codes that cover a wide range of tasks,
utilize existing packages, and allow iterative refinement with human feedback.
We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2,
MetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17
manipulation tasks, policies trained with generated reward codes achieve
similar or better task success rates and convergence speed than expert-written
reward codes. For locomotion tasks, our method learns six novel locomotion
behaviors with a success rate exceeding 94%. Furthermore, we show that the
policies trained in the simulator with our method can be deployed in the real
world. Finally, Text2Reward further improves the policies by refining their
reward functions with human feedback. Video results are available at
https://text-to-reward.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1&quot;&gt;Tianbao Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Siheng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chen Henry Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yitao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Q/0/1/0/all/0/1&quot;&gt;Qian Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1&quot;&gt;Victor Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yanchao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1&quot;&gt;Tao Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2304.00216">
<title>Cross-scale Multi-instance Learning for Pathological Image Diagnosis. (arXiv:2304.00216v2 [eess.IV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2304.00216</link>
<description rdf:parseType="Literal">&lt;p&gt;Analyzing high resolution whole slide images (WSIs) with regard to
information across multiple scales poses a significant challenge in digital
pathology. Multi-instance learning (MIL) is a common solution for working with
high resolution images by classifying bags of objects (i.e. sets of smaller
image patches). However, such processing is typically performed at a single
scale (e.g., 20x magnification) of WSIs, disregarding the vital inter-scale
information that is key to diagnoses by human pathologists. In this study, we
propose a novel cross-scale MIL algorithm to explicitly aggregate inter-scale
relationships into a single MIL network for pathological image diagnosis. The
contribution of this paper is three-fold: (1) A novel cross-scale MIL (CS-MIL)
algorithm that integrates the multi-scale information and the inter-scale
relationships is proposed; (2) A toy dataset with scale-specific morphological
features is created and released to examine and visualize differential
cross-scale attention; (3) Superior performance on both in-house and public
datasets is demonstrated by our simple cross-scale MIL strategy. The official
implementation is publicly available at https://github.com/hrlblab/CS-MIL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Deng_R/0/1/0/all/0/1&quot;&gt;Ruining Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cui_C/0/1/0/all/0/1&quot;&gt;Can Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Remedios_L/0/1/0/all/0/1&quot;&gt;Lucas W. Remedios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bao_S/0/1/0/all/0/1&quot;&gt;Shunxing Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Womick_R/0/1/0/all/0/1&quot;&gt;R. Michael Womick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chiron_S/0/1/0/all/0/1&quot;&gt;Sophie Chiron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Roland_J/0/1/0/all/0/1&quot;&gt;Joseph T. Roland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lau_K/0/1/0/all/0/1&quot;&gt;Ken S. Lau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wilson_K/0/1/0/all/0/1&quot;&gt;Keith T. Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yaohong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Coburn_L/0/1/0/all/0/1&quot;&gt;Lori A. Coburn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Landman_B/0/1/0/all/0/1&quot;&gt;Bennett A. Landman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huo_Y/0/1/0/all/0/1&quot;&gt;Yuankai Huo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/2309.11132">
<title>Contrastive Pseudo Learning for Open-World DeepFake Attribution. (arXiv:2309.11132v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/2309.11132</link>
<description rdf:parseType="Literal">&lt;p&gt;The challenge in sourcing attribution for forgery faces has gained widespread
attention due to the rapid development of generative techniques. While many
recent works have taken essential steps on GAN-generated faces, more
threatening attacks related to identity swapping or expression transferring are
still overlooked. And the forgery traces hidden in unknown attacks from the
open-world unlabeled faces still remain under-explored. To push the related
frontier research, we introduce a new benchmark called Open-World DeepFake
Attribution (OW-DFA), which aims to evaluate attribution performance against
various types of fake faces under open-world scenarios. Meanwhile, we propose a
novel framework named Contrastive Pseudo Learning (CPL) for the OW-DFA task
through 1) introducing a Global-Local Voting module to guide the feature
alignment of forged faces with different manipulated regions, 2) designing a
Confidence-based Soft Pseudo-label strategy to mitigate the pseudo-noise caused
by similar methods in unlabeled set. In addition, we extend the CPL framework
with a multi-stage paradigm that leverages pre-train technique and iterative
learning to further enhance traceability performance. Extensive experiments
verify the superiority of our proposed method on the OW-DFA and also
demonstrate the interpretability of deepfake attribution task and its impact on
improving the security of deepfake detection area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zhimin Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1&quot;&gt;Taiping Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1&quot;&gt;Bangjie Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_R/0/1/0/all/0/1&quot;&gt;Ran Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1&quot;&gt;Shouhong Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lizhuang Ma&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>