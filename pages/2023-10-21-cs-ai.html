<!DOCTYPE html>
<html>
<head>
<title>2023-10-21-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2310.12162">AI Potentiality and Awareness: A Position Paper from the Perspective of Human-AI Teaming in Cybersecurity. (arXiv:2310.12162v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sarker_I/0/1/0/all/0/1">Iqbal H. Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Janicke_H/0/1/0/all/0/1">Helge Janicke</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammad_N/0/1/0/all/0/1">Nazeeruddin Mohammad</a>, <a href="http://arxiv.org/find/cs/1/au:+Watters_P/0/1/0/all/0/1">Paul Watters</a>, <a href="http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1">Surya Nepal</a></p>
<p>This position paper explores the broad landscape of AI potentiality in the
context of cybersecurity, with a particular emphasis on its possible risk
factors with awareness, which can be managed by incorporating human experts in
the loop, i.e., "Human-AI" teaming. As artificial intelligence (AI)
technologies advance, they will provide unparalleled opportunities for attack
identification, incident response, and recovery. However, the successful
deployment of AI into cybersecurity measures necessitates an in-depth
understanding of its capabilities, challenges, and ethical and legal
implications to handle associated risk factors in real-world application areas.
Towards this, we emphasize the importance of a balanced approach that
incorporates AI's computational power with human expertise. AI systems may
proactively discover vulnerabilities and detect anomalies through pattern
recognition, and predictive modeling, significantly enhancing speed and
accuracy. Human experts can explain AI-generated decisions to stakeholders,
regulators, and end-users in critical situations, ensuring responsibility and
accountability, which helps establish trust in AI-driven security solutions.
Therefore, in this position paper, we argue that human-AI teaming is worthwhile
in cybersecurity, in which human expertise such as intuition, critical
thinking, or contextual understanding is combined with AI's computational power
to improve overall cyber defenses.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12168">RK-core: An Established Methodology for Exploring the Hierarchical Structure within Datasets. (arXiv:2310.12168v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yutian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1">Jiaqi Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zuohui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xuan_Q/0/1/0/all/0/1">Qi Xuan</a></p>
<p>Recently, the field of machine learning has undergone a transition from
model-centric to data-centric. The advancements in diverse learning tasks have
been propelled by the accumulation of more extensive datasets, subsequently
facilitating the training of larger models on these datasets. However, these
datasets remain relatively under-explored. To this end, we introduce a
pioneering approach known as RK-core, to empower gaining a deeper understanding
of the intricate hierarchical structure within datasets. Across several
benchmark datasets, we find that samples with low coreness values appear less
representative of their respective categories, and conversely, those with high
coreness values exhibit greater representativeness. Correspondingly, samples
with high coreness values make a more substantial contribution to the
performance in comparison to those with low coreness values. Building upon
this, we further employ RK-core to analyze the hierarchical structure of
samples with different coreset selection methods. Remarkably, we find that a
high-quality coreset should exhibit hierarchical diversity instead of solely
opting for representative samples. The code is available at
https://github.com/yaolu-zjut/Kcore.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12183">An Optimistic-Robust Approach for Dynamic Positioning of Omnichannel Inventories. (arXiv:2310.12183v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Harsha_P/0/1/0/all/0/1">Pavithra Harsha</a>, <a href="http://arxiv.org/find/math/1/au:+Subramanian_S/0/1/0/all/0/1">Shivaram Subramanian</a>, <a href="http://arxiv.org/find/math/1/au:+Koc_A/0/1/0/all/0/1">Ali Koc</a>, <a href="http://arxiv.org/find/math/1/au:+Ramakrishna_M/0/1/0/all/0/1">Mahesh Ramakrishna</a>, <a href="http://arxiv.org/find/math/1/au:+Quanz_B/0/1/0/all/0/1">Brian Quanz</a>, <a href="http://arxiv.org/find/math/1/au:+Shah_D/0/1/0/all/0/1">Dhruv Shah</a>, <a href="http://arxiv.org/find/math/1/au:+Narayanaswami_C/0/1/0/all/0/1">Chandra Narayanaswami</a></p>
<p>We introduce a new class of data-driven and distribution-free
optimistic-robust bimodal inventory optimization (BIO) strategy to effectively
allocate inventory across a retail chain to meet time-varying, uncertain
omnichannel demand. While prior Robust optimization (RO) methods emphasize the
downside, i.e., worst-case adversarial demand, BIO also considers the upside to
remain resilient like RO while also reaping the rewards of improved
average-case performance by overcoming the presence of endogenous outliers.
This bimodal strategy is particularly valuable for balancing the tradeoff
between lost sales at the store and the costs of cross-channel e-commerce
fulfillment, which is at the core of our inventory optimization model. These
factors are asymmetric due to the heterogenous behavior of the channels, with a
bias towards the former in terms of lost-sales cost and a dependence on network
effects for the latter. We provide structural insights about the BIO solution
and how it can be tuned to achieve a preferred tradeoff between robustness and
the average-case. Our experiments show that significant benefits can be
achieved by rethinking traditional approaches to inventory management, which
are siloed by channel and location. Using a real-world dataset from a large
American omnichannel retail chain, a business value assessment during a peak
period indicates over a 15% profitability gain for BIO over RO and other
baselines while also preserving the (practical) worst case performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12184">Architectural Implications of GNN Aggregation Programming Abstractions. (arXiv:2310.12184v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yingjie Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianlei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1">Ao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_T/0/1/0/all/0/1">Tong Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1">Chunming Hu</a></p>
<p>Graph neural networks (GNNs) have gained significant popularity due to the
powerful capability to extract useful representations from graph data. As the
need for efficient GNN computation intensifies, a variety of programming
abstractions designed for optimizing GNN Aggregation have emerged to facilitate
acceleration. However, there is no comprehensive evaluation and analysis upon
existing abstractions, thus no clear consensus on which approach is better. In
this letter, we classify existing programming abstractions for GNN Aggregation
by the dimension of data organization and propagation method. By constructing
these abstractions on a state-of-the-art GNN library, we perform a thorough and
detailed characterization study to compare their performance and efficiency,
and provide several insights on future GNN acceleration based on our analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12186">Stranger Danger! Cross-Community Interactions with Fringe Users Increase the Growth of Fringe Communities on Reddit. (arXiv:2310.12186v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Russo_G/0/1/0/all/0/1">Giuseppe Russo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1">Manoel Horta Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1">Robert West</a></p>
<p>Fringe communities promoting conspiracy theories and extremist ideologies
have thrived on mainstream platforms, raising questions about the mechanisms
driving their growth. Here, we hypothesize and study a possible mechanism: new
members may be recruited through fringe-interactions: the exchange of comments
between members and non-members of fringe communities. We apply text-based
causal inference techniques to study the impact of fringe-interactions on the
growth of three prominent fringe communities on Reddit: r/Incel,
r/GenderCritical, and r/The_Donald. Our results indicate that
fringe-interactions attract new members to fringe communities. Users who
receive these interactions are up to 4.2 percentage points (pp) more likely to
join fringe communities than similar, matched users who do not.
</p>
<p>This effect is influenced by 1) the characteristics of communities where the
interaction happens (e.g., left vs. right-leaning communities) and 2) the
language used in the interactions. Interactions using toxic language have a 5pp
higher chance of attracting newcomers to fringe communities than non-toxic
interactions. We find no effect when repeating this analysis by replacing
fringe (r/Incel, r/GenderCritical, and r/The_Donald) with non-fringe
communities (r/climatechange, r/NBA, r/leagueoflegends), suggesting this growth
mechanism is specific to fringe communities. Overall, our findings suggest that
curtailing fringe-interactions may reduce the growth of fringe communities on
mainstream platforms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12234">An Eager Satisfiability Modulo Theories Solver for Algebraic Datatypes. (arXiv:2310.12234v1 [cs.LO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1">Amar Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Mora_F/0/1/0/all/0/1">Federico Mora</a>, <a href="http://arxiv.org/find/cs/1/au:+Seshia_S/0/1/0/all/0/1">Sanjit A. Seshia</a></p>
<p>Algebraic data types (ADTs) are a construct classically found in functional
programming languages that capture data structures like enumerated types,
lists, and trees. In recent years, interest in ADTs has increased. For example,
popular programming languages, like Python, have added support for ADTs.
Automated reasoning about ADTs can be done using satisfiability modulo theories
(SMT) solving, an extension of the Boolean satisfiability problem with
constraints over first-order structures. Unfortunately, SMT solvers that
support ADTs do not scale as state-of-the-art approaches all use variations of
the same \emph{lazy} approach. In this paper, we present an SMT solver that
takes a fundamentally different approach, an \emph{eager} approach.
Specifically, our solver reduces ADT queries to a simpler logical theory,
uninterpreted functions (UF), and then uses an existing solver on the reduced
query. We prove the soundness and completeness of our approach and demonstrate
that it outperforms the state-of-theart on existing benchmarks, as well as a
new, more challenging benchmark set from the planning domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12238">Few-Shot In-Context Imitation Learning via Implicit Graph Alignment. (arXiv:2310.12238v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vosylius_V/0/1/0/all/0/1">Vitalis Vosylius</a>, <a href="http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1">Edward Johns</a></p>
<p>Consider the following problem: given a few demonstrations of a task across a
few different objects, how can a robot learn to perform that same task on new,
previously unseen objects? This is challenging because the large variety of
objects within a class makes it difficult to infer the task-relevant
relationship between the new objects and the objects in the demonstrations. We
address this by formulating imitation learning as a conditional alignment
problem between graph representations of objects. Consequently, we show that
this conditioning allows for in-context learning, where a robot can perform a
task on a set of new objects immediately after the demonstrations, without any
prior knowledge about the object class or any further training. In our
experiments, we explore and validate our design choices, and we show that our
method is highly effective for few-shot learning of several real-world,
everyday tasks, whilst outperforming baselines. Videos are available on our
project webpage at https://www.robot-learning.uk/implicit-graph-alignment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12244">A Unified Approach to Domain Incremental Learning with Memory: Theory and Algorithm. (arXiv:2310.12244v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Haizhou Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a></p>
<p>Domain incremental learning aims to adapt to a sequence of domains with
access to only a small subset of data (i.e., memory) from previous domains.
Various methods have been proposed for this problem, but it is still unclear
how they are related and when practitioners should choose one method over
another. In response, we propose a unified framework, dubbed Unified Domain
Incremental Learning (UDIL), for domain incremental learning with memory. Our
UDIL **unifies** various existing methods, and our theoretical analysis shows
that UDIL always achieves a tighter generalization error bound compared to
these methods. The key insight is that different existing methods correspond to
our bound with different **fixed** coefficients; based on insights from this
unification, our UDIL allows **adaptive** coefficients during training, thereby
always achieving the tightest bound. Empirical results show that our UDIL
outperforms the state-of-the-art domain incremental learning methods on both
synthetic and real-world datasets. Code will be available at
https://github.com/Wang-ML-Lab/unified-continual-learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12274">An Image is Worth Multiple Words: Learning Object Level Concepts using Multi-Concept Prompt Learning. (arXiv:2310.12274v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Chen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanno_R/0/1/0/all/0/1">Ryutaro Tanno</a>, <a href="http://arxiv.org/find/cs/1/au:+Saseendran_A/0/1/0/all/0/1">Amrutha Saseendran</a>, <a href="http://arxiv.org/find/cs/1/au:+Diethe_T/0/1/0/all/0/1">Tom Diethe</a>, <a href="http://arxiv.org/find/cs/1/au:+Teare_P/0/1/0/all/0/1">Philip Teare</a></p>
<p>Textural Inversion, a prompt learning method, learns a singular embedding for
a new "word" to represent image style and appearance, allowing it to be
integrated into natural language sentences to generate novel synthesised
images. However, identifying and integrating multiple object-level concepts
within one scene poses significant challenges even when embeddings for
individual concepts are attainable. This is further confirmed by our empirical
tests. To address this challenge, we introduce a framework for Multi-Concept
Prompt Learning (MCPL), where multiple new "words" are simultaneously learned
from a single sentence-image pair. To enhance the accuracy of word-concept
correlation, we propose three regularisation techniques: Attention Masking
(AttnMask) to concentrate learning on relevant areas; Prompts Contrastive Loss
(PromptCL) to separate the embeddings of different concepts; and Bind adjective
(Bind adj.) to associate new "words" with known words. We evaluate via image
generation, editing, and attention visualisation with diverse images. Extensive
quantitative comparisons demonstrate that our method can learn more
semantically disentangled concepts with enhanced word-concept correlation.
Additionally, we introduce a novel dataset and evaluation protocol tailored for
this new task of learning object-level concepts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12281">Enhancing the Performance of Automated Grade Prediction in MOOC using Graph Representation Learning. (arXiv:2310.12281v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Farokhi_S/0/1/0/all/0/1">Soheila Farokhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yaramala_A/0/1/0/all/0/1">Aswani Yaramala</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiangtao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Muhammad F. A. Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xiaojun Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Karimi_H/0/1/0/all/0/1">Hamid Karimi</a></p>
<p>In recent years, Massive Open Online Courses (MOOCs) have gained significant
traction as a rapidly growing phenomenon in online learning. Unlike traditional
classrooms, MOOCs offer a unique opportunity to cater to a diverse audience
from different backgrounds and geographical locations. Renowned universities
and MOOC-specific providers, such as Coursera, offer MOOC courses on various
subjects. Automated assessment tasks like grade and early dropout predictions
are necessary due to the high enrollment and limited direct interaction between
teachers and learners. However, current automated assessment approaches
overlook the structural links between different entities involved in the
downstream tasks, such as the students and courses. Our hypothesis suggests
that these structural relationships, manifested through an interaction graph,
contain valuable information that can enhance the performance of the task at
hand. To validate this, we construct a unique knowledge graph for a large MOOC
dataset, which will be publicly available to the research community.
Furthermore, we utilize graph embedding techniques to extract latent structural
information encoded in the interactions between entities in the dataset. These
techniques do not require ground truth labels and can be utilized for various
tasks. Finally, by combining entity-specific features, behavioral features, and
extracted structural features, we enhance the performance of predictive machine
learning models in student assignment grade prediction. Our experiments
demonstrate that structural features can significantly improve the predictive
performance of downstream assessment tasks. The code and data are available in
\url{https://github.com/DSAatUSU/MOOPer_grade_prediction}
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12290">Fact-based Agent modeling for Multi-Agent Reinforcement Learning. (arXiv:2310.12290v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fang_B/0/1/0/all/0/1">Baofu Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Caiming Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a></p>
<p>In multi-agent systems, agents need to interact and collaborate with other
agents in environments. Agent modeling is crucial to facilitate agent
interactions and make adaptive cooperation strategies. However, it is
challenging for agents to model the beliefs, behaviors, and intentions of other
agents in non-stationary environment where all agent policies are learned
simultaneously. In addition, the existing methods realize agent modeling
through behavior cloning which assume that the local information of other
agents can be accessed during execution or training. However, this assumption
is infeasible in unknown scenarios characterized by unknown agents, such as
competition teams, unreliable communication and federated learning due to
privacy concerns. To eliminate this assumption and achieve agent modeling in
unknown scenarios, Fact-based Agent modeling (FAM) method is proposed in which
fact-based belief inference (FBI) network models other agents in partially
observable environment only based on its local information. The reward and
observation obtained by agents after taking actions are called facts, and FAM
uses facts as reconstruction target to learn the policy representation of other
agents through a variational autoencoder. We evaluate FAM on various Multiagent
Particle Environment (MPE) and compare the results with several
state-of-the-art MARL algorithms. Experimental results show that compared with
baseline methods, FAM can effectively improve the efficiency of agent policy
learning by making adaptive cooperation strategies in multi-agent reinforcement
learning tasks, while achieving higher returns in complex
competitive-cooperative mixed scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12298">Jorge: Approximate Preconditioning for GPU-efficient Second-order Optimization. (arXiv:2310.12298v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Siddharth Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sating_Z/0/1/0/all/0/1">Zachary Sating</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatele_A/0/1/0/all/0/1">Abhinav Bhatele</a></p>
<p>Despite their better convergence properties compared to first-order
optimizers, second-order optimizers for deep learning have been less popular
due to their significant computational costs. The primary efficiency bottleneck
in such optimizers is matrix inverse calculations in the preconditioning step,
which are expensive to compute on GPUs. In this paper, we introduce Jorge, a
second-order optimizer that promises the best of both worlds -- rapid
convergence benefits of second-order methods, and high computational efficiency
typical of first-order methods. We address the primary computational bottleneck
of computing matrix inverses by completely eliminating them using an
approximation of the preconditioner computation. This makes Jorge extremely
efficient on GPUs in terms of wall-clock time. Further, we describe an approach
to determine Jorge's hyperparameters directly from a well-tuned SGD baseline,
thereby significantly minimizing tuning efforts. Our empirical evaluations
demonstrate the distinct advantages of using Jorge, outperforming
state-of-the-art optimizers such as SGD, AdamW, and Shampoo across multiple
deep learning models, both in terms of sample efficiency and wall-clock time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12303">Document-Level Language Models for Machine Translation. (arXiv:2310.12303v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Petrick_F/0/1/0/all/0/1">Frithjof Petrick</a>, <a href="http://arxiv.org/find/cs/1/au:+Herold_C/0/1/0/all/0/1">Christian Herold</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrushkov_P/0/1/0/all/0/1">Pavel Petrushkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Khadivi_S/0/1/0/all/0/1">Shahram Khadivi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a></p>
<p>Despite the known limitations, most machine translation systems today still
operate on the sentence-level. One reason for this is, that most parallel
training data is only sentence-level aligned, without document-level meta
information available. In this work, we set out to build context-aware
translation systems utilizing document-level monolingual data instead. This can
be achieved by combining any existing sentence-level translation model with a
document-level language model. We improve existing approaches by leveraging
recent advancements in model combination. Additionally, we propose novel
weighting techniques that make the system combination more flexible and
significantly reduce computational overhead. In a comprehensive evaluation on
four diverse translation tasks, we show that our extensions improve
document-targeted scores substantially and are also computationally more
efficient. However, we also find that in most scenarios, back-translation gives
even better results, at the cost of having to re-train the translation system.
Finally, we explore language model fusion in the light of recent advancements
in large language models. Our findings suggest that there might be strong
potential in utilizing large language models via model combination.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12304">Preference Optimization for Molecular Language Models. (arXiv:2310.12304v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Park_R/0/1/0/all/0/1">Ryan Park</a>, <a href="http://arxiv.org/find/stat/1/au:+Theisen_R/0/1/0/all/0/1">Ryan Theisen</a>, <a href="http://arxiv.org/find/stat/1/au:+Sahni_N/0/1/0/all/0/1">Navriti Sahni</a>, <a href="http://arxiv.org/find/stat/1/au:+Patek_M/0/1/0/all/0/1">Marcel Patek</a>, <a href="http://arxiv.org/find/stat/1/au:+Cichonska_A/0/1/0/all/0/1">Anna Cicho&#x144;ska</a>, <a href="http://arxiv.org/find/stat/1/au:+Rahman_R/0/1/0/all/0/1">Rayees Rahman</a></p>
<p>Molecular language modeling is an effective approach to generating novel
chemical structures. However, these models do not \emph{a priori} encode
certain preferences a chemist may desire. We investigate the use of fine-tuning
using Direct Preference Optimization to better align generated molecules with
chemist preferences. Our findings suggest that this approach is simple,
efficient, and highly effective.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12309">A Unifying Framework for Learning Argumentation Semantics. (arXiv:2310.12309v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mileva_Z/0/1/0/all/0/1">Zlatina Mileva</a>, <a href="http://arxiv.org/find/cs/1/au:+Bikakis_A/0/1/0/all/0/1">Antonis Bikakis</a>, <a href="http://arxiv.org/find/cs/1/au:+DAsaro_F/0/1/0/all/0/1">Fabio Aurelio D&#x27;Asaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1">Mark Law</a>, <a href="http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1">Alessandra Russo</a></p>
<p>Argumentation is a very active research field of Artificial Intelligence
concerned with the representation and evaluation of arguments used in dialogues
between humans and/or artificial agents. Acceptability semantics of formal
argumentation systems define the criteria for the acceptance or rejection of
arguments. Several software systems, known as argumentation solvers, have been
developed to compute the accepted/rejected arguments using such criteria. These
include systems that learn to identify the accepted arguments using
non-interpretable methods. In this paper we present a novel framework, which
uses an Inductive Logic Programming approach to learn the acceptability
semantics for several abstract and structured argumentation frameworks in an
interpretable way. Through an empirical evaluation we show that our framework
outperforms existing argumentation solvers, thus opening up new future research
directions in the area of formal argumentation and human-machine dialogues.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12318">The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis. (arXiv:2310.12318v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Venkit_P/0/1/0/all/0/1">Pranav Narayanan Venkit</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinath_M/0/1/0/all/0/1">Mukund Srinath</a>, <a href="http://arxiv.org/find/cs/1/au:+Gautam_S/0/1/0/all/0/1">Sanjana Gautam</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkatraman_S/0/1/0/all/0/1">Saranya Venkatraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1">Vipul Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Passonneau_R/0/1/0/all/0/1">Rebecca J. Passonneau</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_S/0/1/0/all/0/1">Shomir Wilson</a></p>
<p>We conduct an inquiry into the sociotechnical aspects of sentiment analysis
(SA) by critically examining 189 peer-reviewed papers on their applications,
models, and datasets. Our investigation stems from the recognition that SA has
become an integral component of diverse sociotechnical systems, exerting
influence on both social and technical users. By delving into sociological and
technological literature on sentiment, we unveil distinct conceptualizations of
this term in domains such as finance, government, and medicine. Our study
exposes a lack of explicit definitions and frameworks for characterizing
sentiment, resulting in potential challenges and biases. To tackle this issue,
we propose an ethics sheet encompassing critical inquiries to guide
practitioners in ensuring equitable utilization of SA. Our findings underscore
the significance of adopting an interdisciplinary approach to defining
sentiment in SA and offer a pragmatic solution for its implementation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12324">Opportunities for Adaptive Experiments to Enable Continuous Improvement that Trades-off Instructor and Researcher Incentives. (arXiv:2310.12324v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Musabirov_I/0/1/0/all/0/1">Ilya Musabirov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zavaleta_Bernuy_A/0/1/0/all/0/1">Angela Zavaleta-Bernuy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liut_M/0/1/0/all/0/1">Michael Liut</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1">Joseph Jay Williams</a></p>
<p>Randomized experimental comparisons of alternative pedagogical strategies
could provide useful empirical evidence in instructors' decision-making.
However, traditional experiments do not have a clear and simple pathway to
using data rapidly to try to increase the chances that students in an
experiment get the best conditions. Drawing inspiration from the use of machine
learning and experimentation in product development at leading technology
companies, we explore how adaptive experimentation might help in continuous
course improvement. In adaptive experiments, as different arms/conditions are
deployed to students, data is analyzed and used to change the experience for
future students. This can be done using machine learning algorithms to identify
which actions are more promising for improving student experience or outcomes.
This algorithm can then dynamically deploy the most effective conditions to
future students, resulting in better support for students' needs. We illustrate
the approach with a case study providing a side-by-side comparison of
traditional and adaptive experimentation of self-explanation prompts in online
homework problems in a CS1 course. This provides a first step in exploring the
future of how this methodology can be useful in bridging research and practice
in doing continuous improvement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12342">Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs&#x27; Non-linear Thinking. (arXiv:2310.12342v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1">Yongqi Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dawei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sizhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Simeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1">Jingbo Shang</a></p>
<p>Chain-of-Thought(CoT) prompting and its variants explore equipping large
language models (LLMs) with high-level reasoning abilities by emulating
human-like linear cognition and logic. However, the human mind is complicated
and mixed with both linear and nonlinear thinking. In this work, we propose
\textbf{I}nferential \textbf{E}xclusion \textbf{P}rompting (IEP), a novel
prompting that combines the principles of elimination and inference in order to
guide LLMs to think non-linearly. IEP guides LLMs to plan and then utilize
Natural Language Inference (NLI) to deduce each possible solution's entailment
relation with context, commonsense, or facts, therefore yielding a broader
perspective by thinking back for inferring. This forward planning and backward
eliminating process allows IEP to better simulate the complex human thinking
processes compared to other CoT-based methods, which only reflect linear
cognitive processes. We conducted a series of empirical studies and have
corroborated that IEP consistently outperforms CoT across various tasks.
Additionally, we observe that integrating IEP and CoT further improves the
LLMs' performance on certain tasks, highlighting the necessity of equipping
LLMs with mixed logic processes. Moreover, to better evaluate comprehensive
features inherent in human logic, we introduce \textbf{M}ental-\textbf{A}bility
\textbf{R}easoning \textbf{B}enchmark (MARB). The benchmark comprises six novel
subtasks with a total of 9,115 questions, among which 1,685 are developed with
hand-crafted rationale references. We believe both \textsc{IEP} and
\textsc{MARB} can serve as a promising direction for unveiling LLMs' logic and
verbal reasoning abilities and drive further advancements. \textsc{MARB} will
be available at ~\texttt{anonymity link} soon.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12345">ClusT3: Information Invariant Test-Time Training. (arXiv:2310.12345v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hakim_G/0/1/0/all/0/1">Gustavo A. Vargas Hakim</a>, <a href="http://arxiv.org/find/cs/1/au:+Osowiechi_D/0/1/0/all/0/1">David Osowiechi</a>, <a href="http://arxiv.org/find/cs/1/au:+Noori_M/0/1/0/all/0/1">Mehrdad Noori</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheraghalikhani_M/0/1/0/all/0/1">Milad Cheraghalikhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ismail Ben Ayed</a>, <a href="http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1">Christian Desrosiers</a></p>
<p>Deep Learning models have shown remarkable performance in a broad range of
vision tasks. However, they are often vulnerable against domain shifts at
test-time. Test-time training (TTT) methods have been developed in an attempt
to mitigate these vulnerabilities, where a secondary task is solved at training
time simultaneously with the main task, to be later used as an self-supervised
proxy task at test-time. In this work, we propose a novel unsupervised TTT
technique based on the maximization of Mutual Information between multi-scale
feature maps and a discrete latent representation, which can be integrated to
the standard training as an auxiliary clustering task. Experimental results
demonstrate competitive classification performance on different popular
test-time adaptation benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12379">Solving Hard Analogy Questions with Relation Embedding Chains. (arXiv:2310.12379v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1">Nitesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Schockaert_S/0/1/0/all/0/1">Steven Schockaert</a></p>
<p>Modelling how concepts are related is a central topic in Lexical Semantics. A
common strategy is to rely on knowledge graphs (KGs) such as ConceptNet, and to
model the relation between two concepts as a set of paths. However, KGs are
limited to a fixed set of relation types, and they are incomplete and often
noisy. Another strategy is to distill relation embeddings from a fine-tuned
language model. However, this is less suitable for words that are only
indirectly related and it does not readily allow us to incorporate structured
domain knowledge. In this paper, we aim to combine the best of both worlds. We
model relations as paths but associate their edges with relation embeddings.
The paths are obtained by first identifying suitable intermediate words and
then selecting those words for which informative relation embeddings can be
obtained. We empirically show that our proposed representations are useful for
solving hard analogy questions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12386">Online Learning and Planning in Cognitive Hierarchies. (arXiv:2310.12386v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hengst_B/0/1/0/all/0/1">Bernhard Hengst</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagnucco_M/0/1/0/all/0/1">Maurice Pagnucco</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajaratnam_D/0/1/0/all/0/1">David Rajaratnam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sammut_C/0/1/0/all/0/1">Claude Sammut</a>, <a href="http://arxiv.org/find/cs/1/au:+Thielscher_M/0/1/0/all/0/1">Michael Thielscher</a></p>
<p>Complex robot behaviour typically requires the integration of multiple
robotic and Artificial Intelligence (AI) techniques and components. Integrating
such disparate components into a coherent system, while also ensuring global
properties and behaviours, is a significant challenge for cognitive robotics.
Using a formal framework to model the interactions between components can be an
important step in dealing with this challenge. In this paper we extend an
existing formal framework [Clark et al., 2016] to model complex integrated
reasoning behaviours of robotic systems; from symbolic planning through to
online learning of policies and transition systems. Furthermore the new
framework allows for a more flexible modelling of the interactions between
different reasoning components.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12387">Learning to Solve Climate Sensor Placement Problems with a Transformer. (arXiv:2310.12387v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_V/0/1/0/all/0/1">Victoria Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Gang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bryce Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_J/0/1/0/all/0/1">Jochen Schmidt</a></p>
<p>The optimal placement of sensors for environmental monitoring and disaster
management is a challenging problem due to its NP-hard nature. Traditional
methods for sensor placement involve exact, approximation, or heuristic
approaches, with the latter being the most widely used. However, heuristic
methods are limited by expert intuition and experience. Deep learning (DL) has
emerged as a promising approach for generating heuristic algorithms
automatically. In this paper, we introduce a novel sensor placement approach
focused on learning improvement heuristics using deep reinforcement learning
(RL) methods. Our approach leverages an RL formulation for learning improvement
heuristics, driven by an actor-critic algorithm for training the policy
network. We compare our method with several state-of-the-art approaches by
conducting comprehensive experiments, demonstrating the effectiveness and
superiority of our proposed approach in producing high-quality solutions. Our
work presents a promising direction for applying advanced DL and RL techniques
to challenging climate sensor placement problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12397">GPT-4 Doesn&#x27;t Know It&#x27;s Wrong: An Analysis of Iterative Prompting for Reasoning Problems. (arXiv:2310.12397v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Stechly_K/0/1/0/all/0/1">Kaya Stechly</a>, <a href="http://arxiv.org/find/cs/1/au:+Marquez_M/0/1/0/all/0/1">Matthew Marquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1">Subbarao Kambhampati</a></p>
<p>There has been considerable divergence of opinion on the reasoning abilities
of Large Language Models (LLMs). While the initial optimism that reasoning
might emerge automatically with scale has been tempered thanks to a slew of
counterexamples, a wide spread belief in their iterative self-critique
capabilities persists. In this paper, we set out to systematically investigate
the effectiveness of iterative prompting of LLMs in the context of Graph
Coloring, a canonical NP-complete reasoning problem that is related to
propositional satisfiability as well as practical problems like scheduling and
allocation. We present a principled empirical study of the performance of GPT4
in solving graph coloring instances or verifying the correctness of candidate
colorings. In iterative modes, we experiment with the model critiquing its own
answers and an external correct reasoner verifying proposed solutions. In both
cases, we analyze whether the content of the criticisms actually affects bottom
line performance. The study seems to indicate that (i) LLMs are bad at solving
graph coloring instances (ii) they are no better at verifying a solution--and
thus are not effective in iterative modes with LLMs critiquing LLM-generated
solutions (iii) the correctness and content of the criticisms--whether by LLMs
or external solvers--seems largely irrelevant to the performance of iterative
prompting. We show that the observed increase in effectiveness is largely due
to the correct solution being fortuitously present in the top-k completions of
the prompt (and being recognized as such by an external verifier). Our results
thus call into question claims about the self-critiquing capabilities of state
of the art LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12407">Classification-Aided Robust Multiple Target Tracking Using Neural Enhanced Message Passing. (arXiv:2310.12407v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xianglong Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zengfu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1">Quan Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1">Tao Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_H/0/1/0/all/0/1">Hua Lan</a></p>
<p>We address the challenge of tracking an unknown number of targets in strong
clutter environments using measurements from a radar sensor. Leveraging the
range-Doppler spectra information, we identify the measurement classes, which
serve as additional information to enhance clutter rejection and data
association, thus bolstering the robustness of target tracking. We first
introduce a novel neural enhanced message passing approach, where the beliefs
obtained by the unified message passing are fed into the neural network as
additional information. The output beliefs are then utilized to refine the
original beliefs. Then, we propose a classification-aided robust multiple
target tracking algorithm, employing the neural enhanced message passing
technique. This algorithm is comprised of three modules: a message-passing
module, a neural network module, and a Dempster-Shafer module. The
message-passing module is used to represent the statistical model by the factor
graph and infers target kinematic states, visibility states, and data
associations based on the spatial measurement information. The neural network
module is employed to extract features from range-Doppler spectra and derive
beliefs on whether a measurement is target-generated or clutter-generated. The
Dempster-Shafer module is used to fuse the beliefs obtained from both the
factor graph and the neural network. As a result, our proposed algorithm adopts
a model-and-data-driven framework, effectively enhancing clutter suppression
and data association, leading to significant improvements in multiple target
tracking performance. We validate the effectiveness of our approach using both
simulated and real data scenarios, demonstrating its capability to handle
challenging tracking scenarios in practical radar applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12408">Provable Guarantees for Neural Networks via Gradient Feature Learning. (arXiv:2310.12408v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhenmei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Junyi Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yingyu Liang</a></p>
<p>Neural networks have achieved remarkable empirical performance, while the
current theoretical analysis is not adequate for understanding their success,
e.g., the Neural Tangent Kernel approach fails to capture their key feature
learning ability, while recent analyses on feature learning are typically
problem-specific. This work proposes a unified analysis framework for two-layer
networks trained by gradient descent. The framework is centered around the
principle of feature learning from gradients, and its effectiveness is
demonstrated by applications in several prototypical problems, such as mixtures
of Gaussians and parity functions. The framework also sheds light on
interesting network learning phenomena such as feature learning beyond kernels
and the lottery ticket hypothesis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12425">Automated Repair of Declarative Software Specifications in the Era of Large Language Models. (arXiv:2310.12425v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Md Rashedul Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiawei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_I/0/1/0/all/0/1">Iftekhar Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagheri_H/0/1/0/all/0/1">Hamid Bagheri</a></p>
<p>The growing adoption of declarative software specification languages, coupled
with their inherent difficulty in debugging, has underscored the need for
effective and automated repair techniques applicable to such languages.
Researchers have recently explored various methods to automatically repair
declarative software specifications, such as template-based repair,
feedback-driven iterative repair, and bounded exhaustive approaches. The latest
developments in large language models provide new opportunities for the
automatic repair of declarative specifications. In this study, we assess the
effectiveness of utilizing OpenAI's ChatGPT to repair software specifications
written in the Alloy declarative language. Unlike imperative languages,
specifications in Alloy are not executed but rather translated into logical
formulas and evaluated using backend constraint solvers to identify
specification instances and counterexamples to assertions. Our evaluation
focuses on ChatGPT's ability to improve the correctness and completeness of
Alloy declarative specifications through automatic repairs. We analyze the
results produced by ChatGPT and compare them with those of leading automatic
Alloy repair methods. Our study revealed that while ChatGPT falls short in
comparison to existing techniques, it was able to successfully repair bugs that
no other technique could address. Our analysis also identified errors in
ChatGPT's generated repairs, including improper operator usage, type errors,
higher-order logic misuse, and relational arity mismatches. Additionally, we
observed instances of hallucinations in ChatGPT-generated repairs and
inconsistency in its results. Our study provides valuable insights for software
practitioners, researchers, and tool builders considering ChatGPT for
declarative specification repairs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12426">MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models. (arXiv:2310.12426v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nathani_D/0/1/0/all/0/1">Deepak Nathani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">David Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1">Liangming Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a></p>
<p>Language Models (LMs) have shown impressive performance in various natural
language tasks. However, when it comes to natural language reasoning, LMs still
face challenges such as hallucination, generating incorrect intermediate
reasoning steps, and making mathematical errors. Recent research has focused on
enhancing LMs through self-improvement using feedback. Nevertheless, existing
approaches relying on a single generic feedback source fail to address the
diverse error types found in LM-generated reasoning chains. In this work, we
propose Multi-Aspect Feedback, an iterative refinement framework that
integrates multiple feedback modules, including frozen LMs and external tools,
each focusing on a specific error category. Our experimental results
demonstrate the efficacy of our approach to addressing several errors in the
LM-generated reasoning chain and thus improving the overall performance of an
LM in several reasoning tasks. We see a relative improvement of up to 20% in
Mathematical Reasoning and up to 18% in Logical Entailment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12428">Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Rosaler_J/0/1/0/all/0/1">Joshua Rosaler</a>, <a href="http://arxiv.org/find/stat/1/au:+Desai_D/0/1/0/all/0/1">Dhruv Desai</a>, <a href="http://arxiv.org/find/stat/1/au:+Sarmah_B/0/1/0/all/0/1">Bhaskarjit Sarmah</a>, <a href="http://arxiv.org/find/stat/1/au:+Vamvourellis_D/0/1/0/all/0/1">Dimitrios Vamvourellis</a>, <a href="http://arxiv.org/find/stat/1/au:+Onay_D/0/1/0/all/0/1">Deran Onay</a>, <a href="http://arxiv.org/find/stat/1/au:+Mehta_D/0/1/0/all/0/1">Dhagash Mehta</a>, <a href="http://arxiv.org/find/stat/1/au:+Pasquali_S/0/1/0/all/0/1">Stefano Pasquali</a></p>
<p>We initiate a novel approach to explain the out of sample performance of
random forest (RF) models by exploiting the fact that any RF can be formulated
as an adaptive weighted K nearest-neighbors model. Specifically, we use the
proximity between points in the feature space learned by the RF to re-write
random forest predictions exactly as a weighted average of the target labels of
training data points. This linearity facilitates a local notion of
explainability of RF predictions that generates attributions for any model
prediction across observations in the training set, and thereby complements
established methods like SHAP, which instead generates attributions for a model
prediction across dimensions of the feature space. We demonstrate this approach
in the context of a bond pricing model trained on US corporate bond trades, and
compare our approach to various existing approaches to model explainability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12439">PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models. (arXiv:2310.12439v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1">Hongwei Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1">Jian Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhan Qin</a></p>
<p>Prompts have significantly improved the performance of pretrained Large
Language Models (LLMs) on various downstream tasks recently, making them
increasingly indispensable for a diverse range of LLM application scenarios.
However, the backdoor vulnerability, a serious security threat that can
maliciously alter the victim model's normal predictions, has not been
sufficiently explored for prompt-based LLMs. In this paper, we present
POISONPROMPT, a novel backdoor attack capable of successfully compromising both
hard and soft prompt-based LLMs. We evaluate the effectiveness, fidelity, and
robustness of POISONPROMPT through extensive experiments on three popular
prompt methods, using six datasets and three widely used LLMs. Our findings
highlight the potential security threats posed by backdoor attacks on
prompt-based LLMs and emphasize the need for further research in this area.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12443">Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher. (arXiv:2310.12443v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiawei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yinpeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1">Qikai Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wei Lu</a></p>
<p>The advent of Large Language Models (LLMs) has shown the potential to improve
relevance and provide direct answers in web searches. However, challenges arise
in validating the reliability of generated results and the credibility of
contributing sources, due to the limitations of traditional information
retrieval algorithms and the LLM hallucination problem. Aiming to create a
"PageRank" for the LLM era, we strive to transform LLM into a relevant,
responsible, and trustworthy searcher. We propose a novel generative retrieval
framework leveraging the knowledge of LLMs to foster a direct link between
queries and online sources. This framework consists of three core modules:
Generator, Validator, and Optimizer, each focusing on generating trustworthy
online sources, verifying source reliability, and refining unreliable sources,
respectively. Extensive experiments and evaluations highlight our method's
superior relevance, responsibility, and trustfulness against various SOTA
methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12451">MTS-LOF: Medical Time-Series Representation Learning via Occlusion-Invariant Features. (arXiv:2310.12451v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huayu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Carreon_Rascon_A/0/1/0/all/0/1">Ana S. Carreon-Rascon</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiwen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Ao Li</a></p>
<p>Medical time series data are indispensable in healthcare, providing critical
insights for disease diagnosis, treatment planning, and patient management. The
exponential growth in data complexity, driven by advanced sensor technologies,
has presented challenges related to data labeling. Self-supervised learning
(SSL) has emerged as a transformative approach to address these challenges,
eliminating the need for extensive human annotation. In this study, we
introduce a novel framework for Medical Time Series Representation Learning,
known as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and
Masked Autoencoder (MAE) methods, offering a unique approach to representation
learning for medical time series data. By combining these techniques, MTS-LOF
enhances the potential of healthcare applications by providing more
sophisticated, context-rich representations. Additionally, MTS-LOF employs a
multi-masking strategy to facilitate occlusion-invariant feature learning. This
approach allows the model to create multiple views of the data by masking
portions of it. By minimizing the discrepancy between the representations of
these masked patches and the fully visible patches, MTS-LOF learns to capture
rich contextual information within medical time series datasets. The results of
experiments conducted on diverse medical time series datasets demonstrate the
superiority of MTS-LOF over other methods. These findings hold promise for
significantly enhancing healthcare applications by improving representation
learning. Furthermore, our work delves into the integration of joint-embedding
SSL and MAE techniques, shedding light on the intricate interplay between
temporal and structural dependencies in healthcare data. This understanding is
crucial, as it allows us to grasp the complexities of healthcare data analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12454">Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models. (arXiv:2310.12454v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">You Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Jinhui Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yuming Lin</a></p>
<p>Pretrained language models are expected to effectively map input text to a
set of vectors while preserving the inherent relationships within the text.
Consequently, designing a white-box model to compute metrics that reflect the
presence of specific internal relations in these vectors has become a common
approach for post-hoc interpretability analysis of pretrained language models.
However, achieving interpretability in white-box models and ensuring the rigor
of metric computation becomes challenging when the source model lacks inherent
interpretability. Therefore, in this paper, we discuss striking a balance in
this trade-off and propose a novel line to constructing metrics for
understanding the mechanisms of pretrained language models. We have
specifically designed a family of metrics along this line of investigation, and
the model used to compute these metrics is referred to as the tree topological
probe. We conducted measurements on BERT-large by using these metrics. Based on
the experimental results, we propose a speculation regarding the working
mechanism of BERT-like pretrained language models, as well as a strategy for
enhancing fine-tuning performance by leveraging the topological probe to
improve specific submodules.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12459">Affective Conversational Agents: Understanding Expectations and Personal Influences. (arXiv:2310.12459v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hernandez_J/0/1/0/all/0/1">Javier Hernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Suh_J/0/1/0/all/0/1">Jina Suh</a>, <a href="http://arxiv.org/find/cs/1/au:+Amores_J/0/1/0/all/0/1">Judith Amores</a>, <a href="http://arxiv.org/find/cs/1/au:+Rowan_K/0/1/0/all/0/1">Kael Rowan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_G/0/1/0/all/0/1">Gonzalo Ramos</a>, <a href="http://arxiv.org/find/cs/1/au:+Czerwinski_M/0/1/0/all/0/1">Mary Czerwinski</a></p>
<p>The rise of AI conversational agents has broadened opportunities to enhance
human capabilities across various domains. As these agents become more
prevalent, it is crucial to investigate the impact of different affective
abilities on their performance and user experience. In this study, we surveyed
745 respondents to understand the expectations and preferences regarding
affective skills in various applications. Specifically, we assessed preferences
concerning AI agents that can perceive, respond to, and simulate emotions
across 32 distinct scenarios. Our results indicate a preference for scenarios
that involve human interaction, emotional support, and creative tasks, with
influences from factors such as emotional reappraisal and personality traits.
Overall, the desired affective skills in AI agents depend largely on the
application's context and nature, emphasizing the need for adaptability and
context-awareness in the design of affective AI conversational agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12477">An Exploration of In-Context Learning for Speech Language Model. (arXiv:2310.12477v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Hsu_M/0/1/0/all/0/1">Ming-Hao Hsu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1">Shang-Wen Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a></p>
<p>Ever since the development of GPT-3 in the natural language processing (NLP)
field, in-context learning (ICL) has played an important role in utilizing
large language models (LLMs). By presenting the LM utterance-label
demonstrations at the input, the LM can accomplish few-shot learning without
relying on gradient descent or requiring explicit modification of its
parameters. This enables the LM to learn and adapt in a black-box manner.
Despite the success of ICL in NLP, little work is exploring the possibility of
ICL in speech processing. This study proposes the first exploration of ICL with
a speech LM without text supervision. We first show that the current speech LM
does not have the ICL capability. With the proposed warmup training, the speech
LM can, therefore, perform ICL on unseen tasks. In this work, we verify the
feasibility of ICL for speech LM on speech classification tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12480">GRAPE-S: Near Real-Time Coalition Formation for Multiple Service Collectives. (arXiv:2310.12480v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Diehl_G/0/1/0/all/0/1">Grace Diehl</a>, <a href="http://arxiv.org/find/cs/1/au:+Adams_J/0/1/0/all/0/1">Julie A. Adams</a></p>
<p>Robotic collectives for military and disaster response applications require
coalition formation algorithms to partition robots into appropriate task teams.
Collectives' missions will often incorporate tasks that require multiple
high-level robot behaviors or services, which coalition formation must
accommodate. The highly dynamic and unstructured application domains also
necessitate that coalition formation algorithms produce near optimal solutions
(i.e., &gt;95% utility) in near real-time (i.e., &lt;5 minutes) with very large
collectives (i.e., hundreds of robots). No previous coalition formation
algorithm satisfies these requirements. An initial evaluation found that
traditional auction-based algorithms' runtimes are too long, even though the
centralized simulator incorporated ideal conditions unlikely to occur in
real-world deployments (i.e., synchronization across robots and perfect,
instantaneous communication). The hedonic game-based GRAPE algorithm can
produce solutions in near real-time, but cannot be applied to multiple service
collectives. This manuscript integrates GRAPE and a services model, producing
GRAPE-S and Pair-GRAPE-S. These algorithms and two auction baselines were
evaluated using a centralized simulator with up to 1000 robots, and via the
largest distributed coalition formation simulated evaluation to date, with up
to 500 robots. The evaluations demonstrate that auctions transfer poorly to
distributed collectives, resulting in excessive runtimes and low utility
solutions. GRAPE-S satisfies the target domains' coalition formation
requirements, producing near optimal solutions in near real-time, and
Pair-GRAPE-S more than satisfies the domain requirements, producing optimal
solutions in near real-time. GRAPE-S and Pair-GRAPE-S are the first algorithms
demonstrated to support near real-time coalition formation for very large,
distributed collectives with multiple services.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12481">Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models. (arXiv:2310.12481v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1">Wenxiang Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jingyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_R/0/1/0/all/0/1">Ruyi Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jen-tse Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhaopeng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael R. Lyu</a></p>
<p>In this paper, we identify a cultural dominance issue within large language
models (LLMs) due to the predominant use of English data in model training
(e.g. ChatGPT). LLMs often provide inappropriate English-culture-related
answers that are not relevant to the expected culture when users ask in
non-English languages. To systematically evaluate the cultural dominance issue,
we build a benchmark that consists of both concrete (e.g. holidays and songs)
and abstract (e.g. values and opinions) cultural objects. Empirical results
show that the representative GPT models suffer from the culture dominance
problem, where GPT-4 is the most affected while text-davinci-003 suffers the
least from this problem. Our study emphasizes the need for critical examination
of cultural dominance and ethical consideration in their development and
deployment. We show two straightforward methods in model development (i.e.
pretraining on more diverse data) and deployment (e.g. culture-aware prompting)
can significantly mitigate the cultural dominance issue in LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12508">SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation. (arXiv:2310.12508v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Chongyu Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiancheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yihua Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1">Dennis Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1">Eric Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a></p>
<p>With evolving data regulations, machine unlearning (MU) has become an
important tool for fostering trust and safety in today's AI models. However,
existing MU methods focusing on data and/or weight perspectives often grapple
with limitations in unlearning accuracy, stability, and cross-domain
applicability. To address these challenges, we introduce the concept of 'weight
saliency' in MU, drawing parallels with input saliency in model explanation.
This innovation directs MU's attention toward specific model weights rather
than the entire model, improving effectiveness and efficiency. The resultant
method that we call saliency unlearning (SalUn) narrows the performance gap
with 'exact' unlearning (model retraining from scratch after removing the
forgetting dataset). To the best of our knowledge, SalUn is the first
principled MU approach adaptable enough to effectively erase the influence of
forgetting data, classes, or concepts in both image classification and
generation. For example, SalUn yields a stability advantage in high-variance
random data forgetting, e.g., with a 0.2% gap compared to exact unlearning on
the CIFAR-10 dataset. Moreover, in preventing conditional diffusion models from
generating harmful images, SalUn achieves nearly 100% unlearning accuracy,
outperforming current state-of-the-art baselines like Erased Stable Diffusion
and Forget-Me-Not.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12516">Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks. (arXiv:2310.12516v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xiaodong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Hao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1">Dan Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a></p>
<p>Although remarkable progress has been achieved in preventing large language
model (LLM) hallucinations using instruction tuning and retrieval augmentation,
it remains challenging to measure the reliability of LLMs using human-crafted
evaluation data which is not available for many tasks and domains and could
suffer from data leakage. Inspired by adversarial machine learning, this paper
aims to develop a method of automatically generating evaluation data by
appropriately modifying existing data on which LLMs behave faithfully.
Specifically, this paper presents AutoDebug, an LLM-based framework to use
prompting chaining to generate transferable adversarial attacks in the form of
question-answering examples. We seek to understand the extent to which these
examples trigger the hallucination behaviors of LLMs.
</p>
<p>We implement AutoDebug using ChatGPT and evaluate the resulting two variants
of a popular open-domain question-answering dataset, Natural Questions (NQ), on
a collection of open-source and proprietary LLMs under various prompting
settings. Our generated evaluation data is human-readable and, as we show,
humans can answer these modified questions well. Nevertheless, we observe
pronounced accuracy drops across multiple LLMs including GPT-4. Our
experimental results show that LLMs are likely to hallucinate in two categories
of question-answering scenarios where (1) there are conflicts between knowledge
given in the prompt and their parametric knowledge, or (2) the knowledge
expressed in the prompt is complex. Finally, we find that the adversarial
examples generated by our method are transferable across all considered LLMs.
The examples generated by a small model can be used to debug a much larger
model, making our approach cost-effective.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12527">Testing the Consistency of Performance Scores Reported for Binary Classification Problems. (arXiv:2310.12527v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fazekas_A/0/1/0/all/0/1">Attila Fazekas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovacs_G/0/1/0/all/0/1">Gy&#xf6;rgy Kov&#xe1;cs</a></p>
<p>Binary classification is a fundamental task in machine learning, with
applications spanning various scientific domains. Whether scientists are
conducting fundamental research or refining practical applications, they
typically assess and rank classification techniques based on performance
metrics such as accuracy, sensitivity, and specificity. However, reported
performance scores may not always serve as a reliable basis for research
ranking. This can be attributed to undisclosed or unconventional practices
related to cross-validation, typographical errors, and other factors. In a
given experimental setup, with a specific number of positive and negative test
items, most performance scores can assume specific, interrelated values. In
this paper, we introduce numerical techniques to assess the consistency of
reported performance scores and the assumed experimental setup. Importantly,
the proposed approach does not rely on statistical inference but uses numerical
methods to identify inconsistencies with certainty. Through three different
applications related to medicine, we demonstrate how the proposed techniques
can effectively detect inconsistencies, thereby safeguarding the integrity of
research fields. To benefit the scientific community, we have made the
consistency tests available in an open-source Python package.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12541">Large Language Model for Multi-objective Evolutionary Optimization. (arXiv:2310.12541v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhenkun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1">Shunyu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1">Xialiang Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1">Mingxuan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingfu Zhang</a></p>
<p>Multiobjective evolutionary algorithms (MOEAs) are major methods for solving
multiobjective optimization problems (MOPs). Many MOEAs have been proposed in
the past decades, of which the operators need carefully handcrafted design with
domain knowledge. Recently, some attempts have been made to replace the
manually designed operators in MOEAs with learning-based operators (e.g.,
neural network models). However, much effort is still required for designing
and training such models, and the learned operators might not generalize well
to solve new problems. To tackle the above challenges, this work investigates a
novel approach that leverages the powerful large language model (LLM) to design
MOEA operators. With proper prompt engineering, we successfully let a general
LLM serve as a black-box search operator for decomposition-based MOEA (MOEA/D)
in a zero-shot manner. In addition, by learning from the LLM behavior, we
further design an explicit white-box operator with randomness and propose a new
version of decomposition-based MOEA, termed MOEA/D-LO. Experimental studies on
different test benchmarks show that our proposed method can achieve competitive
performance with widely used MOEAs. It is also promising to see the operator
only learned from a few instances can have robust generalization performance on
unseen problems with quite different patterns and settings. The results reveal
the potential benefits of using pre-trained LLMs in the design of MOEAs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12557">DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text. (arXiv:2310.12557v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuaiyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1">Wai Lam</a></p>
<p>Spatial reasoning in text plays a crucial role in various real-world
applications. Existing approaches for spatial reasoning typically infer spatial
relations from pure text, which overlook the gap between natural language and
symbolic structures. Graph neural networks (GNNs) have showcased exceptional
proficiency in inducing and aggregating symbolic structures. However, classical
GNNs face challenges in handling multi-hop spatial reasoning due to the
over-smoothing issue, \textit{i.e.}, the performance decreases substantially as
the number of graph layers increases. To cope with these challenges, we propose
a novel \textbf{Dep}th-\textbf{Wi}se \textbf{G}raph \textbf{N}eural
\textbf{N}etwork (\textbf{DepWiGNN}). Specifically, we design a novel node
memory scheme and aggregate the information over the depth dimension instead of
the breadth dimension of the graph, which empowers the ability to collect long
dependencies without stacking multiple layers. Experimental results on two
challenging multi-hop spatial reasoning datasets show that DepWiGNN outperforms
existing spatial reasoning methods. The comparisons with the other three GNNs
further demonstrate its superiority in capturing long dependency in the graph.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12567">Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark. (arXiv:2310.12567v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jiaming Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Borong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiayi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xuehai Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Weidong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1">Ruiyang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_Y/0/1/0/all/0/1">Yiran Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yifan Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Juntao Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaodong Yang</a></p>
<p>Artificial intelligence (AI) systems possess significant potential to drive
societal progress. However, their deployment often faces obstacles due to
substantial safety concerns. Safe reinforcement learning (SafeRL) emerges as a
solution to optimize policies while simultaneously adhering to multiple
constraints, thereby addressing the challenge of integrating reinforcement
learning in safety-critical scenarios. In this paper, we present an environment
suite called Safety-Gymnasium, which encompasses safety-critical tasks in both
single and multi-agent scenarios, accepting vector and vision-only input.
Additionally, we offer a library of algorithms named Safe Policy Optimization
(SafePO), comprising 16 state-of-the-art SafeRL algorithms. This comprehensive
library can serve as a validation tool for the research community. By
introducing this benchmark, we aim to facilitate the evaluation and comparison
of safety performance, thus fostering the development of reinforcement learning
for safer, more reliable, and responsible real-world applications. The website
of this project can be accessed at
https://sites.google.com/view/safety-gymnasium.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12580">Pretraining Language Models with Text-Attributed Heterogeneous Graphs. (arXiv:2310.12580v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zou_T/0/1/0/all/0/1">Tao Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Le Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yifei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Leilei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bowen Du</a></p>
<p>In many real-world scenarios (e.g., academic networks, social platforms),
different types of entities are not only associated with texts but also
connected by various relationships, which can be abstracted as Text-Attributed
Heterogeneous Graphs (TAHGs). Current pretraining tasks for Language Models
(LMs) primarily focus on separately learning the textual information of each
entity and overlook the crucial aspect of capturing topological connections
among entities in TAHGs. In this paper, we present a new pretraining framework
for LMs that explicitly considers the topological and heterogeneous information
in TAHGs. Firstly, we define a context graph as neighborhoods of a target node
within specific orders and propose a topology-aware pretraining task to predict
nodes involved in the context graph by jointly optimizing an LM and an
auxiliary heterogeneous graph neural network. Secondly, based on the
observation that some nodes are text-rich while others have little text, we
devise a text augmentation strategy to enrich textless nodes with their
neighbors' texts for handling the imbalance issue. We conduct link prediction
and node classification tasks on three datasets from various domains.
Experimental results demonstrate the superiority of our approach over existing
methods and the rationality of each design. Our code is available at
https://github.com/Hope-Rita/THLM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12585">Time-Aware Representation Learning for Time-Sensitive Question Answering. (arXiv:2310.12585v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1">Jungbin Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1">Alice Oh</a></p>
<p>Time is one of the crucial factors in real-world question answering (QA)
problems. However, language models have difficulty understanding the
relationships between time specifiers, such as 'after' and 'before', and
numbers, since existing QA datasets do not include sufficient time expressions.
To address this issue, we propose a Time-Context aware Question Answering
(TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE)
task, and build a time-context dependent data generation framework for model
training. Moreover, we present a metric to evaluate the time awareness of the
QA model using TCSE. The TCSE task consists of a question and four sentence
candidates classified as correct or incorrect based on time and context. The
model is trained to extract the answer span from the sentence that is both
correct in time and context. The model trained with TCQA outperforms baseline
models up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code
are available at https://github.com/sonjbin/TCQA
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12609">Denoising Heat-inspired Diffusion with Insulators for Collision Free Motion Planning. (arXiv:2310.12609v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1">Junwoo Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryu_H/0/1/0/all/0/1">Hyunwoo Ryu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jiwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1">Soochul Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1">Joohwan Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_N/0/1/0/all/0/1">Nikhil Prakash</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jongeun Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Horowitz_R/0/1/0/all/0/1">Roberto Horowitz</a></p>
<p>Diffusion models have risen as a powerful tool in robotics due to their
flexibility and multi-modality. While some of these methods effectively address
complex problems, they often depend heavily on inference-time obstacle
detection and require additional equipment. Addressing these challenges, we
present a method that, during inference time, simultaneously generates only
reachable goals and plans motions that avoid obstacles, all from a single
visual input. Central to our approach is the novel use of a collision-avoiding
diffusion kernel for training. Through evaluations against behavior-cloning and
classical diffusion models, our framework has proven its robustness. It is
particularly effective in multi-modal environments, navigating toward goals and
avoiding unreachable ones blocked by obstacles, while ensuring collision
avoidance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12611">Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model. (arXiv:2310.12611v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chintam_A/0/1/0/all/0/1">Abhijith Chintam</a>, <a href="http://arxiv.org/find/cs/1/au:+Beloch_R/0/1/0/all/0/1">Rahel Beloch</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuidema_W/0/1/0/all/0/1">Willem Zuidema</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanna_M/0/1/0/all/0/1">Michael Hanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Wal_O/0/1/0/all/0/1">Oskar van der Wal</a></p>
<p>Language models (LMs) exhibit and amplify many types of undesirable biases
learned from the training data, including gender bias. However, we lack tools
for effectively and efficiently changing this behavior without hurting general
language modeling performance. In this paper, we study three methods for
identifying causal relations between LM components and particular output:
causal mediation analysis, automated circuit discovery and our novel, efficient
method called DiffMask+ based on differential masking. We apply the methods to
GPT-2 small and the problem of gender bias, and use the discovered sets of
components to perform parameter-efficient fine-tuning for bias mitigation. Our
results show significant overlap in the identified components (despite huge
differences in the computational requirements of the methods) as well as
success in mitigating gender bias, with less damage to general language
modeling compared to full model fine-tuning. However, our work also underscores
the difficulty of defining and measuring bias, and the sensitivity of causal
discovery procedures to dataset choice. We hope our work can contribute to more
attention for dataset development, and lead to more effective mitigation
strategies for other types of bias.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12616">Cross-attention Spatio-temporal Context Transformer for Semantic Segmentation of Historical Maps. (arXiv:2310.12616v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Sidi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yizi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1">Konrad Schindler</a>, <a href="http://arxiv.org/find/cs/1/au:+Hurni_L/0/1/0/all/0/1">Lorenz Hurni</a></p>
<p>Historical maps provide useful spatio-temporal information on the Earth's
surface before modern earth observation techniques came into being. To extract
information from maps, neural networks, which gain wide popularity in recent
years, have replaced hand-crafted map processing methods and tedious manual
labor. However, aleatoric uncertainty, known as data-dependent uncertainty,
inherent in the drawing/scanning/fading defects of the original map sheets and
inadequate contexts when cropping maps into small tiles considering the memory
limits of the training process, challenges the model to make correct
predictions. As aleatoric uncertainty cannot be reduced even with more training
data collected, we argue that complementary spatio-temporal contexts can be
helpful. To achieve this, we propose a U-Net-based network that fuses
spatio-temporal features with cross-attention transformers (U-SpaTem),
aggregating information at a larger spatial range as well as through a temporal
sequence of images. Our model achieves a better performance than other
state-or-art models that use either temporal or spatial contexts. Compared with
pure vision transformers, our model is more lightweight and effective. To the
best of our knowledge, leveraging both spatial and temporal contexts have been
rarely explored before in the segmentation task. Even though our application is
on segmenting historical maps, we believe that the method can be transferred
into other fields with similar problems like temporal sequences of satellite
images. Our code is freely accessible at
https://github.com/chenyizi086/wu.2023.sigspatial.git.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12630">Heart Disease Detection using Vision-Based Transformer Models from ECG Images. (arXiv:2310.12630v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kilimci_Z/0/1/0/all/0/1">Zeynep Hilal Kilimci</a>, <a href="http://arxiv.org/find/cs/1/au:+Yalcin_M/0/1/0/all/0/1">Mustafa Yalcin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kucukmanisa_A/0/1/0/all/0/1">Ayhan Kucukmanisa</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1">Amit Kumar Mishra</a></p>
<p>Heart disease, also known as cardiovascular disease, is a prevalent and
critical medical condition characterized by the impairment of the heart and
blood vessels, leading to various complications such as coronary artery
disease, heart failure, and myocardial infarction. The timely and accurate
detection of heart disease is of paramount importance in clinical practice.
Early identification of individuals at risk enables proactive interventions,
preventive measures, and personalized treatment strategies to mitigate the
progression of the disease and reduce adverse outcomes. In recent years, the
field of heart disease detection has witnessed notable advancements due to the
integration of sophisticated technologies and computational approaches. These
include machine learning algorithms, data mining techniques, and predictive
modeling frameworks that leverage vast amounts of clinical and physiological
data to improve diagnostic accuracy and risk stratification. In this work, we
propose to detect heart disease from ECG images using cutting-edge
technologies, namely vision transformer models. These models are Google-Vit,
Microsoft-Beit, and Swin-Tiny. To the best of our knowledge, this is the
initial endeavor concentrating on the detection of heart diseases through
image-based ECG data by employing cuttingedge technologies namely, transformer
models. To demonstrate the contribution of the proposed framework, the
performance of vision transformer models are compared with state-of-the-art
studies. Experiment results show that the proposed framework exhibits
remarkable classification results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12632">Towards a Deep Learning-based Online Quality Prediction System for Welding Processes. (arXiv:2310.12632v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hahn_Y/0/1/0/all/0/1">Yannik Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Maack_R/0/1/0/all/0/1">Robert Maack</a>, <a href="http://arxiv.org/find/cs/1/au:+Buchholz_G/0/1/0/all/0/1">Guido Buchholz</a>, <a href="http://arxiv.org/find/cs/1/au:+Purrio_M/0/1/0/all/0/1">Marion Purrio</a>, <a href="http://arxiv.org/find/cs/1/au:+Angerhausen_M/0/1/0/all/0/1">Matthias Angerhausen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tercan_H/0/1/0/all/0/1">Hasan Tercan</a>, <a href="http://arxiv.org/find/cs/1/au:+Meisen_T/0/1/0/all/0/1">Tobias Meisen</a></p>
<p>The digitization of manufacturing processes enables promising applications
for machine learning-assisted quality assurance. A widely used manufacturing
process that can strongly benefit from data-driven solutions is \ac{GMAW}. The
welding process is characterized by complex cause-effect relationships between
material properties, process conditions and weld quality. In non-laboratory
environments with frequently changing process parameters, accurate
determination of weld quality by destructive testing is economically
unfeasible. Deep learning offers the potential to identify the relationships in
available process data and predict the weld quality from process observations.
In this paper, we present a concept for a deep learning based predictive
quality system in \ac{GMAW}. At its core, the concept involves a pipeline
consisting of four major phases: collection and management of multi-sensor data
(e.g. current and voltage), real-time processing and feature engineering of the
time series data by means of autoencoders, training and deployment of suitable
recurrent deep learning models for quality predictions, and model evolutions
under changing process conditions using continual learning. The concept
provides the foundation for future research activities in which we will realize
an online predictive quality system for running production.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12638">PSYCHIC: A Neuro-Symbolic Framework for Knowledge Graph Question-Answering Grounding. (arXiv:2310.12638v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Akl_H/0/1/0/all/0/1">Hanna Abi Akl</a></p>
<p>The Scholarly Question Answering over Linked Data (Scholarly QALD) at The
International Semantic Web Conference (ISWC) 2023 challenge presents two
sub-tasks to tackle question answering (QA) over knowledge graphs (KGs). We
answer the KGQA over DBLP (DBLP-QUAD) task by proposing a neuro-symbolic (NS)
framework based on PSYCHIC, an extractive QA model capable of identifying the
query and entities related to a KG question. Our system achieved a F1 score of
00.18% on question answering and came in third place for entity linking (EL)
with a score of 71.00%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12688">Compression of Recurrent Neural Networks using Matrix Factorization. (arXiv:2310.12688v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maison_L/0/1/0/all/0/1">Lucas Maison</a>, <a href="http://arxiv.org/find/cs/1/au:+Bourboux_H/0/1/0/all/0/1">H&#xe9;lion du Mas des Bourboux</a>, <a href="http://arxiv.org/find/cs/1/au:+Courtat_T/0/1/0/all/0/1">Thomas Courtat</a></p>
<p>Compressing neural networks is a key step when deploying models for real-time
or embedded applications. Factorizing the model's matrices using low-rank
approximations is a promising method for achieving compression. While it is
possible to set the rank before training, this approach is neither flexible nor
optimal. In this work, we propose a post-training rank-selection method called
Rank-Tuning that selects a different rank for each matrix. Used in combination
with training adaptations, our method achieves high compression rates with no
or little performance degradation. Our numerical experiments on signal
processing tasks show that we can compress recurrent neural networks up to 14x
with at most 1.4% relative performance reduction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12690">Neurosymbolic Grounding for Compositional World Models. (arXiv:2310.12690v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sehgal_A/0/1/0/all/0/1">Atharva Sehgal</a>, <a href="http://arxiv.org/find/cs/1/au:+Grayeli_A/0/1/0/all/0/1">Arya Grayeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jennifer J. Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1">Swarat Chaudhuri</a></p>
<p>We introduce Cosmos, a framework for object-centric world modeling that is
designed for compositional generalization (CG), i.e., high performance on
unseen input scenes obtained through the composition of known visual "atoms."
The central insight behind Cosmos is the use of a novel form of neurosymbolic
grounding. Specifically, the framework introduces two new tools: (i)
neurosymbolic scene encodings, which represent each entity in a scene using a
real vector computed using a neural encoder, as well as a vector of composable
symbols describing attributes of the entity, and (ii) a neurosymbolic attention
mechanism that binds these entities to learned rules of interaction. Cosmos is
end-to-end differentiable; also, unlike traditional neurosymbolic methods that
require representations to be manually mapped to symbols, it computes an
entity's symbolic attributes using vision-language foundation models. Through
an evaluation that considers two different forms of CG on an established
blocks-pushing domain, we show that the framework establishes a new
state-of-the-art for CG in world modeling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12768">SemantIC: Semantic Interference Cancellation Towards 6G Wireless Communications. (arXiv:2310.12768v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Lin_W/0/1/0/all/0/1">Wensheng Lin</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_Y/0/1/0/all/0/1">Yuna Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1">Lixin Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_Z/0/1/0/all/0/1">Zhu Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Matsumoto_T/0/1/0/all/0/1">Tad Matsumoto</a></p>
<p>This letter proposes a novel anti-interference technique, semantic
interference cancellation (SemantIC), for enhancing information quality towards
the sixth-generation (6G) wireless networks. SemantIC only requires the
receiver to concatenate the channel decoder with a semantic auto-encoder. This
constructs a turbo loop which iteratively and alternately eliminates noise in
the signal domain and the semantic domain. From the viewpoint of network
information theory, the neural network of the semantic auto-encoder stores side
information by training, and provides side information in iterative decoding,
as an implementation of the Wyner-Ziv theorem. Simulation results verify the
performance improvement by SemantIC without extra channel resource cost.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12773">Safe RLHF: Safe Reinforcement Learning from Human Feedback. (arXiv:2310.12773v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Josef Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xuehai Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1">Ruiyang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jiaming Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xinbo Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mickel Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yizhou Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaodong Yang</a></p>
<p>With the development of large language models (LLMs), striking a balance
between the performance and safety of AI systems has never been more critical.
However, the inherent tension between the objectives of helpfulness and
harmlessness presents a significant challenge during LLM training. To address
this issue, we propose Safe Reinforcement Learning from Human Feedback (Safe
RLHF), a novel algorithm for human value alignment. Safe RLHF explicitly
decouples human preferences regarding helpfulness and harmlessness, effectively
avoiding the crowdworkers' confusion about the tension and allowing us to train
separate reward and cost models. We formalize the safety concern of LLMs as an
optimization task of maximizing the reward function while satisfying specified
cost constraints. Leveraging the Lagrangian method to solve this constrained
problem, Safe RLHF dynamically adjusts the balance between the two objectives
during fine-tuning. Through a three-round fine-tuning using Safe RLHF, we
demonstrate a superior ability to mitigate harmful responses while enhancing
model performance compared to existing value-aligned algorithms.
Experimentally, we fine-tuned the Alpaca-7B using Safe RLHF and aligned it with
collected human preferences, significantly improving its helpfulness and
harmlessness according to human evaluations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12774">Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning. (arXiv:2310.12774v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Han Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1">Xingchen Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1">Anna Korhonen</a></p>
<p>Prompt-based learning has been an effective paradigm for large pretrained
language models (LLM), enabling few-shot or even zero-shot learning. Black-box
prompt search has received growing interest recently for its distinctive
properties of gradient-free optimization, proven particularly useful and
powerful for model-as-a-service usage. However, the discrete nature and the
complexity of combinatorial optimization hinder the efficiency of modern
black-box approaches. Despite extensive research on search algorithms, the
crucial aspect of search space design and optimization has been largely
overlooked. In this paper, we first conduct a sensitivity analysis by prompting
LLM, revealing that only a small number of tokens exert a disproportionate
amount of influence on LLM predictions. Leveraging this insight, we propose the
Clustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple
black-box search method that first clusters and prunes the search space to
focus exclusively on influential prompt tokens. By employing even simple search
methods within the pruned search space, ClaPS achieves state-of-the-art
performance across various tasks and LLMs, surpassing the performance of
complex approaches while significantly reducing search costs. Our findings
underscore the critical role of search space design and optimization in
enhancing both the usefulness and the efficiency of black-box prompt-based
learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12800">Exploring Graph Neural Networks for Indian Legal Judgment Prediction. (arXiv:2310.12800v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khatri_M/0/1/0/all/0/1">Mann Khatri</a>, <a href="http://arxiv.org/find/cs/1/au:+Yusuf_M/0/1/0/all/0/1">Mirza Yusuf</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_Y/0/1/0/all/0/1">Yaman Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1">Rajiv Ratn Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1">Ponnurangam Kumaraguru</a></p>
<p>The burdensome impact of a skewed judges-to-cases ratio on the judicial
system manifests in an overwhelming backlog of pending cases alongside an
ongoing influx of new ones. To tackle this issue and expedite the judicial
process, the proposition of an automated system capable of suggesting case
outcomes based on factual evidence and precedent from past cases gains
significance. This research paper centres on developing a graph neural
network-based model to address the Legal Judgment Prediction (LJP) problem,
recognizing the intrinsic graph structure of judicial cases and making it a
binary node classification problem. We explored various embeddings as model
features, while nodes such as time nodes and judicial acts were added and
pruned to evaluate the model's performance. The study is done while considering
the ethical dimension of fairness in these predictions, considering gender and
name biases. A link prediction task is also conducted to assess the model's
proficiency in anticipating connections between two specified nodes. By
harnessing the capabilities of graph neural networks and incorporating fairness
analyses, this research aims to contribute insights towards streamlining the
adjudication process, enhancing judicial efficiency, and fostering a more
equitable legal landscape, ultimately alleviating the strain imposed by
mounting case backlogs. Our best-performing model with XLNet pre-trained
embeddings as its features gives the macro F1 score of 75% for the LJP task.
For link prediction, the same set of features is the best performing giving ROC
of more than 80%
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12802">An effective theory of collective deep learning. (arXiv:2310.12802v1 [physics.soc-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Arola_Fernandez_L/0/1/0/all/0/1">Llu&#xed;s Arola-Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/physics/1/au:+Lacasa_L/0/1/0/all/0/1">Lucas Lacasa</a></p>
<p>Unraveling the emergence of collective learning in systems of coupled
artificial neural networks is an endeavor with broader implications for
physics, machine learning, neuroscience and society. Here we introduce a
minimal model that condenses several recent decentralized algorithms by
considering a competition between two terms: the local learning dynamics in the
parameters of each neural network unit, and a diffusive coupling among units
that tends to homogenize the parameters of the ensemble. We derive the
coarse-grained behavior of our model via an effective theory for linear
networks that we show is analogous to a deformed Ginzburg-Landau model with
quenched disorder. This framework predicts (depth-dependent)
disorder-order-disorder phase transitions in the parameters' solutions that
reveal the onset of a collective learning phase, along with a depth-induced
delay of the critical point and a robust shape of the microscopic learning
path. We validate our theory in realistic ensembles of coupled nonlinear
networks trained in the MNIST dataset under privacy constraints. Interestingly,
experiments confirm that individual networks -- trained only with private data
-- can fully generalize to unseen data classes when the collective learning
phase emerges. Our work elucidates the physics of collective learning and
contributes to the mechanistic interpretability of deep learning in
decentralized settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12808">Model Merging by Uncertainty-Based Gradient Matching. (arXiv:2310.12808v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Daheim_N/0/1/0/all/0/1">Nico Daheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Mollenhoff_T/0/1/0/all/0/1">Thomas M&#xf6;llenhoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1">Edoardo Maria Ponti</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mohammad Emtiyaz Khan</a></p>
<p>Models trained on different datasets can be merged by a weighted-averaging of
their parameters, but why does it work and when can it fail? Here, we connect
the inaccuracy of weighted-averaging to mismatches in the gradients and propose
a new uncertainty-based scheme to improve the performance by reducing the
mismatch. The connection also reveals implicit assumptions in other schemes
such as averaging, task arithmetic, and Fisher-weighted averaging. Our new
method gives consistent improvements for large language models and vision
transformers, both in terms of performance and robustness to hyperparameters.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12815">Prompt Injection Attacks and Defenses in LLM-Integrated Applications. (arXiv:2310.12815v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yupei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yuqi Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_R/0/1/0/all/0/1">Runpeng Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jinyuan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1">Neil Zhenqiang Gong</a></p>
<p>Large Language Models (LLMs) are increasingly deployed as the backend for a
variety of real-world applications called LLM-Integrated Applications. Multiple
recent works showed that LLM-Integrated Applications are vulnerable to prompt
injection attacks, in which an attacker injects malicious instruction/data into
the input of those applications such that they produce results as the attacker
desires. However, existing works are limited to case studies. As a result, the
literature lacks a systematic understanding of prompt injection attacks and
their defenses. We aim to bridge the gap in this work. In particular, we
propose a general framework to formalize prompt injection attacks. Existing
attacks, which are discussed in research papers and blog posts, are special
cases in our framework. Our framework enables us to design a new attack by
combining existing attacks. Moreover, we also propose a framework to
systematize defenses against prompt injection attacks. Using our frameworks, we
conduct a systematic evaluation on prompt injection attacks and their defenses
with 10 LLMs and 7 tasks. We hope our frameworks can inspire future research in
this field. Our code is available at
https://github.com/liu00222/Open-Prompt-Injection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12817">2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision. (arXiv:2310.12817v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng-Kun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Min-Hung Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yung-Yu Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yen-Yu Lin</a></p>
<p>We present a Multimodal Interlaced Transformer (MIT) that jointly considers
2D and 3D data for weakly supervised point cloud segmentation. Research studies
have shown that 2D and 3D features are complementary for point cloud
segmentation. However, existing methods require extra 2D annotations to achieve
2D-3D information fusion. Considering the high annotation cost of point clouds,
effective 2D and 3D feature fusion based on weakly supervised learning is in
great demand. To this end, we propose a transformer model with two encoders and
one decoder for weakly supervised point cloud segmentation using only
scene-level class tags. Specifically, the two encoders compute the
self-attended features for 3D point clouds and 2D multi-view images,
respectively. The decoder implements interlaced 2D-3D cross-attention and
carries out implicit 2D and 3D feature fusion. We alternately switch the roles
of queries and key-value pairs in the decoder layers. It turns out that the 2D
and 3D features are iteratively enriched by each other. Experiments show that
it performs favorably against existing weakly supervised point cloud
segmentation methods by a large margin on the S3DIS and ScanNet benchmarks. The
project page will be available at https://jimmy15923.github.io/mit_web/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12818">Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models. (arXiv:2310.12818v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weize Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaoyue Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yankai Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1">Ruobing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a></p>
<p>Parameter-shared pre-trained language models (PLMs) have emerged as a
successful approach in resource-constrained environments, enabling substantial
reductions in model storage and memory costs without significant performance
compromise. However, it is important to note that parameter sharing does not
alleviate computational burdens associated with inference, thus impeding its
practicality in situations characterized by limited stringent latency
requirements or computational resources. Building upon neural ordinary
differential equations (ODEs), we introduce a straightforward technique to
enhance the inference efficiency of parameter-shared PLMs. Additionally, we
propose a simple pre-training technique that leads to fully or partially shared
models capable of achieving even greater inference acceleration. The
experimental results demonstrate the effectiveness of our methods on both
autoregressive and autoencoding PLMs, providing novel insights into more
efficient utilization of parameter-shared models in resource-constrained
settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12819">Hybrid Search for Efficient Planning with Completeness Guarantees. (arXiv:2310.12819v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kujanpaa_K/0/1/0/all/0/1">Kalle Kujanp&#xe4;&#xe4;</a>, <a href="http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1">Joni Pajarinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilin_A/0/1/0/all/0/1">Alexander Ilin</a></p>
<p>Solving complex planning problems has been a long-standing challenge in
computer science. Learning-based subgoal search methods have shown promise in
tackling these problems, but they often suffer from a lack of completeness
guarantees, meaning that they may fail to find a solution even if one exists.
In this paper, we propose an efficient approach to augment a subgoal search
method to achieve completeness in discrete action spaces. Specifically, we
augment the high-level search with low-level actions to execute a multi-level
(hybrid) search, which we call complete subgoal search. This solution achieves
the best of both worlds: the practical efficiency of high-level search and the
completeness of low-level search. We apply the proposed search method to a
recently proposed subgoal search algorithm and evaluate the algorithm trained
on offline data on complex planning problems. We demonstrate that our complete
subgoal search not only guarantees completeness but can even improve
performance in terms of search expansions for instances that the high-level
could solve without low-level augmentations. Our approach makes it possible to
apply subgoal-level planning for systems where completeness is a critical
requirement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12823">AgentTuning: Enabling Generalized Agent Abilities for LLMs. (arXiv:2310.12823v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Aohan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingdao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1">Rui Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bowen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuxiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a></p>
<p>Open large language models (LLMs) with great performance in various tasks
have significantly advanced the development of LLMs. However, they are far
inferior to commercial models such as ChatGPT and GPT-4 when acting as agents
to tackle complex tasks in the real world. These agent tasks employ LLMs as the
central controller responsible for planning, memorization, and tool
utilization, necessitating both fine-grained prompting methods and robust LLMs
to achieve satisfactory performance. Though many prompting methods have been
proposed to complete particular agent tasks, there is lack of research focusing
on improving the agent capabilities of LLMs themselves without compromising
their general abilities. In this work, we present AgentTuning, a simple and
general method to enhance the agent abilities of LLMs while maintaining their
general LLM capabilities. We construct AgentInstruct, a lightweight
instruction-tuning dataset containing high-quality interaction trajectories. We
employ a hybrid instruction-tuning strategy by combining AgentInstruct with
open-source instructions from general domains. AgentTuning is used to
instruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show
that AgentTuning enables LLMs' agent capabilities without compromising general
abilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent
tasks, demonstrating generalized agent capabilities. We open source the
AgentInstruct and AgentLM-7B, 13B, and 70B models at
https://github.com/THUDM/AgentTuning , serving open and powerful alternatives
to commercial LLMs for agent tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12846">Physical Information Neural Networks for Solving High-index Differential-algebraic Equation Systems Based on Radau Methods. (arXiv:2310.12846v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Chen_J/0/1/0/all/0/1">Jiasheng Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Tang_J/0/1/0/all/0/1">Juan Tang</a>, <a href="http://arxiv.org/find/math/1/au:+Yan_M/0/1/0/all/0/1">Ming Yan</a>, <a href="http://arxiv.org/find/math/1/au:+Lai_S/0/1/0/all/0/1">Shuai Lai</a>, <a href="http://arxiv.org/find/math/1/au:+Liang_K/0/1/0/all/0/1">Kun Liang</a>, <a href="http://arxiv.org/find/math/1/au:+Lu_J/0/1/0/all/0/1">Jianguang Lu</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_W/0/1/0/all/0/1">Wenqiang Yang</a></p>
<p>As is well known, differential algebraic equations (DAEs), which are able to
describe dynamic changes and underlying constraints, have been widely applied
in engineering fields such as fluid dynamics, multi-body dynamics, mechanical
systems and control theory. In practical physical modeling within these
domains, the systems often generate high-index DAEs. Classical implicit
numerical methods typically result in varying order reduction of numerical
accuracy when solving high-index systems.~Recently, the physics-informed neural
network (PINN) has gained attention for solving DAE systems. However, it faces
challenges like the inability to directly solve high-index systems, lower
predictive accuracy, and weaker generalization capabilities. In this paper, we
propose a PINN computational framework, combined Radau IIA numerical method
with a neural network structure via the attention mechanisms, to directly solve
high-index DAEs. Furthermore, we employ a domain decomposition strategy to
enhance solution accuracy. We conduct numerical experiments with two classical
high-index systems as illustrative examples, investigating how different orders
of the Radau IIA method affect the accuracy of neural network solutions. The
experimental results demonstrate that the PINN based on a 5th-order Radau IIA
method achieves the highest level of system accuracy. Specifically, the
absolute errors for all differential variables remains as low as $10^{-6}$, and
the absolute errors for algebraic variables is maintained at $10^{-5}$,
surpassing the results found in existing literature. Therefore, our method
exhibits excellent computational accuracy and strong generalization
capabilities, providing a feasible approach for the high-precision solution of
larger-scale DAEs with higher indices or challenging high-dimensional partial
differential algebraic equation systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12866">Predicting Ovarian Cancer Treatment Response in Histopathology using Hierarchical Vision Transformers and Multiple Instance Learning. (arXiv:2310.12866v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Breen_J/0/1/0/all/0/1">Jack Breen</a>, <a href="http://arxiv.org/find/eess/1/au:+Allen_K/0/1/0/all/0/1">Katie Allen</a>, <a href="http://arxiv.org/find/eess/1/au:+Zucker_K/0/1/0/all/0/1">Kieran Zucker</a>, <a href="http://arxiv.org/find/eess/1/au:+Hall_G/0/1/0/all/0/1">Geoff Hall</a>, <a href="http://arxiv.org/find/eess/1/au:+Ravikumar_N/0/1/0/all/0/1">Nishant Ravikumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Orsi_N/0/1/0/all/0/1">Nicolas M. Orsi</a></p>
<p>For many patients, current ovarian cancer treatments offer limited clinical
benefit. For some therapies, it is not possible to predict patients' responses,
potentially exposing them to the adverse effects of treatment without any
therapeutic benefit. As part of the automated prediction of treatment
effectiveness in ovarian cancer using histopathological images (ATEC23)
challenge, we evaluated the effectiveness of deep learning to predict whether a
course of treatment including the antiangiogenic drug bevacizumab could
contribute to remission or prevent disease progression for at least 6 months in
a set of 282 histopathology whole slide images (WSIs) from 78 ovarian cancer
patients. Our approach used a pretrained Hierarchical Image Pyramid Transformer
(HIPT) to extract region-level features and an attention-based multiple
instance learning (ABMIL) model to aggregate features and classify whole
slides. The optimal HIPT-ABMIL model had an internal balanced accuracy of 60.2%
+- 2.9% and an AUC of 0.646 +- 0.033. Histopathology-specific model pretraining
was found to be beneficial to classification performance, though hierarchical
transformers were not, with a ResNet feature extractor achieving similar
performance. Due to the dataset being small and highly heterogeneous,
performance was variable across 5-fold cross-validation folds, and there were
some extreme differences between validation and test set performance within
folds. The model did not generalise well to tissue microarrays, with accuracy
worse than random chance. It is not yet clear whether ovarian cancer WSIs
contain information that can be used to accurately predict treatment response,
with further validation using larger, higher-quality datasets required.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12880">TwinPot: Digital Twin-assisted Honeypot for Cyber-Secure Smart Seaports. (arXiv:2310.12880v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yigit_Y/0/1/0/all/0/1">Yagmur Yigit</a>, <a href="http://arxiv.org/find/cs/1/au:+Kinaci_O/0/1/0/all/0/1">Omer Kemal Kinaci</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_T/0/1/0/all/0/1">Trung Q. Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Canberk_B/0/1/0/all/0/1">Berk Canberk</a></p>
<p>The idea of next-generation ports has become more apparent in the last ten
years in response to the challenge posed by the rising demand for efficiency
and the ever-increasing volume of goods. In this new era of intelligent
infrastructure and facilities, it is evident that cyber-security has recently
received the most significant attention from the seaport and maritime
authorities, and it is a primary concern on the agenda of most ports.
Traditional security solutions can be applied to safeguard IoT and
Cyber-Physical Systems (CPS) from harmful entities. Nevertheless, security
researchers can only watch, examine, and learn about the behaviors of attackers
if these solutions operate more transparently. Herein, honeypots are potential
solutions since they offer valuable information about the attackers. It can be
virtual or physical. Virtual honeypots must be more realistic to entice
attackers, necessitating better high-fidelity. To this end, Digital Twin (DT)
technology can be employed to increase the complexity and simulation fidelity
of the honeypots. Seaports can be attacked from both their existing devices and
external devices at the same time. Existing mechanisms are insufficient to
detect external attacks; therefore, the current systems cannot handle attacks
at the desired level. DT and honeypot technologies can be used together to
tackle them. Consequently, we suggest a DT-assisted honeypot, called TwinPot,
for external attacks in smart seaports. Moreover, we propose an intelligent
attack detection mechanism to handle different attack types using DT for
internal attacks. Finally, we build an extensive smart seaport dataset for
internal and external attacks using the MANSIM tool and two existing datasets
to test the performance of our system. We show that under simultaneous internal
and external attacks on the system, our solution successfully detects internal
and external attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12900">Personalized human mobility prediction for HuMob challenge. (arXiv:2310.12900v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Suzuki_M/0/1/0/all/0/1">Masahiro Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Furuta_S/0/1/0/all/0/1">Shomu Furuta</a>, <a href="http://arxiv.org/find/cs/1/au:+Fukazawa_Y/0/1/0/all/0/1">Yusuke Fukazawa</a></p>
<p>We explain the methodology used to create the data submitted to HuMob
Challenge, a data analysis competition for human mobility prediction. We
adopted a personalized model to predict the individual's movement trajectory
from their data, instead of predicting from the overall movement, based on the
hypothesis that human movement is unique to each person. We devised the
features such as the date and time, activity time, days of the week, time of
day, and frequency of visits to POI (Point of Interest). As additional
features, we incorporated the movement of other individuals with similar
behavior patterns through the employment of clustering. The machine learning
model we adopted was the Support Vector Regression (SVR). We performed accuracy
through offline assessment and carried out feature selection and parameter
tuning. Although overall dataset provided consists of 100,000 users trajectory,
our method use only 20,000 target users data, and do not need to use other
80,000 data. Despite the personalized model's traditional feature engineering
approach, this model yields reasonably good accuracy with lower computational
cost.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12902">Experimental Narratives: A Comparison of Human Crowdsourced Storytelling and AI Storytelling. (arXiv:2310.12902v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Begus_N/0/1/0/all/0/1">Nina Begus</a></p>
<p>The paper proposes a framework that combines behavioral and computational
experiments employing fictional prompts as a novel tool for investigating
cultural artifacts and social biases in storytelling both by humans and
generative AI. The study analyzes 250 stories authored by crowdworkers in June
2019 and 80 stories generated by GPT-3.5 and GPT-4 in March 2023 by merging
methods from narratology and inferential statistics. Both crowdworkers and
large language models responded to identical prompts about creating and falling
in love with an artificial human. The proposed experimental paradigm allows a
direct comparison between human and LLM-generated storytelling. Responses to
the Pygmalionesque prompts confirm the pervasive presence of the Pygmalion myth
in the collective imaginary of both humans and large language models. All
solicited narratives present a scientific or technological pursuit. The
analysis reveals that narratives from GPT-3.5 and particularly GPT-4 are more
more progressive in terms of gender roles and sexuality than those written by
humans. While AI narratives can occasionally provide innovative plot twists,
they offer less imaginative scenarios and rhetoric than human-authored texts.
The proposed framework argues that fiction can be used as a window into human
and AI-based collective imaginary and social dimensions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2105.09407">Trilevel and Multilevel Optimization using Monotone Operator Theory. (arXiv:2105.09407v2 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Shafiei_A/0/1/0/all/0/1">Allahkaram Shafiei</a>, <a href="http://arxiv.org/find/math/1/au:+Kungurtsev_V/0/1/0/all/0/1">Vyacheslav Kungurtsev</a>, <a href="http://arxiv.org/find/math/1/au:+Marecek_J/0/1/0/all/0/1">Jakub Marecek</a></p>
<p>We consider rather a general class of multi-level optimization problems,
where a convex objective function is to be minimized subject to constraints of
optimality of nested convex optimization problems. As a special case, we
consider a trilevel optimization problem, where the objective of the two lower
layers consists of a sum of a smooth and a non-smooth term.~Based on
fixed-point theory and related arguments, we present a natural first-order
algorithm and analyze its convergence and rates of convergence in several
regimes of parameters.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2201.13001">Deep Discriminative to Kernel Density Networks for Calibrated Inference. (arXiv:2201.13001v6 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dey_J/0/1/0/all/0/1">Jayanta Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+LeVine_W/0/1/0/all/0/1">Will LeVine</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haoyin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1">Ashwin De Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomita_T/0/1/0/all/0/1">Tyler M. Tomita</a>, <a href="http://arxiv.org/find/cs/1/au:+Geisa_A/0/1/0/all/0/1">Ali Geisa</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1">Tiffany Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Desman_J/0/1/0/all/0/1">Jacob Desman</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1">Joshua T. Vogelstein</a></p>
<p>Deep discriminative approaches like random forests and deep neural networks
have recently found applications in many important real-world scenarios.
However, deploying these learning algorithms in safety-critical applications
raises concerns, particularly when it comes to ensuring confidence calibration
for both in-distribution and out-of-distribution data points. Many popular
methods for in-distribution (ID) calibration, such as isotonic regression and
Platt's sigmoidal regression, exhibit excellent ID calibration performance but
often at the cost of classification accuracy. Moreover, these methods are not
calibrated for the entire feature space, leading to overconfidence in the case
of out-of-distribution (OOD) samples. In this paper, we leveraged the fact that
deep models, including both random forests and deep-nets, learn internal
representations which are unions of polytopes with affine activation functions
to conceptualize them both as partitioning rules of the feature space. We
replace the affine function in each polytope populated by the training data
with a Gaussian kernel. We propose sufficient conditions for our proposed
methods to be consistent estimators of the corresponding class conditional
densities. Moreover, our experiments on both tabular and vision benchmarks show
that the proposed approaches obtain well-calibrated posteriors while mostly
preserving or improving the classification accuracy of the original algorithm
for in-distribution region, and extrapolates beyond the training data to handle
out-of-distribution inputs appropriately.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.14276">Example-based Hypernetworks for Out-of-Distribution Generalization. (arXiv:2203.14276v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Volk_T/0/1/0/all/0/1">Tomer Volk</a>, <a href="http://arxiv.org/find/cs/1/au:+Ben_David_E/0/1/0/all/0/1">Eyal Ben-David</a>, <a href="http://arxiv.org/find/cs/1/au:+Amosy_O/0/1/0/all/0/1">Ohad Amosy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a></p>
<p>As Natural Language Processing (NLP) algorithms continually achieve new
milestones, out-of-distribution generalization remains a significant challenge.
This paper addresses the issue of multi-source adaptation for unfamiliar
domains: We leverage labeled data from multiple source domains to generalize to
unknown target domains at training. Our innovative framework employs
example-based Hypernetwork adaptation: a T5 encoder-decoder initially generates
a unique signature from an input example, embedding it within the source
domains' semantic space. This signature is subsequently utilized by a
Hypernetwork to generate the task classifier's weights. We evaluated our method
across two tasks - sentiment classification and natural language inference - in
29 adaptation scenarios, where it outpaced established algorithms. In an
advanced version, the signature also enriches the input example's
representation. We also compare our finetuned architecture to few-shot GPT-3,
demonstrating its effectiveness in essential use cases. To our knowledge, this
marks the first application of Hypernetworks to the adaptation for unknown
domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.07162">Category-Agnostic 6D Pose Estimation with Conditional Neural Processes. (arXiv:2206.07162v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yumeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1">Ning Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1">Hanna Ziesche</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a></p>
<p>We present a novel meta-learning approach for 6D pose estimation on unknown
objects. In contrast to ``instance-level" and ``category-level" pose estimation
methods, our algorithm learns object representation in a category-agnostic way,
which endows it with strong generalization capabilities across object
categories. Specifically, we employ a neural process-based meta-learning
approach to train an encoder to capture texture and geometry of an object in a
latent representation, based on very few RGB-D images and ground-truth
keypoints. The latent representation is then used by a simultaneously
meta-trained decoder to predict the 6D pose of the object in new images.
Furthermore, we propose a novel geometry-aware decoder for the keypoint
prediction using a Graph Neural Network (GNN), which explicitly takes geometric
constraints specific to each object into consideration. To evaluate our
algorithm, extensive experiments are conducted on the \linemod dataset, and on
our new fully-annotated synthetic datasets generated from Multiple Categories
in Multiple Scenes (MCMS). Experimental results demonstrate that our model
performs well on unseen objects with very different shapes and appearances.
Remarkably, our model also shows robust performance on occluded scenes although
trained fully on data without occlusion. To our knowledge, this is the first
work exploring \textbf{cross-category level} 6D pose estimation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.07940">When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting. (arXiv:2206.07940v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1">Harshavardhan Kamarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1">Lingkai Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1">Alexander Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1">B. Aditya Prakash</a></p>
<p>Probabilistic hierarchical time-series forecasting is an important variant of
time-series forecasting, where the goal is to model and forecast multivariate
time-series that have underlying hierarchical relations. Most methods focus on
point predictions and do not provide well-calibrated probabilistic forecasts
distributions. Recent state-of-art probabilistic forecasting methods also
impose hierarchical relations on point predictions and samples of distribution
which does not account for coherency of forecast distributions. Previous works
also silently assume that datasets are always consistent with given
hierarchical relations and do not adapt to real-world datasets that show
deviation from this assumption. We close both these gap and propose PROFHiT,
which is a fully probabilistic hierarchical forecasting model that jointly
models forecast distribution of entire hierarchy. PROFHiT uses a flexible
probabilistic Bayesian approach and introduces a novel Distributional Coherency
regularization to learn from hierarchical relations for entire forecast
distribution that enables robust and calibrated forecasts as well as adapt to
datasets of varying hierarchical consistency. On evaluating PROFHiT over wide
range of datasets, we observed 41-88% better performance in accuracy and
significantly better calibration. Due to modeling the coherency over full
distribution, we observed that PROFHiT can robustly provide reliable forecasts
even if up to 10% of input time-series data is missing where other methods'
performance severely degrade by over 70%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.07025">Learning to translate by learning to communicate. (arXiv:2207.07025v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Downey_C/0/1/0/all/0/1">C.M. Downey</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xuhui Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Leo Z. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinert_Threlkeld_S/0/1/0/all/0/1">Shane Steinert-Threlkeld</a></p>
<p>We formulate and test a technique to use Emergent Communication (EC) with a
pre-trained multilingual model to improve on modern Unsupervised NMT systems,
especially for low-resource languages. It has been argued that the current
dominant paradigm in NLP of pre-training on text-only corpora will not yield
robust natural language understanding systems, and the need for grounded,
goal-oriented, and interactive language learning has been high lighted. In our
approach, we embed a multilingual model (mBART, Liu et al., 2020) into an EC
image-reference game, in which the model is incentivized to use multilingual
generations to accomplish a vision-grounded task. The hypothesis is that this
will align multiple languages to a shared task space. We present two variants
of EC Fine-Tuning (Steinert-Threlkeld et al., 2022), one of which outperforms a
backtranslation-only baseline in all four languages investigated, including the
low-resource language Nepali.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.06348">Can Brain Signals Reveal Inner Alignment with Human Languages?. (arXiv:2208.06348v4 [q-bio.NC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Han_W/0/1/0/all/0/1">William Han</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Qiu_J/0/1/0/all/0/1">Jielin Qiu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_J/0/1/0/all/0/1">Jiacheng Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xu_M/0/1/0/all/0/1">Mengdi Xu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Weber_D/0/1/0/all/0/1">Douglas Weber</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a></p>
<p>Brain Signals, such as Electroencephalography (EEG), and human languages have
been widely explored independently for many downstream tasks, however, the
connection between them has not been well explored. In this study, we explore
the relationship and dependency between EEG and language. To study at the
representation level, we introduced \textbf{MTAM}, a \textbf{M}ultimodal
\textbf{T}ransformer \textbf{A}lignment \textbf{M}odel, to observe coordinated
representations between the two modalities. We used various relationship
alignment-seeking techniques, such as Canonical Correlation Analysis and
Wasserstein Distance, as loss functions to transfigure features. On downstream
applications, sentiment analysis and relation detection, we achieved new
state-of-the-art results on two datasets, ZuCo and K-EmoCon. Our method
achieved an F1-score improvement of 1.7% on K-EmoCon and 9.3% on Zuco datasets
for sentiment analysis, and 7.4% on ZuCo for relation detection. In addition,
we provide interpretations of the performance improvement: (1) feature
distribution shows the effectiveness of the alignment module for discovering
and encoding the relationship between EEG and language; (2) alignment weights
show the influence of different language semantics as well as EEG frequency
features; (3) brain topographical maps provide an intuitive demonstration of
the connectivity in the brain regions. Our code is available at
\url{https://github.com/Jason-Qiu/EEG_Language_Alignment}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.04030">Unraveling the Connections between Privacy and Certified Robustness in Federated Learning Against Poisoning Attacks. (arXiv:2209.04030v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Chulin Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yunhui Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qinbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1">Sanmi Koyejo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a></p>
<p>Federated learning (FL) provides an efficient paradigm to jointly train a
global model leveraging data from distributed users. As local training data
comes from different users who may not be trustworthy, several studies have
shown that FL is vulnerable to poisoning attacks. Meanwhile, to protect the
privacy of local users, FL is usually trained in a differentially private way
(DPFL). Thus, in this paper, we ask: What are the underlying connections
between differential privacy and certified robustness in FL against poisoning
attacks? Can we leverage the innate privacy property of DPFL to provide
certified robustness for FL? Can we further improve the privacy of FL to
improve such robustness certification? We first investigate both user-level and
instance-level privacy of FL and provide formal privacy analysis to achieve
improved instance-level privacy. We then provide two robustness certification
criteria: certified prediction and certified attack inefficacy for DPFL on both
user and instance levels. Theoretically, we provide the certified robustness of
DPFL based on both criteria given a bounded number of adversarial users or
instances. Empirically, we conduct extensive experiments to verify our theories
under a range of poisoning attacks on different datasets. We find that
increasing the level of privacy protection in DPFL results in stronger
certified attack inefficacy; however, it does not necessarily lead to a
stronger certified prediction. Thus, achieving the optimal certified prediction
requires a proper balance between privacy and utility loss.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.05015">Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v5 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lim_M/0/1/0/all/0/1">Michael H. Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Becker_T/0/1/0/all/0/1">Tyler J. Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1">Mykel J. Kochenderfer</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomlin_C/0/1/0/all/0/1">Claire J. Tomlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunberg_Z/0/1/0/all/0/1">Zachary N. Sunberg</a></p>
<p>Partially observable Markov decision processes (POMDPs) provide a flexible
representation for real-world decision and control problems. However, POMDPs
are notoriously difficult to solve, especially when the state and observation
spaces are continuous or hybrid, which is often the case for physical systems.
While recent online sampling-based POMDP algorithms that plan with observation
likelihood weighting have shown practical effectiveness, a general theory
characterizing the approximation error of the particle filtering techniques
that these algorithms use has not previously been proposed. Our main
contribution is bounding the error between any POMDP and its corresponding
finite sample particle belief MDP (PB-MDP) approximation. This fundamental
bridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP
algorithm to a POMDP by solving the corresponding particle belief MDP, thereby
extending the convergence guarantees of the MDP algorithm to the POMDP.
Practically, this is implemented by using the particle filter belief transition
model as the generative model for the MDP solver. While this requires access to
the observation density model from the POMDP, it only increases the transition
sampling complexity of the MDP solver by a factor of $\mathcal{O}(C)$, where
$C$ is the number of particles. Thus, when combined with sparse sampling MDP
algorithms, this approach can yield algorithms for POMDPs that have no direct
theoretical dependence on the size of the state and observation spaces. In
addition to our theoretical contribution, we perform five numerical experiments
on benchmark POMDPs to demonstrate that a simple MDP algorithm adapted using
PB-MDP approximation, Sparse-PFT, achieves performance competitive with other
leading continuous observation POMDP solvers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.13623">Reinforcement Learning and Bandits for Speech and Language Processing: Tutorial, Review and Outlook. (arXiv:2210.13623v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Baihan Lin</a></p>
<p>In recent years, reinforcement learning and bandits have transformed a wide
range of real-world applications including healthcare, finance, recommendation
systems, robotics, and last but not least, the speech and natural language
processing. While most speech and language applications of reinforcement
learning algorithms are centered around improving the training of deep neural
networks with its flexible optimization properties, there are still many
grounds to explore to utilize the benefits of reinforcement learning, such as
its reward-driven adaptability, state representations, temporal structures and
generalizability. In this survey, we present an overview of recent advancements
of reinforcement learning and bandits, and discuss how they can be effectively
employed to solve speech and natural language processing problems with models
that are adaptive, interactive and scalable.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.08238">Exploiting Contrastive Learning and Numerical Evidence for Improving Confusing Legal Judgment Prediction. (arXiv:2211.08238v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1">Leilei Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baokui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1">Kun Kuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yating Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1">Anh Tuan Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a></p>
<p>Given the fact description text of a legal case, legal judgment prediction
(LJP) aims to predict the case's charge, law article and penalty term. A core
problem of LJP is how to distinguish confusing legal cases, where only subtle
text differences exist. Previous studies fail to distinguish different
classification errors with a standard cross-entropy classification loss, and
ignore the numbers in the fact description for predicting the term of penalty.
To tackle these issues, in this work, first, we propose a moco-based supervised
contrastive learning to learn distinguishable representations, and explore the
best strategy to construct positive example pairs to benefit all three subtasks
of LJP simultaneously. Second, in order to exploit the numbers in legal cases
for predicting the penalty terms of certain cases, we further enhance the
representation of the fact description with extracted crime amounts which are
encoded by a pre-trained numeracy model. Extensive experiments on public
benchmarks show that the proposed method achieves new state-of-the-art results,
especially on confusing legal cases. Ablation studies also demonstrate the
effectiveness of each component.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.07469">Learning threshold neurons via the &quot;edge of stability&quot;. (arXiv:2212.07469v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahn_K/0/1/0/all/0/1">Kwangjun Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1">S&#xe9;bastien Bubeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Chewi_S/0/1/0/all/0/1">Sinho Chewi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yin Tat Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Suarez_F/0/1/0/all/0/1">Felipe Suarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a></p>
<p>Existing analyses of neural network training often operate under the
unrealistic assumption of an extremely small learning rate. This lies in stark
contrast to practical wisdom and empirical studies, such as the work of J.
Cohen et al. (ICLR 2021), which exhibit startling new phenomena (the "edge of
stability" or "unstable convergence") and potential benefits for generalization
in the large learning rate regime. Despite a flurry of recent works on this
topic, however, the latter effect is still poorly understood. In this paper, we
take a step towards understanding genuinely non-convex training dynamics with
large learning rates by performing a detailed analysis of gradient descent for
simplified models of two-layer neural networks. For these models, we provably
establish the edge of stability phenomenon and discover a sharp phase
transition for the step size below which the neural network fails to learn
"threshold-like" neurons (i.e., neurons with a non-zero first-layer bias). This
elucidates one possible mechanism by which the edge of stability can in fact
lead to better generalization, as threshold neurons are basic building blocks
with useful inductive bias for many tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.08731">Multi-person 3D pose estimation from unlabelled data. (arXiv:2212.08731v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Criado_D/0/1/0/all/0/1">Daniel Rodriguez-Criado</a>, <a href="http://arxiv.org/find/cs/1/au:+Bachiller_P/0/1/0/all/0/1">Pilar Bachiller</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogiatzis_G/0/1/0/all/0/1">George Vogiatzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Manso_L/0/1/0/all/0/1">Luis J. Manso</a></p>
<p>Its numerous applications make multi-human 3D pose estimation a remarkably
impactful area of research. Nevertheless, assuming a multiple-view system
composed of several regular RGB cameras, 3D multi-pose estimation presents
several challenges. First of all, each person must be uniquely identified in
the different views to separate the 2D information provided by the cameras.
Secondly, the 3D pose estimation process from the multi-view 2D information of
each person must be robust against noise and potential occlusions in the
scenario. In this work, we address these two challenges with the help of deep
learning. Specifically, we present a model based on Graph Neural Networks
capable of predicting the cross-view correspondence of the people in the
scenario along with a Multilayer Perceptron that takes the 2D points to yield
the 3D poses of each person. These two models are trained in a self-supervised
manner, thus avoiding the need for large datasets with 3D annotations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.09561">Large Language Models are Better Reasoners with Self-Verification. (arXiv:2212.09561v5 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Weng_Y/0/1/0/all/0/1">Yixuan Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Minjun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shizhu He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shengping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Bin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jun Zhao</a></p>
<p>Recently, with the chain of thought (CoT) prompting, large language models
(LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural
language processing tasks such as arithmetic, commonsense, and logical
reasoning. However, LLMs with CoT require multi-step prompting and multi-token
prediction, which is highly sensitive to individual mistakes and vulnerable to
error accumulation. The above issues make the LLMs need the ability to verify
the answers. In fact, after inferring conclusions in some thinking decision
tasks, people often check them by re-verifying steps to avoid some mistakes. In
this paper, we propose and prove that LLMs also have similar self-verification
abilities. We take the conclusion obtained by CoT as one of the conditions for
solving the original problem. By performing a backward verification of the
answers that LLM deduced for itself, we can obtain interpretable answer
validation scores to select the candidate answer with the highest score.
Experimental results demonstrate that the proposed method can improve the
reasoning performance on various arithmetic, commonsense, and logical reasoning
datasets. Our code is publicly available at:
https://github.com/WENGSYX/Self-Verification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.09724">A Retrieve-and-Read Framework for Knowledge Graph Link Prediction. (arXiv:2212.09724v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1">Vardaan Pahuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boshi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1">Hugo Latapie</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasa_J/0/1/0/all/0/1">Jayanth Srinivasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yu Su</a></p>
<p>Knowledge graph (KG) link prediction aims to infer new facts based on
existing facts in the KG. Recent studies have shown that using the graph
neighborhood of a node via graph neural networks (GNNs) provides more useful
information compared to just using the query information. Conventional GNNs for
KG link prediction follow the standard message-passing paradigm on the entire
KG, which leads to superfluous computation, over-smoothing of node
representations, and also limits their expressive power. On a large scale, it
becomes computationally expensive to aggregate useful information from the
entire KG for inference. To address the limitations of existing KG link
prediction frameworks, we propose a novel retrieve-and-read framework, which
first retrieves a relevant subgraph context for the query and then jointly
reasons over the context and the query with a high-capacity reader. As part of
our exemplar instantiation for the new framework, we propose a novel
Transformer-based GNN as the reader, which incorporates graph-based attention
structure and cross-attention between query and context for deep fusion. This
simple yet effective design enables the model to focus on salient context
information relevant to the query. Empirical results on two standard KG link
prediction datasets demonstrate the competitive performance of the proposed
method. Furthermore, our analysis yields valuable insights for designing
improved retrievers within the framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.10784">Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical Relation Extraction?. (arXiv:2212.10784v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiashu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Mingyu Derek Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Muhao Chen</a></p>
<p>Two key obstacles in biomedical relation extraction (RE) are the scarcity of
annotations and the prevalence of instances without explicitly pre-defined
labels due to low annotation coverage. Existing approaches, which treat
biomedical RE as a multi-class classification task, often result in poor
generalization in low-resource settings and do not have the ability to make
selective prediction on unknown cases but give a guess from seen relations,
hindering the applicability of those approaches. We present NBR, which converts
biomedical RE as natural language inference formulation through indirect
supervision. By converting relations to natural language hypotheses, NBR is
capable of exploiting semantic cues to alleviate annotation scarcity. By
incorporating a ranking-based loss that implicitly calibrates abstinent
instances, NBR learns a clearer decision boundary and is instructed to abstain
on uncertain instances. Extensive experiments on three widely-used biomedical
RE benchmarks, namely ChemProt, DDI and GAD, verify the effectiveness of NBR in
both full-set and low-resource regimes. Our analysis demonstrates that indirect
supervision benefits biomedical RE even when a domain gap exists, and combining
NLI knowledge with biomedical knowledge leads to the best performance gains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.01328">IC3: Image Captioning by Committee Consensus. (arXiv:2302.01328v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chan_D/0/1/0/all/0/1">David M. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Myers_A/0/1/0/all/0/1">Austin Myers</a>, <a href="http://arxiv.org/find/cs/1/au:+Vijayanarasimhan_S/0/1/0/all/0/1">Sudheendra Vijayanarasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ross_D/0/1/0/all/0/1">David A. Ross</a>, <a href="http://arxiv.org/find/cs/1/au:+Canny_J/0/1/0/all/0/1">John Canny</a></p>
<p>If you ask a human to describe an image, they might do so in a thousand
different ways. Traditionally, image captioning models are trained to generate
a single "best" (most like a reference) image caption. Unfortunately, doing so
encourages captions that are "informationally impoverished," and focus on only
a subset of the possible details, while ignoring other potentially useful
information in the scene. In this work, we introduce a simple, yet novel,
method: "Image Captioning by Committee Consensus" (IC3), designed to generate a
single caption that captures high-level details from several annotator
viewpoints. Humans rate captions produced by IC3 at least as helpful as
baseline SOTA models more than two thirds of the time, and IC3 can improve the
performance of SOTA automated recall systems by up to 84%, outperforming single
human-generated reference captions, and indicating significant improvements
over SOTA approaches for visual description. Code is available at
https://davidmchan.github.io/caption-by-committee/
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.06762">Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study. (arXiv:2304.06762v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAfee_L/0/1/0/all/0/1">Lawrence McAfee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1">Oleksii Kuchaiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a></p>
<p>Large decoder-only language models (LMs) can be largely improved in terms of
perplexity by retrieval (e.g., RETRO), but its impact on text generation
quality and downstream task accuracy is unclear. Thus, it is still an open
question: shall we pretrain large autoregressive LMs with retrieval? To answer
it, we perform a comprehensive study on a scalable pre-trained
retrieval-augmented LM (i.e., RETRO) compared with standard GPT and
retrieval-augmented GPT incorporated at fine-tuning or inference stages. We
first provide the recipe to reproduce RETRO up to 9.5B parameters while
retrieving a text corpus with 330B tokens. Based on that, we have the following
novel findings: i) RETRO outperforms GPT on text generation with much less
degeneration (i.e., repetition), moderately higher factual accuracy, and
slightly lower toxicity with a nontoxic retrieval database. ii) On the LM
Evaluation Harness benchmark, RETRO largely outperforms GPT on
knowledge-intensive tasks, but is on par with GPT on other tasks. Furthermore,
we introduce a simple variant of the model, RETRO++, which largely improves
open-domain QA results of original RETRO (e.g., EM score +8.6 on Natural
Question) and significantly outperforms retrieval-augmented GPT in both
fine-tuning and zero-shot evaluation settings. Our findings highlight the
promising direction of pretraining autoregressive LMs with retrieval as future
foundation models. We release our implementation at:
https://github.com/NVIDIA/Megatron-LM#retro.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.07063">Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors. (arXiv:2304.07063v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hang Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zihao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yangqiu Song</a></p>
<p>Reasoning on knowledge graphs is a challenging task because it utilizes
observed information to predict the missing one. Particularly, answering
complex queries based on first-order logic is one of the crucial tasks to
verify learning to reason abilities for generalization and composition.
Recently, the prevailing method is query embedding which learns the embedding
of a set of entities and treats logic operations as set operations and has
shown great empirical success. Though there has been much research following
the same formulation, many of its claims lack a formal and systematic
inspection. In this paper, we rethink this formulation and justify many of the
previous claims by characterizing the scope of queries investigated previously
and precisely identifying the gap between its formulation and its goal, as well
as providing complexity analysis for the currently investigated queries.
Moreover, we develop a new dataset containing ten new types of queries with
features that have never been considered and therefore can provide a thorough
investigation of complex queries. Finally, we propose a new neural-symbolic
method, Fuzzy Inference with Truth value (FIT), where we equip the neural link
predictors with fuzzy logic theory to support end-to-end learning using complex
queries with provable reasoning capability. Empirical results show that our
method outperforms previous methods significantly in the new dataset and also
surpasses previous methods in the existing dataset at the same time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.08503">A Scalable Test Problem Generator for Sequential Transfer Optimization. (arXiv:2304.08503v4 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1">Xiaoming Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cuie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Liang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Linqi Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1">Kay Chen Tan</a></p>
<p>Sequential transfer optimization (STO), which aims to improve the
optimization performance on a task of interest by exploiting the knowledge
captured from several previously-solved optimization tasks stored in a
database, has been gaining increasing research attention over the years.
However, despite the remarkable advances in algorithm design, the development
of a systematic benchmark suite for comprehensive comparisons of STO algorithms
received far less attention. Existing test problems are either simply generated
by assembling other benchmark functions or extended from specific practical
problems with limited scalability. The relationships between the optimal
solutions of the source and target tasks in these problems are also often
manually configured, limiting their ability to model different similarity
relationships presented in real-world problems. Consequently, the good
performance achieved by an algorithm on these problems might be biased and hard
to be generalized to other problems. In light of the above, in this study, we
first introduce four concepts for characterizing STO problems and present an
important problem feature, namely similarity distribution, which quantitatively
delineates the relationship between the optima of the source and target tasks.
Then, we present the general design guidelines of STO problems and a particular
STO problem generator with good scalability. Specifically, the similarity
distribution of a problem can be easily customized, enabling a continuous
spectrum of representation of the diverse similarity relationships of
real-world problems. Lastly, a benchmark suite with 12 STO problems featured by
a variety of customized similarity relationships is developed using the
proposed generator. The source code of the problem generator is available at
https://github.com/XmingHsueh/STOP-G.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.10557">An Introduction to Transformers. (arXiv:2304.10557v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1">Richard E. Turner</a></p>
<p>The transformer is a neural network component that can be used to learn
useful representations of sequences or sets of data-points. The transformer has
driven recent advances in natural language processing, computer vision, and
spatio-temporal modelling. There are many introductions to transformers, but
most do not contain precise mathematical descriptions of the architecture and
the intuitions behind the design choices are often also missing. Moreover, as
research takes a winding path, the explanations for the components of the
transformer can be idiosyncratic. In this note we aim for a mathematically
precise, intuitive, and clean description of the transformer architecture. We
will not discuss training as this is rather standard. We assume that the reader
is familiar with fundamental topics in machine learning including multi-layer
perceptrons, linear transformations, softmax functions and basic probability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.12410">PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques. (arXiv:2304.12410v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sabry_M/0/1/0/all/0/1">Mohammed Sabry</a>, <a href="http://arxiv.org/find/cs/1/au:+Belz_A/0/1/0/all/0/1">Anya Belz</a></p>
<p>Recent parameter-efficient finetuning (PEFT) techniques aim to improve over
the considerable cost of fully finetuning large pretrained language models
(PLM). As different PEFT techniques proliferate, it is becoming difficult to
compare them, in particular in terms of (i) the structure and functionality
they add to the PLM, (ii) the different types and degrees of efficiency
improvements achieved, (iii) performance at different downstream tasks, and
(iv) how differences in structure and functionality relate to efficiency and
task performance. To facilitate such comparisons, this paper presents a
reference architecture which standardises aspects shared by different PEFT
techniques, while isolating differences to specific locations and interactions
with the standard components. Through this process of standardising and
isolating differences, a modular view of PEFT techniques emerges, supporting
not only direct comparison of different techniques and their efficiency and
task performance, but also systematic exploration of reusability and
composability of the different types of finetuned modules. We demonstrate how
the reference architecture can be applied to understand properties and relative
advantages of PEFT techniques, hence to inform selection of techniques for
specific tasks, and design choices for new PEFT techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.03495">Automatic Prompt Optimization with &quot;Gradient Descent&quot; and Beam Search. (arXiv:2305.03495v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1">Reid Pryzant</a>, <a href="http://arxiv.org/find/cs/1/au:+Iter_D/0/1/0/all/0/1">Dan Iter</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jerry Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yin Tat Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chenguang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Michael Zeng</a></p>
<p>Large Language Models (LLMs) have shown impressive performance as general
purpose agents, but their abilities remain highly dependent on prompts which
are hand written with onerous trial-and-error effort. We propose a simple and
nonparametric solution to this problem, Automatic Prompt Optimization (APO),
which is inspired by numerical gradient descent to automatically improve
prompts, assuming access to training data and an LLM API. The algorithm uses
minibatches of data to form natural language "gradients" that criticize the
current prompt. The gradients are then "propagated" into the prompt by editing
the prompt in the opposite semantic direction of the gradient. These gradient
descent steps are guided by a beam search and bandit selection procedure which
significantly improves algorithmic efficiency. Preliminary results across three
benchmark NLP tasks and the novel problem of LLM jailbreak detection suggest
that Automatic Prompt Optimization can outperform prior prompt editing
techniques and improve an initial prompt's performance by up to 31%, by using
data to rewrite vague task descriptions into more precise annotation
instructions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.05896">A Black-Box Attack on Code Models via Representation Nearest Neighbor Search. (arXiv:2305.05896v3 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Wei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1">Qiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shangqing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiaofei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Traon_Y/0/1/0/all/0/1">Yves Le Traon</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a></p>
<p>Existing methods for generating adversarial code examples face several
challenges: limted availability of substitute variables, high verification
costs for these substitutes, and the creation of adversarial samples with
noticeable perturbations. To address these concerns, our proposed approach,
RNNS, uses a search seed based on historical attacks to find potential
adversarial substitutes. Rather than directly using the discrete substitutes,
they are mapped to a continuous vector space using a pre-trained variable name
encoder. Based on the vector representation, RNNS predicts and selects better
substitutes for attacks. We evaluated the performance of RNNS across six coding
tasks encompassing three programming languages: Java, Python, and C. We
employed three pre-trained code models (CodeBERT, GraphCodeBERT, and CodeT5)
that resulted in a cumulative of 18 victim models. The results demonstrate that
RNNS outperforms baselines in terms of ASR and QT. Furthermore, the
perturbation of adversarial examples introduced by RNNS is smaller compared to
the baselines in terms of the number of replaced variables and the change in
variable length. Lastly, our experiments indicate that RNNS is efficient in
attacking defended models and can be employed for adversarial training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.12295">Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning. (arXiv:2305.12295v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1">Liangming Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1">Alon Albalak</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a></p>
<p>Large Language Models (LLMs) have shown human-like reasoning abilities but
still struggle with complex logical problems. This paper introduces a novel
framework, Logic-LM, which integrates LLMs with symbolic solvers to improve
logical problem-solving. Our method first utilizes LLMs to translate a natural
language problem into a symbolic formulation. Afterward, a deterministic
symbolic solver performs inference on the formulated problem. We also introduce
a self-refinement module, which utilizes the symbolic solver's error messages
to revise symbolic formalizations. We demonstrate Logic-LM's effectiveness on
five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO,
LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant
performance boost of 39.2% over using LLM alone with standard prompting and
18.4% over LLM with chain-of-thought prompting. Our findings suggest that
Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for
faithful logical reasoning. Code and data are publicly available at
https://github.com/teacherpeterpan/Logic-LLM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.12818">Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs. (arXiv:2305.12818v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yihong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Haotian Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Weissweiler_L/0/1/0/all/0/1">Leonie Weissweiler</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_R/0/1/0/all/0/1">Renhao Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a></p>
<p>In comparative linguistics, colexification refers to the phenomenon of a
lexical form conveying two or more distinct meanings. Existing work on
colexification patterns relies on annotated word lists, limiting scalability
and usefulness in NLP. In contrast, we identify colexification patterns of more
than 2,000 concepts across 1,335 languages directly from an unannotated
parallel corpus. We then propose simple and effective methods to build
multilingual graphs from the colexification patterns: ColexNet and ColexNet+.
ColexNet's nodes are concepts and its edges are colexifications. In ColexNet+,
concept nodes are additionally linked through intermediate nodes, each
representing an ngram in one of 1,334 languages. We use ColexNet+ to train
$\overrightarrow{\mbox{ColexNet+}}$, high-quality multilingual embeddings that
are well-suited for transfer learning. In our experiments, we first show that
ColexNet achieves high recall on CLICS, a dataset of crosslingual
colexifications. We then evaluate $\overrightarrow{\mbox{ColexNet+}}$ on
roundtrip translation, sentence retrieval and sentence classification and show
that our embeddings surpass several transfer learning baselines. This
demonstrates the benefits of using colexification as a source of information in
multilingual NLP.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.14381">Connecting Multi-modal Contrastive Representations. (arXiv:2305.14381v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zehan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xize Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haifeng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiageng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1">Li Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_A/0/1/0/all/0/1">Aoxiong Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhou Zhao</a></p>
<p>Multi-modal Contrastive Representation learning aims to encode different
modalities into a semantically aligned shared space. This paradigm shows
remarkable generalization ability on numerous downstream tasks across various
modalities. However, the reliance on massive high-quality data pairs limits its
further development on more modalities. This paper proposes a novel
training-efficient method for learning MCR without paired data called
Connecting Multi-modal Contrastive Representations (C-MCR). Specifically, given
two existing MCRs pre-trained on (A, B) and (B, C) modality pairs, we project
them to a new space and use the data from the overlapping modality B to
aligning the two MCRs in the new space. Meanwhile, since the modality pairs (A,
B) and (B, C) are already aligned within each MCR, the connection learned by
overlapping modality can also be transferred to non-overlapping modality pair
(A, C). To unleash the potential of C-MCR, we further introduce a
semantic-enhanced inter- and intra-MCR connection method. We first enhance the
semantic consistency and completion of embeddings across different modalities
for more robust alignment. Then we utilize the inter-MCR alignment to establish
the connection, and employ the intra-MCR alignment to better maintain the
connection for inputs from non-overlapping modalities. To demonstrate the
effectiveness of C-MCR, we connect CLIP and CLAP via texts to derive
audio-visual representations, and integrate CLIP and ULIP via images for
3D-language representations. Remarkably, without using any paired data, C-MCR
for audio-visual achieves state-of-the-art performance on audio-image
retrieval, audio-visual source localization, and counterfactual audio-image
recognition tasks. Furthermore, C-MCR for 3D-language also attains advanced
zero-shot 3D point cloud classification accuracy on ModelNet40.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16291">Voyager: An Open-Ended Embodied Agent with Large Language Models. (arXiv:2305.16291v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuqi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yunfan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandlekar_A/0/1/0/all/0/1">Ajay Mandlekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Linxi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a></p>
<p>We introduce Voyager, the first LLM-powered embodied lifelong learning agent
in Minecraft that continuously explores the world, acquires diverse skills, and
makes novel discoveries without human intervention. Voyager consists of three
key components: 1) an automatic curriculum that maximizes exploration, 2) an
ever-growing skill library of executable code for storing and retrieving
complex behaviors, and 3) a new iterative prompting mechanism that incorporates
environment feedback, execution errors, and self-verification for program
improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses
the need for model parameter fine-tuning. The skills developed by Voyager are
temporally extended, interpretable, and compositional, which compounds the
agent's abilities rapidly and alleviates catastrophic forgetting. Empirically,
Voyager shows strong in-context lifelong learning capability and exhibits
exceptional proficiency in playing Minecraft. It obtains 3.3x more unique
items, travels 2.3x longer distances, and unlocks key tech tree milestones up
to 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill
library in a new Minecraft world to solve novel tasks from scratch, while other
techniques struggle to generalize. We open-source our full codebase and prompts
at https://voyager.minedojo.org/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16986">NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models. (arXiv:2305.16986v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1">Gengze Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yicong Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a></p>
<p>Trained with an unprecedented scale of data, large language models (LLMs)
like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities
from model scaling. Such a trend underscored the potential of training LLMs
with unlimited language data, advancing the development of a universal embodied
agent. In this work, we introduce the NavGPT, a purely LLM-based
instruction-following navigation agent, to reveal the reasoning capability of
GPT models in complex embodied scenes by performing zero-shot sequential action
prediction for vision-and-language navigation (VLN). At each step, NavGPT takes
the textual descriptions of visual observations, navigation history, and future
explorable directions as inputs to reason the agent's current status, and makes
the decision to approach the target. Through comprehensive experiments, we
demonstrate NavGPT can explicitly perform high-level planning for navigation,
including decomposing instruction into sub-goal, integrating commonsense
knowledge relevant to navigation task resolution, identifying landmarks from
observed scenes, tracking navigation progress, and adapting to exceptions with
plan adjustment. Furthermore, we show that LLMs is capable of generating
high-quality navigational instructions from observations and actions along a
path, as well as drawing accurate top-down metric trajectory given the agent's
navigation history. Despite the performance of using NavGPT to zero-shot R2R
tasks still falling short of trained models, we suggest adapting multi-modality
inputs for LLMs to use as visual navigation agents and applying the explicit
reasoning of LLMs to benefit learning-based models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.00477">Make Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1">Baohao Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shaomu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1">Christof Monz</a></p>
<p>Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs)
has emerged as a highly successful approach, with training only a small number
of parameters without sacrificing performance and becoming the de-facto
learning paradigm with the increasing size of PLMs. However, existing PEFT
methods are not memory-efficient, because they still require caching most of
the intermediate activations for the gradient calculation, akin to fine-tuning.
One effective way to reduce the activation memory is to apply a reversible
model, so the intermediate activations are not necessary to be cached and can
be recomputed. Nevertheless, modifying a PLM to its reversible variant is not
straightforward, since the reversible model has a distinct architecture from
the currently released PLMs. In this paper, we first investigate what is a key
factor for the success of existing PEFT methods, and realize that it's
essential to preserve the PLM's starting point when initializing a PEFT method.
With this finding, we propose memory-efficient fine-tuning (MEFT) that inserts
adapters into a PLM, preserving the PLM's starting point and making it
reversible without additional pre-training. We evaluate MEFT on the GLUE
benchmark and five question-answering tasks with various backbones, BERT,
RoBERTa, BART and OPT. MEFT significantly reduces the activation memory up to
84% of full fine-tuning with a negligible amount of trainable parameters.
Moreover, MEFT achieves the same score on GLUE and a comparable score on the
question-answering tasks as full fine-tuning. A similar finding is also
observed for the image classification task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.03659">Schema First! Learn Versatile Knowledge Graph Embeddings by Capturing Semantics with MASCHInE. (arXiv:2306.03659v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hubert_N/0/1/0/all/0/1">Nicolas Hubert</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1">Heiko Paulheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Monnin_P/0/1/0/all/0/1">Pierre Monnin</a>, <a href="http://arxiv.org/find/cs/1/au:+Brun_A/0/1/0/all/0/1">Armelle Brun</a>, <a href="http://arxiv.org/find/cs/1/au:+Monticolo_D/0/1/0/all/0/1">Davy Monticolo</a></p>
<p>Knowledge graph embedding models (KGEMs) have gained considerable traction in
recent years. These models learn a vector representation of knowledge graph
entities and relations, a.k.a. knowledge graph embeddings (KGEs). Learning
versatile KGEs is desirable as it makes them useful for a broad range of tasks.
However, KGEMs are usually trained for a specific task, which makes their
embeddings task-dependent. In parallel, the widespread assumption that KGEMs
actually create a semantic representation of the underlying entities and
relations (e.g., project similar entities closer than dissimilar ones) has been
challenged. In this work, we design heuristics for generating protographs --
small, modified versions of a KG that leverage RDF/S information. The learnt
protograph-based embeddings are meant to encapsulate the semantics of a KG, and
can be leveraged in learning KGEs that, in turn, also better capture semantics.
Extensive experiments on various evaluation benchmarks demonstrate the
soundness of this approach, which we call Modular and Agnostic SCHema-based
Integration of protograph Embeddings (MASCHInE). In particular, MASCHInE helps
produce more versatile KGEs that yield substantially better performance for
entity clustering and node classification tasks. For link prediction, using
MASCHinE substantially increases the number of semantically valid predictions
with equivalent rank-based performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.04542">On the Design Fundamentals of Diffusion Models: A Survey. (arXiv:2306.04542v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chang_Z/0/1/0/all/0/1">Ziyi Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Koulieris_G/0/1/0/all/0/1">George Alex Koulieris</a>, <a href="http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1">Hubert P. H. Shum</a></p>
<p>Diffusion models are generative models, which gradually add and remove noise
to learn the underlying distribution of training data for data generation. The
components of diffusion models have gained significant attention with many
design choices proposed. Existing reviews have primarily focused on
higher-level solutions, thereby covering less on the design fundamentals of
components. This study seeks to address this gap by providing a comprehensive
and coherent review on component-wise design choices in diffusion models.
Specifically, we organize this review according to their three key components,
namely the forward process, the reverse process, and the sampling procedure.
This allows us to provide a fine-grained perspective of diffusion models,
benefiting future studies in the analysis of individual components, the
applicability of design choices, and the implementation of diffusion models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.06344">Language-Guided Traffic Simulation via Scene-Level Diffusion. (arXiv:2306.06344v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Ziyuan Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Rempe_D/0/1/0/all/0/1">Davis Rempe</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ivanovic_B/0/1/0/all/0/1">Boris Ivanovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yulong Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Danfei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1">Marco Pavone</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1">Baishakhi Ray</a></p>
<p>Realistic and controllable traffic simulation is a core capability that is
necessary to accelerate autonomous vehicle (AV) development. However, current
approaches for controlling learning-based traffic models require significant
domain expertise and are difficult for practitioners to use. To remedy this, we
present CTG++, a scene-level conditional diffusion model that can be guided by
language instructions. Developing this requires tackling two challenges: the
need for a realistic and controllable traffic model backbone, and an effective
method to interface with a traffic model using language. To address these
challenges, we first propose a scene-level diffusion model equipped with a
spatio-temporal transformer backbone, which generates realistic and
controllable traffic. We then harness a large language model (LLM) to convert a
user's query into a loss function, guiding the diffusion model towards
query-compliant generation. Through comprehensive evaluation, we demonstrate
the effectiveness of our proposed method in generating realistic,
query-compliant traffic simulations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.08141">ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations. (arXiv:2306.08141v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vodrahalli_K/0/1/0/all/0/1">Kailas Vodrahalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">James Zou</a></p>
<p>As generative AI becomes more prevalent, it is important to study how human
users interact with such models. In this work, we investigate how people use
text-to-image models to generate desired target images. To study this
interaction, we created ArtWhisperer, an online game where users are given a
target image and are tasked with iteratively finding a prompt that creates a
similar-looking image as the target. Through this game, we recorded over 50,000
human-AI interactions; each interaction corresponds to one text prompt created
by a user and the corresponding generated image. The majority of these are
repeated interactions where a user iterates to find the best prompt for their
target image, making this a unique sequential dataset for studying human-AI
collaborations. In an initial analysis of this dataset, we identify several
characteristics of prompt interactions and user strategies. People submit
diverse prompts and are able to discover a variety of text descriptions that
generate similar images. Interestingly, prompt diversity does not decrease as
users find better prompts. We further propose a new metric to quantify the
steerability of AI using our dataset. We define steerability as the expected
number of interactions required to adequately complete a task. We estimate this
value by fitting a Markov chain for each target task and calculating the
expected time to reach an adequate score in the Markov chain. We quantify and
compare AI steerability across different types of target images and two
different models, finding that images of cities and natural world images are
more steerable than artistic and fantasy images. These findings provide
insights into human-AI interaction behavior, present a concrete method of
assessing AI steerability, and demonstrate the general utility of the
ArtWhisperer dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09983">Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fluri_L/0/1/0/all/0/1">Lukas Fluri</a>, <a href="http://arxiv.org/find/cs/1/au:+Paleka_D/0/1/0/all/0/1">Daniel Paleka</a>, <a href="http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1">Florian Tram&#xe8;r</a></p>
<p>If machine learning models were to achieve superhuman abilities at various
reasoning or decision-making tasks, how would we go about evaluating such
models, given that humans would necessarily be poor proxies for ground truth?
In this paper, we propose a framework for evaluating superhuman models via
consistency checks. Our premise is that while the correctness of superhuman
decisions may be impossible to evaluate, we can still surface mistakes if the
model's decisions fail to satisfy certain logical, human-interpretable rules.
We instantiate our framework on three tasks where correctness of decisions is
hard to evaluate due to either superhuman model abilities, or to otherwise
missing ground truth: evaluating chess positions, forecasting future events,
and making legal judgments. We show that regardless of a model's (possibly
superhuman) performance on these tasks, we can discover logical inconsistencies
in decision making. For example: a chess engine assigning opposing valuations
to semantically identical boards; GPT-4 forecasting that sports records will
evolve non-monotonically over time; or an AI judge assigning bail to a
defendant only after we add a felony to their criminal record.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11586">Provably Powerful Graph Neural Networks for Directed Multigraphs. (arXiv:2306.11586v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Egressy_B/0/1/0/all/0/1">B&#xe9;ni Egressy</a>, <a href="http://arxiv.org/find/cs/1/au:+Niederhausern_L/0/1/0/all/0/1">Luc von Niederh&#xe4;usern</a>, <a href="http://arxiv.org/find/cs/1/au:+Blanusa_J/0/1/0/all/0/1">Jovan Blanusa</a>, <a href="http://arxiv.org/find/cs/1/au:+Altman_E/0/1/0/all/0/1">Erik Altman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1">Roger Wattenhofer</a>, <a href="http://arxiv.org/find/cs/1/au:+Atasu_K/0/1/0/all/0/1">Kubilay Atasu</a></p>
<p>This paper analyses a set of simple adaptations that transform standard
message-passing Graph Neural Networks (GNN) into provably powerful directed
multigraph neural networks. The adaptations include multigraph port numbering,
ego IDs, and reverse message passing. We prove that the combination of these
theoretically enables the detection of any directed subgraph pattern. To
validate the effectiveness of our proposed adaptations in practice, we conduct
experiments on synthetic subgraph detection tasks, which demonstrate
outstanding performance with almost perfect results. Moreover, we apply our
proposed adaptations to two financial crime analysis tasks. We observe dramatic
improvements in detecting money laundering transactions, improving the
minority-class F1 score of a standard message-passing GNN by up to 30%, and
closely matching or outperforming tree-based and GNN baselines. Similarly
impressive results are observed on a real-world phishing detection dataset,
boosting three standard GNNs' F1 scores by around 15% and outperforming all
baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.13856">Learning-to-Rank Meets Language: Boosting Language-Driven Ordering Alignment for Ordinal Classification. (arXiv:2306.13856v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peipei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Huaibo Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1">Chunshui Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1">Ran He</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhaofeng He</a></p>
<p>We present a novel language-driven ordering alignment method for ordinal
classification. The labels in ordinal classification contain additional
ordering relations, making them prone to overfitting when relying solely on
training data. Recent developments in pre-trained vision-language models
inspire us to leverage the rich ordinal priors in human language by converting
the original task into a vision-language alignment task. Consequently, we
propose L2RCLIP, which fully utilizes the language priors from two
perspectives. First, we introduce a complementary prompt tuning technique
called RankFormer, designed to enhance the ordering relation of original rank
prompts. It employs token-level attention with residual-style prompt blending
in the word embedding space. Second, to further incorporate language priors, we
revisit the approximate bound optimization of vanilla cross-entropy loss and
restructure it within the cross-modal embedding space. Consequently, we propose
a cross-modal ordinal pairwise loss to refine the CLIP feature space, where
texts and images maintain both semantic alignment and ordering alignment.
Extensive experiments on three ordinal classification tasks, including facial
age estimation, historical color image (HCI) classification, and aesthetic
assessment demonstrate its promising performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03512">Transfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data. (arXiv:2307.03512v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sech_G/0/1/0/all/0/1">Gregory Sech</a>, <a href="http://arxiv.org/find/cs/1/au:+Soleni_P/0/1/0/all/0/1">Paolo Soleni</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaart_W/0/1/0/all/0/1">Wouter B. Verschoof-van der Vaart</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokalj_Z/0/1/0/all/0/1">&#x17d;iga Kokalj</a>, <a href="http://arxiv.org/find/cs/1/au:+Traviglia_A/0/1/0/all/0/1">Arianna Traviglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiorucci_M/0/1/0/all/0/1">Marco Fiorucci</a></p>
<p>When applying deep learning to remote sensing data in archaeological
research, a notable obstacle is the limited availability of suitable datasets
for training models. The application of transfer learning is frequently
employed to mitigate this drawback. However, there is still a need to explore
its effectiveness when applied across different archaeological datasets. This
paper compares the performance of various transfer learning configurations
using two semantic segmentation deep neural networks on two LiDAR datasets. The
experimental results indicate that transfer learning-based approaches in
archaeology can lead to performance improvements, although a systematic
enhancement has not yet been observed. We provide specific insights about the
validity of such techniques that can serve as a baseline for future works.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03810">URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates. (arXiv:2307.03810v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kirchhof_M/0/1/0/all/0/1">Michael Kirchhof</a>, <a href="http://arxiv.org/find/cs/1/au:+Mucsanyi_B/0/1/0/all/0/1">B&#xe1;lint Mucs&#xe1;nyi</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Seong Joon Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1">Enkelejda Kasneci</a></p>
<p>Representation learning has significantly driven the field to develop
pretrained models that can act as a valuable starting point when transferring
to new datasets. With the rising demand for reliable machine learning and
uncertainty quantification, there is a need for pretrained models that not only
provide embeddings but also transferable uncertainty estimates. To guide the
development of such models, we propose the Uncertainty-aware Representation
Learning (URL) benchmark. Besides the transferability of the representations,
it also measures the zero-shot transferability of the uncertainty estimate
using a novel metric. We apply URL to evaluate eleven uncertainty quantifiers
that are pretrained on ImageNet and transferred to eight downstream datasets.
We find that approaches that focus on the uncertainty of the representation
itself or estimate the prediction risk directly outperform those that are based
on the probabilities of upstream classes. Yet, achieving transferable
uncertainty quantification remains an open challenge. Our findings indicate
that it is not necessarily in conflict with traditional representation learning
goals. Code is provided under https://github.com/mkirchhof/url .
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06125">Learning Hierarchical Interactive Multi-Object Search for Mobile Manipulation. (arXiv:2307.06125v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schmalstieg_F/0/1/0/all/0/1">Fabian Schmalstieg</a>, <a href="http://arxiv.org/find/cs/1/au:+Honerkamp_D/0/1/0/all/0/1">Daniel Honerkamp</a>, <a href="http://arxiv.org/find/cs/1/au:+Welschehold_T/0/1/0/all/0/1">Tim Welschehold</a>, <a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1">Abhinav Valada</a></p>
<p>Existing object-search approaches enable robots to search through free
pathways, however, robots operating in unstructured human-centered environments
frequently also have to manipulate the environment to their needs. In this
work, we introduce a novel interactive multi-object search task in which a
robot has to open doors to navigate rooms and search inside cabinets and
drawers to find target objects. These new challenges require combining
manipulation and navigation skills in unexplored environments. We present
HIMOS, a hierarchical reinforcement learning approach that learns to compose
exploration, navigation, and manipulation skills. To achieve this, we design an
abstract high-level action space around a semantic map memory and leverage the
explored environment as instance navigation points. We perform extensive
experiments in simulation and the real world that demonstrate that, with
accurate perception, the decision making of HIMOS effectively transfers to new
environments in a zero-shot manner. It shows robustness to unseen subpolicies,
failures in their execution, and different robot kinematics. These capabilities
open the door to a wide range of downstream tasks across embodied AI and
real-world use cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.09688">Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation. (arXiv:2307.09688v2 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1">Haitao Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haoming Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Chen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">Hongzhi Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Haoyu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Hanqing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhengyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruirui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Monica Xiao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Goutam_R/0/1/0/all/0/1">Rahul Goutam</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haiyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Subbian_K/0/1/0/all/0/1">Karthik Subbian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Suhang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yizhou Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1">Bing Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xianfeng Tang</a></p>
<p>Modeling customer shopping intentions is a crucial task for e-commerce, as it
directly impacts user experience and engagement. Thus, accurately understanding
customer preferences is essential for providing personalized recommendations.
Session-based recommendation, which utilizes customer session data to predict
their next interaction, has become increasingly popular. However, existing
session datasets have limitations in terms of item attributes, user diversity,
and dataset scale. As a result, they cannot comprehensively capture the
spectrum of user behaviors and preferences. To bridge this gap, we present the
Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It
is the first multilingual dataset consisting of millions of user sessions from
six different locales, where the major languages of products are English,
German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can
help us enhance personalization and understanding of user preferences, which
can benefit various existing tasks as well as enable new tasks. To test the
potential of the dataset, we introduce three tasks in this work: (1)
next-product recommendation, (2) next-product recommendation with domain
shifts, and (3) next-product title generation. With the above tasks, we
benchmark a range of algorithms on our proposed dataset, drawing new insights
for further research and practice. In addition, based on the proposed dataset
and tasks, we hosted a competition in the KDD CUP 2023 and have attracted
thousands of users and submissions. The winning solutions and the associated
workshop can be accessed at our website https://kddcup23.github.io/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.06368">Topic-Level Bayesian Surprise and Serendipity for Recommender Systems. (arXiv:2308.06368v2 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hasan_T/0/1/0/all/0/1">Tonmoy Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bunescu_R/0/1/0/all/0/1">Razvan Bunescu</a></p>
<p>A recommender system that optimizes its recommendations solely to fit a
user's history of ratings for consumed items can create a filter bubble,
wherein the user does not get to experience items from novel, unseen
categories. One approach to mitigate this undesired behavior is to recommend
items with high potential for serendipity, namely surprising items that are
likely to be highly rated. In this paper, we propose a content-based
formulation of serendipity that is rooted in Bayesian surprise and use it to
measure the serendipity of items after they are consumed and rated by the user.
When coupled with a collaborative-filtering component that identifies similar
users, this enables recommending items with high potential for serendipity. To
facilitate the evaluation of topic-level models for surprise and serendipity,
we introduce a dataset of book reading histories extracted from Goodreads,
containing over 26 thousand users and close to 1.3 million books, where we
manually annotate 449 books read by 4 users in terms of their time-dependent,
topic-level surprise. Experimental evaluations show that models that use
Bayesian surprise correlate much better with the manual annotations of
topic-level surprise than distance-based heuristics, and also obtain better
serendipitous item recommendation performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.02072">DeepVol: A Pre-Trained Universal Asset Volatility Model. (arXiv:2309.02072v3 [econ.EM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Liu_C/0/1/0/all/0/1">Chen Liu</a>, <a href="http://arxiv.org/find/econ/1/au:+Tran_M/0/1/0/all/0/1">Minh-Ngoc Tran</a>, <a href="http://arxiv.org/find/econ/1/au:+Wang_C/0/1/0/all/0/1">Chao Wang</a>, <a href="http://arxiv.org/find/econ/1/au:+Gerlach_R/0/1/0/all/0/1">Richard Gerlach</a>, <a href="http://arxiv.org/find/econ/1/au:+Kohn_R/0/1/0/all/0/1">Robert Kohn</a></p>
<p>This paper introduces DeepVol, a pre-trained deep learning volatility model
that is more general than traditional econometric models. DeepVol leverage the
power of transfer learning to effectively capture and model the volatility
dynamics of all financial assets, including previously unseen ones, using a
single universal model. This contrasts to the usual practice in the
econometrics literature, which trains a separate model for each asset. The
introduction of DeepVol opens up new avenues for volatility modeling in the
finance industry, potentially transforming the way volatility is predicted.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10444">Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models. (arXiv:2309.10444v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1">Qiming Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Leinonen_J/0/1/0/all/0/1">Juho Leinonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1">Alex Yuxuan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1">Wanjun Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pistotti_T/0/1/0/all/0/1">Tim Pistotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1">Alice Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Denny_P/0/1/0/all/0/1">Paul Denny</a>, <a href="http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1">Michael Witbrock</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiamou Liu</a></p>
<p>Learnersourcing involves students generating and sharing learning resources
with their peers. When learnersourcing multiple-choice questions, creating
explanations for the generated questions is a crucial step as it facilitates a
deeper understanding of the related concepts. However, it is often difficult
for students to craft effective explanations due to limited subject
understanding and a tendency to merely restate the question stem, distractors,
and correct answer. To help scaffold this task, in this work we propose a
self-reinforcement large-language-model framework, with the goal of generating
and evaluating explanations automatically. Comprising three modules, the
framework generates student-aligned explanations, evaluates these explanations
to ensure their quality and iteratively enhances the explanations. If an
explanation's evaluation score falls below a defined threshold, the framework
iteratively refines and reassesses the explanation. Importantly, our framework
emulates the manner in which students compose explanations at the relevant
grade level. For evaluation, we had a human subject-matter expert compare the
explanations generated by students with the explanations created by the
open-source large language model Vicuna-13B, a version of Vicuna-13B that had
been fine-tuned using our method, and by GPT-4. We observed that, when compared
to other large language models, GPT-4 exhibited a higher level of creativity in
generating explanations. We also found that explanations generated by GPT-4
were ranked higher by the human expert than both those created by the other
models and the original student-created explanations. Our findings represent a
significant advancement in enriching the learnersourcing experience for
students and enhancing the capabilities of large language models in educational
applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12871">AnglE-optimized Text Embeddings. (arXiv:2309.12871v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xianming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jing Li</a></p>
<p>High-quality text embedding is pivotal in improving semantic textual
similarity (STS) tasks, which are crucial components in Large Language Model
(LLM) applications. However, a common challenge existing text embedding models
face is the problem of vanishing gradients, primarily due to their reliance on
the cosine function in the optimization objective, which has saturation zones.
To address this issue, this paper proposes a novel angle-optimized text
embedding model called AnglE. The core idea of AnglE is to introduce angle
optimization in a complex space. This novel approach effectively mitigates the
adverse effects of the saturation zone in the cosine function, which can impede
gradient and hinder optimization processes. To set up a comprehensive STS
evaluation, we experimented on existing short-text STS datasets and a newly
collected long-text STS dataset from GitHub Issues. Furthermore, we examine
domain-specific STS scenarios with limited labeled data and explore how AnglE
works with LLM-annotated data. Extensive experiments were conducted on various
tasks including short-text STS, long-text STS, and domain-specific STS tasks.
The results show that AnglE outperforms the state-of-the-art (SOTA) STS models
that ignore the cosine saturation zone. These findings demonstrate the ability
of AnglE to generate high-quality text embeddings and the usefulness of angle
optimization in STS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.13218">AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling. (arXiv:2309.13218v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amarasinghe_P/0/1/0/all/0/1">Pivithuru Thejan Amarasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1">Su Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Alahakoon_D/0/1/0/all/0/1">Damminda Alahakoon</a></p>
<p>Business optimisation refers to the process of finding and implementing
efficient and cost-effective means of operation to bring a competitive
advantage for businesses. Synthesizing problem formulations is an integral part
of business optimisation, which relies on human expertise to construct problem
formulations using optimisation languages. Interestingly, with advancements in
Large Language Models (LLMs), the human expertise needed in problem formulation
can be minimized. However, developing an LLM for problem formulation is
challenging, due to training data, token limitations, and lack of appropriate
performance metrics. For the requirement of training data, recent attention has
been directed towards fine-tuning pre-trained LLMs for downstream tasks rather
than training an LLM from scratch for a specific task. In this paper, we adopt
an LLM fine-tuning approach and propose an AI-Copilot for business optimisation
problem formulation. For token limitations, we introduce modularization and
prompt engineering techniques to synthesize complex problem formulations as
modules that fit into the token limits of LLMs. Additionally, we design
performance evaluation metrics that are better suited for assessing the
accuracy and quality of problem formulations. The experiment results
demonstrate that with this approach we can synthesize complex and large problem
formulations for a typical business optimisation problem in production
scheduling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.00378">Measuring Value Understanding in Language Models through Discriminator-Critique Gap. (arXiv:2310.00378v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhaowei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_F/0/1/0/all/0/1">Fengshuo Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jun Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaodong Yang</a></p>
<p>Recent advancements in Large Language Models (LLMs) have heightened concerns
about their potential misalignment with human values. However, evaluating their
grasp of these values is complex due to their intricate and adaptable nature.
We argue that truly understanding values in LLMs requires considering both
"know what" and "know why". To this end, we present the Value Understanding
Measurement (VUM) framework that quantitatively assesses both "know what" and
"know why" by measuring the discriminator-critique gap related to human values.
Using the Schwartz Value Survey, we specify our evaluation values and develop a
thousand-level dialogue dataset with GPT-4. Our assessment looks at both the
value alignment of LLM's outputs compared to baseline answers and how LLM
responses align with reasons for value recognition versus GPT-4's annotations.
We evaluate five representative LLMs and provide strong evidence that the
scaling law significantly impacts "know what" but not much on "know why", which
has consistently maintained a high level. This may further suggest that LLMs
might craft plausible explanations based on the provided context without truly
understanding their inherent value, indicating potential risks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.01448">Meta Semantic Template for Evaluation of Large Language Models. (arXiv:2310.01448v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yachuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1">Qiaozhu Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a></p>
<p>Do large language models (LLMs) genuinely understand the semantics of the
language, or just memorize the training data? The recent concern on potential
data contamination of LLMs has raised awareness of the community to conduct
research on LLMs evaluation. In this paper, we propose MSTemp, an approach that
creates meta semantic templates to evaluate the semantic understanding ability
of LLMs. The core of MSTemp is not to perform evaluation directly on existing
benchmark datasets, but to generate new out-of-distribution (OOD) evaluation
sets using existing datasets as seeds. Specifically, for a given sentence,
MSTemp leverages another language model to generate new samples while
preserving its semantics. The new samples are called semantic templates to the
original sentence. Then, MSTemp generates evaluation samples via sentence
parsing and random word replacement on the semantic templates. MSTemp is highly
flexible, dynamic, and cost-effective. Our initial experiments show that
MSTemp-generated samples can significantly reduce the performance of LLMs using
existing datasets as seeds. We hope this initial work can shed light on future
research of LLMs evaluation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.01680">Keypoint-Augmented Self-Supervised Learning for Medical Image Segmentation with Limited Annotation. (arXiv:2310.01680v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhangsihao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1">Mengwei Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1">Kaize Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerig_G/0/1/0/all/0/1">Guido Gerig</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yalin Wang</a></p>
<p>Pretraining CNN models (i.e., UNet) through self-supervision has become a
powerful approach to facilitate medical image segmentation under low annotation
regimes. Recent contrastive learning methods encourage similar global
representations when the same image undergoes different transformations, or
enforce invariance across different image/patch features that are intrinsically
correlated. However, CNN-extracted global and local features are limited in
capturing long-range spatial dependencies that are essential in biological
anatomy. To this end, we present a keypoint-augmented fusion layer that
extracts representations preserving both short- and long-range self-attention.
In particular, we augment the CNN feature map at multiple scales by
incorporating an additional input that learns long-range spatial self-attention
among localized keypoint features. Further, we introduce both global and local
self-supervised pretraining for the framework. At the global scale, we obtain
global representations from both the bottleneck of the UNet, and by aggregating
multiscale keypoint features. These global features are subsequently
regularized through image-level contrastive objectives. At the local scale, we
define a distance-based criterion to first establish correspondences among
keypoints and encourage similarity between their features. Through extensive
experiments on both MRI and CT segmentation tasks, we demonstrate the
architectural advantages of our proposed method in comparison to both CNN and
Transformer-based UNets, when all architectures are trained with randomly
initialized weights. With our proposed pretraining strategy, our method further
outperforms existing SSL methods by producing more robust self-attention and
achieving state-of-the-art segmentation results. The code is available at
https://github.com/zshyang/kaf.git.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02031">OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1">Zhen Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1">Yida Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1">Yixin Ou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1">Daxiong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1">Guozhou Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huajun Chen</a></p>
<p>Ocean science, which delves into the oceans that are reservoirs of life and
biodiversity, is of great significance given that oceans cover over 70% of our
planet's surface. Recently, advances in Large Language Models (LLMs) have
transformed the paradigm in science. Despite the success in other domains,
current LLMs often fall short in catering to the needs of domain experts like
oceanographers, and the potential of LLMs for ocean science is under-explored.
The intrinsic reason may be the immense and intricate nature of ocean data as
well as the necessity for higher granularity and richness in knowledge. To
alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean
domain, which is expert in various ocean science tasks. We propose DoInstruct,
a novel framework to automatically obtain a large volume of ocean domain
instruction data, which generates instructions based on multi-agent
collaboration. Additionally, we construct the first oceanography benchmark,
OceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though
comprehensive experiments, OceanGPT not only shows a higher level of knowledge
expertise for oceans science tasks but also gains preliminary embodied
intelligence capabilities in ocean technology. Codes, data and checkpoints will
soon be available at https://github.com/zjunlp/KnowLM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02227">SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training. (arXiv:2310.02227v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meidani_K/0/1/0/all/0/1">Kazem Meidani</a>, <a href="http://arxiv.org/find/cs/1/au:+Shojaee_P/0/1/0/all/0/1">Parshin Shojaee</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1">Chandan K. Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1">Amir Barati Farimani</a></p>
<p>In an era where symbolic mathematical equations are indispensable for
modeling complex natural phenomena, scientific inquiry often involves
collecting observations and translating them into mathematical expressions.
Recently, deep learning has emerged as a powerful tool for extracting insights
from data. However, existing models typically specialize in either numeric or
symbolic domains, and are usually trained in a supervised manner tailored to
specific tasks. This approach neglects the substantial benefits that could
arise from a task-agnostic unified understanding between symbolic equations and
their numeric counterparts. To bridge the gap, we introduce SNIP, a
Symbolic-Numeric Integrated Pre-training, which employs joint contrastive
learning between symbolic and numeric domains, enhancing their mutual
similarities in the pre-trained embeddings. By performing latent space
analysis, we observe that SNIP provides cross-domain insights into the
representations, revealing that symbolic supervision enhances the embeddings of
numeric data and vice versa. We evaluate SNIP across diverse tasks, including
symbolic-to-numeric mathematical property prediction and numeric-to-symbolic
equation discovery, commonly known as symbolic regression. Results show that
SNIP effectively transfers to various tasks, consistently outperforming fully
supervised baselines and competing strongly with established task-specific
methods, especially in few-shot learning scenarios where available data is
limited.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02554">zkFL: Zero-Knowledge Proof-based Gradient Aggregation for Federated Learning. (arXiv:2310.02554v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhipeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1">Nanqing Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiahao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Knottenbelt_W/0/1/0/all/0/1">William Knottenbelt</a></p>
<p>Federated Learning (FL) is a machine learning paradigm, which enables
multiple and decentralized clients to collaboratively train a model under the
orchestration of a central aggregator. Traditional FL solutions rely on the
trust assumption of the centralized aggregator, which forms cohorts of clients
in a fair and honest manner. However, a malicious aggregator, in reality, could
abandon and replace the client's training models, or launch Sybil attacks to
insert fake clients. Such malicious behaviors give the aggregator more power to
control clients in the FL setting and determine the final training results. In
this work, we introduce zkFL, which leverages zero-knowledge proofs (ZKPs) to
tackle the issue of a malicious aggregator during the training model
aggregation process. To guarantee the correct aggregation results, the
aggregator needs to provide a proof per round. The proof can demonstrate to the
clients that the aggregator executes the intended behavior faithfully. To
further reduce the verification cost of clients, we employ a blockchain to
handle the proof in a zero-knowledge way, where miners (i.e., the nodes
validating and maintaining the blockchain data) can verify the proof without
knowing the clients' local and aggregated models. The theoretical analysis and
empirical results show that zkFL can achieve better security and privacy than
traditional FL, without modifying the underlying FL network structure or
heavily compromising the training speed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02658">Solving Multi-Configuration Problems: A Performance Analysis with Choco Solver. (arXiv:2310.02658v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ritz_B/0/1/0/all/0/1">Benjamin Ritz</a>, <a href="http://arxiv.org/find/cs/1/au:+Felfernig_A/0/1/0/all/0/1">Alexander Felfernig</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1">Viet-Man Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Lubos_S/0/1/0/all/0/1">Sebastian Lubos</a></p>
<p>In many scenarios, configurators support the configuration of a solution that
satisfies the preferences of a single user. The concept of
\emph{multi-configuration} is based on the idea of configuring a set of
configurations. Such a functionality is relevant in scenarios such as the
configuration of personalized exams, the configuration of project teams, and
the configuration of different trips for individual members of a tourist group
(e.g., when visiting a specific city). In this paper, we exemplify the
application of multi-configuration for generating individualized exams. We also
provide a constraint solver performance analysis which helps to gain some
insights into corresponding performance issues.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.06165">CAW-coref: Conjunction-Aware Word-level Coreference Resolution. (arXiv:2310.06165v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+DOosterlinck_K/0/1/0/all/0/1">Karel D&#x27;Oosterlinck</a>, <a href="http://arxiv.org/find/cs/1/au:+Bitew_S/0/1/0/all/0/1">Semere Kiros Bitew</a>, <a href="http://arxiv.org/find/cs/1/au:+Papineau_B/0/1/0/all/0/1">Brandon Papineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1">Christopher Potts</a>, <a href="http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1">Thomas Demeester</a>, <a href="http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1">Chris Develder</a></p>
<p>State-of-the-art coreference resolutions systems depend on multiple LLM calls
per document and are thus prohibitively expensive for many use cases (e.g.,
information extraction with large corpora). The leading word-level coreference
system (WL-coref) attains 96.6% of these SOTA systems' performance while being
much more efficient. In this work, we identify a routine yet important failure
case of WL-coref: dealing with conjoined mentions such as 'Tom and Mary'. We
offer a simple yet effective solution that improves the performance on the
OntoNotes test set by 0.9% F1, shrinking the gap between efficient word-level
coreference resolution and expensive SOTA approaches by 34.6%. Our
Conjunction-Aware Word-level coreference model (CAW-coref) and code is
available at https://github.com/KarelDO/wl-coref.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.07091">Jaeger: A Concatenation-Based Multi-Transformer VQA Model. (arXiv:2310.07091v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1">Jieting Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zewei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1">Penghao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1">Yidong Gan</a></p>
<p>Document-based Visual Question Answering poses a challenging task between
linguistic sense disambiguation and fine-grained multimodal retrieval. Although
there has been encouraging progress in document-based question answering due to
the utilization of large language and open-world prior models\cite{1}, several
challenges persist, including prolonged response times, extended inference
durations, and imprecision in matching. In order to overcome these challenges,
we propose Jaegar, a concatenation-based multi-transformer VQA model. To derive
question features, we leverage the exceptional capabilities of RoBERTa
large\cite{2} and GPT2-xl\cite{3} as feature extractors. Subsequently, we
subject the outputs from both models to a concatenation process. This operation
allows the model to consider information from diverse sources concurrently,
strengthening its representational capability. By leveraging pre-trained models
for feature extraction, our approach has the potential to amplify the
performance of these models through concatenation. After concatenation, we
apply dimensionality reduction to the output features, reducing the model's
computational effectiveness and inference time. Empirical results demonstrate
that our proposed model achieves competitive performance on Task C of the
PDF-VQA Dataset. If the user adds any new data, they should make sure to style
it as per the instructions provided in previous sections.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.07488">KwaiYiiMath: Technical Report. (arXiv:2310.07488v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jiayi Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Lei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiaoyang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengzong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhirui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengnan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xue Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xucheng Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yiqiao Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1">Chao Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chengru Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1">Junchen Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zijia Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fuzheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Di Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1">Kun Gai</a></p>
<p>Recent advancements in large language models (LLMs) have demonstrated
remarkable abilities in handling a variety of natural language processing (NLP)
downstream tasks, even on mathematical tasks requiring multi-step reasoning. In
this report, we introduce the KwaiYiiMath which enhances the mathematical
reasoning abilities of KwaiYiiBase1, by applying Supervised Fine-Tuning (SFT)
and Reinforced Learning from Human Feedback (RLHF), including on both English
and Chinese mathematical tasks. Meanwhile, we also constructed a small-scale
Chinese primary school mathematics test set (named KMath), consisting of 188
examples to evaluate the correctness of the problem-solving process generated
by the models. Empirical studies demonstrate that KwaiYiiMath can achieve
state-of-the-art (SOTA) performance on GSM8k, CMath, and KMath compared with
the similar size models, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.07560">ROMO: Retrieval-enhanced Offline Model-based Optimization. (arXiv:2310.07560v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingcheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haoran Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1">Hulei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Hongqiao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zheng Tian</a></p>
<p>Data-driven black-box model-based optimization (MBO) problems arise in a
great number of practical application scenarios, where the goal is to find a
design over the whole space maximizing a black-box target function based on a
static offline dataset. In this work, we consider a more general but
challenging MBO setting, named constrained MBO (CoMBO), where only part of the
design space can be optimized while the rest is constrained by the environment.
A new challenge arising from CoMBO is that most observed designs that satisfy
the constraints are mediocre in evaluation. Therefore, we focus on optimizing
these mediocre designs in the offline dataset while maintaining the given
constraints rather than further boosting the best observed design in the
traditional MBO setting. We propose retrieval-enhanced offline model-based
optimization (ROMO), a new derivable forward approach that retrieves the
offline dataset and aggregates relevant samples to provide a trusted
prediction, and use it for gradient-based optimization. ROMO is simple to
implement and outperforms state-of-the-art approaches in the CoMBO setting.
Empirically, we conduct experiments on a synthetic Hartmann (3D) function
dataset, an industrial CIO dataset, and a suite of modified tasks in the
Design-Bench benchmark. Results show that ROMO performs well in a wide range of
constrained optimization tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.07570">ChatGPT for Computational Topology. (arXiv:2310.07570v2 [math.AT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Liu_J/0/1/0/all/0/1">Jian Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/math/1/au:+Wei_G/0/1/0/all/0/1">Guo-Wei Wei</a></p>
<p>ChatGPT represents a significant milestone in the field of artificial
intelligence (AI), finding widespread applications across diverse domains.
However, its effectiveness in mathematical contexts has been somewhat
constrained by its susceptibility to conceptual errors. Concurrently,
topological data analysis (TDA), a relatively new discipline, has garnered
substantial interest in recent years. Nonetheless, the advancement of TDA is
impeded by the limited understanding of computational algorithms and coding
proficiency among theoreticians. This work endeavors to bridge the gap between
theoretical topological concepts and their practical implementation in
computational topology through the utilization of ChatGPT. We showcase how a
pure theoretician, devoid of computational experience and coding skills, can
effectively transform mathematical formulations and concepts into functional
code for computational topology with the assistance of ChatGPT. Our strategy
outlines a productive process wherein a mathematician trains ChatGPT on pure
mathematical concepts, steers ChatGPT towards generating computational topology
code, and subsequently validates the generated code using established examples.
Our specific case studies encompass the computation of Betti numbers, Laplacian
matrices, and Dirac matrices for simplicial complexes, as well as the
persistence of various homologies and Laplacians. Furthermore, we explore the
application of ChatGPT in computing recently developed topological theories for
hypergraphs and digraphs. This work serves as an initial step towards
effectively transforming pure mathematical theories into practical
computational tools, with the ultimate goal of enabling real applications
across diverse fields.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.07587">Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer. (arXiv:2310.07587v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1">Zikai Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Songshang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hualiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jin Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Joey Tianyi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Howard Hao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zuozhu Liu</a></p>
<p>Data privacy and long-tailed distribution are the norms rather than the
exception in many real-world tasks. This paper investigates a federated
long-tailed learning (Fed-LT) task in which each client holds a locally
heterogeneous dataset; if the datasets can be globally aggregated, they jointly
exhibit a long-tailed distribution. Under such a setting, existing federated
optimization and/or centralized long-tailed learning methods hardly apply due
to challenges in (a) characterizing the global long-tailed distribution under
privacy constraints and (b) adjusting the local learning strategy to cope with
the head-tail imbalance. In response, we propose a method termed
$\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB)
module that re-weights clients' gradients in a closed-loop manner, based on the
feedback of global long-tailed distribution evaluated by a Direct Prior
Analyzer (DPA) module. Using $\texttt{Fed-GraB}$, clients can effectively
alleviate the distribution drift caused by data heterogeneity during the model
training process and obtain a global model with better performance on the
minority classes while maintaining the performance of the majority classes.
Extensive experiments demonstrate that $\texttt{Fed-GraB}$ achieves
state-of-the-art performance on representative datasets such as CIFAR-10-LT,
CIFAR-100-LT, ImageNet-LT, and iNaturalist.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08395">Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation. (arXiv:2310.08395v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yuanyuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hanlun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_W/0/1/0/all/0/1">Weining Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yunshi Lan</a></p>
<p>The task of Question Generation over Knowledge Bases (KBQG) aims to convert a
logical form into a natural language question. For the sake of expensive cost
of large-scale question annotation, the methods of KBQG under low-resource
scenarios urgently need to be developed. However, current methods heavily rely
on annotated data for fine-tuning, which is not well-suited for few-shot
question generation. The emergence of Large Language Models (LLMs) has shown
their impressive generalization ability in few-shot tasks. Inspired by
Chain-of-Thought (CoT) prompting, which is an in-context learning strategy for
reasoning, we formulate KBQG task as a reasoning problem, where the generation
of a complete question is splitted into a series of sub-question generation.
Our proposed prompting method KQG-CoT first retrieves supportive logical forms
from the unlabeled data pool taking account of the characteristics of the
logical form. Then, we write a prompt to explicit the reasoning chain of
generating complicated questions based on the selected demonstrations. To
further ensure prompt quality, we extend KQG-CoT into KQG-CoT+ via sorting the
logical forms by their complexity. We conduct extensive experiments over three
public KBQG datasets. The results demonstrate that our prompting method
consistently outperforms other prompting baselines on the evaluated datasets.
Remarkably, our KQG-CoT+ method could surpass existing few-shot SoTA results of
the PathQuestions dataset by 18.25, 10.72, and 10.18 absolute points on BLEU-4,
METEOR, and ROUGE-L, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09342">Ranking LLM-Generated Loop Invariants for Program Verification. (arXiv:2310.09342v2 [cs.PL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Saikat Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Lahiri_S/0/1/0/all/0/1">Shuvendu K. Lahiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakhoury_S/0/1/0/all/0/1">Sarah Fakhoury</a>, <a href="http://arxiv.org/find/cs/1/au:+Musuvathi_M/0/1/0/all/0/1">Madanlal Musuvathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lal_A/0/1/0/all/0/1">Akash Lal</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1">Aseem Rastogi</a>, <a href="http://arxiv.org/find/cs/1/au:+Senthilnathan_A/0/1/0/all/0/1">Aditya Senthilnathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rahul Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Swamy_N/0/1/0/all/0/1">Nikhil Swamy</a></p>
<p>Synthesizing inductive loop invariants is fundamental to automating program
verification. In this work, we observe that Large Language Models (such as
gpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of
programs in a 0-shot setting, yet require several samples to generate the
correct invariants. This can lead to a large number of calls to a program
verifier to establish an invariant. To address this issue, we propose a {\it
re-ranking} approach for the generated results of LLMs. We have designed a
ranker that can distinguish between correct inductive invariants and incorrect
attempts based on the problem definition. The ranker is optimized as a
contrastive ranker. Experimental results demonstrate that this re-ranking
mechanism significantly improves the ranking of correct invariants among the
generated candidates, leading to a notable reduction in the number of calls to
a verifier.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09430">A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks. (arXiv:2310.09430v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1">Qiming Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gendron_G/0/1/0/all/0/1">Gael Gendron</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1">Alex Yuxuan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1">Wanjun Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_N/0/1/0/all/0/1">Neset Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1">Michael Witbrock</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiamou Liu</a></p>
<p>Large language models (LLMs), such as GPT-3.5 and GPT-4, have greatly
advanced the performance of artificial systems on various natural language
processing tasks to human-like levels. However, their generalisation and
robustness to perform logical reasoning remain under-evaluated. To probe this
ability, we propose three new logical reasoning datasets named "ReClor-plus",
"LogiQA-plus" and "LogiQAv2-plus", each featuring three subsets: the first with
randomly shuffled options, the second with the correct choices replaced by
"none of the other options are correct", and a combination of the previous two
subsets. We carry out experiments on these datasets with both discriminative
and generative LLMs and show that these simple tricks greatly hinder the
performance of the language models. Despite their superior performance on the
original publicly available datasets, we find that all models struggle to
answer our newly constructed datasets. We show that introducing task variations
by perturbing a sizable training set can markedly improve the model's
generalisation and robustness in logical reasoning tasks. Moreover, applying
logic-driven data augmentation for fine-tuning, combined with prompting can
enhance the generalisation performance of both discriminative large language
models and generative large language models. These results offer insights into
assessing and improving the generalisation and robustness of large language
models for logical reasoning tasks. We make our source code and data publicly
available
\url{https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10537">Microscaling Data Formats for Deep Learning. (arXiv:2310.10537v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rouhani_B/0/1/0/all/0/1">Bita Darvish Rouhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Ritchie Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+More_A/0/1/0/all/0/1">Ankit More</a>, <a href="http://arxiv.org/find/cs/1/au:+Hall_M/0/1/0/all/0/1">Mathew Hall</a>, <a href="http://arxiv.org/find/cs/1/au:+Khodamoradi_A/0/1/0/all/0/1">Alireza Khodamoradi</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Summer Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_D/0/1/0/all/0/1">Dhruv Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Cornea_M/0/1/0/all/0/1">Marius Cornea</a>, <a href="http://arxiv.org/find/cs/1/au:+Dellinger_E/0/1/0/all/0/1">Eric Dellinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Denolf_K/0/1/0/all/0/1">Kristof Denolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusan_S/0/1/0/all/0/1">Stosic Dusan</a>, <a href="http://arxiv.org/find/cs/1/au:+Elango_V/0/1/0/all/0/1">Venmugil Elango</a>, <a href="http://arxiv.org/find/cs/1/au:+Golub_M/0/1/0/all/0/1">Maximilian Golub</a>, <a href="http://arxiv.org/find/cs/1/au:+Heinecke_A/0/1/0/all/0/1">Alexander Heinecke</a>, <a href="http://arxiv.org/find/cs/1/au:+James_Roxby_P/0/1/0/all/0/1">Phil James-Roxby</a>, <a href="http://arxiv.org/find/cs/1/au:+Jani_D/0/1/0/all/0/1">Dharmesh Jani</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolhe_G/0/1/0/all/0/1">Gaurav Kolhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Langhammer_M/0/1/0/all/0/1">Martin Langhammer</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Ada Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Melnick_L/0/1/0/all/0/1">Levi Melnick</a>, <a href="http://arxiv.org/find/cs/1/au:+Mesmakhosroshahi_M/0/1/0/all/0/1">Maral Mesmakhosroshahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1">Andres Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Schulte_M/0/1/0/all/0/1">Michael Schulte</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafipour_R/0/1/0/all/0/1">Rasoul Shafipour</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Lei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Siu_M/0/1/0/all/0/1">Michael Siu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubey_P/0/1/0/all/0/1">Pradeep Dubey</a>, <a href="http://arxiv.org/find/cs/1/au:+Micikevicius_P/0/1/0/all/0/1">Paulius Micikevicius</a>, <a href="http://arxiv.org/find/cs/1/au:+Naumov_M/0/1/0/all/0/1">Maxim Naumov</a>, <a href="http://arxiv.org/find/cs/1/au:+Verrilli_C/0/1/0/all/0/1">Colin Verrilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Wittig_R/0/1/0/all/0/1">Ralph Wittig</a>, <a href="http://arxiv.org/find/cs/1/au:+Burger_D/0/1/0/all/0/1">Doug Burger</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_E/0/1/0/all/0/1">Eric Chung</a></p>
<p>Narrow bit-width data formats are key to reducing the computational and
storage costs of modern deep learning applications. This paper evaluates
Microscaling (MX) data formats that combine a per-block scaling factor with
narrow floating-point and integer types for individual elements. MX formats
balance the competing needs of hardware efficiency, model accuracy, and user
friction. Empirical results on over two dozen benchmarks demonstrate
practicality of MX data formats as a drop-in replacement for baseline FP32 for
AI inference and training with low user friction. We also show the first
instance of training generative language models at sub-8-bit weights,
activations, and gradients with minimal accuracy loss and no modifications to
the training recipe.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10638">In-Context Pretraining: Language Modeling Beyond Document Boundaries. (arXiv:2310.10638v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1">Weijia Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1">Sewon Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Lomeli_M/0/1/0/all/0/1">Maria Lomeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chunting Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Margaret Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_V/0/1/0/all/0/1">Victoria Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Yih_S/0/1/0/all/0/1">Scott Yih</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1">Mike Lewis</a></p>
<p>Large language models (LMs) are currently trained to predict tokens given
document prefixes, enabling them to directly perform long-form generation and
prompting-style tasks which can be reduced to document completion. Existing
pretraining pipelines train LMs by concatenating random sets of short documents
to create input contexts but the prior documents provide no signal for
predicting the next document. We instead present In-Context Pretraining, a new
approach where language models are pretrained on a sequence of related
documents, thereby explicitly encouraging them to read and reason across
document boundaries. We can do In-Context Pretraining by simply changing the
document ordering so that each context contains related documents, and directly
applying existing pretraining pipelines. However, this document sorting problem
is challenging. There are billions of documents and we would like the sort to
maximize contextual similarity for every document without repeating any data.
To do this, we introduce approximate algorithms for finding related documents
with efficient nearest neighbor search and constructing coherent input contexts
with a graph traversal algorithm. Our experiments show In-Context Pretraining
offers a simple and scalable approach to significantly enhance LMs'performance:
we see notable improvements in tasks that require more complex contextual
reasoning, including in-context learning (+8%), reading comprehension (+15%),
faithfulness to previous contexts (+16%), long-context reasoning (+5%), and
retrieval augmentation (+9%).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10692">ACES: Generating Diverse Programming Puzzles with Autotelic Language Models and Semantic Descriptors. (arXiv:2310.10692v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pourcel_J/0/1/0/all/0/1">Julien Pourcel</a>, <a href="http://arxiv.org/find/cs/1/au:+Colas_C/0/1/0/all/0/1">C&#xe9;dric Colas</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Teodorescu_L/0/1/0/all/0/1">Laetitia Teodorescu</a></p>
<p>Finding and selecting new and interesting problems to solve is at the heart
of curiosity, science and innovation. We here study automated problem
generation in the context of the open-ended space of python programming
puzzles. Existing generative models often aim at modeling a reference
distribution without any explicit diversity optimization. Other methods
explicitly optimizing for diversity do so either in limited hand-coded
representation spaces or in uninterpretable learned embedding spaces that may
not align with human perceptions of interesting variations. With ACES
(Autotelic Code Exploration via Semantic descriptors), we introduce a new
autotelic generation method that leverages semantic descriptors produced by a
large language model (LLM) to directly optimize for interesting diversity, as
well as few-shot-based generation. Each puzzle is labeled along 10 dimensions,
each capturing a programming skill required to solve it. ACES generates and
pursues novel and feasible goals to explore that abstract semantic space,
slowly discovering a diversity of solvable programming puzzles in any given
run. Across a set of experiments, we show that ACES discovers a richer
diversity of puzzles than existing diversity-maximizing algorithms as measured
across a range of diversity metrics. We further study whether and in which
conditions this diversity can translate into the successful training of puzzle
solving models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10765">BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys. (arXiv:2310.10765v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yu Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1">Naoto Usuyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1">Matthew P. Lungren</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1">Hoifung Poon</a></p>
<p>Rapid progress has been made in instruction-learning for image editing with
natural-language instruction, as exemplified by InstructPix2Pix. In
biomedicine, such methods can be applied to counterfactual image generation,
which helps differentiate causal structure from spurious correlation and
facilitate robust image interpretation for disease progression modeling.
However, generic image-editing models are ill-suited for the biomedical domain,
and counterfactual biomedical image generation is largely underexplored. In
this paper, we present BiomedJourney, a novel method for counterfactual
biomedical image generation by instruction-learning from multimodal patient
journeys. Given a patient with two biomedical images taken at different time
points, we use GPT-4 to process the corresponding imaging reports and generate
a natural language description of disease progression. The resulting triples
(prior image, progression description, new image) are then used to train a
latent diffusion model for counterfactual biomedical image generation. Given
the relative scarcity of image time series data, we introduce a two-stage
curriculum that first pretrains the denoising network using the much more
abundant single image-report pairs (with dummy prior image), and then continues
training using the counterfactual triples. Experiments using the standard
MIMIC-CXR dataset demonstrate the promise of our method. In a comprehensive
battery of tests on counterfactual medical image generation, BiomedJourney
substantially outperforms prior state-of-the-art methods in instruction image
editing and medical image generation such as InstructPix2Pix and RoentGen. To
facilitate future study in counterfactual medical generation, we plan to
release our instruction-learning code and pretrained models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11102">HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning. (arXiv:2310.11102v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yulan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhirui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1">Sheng Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1">Junchen Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fuzheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a></p>
<p>Generative self-supervised learning (SSL) has exhibited significant potential
and garnered increasing interest in graph learning. In this study, we aim to
explore the problem of generative SSL in the context of heterogeneous graph
learning (HGL). The previous SSL approaches for heterogeneous graphs have
primarily relied on contrastive learning, necessitating the design of complex
views to capture heterogeneity. However, existing generative SSL methods have
not fully leveraged the capabilities of generative models to address the
challenges of HGL. In this paper, we present HGCVAE, a novel contrastive
variational graph auto-encoder that liberates HGL from the burden of intricate
heterogeneity capturing. Instead of focusing on complicated heterogeneity,
HGCVAE harnesses the full potential of generative SSL. HGCVAE innovatively
consolidates contrastive learning with generative SSL, introducing several key
innovations. Firstly, we employ a progressive mechanism to generate
high-quality hard negative samples for contrastive learning, utilizing the
power of variational inference. Additionally, we present a dynamic mask
strategy to ensure effective and stable learning. Moreover, we propose an
enhanced scaled cosine error as the criterion for better attribute
reconstruction. As an initial step in combining generative and contrastive SSL,
HGCVAE achieves remarkable results compared to various state-of-the-art
baselines, confirming its superiority.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11466">Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction. (arXiv:2310.11466v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yufei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Siyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jin Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lirong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_O/0/1/0/all/0/1">Odin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Haitao Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1">Jingqi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zhangyang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jiangbin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Stan.ZQ.Li</a></p>
<p>Protein structure-based property prediction has emerged as a promising
approach for various biological tasks, such as protein function prediction and
sub-cellular location estimation. The existing methods highly rely on
experimental protein structure data and fail in scenarios where these data are
unavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were
utilized as alternatives. However, we observed that current practices, which
simply employ accurately predicted structures during inference, suffer from
notable degradation in prediction accuracy. While similar phenomena have been
extensively studied in general fields (e.g., Computer Vision) as model
robustness, their impact on protein property prediction remains unexplored. In
this paper, we first investigate the reason behind the performance decrease
when utilizing predicted structures, attributing it to the structure embedding
bias from the perspective of structure representation learning. To study this
problem, we identify a Protein 3D Graph Structure Learning Problem for Robust
Protein Property Prediction (PGSL-RP3), collect benchmark datasets, and present
a protein Structure embedding Alignment Optimization framework (SAO) to
mitigate the problem of structure embedding bias between the predicted and
experimental protein structures. Extensive experiments have shown that our
framework is model-agnostic and effective in improving the property prediction
of both predicted structures and experimental structures. The benchmark
datasets and codes will be released to benefit the community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11569">When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting. (arXiv:2310.11569v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1">Harshavardhan Kamarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1">Lingkai Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1">Alexander Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1">B. Aditya Prakash</a></p>
<p>Probabilistic hierarchical time-series forecasting is an important variant of
time-series forecasting, where the goal is to model and forecast multivariate
time-series that have underlying hierarchical relations. Most methods focus on
point predictions and do not provide well-calibrated probabilistic forecasts
distributions. Recent state-of-art probabilistic forecasting methods also
impose hierarchical relations on point predictions and samples of distribution
which does not account for coherency of forecast distributions. Previous works
also silently assume that datasets are always consistent with given
hierarchical relations and do not adapt to real-world datasets that show
deviation from this assumption. We close both these gap and propose PROFHiT,
which is a fully probabilistic hierarchical forecasting model that jointly
models forecast distribution of entire hierarchy. PROFHiT uses a flexible
probabilistic Bayesian approach and introduces a novel Distributional Coherency
regularization to learn from hierarchical relations for entire forecast
distribution that enables robust and calibrated forecasts as well as adapt to
datasets of varying hierarchical consistency. On evaluating PROFHiT over wide
range of datasets, we observed 41-88% better performance in accuracy and
significantly better calibration. Due to modeling the coherency over full
distribution, we observed that PROFHiT can robustly provide reliable forecasts
even if up to 10% of input time-series data is missing where other methods'
performance severely degrade by over 70%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11595">WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks. (arXiv:2310.11595v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1">Jun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1">Zhihao Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yingbo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1">Zhiwei Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xian Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingsong Chen</a></p>
<p>Due to the popularity of Artificial Intelligence (AI) technology, numerous
backdoor attacks are designed by adversaries to mislead deep neural network
predictions by manipulating training samples and training processes. Although
backdoor attacks are effective in various real scenarios, they still suffer
from the problems of both low fidelity of poisoned samples and non-negligible
transfer in latent space, which make them easily detectable by existing
backdoor detection algorithms. To overcome the weakness, this paper proposes a
novel frequency-based backdoor attack method named WaveAttack, which obtains
image high-frequency features through Discrete Wavelet Transform (DWT) to
generate backdoor triggers. Furthermore, we introduce an asymmetric frequency
obfuscation method, which can add an adaptive residual in the training and
inference stage to improve the impact of triggers and further enhance the
effectiveness of WaveAttack. Comprehensive experimental results show that
WaveAttack not only achieves higher stealthiness and effectiveness, but also
outperforms state-of-the-art (SOTA) backdoor attack methods in the fidelity of
images by up to 28.27\% improvement in PSNR, 1.61\% improvement in SSIM, and
70.59\% reduction in IS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11670">Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning. (arXiv:2310.11670v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jie Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhaofeng He</a></p>
<p>Parameter-efficient fine-tuning (PEFT) has shown its effectiveness in
adapting the pre-trained language models to downstream tasks while only
updating a small number of parameters. Despite the success, most existing
methods independently adapt to each task without considering knowledge transfer
between tasks and are limited to low-data regimes. To overcome this issue, we
propose Prototype-based HyperAdapter (PHA), a novel framework built on the
adapter-tuning and hypernetwork. It introduces an instance-dense retriever and
a prototypical hypernetwork to generate the conditional modules in a
sample-efficient manner. This leads to comparable performance improvements
against existing PEFT methods on multi-task learning and few-shot transfer
learning. More importantly, when the available data size gets smaller, our
method outperforms other strong baselines by a large margin. Based on our
extensive empirical experiments across various datasets, we demonstrate that
PHA strikes a better trade-off between trainable parameters, accuracy on stream
tasks, and sample efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11709">Live Graph Lab: Towards Open, Dynamic and Real Transaction Graphs with NFT. (arXiv:2310.11709v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1">Bingqiao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shengliang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Bingsheng He</a></p>
<p>Numerous studies have been conducted to investigate the properties of
large-scale temporal graphs. Despite the ubiquity of these graphs in real-world
scenarios, it's usually impractical for us to obtain the whole real-time graphs
due to privacy concerns and technical limitations. In this paper, we introduce
the concept of {\it Live Graph Lab} for temporal graphs, which enables open,
dynamic and real transaction graphs from blockchains. Among them, Non-fungible
tokens (NFTs) have become one of the most prominent parts of blockchain over
the past several years. With more than \$40 billion market capitalization, this
decentralized ecosystem produces massive, anonymous and real transaction
activities, which naturally forms a complicated transaction network. However,
there is limited understanding about the characteristics of this emerging NFT
ecosystem from a temporal graph analysis perspective. To mitigate this gap, we
instantiate a live graph with NFT transaction network and investigate its
dynamics to provide new observations and insights. Specifically, through
downloading and parsing the NFT transaction activities, we obtain a temporal
graph with more than 4.5 million nodes and 124 million edges. Then, a series of
measurements are presented to understand the properties of the NFT ecosystem.
Through comparisons with social, citation, and web networks, our analyses give
intriguing findings and point out potential directions for future exploration.
Finally, we also study machine learning models in this live graph to enrich the
current datasets and provide new opportunities for the graph community. The
source codes and dataset are available at https://livegraphlab.github.io.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11971">Improving Generalization of Alignment with Human Preferences through Group Invariant Learning. (arXiv:2310.11971v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1">Rui Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">Wei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1">Yuan Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1">Wenbin Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1">Shihan Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuhao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1">Zhiheng Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haoran Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1">Tao Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuanjing Huang</a></p>
<p>The success of AI assistants based on language models (LLMs) hinges crucially
on Reinforcement Learning from Human Feedback (RLHF), which enables the
generation of responses more aligned with human preferences. As universal AI
assistants, there's a growing expectation for them to perform consistently
across various domains. However, previous work shows that Reinforcement
Learning (RL) often exploits shortcuts to attain high rewards and overlooks
challenging samples. This focus on quick reward gains undermines both the
stability in training and the model's ability to generalize to new, unseen
data. In this work, we propose a novel approach that can learn a consistent
policy via RL across various data groups or domains. Given the challenges
associated with acquiring group annotations, our method automatically
classifies data into different groups, deliberately maximizing performance
variance. Then, we optimize the policy to perform well on challenging groups.
Lastly, leveraging the established groups, our approach adaptively adjusts the
exploration space, allocating more learning capacity to more challenging data
and preventing the model from over-optimizing on simpler data. Experimental
results indicate that our approach significantly enhances training stability
and model generalization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.17525">MeLM, a generative pretrained language modeling framework that solves forward and inverse mechanics problems. (arXiv:2306.17525v1 [cond-mat.mtrl-sci] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Buehler_M/0/1/0/all/0/1">Markus J. Buehler</a></p>
<p>We report a flexible multi-modal mechanics language model, MeLM, applied to
solve various nonlinear forward and inverse problems, that can deal with a set
of instructions, numbers and microstructure data. The framework is applied to
various examples including bio-inspired hierarchical honeycomb design, carbon
nanotube mechanics, and protein unfolding. In spite of the flexible nature of
the model-which allows us to easily incorporate diverse materials, scales, and
mechanical features-it performs well across disparate forward and inverse
tasks. Based on an autoregressive attention-model, MeLM effectively represents
a large multi-particle system consisting of hundreds of millions of neurons,
where the interaction potentials are discovered through graph-forming
self-attention mechanisms that are then used to identify relationships from
emergent structures, while taking advantage of synergies discovered in the
training data. We show that the model can solve complex degenerate mechanics
design problems and determine novel material architectures across a range of
hierarchical levels, providing an avenue for materials discovery and analysis.
Looking beyond the demonstrations reported in this paper, we discuss other
opportunities in applied mechanics and general considerations about the use of
large language models in modeling, design, and analysis that can span a broad
spectrum of material properties from mechanical, thermal, optical, to
electronic.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.10170">Generative modeling, design and analysis of spider silk protein sequences for enhanced mechanical properties. (arXiv:2309.10170v1 [cond-mat.mtrl-sci] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Lu_W/0/1/0/all/0/1">Wei Lu</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Kaplan_D/0/1/0/all/0/1">David L. Kaplan</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Buehler_M/0/1/0/all/0/1">Markus J. Buehler</a></p>
<p>Spider silks are remarkable materials characterized by superb mechanical
properties such as strength, extensibility and lightweightedness. Yet, to date,
limited models are available to fully explore sequence-property relationships
for analysis and design. Here we propose a custom generative large-language
model to enable design of novel spider silk protein sequences to meet complex
combinations of target mechanical properties. The model, pretrained on a large
set of protein sequences, is fine-tuned on ~1,000 major ampullate spidroin
(MaSp) sequences for which associated fiber-level mechanical properties exist,
to yield an end-to-end forward and inverse generative strategy. Performance is
assessed through: (1), a novelty analysis and protein type classification for
generated spidroin sequences through BLAST searches, (2) property evaluation
and comparison with similar sequences, (3) comparison of molecular structures,
as well as, and (4) a detailed sequence motif analyses. We generate silk
sequences with property combinations that do not exist in nature, and develop a
deep understanding the mechanistic roles of sequence patterns in achieving
overarching key mechanical properties (elastic modulus, strength, toughness,
failure strain). The model provides an efficient approach to expand the silkome
dataset, facilitating further sequence-structure analyses of silks, and
establishes a foundation for synthetic silk design and optimization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.10541">Efficient Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories. (arXiv:2310.10541v1 [cs.CV] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jiyuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wenzhuo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1">Kwok-Yan Lam</a></p>
<p>Training a large and state-of-the-art machine learning model typically
necessitates the use of large-scale datasets, which, in turn, makes the
training and parameter-tuning process expensive and time-consuming. Some
researchers opt to distil information from real-world datasets into tiny and
compact synthetic datasets while maintaining their ability to train a
well-performing model, hence proposing a data-efficient method known as Dataset
Distillation (DD). Despite recent progress in this field, existing methods
still underperform and cannot effectively replace large datasets. In this
paper, unlike previous methods that focus solely on improving the efficacy of
student distillation, we are the first to recognize the important interplay
between expert and student. We argue the significant impact of expert
smoothness when employing more potent expert trajectories in subsequent dataset
distillation. Based on this, we introduce the integration of clipping loss and
gradient penalty to regulate the rate of parameter changes in expert
trajectories. Furthermore, in response to the sensitivity exhibited towards
randomly initialized variables during distillation, we propose representative
initialization for synthetic dataset and balanced inner-loop loss. Finally, we
present two enhancement strategies, namely intermediate matching loss and
weight perturbation, to mitigate the potential occurrence of cumulative errors.
We conduct extensive experiments on datasets of different scales, sizes, and
resolutions. The results demonstrate that the proposed method significantly
outperforms prior methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11798">Auction-Based Scheduling. (arXiv:2310.11798v1 [cs.AI] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Avni_G/0/1/0/all/0/1">Guy Avni</a>, <a href="http://arxiv.org/find/cs/1/au:+Mallik_K/0/1/0/all/0/1">Kaushik Mallik</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadhukhan_S/0/1/0/all/0/1">Suman Sadhukhan</a></p>
<p>Many sequential decision-making tasks require satisfaction of multiple,
partially contradictory objectives. Existing approaches are monolithic, namely
all objectives are fulfilled using a single policy, which is a function that
selects a sequence of actions. We present auction-based scheduling, a modular
framework for multi-objective decision-making problems. Each objective is
fulfilled using a separate policy, and the policies can be independently
created, modified, and replaced. Understandably, different policies with
conflicting goals may choose conflicting actions at a given time. In order to
resolve conflicts, and compose policies, we employ a novel auction-based
mechanism. We allocate a bounded budget to each policy, and at each step, the
policies simultaneously bid from their available budgets for the privilege of
being scheduled and choosing an action. Policies express their scheduling
urgency using their bids and the bounded budgets ensure long-run scheduling
fairness. We lay the foundations of auction-based scheduling using path
planning problems on finite graphs with two temporal objectives. We present
decentralized algorithms to synthesize a pair of policies, their initially
allocated budgets, and bidding strategies. We consider three categories of
decentralized synthesis problems, parameterized by the assumptions that the
policies make on each other: (a) strong synthesis, with no assumptions and
strongest guarantees, (b) assume-admissible synthesis, with weakest rationality
assumptions, and (c) assume-guarantee synthesis, with explicit contract-based
assumptions. For reachability objectives, we show that, surprisingly,
decentralized assume-admissible synthesis is always possible when the
out-degrees of all vertices are at most two.
</p>
</p>
</div>

    </div>
    </body>
    