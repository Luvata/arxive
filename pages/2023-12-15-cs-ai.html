<!DOCTYPE html>
<html>
<head>
<title>2023-12-15-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2312.07553">Hijacking Context in Large Multi-modal Models. (arXiv:2312.07553v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1">Joonhyun Jeong</a></p>
<p>Recently, Large Multi-modal Models (LMMs) have demonstrated their ability to
understand the visual contents of images given the instructions regarding the
images. Built upon the Large Language Models (LLMs), LMMs also inherit their
abilities and characteristics such as in-context learning where a coherent
sequence of images and texts are given as the input prompt. However, we
identify a new limitation of off-the-shelf LMMs where a small fraction of
incoherent images or text descriptions mislead LMMs to only generate biased
output about the hijacked context, not the originally intended context. To
address this, we propose a pre-filtering method that removes irrelevant
contexts via GPT-4V, based on its robustness towards distribution shift within
the contexts. We further investigate whether replacing the hijacked visual and
textual contexts with the correlated ones via GPT-4V and text-to-image models
can help yield coherent responses.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07556">Federated Learning for Short Text Clustering. (arXiv:2312.07556v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Mengling Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chaochao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1">Xinting Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xiaolin Zheng</a></p>
<p>Short text clustering has been popularly studied for its significance in
mining valuable insights from many short texts. In this paper, we focus on the
federated short text clustering (FSTC) problem, i.e., clustering short texts
that are distributed in different clients, which is a realistic problem under
privacy requirements. Compared with the centralized short text clustering
problem that short texts are stored on a central server, the FSTC problem has
not been explored yet. To fill this gap, we propose a Federated Robust Short
Text Clustering (FSTC) framework. FSTC includes two main modules, i.e., robust
short text clustering module and federated cluster center aggregation module.
The robust short text clustering module aims to train an effective short text
clustering model with local data in each client. We innovatively combine
optimal transport to generate pseudo-labels with Gaussian-uniform mixture model
to ensure the reliability of the pseudo-supervised data. The federated cluster
center aggregation module aims to exchange knowledge across clients without
sharing local raw data in an efficient way. The server aggregates the local
cluster centers from different clients and then sends the global centers back
to all clients in each communication round. Our empirical studies on three
short text clustering datasets demonstrate that FSTC significantly outperforms
the federated short text clustering baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07559">PaperQA: Retrieval-Augmented Generative Agent for Scientific Research. (arXiv:2312.07559v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lala_J/0/1/0/all/0/1">Jakub L&#xe1;la</a>, <a href="http://arxiv.org/find/cs/1/au:+ODonoghue_O/0/1/0/all/0/1">Odhran O&#x27;Donoghue</a>, <a href="http://arxiv.org/find/cs/1/au:+Shtedritski_A/0/1/0/all/0/1">Aleksandar Shtedritski</a>, <a href="http://arxiv.org/find/cs/1/au:+Cox_S/0/1/0/all/0/1">Sam Cox</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriques_S/0/1/0/all/0/1">Samuel G. Rodriques</a>, <a href="http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1">Andrew D. White</a></p>
<p>Large Language Models (LLMs) generalize well across language tasks, but
suffer from hallucinations and uninterpretability, making it difficult to
assess their accuracy without ground-truth. Retrieval-Augmented Generation
(RAG) models have been proposed to reduce hallucinations and provide provenance
for how an answer was generated. Applying such models to the scientific
literature may enable large-scale, systematic processing of scientific
knowledge. We present PaperQA, a RAG agent for answering questions over the
scientific literature. PaperQA is an agent that performs information retrieval
across full-text scientific articles, assesses the relevance of sources and
passages, and uses RAG to provide answers. Viewing this agent as a question
answering model, we find it exceeds performance of existing LLMs and LLM agents
on current science QA benchmarks. To push the field closer to how humans
perform research on scientific literature, we also introduce LitQA, a more
complex benchmark that requires retrieval and synthesis of information from
full-text scientific papers across the literature. Finally, we demonstrate
PaperQA's matches expert human researchers on LitQA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07571">Investigating YOLO Models Towards Outdoor Obstacle Detection For Visually Impaired People. (arXiv:2312.07571v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Chenhao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_P/0/1/0/all/0/1">Pramit Saha</a></p>
<p>The utilization of deep learning-based object detection is an effective
approach to assist visually impaired individuals in avoiding obstacles. In this
paper, we implemented seven different YOLO object detection models
\textit{viz}., YOLO-NAS (small, medium, large), YOLOv8, YOLOv7, YOLOv6, and
YOLOv5 and performed comprehensive evaluation with carefully tuned
hyperparameters, to analyze how these models performed on images containing
common daily-life objects presented on roads and sidewalks. After a systematic
investigation, YOLOv8 was found to be the best model, which reached a precision
of $80\%$ and a recall of $68.2\%$ on a well-known Obstacle Dataset which
includes images from VOC dataset, COCO dataset, and TT100K dataset along with
images collected by the researchers in the field. Despite being the latest
model and demonstrating better performance in many other applications, YOLO-NAS
was found to be suboptimal for the obstacle detection task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07579">Cross Fertilizing Empathy from Brain to Machine as a Value Alignment Strategy. (arXiv:2312.07579v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gonier_D/0/1/0/all/0/1">Devin Gonier</a>, <a href="http://arxiv.org/find/cs/1/au:+Adduci_A/0/1/0/all/0/1">Adrian Adduci</a>, <a href="http://arxiv.org/find/cs/1/au:+LoCascio_C/0/1/0/all/0/1">Cassidy LoCascio</a></p>
<p>AI Alignment research seeks to align human and AI goals to ensure independent
actions by a machine are always ethical. This paper argues empathy is necessary
for this task, despite being often neglected in favor of more deductive
approaches. We offer an inside-out approach that grounds morality within the
context of the brain as a basis for algorithmically understanding ethics and
empathy. These arguments are justified via a survey of relevant literature. The
paper concludes with a suggested experimental approach to future research and
some initial experimental observations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07586">Characteristic Guidance: Non-linear Correction for DDPM at Large Guidance Scale. (arXiv:2312.07586v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Candi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yuan Lan</a></p>
<p>Popular guidance for denoising diffusion probabilistic model (DDPM) linearly
combines distinct conditional models together to provide enhanced control over
samples. However, this approach overlooks nonlinear effects that become
significant when guidance scale is large. To address this issue, we propose
characteristic guidance, a novel method that provides non-linear correction for
classifier-free guided DDPMs. Such correction forces the guided DDPMs to
respect the Fokker-Planck equation of their underlying diffusion process, in a
way that is first-principle, training-free, derivative-free, and compatible
with existing sampling methods. Experiments show that characteristic guidance
is robust to various applications, offers enhanced control over sample
generation, suppresses color and exposure issues even for latent space
sampling, and can handle physics problems such as the phase transitions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07589">ConvD: Attention Enhanced Dynamic Convolutional Embeddings for Knowledge Graph Completion. (arXiv:2312.07589v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1">Wenbin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zirui Chen</a></p>
<p>Knowledge graphs generally suffer from incompleteness, which can be
alleviated by completing the missing information. Deep knowledge convolutional
embedding models based on neural networks are currently popular methods for
knowledge graph completion. However, most existing methods use external
convolution kernels and traditional plain convolution processes, which limits
the feature interaction capability of the model. In this paper, we propose a
novel dynamic convolutional embedding model ConvD for knowledge graph
completion, which directly reshapes the relation embeddings into multiple
internal convolution kernels to improve the external convolution kernels of the
traditional convolutional embedding model. The internal convolution kernels can
effectively augment the feature interaction between the relation embeddings and
entity embeddings, thus enhancing the model embedding performance. Moreover, we
design a priori knowledge-optimized attention mechanism, which can assign
different contribution weight coefficients to multiple relation convolution
kernels for dynamic convolution to improve the expressiveness of the model
further. Extensive experiments on various datasets show that our proposed model
consistently outperforms the state-of-the-art baseline methods, with average
improvements ranging from 11.30\% to 16.92\% across all model evaluation
metrics. Ablation experiments verify the effectiveness of each component module
of the ConvD model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07592">Evaluating ChatGPT as a Question Answering System: A Comprehensive Analysis and Comparison with Existing Models. (arXiv:2312.07592v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bahak_H/0/1/0/all/0/1">Hossein Bahak</a>, <a href="http://arxiv.org/find/cs/1/au:+Taheri_F/0/1/0/all/0/1">Farzaneh Taheri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zojaji_Z/0/1/0/all/0/1">Zahra Zojaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1">Arefeh Kazemi</a></p>
<p>In the current era, a multitude of language models has emerged to cater to
user inquiries. Notably, the GPT-3.5 Turbo language model has gained
substantial attention as the underlying technology for ChatGPT. Leveraging
extensive parameters, this model adeptly responds to a wide range of questions.
However, due to its reliance on internal knowledge, the accuracy of responses
may not be absolute. This article scrutinizes ChatGPT as a Question Answering
System (QAS), comparing its performance to other existing QASs. The primary
focus is on evaluating ChatGPT's proficiency in extracting responses from
provided paragraphs, a core QAS capability. Additionally, performance
comparisons are made in scenarios without a surrounding passage. Multiple
experiments, exploring response hallucination and considering question
complexity, were conducted on ChatGPT. Evaluation employed well-known Question
Answering (QA) datasets, including SQuAD, NewsQA, and PersianQuAD, across
English and Persian languages. Metrics such as F-score, exact match, and
accuracy were employed in the assessment. The study reveals that, while ChatGPT
demonstrates competence as a generative model, it is less effective in question
answering compared to task-specific models. Providing context improves its
performance, and prompt engineering enhances precision, particularly for
questions lacking explicit answers in provided paragraphs. ChatGPT excels at
simpler factual questions compared to "how" and "why" question types. The
evaluation highlights occurrences of hallucinations, where ChatGPT provides
responses to questions without available answers in the provided context.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07602">Sense, Predict, Adapt, Repeat: A Blueprint for Design of New Adaptive AI-Centric Sensing Systems. (arXiv:2312.07602v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Hor_S/0/1/0/all/0/1">Soheil Hor</a>, <a href="http://arxiv.org/find/eess/1/au:+Arbabian_A/0/1/0/all/0/1">Amin Arbabian</a></p>
<p>As Moore's Law loses momentum, improving size, performance, and efficiency of
processors has become increasingly challenging, ending the era of predictable
improvements in hardware performance. Meanwhile, the widespread incorporation
of high-definition sensors in consumer devices and autonomous technologies has
fueled a significant upsurge in sensory data. Current global trends reveal that
the volume of generated data already exceeds human consumption capacity, making
AI algorithms the primary consumers of data worldwide. To address this, a novel
approach to designing AI-centric sensing systems is needed that can bridge the
gap between the increasing capabilities of high-definition sensors and the
limitations of AI processors. This paper provides an overview of efficient
sensing and perception methods in both AI and sensing domains, emphasizing the
necessity of co-designing AI algorithms and sensing systems for dynamic
perception. The proposed approach involves a framework for designing and
analyzing dynamic AI-in-the-loop sensing systems, suggesting a fundamentally
new method for designing adaptive sensing systems through inference-time
AI-to-sensor feedback and end-to-end efficiency and performance optimization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07606">Pedestrian and Passenger Interaction with Autonomous Vehicles: Field Study in a Crosswalk Scenario. (arXiv:2312.07606v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Izquierdo_R/0/1/0/all/0/1">Rub&#xe9;n Izquierdo</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonso_J/0/1/0/all/0/1">Javier Alonso</a>, <a href="http://arxiv.org/find/cs/1/au:+Benderius_O/0/1/0/all/0/1">Ola Benderius</a>, <a href="http://arxiv.org/find/cs/1/au:+Sotelo_M/0/1/0/all/0/1">Miguel &#xc1;ngel Sotelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Llorca_D/0/1/0/all/0/1">David Fern&#xe1;ndez Llorca</a></p>
<p>This study presents the outcomes of empirical investigations pertaining to
human-vehicle interactions involving an autonomous vehicle equipped with both
internal and external Human Machine Interfaces (HMIs) within a crosswalk
scenario. The internal and external HMIs were integrated with implicit
communication techniques, incorporating a combination of gentle and aggressive
braking maneuvers within the crosswalk. Data were collected through a
combination of questionnaires and quantifiable metrics, including pedestrian
decision to cross related to the vehicle distance and speed. The questionnaire
responses reveal that pedestrians experience enhanced safety perceptions when
the external HMI and gentle braking maneuvers are used in tandem. In contrast,
the measured variables demonstrate that the external HMI proves effective when
complemented by the gentle braking maneuver. Furthermore, the questionnaire
results highlight that the internal HMI enhances passenger confidence only when
paired with the aggressive braking maneuver.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07624">Adaptive Proximal Policy Optimization with Upper Confidence Bound. (arXiv:2312.07624v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jingzehua Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1">Zifeng Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jinxin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+wang_D/0/1/0/all/0/1">Donglin wang</a></p>
<p>Trust Region Policy Optimization (TRPO) attractively optimizes the policy
while constraining the update of the new policy within a trust region, ensuring
the stability and monotonic optimization. Building on the theoretical
guarantees of trust region optimization, Proximal Policy Optimization (PPO)
successfully enhances the algorithm's sample efficiency and reduces deployment
complexity by confining the update of the new and old policies within a
surrogate trust region. However, this approach is limited by the fixed setting
of surrogate trust region and is not sufficiently adaptive, because there is no
theoretical proof that the optimal clipping bound remains consistent throughout
the entire training process, truncating the ratio of the new and old policies
within surrogate trust region can ensure that the algorithm achieves its best
performance, therefore, exploring and researching a dynamic clip bound for
improving PPO's performance can be quite beneficial. To design an adaptive
clipped trust region and explore the dynamic clip bound's impact on the
performance of PPO, we introduce an adaptive PPO-CLIP (Adaptive-PPO) method
that dynamically explores and exploits the clip bound using a bandit during the
online training process. Furthermore, ample experiments will initially
demonstrate that our Adaptive-PPO exhibits sample efficiency and performance
compared to PPO-CLIP.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07625">Astrocyte-Enabled Advancements in Spiking Neural Networks for Large Language Modeling. (arXiv:2312.07625v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shen_G/0/1/0/all/0/1">Guobin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dongcheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yiting Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jindong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yi Zeng</a></p>
<p>Within the complex neuroarchitecture of the brain, astrocytes play crucial
roles in development, structure, and metabolism. These cells regulate neural
activity through tripartite synapses, directly impacting cognitive processes
such as learning and memory. Despite the growing recognition of astrocytes'
significance, traditional Spiking Neural Network (SNN) models remain
predominantly neuron-centric, overlooking the profound influence of astrocytes
on neural dynamics. Inspired by these biological insights, we have developed an
Astrocyte-Modulated Spiking Unit (AM-SU), an innovative framework that
integrates neuron-astrocyte interactions into the computational paradigm,
demonstrating wide applicability across various hardware platforms. Our
Astrocyte-Modulated Spiking Neural Network (AM-SNet) exhibits exceptional
performance in tasks involving memory retention and natural language
generation, particularly in handling long-term dependencies and complex
linguistic structures. The design of AM-SNet not only enhances its biological
authenticity but also introduces novel computational dynamics, enabling more
effective processing of complex temporal dependencies. Furthermore, AM-SNet
shows low latency, high throughput, and reduced memory usage in practical
applications, making it highly suitable for resource-constrained environments.
By successfully integrating astrocytic dynamics into intelligent neural
networks, our work narrows the gap between biological plausibility and neural
modeling, laying the groundwork for future biologically-inspired neural
computing research that includes both neurons and astrocytes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07631">AI-driven projection tomography with multicore fibre-optic cell rotation. (arXiv:2312.07631v1 [physics.med-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Sun_J/0/1/0/all/0/1">Jiawei Sun</a>, <a href="http://arxiv.org/find/physics/1/au:+Yang_B/0/1/0/all/0/1">Bin Yang</a>, <a href="http://arxiv.org/find/physics/1/au:+Koukourakis_N/0/1/0/all/0/1">Nektarios Koukourakis</a>, <a href="http://arxiv.org/find/physics/1/au:+Guck_J/0/1/0/all/0/1">Jochen Guck</a>, <a href="http://arxiv.org/find/physics/1/au:+Czarske_J/0/1/0/all/0/1">Juergen W. Czarske</a></p>
<p>Optical tomography has emerged as a non-invasive imaging method, providing
three-dimensional insights into subcellular structures and thereby enabling a
deeper understanding of cellular functions, interactions, and processes.
Conventional optical tomography methods are constrained by a limited
illumination scanning range, leading to anisotropic resolution and incomplete
imaging of cellular structures. To overcome this problem, we employ a compact
multi-core fibre-optic cell rotator system that facilitates precise optical
manipulation of cells within a microfluidic chip, achieving full-angle
projection tomography with isotropic resolution. Moreover, we demonstrate an
AI-driven tomographic reconstruction workflow, which can be a paradigm shift
from conventional computational methods, often demanding manual processing, to
a fully autonomous process. The performance of the proposed cell rotation
tomography approach is validated through the three-dimensional reconstruction
of cell phantoms and HL60 human cancer cells. The versatility of this
learning-based tomographic reconstruction workflow paves the way for its broad
application across diverse tomographic imaging modalities, including but not
limited to flow cytometry tomography and acoustic rotation tomography.
Therefore, this AI-driven approach can propel advancements in cell biology,
aiding in the inception of pioneering therapeutics, and augmenting early-stage
cancer diagnostics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07635">Clash of the Explainers: Argumentation for Context-Appropriate Explanations. (arXiv:2312.07635v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Methnani_L/0/1/0/all/0/1">Leila Methnani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dignum_V/0/1/0/all/0/1">Virginia Dignum</a>, <a href="http://arxiv.org/find/cs/1/au:+Theodorou_A/0/1/0/all/0/1">Andreas Theodorou</a></p>
<p>Understanding when and why to apply any given eXplainable Artificial
Intelligence (XAI) technique is not a straightforward task. There is no single
approach that is best suited for a given context. This paper aims to address
the challenge of selecting the most appropriate explainer given the context in
which an explanation is required. For AI explainability to be effective,
explanations and how they are presented needs to be oriented towards the
stakeholder receiving the explanation. If -- in general -- no single
explanation technique surpasses the rest, then reasoning over the available
methods is required in order to select one that is context-appropriate. Due to
the transparency they afford, we propose employing argumentation techniques to
reach an agreement over the most suitable explainers from a given set of
possible explainers.
</p>
<p>In this paper, we propose a modular reasoning system consisting of a given
mental model of the relevant stakeholder, a reasoner component that solves the
argumentation problem generated by a multi-explainer component, and an AI model
that is to be explained suitably to the stakeholder of interest. By formalising
supporting premises -- and inferences -- we can map stakeholder characteristics
to those of explanation techniques. This allows us to reason over the
techniques and prioritise the best one for the given context, while also
offering transparency into the selection decision.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07637">Responsibility in Extensive Form Games. (arXiv:2312.07637v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1">Qi Shi</a></p>
<p>Two different forms of responsibility, counterfactual and seeing-to-it, have
been extensively discussed in the philosophy and AI in the context of a single
agent or multiple agents acting simultaneously. Although the generalisation of
counterfactual responsibility to a setting where multiple agents act in some
order is relatively straightforward, the same cannot be said about seeing-to-it
responsibility. Two versions of seeing-to-it modality applicable to such
settings have been proposed in the literature. Neither of them perfectly
captures the intuition of responsibility. This paper proposes a definition of
seeing-to-it responsibility for such settings that amalgamate the two
modalities.
</p>
<p>This paper shows that the newly proposed notion of responsibility and
counterfactual responsibility are not definable through each other and studies
the responsibility gap for these two forms of responsibility. It shows that
although these two forms of responsibility are not enough to ascribe
responsibility in each possible situation, this gap does not exist if
higher-order responsibility is taken into account.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07638">Teaching Unknown Objects by Leveraging Human Gaze and Augmented Reality in Human-Robot Interaction. (arXiv:2312.07638v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Weber_D/0/1/0/all/0/1">Daniel Weber</a></p>
<p>Robots are becoming increasingly popular in a wide range of environments due
to their exceptional work capacity, precision, efficiency, and scalability.
This development has been further encouraged by advances in Artificial
Intelligence, particularly Machine Learning. By employing sophisticated neural
networks, robots are given the ability to detect and interact with objects in
their vicinity. However, a significant drawback arises from the underlying
dependency on extensive datasets and the availability of substantial amounts of
training data for these object detection models. This issue becomes
particularly problematic when the specific deployment location of the robot and
the surroundings, are not known in advance. The vast and ever-expanding array
of objects makes it virtually impossible to comprehensively cover the entire
spectrum of existing objects using preexisting datasets alone. The goal of this
dissertation was to teach a robot unknown objects in the context of Human-Robot
Interaction (HRI) in order to liberate it from its data dependency, unleashing
it from predefined scenarios. In this context, the combination of eye tracking
and Augmented Reality created a powerful synergy that empowered the human
teacher to communicate with the robot and effortlessly point out objects by
means of human gaze. This holistic approach led to the development of a
multimodal HRI system that enabled the robot to identify and visually segment
the Objects of Interest in 3D space. Through the class information provided by
the human, the robot was able to learn the objects and redetect them at a later
stage. Due to the knowledge gained from this HRI based teaching, the robot's
object detection capabilities exhibited comparable performance to
state-of-the-art object detectors trained on extensive datasets, without being
restricted to predefined classes, showcasing its versatility and adaptability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07671">Reacting like Humans: Incorporating Intrinsic Human Behaviors into NAO through Sound-Based Reactions for Enhanced Sociability. (arXiv:2312.07671v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghadami_A/0/1/0/all/0/1">Ali Ghadami</a>, <a href="http://arxiv.org/find/cs/1/au:+Taghimohammadi_M/0/1/0/all/0/1">Mohammadreza Taghimohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadzadeh_M/0/1/0/all/0/1">Mohammad Mohammadzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseinipour_M/0/1/0/all/0/1">Mohammad Hosseinipour</a>, <a href="http://arxiv.org/find/cs/1/au:+Taheri_A/0/1/0/all/0/1">Alireza Taheri</a></p>
<p>Robots' acceptability among humans and their sociability can be significantly
enhanced by incorporating human-like reactions. Humans can react to
environmental events very quickly and without thinking. An instance where
humans display natural reactions is when they encounter a sudden and loud sound
that startles or frightens them. During such moments, individuals may
instinctively move their hands, turn toward the origin of the sound, and try to
determine the event's cause. This inherent behavior motivated us to explore
this less-studied part of social robotics. In this work, a multi-modal system
composed of an action generator, sound classifier, and YOLO object detector was
designed to sense the environment and, in the presence of sudden loud sounds,
show natural human fear reactions, and finally, locate the fear-causing sound
source in the environment. These unique and valid generated motions and
inferences could imitate intrinsic human reactions and enhance the sociability
of robots. For motion generation, a model based on LSTM and MDN networks was
proposed to synthesize various motions. Also, in the case of sound detection, a
transfer learning model was preferred that used the spectrogram of sound
signals as its input. After developing individual models for sound detection,
motion generation, and image recognition, they were integrated into a
comprehensive fear module that was implemented on the NAO robot. Finally, the
fear module was tested in practical application and two groups of experts and
non-experts filled out a questionnaire to evaluate the performance of the
robot. Given our promising results, this preliminary exploratory research
provides a fresh perspective on social robotics and could be a starting point
for modeling intrinsic human behaviors and emotions in robots.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07685">A Perspective of Q-value Estimation on Offline-to-Online Reinforcement Learning. (arXiv:2312.07685v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinmin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chuming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Y/0/1/0/all/0/1">Yazhe Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaodong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a></p>
<p>Offline-to-online Reinforcement Learning (O2O RL) aims to improve the
performance of offline pretrained policy using only a few online samples. Built
on offline RL algorithms, most O2O methods focus on the balance between RL
objective and pessimism, or the utilization of offline and online samples. In
this paper, from a novel perspective, we systematically study the challenges
that remain in O2O RL and identify that the reason behind the slow improvement
of the performance and the instability of online finetuning lies in the
inaccurate Q-value estimation inherited from offline pretraining. Specifically,
we demonstrate that the estimation bias and the inaccurate rank of Q-value
cause a misleading signal for the policy update, making the standard offline RL
algorithms, such as CQL and TD3-BC, ineffective in the online finetuning. Based
on this observation, we address the problem of Q-value estimation by two
techniques: (1) perturbed value update and (2) increased frequency of Q-value
updates. The first technique smooths out biased Q-value estimation with sharp
peaks, preventing early-stage policy exploitation of sub-optimal actions. The
second one alleviates the estimation bias inherited from offline pretraining by
accelerating learning. Extensive experiments on the MuJoco and Adroit
environments demonstrate that the proposed method, named SO2, significantly
alleviates Q-value estimation issues, and consistently improves the performance
against the state-of-the-art methods by up to 83.1%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07696">Real-time Network Intrusion Detection via Decision Transformers. (arXiv:2312.07696v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingdi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hanhan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_Y/0/1/0/all/0/1">Yongsheng Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Adam_G/0/1/0/all/0/1">Gina Adam</a>, <a href="http://arxiv.org/find/cs/1/au:+Bastian_N/0/1/0/all/0/1">Nathaniel D. Bastian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_T/0/1/0/all/0/1">Tian Lan</a></p>
<p>Many cybersecurity problems that require real-time decision-making based on
temporal observations can be abstracted as a sequence modeling problem, e.g.,
network intrusion detection from a sequence of arriving packets. Existing
approaches like reinforcement learning may not be suitable for such
cybersecurity decision problems, since the Markovian property may not
necessarily hold and the underlying network states are often not observable. In
this paper, we cast the problem of real-time network intrusion detection as
casual sequence modeling and draw upon the power of the transformer
architecture for real-time decision-making. By conditioning a causal decision
transformer on past trajectories, consisting of the rewards, network packets,
and detection decisions, our proposed framework will generate future detection
decisions to achieve the desired return. It enables decision transformers to be
applied to real-time network intrusion detection, as well as a novel tradeoff
between the accuracy and timeliness of detection. The proposed solution is
evaluated on public network intrusion detection datasets and outperforms
several baseline algorithms using reinforcement learning and sequence modeling,
in terms of detection accuracy and timeliness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07705">Brain-optimized inference improves reconstructions of fMRI brain activity. (arXiv:2312.07705v1 [q-bio.NC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Kneeland_R/0/1/0/all/0/1">Reese Kneeland</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ojeda_J/0/1/0/all/0/1">Jordyn Ojeda</a>, <a href="http://arxiv.org/find/q-bio/1/au:+St_Yves_G/0/1/0/all/0/1">Ghislain St-Yves</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Naselaris_T/0/1/0/all/0/1">Thomas Naselaris</a></p>
<p>The release of large datasets and developments in AI have led to dramatic
improvements in decoding methods that reconstruct seen images from human brain
activity. We evaluate the prospect of further improving recent decoding methods
by optimizing for consistency between reconstructions and brain activity during
inference. We sample seed reconstructions from a base decoding method, then
iteratively refine these reconstructions using a brain-optimized encoding model
that maps images to brain activity. At each iteration, we sample a small
library of images from an image distribution (a diffusion model) conditioned on
a seed reconstruction from the previous iteration. We select those that best
approximate the measured brain activity when passed through our encoding model,
and use these images for structural guidance during the generation of the small
library in the next iteration. We reduce the stochasticity of the image
distribution at each iteration, and stop when a criterion on the "width" of the
image distribution is met. We show that when this process is applied to recent
decoding methods, it outperforms the base decoding method as measured by human
raters, a variety of image feature metrics, and alignment to brain activity.
These results demonstrate that reconstruction quality can be significantly
improved by explicitly aligning decoding distributions to brain activity
distributions, even when the seed reconstruction is output from a
state-of-the-art decoding algorithm. Interestingly, the rate of refinement
varies systematically across visual cortex, with earlier visual areas generally
converging more slowly and preferring narrower image distributions, relative to
higher-level brain areas. Brain-optimized inference thus offers a succinct and
novel method for improving reconstructions and exploring the diversity of
representations across visual brain areas.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07711">Leveraging Large Language Models to Build and Execute Computational Workflows. (arXiv:2312.07711v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Duque_A/0/1/0/all/0/1">Alejandro Duque</a>, <a href="http://arxiv.org/find/cs/1/au:+Syed_A/0/1/0/all/0/1">Abdullah Syed</a>, <a href="http://arxiv.org/find/cs/1/au:+Day_K/0/1/0/all/0/1">Kastan V. Day</a>, <a href="http://arxiv.org/find/cs/1/au:+Berry_M/0/1/0/all/0/1">Matthew J. Berry</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_D/0/1/0/all/0/1">Daniel S. Katz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kindratenko_V/0/1/0/all/0/1">Volodymyr V. Kindratenko</a></p>
<p>The recent development of large language models (LLMs) with multi-billion
parameters, coupled with the creation of user-friendly application programming
interfaces (APIs), has paved the way for automatically generating and executing
code in response to straightforward human queries. This paper explores how
these emerging capabilities can be harnessed to facilitate complex scientific
workflows, eliminating the need for traditional coding methods. We present
initial findings from our attempt to integrate Phyloflow with OpenAI's
function-calling API, and outline a strategy for developing a comprehensive
workflow management system based on these concepts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07721">Saturn Platform: Foundation Model Operations and Generative AI for Financial Services. (arXiv:2312.07721v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Busson_A/0/1/0/all/0/1">Antonio J. G. Busson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaio_R/0/1/0/all/0/1">Rennan Gaio</a>, <a href="http://arxiv.org/find/cs/1/au:+Rocha_R/0/1/0/all/0/1">Rafael H. Rocha</a>, <a href="http://arxiv.org/find/cs/1/au:+Evangelista_F/0/1/0/all/0/1">Francisco Evangelista</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizzi_B/0/1/0/all/0/1">Bruno Rizzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_L/0/1/0/all/0/1">Luan Carvalho</a>, <a href="http://arxiv.org/find/cs/1/au:+Miceli_R/0/1/0/all/0/1">Rafael Miceli</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabaioli_M/0/1/0/all/0/1">Marcos Rabaioli</a>, <a href="http://arxiv.org/find/cs/1/au:+Favaro_D/0/1/0/all/0/1">David Favaro</a></p>
<p>Saturn is an innovative platform that assists Foundation Model (FM) building
and its integration with IT operations (Ops). It is custom-made to meet the
requirements of data scientists, enabling them to effectively create and
implement FMs while enhancing collaboration within their technical domain. By
offering a wide range of tools and features, Saturn streamlines and automates
different stages of FM development, making it an invaluable asset for data
science teams. This white paper introduces prospective applications of
generative AI models derived from FMs in the financial sector.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07723">Automated Behavioral Analysis Using Instance Segmentation. (arXiv:2312.07723v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Forest_J/0/1/0/all/0/1">Jeremy Forest</a>, <a href="http://arxiv.org/find/cs/1/au:+Einhorn_M/0/1/0/all/0/1">Matthew Einhorn</a>, <a href="http://arxiv.org/find/cs/1/au:+Cleland_T/0/1/0/all/0/1">Thomas A. Cleland</a></p>
<p>Animal behavior analysis plays a crucial role in various fields, such as life
science and biomedical research. However, the scarcity of available data and
the high cost associated with obtaining a large number of labeled datasets pose
significant challenges. In this research, we propose a novel approach that
leverages instance segmentation-based transfer learning to address these
issues. By capitalizing on fine-tuning the classification head of the instance
segmentation network, we enable the tracking of multiple animals and facilitate
behavior analysis in laboratory-recorded videos. To demonstrate the
effectiveness of our method, we conducted a series of experiments, revealing
that our approach achieves exceptional performance levels, comparable to human
capabilities, across a diverse range of animal behavior analysis tasks.
Moreover, we emphasize the practicality of our solution, as it requires only a
small number of labeled images for training. To facilitate the adoption and
further development of our method, we have developed an open-source
implementation named Annolid (An annotation and instance segmentation-based
multiple animal tracking and behavior analysis package). The codebase is
publicly available on GitHub at https://github.com/cplab/annolid. This resource
serves as a valuable asset for researchers and practitioners interested in
advancing animal behavior analysis through state-of-the-art techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07751">Large Human Language Models: A Need and the Challenges. (arXiv:2312.07751v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Soni_N/0/1/0/all/0/1">Nikita Soni</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1">H. Andrew Schwartz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1">Jo&#xe3;o Sedoc</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1">Niranjan Balasubramanian</a></p>
<p>As research in human-centered NLP advances, there is a growing recognition of
the importance of incorporating human and social factors into NLP models. At
the same time, our NLP systems have become heavily reliant on LLMs, most of
which do not model authors. To build NLP systems that can truly understand
human language, we must better integrate human contexts into LLMs. This brings
to the fore a range of design considerations and challenges in terms of what
human aspects to capture, how to represent them, and what modeling strategies
to pursue. To address these, we advocate for three positions toward creating
large human language models (LHLMs) using concepts from psychological and
behavioral sciences: First, LM training should include the human context.
Second, LHLMs should recognize that people are more than their group(s). Third,
LHLMs should be able to account for the dynamic and temporally-dependent nature
of the human context. We refer to relevant advances and present open challenges
that need to be addressed and their possible solutions in realizing these
goals.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07753">Polynomial-based Self-Attention for Table Representation learning. (arXiv:2312.07753v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jayoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1">Yehjin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1">Noseong Park</a></p>
<p>Structured data, which constitutes a significant portion of existing data
types, has been a long-standing research topic in the field of machine
learning. Various representation learning methods for tabular data have been
proposed, ranging from encoder-decoder structures to Transformers. Among these,
Transformer-based methods have achieved state-of-the-art performance not only
in tabular data but also in various other fields, including computer vision and
natural language processing. However, recent studies have revealed that
self-attention, a key component of Transformers, can lead to an oversmoothing
issue. We show that Transformers for tabular data also face this problem, and
to address the problem, we propose a novel matrix polynomial-based
self-attention layer as a substitute for the original self-attention layer,
which enhances model scalability. In our experiments with three representative
table learning models equipped with our proposed layer, we illustrate that the
layer effectively mitigates the oversmoothing problem and enhances the
representation performance of the existing methods, outperforming the
state-of-the-art table representation methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07767">Spatial Knowledge-Infused Hierarchical Learning: An Application in Flood Mapping on Earth Imagery. (arXiv:2312.07767v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zelin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">Tingsong Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1">Wenchong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhe Jiang</a></p>
<p>Deep learning for Earth imagery plays an increasingly important role in
geoscience applications such as agriculture, ecology, and natural disaster
management. Still, progress is often hindered by the limited training labels.
Given Earth imagery with limited training labels, a base deep neural network
model, and a spatial knowledge base with label constraints, our problem is to
infer the full labels while training the neural network. The problem is
challenging due to the sparse and noisy input labels, spatial uncertainty
within the label inference process, and high computational costs associated
with a large number of sample locations. Existing works on neuro-symbolic
models focus on integrating symbolic logic into neural networks (e.g., loss
function, model architecture, and training label augmentation), but these
methods do not fully address the challenges of spatial data (e.g., spatial
uncertainty, the trade-off between spatial granularity and computational
costs). To bridge this gap, we propose a novel Spatial Knowledge-Infused
Hierarchical Learning (SKI-HL) framework that iteratively infers sample labels
within a multi-resolution hierarchy. Our framework consists of a module to
selectively infer labels in different resolutions based on spatial uncertainty
and a module to train neural network parameters with uncertainty-aware
multi-instance learning. Extensive experiments on real-world flood mapping
datasets show that the proposed model outperforms several baseline methods. The
code is available at \url{https://github.com/ZelinXu2000/SKI-HL}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07779">Tell, don&#x27;t show: Declarative facts influence how LLMs generalize. (arXiv:2312.07779v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meinke_A/0/1/0/all/0/1">Alexander Meinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_O/0/1/0/all/0/1">Owain Evans</a></p>
<p>We examine how large language models (LLMs) generalize from abstract
declarative statements in their training data. As an illustration, consider an
LLM that is prompted to generate weather reports for London in 2050. One
possibility is that the temperatures in the reports match the mean and variance
of reports from 2023 (i.e. matching the statistics of pretraining). Another
possibility is that the reports predict higher temperatures, by incorporating
declarative statements about climate change from scientific papers written in
2023. An example of such a declarative statement is "global temperatures will
increase by $1^{\circ} \mathrm{C}$ by 2050".
</p>
<p>To test the influence of abstract declarative statements, we construct tasks
in which LLMs are finetuned on both declarative and procedural information. We
find that declarative statements influence model predictions, even when they
conflict with procedural information. In particular, finetuning on a
declarative statement $S$ increases the model likelihood for logical
consequences of $S$. The effect of declarative statements is consistent across
three domains: aligning an AI assistant, predicting weather, and predicting
demographic features. Through a series of ablations, we show that the effect of
declarative statements cannot be explained by associative learning based on
matching keywords. Nevertheless, the effect of declarative statements on model
likelihoods is small in absolute terms and increases surprisingly little with
model size (i.e. from 330 million to 175 billion parameters). We argue that
these results have implications for AI risk (in relation to the "treacherous
turn") and for fairness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07784">Robust MRI Reconstruction by Smoothed Unrolling (SMUG). (arXiv:2312.07784v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Liang_S/0/1/0/all/0/1">Shijun Liang</a>, <a href="http://arxiv.org/find/eess/1/au:+Nguyen_V/0/1/0/all/0/1">Van Hoang Minh Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Jia_J/0/1/0/all/0/1">Jinghan Jia</a>, <a href="http://arxiv.org/find/eess/1/au:+Alkhouri_I/0/1/0/all/0/1">Ismail Alkhouri</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ravishankar_S/0/1/0/all/0/1">Saiprasad Ravishankar</a></p>
<p>As the popularity of deep learning (DL) in the field of magnetic resonance
imaging (MRI) continues to rise, recent research has indicated that DL-based
MRI reconstruction models might be excessively sensitive to minor input
disturbances, including worst-case additive perturbations. This sensitivity
often leads to unstable, aliased images. This raises the question of how to
devise DL techniques for MRI reconstruction that can be robust to train-test
variations. To address this problem, we propose a novel image reconstruction
framework, termed Smoothed Unrolling (SMUG), which advances a deep
unrolling-based MRI reconstruction model using a randomized smoothing
(RS)-based robust learning approach. RS, which improves the tolerance of a
model against input noises, has been widely used in the design of adversarial
defense approaches for image classification tasks. Yet, we find that the
conventional design that applies RS to the entire DL-based MRI model is
ineffective. In this paper, we show that SMUG and its variants address the
above issue by customizing the RS process based on the unrolling architecture
of a DL-based MRI reconstruction model. Compared to the vanilla RS approach, we
show that SMUG improves the robustness of MRI reconstruction with respect to a
diverse set of instability sources, including worst-case and random noise
perturbations to input measurements, varying measurement sampling rates, and
different numbers of unrolling steps. Furthermore, we theoretically analyze the
robustness of our method in the presence of perturbations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07795">Traffic Signal Control Using Lightweight Transformers: An Offline-to-Online RL Approach. (arXiv:2312.07795v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xingshuai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Boulet_B/0/1/0/all/0/1">Benoit Boulet</a></p>
<p>Efficient traffic signal control is critical for reducing traffic congestion
and improving overall transportation efficiency. The dynamic nature of traffic
flow has prompted researchers to explore Reinforcement Learning (RL) for
traffic signal control (TSC). Compared with traditional methods, RL-based
solutions have shown preferable performance. However, the application of
RL-based traffic signal controllers in the real world is limited by the low
sample efficiency and high computational requirements of these solutions. In
this work, we propose DTLight, a simple yet powerful lightweight Decision
Transformer-based TSC method that can learn policy from easily accessible
offline datasets. DTLight novelly leverages knowledge distillation to learn a
lightweight controller from a well-trained larger teacher model to reduce
implementation computation. Additionally, it integrates adapter modules to
mitigate the expenses associated with fine-tuning, which makes DTLight
practical for online adaptation with minimal computation and only a few
fine-tuning steps during real deployment. Moreover, DTLight is further enhanced
to be more applicable to real-world TSC problems. Extensive experiments on
synthetic and real-world scenarios show that DTLight pre-trained purely on
offline datasets can outperform state-of-the-art online RL-based methods in
most scenarios. Experiment results also show that online fine-tuning further
improves the performance of DTLight by up to 42.6% over the best online RL
baseline methods. In this work, we also introduce Datasets specifically
designed for TSC with offline RL (referred to as DTRL). Our datasets and code
are publicly available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07796">Harnessing Retrieval-Augmented Generation (RAG) for Uncovering Knowledge Gaps. (arXiv:2312.07796v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hurtado_J/0/1/0/all/0/1">Joan Figuerola Hurtado</a></p>
<p>The paper presents a methodology for uncovering knowledge gaps on the
internet using the Retrieval Augmented Generation (RAG) model. By simulating
user search behaviour, the RAG system identifies and addresses gaps in
information retrieval systems. The study demonstrates the effectiveness of the
RAG system in generating relevant suggestions with a consistent accuracy of
93%. The methodology can be applied in various fields such as scientific
discovery, educational enhancement, research development, market analysis,
search engine optimisation, and content development. The results highlight the
value of identifying and understanding knowledge gaps to guide future
endeavours.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07797">Sentiment analysis in Tourism: Fine-tuning BERT or sentence embeddings concatenation?. (arXiv:2312.07797v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bouabdallaoui_I/0/1/0/all/0/1">Ibrahim Bouabdallaoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerouate_F/0/1/0/all/0/1">Fatima Guerouate</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouhaddour_S/0/1/0/all/0/1">Samya Bouhaddour</a>, <a href="http://arxiv.org/find/cs/1/au:+Saadi_C/0/1/0/all/0/1">Chaimae Saadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sbihi_M/0/1/0/all/0/1">Mohammed Sbihi</a></p>
<p>Undoubtedly that the Bidirectional Encoder representations from Transformers
is the most powerful technique in making Natural Language Processing tasks such
as Named Entity Recognition, Question &amp; Answers or Sentiment Analysis, however,
the use of traditional techniques remains a major potential for the improvement
of recent models, in particular word tokenization techniques and embeddings,
but also the improvement of neural network architectures which are now the core
of each architecture. recent. In this paper, we conduct a comparative study
between Fine-Tuning the Bidirectional Encoder Representations from Transformers
and a method of concatenating two embeddings to boost the performance of a
stacked Bidirectional Long Short-Term Memory-Bidirectional Gated Recurrent
Units model; these two approaches are applied in the context of sentiment
analysis of shopping places in Morocco. A search for the best learning rate was
made at the level of the two approaches, and a comparison of the best
optimizers was made for each sentence embedding combination with regard to the
second approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07814">A Foundational Multimodal Vision Language AI Assistant for Human Pathology. (arXiv:2312.07814v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Ming Y. Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bowen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Williamson_D/0/1/0/all/0/1">Drew F. K. Williamson</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Richard J. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikamura_K/0/1/0/all/0/1">Kenji Ikamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerber_G/0/1/0/all/0/1">Georg Gerber</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_I/0/1/0/all/0/1">Ivy Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_L/0/1/0/all/0/1">Long Phi Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1">Tong Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Parwani_A/0/1/0/all/0/1">Anil V Parwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_F/0/1/0/all/0/1">Faisal Mahmood</a></p>
<p>The field of computational pathology has witnessed remarkable progress in the
development of both task-specific predictive models and task-agnostic
self-supervised vision encoders. However, despite the explosive growth of
generative artificial intelligence (AI), there has been limited study on
building general purpose, multimodal AI assistants tailored to pathology. Here
we present PathChat, a vision-language generalist AI assistant for human
pathology using an in-house developed foundational vision encoder pretrained on
100 million histology images from over 100,000 patient cases and 1.18 million
pathology image-caption pairs. The vision encoder is then combined with a
pretrained large language model and the whole system is finetuned on over
250,000 diverse disease agnostic visual language instructions. We compare
PathChat against several multimodal vision language AI assistants as well as
GPT4V, which powers the commercially available multimodal general purpose AI
assistant ChatGPT-4. When relevant clinical context is provided with the
histology image, PathChat achieved a diagnostic accuracy of 87% on
multiple-choice questions based on publicly available cases of diverse tissue
origins and disease models. Additionally, using open-ended questions and human
expert evaluation, we found that overall PathChat produced more accurate and
pathologist-preferable responses to diverse queries related to pathology. As an
interactive and general vision language AI assistant that can flexibly handle
both visual and natural language inputs, PathChat can potentially find
impactful applications in pathology education, research, and human-in-the-loop
clinical decision making.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07822">Prototypical Self-Explainable Models Without Re-training. (arXiv:2312.07822v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gautam_S/0/1/0/all/0/1">Srishti Gautam</a>, <a href="http://arxiv.org/find/cs/1/au:+Boubekki_A/0/1/0/all/0/1">Ahcene Boubekki</a>, <a href="http://arxiv.org/find/cs/1/au:+Hohne_M/0/1/0/all/0/1">Marina M. C. H&#xf6;hne</a>, <a href="http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1">Michael C. Kampffmeyer</a></p>
<p>Explainable AI (XAI) has unfolded in two distinct research directions with,
on the one hand, post-hoc methods that explain the predictions of a pre-trained
black-box model and, on the other hand, self-explainable models (SEMs) which
are trained directly to provide explanations alongside their predictions. While
the latter is preferred in most safety-critical scenarios, post-hoc approaches
have received the majority of attention until now, owing to their simplicity
and ability to explain base models without retraining. Current SEMs instead,
require complex architectures and heavily regularized loss functions, thus
necessitating specific and costly training. To address this shortcoming and
facilitate wider use of SEMs, we propose a simple yet efficient universal
method called KMEx (K-Means Explainer), which can convert any existing
pre-trained model into a prototypical SEM. The motivation behind KMEx is to
push towards more transparent deep learning-based decision-making via
class-prototype-based explanations that are guaranteed to be diverse and
trustworthy without retraining the base model. We compare models obtained from
KMEx to state-of-the-art SEMs using an extensive qualitative evaluation to
highlight the strengths and weaknesses of each model, further paving the way
toward a more reliable and objective evaluation of SEMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07832">Denoising diffusion-based synthetic generation of three-dimensional (3D) anisotropic microstructures from two-dimensional (2D) micrographs. (arXiv:2312.07832v1 [cond-mat.mtrl-sci])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cond-mat/1/au:+Lee_K/0/1/0/all/0/1">Kang-Hyun Lee</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Yun_G/0/1/0/all/0/1">Gun Jin Yun</a></p>
<p>Integrated computational materials engineering (ICME) has significantly
enhanced the systemic analysis of the relationship between microstructure and
material properties, paving the way for the development of high-performance
materials. However, analyzing microstructure-sensitive material behavior
remains challenging due to the scarcity of three-dimensional (3D)
microstructure datasets. Moreover, this challenge is amplified if the
microstructure is anisotropic, as this results in anisotropic material
properties as well. In this paper, we present a framework for reconstruction of
anisotropic microstructures solely based on two-dimensional (2D) micrographs
using conditional diffusion-based generative models (DGMs). The proposed
framework involves spatial connection of multiple 2D conditional DGMs, each
trained to generate 2D microstructure samples for three different orthogonal
planes. The connected multiple reverse diffusion processes then enable
effective modeling of a Markov chain for transforming noise into a 3D
microstructure sample. Furthermore, a modified harmonized sampling is employed
to enhance the sample quality while preserving the spatial connection between
the slices of anisotropic microstructure samples in 3D space. To validate the
proposed framework, the 2D-to-3D reconstructed anisotropic microstructure
samples are evaluated in terms of both the spatial correlation function and the
physical material behavior. The results demonstrate that the framework is
capable of reproducing not only the statistical distribution of material phases
but also the material properties in 3D space. This highlights the potential
application of the proposed 2D-to-3D reconstruction framework in establishing
microstructure-property linkages, which could aid high-throughput material
design for future studies
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07835">Video Dynamics Prior: An Internal Learning Approach for Robust Video Enhancements. (arXiv:2312.07835v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_G/0/1/0/all/0/1">Gaurav Shrivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Ser-Nam Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1">Abhinav Shrivastava</a></p>
<p>In this paper, we present a novel robust framework for low-level vision
tasks, including denoising, object removal, frame interpolation, and
super-resolution, that does not require any external training data corpus. Our
proposed approach directly learns the weights of neural modules by optimizing
over the corrupted test sequence, leveraging the spatio-temporal coherence and
internal statistics of videos. Furthermore, we introduce a novel spatial
pyramid loss that leverages the property of spatio-temporal patch recurrence in
a video across the different scales of the video. This loss enhances robustness
to unstructured noise in both the spatial and temporal domains. This further
results in our framework being highly robust to degradation in input frames and
yields state-of-the-art results on downstream tasks such as denoising, object
removal, and frame interpolation. To validate the effectiveness of our
approach, we conduct qualitative and quantitative evaluations on standard video
datasets such as DAVIS, UCF-101, and VIMEO90K-T.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07838">Conflict Transformation and Management. From Cognitive Maps to Value Trees. (arXiv:2312.07838v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tosunlu_B/0/1/0/all/0/1">Berkay H. Tosunlu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guillaume_J/0/1/0/all/0/1">Joseph H.A. Guillaume</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsoukias_A/0/1/0/all/0/1">Alexis Tsouki&#xe0;s</a></p>
<p>Conflict transformation and management are complex decision processes with
extremely high stakes at hand and could greatly benefit from formal approaches
to decision support. For this purpose we develop a general framework about how
to use problem structuring methods for such purposes. More precisely we show
how to transform cognitive maps to value trees in order to promote a more
design-oriented approach to decision support aiming at constructing innovative
solutions for conflict management purposes. We show that our findings have a
much wider validity since they allow to move from a descriptive representation
of a problem situation to a more prescriptive one using formal procedures and
models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07848">Finetuning an LLM on Contextual Knowledge of Classics for Q&amp;A. (arXiv:2312.07848v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Strachan_S/0/1/0/all/0/1">Shane Storm Strachan</a></p>
<p>The open-source publishing of large language models (LLMs) has created many
possibilities for how anyone who understands language and has access to a
computer can interact with significant tools of artificial intelligence,
particularly in the context of learning and knowledge dissemination. However,
the utility of these models in specialized fields like Classics is still
largely unexplored. This project is an attempt to merge the knowledge of
Classics with the capabilities of artificial intelligence by finetuning an LLM
to cater to the specific needs of learners and professionals. The goal of this
project is to develop an LLM that not only reproduces contextual knowledge
accurately but also exhibits a consistent "personality" - and, indeed, has
consistent propriety - to appeal to a diverse audience who possess differing
levels of knowledge. A significant portion of this project was dedicated to
refining the dataset, following the principle of "garbage in, garbage out," to
ensure the model generates relevant, useful, and creative responses when given
a prompt (a statement, question, or single word). After training and
evaluation, my model's ability to handle a vast array of different types of
inputs and prompting exceeded expectations for a 355M parameter model, though
its occasional hallucinations (especially when set with a high temperature),
particularly in its assertions about historical events or its own identity,
make it seem somewhat capricious and more work in the form of continuous
finetuning will be undertaken.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07850">Large Language Model Enhanced Multi-Agent Systems for 6G Communications. (arXiv:2312.07850v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1">Feibo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1">Li Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yubo Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kezhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1">Cunhua Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1">Dusit Niyato</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobre_O/0/1/0/all/0/1">Octavia A. Dobre</a></p>
<p>The rapid development of the Large Language Model (LLM) presents huge
opportunities for 6G communications, e.g., network optimization and management
by allowing users to input task requirements to LLMs by nature language.
However, directly applying native LLMs in 6G encounters various challenges,
such as a lack of private communication data and knowledge, limited logical
reasoning, evaluation, and refinement abilities. Integrating LLMs with the
capabilities of retrieval, planning, memory, evaluation and reflection in
agents can greatly enhance the potential of LLMs for 6G communications. To this
end, we propose a multi-agent system with customized communication knowledge
and tools for solving communication related tasks using natural language,
comprising three components: (1) Multi-agent Data Retrieval (MDR), which
employs the condensate and inference agents to refine and summarize
communication knowledge from the knowledge base, expanding the knowledge
boundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning
(MCP), which utilizes multiple planning agents to generate feasible solutions
for the communication related task from different perspectives based on the
retrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which
utilizes the evaluation agent to assess the solutions, and applies the
reflexion agent and refinement agent to provide improvement suggestions for
current solutions. Finally, we validate the effectiveness of the proposed
multi-agent system by designing a semantic communication system, as a case
study of 6G communications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07855">Exploring Popularity Bias in Session-based Recommendation. (arXiv:2312.07855v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haowen Wang</a></p>
<p>Existing work has revealed that large-scale offline evaluation of recommender
systems for user-item interactions is prone to bias caused by the deployed
system itself, as a form of closed loop feedback. Many adopt the
\textit{propensity} concept to analyze or mitigate this empirical issue. In
this work, we extend the analysis to session-based setup and adapted propensity
calculation to the unique characteristics of session-based recommendation
tasks. Our experiments incorporate neural models and KNN-based models, and
cover both the music and the e-commerce domain. We study the distributions of
propensity and different stratification techniques on different datasets and
find that propensity-related traits are actually dataset-specific. We then
leverage the effect of stratification and achieve promising results compared to
the original models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07856">DTL: Disentangled Transfer Learning for Visual Recognition. (arXiv:2312.07856v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_M/0/1/0/all/0/1">Minghao Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1">Ke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jianxin Wu</a></p>
<p>When pre-trained models become rapidly larger, the cost of fine-tuning on
downstream tasks steadily increases, too. To economically fine-tune these
models, parameter-efficient transfer learning (PETL) is proposed, which only
tunes a tiny subset of trainable parameters to efficiently learn quality
representations. However, current PETL methods are facing the dilemma that
during training the GPU memory footprint is not effectively reduced as
trainable parameters. PETL will likely fail, too, if the full fine-tuning
encounters the out-of-GPU-memory issue. This phenomenon happens because
trainable parameters from these methods are generally entangled with the
backbone, such that a lot of intermediate states have to be stored in GPU
memory for gradient propagation. To alleviate this problem, we introduce
Disentangled Transfer Learning (DTL), which disentangles the trainable
parameters from the backbone using a lightweight Compact Side Network (CSN). By
progressively extracting task-specific information with a few low-rank linear
mappings and appropriately adding the information back to the backbone, CSN
effectively realizes knowledge transfer in various downstream tasks. We
conducted extensive experiments to validate the effectiveness of our method.
The proposed method not only reduces a large amount of GPU memory usage and
trainable parameters, but also outperforms existing PETL methods by a
significant margin in accuracy, achieving new state-of-the-art on several
standard benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07867">BESTMVQA: A Benchmark Evaluation System for Medical Visual Question Answering. (arXiv:2312.07867v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1">Xiaojie Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zixin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liangzhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoli Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Feiyan Liu</a></p>
<p>Medical Visual Question Answering (Med-VQA) is a very important task in
healthcare industry, which answers a natural language question with a medical
image. Existing VQA techniques in information systems can be directly applied
to solving the task. However, they often suffer from (i) the data insufficient
problem, which makes it difficult to train the state of the arts (SOTAs) for
the domain-specific task, and (ii) the reproducibility problem, that many
existing models have not been thoroughly evaluated in a unified experimental
setup. To address these issues, this paper develops a Benchmark Evaluation
SysTem for Medical Visual Question Answering, denoted by BESTMVQA. Given
self-collected clinical data, our system provides a useful tool for users to
automatically build Med-VQA datasets, which helps overcoming the data
insufficient problem. Users also can conveniently select a wide spectrum of
SOTA models from our model library to perform a comprehensive empirical study.
With simple configurations, our system automatically trains and evaluates the
selected models over a benchmark dataset, and reports the comprehensive results
for users to develop new techniques or perform medical practice. Limitations of
existing work are overcome (i) by the data generation tool, which automatically
constructs new datasets from unstructured clinical data, and (ii) by evaluating
SOTAs on benchmark datasets in a unified experimental setup. The demonstration
video of our system can be found at https://youtu.be/QkEeFlu1x4A. Our code and
data will be available soon.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07876">Causality Analysis for Evaluating the Security of Large Language Models. (arXiv:2312.07876v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jun Sun</a></p>
<p>Large Language Models (LLMs) such as GPT and Llama2 are increasingly adopted
in many safety-critical applications. Their security is thus essential. Even
with considerable efforts spent on reinforcement learning from human feedback
(RLHF), recent studies have shown that LLMs are still subject to attacks such
as adversarial perturbation and Trojan attacks. Further research is thus needed
to evaluate their security and/or understand the lack of it. In this work, we
propose a framework for conducting light-weight causality-analysis of LLMs at
the token, layer, and neuron level. We applied our framework to open-source
LLMs such as Llama2 and Vicuna and had multiple interesting discoveries. Based
on a layer-level causality analysis, we show that RLHF has the effect of
overfitting a model to harmful prompts. It implies that such security can be
easily overcome by `unusual' harmful prompts. As evidence, we propose an
adversarial perturbation method that achieves 100\% attack success rate on the
red-teaming tasks of the Trojan Detection Competition 2023. Furthermore, we
show the existence of one mysterious neuron in both Llama2 and Vicuna that has
an unreasonably high causal effect on the output. While we are uncertain on why
such a neuron exists, we show that it is possible to conduct a ``Trojan''
attack targeting that particular neuron to completely cripple the LLM, i.e., we
can generate transferable suffixes to prompts that frequently make the LLM
produce meaningless responses.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07879">CoIE: Chain-of-Instruct Editing for Multi-Attribute Face Manipulation. (arXiv:2312.07879v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhenduo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bowen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guang Liu</a></p>
<p>Current text-to-image editing models often encounter challenges with smoothly
manipulating multiple attributes using a single instruction. Taking inspiration
from the Chain-of-Thought prompting technique utilized in language models, we
present an innovative concept known as Chain-of-Instruct Editing (CoIE), which
enhances the capabilities of these models through step-by-step editing using a
series of instructions. In particular, in the context of face manipulation, we
leverage the contextual learning abilities of a pretrained Large Language Model
(LLM), such as GPT-4, to generate a sequence of instructions from the original
input, utilizing a purpose-designed 1-shot template. To further improve the
precision of each editing step, we conduct fine-tuning on the editing models
using our self-constructed instruction-guided face editing dataset,
Instruct-CelebA. And additionally, we incorporate a super-resolution module to
mitigate the adverse effects of editability and quality degradation.
Experimental results across various challenging cases confirm the significant
boost in multi-attribute facial image manipulation using chain-of-instruct
editing. This is evident in enhanced editing success rates, measured by CLIPSim
and Coverage metrics, improved by 17.86% and 85.45% respectively, and
heightened controllability indicated by Preserve L1 and Quality metrics,
improved by 11.58% and 4.93% respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07885">RAT: Reinforcement-Learning-Driven and Adaptive Testing for Vulnerability Discovery in Web Application Firewalls. (arXiv:2312.07885v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amouei_M/0/1/0/all/0/1">Mohammadhossein Amouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezvani_M/0/1/0/all/0/1">Mohsen Rezvani</a>, <a href="http://arxiv.org/find/cs/1/au:+Fateh_M/0/1/0/all/0/1">Mansoor Fateh</a></p>
<p>Due to the increasing sophistication of web attacks, Web Application
Firewalls (WAFs) have to be tested and updated regularly to resist the
relentless flow of web attacks. In practice, using a brute-force attack to
discover vulnerabilities is infeasible due to the wide variety of attack
patterns. Thus, various black-box testing techniques have been proposed in the
literature. However, these techniques suffer from low efficiency. This paper
presents Reinforcement-Learning-Driven and Adaptive Testing (RAT), an automated
black-box testing strategy to discover injection vulnerabilities in WAFs. In
particular, we focus on SQL injection and Cross-site Scripting, which have been
among the top ten vulnerabilities over the past decade. More specifically, RAT
clusters similar attack samples together. It then utilizes a reinforcement
learning technique combined with a novel adaptive search algorithm to discover
almost all bypassing attack patterns efficiently. We compare RAT with three
state-of-the-art methods considering their objectives. The experiments show
that RAT performs 33.53% and 63.16% on average better than its counterparts in
discovering the most possible bypassing payloads and reducing the number of
attempts before finding the first bypassing payload when testing
well-configured WAFs, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07886">Modality Plug-and-Play: Elastic Modality Adaptation in Multimodal LLMs for Embodied AI. (arXiv:2312.07886v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Boyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wei Gao</a></p>
<p>Large Language Models (LLMs) are capable of reasoning over diverse input data
modalities through pre-trained encoders. However, the growing diversity of
input data modalities prevents incorporating all modalities into LLMs,
especially when LLMs are deployed on resource-constrained edge devices for
embodied AI applications. Instead, a better option is to adaptively involve
only the useful modalities at runtime, depending on the current environmental
contexts and task requirements. For such modality adaptation, existing work
adopts fixed connections between encoders and the LLM's input layer, leading to
high training cost at runtime and ineffective cross-modal interaction. In this
paper, we address these limitations by presenting mPnP-LLM, a new technique
that allows fully elastic, automated and prompt runtime modality adaptation, by
connecting unimodal encoders to a flexible set of last LLM blocks and making
such latent connections fully trainable at runtime. Experiments over the
nuScenes-QA dataset show that mPnP-LLM can achieve up to 3.7x FLOPs reduction
and 30% GPU memory usage reduction, while retaining on-par accuracy with the
existing schemes. Under the same compute budget, mPnP-LLM improves the task
accuracy by up to 4% compared to the best existing scheme.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07899">Morphological Profiling for Drug Discovery in the Era of Deep Learning. (arXiv:2312.07899v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Tang_Q/0/1/0/all/0/1">Qiaosi Tang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ratnayake_R/0/1/0/all/0/1">Ranjala Ratnayake</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Seabra_G/0/1/0/all/0/1">Gustavo Seabra</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Jiang_Z/0/1/0/all/0/1">Zhe Jiang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Fang_R/0/1/0/all/0/1">Ruogu Fang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cui_L/0/1/0/all/0/1">Lina Cui</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ding_Y/0/1/0/all/0/1">Yousong Ding</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kahveci_T/0/1/0/all/0/1">Tamer Kahveci</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_C/0/1/0/all/0/1">Chenglong Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Luesch_H/0/1/0/all/0/1">Hendrik Luesch</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_Y/0/1/0/all/0/1">Yanjun Li</a></p>
<p>Morphological profiling is a valuable tool in phenotypic drug discovery. The
advent of high-throughput automated imaging has enabled the capturing of a wide
range of morphological features of cells or organisms in response to
perturbations at the single-cell resolution. Concurrently, significant advances
in machine learning and deep learning, especially in computer vision, have led
to substantial improvements in analyzing large-scale high-content images at
high-throughput. These efforts have facilitated understanding of compound
mechanism-of-action (MOA), drug repurposing, characterization of cell
morphodynamics under perturbation, and ultimately contributing to the
development of novel therapeutics. In this review, we provide a comprehensive
overview of the recent advances in the field of morphological profiling. We
summarize the image profiling analysis workflow, survey a broad spectrum of
analysis strategies encompassing feature engineering- and deep learning-based
approaches, and introduce publicly available benchmark datasets. We place a
particular emphasis on the application of deep learning in this pipeline,
covering cell segmentation, image representation learning, and multimodal
learning. Additionally, we illuminate the application of morphological
profiling in phenotypic drug discovery and highlight potential challenges and
opportunities in this field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07901">Artificial Intelligence Studies in Cartography: A Review and Synthesis of Methods, Applications, and Ethics. (arXiv:2312.07901v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1">Yuhao Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Song Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_R/0/1/0/all/0/1">Robert E. Roth</a></p>
<p>The past decade has witnessed the rapid development of geospatial artificial
intelligence (GeoAI) primarily due to the ground-breaking achievements in deep
learning and machine learning. A growing number of scholars from cartography
have demonstrated successfully that GeoAI can accelerate previously complex
cartographic design tasks and even enable cartographic creativity in new ways.
Despite the promise of GeoAI, researchers and practitioners have growing
concerns about the ethical issues of GeoAI for cartography. In this paper, we
conducted a systematic content analysis and narrative synthesis of research
studies integrating GeoAI and cartography to summarize current research and
development trends regarding the usage of GeoAI for cartographic design. Based
on this review and synthesis, we first identify dimensions of GeoAI methods for
cartography such as data sources, data formats, map evaluations, and six
contemporary GeoAI models, each of which serves a variety of cartographic
tasks. These models include decision trees, knowledge graph and semantic web
technologies, deep convolutional neural networks, generative adversarial
networks, graph neural networks, and reinforcement learning. Further, we
summarize seven cartographic design applications where GeoAI have been
effectively employed: generalization, symbolization, typography, map reading,
map interpretation, map analysis, and map production. We also raise five
potential ethical challenges that need to be addressed in the integration of
GeoAI for cartography: commodification, responsibility, privacy, bias, and
(together) transparency, explainability, and provenance. We conclude by
identifying four potential research directions for future cartographic research
with GeoAI: GeoAI-enabled active cartographic symbolism, human-in-the-loop
GeoAI for cartography, GeoAI-based mapping-as-a-service, and generative GeoAI
for cartography.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07910">PromptBench: A Unified Library for Evaluation of Large Language Models. (arXiv:2312.07910v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1">Kaijie Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qinlin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a></p>
<p>The evaluation of large language models (LLMs) is crucial to assess their
performance and mitigate potential security risks. In this paper, we introduce
PromptBench, a unified library to evaluate LLMs. It consists of several key
components that are easily used and extended by researchers: prompt
construction, prompt engineering, dataset and model loading, adversarial prompt
attack, dynamic evaluation protocols, and analysis tools. PromptBench is
designed to be an open, general, and flexible codebase for research purposes
that can facilitate original study in creating new benchmarks, deploying
downstream applications, and designing new evaluation protocols. The code is
available at: https://github.com/microsoft/promptbench and will be continuously
supported.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07917">On Designing Multi-UAV aided Wireless Powered Dynamic Communication via Hierarchical Deep Reinforcement Learning. (arXiv:2312.07917v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Ze Yu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_Y/0/1/0/all/0/1">Yue Ling Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Sheng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1">Gege Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kaishun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Leung_V/0/1/0/all/0/1">Victor C. M. Leung</a></p>
<p>This paper proposes a novel design on the wireless powered communication
network (WPCN) in dynamic environments under the assistance of multiple
unmanned aerial vehicles (UAVs). Unlike the existing studies, where the
low-power wireless nodes (WNs) often conform to the coherent
harvest-then-transmit protocol, under our newly proposed double-threshold based
WN type updating rule, each WN can dynamically and repeatedly update its WN
type as an E-node for non-linear energy harvesting over time slots or an I-node
for transmitting data over sub-slots. To maximize the total transmission data
size of all the WNs over T slots, each of the UAVs individually determines its
trajectory and binary wireless energy transmission (WET) decisions over times
slots and its binary wireless data collection (WDC) decisions over sub-slots,
under the constraints of each UAV's limited on-board energy and each WN's node
type updating rule. However, due to the UAVs' tightly-coupled trajectories with
their WET and WDC decisions, as well as each WN's time-varying battery energy,
this problem is difficult to solve optimally. We then propose a new multi-agent
based hierarchical deep reinforcement learning (MAHDRL) framework with two
tiers to solve the problem efficiently, where the soft actor critic (SAC)
policy is designed in tier-1 to determine each UAV's continuous trajectory and
binary WET decision over time slots, and the deep-Q learning (DQN) policy is
designed in tier-2 to determine each UAV's binary WDC decisions over sub-slots
under the given UAV trajectory from tier-1. Both of the SAC policy and the DQN
policy are executed distributively at each UAV. Finally, extensive simulation
results are provided to validate the outweighed performance of the proposed
MAHDRL approach over various state-of-the-art benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07928">Bayesian inversion of GPR waveforms for uncertainty-aware sub-surface material characterization. (arXiv:2312.07928v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Aziz_I/0/1/0/all/0/1">Ishfaq Aziz</a>, <a href="http://arxiv.org/find/eess/1/au:+Soltanaghai_E/0/1/0/all/0/1">Elahe Soltanaghai</a>, <a href="http://arxiv.org/find/eess/1/au:+Watts_A/0/1/0/all/0/1">Adam Watts</a>, <a href="http://arxiv.org/find/eess/1/au:+Alipour_M/0/1/0/all/0/1">Mohamad Alipour</a></p>
<p>Accurate estimation of sub-surface properties like moisture content and depth
of layers is crucial for applications spanning sub-surface condition
monitoring, precision agriculture, and effective wildfire risk assessment. Soil
in nature is often covered by overlaying surface material, making its
characterization using conventional methods challenging. In addition, the
estimation of the properties of the overlaying layer is crucial for
applications like wildfire assessment. This study thus proposes a Bayesian
model-updating-based approach for ground penetrating radar (GPR) waveform
inversion to predict sub-surface properties like the moisture contents and
depths of the soil layer and overlaying material accumulated above the soil.
The dielectric permittivity of material layers were predicted with the proposed
method, along with other parameters, including depth and electrical
conductivity of layers. The proposed Bayesian model updating approach yields
probabilistic estimates of these parameters that can provide information about
the confidence and uncertainty related to the estimates. The methodology was
evaluated for a diverse range of experimental data collected through laboratory
and field investigations. Laboratory investigations included variations in soil
moisture values and depth of the top layer (or overlaying material), and the
field investigation included measurement of field soil moisture for sixteen
days. The results demonstrated predictions consistent with time-domain
reflectometry (TDR) measurements and conventional gravimetric tests. The top
layer depth could also be predicted with reasonable accuracy. The proposed
method provides a promising approach for uncertainty-aware sub-surface
parameter estimation that can enable decision-making for risk assessment across
a wide range of applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07932">A Novel Framework Based on Variational Quantum Algorithms: Revolutionizing Image Classification. (arXiv:2312.07932v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Chen_Y/0/1/0/all/0/1">Yixiong Chen</a></p>
<p>Image classification is a crucial task in machine learning. In recent years,
this field has witnessed rapid development, with a series of image
classification models being proposed and achieving state-of-the-art (SOTA)
results. Parallelly, with the advancement of quantum technologies, quantum
machine learning has attracted a lot of interest. In particular, a class of
algorithms known as variational quantum algorithms (VQAs) has been extensively
studied to improve the performance of classical machine learning. In this
paper, we propose a novel image classification framework using VQAs. The major
advantage of our framework is the elimination of the need for the global
pooling operation typically performed at the end of classical image
classification models. While global pooling can help to reduce computational
complexity, it often results in a significant loss of information. By removing
the global pooling module before the output layer, our approach allows for
effectively capturing more discriminative features and fine-grained details in
images, leading to improved classification performance. Moreover, employing
VQAs enables our framework to have fewer parameters compared to the classical
framework, even in the absence of global pooling, which makes it more
advantageous in preventing overfitting. We apply our method to different SOTA
image classification models and demonstrate the superiority of the proposed
quantum architecture over its classical counterpart through a series of
experiments on public datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07952">Meta-learning to Calibrate Gaussian Processes with Deep Kernels for Regression Uncertainty Estimation. (arXiv:2312.07952v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1">Tomoharu Iwata</a>, <a href="http://arxiv.org/find/stat/1/au:+Kumagai_A/0/1/0/all/0/1">Atsutoshi Kumagai</a></p>
<p>Although Gaussian processes (GPs) with deep kernels have been successfully
used for meta-learning in regression tasks, its uncertainty estimation
performance can be poor. We propose a meta-learning method for calibrating deep
kernel GPs for improving regression uncertainty estimation performance with a
limited number of training data. The proposed method meta-learns how to
calibrate uncertainty using data from various tasks by minimizing the test
expected calibration error, and uses the knowledge for unseen tasks. We design
our model such that the adaptation and calibration for each task can be
performed without iterative procedures, which enables effective meta-learning.
In particular, a task-specific uncalibrated output distribution is modeled by a
GP with a task-shared encoder network, and it is transformed to a calibrated
one using a cumulative density function of a task-specific Gaussian mixture
model (GMM). By integrating the GP and GMM into our neural network-based model,
we can meta-learn model parameters in an end-to-end fashion. Our experiments
demonstrate that the proposed method improves uncertainty estimation
performance while keeping high regression performance compared with the
existing methods using real-world datasets in few-shot settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07955">Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking. (arXiv:2312.07955v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1">Shengsheng Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_D/0/1/0/all/0/1">Dizhan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huaiwen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Changsheng Xu</a></p>
<p>Researchers have recently found that Self-Supervised Learning (SSL) is
vulnerable to backdoor attacks. The attacker can embed hidden SSL backdoors via
a few poisoned examples in the training dataset and maliciously manipulate the
behavior of downstream models. To defend against SSL backdoor attacks, a
feasible route is to detect and remove the poisonous samples in the training
set. However, the existing SSL backdoor defense method fails to detect the
poisonous samples precisely. In this paper, we propose to erase the SSL
backdoor by cluster activation masking and propose a novel PoisonCAM method.
After obtaining the threat model trained on the poisoned dataset, our method
can precisely detect poisonous samples based on the assumption that masking the
backdoor trigger can effectively change the activation of a downstream
clustering model. In experiments, our PoisonCAM achieves 96% accuracy for
backdoor trigger detection compared to 3% of the state-of-the-art method on
poisoned ImageNet-100. Moreover, our proposed PoisonCAM significantly improves
the performance of the trained SSL model under backdoor attacks compared to the
state-of-the-art method. Our code will be available at
https://github.com/LivXue/PoisonCAM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07961">Robust Few-Shot Named Entity Recognition with Boundary Discrimination and Correlation Purification. (arXiv:2312.07961v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1">Xiaojun Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chunxia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tianxiang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhendong Niu</a></p>
<p>Few-shot named entity recognition (NER) aims to recognize novel named
entities in low-resource domains utilizing existing knowledge. However, the
present few-shot NER models assume that the labeled data are all clean without
noise or outliers, and there are few works focusing on the robustness of the
cross-domain transfer learning ability to textual adversarial attacks in
Few-shot NER. In this work, we comprehensively explore and assess the
robustness of few-shot NER models under textual adversarial attack scenario,
and found the vulnerability of existing few-shot NER models. Furthermore, we
propose a robust two-stage few-shot NER method with Boundary Discrimination and
Correlation Purification (BDCP). Specifically, in the span detection stage, the
entity boundary discriminative module is introduced to provide a highly
distinguishing boundary representation space to detect entity spans. In the
entity typing stage, the correlations between entities and contexts are
purified by minimizing the interference information and facilitating
correlation generalization to alleviate the perturbations caused by textual
adversarial attacks. In addition, we construct adversarial examples for
few-shot NER based on public datasets Few-NERD and Cross-Dataset. Comprehensive
evaluations on those two groups of few-shot NER datasets containing adversarial
examples demonstrate the robustness and superiority of the proposed method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07966">A multi-sourced data and agent-based approach for complementing Time Use Surveys in the context of residential human activity and load curve simulation. (arXiv:2312.07966v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schumann_M/0/1/0/all/0/1">Mathieu Schumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynaud_Q/0/1/0/all/0/1">Quentin Reynaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Sempe_F/0/1/0/all/0/1">Fran&#xe7;ois Semp&#xe9;</a> (OASIS), <a href="http://arxiv.org/find/cs/1/au:+Guibourdenche_J/0/1/0/all/0/1">Julien Guibourdenche</a> (RIFT, UNIGE), <a href="http://arxiv.org/find/cs/1/au:+Ly_J/0/1/0/all/0/1">Jean-Baptiste Ly</a> (CPU), <a href="http://arxiv.org/find/cs/1/au:+Sabouret_N/0/1/0/all/0/1">Nicolas Sabouret</a> (CPU, CPU, CPU)</p>
<p>To address the major issues associated with using Time-Use Survey (TUS) for
simulating residential load curves, we present the SMACH approach, which
combines qualitative and quantitative data with agent-based simulation. Our
model consists of autonomous agents assigned with daily tasks. The agents try
to accomplish their assigned tasks to the best of their abilities. Quantitative
data are used to generate tasks assignments. Qualitative studies allow us to
define how agents select, based on plausible cognitive principles, the tasks to
accomplish depending on the context. Our results show a better representation
of weekdays and weekends, a more flexible association of tasks with appliances,
and an improved simulation of load curves compared to real data. Highlights
$\bullet$ Discussion about Time-Use Surveys (TUS) limits and the use of TUS in
activity and energy simulation $\bullet$ Presentation of complementary data
both qualitative and quantitative used to complement TUS data $\bullet$
Proposition of an agent-based approach that balances these limitations
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07971">LMD: Faster Image Reconstruction with Latent Masking Diffusion. (arXiv:2312.07971v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhiyuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+yu_z/0/1/0/all/0/1">zhihuan yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianjun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a></p>
<p>As a class of fruitful approaches, diffusion probabilistic models (DPMs) have
shown excellent advantages in high-resolution image reconstruction. On the
other hand, masked autoencoders (MAEs), as popular self-supervised vision
learners, have demonstrated simpler and more effective image reconstruction and
transfer capabilities on downstream tasks. However, they all require extremely
high training costs, either due to inherent high temporal-dependence (i.e.,
excessively long diffusion steps) or due to artificially low spatial-dependence
(i.e., human-formulated high mask ratio, such as 0.75). To the end, this paper
presents LMD, a faster image reconstruction framework with latent masking
diffusion. First, we propose to project and reconstruct images in latent space
through a pre-trained variational autoencoder, which is theoretically more
efficient than in the pixel-based space. Then, we combine the advantages of
MAEs and DPMs to design a progressive masking diffusion model, which gradually
increases the masking proportion by three different schedulers and reconstructs
the latent features from simple to difficult, without sequentially performing
denoising diffusion as in DPMs or using fixed high masking ratio as in MAEs, so
as to alleviate the high training time-consumption predicament. Our approach
allows for learning high-capacity models and accelerate their training (by 3x
or more) and barely reduces the original accuracy. Inference speed in
downstream tasks also significantly outperforms the previous approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07983">Multi-perspective Feedback-attention Coupling Model for Continuous-time Dynamic Graphs. (arXiv:2312.07983v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaobo Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhipeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hailong Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_J/0/1/0/all/0/1">Jin Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhanheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liying Wang</a></p>
<p>Recently, representation learning over graph networks has gained popularity,
with various models showing promising results. Despite this, several challenges
persist: 1) most methods are designed for static or discrete-time dynamic
graphs; 2) existing continuous-time dynamic graph algorithms focus on a single
evolving perspective; and 3) many continuous-time dynamic graph approaches
necessitate numerous temporal neighbors to capture long-term dependencies. In
response, this paper introduces the Multi-Perspective Feedback-Attention
Coupling (MPFA) model. MPFA incorporates information from both evolving and raw
perspectives, efficiently learning the interleaved dynamics of observed
processes. The evolving perspective employs temporal self-attention to
distinguish continuously evolving temporal neighbors for information
aggregation. Through dynamic updates, this perspective can capture long-term
dependencies using a small number of temporal neighbors. Meanwhile, the raw
perspective utilizes a feedback attention module with growth characteristic
coefficients to aggregate raw neighborhood information. Experimental results on
a self-organizing dataset and seven public datasets validate the efficacy and
competitiveness of our proposed model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07993">A Unified View on Forgetting and Strong Equivalence Notions in Answer Set Programming. (arXiv:2312.07993v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saribatur_Z/0/1/0/all/0/1">Zeynep G. Saribatur</a>, <a href="http://arxiv.org/find/cs/1/au:+Woltran_S/0/1/0/all/0/1">Stefan Woltran</a></p>
<p>Answer Set Programming (ASP) is a prominent rule-based language for knowledge
representation and reasoning with roots in logic programming and non-monotonic
reasoning. The aim to capture the essence of removing (ir)relevant details in
ASP programs led to the investigation of different notions, from strong
persistence (SP) forgetting, to faithful abstractions, and, recently, strong
simplifications, where the latter two can be seen as relaxed and strengthened
notions of forgetting, respectively. Although it was observed that these
notions are related, especially given that they have characterizations through
the semantics for strong equivalence, it remained unclear whether they can be
brought together. In this work, we bridge this gap by introducing a novel
relativized equivalence notion, which is a relaxation of the recent
simplification notion, that is able to capture all related notions from the
literature. We provide necessary and sufficient conditions for relativized
simplifiability, which shows that the challenging part is for when the context
programs do not contain all the atoms to remove. We then introduce an operator
that combines projection and a relaxation of (SP)-forgetting to obtain the
relativized simplifications. We furthermore present complexity results that
complete the overall picture.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08012">uSF: Learning Neural Semantic Field with Uncertainty. (arXiv:2312.08012v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Skorokhodov_V/0/1/0/all/0/1">Vsevolod Skorokhodov</a>, <a href="http://arxiv.org/find/cs/1/au:+Drozdova_D/0/1/0/all/0/1">Darya Drozdova</a>, <a href="http://arxiv.org/find/cs/1/au:+Yudin_D/0/1/0/all/0/1">Dmitry Yudin</a></p>
<p>Recently, there has been an increased interest in NeRF methods which
reconstruct differentiable representation of three-dimensional scenes. One of
the main limitations of such methods is their inability to assess the
confidence of the model in its predictions. In this paper, we propose a new
neural network model for the formation of extended vector representations,
called uSF, which allows the model to predict not only color and semantic label
of each point, but also estimate the corresponding values of uncertainty. We
show that with a small number of images available for training, a model
quantifying uncertainty performs better than a model without such
functionality. Code of the uSF approach is publicly available at
https://github.com/sevashasla/usf/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08021">Improving search relevance of Azure Cognitive Search by Bayesian optimization. (arXiv:2312.08021v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Agarwal_N/0/1/0/all/0/1">Nitin Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Ashish Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+R_K/0/1/0/all/0/1">Kiran R</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Manish Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Boue_L/0/1/0/all/0/1">Laurent Bou&#xe9;</a></p>
<p>Azure Cognitive Search (ACS) has emerged as a major contender in "Search as a
Service" cloud products in recent years. However, one of the major challenges
for ACS users is to improve the relevance of the search results for their
specific usecases. In this paper, we propose a novel method to find the optimal
ACS configuration that maximizes search relevance for a specific usecase
(product search, document search...) The proposed solution improves key online
marketplace metrics such as click through rates (CTR) by formulating the search
relevance problem as hyperparameter tuning. We have observed significant
improvements in real-world search call to action (CTA) rate in multiple
marketplaces by introducing optimized weights generated from the proposed
approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08027">Helping Language Models Learn More: Multi-dimensional Task Prompt for Few-shot Tuning. (arXiv:2312.08027v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Weng_J/0/1/0/all/0/1">Jinta Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiarui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yue Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fa_D/0/1/0/all/0/1">Daidong Fa</a>, <a href="http://arxiv.org/find/cs/1/au:+Xuand_X/0/1/0/all/0/1">Xiaofeng Xuand</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Heyan Huang</a></p>
<p>Large language models (LLMs) can be used as accessible and intelligent
chatbots by constructing natural language queries and directly inputting the
prompt into the large language model. However, different prompt' constructions
often lead to uncertainty in the answers and thus make it hard to utilize the
specific knowledge of LLMs (like ChatGPT). To alleviate this, we use an
interpretable structure to explain the prompt learning principle in LLMs, which
certificates that the effectiveness of language models is determined by
position changes of the task's related tokens. Therefore, we propose MTPrompt,
a multi-dimensional task prompt learning method consisting based on
task-related object, summary, and task description information. By
automatically building and searching for appropriate prompts, our proposed
MTPrompt achieves the best results on few-shot samples setting and five
different datasets. In addition, we demonstrate the effectiveness and stability
of our method in different experimental settings and ablation experiments. In
interaction with large language models, embedding more task-related information
into prompts will make it easier to stimulate knowledge embedded in large
language models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08033">Beyond Top-Class Agreement: Using Divergences to Forecast Performance under Distribution Shift. (arXiv:2312.08033v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schirmer_M/0/1/0/all/0/1">Mona Schirmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nalisnick_E/0/1/0/all/0/1">Eric Nalisnick</a></p>
<p>Knowing if a model will generalize to data 'in the wild' is crucial for safe
deployment. To this end, we study model disagreement notions that consider the
full predictive distribution - specifically disagreement based on Hellinger
distance, Jensen-Shannon and Kullback-Leibler divergence. We find that
divergence-based scores provide better test error estimates and detection rates
on out-of-distribution data compared to their top-1 counterparts. Experiments
involve standard vision and foundation models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08056">Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and Multi-Source Supervision. (arXiv:2312.08056v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shengguang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenglun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1">Qi Su</a></p>
<p>Ancient artifacts are an important medium for cultural preservation and
restoration. However, many physical copies of artifacts are either damaged or
lost, leaving a blank space in archaeological and historical studies that calls
for artifact image generation techniques. Despite the significant advancements
in open-domain text-to-image synthesis, existing approaches fail to capture the
important domain knowledge presented in the textual description, resulting in
errors in recreated images such as incorrect shapes and patterns. In this
paper, we propose a novel knowledge-aware artifact image synthesis approach
that brings lost historical objects accurately into their visual forms. We use
a pretrained diffusion model as backbone and introduce three key techniques to
enhance the text-to-image generation framework: 1) we construct prompts with
explicit archaeological knowledge elicited from large language models (LLMs);
2) we incorporate additional textual guidance to correlated historical
expertise in a contrastive manner; 3) we introduce further visual-semantic
constraints on edge and perceptual features that enable our model to learn more
intricate visual details of the artifacts. Compared to existing approaches, our
proposed model produces higher-quality artifact images that align better with
the implicit details and historical knowledge contained within written
documents, thus achieving significant improvements across automatic metrics and
in human evaluation. Our code and data are available at
https://github.com/danielwusg/artifact_diffusion.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08057">Combinatorial Stochastic-Greedy Bandit. (arXiv:2312.08057v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fourati_F/0/1/0/all/0/1">Fares Fourati</a>, <a href="http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1">Christopher John Quinn</a>, <a href="http://arxiv.org/find/cs/1/au:+Alouini_M/0/1/0/all/0/1">Mohamed-Slim Alouini</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1">Vaneet Aggarwal</a></p>
<p>We propose a novel combinatorial stochastic-greedy bandit (SGB) algorithm for
combinatorial multi-armed bandit problems when no extra information other than
the joint reward of the selected set of $n$ arms at each time step $t\in [T]$
is observed. SGB adopts an optimized stochastic-explore-then-commit approach
and is specifically designed for scenarios with a large set of base arms.
Unlike existing methods that explore the entire set of unselected base arms
during each selection step, our SGB algorithm samples only an optimized
proportion of unselected arms and selects actions from this subset. We prove
that our algorithm achieves a $(1-1/e)$-regret bound of
$\mathcal{O}(n^{\frac{1}{3}} k^{\frac{2}{3}} T^{\frac{2}{3}}
\log(T)^{\frac{2}{3}})$ for monotone stochastic submodular rewards, which
outperforms the state-of-the-art in terms of the cardinality constraint $k$.
Furthermore, we empirically evaluate the performance of our algorithm in the
context of online constrained social influence maximization. Our results
demonstrate that our proposed approach consistently outperforms the other
algorithms, increasing the performance gap as $k$ grows.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08063">Estimation of Concept Explanations Should be Uncertainty Aware. (arXiv:2312.08063v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Piratla_V/0/1/0/all/0/1">Vihari Piratla</a>, <a href="http://arxiv.org/find/cs/1/au:+Heo_J/0/1/0/all/0/1">Juyeon Heo</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sukriti Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a></p>
<p>Model explanations are very valuable for interpreting and debugging
prediction models. We study a specific kind of global explanations called
Concept Explanations, where the goal is to interpret a model using
human-understandable concepts. Recent advances in multi-modal learning
rekindled interest in concept explanations and led to several label-efficient
proposals for estimation. However, existing estimation methods are unstable to
the choice of concepts or dataset that is used for computing explanations. We
observe that instability in explanations is due to high variance in point
estimation of importance scores. We propose an uncertainty aware Bayesian
estimation method, which readily improved reliability of the concept
explanations. We demonstrate with theoretical analysis and empirical evaluation
that explanations computed by our method are more reliable while also being
label-efficient and faithful.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08064">Exploring the Impact of Lay User Feedback for Improving AI Fairness. (arXiv:2312.08064v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Taka_E/0/1/0/all/0/1">Evdoxia Taka</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakao_Y/0/1/0/all/0/1">Yuri Nakao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonoda_R/0/1/0/all/0/1">Ryosuke Sonoda</a>, <a href="http://arxiv.org/find/cs/1/au:+Yokota_T/0/1/0/all/0/1">Takuya Yokota</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1">Lin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpf_S/0/1/0/all/0/1">Simone Stumpf</a></p>
<p>Fairness in AI is a growing concern for high-stakes decision making. Engaging
stakeholders, especially lay users, in fair AI development is promising yet
overlooked. Recent efforts explore enabling lay users to provide AI
fairness-related feedback, but there is still a lack of understanding of how to
integrate users' feedback into an AI model and the impacts of doing so. To
bridge this gap, we collected feedback from 58 lay users on the fairness of a
XGBoost model trained on the Home Credit dataset, and conducted offline
experiments to investigate the effects of retraining models on accuracy, and
individual and group fairness. Our work contributes baseline results of
integrating user fairness feedback in XGBoost, and a dataset and code framework
to bootstrap research in engaging stakeholders in AI fairness. Our discussion
highlights the challenges of employing user feedback in AI fairness and points
the way to a future application area of interactive machine learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08066">A Novel Metric for Measuring Data Quality in Classification Applications (extended version). (arXiv:2312.08066v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roxane_J/0/1/0/all/0/1">Jouseau Roxane</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastien_S/0/1/0/all/0/1">Salva S&#xe9;bastien</a>, <a href="http://arxiv.org/find/cs/1/au:+Chafik_S/0/1/0/all/0/1">Samir Chafik</a></p>
<p>Data quality is a key element for building and optimizing good learning
models. Despite many attempts to characterize data quality, there is still a
need for rigorous formalization and an efficient measure of the quality from
available observations. Indeed, without a clear understanding of the training
and testing processes, it is hard to evaluate the intrinsic performance of a
model. Besides, tools allowing to measure data quality specific to machine
learning are still lacking. In this paper, we introduce and explain a novel
metric to measure data quality. This metric is based on the correlated
evolution between the classification performance and the deterioration of data.
The proposed method has the major advantage of being model-independent.
Furthermore, we provide an interpretation of each criterion and examples of
assessment levels. We confirm the utility of the proposed metric with intensive
numerical experiments and detail some illustrative cases with controlled and
interpretable qualities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08074">PySCIPOpt-ML: Embedding Trained Machine Learning Models into Mixed-Integer Programs. (arXiv:2312.08074v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Turner_M/0/1/0/all/0/1">Mark Turner</a>, <a href="http://arxiv.org/find/math/1/au:+Chmiela_A/0/1/0/all/0/1">Antonia Chmiela</a>, <a href="http://arxiv.org/find/math/1/au:+Koch_T/0/1/0/all/0/1">Thorsten Koch</a>, <a href="http://arxiv.org/find/math/1/au:+Winkler_M/0/1/0/all/0/1">Michael Winkler</a></p>
<p>A standard tool for modelling real-world optimisation problems is
mixed-integer programming (MIP). However, for many of these problems there is
either incomplete information describing variable relations, or the relations
between variables are highly complex. To overcome both these hurdles, machine
learning (ML) models are often used and embedded in the MIP as surrogate models
to represent these relations. Due to the large amount of available ML
frameworks, formulating ML models into MIPs is highly non-trivial. In this
paper we propose a tool for the automatic MIP formulation of trained ML models,
allowing easy integration of ML constraints into MIPs. In addition, we
introduce a library of MIP instances with embedded ML constraints. The project
is available at https://github.com/Opt-Mucca/PySCIPOpt-ML.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08078">Fine-Grained Image-Text Alignment in Medical Imaging Enables Cyclic Image-Report Generation. (arXiv:2312.08078v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Linlin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yixuan Yuan</a></p>
<p>To address these issues, we propose a novel Adaptive patch-word Matching
(AdaMatch) model to correlate chest X-ray (CXR) image regions with words in
medical reports and apply it to CXR-report generation to provide explainability
for the generation process. AdaMatch exploits the fine-grained relation between
adaptive patches and words to provide explanations of specific image regions
with corresponding words. To capture the abnormal regions of varying sizes and
positions, we introduce the Adaptive Patch extraction (AdaPatch) module to
acquire the adaptive patches for these regions adaptively. In order to provide
explicit explainability for CXR-report generation task, we propose an
AdaMatch-based bidirectional large language model for Cyclic CXR-report
generation (AdaMatch-Cyclic). It employs the AdaMatch to obtain the keywords
for CXR images and `keypatches' for medical reports as hints to guide
CXR-report generation. Extensive experiments on two publicly available CXR
datasets prove the effectiveness of our method and its superior performance to
existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08084">A Novel Energy based Model Mechanism for Multi-modal Aspect-Based Sentiment Analysis. (arXiv:2312.08084v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_T/0/1/0/all/0/1">Tianshuo Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zuchao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Ping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lefei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hai Zhao</a></p>
<p>Multi-modal aspect-based sentiment analysis (MABSA) has recently attracted
increasing attention. The span-based extraction methods, such as FSUIE,
demonstrate strong performance in sentiment analysis due to their joint
modeling of input sequences and target labels. However, previous methods still
have certain limitations: (i) They ignore the difference in the focus of visual
information between different analysis targets (aspect or sentiment). (ii)
Combining features from uni-modal encoders directly may not be sufficient to
eliminate the modal gap and can cause difficulties in capturing the image-text
pairwise relevance. (iii) Existing span-based methods for MABSA ignore the
pairwise relevance of target span boundaries. To tackle these limitations, we
propose a novel framework called DQPSA for multi-modal sentiment analysis.
Specifically, our model contains a Prompt as Dual Query (PDQ) module that uses
the prompt as both a visual query and a language query to extract prompt-aware
visual information and strengthen the pairwise relevance between visual
information and the analysis target. Additionally, we introduce an Energy-based
Pairwise Expert (EPE) module that models the boundaries pairing of the analysis
target from the perspective of an Energy-based Model. This expert predicts
aspect or sentiment span based on pairwise stability. Experiments on three
widely used benchmarks demonstrate that DQPSA outperforms previous approaches
and achieves a new state-of-the-art performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08092">A hybrid analysis of LBSN data to early detect anomalies in crowd dynamics. (arXiv:2312.08092v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Diaz_Redondo_R/0/1/0/all/0/1">Rebeca P. D&#xed;az-Redondo</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_Rubio_C/0/1/0/all/0/1">Carlos Garcia-Rubio</a>, <a href="http://arxiv.org/find/cs/1/au:+Vilas_A/0/1/0/all/0/1">Ana Fern&#xe1;ndez Vilas</a>, <a href="http://arxiv.org/find/cs/1/au:+Campo_C/0/1/0/all/0/1">Celeste Campo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Carrion_A/0/1/0/all/0/1">Alicia Rodriguez-Carrion</a></p>
<p>Undoubtedly, Location-based Social Networks (LBSNs) provide an interesting
source of geo-located data that we have previously used to obtain patterns of
the dynamics of crowds throughout urban areas. According to our previous
results, activity in LBSNs reflects the real activity in the city. Therefore,
unexpected behaviors in the social media activity are a trustful evidence of
unexpected changes of the activity in the city. In this paper we introduce a
hybrid solution to early detect these changes based on applying a combination
of two approaches, the use of entropy analysis and clustering techniques, on
the data gathered from LBSNs. In particular, we have performed our experiments
over a data set collected from Instagram for seven months in New York City,
obtaining promising results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08098">Adversarial Socialbots Modeling Based on Structural Information Principles. (arXiv:2312.08098v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xianghua Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Angsheng Li</a></p>
<p>The importance of effective detection is underscored by the fact that
socialbots imitate human behavior to propagate misinformation, leading to an
ongoing competition between socialbots and detectors. Despite the rapid
advancement of reactive detectors, the exploration of adversarial socialbot
modeling remains incomplete, significantly hindering the development of
proactive detectors. To address this issue, we propose a mathematical
Structural Information principles-based Adversarial Socialbots Modeling
framework, namely SIASM, to enable more accurate and effective modeling of
adversarial behaviors. First, a heterogeneous graph is presented to integrate
various users and rich activities in the original social network and measure
its dynamic uncertainty as structural entropy. By minimizing the
high-dimensional structural entropy, a hierarchical community structure of the
social network is generated and referred to as the optimal encoding tree.
Secondly, a novel method is designed to quantify influence by utilizing the
assigned structural entropy, which helps reduce the computational cost of SIASM
by filtering out uninfluential users. Besides, a new conditional structural
entropy is defined between the socialbot and other users to guide the follower
selection for network influence maximization. Extensive and comparative
experiments on both homogeneous and heterogeneous social networks demonstrate
that, compared with state-of-the-art baselines, the proposed SIASM framework
yields substantial performance improvements in terms of network influence (up
to 16.32%) and sustainable stealthiness (up to 16.29%) when evaluated against a
robust detector with 90% accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08107">Causal Optimal Transport of Abstractions. (arXiv:2312.08107v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Felekis_Y/0/1/0/all/0/1">Yorgos Felekis</a>, <a href="http://arxiv.org/find/cs/1/au:+Zennaro_F/0/1/0/all/0/1">Fabio Massimo Zennaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Branchini_N/0/1/0/all/0/1">Nicola Branchini</a>, <a href="http://arxiv.org/find/cs/1/au:+Damoulas_T/0/1/0/all/0/1">Theodoros Damoulas</a></p>
<p>Causal abstraction (CA) theory establishes formal criteria for relating
multiple structural causal models (SCMs) at different levels of granularity by
defining maps between them. These maps have significant relevance for
real-world challenges such as synthesizing causal evidence from multiple
experimental environments, learning causally consistent representations at
different resolutions, and linking interventions across multiple SCMs. In this
work, we propose COTA, the first method to learn abstraction maps from
observational and interventional data without assuming complete knowledge of
the underlying SCMs. In particular, we introduce a multi-marginal Optimal
Transport (OT) formulation that enforces do-calculus causal constraints,
together with a cost function that relies on interventional information. We
extensively evaluate COTA on synthetic and real world problems, and showcase
its advantages over non-causal, independent and aggregated COTA formulations.
Finally, we demonstrate the efficiency of our method as a data augmentation
tool by comparing it against the state-of-the-art CA learning framework, which
assumes fully specified SCMs, on a real-world downstream task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08143">Efficient Representation of the Activation Space in Deep Neural Networks. (arXiv:2312.08143v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Akumu_T/0/1/0/all/0/1">Tanya Akumu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cintas_C/0/1/0/all/0/1">Celia Cintas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tadesse_G/0/1/0/all/0/1">Girmaw Abebe Tadesse</a>, <a href="http://arxiv.org/find/cs/1/au:+Oshingbesan_A/0/1/0/all/0/1">Adebayo Oshingbesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Speakman_S/0/1/0/all/0/1">Skyler Speakman</a>, <a href="http://arxiv.org/find/cs/1/au:+McFowland_E/0/1/0/all/0/1">Edward McFowland III</a></p>
<p>The representations of the activation space of deep neural networks (DNNs)
are widely utilized for tasks like natural language processing, anomaly
detection and speech recognition. Due to the diverse nature of these tasks and
the large size of DNNs, an efficient and task-independent representation of
activations becomes crucial. Empirical p-values have been used to quantify the
relative strength of an observed node activation compared to activations
created by already-known inputs. Nonetheless, keeping raw data for these
calculations increases memory resource consumption and raises privacy concerns.
To this end, we propose a model-agnostic framework for creating representations
of activations in DNNs using node-specific histograms to compute p-values of
observed activations without retaining already-known inputs. Our proposed
approach demonstrates promising potential when validated with multiple network
architectures across various downstream tasks and compared with the kernel
density estimates and brute-force empirical baselines. In addition, the
framework reduces memory usage by 30% with up to 4 times faster p-value
computing time while maintaining state of-the-art detection power in downstream
tasks such as the detection of adversarial attacks and synthesized content.
Moreover, as we do not persist raw data at inference time, we could potentially
reduce susceptibility to attacks and privacy issues.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08157">CIDR: A Cooperative Integrated Dynamic Refining Method for Minimal Feature Removal Problem. (arXiv:2312.08157v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Taolin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaofeng He</a></p>
<p>The minimal feature removal problem in the post-hoc explanation area aims to
identify the minimal feature set (MFS). Prior studies using the greedy
algorithm to calculate the minimal feature set lack the exploration of feature
interactions under a monotonic assumption which cannot be satisfied in general
scenarios. In order to address the above limitations, we propose a Cooperative
Integrated Dynamic Refining method (CIDR) to efficiently discover minimal
feature sets. Specifically, we design Cooperative Integrated Gradients (CIG) to
detect interactions between features. By incorporating CIG and characteristics
of the minimal feature set, we transform the minimal feature removal problem
into a knapsack problem. Additionally, we devise an auxiliary Minimal Feature
Refinement algorithm to determine the minimal feature set from numerous
candidate sets. To the best of our knowledge, our work is the first to address
the minimal feature removal problem in the field of natural language
processing. Extensive experiments demonstrate that CIDR is capable of tracing
representative minimal feature sets with improved interpretability across
various models and datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08195">Concept-centric Personalization with Large-scale Diffusion Priors. (arXiv:2312.08195v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1">Pu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Feng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tianrui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qing Song</a></p>
<p>Despite large-scale diffusion models being highly capable of generating
diverse open-world content, they still struggle to match the photorealism and
fidelity of concept-specific generators. In this work, we present the task of
customizing large-scale diffusion priors for specific concepts as
concept-centric personalization. Our goal is to generate high-quality
concept-centric images while maintaining the versatile controllability inherent
to open-world models, enabling applications in diverse tasks such as
concept-centric stylization and image translation. To tackle these challenges,
we identify catastrophic forgetting of guidance prediction from diffusion
priors as the fundamental issue. Consequently, we develop a guidance-decoupled
personalization framework specifically designed to address this task. We
propose Generalized Classifier-free Guidance (GCFG) as the foundational theory
for our framework. This approach extends Classifier-free Guidance (CFG) to
accommodate an arbitrary number of guidances, sourced from a variety of
conditions and models. Employing GCFG enables us to separate conditional
guidance into two distinct components: concept guidance for fidelity and
control guidance for controllability. This division makes it feasible to train
a specialized model for concept guidance, while ensuring both control and
unconditional guidance remain intact. We then present a null-text
Concept-centric Diffusion Model as a concept-specific generator to learn
concept guidance without the need for text annotations. Code will be available
at https://github.com/PRIV-Creation/Concept-centric-Personalization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08198">Towards Model-Based Data Acquisition for Subjective Multi-Task NLP Problems. (arXiv:2312.08198v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kanclerz_K/0/1/0/all/0/1">Kamil Kanclerz</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielaniewicz_J/0/1/0/all/0/1">Julita Bielaniewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gruza_M/0/1/0/all/0/1">Marcin Gruza</a>, <a href="http://arxiv.org/find/cs/1/au:+Kocon_J/0/1/0/all/0/1">Jan Kocon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wozniak_S/0/1/0/all/0/1">Stanis&#x142;aw Wo&#x17a;niak</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazienko_P/0/1/0/all/0/1">Przemys&#x142;aw Kazienko</a></p>
<p>Data annotated by humans is a source of knowledge by describing the
peculiarities of the problem and therefore fueling the decision process of the
trained model. Unfortunately, the annotation process for subjective natural
language processing (NLP) problems like offensiveness or emotion detection is
often very expensive and time-consuming. One of the inevitable risks is to
spend some of the funds and annotator effort on annotations that do not provide
any additional knowledge about the specific task. To minimize these costs, we
propose a new model-based approach that allows the selection of tasks annotated
individually for each text in a multi-task scenario. The experiments carried
out on three datasets, dozens of NLP tasks, and thousands of annotations show
that our method allows up to 40% reduction in the number of annotations with
negligible loss of knowledge. The results also emphasize the need to collect a
diverse amount of data required to efficiently train a model, depending on the
subjectivity of the annotation task. We also focused on measuring the relation
between subjective tasks by evaluating the model in single-task and multi-task
scenarios. Moreover, for some datasets, training only on the labels predicted
by our model improved the efficiency of task selection as a self-supervised
learning regularization technique.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08221">Curriculum-Enhanced Residual Soft An-Isotropic Normalization for Over-smoothness in Deep GNNs. (arXiv:2312.08221v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qirong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuling Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Longkun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yang-Geng Fu</a></p>
<p>Despite Graph neural networks' significant performance gain over many classic
techniques in various graph-related downstream tasks, their successes are
restricted in shallow models due to over-smoothness and the difficulties of
optimizations among many other issues. In this paper, to alleviate the
over-smoothing issue, we propose a soft graph normalization method to preserve
the diversities of node embeddings and prevent indiscrimination due to possible
over-closeness. Combined with residual connections, we analyze the reason why
the method can effectively capture the knowledge in both input graph structures
and node features even with deep networks. Additionally, inspired by Curriculum
Learning that learns easy examples before the hard ones, we propose a novel
label-smoothing-based learning framework to enhance the optimization of deep
GNNs, which iteratively smooths labels in an auxiliary graph and constructs
many gradual non-smooth tasks for extracting increasingly complex knowledge and
gradually discriminating nodes from coarse to fine. The method arguably reduces
the risk of overfitting and generalizes better results. Finally, extensive
experiments are carried out to demonstrate the effectiveness and potential of
the proposed model and learning framework through comparison with twelve
existing baselines including the state-of-the-art methods on twelve real-world
node classification benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08224">GLOP: Learning Global Partition and Local Construction for Solving Large-scale Routing Problems in Real-time. (arXiv:2312.08224v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Haoran Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiarui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Helan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zhiguang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fanzhang Li</a></p>
<p>The recent end-to-end neural solvers have shown promise for small-scale
routing problems but suffered from limited real-time scaling-up performance.
This paper proposes GLOP (Global and Local Optimization Policies), a unified
hierarchical framework that efficiently scales toward large-scale routing
problems. GLOP partitions large routing problems into Travelling Salesman
Problems (TSPs) and TSPs into Shortest Hamiltonian Path Problems. For the first
time, we hybridize non-autoregressive neural heuristics for coarse-grained
problem partitions and autoregressive neural heuristics for fine-grained route
constructions, leveraging the scalability of the former and the meticulousness
of the latter. Experimental results show that GLOP achieves competitive and
state-of-the-art real-time performance on large-scale routing problems,
including TSP, ATSP, CVRP, and PCTSP.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08248">A Survey of Generative AI for Intelligent Transportation Systems. (arXiv:2312.08248v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Huan Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a></p>
<p>Intelligent transportation systems play a crucial role in modern traffic
management and optimization, greatly improving traffic efficiency and safety.
With the rapid development of generative artificial intelligence (Generative
AI) technologies in the fields of image generation and natural language
processing, generative AI has also played a crucial role in addressing key
issues in intelligent transportation systems, such as data sparsity, difficulty
in observing abnormal scenarios, and in modeling data uncertainty. In this
review, we systematically investigate the relevant literature on generative AI
techniques in addressing key issues in different types of tasks in intelligent
transportation systems. First, we introduce the principles of different
generative AI techniques, and their potential applications. Then, we classify
tasks in intelligent transportation systems into four types: traffic
perception, traffic prediction, traffic simulation, and traffic
decision-making. We systematically illustrate how generative AI techniques
addresses key issues in these four different types of tasks. Finally, we
summarize the challenges faced in applying generative AI to intelligent
transportation systems, and discuss future research directions based on
different application scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08274">High-throughput Biomedical Relation Extraction for Semi-Structured Web Articles Empowered by Large Language Models. (arXiv:2312.08274v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Songchi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Sheng Yu</a></p>
<p>Objective: To develop a high-throughput biomedical relation extraction system
that takes advantage of the large language models' (LLMs) reading comprehension
ability and biomedical world knowledge in a scalable and evidential manner.
Methods: We formulate the relation extraction task as a simple binary
classification problem for large language models such as ChatGPT. Specifically,
LLMs make the decision based on the external corpus and its world knowledge,
giving the reason for the judgment to factual verification. This method is
tailored for semi-structured web articles, wherein we designate the main title
as the tail entity and explicitly incorporate it into the context, and the
potential head entities are matched based on a biomedical thesaurus. Moreover,
lengthy contents are sliced into text chunks, embedded, and retrieved with
additional embedding models, ensuring compatibility with the context window
size constraints of available open-source LLMs. Results: Using an open-source
LLM, we extracted 304315 relation triplets of three distinct relation types
from four reputable biomedical websites. To assess the efficacy of the basic
pipeline employed for biomedical relation extraction, we curated a benchmark
dataset annotated by a medical expert. Evaluation results indicate that the
pipeline exhibits performance comparable to that of GPT-4. Case studies further
illuminate challenges faced by contemporary LLMs in the context of biomedical
relation extraction for semi-structured web articles. Conclusion: The proposed
method has demonstrated its effectiveness in leveraging the strengths of LLMs
for high-throughput biomedical relation extraction. Its adaptability is
evident, as it can be seamlessly extended to diverse semi-structured biomedical
websites, facilitating the extraction of various types of biomedical relations
with ease.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08282">Prompting LLMs with content plans to enhance the summarization of scientific articles. (arXiv:2312.08282v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Creo_A/0/1/0/all/0/1">Aldan Creo</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lama_M/0/1/0/all/0/1">Manuel Lama</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Vidal_J/0/1/0/all/0/1">Juan C. Vidal</a> (1) ((1) Singular Research Center on Intelligent Technologies (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain)</p>
<p>This paper presents novel prompting techniques to improve the performance of
automatic summarization systems for scientific articles. Scientific article
summarization is highly challenging due to the length and complexity of these
documents. We conceive, implement, and evaluate prompting techniques that
provide additional contextual information to guide summarization systems.
Specifically, we feed summarizers with lists of key terms extracted from
articles, such as author keywords or automatically generated keywords. Our
techniques are tested with various summarization models and input texts.
Results show performance gains, especially for smaller models summarizing
sections separately. This evidences that prompting is a promising approach to
overcoming the limitations of less powerful systems. Our findings introduce a
new research direction of using prompts to aid smaller models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08287">On the verification of Embeddings using Hybrid Markov Logic. (arXiv:2312.08287v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shakya_A/0/1/0/all/0/1">Anup Shakya</a>, <a href="http://arxiv.org/find/cs/1/au:+Magar_A/0/1/0/all/0/1">Abisha Thapa Magar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkhel_S/0/1/0/all/0/1">Somdeb Sarkhel</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopal_D/0/1/0/all/0/1">Deepak Venugopal</a></p>
<p>The standard approach to verify representations learned by Deep Neural
Networks is to use them in specific tasks such as classification or regression,
and measure their performance based on accuracy in such tasks. However, in many
cases, we would want to verify more complex properties of a learned
representation. To do this, we propose a framework based on a probabilistic
first-order language, namely, Hybrid Markov Logic Networks (HMLNs) where we
specify properties over embeddings mixed with symbolic domain knowledge. We
present an approach to learn parameters for the properties within this
framework. Further, we develop a verification method to test embeddings in this
framework by encoding this task as a Mixed Integer Linear Program for which we
can leverage existing state-of-the-art solvers. We illustrate verification in
Graph Neural Networks, Deep Knowledge Tracing and Intelligent Tutoring Systems
to demonstrate the generality of our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08303">Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models. (arXiv:2312.08303v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qiong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yiming Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1">Cheng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1">Zheng Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Psounis_K/0/1/0/all/0/1">Konstantinos Psounis</a></p>
<p>Toxic content detection is crucial for online services to remove
inappropriate content that violates community standards. To automate the
detection process, prior works have proposed varieties of machine learning (ML)
approaches to train Language Models (LMs) for toxic content detection. However,
both their accuracy and transferability across datasets are limited. Recently,
Large Language Models (LLMs) have shown promise in toxic content detection due
to their superior zero-shot and few-shot in-context learning ability as well as
broad transferability on ML tasks. However, efficiently designing prompts for
LLMs remains challenging. Moreover, the high run-time cost of LLMs may hinder
their deployments in production. To address these challenges, in this work, we
propose BD-LLM, a novel and efficient approach to Bootstrapping and Distilling
LLMs for toxic content detection. Specifically, we design a novel prompting
method named Decision-Tree-of-Thought (DToT) to bootstrap LLMs' detection
performance and extract high-quality rationales. DToT can automatically select
more fine-grained context to re-prompt LLMs when their responses lack
confidence. Additionally, we use the rationales extracted via DToT to fine-tune
student LMs. Our experimental results on various datasets demonstrate that DToT
can improve the accuracy of LLMs by up to 4.6%. Furthermore, student LMs
fine-tuned with rationales extracted via DToT outperform baselines on all
datasets with up to 16.9\% accuracy improvement, while being more than 60x
smaller than conventional LLMs. Finally, we observe that student LMs fine-tuned
with rationales exhibit better cross-dataset transferability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08317">Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4. (arXiv:2312.08317v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1">Pei Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shunquan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Miaohui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a></p>
<p>Dynamic analysis methods effectively identify shelled, wrapped, or obfuscated
malware, thereby preventing them from invading computers. As a significant
representation of dynamic malware behavior, the API (Application Programming
Interface) sequence, comprised of consecutive API calls, has progressively
become the dominant feature of dynamic analysis methods. Though there have been
numerous deep learning models for malware detection based on API sequences, the
quality of API call representations produced by those models is limited. These
models cannot generate representations for unknown API calls, which weakens
both the detection performance and the generalization. Further, the concept
drift phenomenon of API calls is prominent. To tackle these issues, we
introduce a prompt engineering-assisted malware dynamic analysis using GPT-4.
In this method, GPT-4 is employed to create explanatory text for each API call
within the API sequence. Afterward, the pre-trained language model BERT is used
to obtain the representation of the text, from which we derive the
representation of the API sequence. Theoretically, this proposed method is
capable of generating representations for all API calls, excluding the
necessity for dataset training during the generation process. Utilizing the
representation, a CNN-based detection model is designed to extract the feature.
We adopt five benchmark datasets to validate the performance of the proposed
model. The experimental results reveal that the proposed detection algorithm
performs better than the state-of-the-art method (TextCNN). Specifically, in
cross-database experiments and few-shot learning experiments, the proposed
model achieves excellent detection performance and almost a 100% recall rate
for malware, verifying its superior generalization performance. The code is
available at: github.com/yan-scnu/Prompted_Dynamic_Detection.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08344">FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects. (arXiv:2312.08344v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wen_B/0/1/0/all/0/1">Bowen Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1">Jan Kautz</a>, <a href="http://arxiv.org/find/cs/1/au:+Birchfield_S/0/1/0/all/0/1">Stan Birchfield</a></p>
<p>We present FoundationPose, a unified foundation model for 6D object pose
estimation and tracking, supporting both model-based and model-free setups. Our
approach can be instantly applied at test-time to a novel object without
fine-tuning, as long as its CAD model is given, or a small number of reference
images are captured. We bridge the gap between these two setups with a neural
implicit representation that allows for effective novel view synthesis, keeping
the downstream pose estimation modules invariant under the same unified
framework. Strong generalizability is achieved via large-scale synthetic
training, aided by a large language model (LLM), a novel transformer-based
architecture, and contrastive learning formulation. Extensive evaluation on
multiple public datasets involving challenging scenarios and objects indicate
our unified approach outperforms existing methods specialized for each task by
a large margin. In addition, it even achieves comparable results to
instance-level methods despite the reduced assumptions. Project page:
https://nvlabs.github.io/FoundationPose/
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08358">Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF. (arXiv:2312.08358v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Siththaranjan_A/0/1/0/all/0/1">Anand Siththaranjan</a>, <a href="http://arxiv.org/find/cs/1/au:+Laidlaw_C/0/1/0/all/0/1">Cassidy Laidlaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1">Dylan Hadfield-Menell</a></p>
<p>In practice, preference learning from human feedback depends on incomplete
data with hidden context. Hidden context refers to data that affects the
feedback received, but which is not represented in the data used to train a
preference model. This captures common issues of data collection, such as
having human annotators with varied preferences, cognitive processes that
result in seemingly irrational behavior, and combining data labeled according
to different criteria. We prove that standard applications of preference
learning, including reinforcement learning from human feedback (RLHF),
implicitly aggregate over hidden contexts according to a well-known voting rule
called Borda count. We show this can produce counter-intuitive results that are
very different from other methods which implicitly aggregate via expected
utility. Furthermore, our analysis formalizes the way that preference learning
from users with diverse values tacitly implements a social choice function. A
key implication of this result is that annotators have an incentive to
misreport their preferences in order to influence the learned model, leading to
vulnerabilities in the deployment of RLHF. As a step towards mitigating these
problems, we introduce a class of methods called distributional preference
learning (DPL). DPL methods estimate a distribution of possible score values
for each alternative in order to better account for hidden context.
Experimental results indicate that applying DPL to RLHF for LLM chatbots
identifies hidden context in the data and significantly reduces subsequent
jailbreak vulnerability. Our code and data are available at
https://github.com/cassidylaidlaw/hidden-context
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08365">An Invitation to Deep Reinforcement Learning. (arXiv:2312.08365v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jaeger_B/0/1/0/all/0/1">Bernhard Jaeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1">Andreas Geiger</a></p>
<p>Training a deep neural network to maximize a target objective has become the
standard recipe for successful machine learning over the last decade. These
networks can be optimized with supervised learning, if the target objective is
differentiable. For many interesting problems, this is however not the case.
Common objectives like intersection over union (IoU), bilingual evaluation
understudy (BLEU) score or rewards cannot be optimized with supervised
learning. A common workaround is to define differentiable surrogate losses,
leading to suboptimal solutions with respect to the actual objective.
Reinforcement learning (RL) has emerged as a promising alternative for
optimizing deep neural networks to maximize non-differentiable objectives in
recent years. Examples include aligning large language models via human
feedback, code generation, object detection or control problems. This makes RL
techniques relevant to the larger machine learning audience. The subject is,
however, time intensive to approach due to the large range of methods, as well
as the often very theoretical presentation. In this introduction, we take an
alternative approach, different from classic reinforcement learning textbooks.
Rather than focusing on tabular problems, we introduce reinforcement learning
as a generalization of supervised learning, which we first apply to
non-differentiable objectives and later to temporal problems. Assuming only
basic knowledge of supervised learning, the reader will be able to understand
state-of-the-art deep RL algorithms like proximal policy optimization (PPO)
after reading this tutorial.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.08369">The Effective Horizon Explains Deep RL Performance in Stochastic Environments. (arXiv:2312.08369v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Laidlaw_C/0/1/0/all/0/1">Cassidy Laidlaw</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhu_B/0/1/0/all/0/1">Banghua Zhu</a>, <a href="http://arxiv.org/find/stat/1/au:+Russell_S/0/1/0/all/0/1">Stuart Russell</a>, <a href="http://arxiv.org/find/stat/1/au:+Dragan_A/0/1/0/all/0/1">Anca Dragan</a></p>
<p>Reinforcement learning (RL) theory has largely focused on proving minimax
sample complexity bounds. These require strategic exploration algorithms that
use relatively limited function classes for representing the policy or value
function. Our goal is to explain why deep RL algorithms often perform well in
practice, despite using random exploration and much more expressive function
classes like neural networks. Our work arrives at an explanation by showing
that many stochastic MDPs can be solved by performing only a few steps of value
iteration on the random policy's Q function and then acting greedily. When this
is true, we find that it is possible to separate the exploration and learning
components of RL, making it much easier to analyze. We introduce a new RL
algorithm, SQIRL, that iteratively learns a near-optimal policy by exploring
randomly to collect rollouts and then performing a limited number of steps of
fitted-Q iteration over those rollouts. Any regression algorithm that satisfies
basic in-distribution generalization properties can be used in SQIRL to
efficiently solve common MDPs. This can explain why deep RL works neural
networks, since it is empirically established that neural networks generalize
well in-distribution. Furthermore, SQIRL explains why random exploration works
well in practice, since we show many environments can be solved by estimating
the random policy's Q-function and then applying zero or a few steps of value
iteration. We leverage SQIRL to derive instance-dependent sample complexity
bounds for RL that are exponential only in an "effective horizon" of lookahead
and on the complexity of the class used for function approximation.
Empirically, we also find that SQIRL performance strongly correlates with PPO
and DQN performance in a variety of stochastic environments, supporting that
our theoretical analysis is predictive of practical performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2008.07324">Intelligence Primer. (arXiv:2008.07324v4 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fezer_K/0/1/0/all/0/1">Karl Fezer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sloss_A/0/1/0/all/0/1">Andrew Sloss</a></p>
<p>Intelligence is a fundamental part of all living things, as well as the
foundation for Artificial Intelligence. In this primer we explore the ideas
associated with intelligence and, by doing so, understand the implications and
constraints and potentially outline the capabilities of future systems.
Artificial Intelligence, in the form of Machine Learning, has already had a
significant impact on our lives. As an exploration, we journey into different
parts of intelligence that appear essential. We hope that people find this
helpful in determining the future. Also, during the exploration, we hope to
create new thought-provoking questions. Intelligence is not a single weighable
quantity but a subject that spans Biology, Physics, Philosophy, Cognitive
Science, Neuroscience, Psychology, and Computer Science. The historian Yuval
Noah Harari pointed out that engineers and scientists in the future will have
to broaden their understandings to include disciplines such as Psychology,
Philosophy, and Ethics. Fiction writers have long portrayed engineers and
scientists as deficient in these areas. Today, in modern society, the emergence
of Artificial Intelligence and legal requirements act as forcing functions to
push these broader subjects into the foreground. We start with an introduction
to intelligence and move quickly to more profound thoughts and ideas. We call
this a Life, the Universe, and Everything primer, after the famous science
fiction book by Douglas Adams. Forty-two may be the correct answer, but what
are the questions?
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2101.11992">Acting in Delayed Environments with Non-Stationary Markov Policies. (arXiv:2101.11992v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Derman_E/0/1/0/all/0/1">Esther Derman</a>, <a href="http://arxiv.org/find/cs/1/au:+Dalal_G/0/1/0/all/0/1">Gal Dalal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a></p>
<p>The standard Markov Decision Process (MDP) formulation hinges on the
assumption that an action is executed immediately after it was chosen. However,
assuming it is often unrealistic and can lead to catastrophic failures in
applications such as robotic manipulation, cloud computing, and finance. We
introduce a framework for learning and planning in MDPs where the
decision-maker commits actions that are executed with a delay of $m$ steps. The
brute-force state augmentation baseline where the state is concatenated to the
last $m$ committed actions suffers from an exponential complexity in $m$, as we
show for policy iteration. We then prove that with execution delay,
deterministic Markov policies in the original state-space are sufficient for
attaining maximal reward, but need to be non-stationary. As for stationary
Markov policies, we show they are sub-optimal in general. Consequently, we
devise a non-stationary Q-learning style model-based algorithm that solves
delayed execution tasks without resorting to state-augmentation. Experiments on
tabular, physical, and Atari domains reveal that it converges quickly to high
performance even for substantial delays, while standard approaches that either
ignore the delay or rely on state-augmentation struggle or fail due to
divergence. The code is available at github.com/galdl/rl_delay_basic and
github.com/galdl/rl_delay_atari.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2104.12156">Sequential composition of answer set programs. (arXiv:2104.12156v5 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Antic_C/0/1/0/all/0/1">Christian Anti&#x107;</a></p>
<p>This paper introduces the sequential composition of answer set programs. On
the semantic side, we show that the immediate consequence operator of a program
can be represented via composition, which allows us to compute the least model
semantics of Horn programs without any explicit reference to operators. As a
result, we can characterize answer sets algebraically, which provides an
algebraic characterization of strong and uniform equivalence. In a broader
sense, this paper is a first step towards an algebra of answer set programs and
in the future we plan to lift the methods of this paper to wider classes of
programs, most importantly to higher-order and disjunctive programs and
extensions thereof.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.01881">Measuring Self-Supervised Representation Quality for Downstream Classification using Discriminative Features. (arXiv:2203.01881v6 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kalibhat_N/0/1/0/all/0/1">Neha Kalibhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Narang_K/0/1/0/all/0/1">Kanika Narang</a>, <a href="http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1">Hamed Firooz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1">Maziar Sanjabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1">Soheil Feizi</a></p>
<p>Self-supervised learning (SSL) has shown impressive results in downstream
classification tasks. However, there is limited work in understanding their
failure modes and interpreting their learned representations. In this paper, we
study the representation space of state-of-the-art self-supervised models
including SimCLR, SwaV, MoCo, BYOL, DINO, SimSiam, VICReg and Barlow Twins.
Without the use of class label information, we discover discriminative features
that correspond to unique physical attributes in images, present mostly in
correctly-classified representations. Using these features, we can compress the
representation space by up to 40% without significantly affecting linear
classification performance. We then propose Self-Supervised Representation
Quality Score (or Q-Score), an unsupervised score that can reliably predict if
a given sample is likely to be mis-classified during linear evaluation,
achieving AUPRC of 91.45 on ImageNet-100 and 78.78 on ImageNet-1K. Q-Score can
also be used as a regularization term on pre-trained encoders to remedy
low-quality representations. Fine-tuning with Q-Score regularization can boost
the linear probing accuracy of SSL models by up to 5.8% on ImageNet-100 and
3.7% on ImageNet-1K compared to their baselines. Finally, using gradient
heatmaps and Salient ImageNet masks, we define a metric to quantify the
interpretability of each representation. We show that discriminative features
are strongly correlated to core attributes and, enhancing these features
through Q-score regularization makes SSL representations more interpretable.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.11194">Controller-Guided Partial Label Consistency Regularization with Unlabeled Data. (arXiv:2210.11194v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qian-Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Bowen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingyan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianxiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zimo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a></p>
<p>Partial label learning (PLL) learns from training examples each associated
with multiple candidate labels, among which only one is valid. In recent years,
benefiting from the strong capability of dealing with ambiguous supervision and
the impetus of modern data augmentation methods, consistency
regularization-based PLL methods have achieved a series of successes and become
mainstream. However, as the partial annotation becomes insufficient, their
performances drop significantly. In this paper, we leverage easily accessible
unlabeled examples to facilitate the partial label consistency regularization.
In addition to a partial supervised loss, our method performs a
controller-guided consistency regularization at both the label-level and
representation-level with the help of unlabeled data. To minimize the
disadvantages of insufficient capabilities of the initial supervised model, we
use the controller to estimate the confidence of each current prediction to
guide the subsequent consistency regularization. Furthermore, we dynamically
adjust the confidence thresholds so that the number of samples of each class
participating in consistency regularization remains roughly equal to alleviate
the problem of class-imbalance. Experiments show that our method achieves
satisfactory performances in more practical situations, and its modules can be
applied to existing PLL methods to enhance their capabilities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.04118">ConsPrompt: Exploiting Contrastive Samples for Fewshot Prompt Learning. (arXiv:2211.04118v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Weng_J/0/1/0/all/0/1">Jinta Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yifan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_d/0/1/0/all/0/1">d Donghao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1">Hao You</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yue Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Heyan Huang</a></p>
<p>Prompt recently have become an effective linguistic tool on utilizing the
pre-trained language models. However, in few-shot scenarios, subtle changes of
prompt's design always make the result widely different, and the prompt design
is also easy to overfit the current limited samples. To alleviate this, we
explore how to utilize suitable contrastive samples and multiple contrastive
learning methods to realize a more robust prompt's representation. Therefore,
the contrastive prompt model ConsPrompt combining with prompt encoding network,
contrastive sampling modules, and contrastive scoring modules are introduced to
realize differential contrastive learning. Our results exhibit the
state-of-the-art performance in different few-shot settings, and the ablation
experiments also certificate the effectiveness in utilizing multi-degree
contrastive learning in prompt-based fine-tuning process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.07350">Graph schemas as abstractions for transfer learning, inference, and planning. (arXiv:2302.07350v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guntupalli_J/0/1/0/all/0/1">J. Swaroop Guntupalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Raju_R/0/1/0/all/0/1">Rajkumar Vasudeva Raju</a>, <a href="http://arxiv.org/find/cs/1/au:+Kushagra_S/0/1/0/all/0/1">Shrinu Kushagra</a>, <a href="http://arxiv.org/find/cs/1/au:+Wendelken_C/0/1/0/all/0/1">Carter Wendelken</a>, <a href="http://arxiv.org/find/cs/1/au:+Sawyer_D/0/1/0/all/0/1">Danny Sawyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_I/0/1/0/all/0/1">Ishan Deshpande</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1">Guangyao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazaro_Gredilla_M/0/1/0/all/0/1">Miguel L&#xe1;zaro-Gredilla</a>, <a href="http://arxiv.org/find/cs/1/au:+George_D/0/1/0/all/0/1">Dileep George</a></p>
<p>Transferring latent structure from one environment or problem to another is a
mechanism by which humans and animals generalize with very little data.
Inspired by cognitive and neurobiological insights, we propose graph schemas as
a mechanism of abstraction for transfer learning. Graph schemas start with
latent graph learning where perceptually aliased observations are disambiguated
in the latent space using contextual information. Latent graph learning is also
emerging as a new computational model of the hippocampus to explain map
learning and transitive inference. Our insight is that a latent graph can be
treated as a flexible template -- a schema -- that models concepts and
behaviors, with slots that bind groups of latent nodes to the specific
observations or groundings. By treating learned latent graphs (schemas) as
prior knowledge, new environments can be quickly learned as compositions of
schemas and their newly learned bindings. We evaluate graph schemas on two
previously published challenging tasks: the memory &amp; planning game and one-shot
StreetLearn, which are designed to test rapid task solving in novel
environments. Graph schemas can be learned in far fewer episodes than previous
baselines, and can model and plan in a few steps in novel variations of these
tasks. We also demonstrate learning, matching, and reusing graph schemas in
more challenging 2D and 3D environments with extensive perceptual aliasing and
size variations, and show how different schemas can be composed to model larger
and more complex environments. To summarize, our main contribution is a unified
system, inspired and grounded in cognitive science, that facilitates rapid
transfer learning of new environments using schemas via map-induction and
composition that handles perceptual aliasing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.02618">Ensemble Reinforcement Learning: A Survey. (arXiv:2303.02618v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yanjie Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Suganthan_P/0/1/0/all/0/1">P. N. Suganthan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1">Witold Pedrycz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_J/0/1/0/all/0/1">Junwei Ou</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yongming He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingwu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yutong Wu</a></p>
<p>Reinforcement Learning (RL) has emerged as a highly effective technique for
addressing various scientific and applied problems. Despite its success,
certain complex tasks remain challenging to be addressed solely with a single
model and algorithm. In response, ensemble reinforcement learning (ERL), a
promising approach that combines the benefits of both RL and ensemble learning
(EL), has gained widespread popularity. ERL leverages multiple models or
training algorithms to comprehensively explore the problem space and possesses
strong generalization capabilities. In this study, we present a comprehensive
survey on ERL to provide readers with an overview of recent advances and
challenges in the field. Firstly, we provide an introduction to the background
and motivation for ERL. Secondly, we conduct a detailed analysis of strategies
such as model selection and combination that have been successfully implemented
in ERL. Subsequently, we explore the application of ERL, summarize the
datasets, and analyze the algorithms employed. Finally, we outline several open
questions and discuss future research directions of ERL. By offering guidance
for future scientific research and engineering applications, this survey
significantly contributes to the advancement of ERL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.05397">TOLD: A Novel Two-Stage Overlap-Aware Framework for Speaker Diarization. (arXiv:2303.05397v2 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaming Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1">Zhihao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shiliang Zhang</a></p>
<p>Recently, end-to-end neural diarization (EEND) is introduced and achieves
promising results in speaker-overlapped scenarios. In EEND, speaker diarization
is formulated as a multi-label prediction problem, where speaker activities are
estimated independently and their dependency are not well considered. To
overcome these disadvantages, we employ the power set encoding to reformulate
speaker diarization as a single-label classification problem and propose the
overlap-aware EEND (EEND-OLA) model, in which speaker overlaps and dependency
can be modeled explicitly. Inspired by the success of two-stage hybrid systems,
we further propose a novel Two-stage OverLap-aware Diarization framework (TOLD)
by involving a speaker overlap-aware post-processing (SOAP) model to
iteratively refine the diarization results of EEND-OLA. Experimental results
show that, compared with the original EEND, the proposed EEND-OLA achieves a
14.39% relative improvement in terms of diarization error rates (DER), and
utilizing SOAP provides another 19.33% relative improvement. As a result, our
method TOLD achieves a DER of 10.14% on the CALLHOME dataset, which is a new
state-of-the-art result on this benchmark to the best of our knowledge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.11420">ADCNet: Learning from Raw Radar Data via Distillation. (arXiv:2303.11420v3 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Yang_B/0/1/0/all/0/1">Bo Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Khatri_I/0/1/0/all/0/1">Ishan Khatri</a>, <a href="http://arxiv.org/find/eess/1/au:+Happold_M/0/1/0/all/0/1">Michael Happold</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_C/0/1/0/all/0/1">Chulong Chen</a></p>
<p>As autonomous vehicles and advanced driving assistance systems have entered
wider deployment, there is an increased interest in building robust perception
systems using radars. Radar-based systems are lower cost and more robust to
adverse weather conditions than their LiDAR-based counterparts; however the
point clouds produced are typically noisy and sparse by comparison. In order to
combat these challenges, recent research has focused on consuming the raw radar
data, instead of the final radar point cloud. We build on this line of work and
demonstrate that by bringing elements of the signal processing pipeline into
our network and then pre-training on the signal processing task, we are able to
achieve state of the art detection performance on the RADIal dataset. Our
method uses expensive offline signal processing algorithms to pseudo-label data
and trains a network to distill this information into a fast convolutional
backbone, which can then be finetuned for perception tasks. Extensive
experiment results corroborate the effectiveness of the proposed techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.17728">Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text. (arXiv:2303.17728v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rehana_H/0/1/0/all/0/1">Hasin Rehana</a>, <a href="http://arxiv.org/find/cs/1/au:+Cam_N/0/1/0/all/0/1">Nur Bengisu &#xc7;am</a>, <a href="http://arxiv.org/find/cs/1/au:+Basmaci_M/0/1/0/all/0/1">Mert Basmaci</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jie Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jemiyo_C/0/1/0/all/0/1">Christianah Jemiyo</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yongqun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozgur_A/0/1/0/all/0/1">Arzucan &#xd6;zg&#xfc;r</a>, <a href="http://arxiv.org/find/cs/1/au:+Hur_J/0/1/0/all/0/1">Junguk Hur</a></p>
<p>Detecting protein-protein interactions (PPIs) is crucial for understanding
genetic mechanisms, disease pathogenesis, and drug design. However, with the
fast-paced growth of biomedical literature, there is a growing need for
automated and accurate extraction of PPIs to facilitate scientific knowledge
discovery. Pre-trained language models, such as generative pre-trained
transformers (GPT) and bidirectional encoder representations from transformers
(BERT), have shown promising results in natural language processing (NLP)
tasks. We evaluated the performance of PPI identification of multiple GPT and
BERT models using three manually curated gold-standard corpora: Learning
Language in Logic (LLL) with 164 PPIs in 77 sentences, Human Protein Reference
Database with 163 PPIs in 145 sentences, and Interaction Extraction Performance
Assessment with 335 PPIs in 486 sentences. BERT-based models achieved the best
overall performance, with BioBERT achieving the highest recall (91.95%) and
F1-score (86.84%) and PubMedBERT achieving the highest precision (85.25%).
Interestingly, despite not being explicitly trained for biomedical texts, GPT-4
achieved commendable performance, comparable to the top-performing BERT models.
It achieved a precision of 88.37%, a recall of 85.14%, and an F1-score of
86.49% on the LLL dataset. These results suggest that GPT models can
effectively detect PPIs from text data, offering promising avenues for
application in biomedical literature mining. Further research could explore how
these models might be fine-tuned for even more specialized tasks within the
biomedical domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.08485">Visual Instruction Tuning. (arXiv:2304.08485v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haotian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qingyang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yong Jae Lee</a></p>
<p>Instruction tuning large language models (LLMs) using machine-generated
instruction-following data has improved zero-shot capabilities on new tasks,
but the idea is less explored in the multimodal field. In this paper, we
present the first attempt to use language-only GPT-4 to generate multimodal
language-image instruction-following data. By instruction tuning on such
generated data, we introduce LLaVA: Large Language and Vision Assistant, an
end-to-end trained large multimodal model that connects a vision encoder and
LLM for general-purpose visual and language understanding.Our early experiments
show that LLaVA demonstrates impressive multimodel chat abilities, sometimes
exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and
yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal
instruction-following dataset. When fine-tuned on Science QA, the synergy of
LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make
GPT-4 generated visual instruction tuning data, our model and code base
publicly available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.12477">On Dynamic Programming Decompositions of Static Risk Measures in Markov Decision Processes. (arXiv:2304.12477v3 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Hau_J/0/1/0/all/0/1">Jia Lin Hau</a>, <a href="http://arxiv.org/find/math/1/au:+Delage_E/0/1/0/all/0/1">Erick Delage</a>, <a href="http://arxiv.org/find/math/1/au:+Ghavamzadeh_M/0/1/0/all/0/1">Mohammad Ghavamzadeh</a>, <a href="http://arxiv.org/find/math/1/au:+Petrik_M/0/1/0/all/0/1">Marek Petrik</a></p>
<p>Optimizing static risk-averse objectives in Markov decision processes is
difficult because they do not admit standard dynamic programming equations
common in Reinforcement Learning (RL) algorithms. Dynamic programming
decompositions that augment the state space with discrete risk levels have
recently gained popularity in the RL community. Prior work has shown that these
decompositions are optimal when the risk level is discretized sufficiently.
However, we show that these popular decompositions for
Conditional-Value-at-Risk (CVaR) and Entropic-Value-at-Risk (EVaR) are
inherently suboptimal regardless of the discretization level. In particular, we
show that a saddle point property assumed to hold in prior literature may be
violated. However, a decomposition does hold for Value-at-Risk and our proof
demonstrates how this risk measure differs from CVaR and EVaR. Our findings are
significant because risk-averse algorithms are used in high-stake environments,
making their correctness much more critical.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.03520">Context-Aware Semantic Similarity Measurement for Unsupervised Word Sense Disambiguation. (arXiv:2305.03520v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Martinez_Gil_J/0/1/0/all/0/1">Jorge Martinez-Gil</a></p>
<p>The issue of word sense ambiguity poses a significant challenge in natural
language processing due to the scarcity of annotated data to feed machine
learning models to face the challenge. Therefore, unsupervised word sense
disambiguation methods have been developed to overcome that challenge without
relying on annotated data. This research proposes a new context-aware approach
to unsupervised word sense disambiguation, which provides a flexible mechanism
for incorporating contextual information into the similarity measurement
process. We experiment with a popular benchmark dataset to evaluate the
proposed strategy and compare its performance with state-of-the-art
unsupervised word sense disambiguation techniques. The experimental results
indicate that our approach substantially enhances disambiguation accuracy and
surpasses the performance of several existing techniques. Our findings
underscore the significance of integrating contextual information in semantic
similarity measurements to manage word sense ambiguity in unsupervised
scenarios effectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.06152">Structure-CLIP: Towards Scene Graph Knowledge to Enhance Multi-modal Structured Representations. (arXiv:2305.06152v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yufeng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiji Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rongsheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weijie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zeng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhou Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1">Tangjie Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhipeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wen Zhang</a></p>
<p>Large-scale vision-language pre-training has achieved significant performance
in multi-modal understanding and generation tasks. However, existing methods
often perform poorly on image-text matching tasks that require structured
representations, i.e., representations of objects, attributes, and relations.
As illustrated in Fig.~reffig:case (a), the models cannot make a distinction
between ``An astronaut rides a horse" and ``A horse rides an astronaut". This
is because they fail to fully leverage structured knowledge when learning
representations in multi-modal scenarios. In this paper, we present an
end-to-end framework Structure-CLIP, which integrates Scene Graph Knowledge
(SGK) to enhance multi-modal structured representations. Firstly, we use scene
graphs to guide the construction of semantic negative examples, which results
in an increased emphasis on learning structured representations. Moreover, a
Knowledge-Enhance Encoder (KEE) is proposed to leverage SGK as input to further
enhance structured representations. To verify the effectiveness of the proposed
framework, we pre-train our model with the aforementioned approaches and
conduct experiments on downstream tasks. Experimental results demonstrate that
Structure-CLIP achieves state-of-the-art (SOTA) performance on VG-Attribution
and VG-Relation datasets, with 12.5% and 4.1% ahead of the multi-modal SOTA
model respectively. Meanwhile, the results on MSCOCO indicate that
Structure-CLIP significantly enhances the structured representations while
maintaining the ability of general representations. Our code is available at
https://github.com/zjukg/Structure-CLIP.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.06161">StarCoder: may the source be with you!. (arXiv:2305.06161v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Raymond Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Allal_L/0/1/0/all/0/1">Loubna Ben Allal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_Y/0/1/0/all/0/1">Yangtian Zi</a>, <a href="http://arxiv.org/find/cs/1/au:+Muennighoff_N/0/1/0/all/0/1">Niklas Muennighoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Kocetkov_D/0/1/0/all/0/1">Denis Kocetkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Mou_C/0/1/0/all/0/1">Chenghao Mou</a>, <a href="http://arxiv.org/find/cs/1/au:+Marone_M/0/1/0/all/0/1">Marc Marone</a>, <a href="http://arxiv.org/find/cs/1/au:+Akiki_C/0/1/0/all/0/1">Christopher Akiki</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chim_J/0/1/0/all/0/1">Jenny Chim</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheltonozhskii_E/0/1/0/all/0/1">Evgenii Zheltonozhskii</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_T/0/1/0/all/0/1">Terry Yue Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Thomas Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehaene_O/0/1/0/all/0/1">Olivier Dehaene</a>, <a href="http://arxiv.org/find/cs/1/au:+Davaadorj_M/0/1/0/all/0/1">Mishig Davaadorj</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamy_Poirier_J/0/1/0/all/0/1">Joel Lamy-Poirier</a>, <a href="http://arxiv.org/find/cs/1/au:+Monteiro_J/0/1/0/all/0/1">Jo&#xe3;o Monteiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Shliazhko_O/0/1/0/all/0/1">Oleh Shliazhko</a>, <a href="http://arxiv.org/find/cs/1/au:+Gontier_N/0/1/0/all/0/1">Nicolas Gontier</a>, <a href="http://arxiv.org/find/cs/1/au:+Meade_N/0/1/0/all/0/1">Nicholas Meade</a>, <a href="http://arxiv.org/find/cs/1/au:+Zebaze_A/0/1/0/all/0/1">Armel Zebaze</a>, <a href="http://arxiv.org/find/cs/1/au:+Yee_M/0/1/0/all/0/1">Ming-Ho Yee</a>, <a href="http://arxiv.org/find/cs/1/au:+Umapathi_L/0/1/0/all/0/1">Logesh Kumar Umapathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipkin_B/0/1/0/all/0/1">Benjamin Lipkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Oblokulov_M/0/1/0/all/0/1">Muhtasham Oblokulov</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiruo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Murthy_R/0/1/0/all/0/1">Rudra Murthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Stillerman_J/0/1/0/all/0/1">Jason Stillerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1">Siva Sankalp Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Abulkhanov_D/0/1/0/all/0/1">Dmitry Abulkhanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zocca_M/0/1/0/all/0/1">Marco Zocca</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_M/0/1/0/all/0/1">Manan Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhihan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fahmy_N/0/1/0/all/0/1">Nour Fahmy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_U/0/1/0/all/0/1">Urvashi Bhattacharyya</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1">Wenhao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Swayam Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Luccioni_S/0/1/0/all/0/1">Sasha Luccioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Villegas_P/0/1/0/all/0/1">Paulo Villegas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunakov_M/0/1/0/all/0/1">Maxim Kunakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhdanov_F/0/1/0/all/0/1">Fedor Zhdanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_M/0/1/0/all/0/1">Manuel Romero</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1">Tony Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Timor_N/0/1/0/all/0/1">Nadav Timor</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1">Jennifer Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlesinger_C/0/1/0/all/0/1">Claire Schlesinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Schoelkopf_H/0/1/0/all/0/1">Hailey Schoelkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Ebert_J/0/1/0/all/0/1">Jan Ebert</a>, <a href="http://arxiv.org/find/cs/1/au:+Dao_T/0/1/0/all/0/1">Tri Dao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_M/0/1/0/all/0/1">Mayank Mishra</a>, et al. (15 additional authors not shown)</p>
<p>The BigCode community, an open-scientific collaboration working on the
responsible development of Large Language Models for Code (Code LLMs),
introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context
length, infilling capabilities and fast large-batch inference enabled by
multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced
from The Stack, a large collection of permissively licensed GitHub repositories
with inspection tools and an opt-out process. We fine-tuned StarCoderBase on
35B Python tokens, resulting in the creation of StarCoder. We perform the most
comprehensive evaluation of Code LLMs to date and show that StarCoderBase
outperforms every open Code LLM that supports multiple programming languages
and matches or outperforms the OpenAI code-cushman-001 model. Furthermore,
StarCoder outperforms every model that is fine-tuned on Python, can be prompted
to achieve 40\% pass@1 on HumanEval, and still retains its performance on other
programming languages. We take several important steps towards a safe
open-access model release, including an improved PII redaction pipeline and a
novel attribution tracing tool, and make the StarCoder models publicly
available under a more commercially viable version of the Open Responsible AI
Model license.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18290">Direct Preference Optimization: Your Language Model is Secretly a Reward Model. (arXiv:2305.18290v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rafailov_R/0/1/0/all/0/1">Rafael Rafailov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Archit Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_E/0/1/0/all/0/1">Eric Mitchell</a>, <a href="http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1">Christopher D. Manning</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a></p>
<p>While large-scale unsupervised language models (LMs) learn broad world
knowledge and some reasoning skills, achieving precise control of their
behavior is difficult due to the completely unsupervised nature of their
training. Existing methods for gaining such steerability collect human labels
of the relative quality of model generations and fine-tune the unsupervised LM
to align with these preferences, often with reinforcement learning from human
feedback (RLHF). However, RLHF is a complex and often unstable procedure, first
fitting a reward model that reflects the human preferences, and then
fine-tuning the large unsupervised LM using reinforcement learning to maximize
this estimated reward without drifting too far from the original model. In this
paper we introduce a new parameterization of the reward model in RLHF that
enables extraction of the corresponding optimal policy in closed form, allowing
us to solve the standard RLHF problem with only a simple classification loss.
The resulting algorithm, which we call Direct Preference Optimization (DPO), is
stable, performant, and computationally lightweight, eliminating the need for
sampling from the LM during fine-tuning or performing significant
hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align
with human preferences as well as or better than existing methods. Notably,
fine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of
generations, and matches or improves response quality in summarization and
single-turn dialogue while being substantially simpler to implement and train.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.03061">Structured Voronoi Sampling. (arXiv:2306.03061v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1">Afra Amini</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1">Li Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a></p>
<p>Gradient-based sampling algorithms have demonstrated their effectiveness in
text generation, especially in the context of controlled text generation.
However, there exists a lack of theoretically grounded and principled
approaches for this task. In this paper, we take an important step toward
building a principled approach for sampling from language models with
gradient-based methods. We use discrete distributions given by language models
to define densities and develop an algorithm based on Hamiltonian Monte Carlo
to sample from them. We name our gradient-based technique Structured Voronoi
Sampling (SVS). In an experimental setup where the reference distribution is
known, we show that the empirical distribution of SVS samples is closer to the
reference distribution compared to alternative sampling schemes. Furthermore,
in a controlled generation task, SVS is able to generate fluent and diverse
samples while following the control targets significantly better than other
methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.14209">Deep image prior inpainting of ancient frescoes in the Mediterranean Alpine arc. (arXiv:2306.14209v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Merizzi_F/0/1/0/all/0/1">Fabio Merizzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Saillard_P/0/1/0/all/0/1">Perrine Saillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Acquier_O/0/1/0/all/0/1">Oceane Acquier</a>, <a href="http://arxiv.org/find/cs/1/au:+Morotti_E/0/1/0/all/0/1">Elena Morotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Piccolomini_E/0/1/0/all/0/1">Elena Loli Piccolomini</a>, <a href="http://arxiv.org/find/cs/1/au:+Calatroni_L/0/1/0/all/0/1">Luca Calatroni</a>, <a href="http://arxiv.org/find/cs/1/au:+Dessi_R/0/1/0/all/0/1">Rosa Maria Dess&#xec;</a></p>
<p>The unprecedented success of image reconstruction approaches based on deep
neural networks has revolutionised both the processing and the analysis
paradigms in several applied disciplines. In the field of digital humanities,
the task of digital reconstruction of ancient frescoes is particularly
challenging due to the scarce amount of available training data caused by
ageing, wear, tear and retouching over time. To overcome these difficulties, we
consider the Deep Image Prior (DIP) inpainting approach which computes
appropriate reconstructions by relying on the progressive updating of an
untrained convolutional neural network so as to match the reliable piece of
information in the image at hand while promoting regularisation elsewhere. In
comparison with state-of-the-art approaches (based on variational/PDEs and
patch-based methods), DIP-based inpainting reduces artefacts and better adapts
to contextual/non-local information, thus providing a valuable and effective
tool for art historians. As a case study, we apply such approach to reconstruct
missing image contents in a dataset of highly damaged digital images of
medieval paintings located into several chapels in the Mediterranean Alpine Arc
and provide a detailed description on how visible and invisible (e.g.,
infrared) information can be integrated for identifying and reconstructing
damaged image regions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.02345">LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning. (arXiv:2307.02345v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lv_O/0/1/0/all/0/1">Outongyi Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bingxin Zhou</a></p>
<p>Modern reinforcement learning (RL) can be categorized into online and offline
variants. As a pivotal aspect of both online and offline RL, current research
on the Bellman equation revolves primarily around optimization techniques and
performance enhancement rather than exploring the inherent structural
properties of the Bellman error, such as its distribution characteristics. This
study investigates the distribution of the Bellman approximation error through
iterative exploration of the Bellman equation with the observation that the
Bellman error approximately follows the Logistic distribution. Based on this,
we proposed the utilization of the Logistic maximum likelihood function (LLoss)
as an alternative to the commonly used mean squared error (MSELoss) that
assumes a Normal distribution for Bellman errors. We validated the hypotheses
through extensive numerical experiments across diverse online and offline
environments. In particular, we applied the Logistic correction to loss
functions in various RL baseline methods and observed that the results with
LLoss consistently outperformed the MSE counterparts. We also conducted the
Kolmogorov-Smirnov tests to confirm the reliability of the Logistic
distribution. Moreover, our theory connects the Bellman error to the
proportional reward scaling phenomenon by providing a distribution-based
analysis. Furthermore, we applied the bias-variance decomposition for sampling
from the Logistic distribution. The theoretical and empirical insights of this
study lay a valuable foundation for future investigations and enhancements
centered on the distribution of Bellman error.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00031">Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges. (arXiv:2308.00031v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Franceschelli_G/0/1/0/all/0/1">Giorgio Franceschelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Musolesi_M/0/1/0/all/0/1">Mirco Musolesi</a></p>
<p>Generative Artificial Intelligence (AI) is one of the most exciting
developments in Computer Science of the last decade. At the same time,
Reinforcement Learning (RL) has emerged as a very successful paradigm for a
variety of machine learning tasks. In this survey, we discuss the state of the
art, opportunities and open research questions in applying RL to generative AI.
In particular, we will discuss three types of applications, namely, RL as an
alternative way for generation without specified objectives; as a way for
generating outputs while concurrently maximizing an objective function; and,
finally, as a way of embedding desired characteristics, which cannot be easily
captured by means of an objective function, into the generative process. We
conclude the survey with an in-depth discussion of the opportunities and
challenges in this fascinating emerging area.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05170">FPGA Resource-aware Structured Pruning for Real-Time Neural Networks. (arXiv:2308.05170v2 [cs.AR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ramhorst_B/0/1/0/all/0/1">Benjamin Ramhorst</a>, <a href="http://arxiv.org/find/cs/1/au:+Loncar_V/0/1/0/all/0/1">Vladimir Loncar</a>, <a href="http://arxiv.org/find/cs/1/au:+Constantinides_G/0/1/0/all/0/1">George A. Constantinides</a></p>
<p>Neural networks achieve state-of-the-art performance in image classification,
speech recognition, scientific analysis and many more application areas. Due to
the high computational complexity and memory footprint of neural networks,
various compression techniques, such as pruning and quantization, have been
proposed in literature. Pruning sparsifies a neural network, reducing the
number of multiplications and memory. However, pruning often fails to capture
properties of the underlying hardware, causing unstructured sparsity and
load-balance inefficiency, thus bottlenecking resource improvements. We propose
a hardware-centric formulation of pruning, by formulating it as a knapsack
problem with resource-aware tensor structures. Evaluated on a range of tasks,
including sub-microsecond particle classification at CERN's Large Hadron
Collider and fast image classification, the proposed method achieves reductions
ranging between 55% and 92% in the DSP utilization and up to 81% in BRAM
utilization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.08742">PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaopeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shasha Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shezheng Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jie Yu</a></p>
<p>Model editing techniques modify a minor proportion of knowledge in Large
Language Models (LLMs) at a relatively low cost, which have demonstrated
notable success. Existing methods assume Transformer Layer (TL) hidden states
are values of key-value memories of the Feed-Forward Network (FFN). They
usually optimize the TL hidden states to memorize target knowledge and use it
to update the weights of the FFN in LLMs. However, the information flow of TL
hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN,
and residual connections. Existing methods neglect the fact that the TL hidden
states contains information not specifically required for FFN. Consequently,
the performance of model editing decreases. To achieve more precise model
editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes
certain general knowledge extraction patterns. This implies that MHSA weights
do not require updating when new knowledge is introduced. Based on above
findings, we introduce PMET, which simultaneously optimizes Transformer
Component (TC, namely MHSA and FFN) hidden states, while only using the
optimized TC hidden states of FFN to precisely update FFN weights. Our
experiments demonstrate that PMET exhibits state-of-the-art performance on both
the COUNTERFACT and zsRE datasets. Our ablation experiments substantiate the
effectiveness of our enhancements, further reinforcing the finding that the
MHSA encodes certain general knowledge extraction patterns and indicating its
storage of a small amount of factual knowledge. Our code is available at
https://github.com/xpq-tech/PMET.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.01226">Saturn: An Optimized Data System for Large Model Deep Learning Workloads. (arXiv:2309.01226v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nagrecha_K/0/1/0/all/0/1">Kabir Nagrecha</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Arun Kumar</a></p>
<p>Large language models such as GPT-3 &amp; ChatGPT have transformed deep learning
(DL), powering applications that have captured the public's imagination. These
models are rapidly being adopted across domains for analytics on various
modalities, often by finetuning pre-trained base models. Such models need
multiple GPUs due to both their size and computational load, driving the
development of a bevy of "model parallelism" techniques &amp; tools. Navigating
such parallelism choices, however, is a new burden for end users of DL such as
data scientists, domain scientists, etc. who may lack the necessary systems
knowhow. The need for model selection, which leads to many models to train due
to hyper-parameter tuning or layer-wise finetuning, compounds the situation
with two more burdens: resource apportioning and scheduling. In this work, we
tackle these three burdens for DL users in a unified manner by formalizing them
as a joint problem that we call SPASE: Select a Parallelism, Allocate
resources, and SchedulE. We propose a new information system architecture to
tackle the SPASE problem holistically, representing a key step toward enabling
wider adoption of large DL models. We devise an extensible template for
existing parallelism schemes and combine it with an automated empirical
profiler for runtime estimation. We then formulate SPASE as an MILP.
</p>
<p>We find that direct use of an MILP-solver is significantly more effective
than several baseline heuristics. We optimize the system runtime further with
an introspective scheduling approach. We implement all these techniques into a
new data system we call Saturn. Experiments with benchmark DL workloads show
that Saturn achieves 39-49% lower model selection runtimes than typical current
DL practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.01922">Regret Analysis of Policy Gradient Algorithm for Infinite Horizon Average Reward Markov Decision Processes. (arXiv:2309.01922v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bai_Q/0/1/0/all/0/1">Qinbo Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_W/0/1/0/all/0/1">Washim Uddin Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1">Vaneet Aggarwal</a></p>
<p>In this paper, we consider an infinite horizon average reward Markov Decision
Process (MDP). Distinguishing itself from existing works within this context,
our approach harnesses the power of the general policy gradient-based
algorithm, liberating it from the constraints of assuming a linear MDP
structure. We propose a policy gradient-based algorithm and show its global
convergence property. We then prove that the proposed algorithm has
$\tilde{\mathcal{O}}({T}^{3/4})$ regret. Remarkably, this paper marks a
pioneering effort by presenting the first exploration into regret-bound
computation for the general parameterized policy gradient algorithm in the
context of average reward scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.02784">Norm Tweaking: High-performance Low-bit Quantization of Large Language Models. (arXiv:2309.02784v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiangxiang Chu</a></p>
<p>As the size of large language models (LLMs) continues to grow, model
compression without sacrificing accuracy has become a crucial challenge for
deployment. While some quantization methods, such as GPTQ, have made progress
in achieving acceptable 4-bit weight-only quantization, attempts at lower-bit
quantization often result in severe performance degradation. In this paper, we
introduce a technique called norm tweaking, which can be used as a plugin in
current PTQ methods to achieve high precision while being cost-efficient. Our
approach is inspired by the observation that rectifying the quantized
activation distribution to match its float counterpart can readily restore
accuracy for LLMs. To achieve this, we carefully design a tweaking strategy
that includes calibration data generation and channel-wise distance constraint
to update the weights of normalization layers for better generalization. We
conduct extensive experiments on various datasets using several open-sourced
LLMs. Our method demonstrates significant improvements in both weight-only
quantization and joint quantization of weights and activations, surpassing
existing PTQ methods. On GLM-130B and OPT-66B, our method even achieves the
same level of accuracy at 2-bit quantization as their float ones. Our simple
and effective approach makes it more practical for real-world applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.04856">AmbientFlow: Invertible generative models from incomplete, noisy measurements. (arXiv:2309.04856v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kelkar_V/0/1/0/all/0/1">Varun A. Kelkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_R/0/1/0/all/0/1">Rucha Deshpande</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1">Arindam Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Anastasio_M/0/1/0/all/0/1">Mark A. Anastasio</a></p>
<p>Generative models have gained popularity for their potential applications in
imaging science, such as image reconstruction, posterior sampling and data
sharing. Flow-based generative models are particularly attractive due to their
ability to tractably provide exact density estimates along with fast,
inexpensive and diverse samples. Training such models, however, requires a
large, high quality dataset of objects. In applications such as computed
imaging, it is often difficult to acquire such data due to requirements such as
long acquisition time or high radiation dose, while acquiring noisy or
partially observed measurements of these objects is more feasible. In this
work, we propose AmbientFlow, a framework for learning flow-based generative
models directly from noisy and incomplete data. Using variational Bayesian
methods, a novel framework for establishing flow-based generative models from
noisy, incomplete data is proposed. Extensive numerical studies demonstrate the
effectiveness of AmbientFlow in learning the object distribution. The utility
of AmbientFlow in a downstream inference task of image reconstruction is
demonstrated.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.01217">ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale. (arXiv:2310.01217v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Frohmann_M/0/1/0/all/0/1">Markus Frohmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Holtermann_C/0/1/0/all/0/1">Carolin Holtermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Masoudian_S/0/1/0/all/0/1">Shahed Masoudian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1">Anne Lauscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekabsaz_N/0/1/0/all/0/1">Navid Rekabsaz</a></p>
<p>Multi-task learning (MTL) has shown considerable practical benefits,
particularly when using pre-trained language models (PLMs). While this is
commonly achieved by simultaneously learning $n$ tasks under a joint
optimization procedure, recent methods such as AdapterFusion structure the
problem into two distinct stages: (i) task learning, where knowledge specific
to a task is encapsulated within sets of parameters (e.g., adapters), and (ii)
transfer, where this already learned knowledge is leveraged for a target task.
This separation of concerns provides numerous benefits, such as promoting
reusability, and addressing cases involving data privacy and societal concerns;
on the flip side, current two-stage MTL methods come with the cost of
introducing a substantial number of additional parameters. In this work, we
address this issue by leveraging the usefulness of linearly scaling the output
representations of source adapters for transfer learning. We introduce
ScaLearn, a simple and highly parameter-efficient two-stage MTL method that
capitalizes on the knowledge of the source tasks by learning a minimal set of
scaling parameters that enable effective knowledge transfer to a target task.
Our experiments on three benchmarks (GLUE, SuperGLUE, and HumSet) show that our
ScaLearn, in addition to facilitating the benefits of two-stage MTL,
consistently outperforms strong baselines with only a small number of transfer
parameters - roughly 0.35% of those of AdapterFusion. Remarkably, we observe
that ScaLearn maintains its strong abilities even when further reducing
parameters through uniform scaling and layer-sharing, achieving similarly
competitive results with only $8$ transfer parameters for each target task. Our
proposed approach thus demonstrates the power of simple scaling as a promise
for more efficient task transfer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02161">Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models. (arXiv:2310.02161v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Michael Xieyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tongshuang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianying Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Franklin Mingzhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kittur_A/0/1/0/all/0/1">Aniket Kittur</a>, <a href="http://arxiv.org/find/cs/1/au:+Myers_B/0/1/0/all/0/1">Brad A. Myers</a></p>
<p>Sensemaking in unfamiliar domains can be challenging, demanding considerable
user effort to compare different options with respect to various criteria.
Prior research and our formative study found that people would benefit from
reading an overview of an information space upfront, including the criteria
others previously found useful. However, existing sensemaking tools struggle
with the "cold-start" problem -- not only requiring significant input from
previous users to generate and share these overviews, but also that such
overviews may turn out to be biased and incomplete. In this work, we introduce
a novel system, Selenite, which leverages LLMs as reasoning machines and
knowledge retrievers to automatically produce a comprehensive overview of
options and criteria to jumpstart users' sensemaking processes. Subsequently,
Selenite also adapts as people use it, helping users find, read, and navigate
unfamiliar information in a systematic yet personalized manner. Through three
studies, we found that Selenite produced accurate and high-quality overviews
reliably, significantly accelerated users' information processing, and
effectively improved their overall comprehension and sensemaking experience.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.03149">Attributing Learned Concepts in Neural Networks to Training Data. (arXiv:2310.03149v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Konz_N/0/1/0/all/0/1">Nicholas Konz</a>, <a href="http://arxiv.org/find/cs/1/au:+Godfrey_C/0/1/0/all/0/1">Charles Godfrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Shapiro_M/0/1/0/all/0/1">Madelyn Shapiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1">Jonathan Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1">Henry Kvinge</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1">Davis Brown</a></p>
<p>By now there is substantial evidence that deep learning models learn certain
human-interpretable features as part of their internal representations of data.
As having the right (or wrong) concepts is critical to trustworthy machine
learning systems, it is natural to ask which inputs from the model's original
training set were most important for learning a concept at a given layer. To
answer this, we combine data attribution methods with methods for probing the
concepts learned by a model. Training network and probe ensembles for two
concept datasets on a range of network layers, we use the recently developed
TRAK method for large-scale data attribution. We find some evidence for
convergence, where removing the 10,000 top attributing images for a concept and
retraining the model does not change the location of the concept in the network
nor the probing sparsity of the concept. This suggests that rather than being
highly dependent on a few specific examples, the features that inform the
development of a concept are spread in a more diffuse manner across its
exemplars, implying robustness in concept formation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.04353">A Language-Agent Approach to Formal Theorem-Proving. (arXiv:2310.04353v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thakur_A/0/1/0/all/0/1">Amitayush Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yeming Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1">Swarat Chaudhuri</a></p>
<p>Language agents, which use a large language model (LLM) capable of in-context
learning to interact with an external environment, have recently emerged as a
promising approach to control tasks. We present the first language-agent
approach to formal theorem-proving. Our method, COPRA, uses a high-capacity,
black-box LLM (GPT-4) as part of a policy for a stateful backtracking search.
During the search, the policy can select proof tactics and retrieve lemmas and
definitions from an external database. Each selected tactic is executed in the
underlying proof framework, and the execution feedback is used to build the
prompt for the next policy invocation. The search also tracks selected
information from its history and uses it to reduce hallucinations and
unnecessary LLM queries.
</p>
<p>We evaluate our implementation of COPRA on the miniF2F benchmark for Lean and
a set of Coq tasks from the Compcert project. On these benchmarks, COPRA
significantly outperforms one-shot invocations of GPT-4, as well as
state-of-the-art models fine-tuned on proof data, at finding correct proofs
quickly. Our code and data are available at
https://github.com/trishullab/copra.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09053">DATT: Deep Adaptive Trajectory Tracking for Quadrotor Control. (arXiv:2310.09053v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kevin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rana_R/0/1/0/all/0/1">Rwik Rana</a>, <a href="http://arxiv.org/find/cs/1/au:+Spitzer_A/0/1/0/all/0/1">Alexander Spitzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1">Guanya Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1">Byron Boots</a></p>
<p>Precise arbitrary trajectory tracking for quadrotors is challenging due to
unknown nonlinear dynamics, trajectory infeasibility, and actuation limits. To
tackle these challenges, we present Deep Adaptive Trajectory Tracking (DATT), a
learning-based approach that can precisely track arbitrary, potentially
infeasible trajectories in the presence of large disturbances in the real
world. DATT builds on a novel feedforward-feedback-adaptive control structure
trained in simulation using reinforcement learning. When deployed on real
hardware, DATT is augmented with a disturbance estimator using L1 adaptive
control in closed-loop, without any fine-tuning. DATT significantly outperforms
competitive adaptive nonlinear and model predictive controllers for both
feasible smooth and infeasible trajectories in unsteady wind fields, including
challenging scenarios where baselines completely fail. Moreover, DATT can
efficiently run online with an inference time less than 3.2 ms, less than 1/4
of the adaptive nonlinear model predictive control baseline
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.03426">GQKVA: Efficient Pre-training of Transformers by Grouping Queries, Keys, and Values. (arXiv:2311.03426v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Javadi_F/0/1/0/all/0/1">Farnoosh Javadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_W/0/1/0/all/0/1">Walid Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajimolahoseini_H/0/1/0/all/0/1">Habib Hajimolahoseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Ataiefard_F/0/1/0/all/0/1">Foozhan Ataiefard</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassanpour_M/0/1/0/all/0/1">Mohammad Hassanpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Asani_S/0/1/0/all/0/1">Saina Asani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_A/0/1/0/all/0/1">Austin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Awad_O/0/1/0/all/0/1">Omar Mohamed Awad</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kangling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a></p>
<p>Massive transformer-based models face several challenges, including slow and
computationally intensive pre-training and over-parametrization. This paper
addresses these challenges by proposing a versatile method called GQKVA, which
generalizes query, key, and value grouping techniques. GQKVA is designed to
speed up transformer pre-training while reducing the model size. Our
experiments with various GQKVA variants highlight a clear trade-off between
performance and model size, allowing for customized choices based on resource
and time limitations. Our findings also indicate that the conventional
multi-head attention approach is not always the best choice, as there are
lighter and faster alternatives available. We tested our method on ViT, which
achieved an approximate 0.3% increase in accuracy while reducing the model size
by about 4% in the task of image classification. Additionally, our most
aggressive model reduction experiment resulted in a reduction of approximately
15% in model size, with only around a 1% drop in accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.05608">FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts. (arXiv:2311.05608v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yichen Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ran_D/0/1/0/all/0/1">Delong Ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jinyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Conglei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_T/0/1/0/all/0/1">Tianshuo Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Anyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_S/0/1/0/all/0/1">Sisi Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoyun Wang</a></p>
<p>Ensuring the safety of artificial intelligence-generated content (AIGC) is a
longstanding topic in the artificial intelligence (AI) community, and the
safety concerns associated with Large Language Models (LLMs) have been widely
investigated. Recently, large vision-language models (VLMs) represent an
unprecedented revolution, as they are built upon LLMs but can incorporate
additional modalities (e.g., images). However, the safety of VLMs lacks
systematic evaluation, and there may be an overconfidence in the safety
guarantees provided by their underlying LLMs. In this paper, to demonstrate
that introducing additional modality modules leads to unforeseen AI safety
issues, we propose FigStep, a straightforward yet effective jailbreaking
algorithm against VLMs. Instead of feeding textual harmful instructions
directly, FigStep converts the harmful content into images through typography
to bypass the safety alignment within the textual module of the VLMs, inducing
VLMs to output unsafe responses that violate common AI safety policies. In our
evaluation, we manually review 46,500 model responses generated by 3 families
of the promising open-source VLMs, i.e., LLaVA, MiniGPT4, and CogVLM (a total
of 6 VLMs). The experimental results show that FigStep can achieve an average
attack success rate of 82.50% on 500 harmful queries in 10 topics. Moreover, we
demonstrate that the methodology of FigStep can even jailbreak GPT-4V, which
already leverages an OCR detector to filter harmful queries. Above all, our
work reveals that VLMs are vulnerable to jailbreaking attacks, which highlights
the necessity of novel safety alignments between visual and textual modalities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.08836">Evaluating Gender Bias in the Translation of Gender-Neutral Languages into English. (arXiv:2311.08836v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rarrick_S/0/1/0/all/0/1">Spencer Rarrick</a>, <a href="http://arxiv.org/find/cs/1/au:+Naik_R/0/1/0/all/0/1">Ranjita Naik</a>, <a href="http://arxiv.org/find/cs/1/au:+Poudel_S/0/1/0/all/0/1">Sundar Poudel</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhary_V/0/1/0/all/0/1">Vishal Chowdhary</a></p>
<p>Machine Translation (MT) continues to improve in quality and adoption, yet
the inadvertent perpetuation of gender bias remains a significant concern.
Despite numerous studies into gender bias in translations from gender-neutral
languages such as Turkish into more strongly gendered languages like English,
there are no benchmarks for evaluating this phenomenon or for assessing
mitigation strategies. To address this gap, we introduce GATE X-E, an extension
to the GATE (Rarrick et al., 2023) corpus, that consists of human translations
from Turkish, Hungarian, Finnish, and Persian into English. Each translation is
accompanied by feminine, masculine, and neutral variants for each possible
gender interpretation. The dataset, which contains between 1250 and 1850
instances for each of the four language pairs, features natural sentences with
a wide range of sentence lengths and domains, challenging translation rewriters
on various linguistic phenomena. Additionally, we present an English gender
rewriting solution built on GPT-3.5 Turbo and use GATE X-E to evaluate it. We
open source our contributions to encourage further research on gender
debiasing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13435">PG-Video-LLaVA: Pixel Grounding Large Video-Language Models. (arXiv:2311.13435v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Munasinghe_S/0/1/0/all/0/1">Shehan Munasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Thushara_R/0/1/0/all/0/1">Rusiru Thushara</a>, <a href="http://arxiv.org/find/cs/1/au:+Maaz_M/0/1/0/all/0/1">Muhammad Maaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasheed_H/0/1/0/all/0/1">Hanoona Abdul Rasheed</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mubarak Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1">Fahad Khan</a></p>
<p>Extending image-based Large Multimodal Models (LMMs) to videos is challenging
due to the inherent complexity of video data. The recent approaches extending
image-based LMMs to videos either lack the grounding capabilities (e.g.,
VideoChat, Video-ChatGPT, Video-LLaMA) or do not utilize the audio-signals for
better video understanding (e.g., Video-ChatGPT). Addressing these gaps, we
propose PG-Video-LLaVA, the first LMM with pixel-level grounding capability,
integrating audio cues by transcribing them into text to enrich video-context
understanding. Our framework uses an off-the-shelf tracker and a novel
grounding module, enabling it to spatially localize objects in videos following
user instructions. We evaluate PG-Video-LLaVA using video-based generative and
question-answering benchmarks and introduce new benchmarks specifically
designed to measure prompt-based object grounding performance in videos.
Further, we propose the use of Vicuna over GPT-3.5, as utilized in
Video-ChatGPT, for video-based conversation benchmarking, ensuring
reproducibility of results which is a concern with the proprietary nature of
GPT-3.5. Our framework builds on SoTA image-based LLaVA model and extends its
advantages to the video domain, delivering promising gains on video-based
conversation and grounding tasks. Project Page:
https://github.com/mbzuai-oryx/Video-LLaVA
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.00102">FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network And Feature Embedding Aggregation. (arXiv:2312.00102v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fanfei Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lele Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxin Wang</a></p>
<p>Federated learning (FL) is an emerging paradigm for decentralized training of
machine learning models on distributed clients, without revealing the data to
the central server. The learning scheme may be horizontal, vertical or hybrid
(both vertical and horizontal). Most existing research work with deep neural
network (DNN) modelling is focused on horizontal data distributions, while
vertical and hybrid schemes are much less studied. In this paper, we propose a
generalized algorithm FedEmb, for modelling vertical and hybrid DNN-based
learning. The idea of our algorithm is characterised by higher inference
accuracy, stronger privacy-preserving properties, and lower client-server
communication bandwidth demands as compared with existing work. The
experimental results show that FedEmb is an effective method to tackle both
split feature &amp; subject space decentralized problems, shows 0.3% to 4.2%
inference accuracy improvement with limited privacy revealing for datasets
stored in local clients, and reduces 88.9 % time complexity over vertical
baseline method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.00812">Empowering Autonomous Driving with Large Language Models: A Safety Perspective. (arXiv:2312.00812v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yixuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_R/0/1/0/all/0/1">Ruochen Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lang_C/0/1/0/all/0/1">Chengtian Lang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_S/0/1/0/all/0/1">Sinong Simon Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuoran Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qi Zhu</a></p>
<p>Autonomous Driving (AD) faces crucial hurdles for commercial launch, notably
in the form of diminished public trust and safety concerns from long-tail
unforeseen driving scenarios. This predicament is due to the limitation of deep
neural networks in AD software, which struggle with interpretability and
exhibit poor generalization capabilities in out-of-distribution and uncertain
scenarios. To this end, this paper advocates for the integration of Large
Language Models (LLMs) into the AD system, leveraging their robust common-sense
knowledge, reasoning abilities, and human-interaction capabilities. The
proposed approach deploys the LLM as an intelligent decision-maker in planning,
incorporating safety verifiers for contextual safety learning to enhance
overall AD performance and safety. We present results from two case studies
that affirm the efficacy of our approach. We further discuss the potential
integration of LLM for other AD software components including perception,
prediction, and simulation. Despite the observed challenges in the case
studies, the integration of LLMs is promising and beneficial for reinforcing
both safety and performance in AD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.01241">Just-in-Time Security Patch Detection -- LLM At the Rescue for Data Augmentation. (arXiv:2312.01241v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xunzhu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenghan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kisub Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_H/0/1/0/all/0/1">Haoye Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Ezzini_S/0/1/0/all/0/1">Saad Ezzini</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_J/0/1/0/all/0/1">Jacques Klein</a></p>
<p>In the face of growing vulnerabilities found in open-source software, the
need to identify {discreet} security patches has become paramount. The lack of
consistency in how software providers handle maintenance often leads to the
release of security patches without comprehensive advisories, leaving users
vulnerable to unaddressed security risks. To address this pressing issue, we
introduce a novel security patch detection system, LLMDA, which capitalizes on
Large Language Models (LLMs) and code-text alignment methodologies for patch
review, data enhancement, and feature combination. Within LLMDA, we initially
utilize LLMs for examining patches and expanding data of PatchDB and SPI-DB,
two security patch datasets from recent literature. We then use labeled
instructions to direct our LLMDA, differentiating patches based on security
relevance. Following this, we apply a PTFormer to merge patches with code,
formulating hybrid attributes that encompass both the innate details and the
interconnections between the patches and the code. This distinctive combination
method allows our system to capture more insights from the combined context of
patches and code, hence improving detection precision. Finally, we devise a
probabilistic batch contrastive learning mechanism within batches to augment
the capability of the our LLMDA in discerning security patches. The results
reveal that LLMDA significantly surpasses the start of the art techniques in
detecting security patches, underscoring its promise in fortifying software
maintenance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.03038">Sample-based Dynamic Hierarchical Transformer with Layer and Head Flexibility via Contextual Bandit. (arXiv:2312.03038v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fanfei Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lele Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxin Wang</a></p>
<p>Transformer requires a fixed number of layers and heads which makes them
inflexible to the complexity of individual samples and expensive in training
and inference. To address this, we propose a sample-based Dynamic Hierarchical
Transformer (DHT) model whose layers and heads can be dynamically configured
with single data samples via solving contextual bandit problems. To determine
the number of layers and heads, we use the Uniform Confidence Bound while we
deploy combinatorial Thompson Sampling in order to select specific head
combinations given their number. Different from previous work that focuses on
compressing trained networks for inference only, DHT is not only advantageous
for adaptively optimizing the underlying network architecture during training
but also has a flexible network for efficient inference. To the best of our
knowledge, this is the first comprehensive data-driven dynamic transformer
without any additional auxiliary neural networks that implement the dynamic
system. According to the experiment results, we achieve up to 74% computational
savings for both training and inference with a minimal loss of accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04730">DeceptPrompt: Exploiting LLM-driven Code Generation via Adversarial Natural Language Instructions. (arXiv:2312.04730v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhou Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaogeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a></p>
<p>With the advancement of Large Language Models (LLMs), significant progress
has been made in code generation, enabling LLMs to transform natural language
into programming code. These Code LLMs have been widely accepted by massive
users and organizations. However, a dangerous nature is hidden in the code,
which is the existence of fatal vulnerabilities. While some LLM providers have
attempted to address these issues by aligning with human guidance, these
efforts fall short of making Code LLMs practical and robust. Without a deep
understanding of the performance of the LLMs under the practical worst cases,
it would be concerning to apply them to various real-world applications. In
this paper, we answer the critical issue: Are existing Code LLMs immune to
generating vulnerable code? If not, what is the possible maximum severity of
this issue in practical deployment scenarios? In this paper, we introduce
DeceptPrompt, a novel algorithm that can generate adversarial natural language
instructions that drive the Code LLMs to generate functionality correct code
with vulnerabilities. DeceptPrompt is achieved through a systematic
evolution-based algorithm with a fine grain loss design. The unique advantage
of DeceptPrompt enables us to find natural prefix/suffix with totally benign
and non-directional semantic meaning, meanwhile, having great power in inducing
the Code LLMs to generate vulnerable code. This feature can enable us to
conduct the almost-worstcase red-teaming on these LLMs in a real scenario,
where users are using natural language. Our extensive experiments and analyses
on DeceptPrompt not only validate the effectiveness of our approach but also
shed light on the huge weakness of LLMs in the code generation task. When
applying the optimized prefix/suffix, the attack success rate (ASR) will
improve by average 50% compared with no prefix/suffix applying.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.05259">Optimizing the Passenger Flow for Airport Security Check. (arXiv:2312.05259v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fanfei Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaotian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Chaoyu Xie</a></p>
<p>Due to the necessary security for the airport and flight, passengers are
required to have strict security check before getting aboard. However, there
are frequent complaints of wasting huge amount of time while waiting for the
security check. This paper presents a potential solution aimed at optimizing
gate setup procedures specifically tailored for Chicago OHare International
Airport. By referring to queueing theory and performing Monte Carlo
simulations, we propose an approach to significantly diminish the average
waiting time to a more manageable level. Additionally, our study meticulously
examines and identifies the influential factors contributing to this
optimization, providing a comprehensive understanding of their impact.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.06036">AI Competitions and Benchmarks: towards impactful challenges with post-challenge papers, benchmarks and other dissemination actions. (arXiv:2312.06036v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marot_A/0/1/0/all/0/1">Antoine Marot</a>, <a href="http://arxiv.org/find/cs/1/au:+Rousseau_D/0/1/0/all/0/1">David Rousseau</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhen Xu</a></p>
<p>Organising an AI challenge does not end with the final event. The
long-lasting impact also needs to be organised. This chapter covers the various
activities after the challenge is formally finished. The target audience of
different post-challenge activities is identified. The various outputs of the
challenge are listed with the means to collect them. The main part of the
chapter is a template for a typical post-challenge paper, including possible
graphs as well as advice on how to turn the challenge into a long-lasting
benchmark.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.06141">Survey on Memory-Augmented Neural Networks: Cognitive Insights to AI Applications. (arXiv:2312.06141v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khosla_S/0/1/0/all/0/1">Savya Khosla</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yifei He</a></p>
<p>This paper explores Memory-Augmented Neural Networks (MANNs), delving into
how they blend human-like memory processes into AI. It covers different memory
types, like sensory, short-term, and long-term memory, linking psychological
theories with AI applications. The study investigates advanced architectures
such as Hopfield Networks, Neural Turing Machines, Correlation Matrix Memories,
Memformer, and Neural Attention Memory, explaining how they work and where they
excel. It dives into real-world uses of MANNs across Natural Language
Processing, Computer Vision, Multimodal Learning, and Retrieval Models, showing
how memory boosters enhance accuracy, efficiency, and reliability in AI tasks.
Overall, this survey provides a comprehensive view of MANNs, offering insights
for future research in memory-based AI systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.06853">LLF-Bench: Benchmark for Interactive Learning from Language Feedback. (arXiv:2312.06853v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Ching-An Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1">Andrey Kolobov</a>, <a href="http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1">Dipendra Misra</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_A/0/1/0/all/0/1">Allen Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Swaminathan_A/0/1/0/all/0/1">Adith Swaminathan</a></p>
<p>We introduce a new benchmark, LLF-Bench (Learning from Language Feedback
Benchmark; pronounced as "elf-bench"), to evaluate the ability of AI agents to
interactively learn from natural language feedback and instructions. Learning
from language feedback (LLF) is essential for people, largely because the rich
information this feedback provides can help a learner avoid much of trial and
error and thereby speed up the learning process. Large Language Models (LLMs)
have recently enabled AI agents to comprehend natural language -- and hence AI
agents can potentially benefit from language feedback during learning like
humans do. But existing interactive benchmarks do not assess this crucial
capability: they either use numeric reward feedback or require no learning at
all (only planning or information retrieval). LLF-Bench is designed to fill
this omission. LLF-Bench is a diverse collection of sequential decision-making
tasks that includes user recommendation, poem writing, navigation, and robot
control. The objective of an agent is to interactively solve these tasks based
on their natural-language instructions and the feedback received after taking
actions. Crucially, to ensure that the agent actually "learns" from the
feedback, LLF-Bench implements several randomization techniques (such as
paraphrasing and environment randomization) to ensure that the task isn't
familiar to the agent and that the agent is robust to various verbalizations.
In addition, LLF-Bench provides a unified OpenAI Gym interface for all its
tasks and allows the users to easily configure the information the feedback
conveys (among suggestion, explanation, and instantaneous performance) to study
how agents respond to different types of feedback. Together, these features
make LLF-Bench a unique research platform for developing and testing LLF
agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07107">The Logic of Doxastic Strategies. (arXiv:2312.07107v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Junli Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Naumov_P/0/1/0/all/0/1">Pavel Naumov</a></p>
<p>In many real-world situations, there is often not enough information to know
that a certain strategy will succeed in achieving the goal, but there is a good
reason to believe that it will. The paper introduces the term ``doxastic'' for
such strategies.
</p>
<p>The main technical contribution is a sound and complete logical system that
describes the interplay between doxastic strategy and belief modalities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07424">How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary Investigation. (arXiv:2312.07424v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhongyi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1">Guanglin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1">Rundong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tailin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yilong Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1">Lina Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a></p>
<p>In machine learning, generalization against distribution shifts -- where
deployment conditions diverge from the training scenarios -- is crucial,
particularly in fields like climate modeling, biomedicine, and autonomous
driving. The emergence of foundation models, distinguished by their extensive
pretraining and task versatility, has led to an increased interest in their
adaptability to distribution shifts. GPT-4V(ision) acts as the most advanced
publicly accessible multimodal foundation model, with extensive applications
across various domains, including anomaly detection, video understanding, image
generation, and medical diagnosis. However, its robustness against data
distributions remains largely underexplored. Addressing this gap, this study
rigorously evaluates GPT-4V's adaptability and generalization capabilities in
dynamic environments, benchmarking against prominent models like CLIP and
LLaVA. We delve into GPT-4V's zero-shot generalization across 13 diverse
datasets spanning natural, medical, and molecular domains. We further
investigate its adaptability to controlled data perturbations and examine the
efficacy of in-context learning as a tool to enhance its adaptation. Our
findings delineate GPT-4V's capability boundaries in distribution shifts,
shedding light on its strengths and limitations across various scenarios.
Importantly, this investigation contributes to our understanding of how AI
foundation models generalize to distribution shifts, offering pivotal insights
into their adaptability and robustness. Code is publicly available at
https://github.com/jameszhou-gl/gpt-4v-distribution-shift.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.16426">High Dynamic Range Image Reconstruction via Deep Explicit Polynomial Curve Estimation. (arXiv:2307.16426v1 [eess.IV] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Tang_J/0/1/0/all/0/1">Jiaqi Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1">Xiaogang Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_S/0/1/0/all/0/1">Sixing Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Ying-Cong Chen</a></p>
<p>Due to limited camera capacities, digital images usually have a narrower
dynamic illumination range than real-world scene radiance. To resolve this
problem, High Dynamic Range (HDR) reconstruction is proposed to recover the
dynamic range to better represent real-world scenes. However, due to different
physical imaging parameters, the tone-mapping functions between images and real
radiance are highly diverse, which makes HDR reconstruction extremely
challenging. Existing solutions can not explicitly clarify a corresponding
relationship between the tone-mapping function and the generated HDR image, but
this relationship is vital when guiding the reconstruction of HDR images. To
address this problem, we propose a method to explicitly estimate the tone
mapping function and its corresponding HDR image in one network. Firstly, based
on the characteristics of the tone mapping function, we construct a model by a
polynomial to describe the trend of the tone curve. To fit this curve, we use a
learnable network to estimate the coefficients of the polynomial. This curve
will be automatically adjusted according to the tone space of the Low Dynamic
Range (LDR) image, and reconstruct the real HDR image. Besides, since all
current datasets do not provide the corresponding relationship between the tone
mapping function and the LDR image, we construct a new dataset with both
synthetic and real images. Extensive experiments show that our method
generalizes well under different tone-mapping functions and achieves SOTA
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07511">A Hitchhiker&#x27;s Guide to Geometric GNNs for 3D Atomic Systems. (arXiv:2312.07511v1 [cs.LG] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Duval_A/0/1/0/all/0/1">Alexandre Duval</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathis_S/0/1/0/all/0/1">Simon V. Mathis</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_C/0/1/0/all/0/1">Chaitanya K. Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_V/0/1/0/all/0/1">Victor Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Miret_S/0/1/0/all/0/1">Santiago Miret</a>, <a href="http://arxiv.org/find/cs/1/au:+Malliaros_F/0/1/0/all/0/1">Fragkiskos D. Malliaros</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1">Taco Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1">Pietro Lio</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>, <a href="http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1">Michael Bronstein</a></p>
<p>Recent advances in computational modelling of atomic systems, spanning
molecules, proteins, and materials, represent them as geometric graphs with
atoms embedded as nodes in 3D Euclidean space. In these graphs, the geometric
attributes transform according to the inherent physical symmetries of 3D atomic
systems, including rotations and translations in Euclidean space, as well as
node permutations. In recent years, Geometric Graph Neural Networks have
emerged as the preferred machine learning architecture powering applications
ranging from protein structure prediction to molecular simulations and material
generation. Their specificity lies in the inductive biases they leverage --
such as physical symmetries and chemical properties -- to learn informative
representations of these geometric graphs. In this opinionated paper, we
provide a comprehensive and self-contained overview of the field of Geometric
GNNs for 3D atomic systems. We cover fundamental background material and
introduce a pedagogical taxonomy of Geometric GNN architectures:(1) invariant
networks, (2) equivariant networks in Cartesian basis, (3) equivariant networks
in spherical basis, and (4) unconstrained networks. Additionally, we outline
key datasets and application areas and suggest future research directions. The
objective of this work is to present a structured perspective on the field,
making it accessible to newcomers and aiding practitioners in gaining an
intuition for its mathematical abstractions.
</p>
</p>
</div>

    </div>
    </body>
    