<!DOCTYPE html>
<html>
<head>
<title>2023-07-27-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2307.13698">Exploring the Lottery Ticket Hypothesis with Explainability Methods: Insights into Sparse Network Performance. (arXiv:2307.13698v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Shantanu Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Batmanghelich_K/0/1/0/all/0/1">Kayhan Batmanghelich</a></p>
<p>Discovering a high-performing sparse network within a massive neural network
is advantageous for deploying them on devices with limited storage, such as
mobile phones. Additionally, model explainability is essential to fostering
trust in AI. The Lottery Ticket Hypothesis (LTH) finds a network within a deep
network with comparable or superior performance to the original model. However,
limited study has been conducted on the success or failure of LTH in terms of
explainability. In this work, we examine why the performance of the pruned
networks gradually increases or decreases. Using Grad-CAM and Post-hoc concept
bottleneck models (PCBMs), respectively, we investigate the explainability of
pruned networks in terms of pixels and high-level concepts. We perform
extensive experiments across vision and medical imaging datasets. As more
weights are pruned, the performance of the network degrades. The discovered
concepts and pixels from the pruned networks are inconsistent with the original
network -- a possible reason for the drop in performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13700">CAMP: A Context-Aware Cricket Players Performance Metric. (arXiv:2307.13700v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ayub_M/0/1/0/all/0/1">Muhammad Sohaib Ayub</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullah_N/0/1/0/all/0/1">Naimat Ullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Sarwan Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_I/0/1/0/all/0/1">Imdad Ullah Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Awais_M/0/1/0/all/0/1">Mian Muhammad Awais</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Muhammad Asad Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Faizullah_S/0/1/0/all/0/1">Safiullah Faizullah</a></p>
<p>Cricket is the second most popular sport after soccer in terms of viewership.
However, the assessment of individual player performance, a fundamental task in
team sports, is currently primarily based on aggregate performance statistics,
including average runs and wickets taken. We propose Context-Aware Metric of
player Performance, CAMP, to quantify individual players' contributions toward
a cricket match outcome. CAMP employs data mining methods and enables effective
data-driven decision-making for selection and drafting, coaching and training,
team line-ups, and strategy development. CAMP incorporates the exact context of
performance, such as opponents' strengths and specific circumstances of games,
such as pressure situations. We empirically evaluate CAMP on data of
limited-over cricket matches between 2001 and 2019. In every match, a committee
of experts declares one player as the best player, called Man of the M}atch
(MoM). The top two rated players by CAMP match with MoM in 83\% of the 961
games. Thus, the CAMP rating of the best player closely matches that of the
domain experts. By this measure, CAMP significantly outperforms the current
best-known players' contribution measure based on the Duckworth-Lewis-Stern
(DLS) method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13701">$\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation. (arXiv:2307.13701v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hang Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zihao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_W/0/1/0/all/0/1">Weizhi Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yangqiu Song</a></p>
<p>To answer complex queries on knowledge graphs, logical reasoning over
incomplete knowledge is required due to the open-world assumption.
Learning-based methods are essential because they are capable of generalizing
over unobserved knowledge. Therefore, an appropriate dataset is fundamental to
both obtaining and evaluating such methods under this paradigm. In this paper,
we propose a comprehensive framework for data generation, model training, and
method evaluation that covers the combinatorial space of Existential
First-order Queries with multiple variables ($\text{EFO}_{k}$). The
combinatorial query space in our framework significantly extends those defined
by set operations in the existing literature. Additionally, we construct a
dataset, $\text{EFO}_{k}$-CQA, with 741 types of query for empirical
evaluation, and our benchmark results provide new insights into how query
hardness affects the results. Furthermore, we demonstrate that the existing
dataset construction process is systematically biased that hinders the
appropriate development of query-answering methods, highlighting the importance
of our work. Our code and data are provided
in~\url{https://github.com/HKUST-KnowComp/EFOK-CQA}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13702">Measuring Faithfulness in Chain-of-Thought Reasoning. (arXiv:2307.13702v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lanham_T/0/1/0/all/0/1">Tamera Lanham</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Anna Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1">Ansh Radhakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_B/0/1/0/all/0/1">Benoit Steiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Denison_C/0/1/0/all/0/1">Carson Denison</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_D/0/1/0/all/0/1">Danny Hernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dustin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Durmus_E/0/1/0/all/0/1">Esin Durmus</a>, <a href="http://arxiv.org/find/cs/1/au:+Hubinger_E/0/1/0/all/0/1">Evan Hubinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Kernion_J/0/1/0/all/0/1">Jackson Kernion</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukosiute_K/0/1/0/all/0/1">Kamil&#x117; Luko&#x161;i&#x16b;t&#x117;</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Karina Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1">Newton Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Joseph_N/0/1/0/all/0/1">Nicholas Joseph</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiefer_N/0/1/0/all/0/1">Nicholas Schiefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rausch_O/0/1/0/all/0/1">Oliver Rausch</a>, <a href="http://arxiv.org/find/cs/1/au:+Larson_R/0/1/0/all/0/1">Robin Larson</a>, <a href="http://arxiv.org/find/cs/1/au:+McCandlish_S/0/1/0/all/0/1">Sam McCandlish</a>, <a href="http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1">Sandipan Kundu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1">Saurav Kadavath</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shannon Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Henighan_T/0/1/0/all/0/1">Thomas Henighan</a>, <a href="http://arxiv.org/find/cs/1/au:+Maxwell_T/0/1/0/all/0/1">Timothy Maxwell</a>, <a href="http://arxiv.org/find/cs/1/au:+Telleen_Lawton_T/0/1/0/all/0/1">Timothy Telleen-Lawton</a>, <a href="http://arxiv.org/find/cs/1/au:+Hume_T/0/1/0/all/0/1">Tristan Hume</a>, <a href="http://arxiv.org/find/cs/1/au:+Hatfield_Dodds_Z/0/1/0/all/0/1">Zac Hatfield-Dodds</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_J/0/1/0/all/0/1">Jared Kaplan</a>, <a href="http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1">Jan Brauner</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1">Samuel R. Bowman</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1">Ethan Perez</a></p>
<p>Large language models (LLMs) perform better when they produce step-by-step,
"Chain-of-Thought" (CoT) reasoning before answering a question, but it is
unclear if the stated reasoning is a faithful explanation of the model's actual
reasoning (i.e., its process for answering the question). We investigate
hypotheses for how CoT reasoning may be unfaithful, by examining how the model
predictions change when we intervene on the CoT (e.g., by adding mistakes or
paraphrasing it). Models show large variation across tasks in how strongly they
condition on the CoT when predicting their answer, sometimes relying heavily on
the CoT and other times primarily ignoring it. CoT's performance boost does not
seem to come from CoT's added test-time compute alone or from information
encoded via the particular phrasing of the CoT. As models become larger and
more capable, they produce less faithful reasoning on most tasks we study.
Overall, our results suggest that CoT can be faithful if the circumstances such
as the model size and task are carefully chosen.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13704">eXplainable Artificial Intelligence (XAI) in age prediction: A systematic review. (arXiv:2307.13704v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kalyakulina_A/0/1/0/all/0/1">Alena Kalyakulina</a>, <a href="http://arxiv.org/find/cs/1/au:+Yusipov_I/0/1/0/all/0/1">Igor Yusipov</a></p>
<p>eXplainable Artificial Intelligence (XAI) is now an important and essential
part of machine learning, allowing to explain the predictions of complex
models. XAI is especially required in risky applications, particularly in
health care, where human lives depend on the decisions of AI systems. One area
of medical research is age prediction and identification of biomarkers of aging
and age-related diseases. However, the role of XAI in the age prediction task
has not previously been explored directly. In this review, we discuss the
application of XAI approaches to age prediction tasks. We give a systematic
review of the works organized by body systems, and discuss the benefits of XAI
in medical applications and, in particular, in the age prediction domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13705">Control and Monitoring of Artificial Intelligence Algorithms. (arXiv:2307.13705v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ortuno_C/0/1/0/all/0/1">Carlos Mario Braga Ortu&#xf1;o</a>, <a href="http://arxiv.org/find/cs/1/au:+Donoso_B/0/1/0/all/0/1">Blanza Martinez Donoso</a>, <a href="http://arxiv.org/find/cs/1/au:+Villanueva_B/0/1/0/all/0/1">Bel&#xe9;n Mu&#xf1;iz Villanueva</a></p>
<p>This paper elucidates the importance of governing an artificial intelligence
model post-deployment and overseeing potential fluctuations in the distribution
of present data in contrast to the training data. The concepts of data drift
and concept drift are explicated, along with their respective foundational
distributions. Furthermore, a range of metrics is introduced, which can be
utilized to scrutinize the model's performance concerning potential temporal
variations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13709">Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items. (arXiv:2307.13709v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fujii_S/0/1/0/all/0/1">Satoru Fujii</a></p>
<p>Many properties in real world, such as desirability or strength in
competitive environment, can't be directly observed, which makes them difficult
to evaluate. To deal with this challenging problem, prior work has primarily
focused on estimating those properties of known items, especially the strength
of sports players, only of those who appears in paired comparison dataset. In
this paper, we introduce Deep Bradley-Terry Rating (DBTR), a novel ML framework
to evaluate any properties of unknown items, not necessarily present in
dataset. Our method seamlessly integrates traditional Bradley-Terry model with
a neural network structure. We also generalizes this architecture further for
asymmetric environment with unfairness, which is much more common in real world
settings. In our experimental analysis, DBTR successfully learned desired
quantification of those properties.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13715">Team Intro to AI team8 at CoachAI Badminton Challenge 2023: Advanced ShuttleNet for Shot Predictions. (arXiv:2307.13715v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shih-Hong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chou_P/0/1/0/all/0/1">Pin-Hsuan Chou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong-Fu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chien-An Han</a></p>
<p>In this paper, our objective is to improve the performance of the existing
framework ShuttleNet in predicting badminton shot types and locations by
leveraging past strokes. We participated in the CoachAI Badminton Challenge at
IJCAI 2023 and achieved significantly better results compared to the baseline.
Ultimately, our team achieved the first position in the competition and we made
our code available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13716">FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning. (arXiv:2307.13716v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Leiming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1">Cihao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1">Sibo Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Ziling Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1">Yuming Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1">Zhaoxiang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Cheewei Tan</a></p>
<p>Traditional federated learning uses the number of samples to calculate the
weights of each client model and uses this fixed weight value to fusion the
global model. However, in practical scenarios, each client's device and data
heterogeneity leads to differences in the quality of each client's model. Thus
the contribution to the global model is not wholly determined by the sample
size. In addition, if clients intentionally upload low-quality or malicious
models, using these models for aggregation will lead to a severe decrease in
global model accuracy. Traditional federated learning algorithms do not address
these issues. To solve this probelm, we propose FedDRL, a model fusion approach
using reinforcement learning based on a two staged approach. In the first
stage, Our method could filter out malicious models and selects trusted client
models to participate in the model fusion. In the second stage, the FedDRL
algorithm adaptively adjusts the weights of the trusted client models and
aggregates the optimal global model. We also define five model fusion scenarios
and compare our method with two baseline algorithms in those scenarios. The
experimental results show that our algorithm has higher reliability than other
algorithms while maintaining accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13744">mL-BFGS: A Momentum-based L-BFGS for Distributed Large-Scale Neural Network Optimization. (arXiv:2307.13744v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Niu_Y/0/1/0/all/0/1">Yue Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fabian_Z/0/1/0/all/0/1">Zalan Fabian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sunwoo Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1">Mahdi Soltanolkotabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1">Salman Avestimehr</a></p>
<p>Quasi-Newton methods still face significant challenges in training
large-scale neural networks due to additional compute costs in the Hessian
related computations and instability issues in stochastic training. A
well-known method, L-BFGS that efficiently approximates the Hessian using
history parameter and gradient changes, suffers convergence instability in
stochastic training. So far, attempts that adapt L-BFGS to large-scale
stochastic training incur considerable extra overhead, which offsets its
convergence benefits in wall-clock time. In this paper, we propose mL-BFGS, a
lightweight momentum-based L-BFGS algorithm that paves the way for quasi-Newton
(QN) methods in large-scale distributed deep neural network (DNN) optimization.
mL-BFGS introduces a nearly cost-free momentum scheme into L-BFGS update and
greatly reduces stochastic noise in the Hessian, therefore stabilizing
convergence during stochastic optimization. For model training at a large
scale, mL-BFGS approximates a block-wise Hessian, thus enabling distributing
compute and memory costs across all computing nodes. We provide a supporting
convergence analysis for mL-BFGS in stochastic settings. To investigate mL-BFGS
potential in large-scale DNN training, we train benchmark neural models using
mL-BFGS and compare performance with baselines (SGD, Adam, and other
quasi-Newton methods). Results show that mL-BFGS achieves both noticeable
iteration-wise and wall-clock speedup.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13750">Solution Path of Time-varying Markov Random Fields with Discrete Regularization. (arXiv:2307.13750v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Fattahi_S/0/1/0/all/0/1">Salar Fattahi</a>, <a href="http://arxiv.org/find/math/1/au:+Gomez_A/0/1/0/all/0/1">Andres Gomez</a></p>
<p>We study the problem of inferring sparse time-varying Markov random fields
(MRFs) with different discrete and temporal regularizations on the parameters.
Due to the intractability of discrete regularization, most approaches for
solving this problem rely on the so-called maximum-likelihood estimation (MLE)
with relaxed regularization, which neither results in ideal statistical
properties nor scale to the dimensions encountered in realistic settings. In
this paper, we address these challenges by departing from the MLE paradigm and
resorting to a new class of constrained optimization problems with exact,
discrete regularization to promote sparsity in the estimated parameters.
Despite the nonconvex and discrete nature of our formulation, we show that it
can be solved efficiently and parametrically for all sparsity levels. More
specifically, we show that the entire solution path of the time-varying MRF for
all sparsity levels can be obtained in $\mathcal{O}(pT^3)$, where $T$ is the
number of time steps and $p$ is the number of unknown parameters at any given
time. The efficient and parametric characterization of the solution path
renders our approach highly suitable for cross-validation, where parameter
estimation is required for varying regularization values. Despite its
simplicity and efficiency, we show that our proposed approach achieves provably
small estimation error for different classes of time-varying MRFs, namely
Gaussian and discrete MRFs, with as few as one sample per time. Utilizing our
algorithm, we can recover the complete solution path for instances of
time-varying MRFs featuring over 30 million variables in less than 12 minutes
on a standard laptop computer. Our code is available at
\url{https://sites.google.com/usc.edu/gomez/data}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13757">UPREVE: An End-to-End Causal Discovery Benchmarking System. (arXiv:2307.13757v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Unni_S/0/1/0/all/0/1">Suraj Jyothi Unni</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1">Paras Sheth</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1">Kaize Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Candan_K/0/1/0/all/0/1">K. Selcuk Candan</a></p>
<p>Discovering causal relationships in complex socio-behavioral systems is
challenging but essential for informed decision-making. We present Upload,
PREprocess, Visualize, and Evaluate (UPREVE), a user-friendly web-based
graphical user interface (GUI) designed to simplify the process of causal
discovery. UPREVE allows users to run multiple algorithms simultaneously,
visualize causal relationships, and evaluate the accuracy of learned causal
graphs. With its accessible interface and customizable features, UPREVE
empowers researchers and practitioners in social computing and
behavioral-cultural modeling (among others) to explore and understand causal
relationships effectively. Our proposed solution aims to make causal discovery
more accessible and user-friendly, enabling users to gain valuable insights for
better decision-making.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13763">Implicitly Normalized Explicitly Regularized Density Estimation. (arXiv:2307.13763v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Kozdoba_M/0/1/0/all/0/1">Mark Kozdoba</a>, <a href="http://arxiv.org/find/stat/1/au:+Perets_B/0/1/0/all/0/1">Binyamin Perets</a>, <a href="http://arxiv.org/find/stat/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a></p>
<p>We propose a new approach to non-parametric density estimation, that is based
on regularizing a Sobolev norm of the density. This method is provably
different from Kernel Density Estimation, and makes the bias of the model clear
and interpretable. While there is no closed analytic form for the associated
kernel, we show that one can approximate it using sampling. The optimization
problem needed to determine the density is non-convex, and standard gradient
methods do not perform well. However, we show that with an appropriate
initialization and using natural gradients, one can obtain well performing
solutions. Finally, while the approach provides unnormalized densities, which
prevents the use of log-likelihood for cross validation, we show that one can
instead adapt Fisher Divergence based Score Matching methods for this task. We
evaluate the resulting method on the comprehensive recent Anomaly Detection
benchmark suite, ADBench, and find that it ranks second best, among more than
15 algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13766">ClusterSeq: Enhancing Sequential Recommender Systems with Clustering based Meta-Learning. (arXiv:2307.13766v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maheri_M/0/1/0/all/0/1">Mohammmadmahdi Maheri</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdollahzadeh_R/0/1/0/all/0/1">Reza Abdollahzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadi_B/0/1/0/all/0/1">Bardia Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rafiei_M/0/1/0/all/0/1">Mina Rafiei</a>, <a href="http://arxiv.org/find/cs/1/au:+Habibi_J/0/1/0/all/0/1">Jafar Habibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabiee_H/0/1/0/all/0/1">Hamid R. Rabiee</a></p>
<p>In practical scenarios, the effectiveness of sequential recommendation
systems is hindered by the user cold-start problem, which arises due to limited
interactions for accurately determining user preferences. Previous studies have
attempted to address this issue by combining meta-learning with user and
item-side information. However, these approaches face inherent challenges in
modeling user preference dynamics, particularly for "minor users" who exhibit
distinct preferences compared to more common or "major users." To overcome
these limitations, we present a novel approach called ClusterSeq, a
Meta-Learning Clustering-Based Sequential Recommender System. ClusterSeq
leverages dynamic information in the user sequence to enhance item prediction
accuracy, even in the absence of side information. This model preserves the
preferences of minor users without being overshadowed by major users, and it
capitalizes on the collective knowledge of users within the same cluster.
Extensive experiments conducted on various benchmark datasets validate the
effectiveness of ClusterSeq. Empirical results consistently demonstrate that
ClusterSeq outperforms several state-of-the-art meta-learning recommenders.
Notably, compared to existing meta-learning methods, our proposed approach
achieves a substantial improvement of 16-39% in Mean Reciprocal Rank (MRR).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13771">Accuracy Amplification in Differentially Private Logistic Regression: A Pre-Training Approach. (arXiv:2307.13771v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hoseinpour_M/0/1/0/all/0/1">Mohammad Hoseinpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoseinpour_M/0/1/0/all/0/1">Milad Hoseinpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Aghagolzadeh_A/0/1/0/all/0/1">Ali Aghagolzadeh</a></p>
<p>Machine learning (ML) models can memorize training datasets. As a result,
training ML models over private datasets can violate the privacy of
individuals. Differential privacy (DP) is a rigorous privacy notion to preserve
the privacy of underlying training datasets in ML models. Yet, training ML
models in a DP framework usually degrades the accuracy of ML models. This paper
aims to boost the accuracy of a DP-ML model, specifically a logistic regression
model, via a pre-training module. In more detail, we initially pre-train our
model on a public training dataset that there is no privacy concern about it.
Then, we fine-tune our model via the DP logistic regression with the private
dataset. In the numerical results, we show that adding a pre-training module
significantly improves the accuracy of the DP logistic regression.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13787">The GANfather: Controllable generation of malicious activity to improve defence systems. (arXiv:2307.13787v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pereira_R/0/1/0/all/0/1">Ricardo Ribeiro Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Bono_J/0/1/0/all/0/1">Jacopo Bono</a>, <a href="http://arxiv.org/find/cs/1/au:+Ascensao_J/0/1/0/all/0/1">Jo&#xe3;o Tiago Ascens&#xe3;o</a>, <a href="http://arxiv.org/find/cs/1/au:+Aparicio_D/0/1/0/all/0/1">David Apar&#xed;cio</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_P/0/1/0/all/0/1">Pedro Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Bizarro_P/0/1/0/all/0/1">Pedro Bizarro</a></p>
<p>Machine learning methods to aid defence systems in detecting malicious
activity typically rely on labelled data. In some domains, such labelled data
is unavailable or incomplete. In practice this can lead to low detection rates
and high false positive rates, which characterise for example anti-money
laundering systems. In fact, it is estimated that 1.7--4 trillion euros are
laundered annually and go undetected. We propose The GANfather, a method to
generate samples with properties of malicious activity, without label
requirements. We propose to reward the generation of malicious samples by
introducing an extra objective to the typical Generative Adversarial Networks
(GANs) loss. Ultimately, our goal is to enhance the detection of illicit
activity using the discriminator network as a novel and robust defence system.
Optionally, we may encourage the generator to bypass pre-existing detection
systems. This setup then reveals defensive weaknesses for the discriminator to
correct. We evaluate our method in two real-world use cases, money laundering
and recommendation systems. In the former, our method moves cumulative amounts
close to 350 thousand dollars through a network of accounts without being
detected by an existing system. In the latter, we recommend the target item to
a broad user base with as few as 30 synthetic attackers. In both cases, we
train a new defence system to capture the synthetic attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13788">Histogram Layer Time Delay Neural Networks for Passive Sonar Classification. (arXiv:2307.13788v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ritu_J/0/1/0/all/0/1">Jarin Ritu</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_E/0/1/0/all/0/1">Ethan Barnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Martell_R/0/1/0/all/0/1">Riley Martell</a>, <a href="http://arxiv.org/find/cs/1/au:+Dine_A/0/1/0/all/0/1">Alexandra Van Dine</a>, <a href="http://arxiv.org/find/cs/1/au:+Peeples_J/0/1/0/all/0/1">Joshua Peeples</a></p>
<p>Underwater acoustic target detection in remote marine sensing operations is
challenging due to complex sound wave propagation. Despite the availability of
reliable sonar systems, target recognition remains a difficult problem. Various
methods address improved target recognition. However, most struggle to
disentangle the high-dimensional, non-linear patterns in the observed target
recordings. In this work, a novel method combines a time delay neural network
and histogram layer to incorporate statistical contexts for improved feature
learning and underwater acoustic target classification. The proposed method
outperforms the baseline model, demonstrating the utility in incorporating
statistical contexts for passive sonar target recognition. The code for this
work is publicly available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13793">Source Condition Double Robust Inference on Functionals of Inverse Problems. (arXiv:2307.13793v1 [stat.ME])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Bennett_A/0/1/0/all/0/1">Andrew Bennett</a>, <a href="http://arxiv.org/find/stat/1/au:+Kallus_N/0/1/0/all/0/1">Nathan Kallus</a>, <a href="http://arxiv.org/find/stat/1/au:+Mao_X/0/1/0/all/0/1">Xiaojie Mao</a>, <a href="http://arxiv.org/find/stat/1/au:+Newey_W/0/1/0/all/0/1">Whitney Newey</a>, <a href="http://arxiv.org/find/stat/1/au:+Syrgkanis_V/0/1/0/all/0/1">Vasilis Syrgkanis</a>, <a href="http://arxiv.org/find/stat/1/au:+Uehara_M/0/1/0/all/0/1">Masatoshi Uehara</a></p>
<p>We consider estimation of parameters defined as linear functionals of
solutions to linear inverse problems. Any such parameter admits a doubly robust
representation that depends on the solution to a dual linear inverse problem,
where the dual solution can be thought as a generalization of the inverse
propensity function. We provide the first source condition double robust
inference method that ensures asymptotic normality around the parameter of
interest as long as either the primal or the dual inverse problem is
sufficiently well-posed, without knowledge of which inverse problem is the more
well-posed one. Our result is enabled by novel guarantees for iterated Tikhonov
regularized adversarial estimators for linear inverse problems, over general
hypothesis spaces, which are developments of independent interest.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13807">Sports Betting: an application of neural networks and modern portfolio theory to the English Premier League. (arXiv:2307.13807v1 [q-fin.PM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Jimenez_V/0/1/0/all/0/1">V&#xe9;lez Jim&#xe9;nez</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Alberto_R/0/1/0/all/0/1">Rom&#xe1;n Alberto</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Ontiveros_L/0/1/0/all/0/1">Lecuanda Ontiveros</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Manuel_J/0/1/0/all/0/1">Jos&#xe9; Manuel</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Possani_E/0/1/0/all/0/1">Edgar Possani</a></p>
<p>This paper presents a novel approach for optimizing betting strategies in
sports gambling by integrating Von Neumann-Morgenstern Expected Utility Theory,
deep learning techniques, and advanced formulations of the Kelly Criterion. By
combining neural network models with portfolio optimization, our method
achieved remarkable profits of 135.8% relative to the initial wealth during the
latter half of the 20/21 season of the English Premier League. We explore
complete and restricted strategies, evaluating their performance, risk
management, and diversification. A deep neural network model is developed to
forecast match outcomes, addressing challenges such as limited variables. Our
research provides valuable insights and practical applications in the field of
sports betting and predictive modeling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13813">How to Scale Your EMA. (arXiv:2307.13813v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Busbridge_D/0/1/0/all/0/1">Dan Busbridge</a>, <a href="http://arxiv.org/find/stat/1/au:+Ramapuram_J/0/1/0/all/0/1">Jason Ramapuram</a>, <a href="http://arxiv.org/find/stat/1/au:+Ablin_P/0/1/0/all/0/1">Pierre Ablin</a>, <a href="http://arxiv.org/find/stat/1/au:+Likhomanenko_T/0/1/0/all/0/1">Tatiana Likhomanenko</a>, <a href="http://arxiv.org/find/stat/1/au:+Dhekane_E/0/1/0/all/0/1">Eeshan Gunesh Dhekane</a>, <a href="http://arxiv.org/find/stat/1/au:+Suau_X/0/1/0/all/0/1">Xavier Suau</a>, <a href="http://arxiv.org/find/stat/1/au:+Webb_R/0/1/0/all/0/1">Russ Webb</a></p>
<p>Preserving training dynamics across batch sizes is an important tool for
practical machine learning as it enables the trade-off between batch size and
wall-clock time. This trade-off is typically enabled by a scaling rule, for
example, in stochastic gradient descent, one should scale the learning rate
linearly with the batch size. Another important tool for practical machine
learning is the model Exponential Moving Average (EMA), which is a model copy
that does not receive gradient information, but instead follows its target
model with some momentum. This model EMA can improve the robustness and
generalization properties of supervised learning, stabilize pseudo-labeling,
and provide a learning signal for Self-Supervised Learning (SSL). Prior works
have treated the model EMA separately from optimization, leading to different
training dynamics across batch sizes and lower model performance. In this work,
we provide a scaling rule for optimization in the presence of model EMAs and
demonstrate its validity across a range of architectures, optimizers, and data
modalities. We also show the rule's validity where the model EMA contributes to
the optimization of the target model, enabling us to train EMA-based
pseudo-labeling and SSL methods at small and large batch sizes. For SSL, we
enable training of BYOL up to batch size 24,576 without sacrificing
performance, optimally a 6$\times$ wall-clock time reduction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13818">Gradient-Based Spectral Embeddings of Random Dot Product Graphs. (arXiv:2307.13818v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fiori_M/0/1/0/all/0/1">Marcelo Fiori</a>, <a href="http://arxiv.org/find/cs/1/au:+Marenco_B/0/1/0/all/0/1">Bernardo Marenco</a>, <a href="http://arxiv.org/find/cs/1/au:+Larroca_F/0/1/0/all/0/1">Federico Larroca</a>, <a href="http://arxiv.org/find/cs/1/au:+Bermolen_P/0/1/0/all/0/1">Paola Bermolen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mateos_G/0/1/0/all/0/1">Gonzalo Mateos</a></p>
<p>The Random Dot Product Graph (RDPG) is a generative model for relational
data, where nodes are represented via latent vectors in low-dimensional
Euclidean space. RDPGs crucially postulate that edge formation probabilities
are given by the dot product of the corresponding latent positions.
Accordingly, the embedding task of estimating these vectors from an observed
graph is typically posed as a low-rank matrix factorization problem. The
workhorse Adjacency Spectral Embedding (ASE) enjoys solid statistical
properties, but it is formally solving a surrogate problem and can be
computationally intensive. In this paper, we bring to bear recent advances in
non-convex optimization and demonstrate their impact to RDPG inference. We
advocate first-order gradient descent methods to better solve the embedding
problem, and to organically accommodate broader network embedding applications
of practical relevance. Notably, we argue that RDPG embeddings of directed
graphs loose interpretability unless the factor matrices are constrained to
have orthogonal columns. We thus develop a novel feasible optimization method
in the resulting manifold. The effectiveness of the graph representation
learning framework is demonstrated on reproducible experiments with both
synthetic and real network data. Our open-source algorithm implementations are
scalable, and unlike the ASE they are robust to missing edge data and can track
slowly-varying latent positions from streaming graphs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13821">Fitting Auditory Filterbanks with Multiresolution Neural Networks. (arXiv:2307.13821v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lostanlen_V/0/1/0/all/0/1">Vincent Lostanlen</a>, <a href="http://arxiv.org/find/cs/1/au:+Haider_D/0/1/0/all/0/1">Daniel Haider</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Han Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lagrange_M/0/1/0/all/0/1">Mathieu Lagrange</a>, <a href="http://arxiv.org/find/cs/1/au:+Balazs_P/0/1/0/all/0/1">Peter Balazs</a>, <a href="http://arxiv.org/find/cs/1/au:+Ehler_M/0/1/0/all/0/1">Martin Ehler</a></p>
<p>Waveform-based deep learning faces a dilemma between nonparametric and
parametric approaches. On one hand, convolutional neural networks (convnets)
may approximate any linear time-invariant system; yet, in practice, their
frequency responses become more irregular as their receptive fields grow. On
the other hand, a parametric model such as LEAF is guaranteed to yield Gabor
filters, hence an optimal time-frequency localization; yet, this strong
inductive bias comes at the detriment of representational capacity. In this
paper, we aim to overcome this dilemma by introducing a neural audio model,
named multiresolution neural network (MuReNN). The key idea behind MuReNN is to
train separate convolutional operators over the octave subbands of a discrete
wavelet transform (DWT). Since the scale of DWT atoms grows exponentially
between octaves, the receptive fields of the subsequent learnable convolutions
in MuReNN are dilated accordingly. For a given real-world dataset, we fit the
magnitude response of MuReNN to that of a well-established auditory filterbank:
Gammatone for speech, CQT for music, and third-octave for urban sounds,
respectively. This is a form of knowledge distillation (KD), in which the
filterbank ''teacher'' is engineered by domain knowledge while the neural
network ''student'' is optimized from data. We compare MuReNN to the state of
the art in terms of goodness of fit after KD on a hold-out set and in terms of
Heisenberg time-frequency localization. Compared to convnets and Gabor
convolutions, we find that MuReNN reaches state-of-the-art performance on all
three optimization problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13824">Offline Reinforcement Learning with On-Policy Q-Function Regularization. (arXiv:2307.13824v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1">Laixi Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dadashi_R/0/1/0/all/0/1">Robert Dadashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1">Yuejie Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_P/0/1/0/all/0/1">Pablo Samuel Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1">Matthieu Geist</a></p>
<p>The core challenge of offline reinforcement learning (RL) is dealing with the
(potentially catastrophic) extrapolation error induced by the distribution
shift between the history dataset and the desired policy. A large portion of
prior work tackles this challenge by implicitly/explicitly regularizing the
learning policy towards the behavior policy, which is hard to estimate reliably
in practice. In this work, we propose to regularize towards the Q-function of
the behavior policy instead of the behavior policy itself, under the premise
that the Q-function can be estimated more reliably and easily by a SARSA-style
estimate and handles the extrapolation error more straightforwardly. We propose
two algorithms taking advantage of the estimated Q-function through
regularizations, and demonstrate they exhibit strong performance on the D4RL
benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13831">Relationship between Batch Size and Number of Steps Needed for Nonconvex Optimization of Stochastic Gradient Descent using Armijo Line Search. (arXiv:2307.13831v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tsukada_Y/0/1/0/all/0/1">Yuki Tsukada</a>, <a href="http://arxiv.org/find/cs/1/au:+Iiduka_H/0/1/0/all/0/1">Hideaki Iiduka</a></p>
<p>Stochastic gradient descent (SGD) is the simplest deep learning optimizer
with which to train deep neural networks. While SGD can use various learning
rates, such as constant or diminishing rates, the previous numerical results
showed that SGD performs better than other deep learning optimizers using when
it uses learning rates given by line search methods. In this paper, we perform
a convergence analysis on SGD with a learning rate given by an Armijo line
search for nonconvex optimization. The analysis indicates that the upper bound
of the expectation of the squared norm of the full gradient becomes small when
the number of steps and the batch size are large. Next, we show that, for SGD
with the Armijo-line-search learning rate, the number of steps needed for
nonconvex optimization is a monotone decreasing convex function of the batch
size; that is, the number of steps needed for nonconvex optimization decreases
as the batch size increases. Furthermore, we show that the stochastic
first-order oracle (SFO) complexity, which is the stochastic gradient
computation cost, is a convex function of the batch size; that is, there exists
a critical batch size that minimizes the SFO complexity. Finally, we provide
numerical results that support our theoretical results. The numerical results
indicate that the number of steps needed for training deep neural networks
decreases as the batch size increases and that there exist the critical batch
sizes that can be estimated from the theoretical results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13850">MAEA: Multimodal Attribution for Embodied AI. (arXiv:2307.13850v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1">Vidhi Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamarapalli_J/0/1/0/all/0/1">Jayant Sravan Tamarapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Yerramilli_S/0/1/0/all/0/1">Sahiti Yerramilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1">Yonatan Bisk</a></p>
<p>Understanding multimodal perception for embodied AI is an open question
because such inputs may contain highly complementary as well as redundant
information for the task. A relevant direction for multimodal policies is
understanding the global trends of each modality at the fusion layer. To this
end, we disentangle the attributions for visual, language, and previous action
inputs across different policies trained on the ALFRED dataset. Attribution
analysis can be utilized to rank and group the failure scenarios, investigate
modeling and dataset biases, and critically analyze multimodal EAI policies for
robustness and user trust before deployment. We present MAEA, a framework to
compute global attributions per modality of any differentiable policy. In
addition, we show how attributions enable lower-level behavior analysis in EAI
policies for language and visual attributions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13851">SplitFed resilience to packet loss: Where to split, that is the question. (arXiv:2307.13851v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shiranthika_C/0/1/0/all/0/1">Chamani Shiranthika</a>, <a href="http://arxiv.org/find/cs/1/au:+Kafshgari_Z/0/1/0/all/0/1">Zahra Hafezi Kafshgari</a>, <a href="http://arxiv.org/find/cs/1/au:+Saeedi_P/0/1/0/all/0/1">Parvaneh Saeedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bajic_I/0/1/0/all/0/1">Ivan V. Baji&#x107;</a></p>
<p>Decentralized machine learning has broadened its scope recently with the
invention of Federated Learning (FL), Split Learning (SL), and their hybrids
like Split Federated Learning (SplitFed or SFL). The goal of SFL is to reduce
the computational power required by each client in FL and parallelize SL while
maintaining privacy. This paper investigates the robustness of SFL against
packet loss on communication links. The performance of various SFL aggregation
strategies is examined by splitting the model at two points -- shallow split
and deep split -- and testing whether the split point makes a statistically
significant difference to the accuracy of the final model. Experiments are
carried out on a segmentation model for human embryo images and indicate the
statistically significant advantage of a deeper split point.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13854">WebArena: A Realistic Web Environment for Building Autonomous Agents. (arXiv:2307.13854v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuyan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Frank F. Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xuhui Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_R/0/1/0/all/0/1">Robert Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1">Abishek Sridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xianyi Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1">Yonatan Bisk</a>, <a href="http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1">Daniel Fried</a>, <a href="http://arxiv.org/find/cs/1/au:+Alon_U/0/1/0/all/0/1">Uri Alon</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a></p>
<p>With generative AI advances, the exciting potential for autonomous agents to
manage daily tasks via natural language commands has emerged. However, cur rent
agents are primarily created and tested in simplified synthetic environments,
substantially limiting real-world scenario representation. In this paper, we
build an environment for agent command and control that is highly realistic and
reproducible. Specifically, we focus on agents that perform tasks on websites,
and we create an environment with fully functional websites from four common
domains: e-commerce, social forum discussions, collaborative software
development, and content management. Our environment is enriched with tools
(e.g., a map) and external knowledge bases (e.g., user manuals) to encourage
human-like task-solving. Building upon our environment, we release a set of
benchmark tasks focusing on evaluating the functional correctness of task
completions. The tasks in our benchmark are diverse, long-horizon, and are
designed to emulate tasks that humans routinely perform on the internet. We
design and implement several autonomous agents, integrating recent techniques
such as reasoning before acting. The results demonstrate that solving complex
tasks is challenging: our best GPT-4-based agent only achieves an end-to-end
task success rate of 10.59%. These results highlight the need for further
development of robust agents, that current state-of-the-art LMs are far from
perfect performance in these real-life tasks, and that WebArena can be used to
measure such progress. Our code, data, environment reproduction resources, and
video demonstrations are publicly available at https://webarena.dev/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13855">Exploring the Sharpened Cosine Similarity. (arXiv:2307.13855v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Skyler Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_F/0/1/0/all/0/1">Fred Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1">Edward Raff</a>, <a href="http://arxiv.org/find/cs/1/au:+Holt_J/0/1/0/all/0/1">James Holt</a></p>
<p>Convolutional layers have long served as the primary workhorse for image
classification. Recently, an alternative to convolution was proposed using the
Sharpened Cosine Similarity (SCS), which in theory may serve as a better
feature detector. While multiple sources report promising results, there has
not been to date a full-scale empirical analysis of neural network performance
using these new layers. In our work, we explore SCS's parameter behavior and
potential as a drop-in replacement for convolutions in multiple CNN
architectures benchmarked on CIFAR-10. We find that while SCS may not yield
significant increases in accuracy, it may learn more interpretable
representations. We also find that, in some circumstances, SCS may confer a
slight increase in adversarial robustness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13856">On the unreasonable vulnerability of transformers for image restoration -- and an easy fix. (arXiv:2307.13856v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Agnihotri_S/0/1/0/all/0/1">Shashank Agnihotri</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandikota_K/0/1/0/all/0/1">Kanchana Vaishnavi Gandikota</a>, <a href="http://arxiv.org/find/cs/1/au:+Grabinski_J/0/1/0/all/0/1">Julia Grabinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandramouli_P/0/1/0/all/0/1">Paramanand Chandramouli</a>, <a href="http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1">Margret Keuper</a></p>
<p>Following their success in visual recognition tasks, Vision
Transformers(ViTs) are being increasingly employed for image restoration. As a
few recent works claim that ViTs for image classification also have better
robustness properties, we investigate whether the improved adversarial
robustness of ViTs extends to image restoration. We consider the recently
proposed Restormer model, as well as NAFNet and the "Baseline network" which
are both simplified versions of a Restormer. We use Projected Gradient Descent
(PGD) and CosPGD, a recently proposed adversarial attack tailored to pixel-wise
prediction tasks for our robustness evaluation. Our experiments are performed
on real-world images from the GoPro dataset for image deblurring. Our analysis
indicates that contrary to as advocated by ViTs in image classification works,
these models are highly susceptible to adversarial attacks. We attempt to
improve their robustness through adversarial training. While this yields a
significant increase in robustness for Restormer, results on other networks are
less promising. Interestingly, the design choices in NAFNet and Baselines,
which were based on iid performance, and not on robust generalization, seem to
be at odds with the model robustness. Thus, we investigate this further and
find a fix.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13861">Learning to Design Analog Circuits to Meet Threshold Specifications. (arXiv:2307.13861v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Krylov_D/0/1/0/all/0/1">Dmitrii Krylov</a>, <a href="http://arxiv.org/find/cs/1/au:+Khajeh_P/0/1/0/all/0/1">Pooya Khajeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_J/0/1/0/all/0/1">Junhan Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Reeves_T/0/1/0/all/0/1">Thomas Reeves</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongkai Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ajmal_H/0/1/0/all/0/1">Hiba Ajmal</a>, <a href="http://arxiv.org/find/cs/1/au:+Aghasi_H/0/1/0/all/0/1">Hamidreza Aghasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_R/0/1/0/all/0/1">Roy Fox</a></p>
<p>Automated design of analog and radio-frequency circuits using supervised or
reinforcement learning from simulation data has recently been studied as an
alternative to manual expert design. It is straightforward for a design agent
to learn an inverse function from desired performance metrics to circuit
parameters. However, it is more common for a user to have threshold performance
criteria rather than an exact target vector of feasible performance measures.
In this work, we propose a method for generating from simulation data a dataset
on which a system can be trained via supervised learning to design circuits to
meet threshold specifications. We moreover perform the to-date most extensive
evaluation of automated analog circuit design, including experimenting in a
significantly more diverse set of circuits than in prior work, covering linear,
nonlinear, and autonomous circuit configurations, and show that our method
consistently reaches success rate better than 90% at 5% error margin, while
also improving data efficiency by upward of an order of magnitude. A demo of
this system is available at circuits.streamlit.app
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13865">Pretrained Deep 2.5D Models for Efficient Predictive Modeling from Retinal OCT. (arXiv:2307.13865v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Emre_T/0/1/0/all/0/1">Taha Emre</a>, <a href="http://arxiv.org/find/cs/1/au:+Oghbaie_M/0/1/0/all/0/1">Marzieh Oghbaie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarty_A/0/1/0/all/0/1">Arunava Chakravarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivail_A/0/1/0/all/0/1">Antoine Rivail</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedl_S/0/1/0/all/0/1">Sophie Riedl</a>, <a href="http://arxiv.org/find/cs/1/au:+Mai_J/0/1/0/all/0/1">Julia Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholl_H/0/1/0/all/0/1">Hendrik P.N. Scholl</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivaprasad_S/0/1/0/all/0/1">Sobha Sivaprasad</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotery_A/0/1/0/all/0/1">Andrew Lotery</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_Erfurth_U/0/1/0/all/0/1">Ursula Schmidt-Erfurth</a>, <a href="http://arxiv.org/find/cs/1/au:+Bogunovic_H/0/1/0/all/0/1">Hrvoje Bogunovi&#x107;</a></p>
<p>In the field of medical imaging, 3D deep learning models play a crucial role
in building powerful predictive models of disease progression. However, the
size of these models presents significant challenges, both in terms of
computational resources and data requirements. Moreover, achieving high-quality
pretraining of 3D models proves to be even more challenging. To address these
issues, hybrid 2.5D approaches provide an effective solution for utilizing 3D
volumetric data efficiently using 2D models. Combining 2D and 3D techniques
offers a promising avenue for optimizing performance while minimizing memory
requirements. In this paper, we explore 2.5D architectures based on a
combination of convolutional neural networks (CNNs), long short-term memory
(LSTM), and Transformers. In addition, leveraging the benefits of recent
non-contrastive pretraining approaches in 2D, we enhanced the performance and
data efficiency of 2.5D techniques even further. We demonstrate the
effectiveness of architectures and associated pretraining on a task of
predicting progression to wet age-related macular degeneration (AMD) within a
six-month period on two large longitudinal OCT datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13868">Learning sources of variability from high-dimensional observational studies. (arXiv:2307.13868v1 [stat.ME])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Bridgeford_E/0/1/0/all/0/1">Eric W. Bridgeford</a>, <a href="http://arxiv.org/find/stat/1/au:+Chung_J/0/1/0/all/0/1">Jaewon Chung</a>, <a href="http://arxiv.org/find/stat/1/au:+Gilbert_B/0/1/0/all/0/1">Brian Gilbert</a>, <a href="http://arxiv.org/find/stat/1/au:+Panda_S/0/1/0/all/0/1">Sambit Panda</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_A/0/1/0/all/0/1">Adam Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1">Cencheng Shen</a>, <a href="http://arxiv.org/find/stat/1/au:+Badea_A/0/1/0/all/0/1">Alexandra Badea</a>, <a href="http://arxiv.org/find/stat/1/au:+Caffo_B/0/1/0/all/0/1">Brian Caffo</a>, <a href="http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1">Joshua T. Vogelstein</a></p>
<p>Causal inference studies whether the presence of a variable influences an
observed outcome. As measured by quantities such as the "average treatment
effect," this paradigm is employed across numerous biological fields, from
vaccine and drug development to policy interventions. Unfortunately, the
majority of these methods are often limited to univariate outcomes. Our work
generalizes causal estimands to outcomes with any number of dimensions or any
measurable space, and formulates traditional causal estimands for nominal
variables as causal discrepancy tests. We propose a simple technique for
adjusting universally consistent conditional independence tests and prove that
these tests are universally consistent causal discrepancy tests. Numerical
experiments illustrate that our method, Causal CDcorr, leads to improvements in
both finite sample validity and power when compared to existing strategies. Our
methods are all open source and available at github.com/ebridge2/cdcorr.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13869">Good Lattice Training: Physics-Informed Neural Networks Accelerated by Number Theory. (arXiv:2307.13869v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Matsubara_T/0/1/0/all/0/1">Takashi Matsubara</a>, <a href="http://arxiv.org/find/cs/1/au:+Yaguchi_T/0/1/0/all/0/1">Takaharu Yaguchi</a></p>
<p>Physics-informed neural networks (PINNs) offer a novel and efficient approach
to solving partial differential equations (PDEs). Their success lies in the
physics-informed loss, which trains a neural network to satisfy a given PDE at
specific points and to approximate the solution. However, the solutions to PDEs
are inherently infinite-dimensional, and the distance between the output and
the solution is defined by an integral over the domain. Therefore, the
physics-informed loss only provides a finite approximation, and selecting
appropriate collocation points becomes crucial to suppress the discretization
errors, although this aspect has often been overlooked. In this paper, we
propose a new technique called good lattice training (GLT) for PINNs, inspired
by number theoretic methods for numerical analysis. GLT offers a set of
collocation points that are effective even with a small number of points and
for multi-dimensional spaces. Our experiments demonstrate that GLT requires
2--20 times fewer collocation points (resulting in lower computational cost)
than uniformly random sampling or Latin hypercube sampling, while achieving
competitive performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13883">ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis. (arXiv:2307.13883v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1">Kensen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Joey Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1">Manzil Zaheer</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1">Pengcheng Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutton_C/0/1/0/all/0/1">Charles Sutton</a></p>
<p>When writing programs, people have the ability to tackle a new complex task
by decomposing it into smaller and more familiar subtasks. While it is
difficult to measure whether neural program synthesis methods have similar
capabilities, we can measure whether they compositionally generalize, that is,
whether a model that has been trained on the simpler subtasks is subsequently
able to solve more complex tasks. In this paper, we characterize several
different forms of compositional generalization that are desirable in program
synthesis, forming a meta-benchmark which we use to create generalization tasks
for two popular datasets, RobustFill and DeepCoder. We then propose ExeDec, a
novel decomposition-based synthesis strategy that predicts execution subgoals
to solve problems step-by-step informed by program execution at each step.
ExeDec has better synthesis performance and greatly improved compositional
generalization ability compared to baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13885">Efficient Estimation of the Local Robustness of Machine Learning Models. (arXiv:2307.13885v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1">Tessa Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivas_S/0/1/0/all/0/1">Suraj Srinivas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1">Himabindu Lakkaraju</a></p>
<p>Machine learning models often need to be robust to noisy input data. The
effect of real-world noise (which is often random) on model predictions is
captured by a model's local robustness, i.e., the consistency of model
predictions in a local region around an input. However, the na\"ive approach to
computing local robustness based on Monte-Carlo sampling is statistically
inefficient, leading to prohibitive computational costs for large-scale
applications. In this work, we develop the first analytical estimators to
efficiently compute local robustness of multi-class discriminative models using
local linear function approximation and the multivariate Normal CDF. Through
the derivation of these estimators, we show how local robustness is connected
to concepts such as randomized smoothing and softmax probability. We also
confirm empirically that these estimators accurately and efficiently compute
the local robustness of standard deep learning models. In addition, we
demonstrate these estimators' usefulness for various tasks involving local
robustness, such as measuring robustness bias and identifying examples that are
vulnerable to noise perturbation in a dataset. By developing these analytical
estimators, this work not only advances conceptual understanding of local
robustness, but also makes its computation practical, enabling the use of local
robustness in critical downstream applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13899">Regularizing Neural Networks with Meta-Learning Generative Models. (arXiv:2307.13899v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1">Shin&#x27;ya Yamaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chijiwa_D/0/1/0/all/0/1">Daiki Chijiwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1">Sekitoshi Kanai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumagai_A/0/1/0/all/0/1">Atsutoshi Kumagai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1">Hisashi Kashima</a></p>
<p>This paper investigates methods for improving generative data augmentation
for deep learning. Generative data augmentation leverages the synthetic samples
produced by generative models as an additional dataset for classification with
small dataset settings. A key challenge of generative data augmentation is that
the synthetic data contain uninformative samples that degrade accuracy. This is
because the synthetic samples do not perfectly represent class categories in
real data and uniform sampling does not necessarily provide useful samples for
tasks. In this paper, we present a novel strategy for generative data
augmentation called meta generative regularization (MGR). To avoid the
degradation of generative data augmentation, MGR utilizes synthetic samples in
the regularization term for feature extractors instead of in the loss function,
e.g., cross-entropy. These synthetic samples are dynamically determined to
minimize the validation losses through meta-learning. We observed that MGR can
avoid the performance degradation of na\"ive generative data augmentation and
boost the baselines. Experiments on six datasets showed that MGR is effective
particularly when datasets are smaller and stably outperforms baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13903">Corruption-Robust Lipschitz Contextual Search. (arXiv:2307.13903v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1">Shiliang Zuo</a></p>
<p>I study the problem of learning a Lipschitz function with corrupted binary
signals. The learner tries to learn a Lipschitz function $f$ that the adversary
chooses. In each round, the adversary selects a context vector $x_t$ in the
input space, and the learner makes a guess to the true function value $f(x_t)$
and receives a binary signal indicating whether the guess was high or low. In a
total of $C$ rounds, the signal may be corrupted, though the value of $C$ is
unknown to the learner. The learner's goal is to incur a small cumulative loss.
I present a natural yet powerful technique sanity check, which proves useful in
designing corruption-robust algorithms. I design algorithms which (treating the
Lipschitz parameter $L$ as constant): for the symmetric loss, the learner
achieves regret $O(C\log T)$ with $d = 1$ and $O_d(C\log T + T^{(d-1)/d})$ with
$d &gt; 1$; for the pricing loss the learner achieves regret $\widetilde{O}
(T^{d/(d+1)} + C\cdot T^{1/(d+1)})$.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13907">Robustness Verification of Deep Neural Networks using Star-Based Reachability Analysis with Variable-Length Time Series Input. (arXiv:2307.13907v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pal_N/0/1/0/all/0/1">Neelanjana Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_D/0/1/0/all/0/1">Diego Manzanas Lopez</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_T/0/1/0/all/0/1">Taylor T Johnson</a></p>
<p>Data-driven, neural network (NN) based anomaly detection and predictive
maintenance are emerging research areas. NN-based analytics of time-series data
offer valuable insights into past behaviors and estimates of critical
parameters like remaining useful life (RUL) of equipment and state-of-charge
(SOC) of batteries. However, input time series data can be exposed to
intentional or unintentional noise when passing through sensors, necessitating
robust validation and verification of these NNs. This paper presents a case
study of the robustness verification approach for time series regression NNs
(TSRegNN) using set-based formal methods. It focuses on utilizing
variable-length input data to streamline input manipulation and enhance network
architecture generalizability. The method is applied to two data sets in the
Prognostics and Health Management (PHM) application areas: (1) SOC estimation
of a Lithium-ion battery and (2) RUL estimation of a turbine engine. The NNs'
robustness is checked using star-based reachability analysis, and several
performance measures evaluate the effect of bounded perturbations in the input
on network outputs, i.e., future outcomes. Overall, the paper offers a
comprehensive case study for validating and verifying NN-based analytics of
time-series data in real-world applications, emphasizing the importance of
robustness testing for accurate and reliable predictions, especially
considering the impact of noise on future outcomes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13909">Graph Neural Networks-based Hybrid Framework For Predicting Particle Crushing Strength. (arXiv:2307.13909v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1">Tongya Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Q/0/1/0/all/0/1">Qingzheng Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wenjie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zunlei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingli Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chun Chen</a></p>
<p>Graph Neural Networks have emerged as an effective machine learning tool for
multi-disciplinary tasks such as pharmaceutical molecule classification and
chemical reaction prediction, because they can model non-euclidean
relationships between different entities. Particle crushing, as a significant
field of civil engineering, describes the breakage of granular materials caused
by the breakage of particle fragment bonds under the modeling of numerical
simulations, which motivates us to characterize the mechanical behaviors of
particle crushing through the connectivity of particle fragments with Graph
Neural Networks (GNNs). However, there lacks an open-source large-scale
particle crushing dataset for research due to the expensive costs of laboratory
tests or numerical simulations. Therefore, we firstly generate a dataset with
45,000 numerical simulations and 900 particle types to facilitate the research
progress of machine learning for particle crushing. Secondly, we devise a
hybrid framework based on GNNs to predict particle crushing strength in a
particle fragment view with the advances of state of the art GNNs. Finally, we
compare our hybrid framework against traditional machine learning methods and
the plain MLP to verify its effectiveness. The usefulness of different features
is further discussed through the gradient attribution explanation w.r.t the
predictions. Our data and code are released at
https://github.com/doujiang-zheng/GNN-For-Particle-Crushing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13916">Online learning in bandits with predicted context. (arXiv:2307.13916v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Guo_Y/0/1/0/all/0/1">Yongyi Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Murphy_S/0/1/0/all/0/1">Susan Murphy</a></p>
<p>We consider the contextual bandit problem where at each time, the agent only
has access to a noisy version of the context and the error variance (or an
estimator of this variance). This setting is motivated by a wide range of
applications where the true context for decision-making is unobserved, and only
a prediction of the context by a potentially complex machine learning algorithm
is available. When the context error is non-diminishing, classical bandit
algorithms fail to achieve sublinear regret. We propose the first online
algorithm in this setting with sublinear regret compared to the appropriate
benchmark. The key idea is to extend the measurement error model in classical
statistics to the online decision-making setting, which is nontrivial due to
the policy being dependent on the noisy context observations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13917">BayesDAG: Gradient-Based Posterior Sampling for Causal Discovery. (arXiv:2307.13917v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Annadani_Y/0/1/0/all/0/1">Yashas Annadani</a>, <a href="http://arxiv.org/find/cs/1/au:+Pawlowski_N/0/1/0/all/0/1">Nick Pawlowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Jennings_J/0/1/0/all/0/1">Joel Jennings</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Cheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_W/0/1/0/all/0/1">Wenbo Gong</a></p>
<p>Bayesian causal discovery aims to infer the posterior distribution over
causal models from observed data, quantifying epistemic uncertainty and
benefiting downstream tasks. However, computational challenges arise due to
joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and
nonlinear functions. Despite recent progress towards efficient posterior
inference over DAGs, existing methods are either limited to variational
inference on node permutation matrices for linear causal models, leading to
compromised inference accuracy, or continuous relaxation of adjacency matrices
constrained by a DAG regularizer, which cannot ensure resulting graphs are
DAGs. In this work, we introduce a scalable Bayesian causal discovery framework
based on stochastic gradient Markov Chain Monte Carlo (SG-MCMC) that overcomes
these limitations. Our approach directly samples DAGs from the posterior
without requiring any DAG regularization, simultaneously draws function
parameter samples and is applicable to both linear and nonlinear causal models.
To enable our approach, we derive a novel equivalence to the permutation-based
DAG learning, which opens up possibilities of using any relaxed gradient
estimator defined over permutations. To our knowledge, this is the first
framework applying gradient-based MCMC sampling for causal discovery. Empirical
evaluations on synthetic and real-world datasets demonstrate our approach's
effectiveness compared to state-of-the-art baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13918">Simulation-based Inference for Cardiovascular Models. (arXiv:2307.13918v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Wehenkel_A/0/1/0/all/0/1">Antoine Wehenkel</a>, <a href="http://arxiv.org/find/stat/1/au:+Behrmann_J/0/1/0/all/0/1">Jens Behrmann</a>, <a href="http://arxiv.org/find/stat/1/au:+Miller_A/0/1/0/all/0/1">Andrew C. Miller</a>, <a href="http://arxiv.org/find/stat/1/au:+Sapiro_G/0/1/0/all/0/1">Guillermo Sapiro</a>, <a href="http://arxiv.org/find/stat/1/au:+Sener_O/0/1/0/all/0/1">Ozan Sener</a>, <a href="http://arxiv.org/find/stat/1/au:+Cuturi_M/0/1/0/all/0/1">Marco Cuturi</a>, <a href="http://arxiv.org/find/stat/1/au:+Jacobsen_J/0/1/0/all/0/1">J&#xf6;rn-Henrik Jacobsen</a></p>
<p>Over the past decades, hemodynamics simulators have steadily evolved and have
become tools of choice for studying cardiovascular systems in-silico. While
such tools are routinely used to simulate whole-body hemodynamics from
physiological parameters, solving the corresponding inverse problem of mapping
waveforms back to plausible physiological parameters remains both promising and
challenging. Motivated by advances in simulation-based inference (SBI), we cast
this inverse problem as statistical inference. In contrast to alternative
approaches, SBI provides \textit{posterior distributions} for the parameters of
interest, providing a \textit{multi-dimensional} representation of uncertainty
for \textit{individual} measurements. We showcase this ability by performing an
in-silico uncertainty analysis of five biomarkers of clinical interest
comparing several measurement modalities. Beyond the corroboration of known
facts, such as the feasibility of estimating heart rate, our study highlights
the potential of estimating new biomarkers from standard-of-care measurements.
SBI reveals practically relevant findings that cannot be captured by standard
sensitivity analyses, such as the existence of sub-populations for which
parameter estimation exhibits distinct uncertainty regimes. Finally, we study
the gap between in-vivo and in-silico with the MIMIC-III waveform database and
critically discuss how cardiovascular simulations can inform real-world data
analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13924">trajdata: A Unified Interface to Multiple Human Trajectory Datasets. (arXiv:2307.13924v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ivanovic_B/0/1/0/all/0/1">Boris Ivanovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1">Guanyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilitschenski_I/0/1/0/all/0/1">Igor Gilitschenski</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1">Marco Pavone</a></p>
<p>The field of trajectory forecasting has grown significantly in recent years,
partially owing to the release of numerous large-scale, real-world human
trajectory datasets for autonomous vehicles (AVs) and pedestrian motion
tracking. While such datasets have been a boon for the community, they each use
custom and unique data formats and APIs, making it cumbersome for researchers
to train and evaluate methods across multiple datasets. To remedy this, we
present trajdata: a unified interface to multiple human trajectory datasets. At
its core, trajdata provides a simple, uniform, and efficient representation and
API for trajectory and map data. As a demonstration of its capabilities, in
this work we conduct a comprehensive empirical evaluation of existing
trajectory datasets, providing users with a rich understanding of the data
underpinning much of current pedestrian and AV motion forecasting research, and
proposing suggestions for future datasets from these insights. trajdata is
permissively licensed (Apache 2.0) and can be accessed online at
https://github.com/NVlabs/trajdata
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13938">Improving Semi-Supervised Semantic Segmentation with Dual-Level Siamese Structure Network. (arXiv:2307.13938v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tain_Z/0/1/0/all/0/1">Zhibo Tain</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaolin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_K/0/1/0/all/0/1">Kun Zhan</a></p>
<p>Semi-supervised semantic segmentation (SSS) is an important task that
utilizes both labeled and unlabeled data to reduce expenses on labeling
training examples. However, the effectiveness of SSS algorithms is limited by
the difficulty of fully exploiting the potential of unlabeled data. To address
this, we propose a dual-level Siamese structure network (DSSN) for pixel-wise
contrastive learning. By aligning positive pairs with a pixel-wise contrastive
loss using strong augmented views in both low-level image space and high-level
feature space, the proposed DSSN is designed to maximize the utilization of
available unlabeled data. Additionally, we introduce a novel class-aware
pseudo-label selection strategy for weak-to-strong supervision, which addresses
the limitations of most existing methods that do not perform selection or apply
a predefined threshold for all classes. Specifically, our strategy selects the
top high-confidence prediction of the weak view for each class to generate
pseudo labels that supervise the strong augmented views. This strategy is
capable of taking into account the class imbalance and improving the
performance of long-tailed classes. Our proposed method achieves
state-of-the-art results on two datasets, PASCAL VOC 2012 and Cityscapes,
outperforming other SSS algorithms by a significant margin.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13943">Topology-aware Robust Optimization for Out-of-distribution Generalization. (arXiv:2307.13943v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qiao_F/0/1/0/all/0/1">Fengchun Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xi Peng</a></p>
<p>Out-of-distribution (OOD) generalization is a challenging machine learning
problem yet highly desirable in many high-stake applications. Existing methods
suffer from overly pessimistic modeling with low generalization confidence. As
generalizing to arbitrary test distributions is impossible, we hypothesize that
further structure on the topology of distributions is crucial in developing
strong OOD resilience. To this end, we propose topology-aware robust
optimization (TRO) that seamlessly integrates distributional topology in a
principled optimization framework. More specifically, TRO solves two
optimization objectives: (1) Topology Learning which explores data manifold to
uncover the distributional topology; (2) Learning on Topology which exploits
the topology to constrain robust optimization for tightly-bounded
generalization risks. We theoretically demonstrate the effectiveness of our
approach and empirically show that it significantly outperforms the state of
the arts in a wide range of tasks including classification, regression, and
semantic segmentation. Moreover, we empirically find the data-driven
distributional topology is consistent with domain knowledge, enhancing the
explainability of our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13944">Entropy Neural Estimation for Graph Contrastive Learning. (arXiv:2307.13944v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yixuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaolin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_K/0/1/0/all/0/1">Kun Zhan</a></p>
<p>Contrastive learning on graphs aims at extracting distinguishable high-level
representations of nodes. In this paper, we theoretically illustrate that the
entropy of a dataset can be approximated by maximizing the lower bound of the
mutual information across different views of a graph, \ie, entropy is estimated
by a neural network. Based on this finding, we propose a simple yet effective
subset sampling strategy to contrast pairwise representations between views of
a dataset. In particular, we randomly sample nodes and edges from a given graph
to build the input subset for a view. Two views are fed into a parameter-shared
Siamese network to extract the high-dimensional embeddings and estimate the
information entropy of the entire graph. For the learning process, we propose
to optimize the network using two objectives, simultaneously. Concretely, the
input of the contrastive loss function consists of positive and negative pairs.
Our selection strategy of pairs is different from previous works and we present
a novel strategy to enhance the representation ability of the graph encoder by
selecting nodes based on cross-view similarities. We enrich the diversity of
the positive and negative pairs by selecting highly similar samples and totally
different data with the guidance of cross-view similarity scores, respectively.
We also introduce a cross-view consistency constraint on the representations
generated from the different views. This objective guarantees the learned
representations are consistent across views from the perspective of the entire
graph. We conduct extensive experiments on seven graph benchmarks, and the
proposed approach achieves competitive performance compared to the current
state-of-the-art methods. The source code will be publicly released once this
paper is accepted.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13962">Understanding Deep Neural Networks via Linear Separability of Hidden Layers. (arXiv:2307.13962v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wensheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lixue Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a></p>
<p>In this paper, we measure the linear separability of hidden layer outputs to
study the characteristics of deep neural networks. In particular, we first
propose Minkowski difference based linear separability measures (MD-LSMs) to
evaluate the linear separability degree of two points sets. Then, we
demonstrate that there is a synchronicity between the linear separability
degree of hidden layer outputs and the network training performance, i.e., if
the updated weights can enhance the linear separability degree of hidden layer
outputs, the updated network will achieve a better training performance, and
vice versa. Moreover, we study the effect of activation function and network
size (including width and depth) on the linear separability of hidden layers.
Finally, we conduct the numerical experiments to validate our findings on some
popular deep networks including multilayer perceptron (MLP), convolutional
neural network (CNN), deep belief network (DBN), ResNet, VGGNet, AlexNet,
vision transformer (ViT) and GoogLeNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13978">Controlling the Latent Space of GANs through Reinforcement Learning: A Case Study on Task-based Image-to-Image Translation. (arXiv:2307.13978v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abbasian_M/0/1/0/all/0/1">Mahyar Abbasian</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajabzadeh_T/0/1/0/all/0/1">Taha Rajabzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Moradipari_A/0/1/0/all/0/1">Ahmadreza Moradipari</a>, <a href="http://arxiv.org/find/cs/1/au:+Aqajari_S/0/1/0/all/0/1">Seyed Amir Hossein Aqajari</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Hongsheng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmani_A/0/1/0/all/0/1">Amir Rahmani</a></p>
<p>Generative Adversarial Networks (GAN) have emerged as a formidable AI tool to
generate realistic outputs based on training datasets. However, the challenge
of exerting control over the generation process of GANs remains a significant
hurdle. In this paper, we propose a novel methodology to address this issue by
integrating a reinforcement learning (RL) agent with a latent-space GAN
(l-GAN), thereby facilitating the generation of desired outputs. More
specifically, we have developed an actor-critic RL agent with a meticulously
designed reward policy, enabling it to acquire proficiency in navigating the
latent space of the l-GAN and generating outputs based on specified tasks. To
substantiate the efficacy of our approach, we have conducted a series of
experiments employing the MNIST dataset, including arithmetic addition as an
illustrative task. The outcomes of these experiments serve to validate our
methodology. Our pioneering integration of an RL agent with a GAN model
represents a novel advancement, holding great potential for enhancing
generative networks in the future.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13989">This is not correct! Negation-aware Evaluation of Language Generation Systems. (arXiv:2307.13989v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Anschutz_M/0/1/0/all/0/1">Miriam Ansch&#xfc;tz</a>, <a href="http://arxiv.org/find/cs/1/au:+Lozano_D/0/1/0/all/0/1">Diego Miguel Lozano</a>, <a href="http://arxiv.org/find/cs/1/au:+Groh_G/0/1/0/all/0/1">Georg Groh</a></p>
<p>Large language models underestimate the impact of negations on how much they
change the meaning of a sentence. Therefore, learned evaluation metrics based
on these models are insensitive to negations. In this paper, we propose
NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that,
we designed a rule-based sentence negation tool and used it to create the
CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a
sentence transformer and an evaluation metric to improve their negation
sensitivity. Evaluating these models on existing benchmarks shows that our
fine-tuned models outperform existing metrics on the negated sentences by far
while preserving their base models' performances on other perturbations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13991">METAVerse: Meta-Learning Traversability Cost Map for Off-Road Navigation. (arXiv:2307.13991v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1">Junwon Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Taekyung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1">Seongyong Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwak_K/0/1/0/all/0/1">Kiho Kwak</a></p>
<p>Autonomous navigation in off-road conditions requires an accurate estimation
of terrain traversability. However, traversability estimation in unstructured
environments is subject to high uncertainty due to the variability of numerous
factors that influence vehicle-terrain interaction. Consequently, it is
challenging to obtain a generalizable model that can accurately predict
traversability in a variety of environments. This paper presents METAVerse, a
meta-learning framework for learning a global model that accurately and
reliably predicts terrain traversability across diverse environments. We train
the traversability prediction network to generate a dense and continuous-valued
cost map from a sparse LiDAR point cloud, leveraging vehicle-terrain
interaction feedback in a self-supervised manner. Meta-learning is utilized to
train a global model with driving data collected from multiple environments,
effectively minimizing estimation uncertainty. During deployment, online
adaptation is performed to rapidly adapt the network to the local environment
by exploiting recent interaction experiences. To conduct a comprehensive
evaluation, we collect driving data from various terrains and demonstrate that
our method can obtain a global model that minimizes uncertainty. Moreover, by
integrating our model with a model predictive controller, we demonstrate that
the reduced uncertainty results in safe and stable navigation in unstructured
and unknown terrains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13994">BovineTalk: Machine Learning for Vocalization Analysis of Dairy Cattle under Negative Affective States. (arXiv:2307.13994v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gavojdian_D/0/1/0/all/0/1">Dinu Gavojdian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazebnik_T/0/1/0/all/0/1">Teddy Lazebnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Mincu_M/0/1/0/all/0/1">Madalina Mincu</a>, <a href="http://arxiv.org/find/cs/1/au:+Oren_A/0/1/0/all/0/1">Ariel Oren</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicolae_I/0/1/0/all/0/1">Ioana Nicolae</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamansky_A/0/1/0/all/0/1">Anna Zamansky</a></p>
<p>There is a critical need to develop and validate non-invasive animal-based
indicators of affective states in livestock species, in order to integrate them
into on-farm assessment protocols, potentially via the use of precision
livestock farming (PLF) tools. One such promising approach is the use of vocal
indicators. The acoustic structure of vocalizations and their functions were
extensively studied in important livestock species, such as pigs, horses,
poultry and goats, yet cattle remain understudied in this context to date. Cows
were shown to produce two types vocalizations: low-frequency calls (LF),
produced with the mouth closed, or partially closed, for close distance
contacts and open mouth emitted high-frequency calls (HF), produced for long
distance communication, with the latter considered to be largely associated
with negative affective states. Moreover, cattle vocalizations were shown to
contain information on individuality across a wide range of contexts, both
negative and positive. Nowadays, dairy cows are facing a series of negative
challenges and stressors in a typical production cycle, making vocalizations
during negative affective states of special interest for research. One
contribution of this study is providing the largest to date pre-processed
(clean from noises) dataset of lactating adult multiparous dairy cows during
negative affective states induced by visual isolation challenges. Here we
present two computational frameworks - deep learning based and explainable
machine learning based, to classify high and low-frequency cattle calls, and
individual cow voice recognition. Our models in these two frameworks reached
87.2% and 89.4% accuracy for LF and HF classification, with 68.9% and 72.5%
accuracy rates for the cow individual identification, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13995">Take Your Pick: Enabling Effective Personalized Federated Learning within Low-dimensional Feature Space. (arXiv:2307.13995v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1">Guogang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuefeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Shaojie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_J/0/1/0/all/0/1">Jianwei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xinghao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jiaxing Shen</a></p>
<p>Personalized federated learning (PFL) is a popular framework that allows
clients to have different models to address application scenarios where
clients' data are in different domains. The typical model of a client in PFL
features a global encoder trained by all clients to extract universal features
from the raw data and personalized layers (e.g., a classifier) trained using
the client's local data. Nonetheless, due to the differences between the data
distributions of different clients (aka, domain gaps), the universal features
produced by the global encoder largely encompass numerous components irrelevant
to a certain client's local task. Some recent PFL methods address the above
problem by personalizing specific parameters within the encoder. However, these
methods encounter substantial challenges attributed to the high dimensionality
and non-linearity of neural network parameter space. In contrast, the feature
space exhibits a lower dimensionality, providing greater intuitiveness and
interpretability as compared to the parameter space. To this end, we propose a
novel PFL framework named FedPick. FedPick achieves PFL in the low-dimensional
feature space by selecting task-relevant features adaptively for each client
from the features generated by the global encoder based on its local data
distribution. It presents a more accessible and interpretable implementation of
PFL compared to those methods working in the parameter space. Extensive
experimental results show that FedPick could effectively select task-relevant
features for each client and improve model performance in cross-domain FL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13996">Fast algorithms for k-submodular maximization subject to a matroid constraint. (arXiv:2307.13996v1 [cs.DS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Niu_S/0/1/0/all/0/1">Shuxian Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Min Li</a></p>
<p>In this paper, we apply a Threshold-Decreasing Algorithm to maximize
$k$-submodular functions under a matroid constraint, which reduces the query
complexity of the algorithm compared to the greedy algorithm with little loss
in approximation ratio. We give a $(\frac{1}{2} - \epsilon)$-approximation
algorithm for monotone $k$-submodular function maximization, and a
$(\frac{1}{3} - \epsilon)$-approximation algorithm for non-monotone case, with
complexity $O(\frac{n(k\cdot EO + IO)}{\epsilon} \log \frac{r}{\epsilon})$,
where $r$ denotes the rank of the matroid, and $IO, EO$ denote the number of
oracles to evaluate whether a subset is an independent set and to compute the
function value of $f$, respectively. Since the constraint of total size can be
looked as a special matroid, called uniform matroid, then we present the fast
algorithm for maximizing $k$-submodular functions subject to a total size
constraint as corollaries. corollaries.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14012">MCMC-Correction of Score-Based Diffusion Models for Model Composition. (arXiv:2307.14012v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Sjoberg_A/0/1/0/all/0/1">Anders Sj&#xf6;berg</a>, <a href="http://arxiv.org/find/stat/1/au:+Lindqvist_J/0/1/0/all/0/1">Jakob Lindqvist</a>, <a href="http://arxiv.org/find/stat/1/au:+Onnheim_M/0/1/0/all/0/1">Magnus &#xd6;nnheim</a>, <a href="http://arxiv.org/find/stat/1/au:+Jirstrand_M/0/1/0/all/0/1">Mats Jirstrand</a>, <a href="http://arxiv.org/find/stat/1/au:+Svensson_L/0/1/0/all/0/1">Lennart Svensson</a></p>
<p>Diffusion models can be parameterised in terms of either a score or an energy
function. The energy parameterisation has better theoretical properties, mainly
that it enables an extended sampling procedure with a Metropolis--Hastings
correction step, based on the change in total energy in the proposed samples.
However, it seems to yield slightly worse performance, and more importantly,
due to the widespread popularity of score-based diffusion, there are limited
availability of off-the-shelf pre-trained energy-based ones. This limitation
undermines the purpose of model composition, which aims to combine pre-trained
models to sample from new distributions. Our proposal, however, suggests
retaining the score parameterization and instead computing the energy-based
acceptance probability through line integration of the score function. This
allows us to re-use existing diffusion models and still combine the reverse
process with various Markov-Chain Monte Carlo (MCMC) methods. We evaluate our
method on a 2D experiment and find that it achieve similar or arguably better
performance than the energy parameterisation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14023">Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?. (arXiv:2307.14023v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kajitsuka_T/0/1/0/all/0/1">Tokio Kajitsuka</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1">Issei Sato</a></p>
<p>Existing analyses of the expressive capacity of Transformer models have
required excessively deep layers for data memorization, leading to a
discrepancy with the Transformers actually used in practice. This is primarily
due to the interpretation of the softmax function as an approximation of the
hardmax function. By clarifying the connection between the softmax function and
the Boltzmann operator, we prove that a single layer of self-attention with
low-rank weight matrices possesses the capability to perfectly capture the
context of an entire input sequence. As a consequence, we show that
single-layer Transformer has a memorization capacity for finite samples, and
that Transformers consisting of one self-attention layer with two feed-forward
neural networks are universal approximators for continuous functions on a
compact domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14025">Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification. (arXiv:2307.14025v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kazeminia_S/0/1/0/all/0/1">Salome Kazeminia</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadafi_A/0/1/0/all/0/1">Ario Sadafi</a>, <a href="http://arxiv.org/find/cs/1/au:+Makhro_A/0/1/0/all/0/1">Asya Makhro</a>, <a href="http://arxiv.org/find/cs/1/au:+Bogdanova_A/0/1/0/all/0/1">Anna Bogdanova</a>, <a href="http://arxiv.org/find/cs/1/au:+Marr_C/0/1/0/all/0/1">Carsten Marr</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1">Bastian Rieck</a></p>
<p>Diagnosing rare anemia disorders using microscopic images is challenging for
skilled specialists and machine-learning methods alike. Due to thousands of
disease-relevant cells in a single blood sample, this constitutes a complex
multiple-instance learning (MIL) problem. While the spatial neighborhood of red
blood cells is not meaningful per se, the topology, i.e., the geometry of blood
samples as a whole, contains informative features to remedy typical MIL issues,
such as vanishing gradients and overfitting when training on limited data. We
thus develop a topology-based approach that extracts multi-scale topological
features from bags of single red blood cell images. The topological features
are used to regularize the model, enforcing the preservation of characteristic
topological properties of the data. Applied to a dataset of 71 patients
suffering from rare anemia disorders with 521 microscopic images of red blood
cells, our experiments show that topological regularization is an effective
method that leads to more than 3% performance improvements for the automated
classification of rare anemia disorders based on single-cell images. This is
the first approach that uses topological properties for regularizing the MIL
process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14066">Pre-Training with Diffusion models for Dental Radiography segmentation. (arXiv:2307.14066v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rousseau_J/0/1/0/all/0/1">J&#xe9;r&#xe9;my Rousseau</a>, <a href="http://arxiv.org/find/cs/1/au:+Alaka_C/0/1/0/all/0/1">Christian Alaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Covili_E/0/1/0/all/0/1">Emma Covili</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayard_H/0/1/0/all/0/1">Hippolyte Mayard</a>, <a href="http://arxiv.org/find/cs/1/au:+Misrachi_L/0/1/0/all/0/1">Laura Misrachi</a>, <a href="http://arxiv.org/find/cs/1/au:+Au_W/0/1/0/all/0/1">Willy Au</a></p>
<p>Medical radiography segmentation, and specifically dental radiography, is
highly limited by the cost of labeling which requires specific expertise and
labor-intensive annotations. In this work, we propose a straightforward
pre-training method for semantic segmentation leveraging Denoising Diffusion
Probabilistic Models (DDPM), which have shown impressive results for generative
modeling. Our straightforward approach achieves remarkable performance in terms
of label efficiency and does not require architectural modifications between
pre-training and downstream tasks. We propose to first pre-train a Unet by
exploiting the DDPM training objective, and then fine-tune the resulting model
on a segmentation task. Our experimental results on the segmentation of dental
radiographs demonstrate that the proposed method is competitive with
state-of-the-art pre-training methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14067">Machine Learning Applications In Healthcare: The State Of Knowledge and Future Directions. (arXiv:2307.14067v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roy_M/0/1/0/all/0/1">Mrinmoy Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Minar_S/0/1/0/all/0/1">Sarwar J. Minar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhar_P/0/1/0/all/0/1">Porarthi Dhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Faruq_A/0/1/0/all/0/1">A T M Omor Faruq</a></p>
<p>Detection of easily missed hidden patterns with fast processing power makes
machine learning (ML) indispensable to today's healthcare system. Though many
ML applications have already been discovered and many are still under
investigation, only a few have been adopted by current healthcare systems. As a
result, there exists an enormous opportunity in healthcare system for ML but
distributed information, scarcity of properly arranged and easily explainable
documentation in related sector are major impede which are making ML
applications difficult to healthcare professionals. This study aimed to gather
ML applications in different areas of healthcare concisely and more effectively
so that necessary information can be accessed immediately with relevant
references. We divided our study into five major groups: community level work,
risk management/ preventive care, healthcare operation management, remote care,
and early detection. Dividing these groups into subgroups, we provided relevant
references with description in tabular form for quick access. Our objective is
to inform people about ML applicability in healthcare industry, reduce the
knowledge gap of clinicians about the ML applications and motivate healthcare
professionals towards more machine learning based healthcare system.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14068">Dynamic Domain Discrepancy Adjustment for Active Multi-Domain Adaptation. (arXiv:2307.14068v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Long Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhipeng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zening Liu</a></p>
<p>Multi-source unsupervised domain adaptation (MUDA) aims to transfer knowledge
from related source domains to an unlabeled target domain. While recent MUDA
methods have shown promising results, most focus on aligning the overall
feature distributions across source domains, which can lead to negative effects
due to redundant features within each domain. Moreover, there is a significant
performance gap between MUDA and supervised methods. To address these
challenges, we propose a novel approach called Dynamic Domain Discrepancy
Adjustment for Active Multi-Domain Adaptation (D3AAMDA). Firstly, we establish
a multi-source dynamic modulation mechanism during the training process based
on the degree of distribution differences between source and target domains.
This mechanism controls the alignment level of features between each source
domain and the target domain, effectively leveraging the local advantageous
feature information within the source domains. Additionally, we propose a
Multi-source Active Boundary Sample Selection (MABS) strategy, which utilizes a
guided dynamic boundary loss to design an efficient query function for
selecting important samples. This strategy achieves improved generalization to
the target domain with minimal sampling costs. We extensively evaluate our
proposed method on commonly used domain adaptation datasets, comparing it
against existing UDA and ADA methods. The experimental results unequivocally
demonstrate the superiority of our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14085">Actions Speak What You Want: Provably Sample-Efficient Reinforcement Learning of the Quantal Stackelberg Equilibrium from Strategic Feedbacks. (arXiv:2307.14085v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Siyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengdi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuoran Yang</a></p>
<p>We study reinforcement learning (RL) for learning a Quantal Stackelberg
Equilibrium (QSE) in an episodic Markov game with a leader-follower structure.
In specific, at the outset of the game, the leader announces her policy to the
follower and commits to it. The follower observes the leader's policy and, in
turn, adopts a quantal response policy by solving an entropy-regularized policy
optimization problem induced by leader's policy. The goal of the leader is to
find her optimal policy, which yields the optimal expected total return, by
interacting with the follower and learning from data. A key challenge of this
problem is that the leader cannot observe the follower's reward, and needs to
infer the follower's quantal response model from his actions against leader's
policies. We propose sample-efficient algorithms for both the online and
offline settings, in the context of function approximation. Our algorithms are
based on (i) learning the quantal response model via maximum likelihood
estimation and (ii) model-free or model-based RL for solving the leader's
decision making problem, and we show that they achieve sublinear regret upper
bounds. Moreover, we quantify the uncertainty of these estimators and leverage
the uncertainty to implement optimistic and pessimistic algorithms for online
and offline settings. Besides, when specialized to the linear and myopic
setting, our algorithms are also computationally efficient. Our theoretical
analysis features a novel performance-difference lemma which incorporates the
error of quantal response model, which might be of independent interest.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14109">GraphRNN Revisited: An Ablation Study and Extensions for Directed Acyclic Graphs. (arXiv:2307.14109v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Das_T/0/1/0/all/0/1">Taniya Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_M/0/1/0/all/0/1">Mark Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_M/0/1/0/all/0/1">Maya Ravichandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Khatri_N/0/1/0/all/0/1">Nikhil Khatri</a></p>
<p>GraphRNN is a deep learning-based architecture proposed by You et al. for
learning generative models for graphs. We replicate the results of You et al.
using a reproduced implementation of the GraphRNN architecture and evaluate
this against baseline models using new metrics. Through an ablation study, we
find that the BFS traversal suggested by You et al. to collapse representations
of isomorphic graphs contributes significantly to model performance.
Additionally, we extend GraphRNN to generate directed acyclic graphs by
replacing the BFS traversal with a topological sort. We demonstrate that this
method improves significantly over a directed-multiclass variant of GraphRNN on
a real-world dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14134">Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models. (arXiv:2307.14134v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kesgin_H/0/1/0/all/0/1">Himmet Toprak Kesgin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuce_M/0/1/0/all/0/1">Muzaffer Kaan Yuce</a>, <a href="http://arxiv.org/find/cs/1/au:+Amasyali_M/0/1/0/all/0/1">Mehmet Fatih Amasyali</a></p>
<p>This study introduces and evaluates tiny, mini, small, and medium-sized
uncased Turkish BERT models, aiming to bridge the research gap in
less-resourced languages. We trained these models on a diverse dataset
encompassing over 75GB of text from multiple sources and tested them on several
tasks, including mask prediction, sentiment analysis, news classification, and,
zero-shot classification. Despite their smaller size, our models exhibited
robust performance, including zero-shot task, while ensuring computational
efficiency and faster execution times. Our findings provide valuable insights
into the development and application of smaller language models, especially in
the context of the Turkish language.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14138">Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards. (arXiv:2307.14138v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nourani_Koliji_B/0/1/0/all/0/1">Behzad Nourani-Koliji</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilaj_S/0/1/0/all/0/1">Steven Bilaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Balef_A/0/1/0/all/0/1">Amir Rezaei Balef</a>, <a href="http://arxiv.org/find/cs/1/au:+Maghsudi_S/0/1/0/all/0/1">Setareh Maghsudi</a></p>
<p>We study the piecewise stationary combinatorial semi-bandit problem with
causally related rewards. In our nonstationary environment, variations in the
base arms' distributions, causal relationships between rewards, or both, change
the reward generation process. In such an environment, an optimal
decision-maker must follow both sources of change and adapt accordingly. The
problem becomes aggravated in the combinatorial semi-bandit setting, where the
decision-maker only observes the outcome of the selected bundle of arms. The
core of our proposed policy is the Upper Confidence Bound (UCB) algorithm. We
assume the agent relies on an adaptive approach to overcome the challenge. More
specifically, it employs a change-point detector based on the Generalized
Likelihood Ratio (GLR) test. Besides, we introduce the notion of group restart
as a new alternative restarting strategy in the decision making process in
structured environments. Finally, our algorithm integrates a mechanism to trace
the variations of the underlying graph structure, which captures the causal
relationships between the rewards in the bandit setting. Theoretically, we
establish a regret upper bound that reflects the effects of the number of
structural- and distribution changes on the performance. The outcome of our
numerical experiments in real-world scenarios exhibits applicability and
superior performance of our proposal compared to the state-of-the-art
benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14145">Toward Design of Synthetic Active Inference Agents by Mere Mortals. (arXiv:2307.14145v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Vries_B/0/1/0/all/0/1">Bert de Vries</a></p>
<p>The theoretical properties of active inference agents are impressive, but how
do we realize effective agents in working hardware and software on edge
devices? This is an interesting problem because the computational load for
policy exploration explodes exponentially, while the computational resources
are very limited for edge devices. In this paper, we discuss the necessary
features for a software toolbox that supports a competent non-expert engineer
to develop working active inference agents. We introduce a toolbox-in-progress
that aims to accelerate the democratization of active inference agents in a
similar way as TensorFlow propelled applications of deep learning technology.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14151">Learning Disentangled Discrete Representations. (arXiv:2307.14151v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Friede_D/0/1/0/all/0/1">David Friede</a>, <a href="http://arxiv.org/find/cs/1/au:+Reimers_C/0/1/0/all/0/1">Christian Reimers</a>, <a href="http://arxiv.org/find/cs/1/au:+Stuckenschmidt_H/0/1/0/all/0/1">Heiner Stuckenschmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1">Mathias Niepert</a></p>
<p>Recent successes in image generation, model-based reinforcement learning, and
text-to-image generation have demonstrated the empirical advantages of discrete
latent representations, although the reasons behind their benefits remain
unclear. We explore the relationship between discrete latent spaces and
disentangled representations by replacing the standard Gaussian variational
autoencoder (VAE) with a tailored categorical variational autoencoder. We show
that the underlying grid structure of categorical distributions mitigates the
problem of rotational invariance associated with multivariate Gaussian
distributions, acting as an efficient inductive prior for disentangled
representations. We provide both analytical and empirical findings that
demonstrate the advantages of discrete VAEs for learning disentangled
representations. Furthermore, we introduce the first unsupervised model
selection strategy that favors disentangled representations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14185">A comparison of machine learning surrogate models of street-scale flooding in Norfolk, Virginia. (arXiv:2307.14185v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+McSpadden_D/0/1/0/all/0/1">Diana McSpadden</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldenberg_S/0/1/0/all/0/1">Steven Goldenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Binata Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Schram_M/0/1/0/all/0/1">Malachi Schram</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodall_J/0/1/0/all/0/1">Jonathan L. Goodall</a>, <a href="http://arxiv.org/find/cs/1/au:+Richter_H/0/1/0/all/0/1">Heather Richter</a></p>
<p>Low-lying coastal cities, exemplified by Norfolk, Virginia, face the
challenge of street flooding caused by rainfall and tides, which strain
transportation and sewer systems and can lead to property damage. While
high-fidelity, physics-based simulations provide accurate predictions of urban
pluvial flooding, their computational complexity renders them unsuitable for
real-time applications. Using data from Norfolk rainfall events between 2016
and 2018, this study compares the performance of a previous surrogate model
based on a random forest algorithm with two deep learning models: Long
Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU). This investigation
underscores the importance of using a model architecture that supports the
communication of prediction uncertainty and the effective integration of
relevant, multi-modal features.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14193">Efficient Learning of Discrete-Continuous Computation Graphs. (arXiv:2307.14193v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Friede_D/0/1/0/all/0/1">David Friede</a>, <a href="http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1">Mathias Niepert</a></p>
<p>Numerous models for supervised and reinforcement learning benefit from
combinations of discrete and continuous model components. End-to-end learnable
discrete-continuous models are compositional, tend to generalize better, and
are more interpretable. A popular approach to building discrete-continuous
computation graphs is that of integrating discrete probability distributions
into neural networks using stochastic softmax tricks. Prior work has mainly
focused on computation graphs with a single discrete component on each of the
graph's execution paths. We analyze the behavior of more complex stochastic
computations graphs with multiple sequential discrete components. We show that
it is challenging to optimize the parameters of these models, mainly due to
small gradients and local minima. We then propose two new strategies to
overcome these challenges. First, we show that increasing the scale parameter
of the Gumbel noise perturbations during training improves the learning
behavior. Second, we propose dropout residual connections specifically tailored
to stochastic, discrete-continuous computation graphs. With an extensive set of
experiments, we show that we can train complex discrete-continuous models which
one cannot train with standard stochastic softmax tricks. We also show that
complex discrete-stochastic models generalize better than their continuous
counterparts on several benchmark datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14199">Application of Random Forest and Support Vector Machine for Investigation of Pressure Filtration Performance, a Zinc Plant Filter Cake Modeling. (arXiv:2307.14199v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kazemi_M/0/1/0/all/0/1">Masoume Kazemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Moradkhani_D/0/1/0/all/0/1">Davood Moradkhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Alipour_A/0/1/0/all/0/1">Alireza Abbas Alipour</a></p>
<p>The hydrometallurgical method of zinc production involves leaching zinc from
ore and then separating the solid residue from the liquid solution by pressure
filtration. This separation process is very important since the solid residue
contains some moisture that can reduce the amount of zinc recovered. This study
modeled the pressure filtration process through Random Forest (RF) and Support
Vector Machine (SVM). The models take continuous variables (extracted features)
from the lab samples as inputs. Thus, regression models namely Random Forest
Regression (RFR) and Support Vector Regression (SVR) were chosen. A total
dataset was obtained during the pressure filtration process in two conditions:
1) Polypropylene (S1) and 2) Polyester fabrics (S2). To predict the cake
moisture, solids concentration (0.2 and 0.38), temperature (35 and 65
centigrade), pH (2, 3.5, and 5), pressure, cake thickness (14, 20, 26, and 34
mm), air-blow time (2, 10 and 15 min) and filtration time were applied as input
variables. The models' predictive accuracy was evaluated by the coefficient of
determination (R2) parameter. The results revealed that the RFR model is
superior to the SVR model for cake moisture prediction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14208">Online Modeling and Monitoring of Dependent Processes under Resource Constraints. (arXiv:2307.14208v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kosolwattana_T/0/1/0/all/0/1">Tanapol Kosolwattana</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huazheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Ying Lin</a></p>
<p>Monitoring a population of dependent processes under limited resources is
critical for abnormal events detection. A novel online collaborative learning
method is proposed to adaptively allocate the resources for exploitation of
high-risk processes and exploration of dependent dynamics. Efficiency of the
proposed method is proved through theoretical analysis and experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14225">Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences. (arXiv:2307.14225v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sanner_S/0/1/0/all/0/1">Scott Sanner</a>, <a href="http://arxiv.org/find/cs/1/au:+Balog_K/0/1/0/all/0/1">Krisztian Balog</a>, <a href="http://arxiv.org/find/cs/1/au:+Radlinski_F/0/1/0/all/0/1">Filip Radlinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Wedin_B/0/1/0/all/0/1">Ben Wedin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dixon_L/0/1/0/all/0/1">Lucas Dixon</a></p>
<p>Traditional recommender systems leverage users' item preference history to
recommend novel content that users may like. However, modern dialog interfaces
that allow users to express language-based preferences offer a fundamentally
different modality for preference input. Inspired by recent successes of
prompting paradigms for large language models (LLMs), we study their use for
making recommendations from both item-based and language-based preferences in
comparison to state-of-the-art item-based collaborative filtering (CF) methods.
To support this investigation, we collect a new dataset consisting of both
item-based and language-based preferences elicited from users along with their
ratings on a variety of (biased) recommended items and (unbiased) random items.
Among numerous experimental results, we find that LLMs provide competitive
recommendation performance for pure language-based preferences (no item
preferences) in the near cold-start case in comparison to item-based CF
methods, despite having no supervised training for this specific task
(zero-shot) or only a few labels (few-shot). This is particularly promising as
language-based preference representations are more explainable and scrutable
than item-based or vector-based representations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14237">Evolving Multi-Objective Neural Network Controllers for Robot Swarms. (arXiv:2307.14237v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mason_K/0/1/0/all/0/1">Karl Mason</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauert_S/0/1/0/all/0/1">Sabine Hauert</a></p>
<p>Many swarm robotics tasks consist of multiple conflicting objectives. This
research proposes a multi-objective evolutionary neural network approach to
developing controllers for swarms of robots. The swarm robot controllers are
trained in a low-fidelity Python simulator and then tested in a high-fidelity
simulated environment using Webots. Simulations are then conducted to test the
scalability of the evolved multi-objective robot controllers to environments
with a larger number of robots. The results presented demonstrate that the
proposed approach can effectively control each of the robots. The robot swarm
exhibits different behaviours as the weighting for each objective is adjusted.
The results also confirm that multi-objective neural network controllers
evolved in a low-fidelity simulator can be transferred to high-fidelity
simulated environments and that the controllers can scale to environments with
a larger number of robots without further retraining needed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14243">Fluorescent Neuronal Cells v2: Multi-Task, Multi-Format Annotations for Deep Learning in Microscopy. (arXiv:2307.14243v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Clissa_L/0/1/0/all/0/1">Luca Clissa</a>, <a href="http://arxiv.org/find/cs/1/au:+Macaluso_A/0/1/0/all/0/1">Antonio Macaluso</a>, <a href="http://arxiv.org/find/cs/1/au:+Morelli_R/0/1/0/all/0/1">Roberto Morelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Occhinegro_A/0/1/0/all/0/1">Alessandra Occhinegro</a>, <a href="http://arxiv.org/find/cs/1/au:+Piscitiello_E/0/1/0/all/0/1">Emiliana Piscitiello</a>, <a href="http://arxiv.org/find/cs/1/au:+Taddei_L/0/1/0/all/0/1">Ludovico Taddei</a>, <a href="http://arxiv.org/find/cs/1/au:+Luppi_M/0/1/0/all/0/1">Marco Luppi</a>, <a href="http://arxiv.org/find/cs/1/au:+Amici_R/0/1/0/all/0/1">Roberto Amici</a>, <a href="http://arxiv.org/find/cs/1/au:+Cerri_M/0/1/0/all/0/1">Matteo Cerri</a>, <a href="http://arxiv.org/find/cs/1/au:+Hitrec_T/0/1/0/all/0/1">Timna Hitrec</a>, <a href="http://arxiv.org/find/cs/1/au:+Rinaldi_L/0/1/0/all/0/1">Lorenzo Rinaldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zoccoli_A/0/1/0/all/0/1">Antonio Zoccoli</a></p>
<p>Fluorescent Neuronal Cells v2 is a collection of fluorescence microscopy
images and the corresponding ground-truth annotations, designed to foster
innovative research in the domains of Life Sciences and Deep Learning. This
dataset encompasses three image collections in which rodent neuronal cells'
nuclei and cytoplasm are stained with diverse markers to highlight their
anatomical or functional characteristics. Alongside the images, we provide
ground-truth annotations for several learning tasks, including semantic
segmentation, object detection, and counting. The contribution is two-fold.
First, given the variety of annotations and their accessible formats, we
envision our work facilitating methodological advancements in computer vision
approaches for segmentation, detection, feature learning, unsupervised and
self-supervised learning, transfer learning, and related areas. Second, by
enabling extensive exploration and benchmarking, we hope Fluorescent Neuronal
Cells v2 will catalyze breakthroughs in fluorescence microscopy analysis and
promote cutting-edge discoveries in life sciences. The data are available at:
https://amsacta.unibo.it/id/eprint/7347
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14273">Deepfake Image Generation for Improved Brain Tumor Segmentation. (arXiv:2307.14273v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Al_Emaryeen_R/0/1/0/all/0/1">Roa&#x27;a Al-Emaryeen</a>, <a href="http://arxiv.org/find/eess/1/au:+Al_Nahhas_S/0/1/0/all/0/1">Sara Al-Nahhas</a>, <a href="http://arxiv.org/find/eess/1/au:+Himour_F/0/1/0/all/0/1">Fatima Himour</a>, <a href="http://arxiv.org/find/eess/1/au:+Mahafza_W/0/1/0/all/0/1">Waleed Mahafza</a>, <a href="http://arxiv.org/find/eess/1/au:+Al_Kadi_O/0/1/0/all/0/1">Omar Al-Kadi</a></p>
<p>As the world progresses in technology and health, awareness of disease by
revealing asymptomatic signs improves. It is important to detect and treat
tumors in early stage as it can be life-threatening. Computer-aided
technologies are used to overcome lingering limitations facing disease
diagnosis, while brain tumor segmentation remains a difficult process,
especially when multi-modality data is involved. This is mainly attributed to
ineffective training due to lack of data and corresponding labelling. This work
investigates the feasibility of employing deep-fake image generation for
effective brain tumor segmentation. To this end, a Generative Adversarial
Network was used for image-to-image translation for increasing dataset size,
followed by image segmentation using a U-Net-based convolutional neural network
trained with deepfake images. Performance of the proposed approach is compared
with ground truth of four publicly available datasets. Results show improved
performance in terms of image segmentation quality metrics, and could
potentially assist when training with limited data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14283">General Purpose Artificial Intelligence Systems (GPAIS): Properties, Definition, Taxonomy, Open Challenges and Implications. (arXiv:2307.14283v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Triguero_I/0/1/0/all/0/1">Isaac Triguero</a>, <a href="http://arxiv.org/find/cs/1/au:+Molina_D/0/1/0/all/0/1">Daniel Molina</a>, <a href="http://arxiv.org/find/cs/1/au:+Poyatos_J/0/1/0/all/0/1">Javier Poyatos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ser_J/0/1/0/all/0/1">Javier Del Ser</a>, <a href="http://arxiv.org/find/cs/1/au:+Herrera_F/0/1/0/all/0/1">Francisco Herrera</a></p>
<p>Most applications of Artificial Intelligence (AI) are designed for a confined
and specific task. However, there are many scenarios that call for a more
general AI, capable of solving a wide array of tasks without being specifically
designed for them. The term General-Purpose Artificial Intelligence Systems
(GPAIS) has been defined to refer to these AI systems. To date, the possibility
of an Artificial General Intelligence, powerful enough to perform any
intellectual task as if it were human, or even improve it, has remained an
aspiration, fiction, and considered a risk for our society. Whilst we might
still be far from achieving that, GPAIS is a reality and sitting at the
forefront of AI research.
</p>
<p>This work discusses existing definitions for GPAIS and proposes a new
definition that allows for a gradual differentiation among types of GPAIS
according to their properties and limitations. We distinguish between
closed-world and open-world GPAIS, characterising their degree of autonomy and
ability based on several factors such as adaptation to new tasks, competence in
domains not intentionally trained for, ability to learn from few data, or
proactive acknowledgment of their own limitations. We then propose a taxonomy
of approaches to realise GPAIS, describing research trends such as the use of
AI techniques to improve another AI or foundation models. As a prime example,
we delve into generative AI, aligning them with the terms and concepts
presented in the taxonomy. Through the proposed definition and taxonomy, our
aim is to facilitate research collaboration across different areas that are
tackling general-purpose tasks, as they share many common aspects. Finally, we
discuss the current state of GPAIS, its challenges and prospects, implications
for our society, and the need for responsible and trustworthy AI systems and
regulation, with the goal of providing a holistic view of GPAIS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14294">Unraveling the Complexity of Splitting Sequential Data: Tackling Challenges in Video and Time Series Analysis. (arXiv:2307.14294v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Botache_D/0/1/0/all/0/1">Diego Botache</a>, <a href="http://arxiv.org/find/cs/1/au:+Dingel_K/0/1/0/all/0/1">Kristina Dingel</a>, <a href="http://arxiv.org/find/cs/1/au:+Huhnstock_R/0/1/0/all/0/1">Rico Huhnstock</a>, <a href="http://arxiv.org/find/cs/1/au:+Ehresmann_A/0/1/0/all/0/1">Arno Ehresmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1">Bernhard Sick</a></p>
<p>Splitting of sequential data, such as videos and time series, is an essential
step in various data analysis tasks, including object tracking and anomaly
detection. However, splitting sequential data presents a variety of challenges
that can impact the accuracy and reliability of subsequent analyses. This
concept article examines the challenges associated with splitting sequential
data, including data acquisition, data representation, split ratio selection,
setting up quality criteria, and choosing suitable selection strategies. We
explore these challenges through two real-world examples: motor test benches
and particle tracking in liquids.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14298">ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality. (arXiv:2307.14298v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Remountakis_M/0/1/0/all/0/1">Manolis Remountakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotis_K/0/1/0/all/0/1">Konstantinos Kotis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kourtzis_B/0/1/0/all/0/1">Babis Kourtzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsekouras_G/0/1/0/all/0/1">George E. Tsekouras</a></p>
<p>Recommender systems have become indispensable tools in the hotel hospitality
industry, enabling personalized and tailored experiences for guests. Recent
advancements in large language models (LLMs), such as ChatGPT, and persuasive
technologies, have opened new avenues for enhancing the effectiveness of those
systems. This paper explores the potential of integrating ChatGPT and
persuasive technologies for automating and improving hotel hospitality
recommender systems. First, we delve into the capabilities of ChatGPT, which
can understand and generate human-like text, enabling more accurate and
context-aware recommendations. We discuss the integration of ChatGPT into
recommender systems, highlighting the ability to analyze user preferences,
extract valuable insights from online reviews, and generate personalized
recommendations based on guest profiles. Second, we investigate the role of
persuasive technology in influencing user behavior and enhancing the persuasive
impact of hotel recommendations. By incorporating persuasive techniques, such
as social proof, scarcity and personalization, recommender systems can
effectively influence user decision-making and encourage desired actions, such
as booking a specific hotel or upgrading their room. To investigate the
efficacy of ChatGPT and persuasive technologies, we present a pilot experi-ment
with a case study involving a hotel recommender system. We aim to study the
impact of integrating ChatGPT and persua-sive techniques on user engagement,
satisfaction, and conversion rates. The preliminary results demonstrate the
potential of these technologies in enhancing the overall guest experience and
business performance. Overall, this paper contributes to the field of hotel
hospitality by exploring the synergistic relationship between LLMs and
persuasive technology in recommender systems, ultimately influencing guest
satisfaction and hotel revenue.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14304">A Constraint Enforcement Deep Reinforcement Learning Framework for Optimal Energy Storage Systems Dispatch. (arXiv:2307.14304v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Hou_S/0/1/0/all/0/1">Shengren Hou</a>, <a href="http://arxiv.org/find/eess/1/au:+Duque_E/0/1/0/all/0/1">Edgar Mauricio Salazar Duque</a>, <a href="http://arxiv.org/find/eess/1/au:+Palensky_P/0/1/0/all/0/1">Peter Palensky</a>, <a href="http://arxiv.org/find/eess/1/au:+Vergara_P/0/1/0/all/0/1">Pedro P. Vergara</a></p>
<p>The optimal dispatch of energy storage systems (ESSs) presents formidable
challenges due to the uncertainty introduced by fluctuations in dynamic prices,
demand consumption, and renewable-based energy generation. By exploiting the
generalization capabilities of deep neural networks (DNNs), deep reinforcement
learning (DRL) algorithms can learn good-quality control models that adaptively
respond to distribution networks' stochastic nature. However, current DRL
algorithms lack the capabilities to enforce operational constraints strictly,
often even providing unfeasible control actions. To address this issue, we
propose a DRL framework that effectively handles continuous action spaces while
strictly enforcing the environments and action space operational constraints
during online operation. Firstly, the proposed framework trains an action-value
function modeled using DNNs. Subsequently, this action-value function is
formulated as a mixed-integer programming (MIP) formulation enabling the
consideration of the environment's operational constraints. Comprehensive
numerical simulations show the superior performance of the proposed MIP-DRL
framework, effectively enforcing all constraints while delivering high-quality
dispatch decisions when compared with state-of-the-art DRL algorithms and the
optimal solution obtained with a perfect forecast of the stochastic variables.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14316">Reinforcement Learning by Guided Safe Exploration. (arXiv:2307.14316v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qisong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Simao_T/0/1/0/all/0/1">Thiago D. Sim&#xe3;o</a>, <a href="http://arxiv.org/find/cs/1/au:+Jansen_N/0/1/0/all/0/1">Nils Jansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tindemans_S/0/1/0/all/0/1">Simon H. Tindemans</a>, <a href="http://arxiv.org/find/cs/1/au:+Spaan_M/0/1/0/all/0/1">Matthijs T. J. Spaan</a></p>
<p>Safety is critical to broadening the application of reinforcement learning
(RL). Often, we train RL agents in a controlled environment, such as a
laboratory, before deploying them in the real world. However, the real-world
target task might be unknown prior to deployment. Reward-free RL trains an
agent without the reward to adapt quickly once the reward is revealed. We
consider the constrained reward-free setting, where an agent (the guide) learns
to explore safely without the reward signal. This agent is trained in a
controlled environment, which allows unsafe interactions and still provides the
safety signal. After the target task is revealed, safety violations are not
allowed anymore. Thus, the guide is leveraged to compose a safe behaviour
policy. Drawing from transfer learning, we also regularize a target policy (the
student) towards the guide while the student is unreliable and gradually
eliminate the influence of the guide as training progresses. The empirical
analysis shows that this method can achieve safe transfer learning and helps
the student solve the target task faster.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14324">Evaluating the Moral Beliefs Encoded in LLMs. (arXiv:2307.14324v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Scherrer_N/0/1/0/all/0/1">Nino Scherrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Claudia Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1">Amir Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Blei_D/0/1/0/all/0/1">David M. Blei</a></p>
<p>This paper presents a case study on the design, administration,
post-processing, and evaluation of surveys on large language models (LLMs). It
comprises two components: (1) A statistical method for eliciting beliefs
encoded in LLMs. We introduce statistical measures and evaluation metrics that
quantify the probability of an LLM "making a choice", the associated
uncertainty, and the consistency of that choice. (2) We apply this method to
study what moral beliefs are encoded in different LLMs, especially in ambiguous
cases where the right choice is not obvious. We design a large-scale survey
comprising 680 high-ambiguity moral scenarios (e.g., "Should I tell a white
lie?") and 687 low-ambiguity moral scenarios (e.g., "Should I stop for a
pedestrian on the road?"). Each scenario includes a description, two possible
actions, and auxiliary labels indicating violated rules (e.g., "do not kill").
We administer the survey to 28 open- and closed-source LLMs. We find that (a)
in unambiguous scenarios, most models "choose" actions that align with
commonsense. In ambiguous cases, most models express uncertainty. (b) Some
models are uncertain about choosing the commonsense action because their
responses are sensitive to the question-wording. (c) Some models reflect clear
preferences in ambiguous scenarios. Specifically, closed-source models tend to
agree with each other.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14326">Waypoint-Based Imitation Learning for Robotic Manipulation. (arXiv:2307.14326v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1">Lucy Xiaoyang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Archit Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tony Z. Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a></p>
<p>While imitation learning methods have seen a resurgent interest for robotic
manipulation, the well-known problem of compounding errors continues to afflict
behavioral cloning (BC). Waypoints can help address this problem by reducing
the horizon of the learning problem for BC, and thus, the errors compounded
over time. However, waypoint labeling is underspecified, and requires
additional human supervision. Can we generate waypoints automatically without
any additional human supervision? Our key insight is that if a trajectory
segment can be approximated by linear motion, the endpoints can be used as
waypoints. We propose Automatic Waypoint Extraction (AWE) for imitation
learning, a preprocessing module to decompose a demonstration into a minimal
set of waypoints which when interpolated linearly can approximate the
trajectory up to a specified error threshold. AWE can be combined with any BC
algorithm, and we find that AWE can increase the success rate of
state-of-the-art algorithms by up to 25% in simulation and by 4-28% on
real-world bimanual manipulation tasks, reducing the decision making horizon by
up to a factor of 10. Videos and code are available at
https://lucys0.github.io/awe/
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14338">TabR: Unlocking the Power of Retrieval-Augmented Tabular Deep Learning. (arXiv:2307.14338v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gorishniy_Y/0/1/0/all/0/1">Yury Gorishniy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubachev_I/0/1/0/all/0/1">Ivan Rubachev</a>, <a href="http://arxiv.org/find/cs/1/au:+Kartashev_N/0/1/0/all/0/1">Nikolay Kartashev</a>, <a href="http://arxiv.org/find/cs/1/au:+Shlenskii_D/0/1/0/all/0/1">Daniil Shlenskii</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotelnikov_A/0/1/0/all/0/1">Akim Kotelnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1">Artem Babenko</a></p>
<p>Deep learning (DL) models for tabular data problems are receiving
increasingly more attention, while the algorithms based on gradient-boosted
decision trees (GBDT) remain a strong go-to solution. Following the recent
trends in other domains, such as natural language processing and computer
vision, several retrieval-augmented tabular DL models have been recently
proposed. For a given target object, a retrieval-based model retrieves other
relevant objects, such as the nearest neighbors, from the available (training)
data and uses their features or even labels to make a better prediction.
However, we show that the existing retrieval-based tabular DL solutions provide
only minor, if any, benefits over the properly tuned simple retrieval-free
baselines. Thus, it remains unclear whether the retrieval-based approach is a
worthy direction for tabular DL.
</p>
<p>In this work, we give a strong positive answer to this question. We start by
incrementally augmenting a simple feed-forward architecture with an
attention-like retrieval component similar to those of many (tabular)
retrieval-based models. Then, we highlight several details of the attention
mechanism that turn out to have a massive impact on the performance on tabular
data problems, but that were not explored in prior work. As a result, we design
TabR -- a simple retrieval-based tabular DL model which, on a set of public
benchmarks, demonstrates the best average performance among tabular DL models,
becomes the new state-of-the-art on several datasets, and even outperforms GBDT
models on the recently proposed ``GBDT-friendly'' benchmark (see the first
figure).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/1808.00560">Compressible Spectral Mixture Kernels with Sparse Dependency Structures for Gaussian Processes. (arXiv:1808.00560v9 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1">Yijue Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_F/0/1/0/all/0/1">Feng Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchiori_E/0/1/0/all/0/1">Elena Marchiori</a>, <a href="http://arxiv.org/find/cs/1/au:+Theodoridis_S/0/1/0/all/0/1">Sergios Theodoridis</a></p>
<p>Spectral mixture (SM) kernels comprise a powerful class of generalized
kernels for Gaussian processes (GPs) to describe complex patterns. This paper
introduces model compression and time- and phase (TP) modulated dependency
structures to the original (SM) kernel for improved generalization of GPs.
Specifically, by adopting Bienaym\'es identity, we generalize the dependency
structure through cross-covariance between the SM components. Then, we propose
a novel SM kernel with a dependency structure (SMD) by using cross-convolution
between the SM components. Furthermore, we ameliorate the expressiveness of the
dependency structure by parameterizing it with time and phase delays. The
dependency structure has clear interpretations in terms of spectral density,
covariance behavior, and sampling path. To enrich the SMD with effective
hyperparameter initialization, compressible SM kernel components, and sparse
dependency structures, we introduce a novel structure adaptation (SA) algorithm
in the end. A thorough comparative analysis of the SMD on both synthetic and
real-life applications corroborates its efficacy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.11959">Revisiting Deep Learning Models for Tabular Data. (arXiv:2106.11959v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gorishniy_Y/0/1/0/all/0/1">Yury Gorishniy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubachev_I/0/1/0/all/0/1">Ivan Rubachev</a>, <a href="http://arxiv.org/find/cs/1/au:+Khrulkov_V/0/1/0/all/0/1">Valentin Khrulkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1">Artem Babenko</a></p>
<p>The existing literature on deep learning for tabular data proposes a wide
range of novel architectures and reports competitive results on various
datasets. However, the proposed models are usually not properly compared to
each other and existing works often use different benchmarks and experiment
protocols. As a result, it is unclear for both researchers and practitioners
what models perform best. Additionally, the field still lacks effective
baselines, that is, the easy-to-use models that provide competitive performance
across different problems.
</p>
<p>In this work, we perform an overview of the main families of DL architectures
for tabular data and raise the bar of baselines in tabular DL by identifying
two simple and powerful deep architectures. The first one is a ResNet-like
architecture which turns out to be a strong baseline that is often missing in
prior works. The second model is our simple adaptation of the Transformer
architecture for tabular data, which outperforms other solutions on most tasks.
Both models are compared to many existing architectures on a diverse set of
tasks under the same training and tuning protocols. We also compare the best DL
models with Gradient Boosted Decision Trees and conclude that there is still no
universally superior solution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2111.09885">Rate-optimal Bayesian Simple Regret in Best Arm Identification. (arXiv:2111.09885v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Komiyama_J/0/1/0/all/0/1">Junpei Komiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Ariu_K/0/1/0/all/0/1">Kaito Ariu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kato_M/0/1/0/all/0/1">Masahiro Kato</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chao Qin</a></p>
<p>We consider best arm identification in the multi-armed bandit problem.
Assuming certain continuity conditions of the prior, we characterize the rate
of the Bayesian simple regret. Differing from Bayesian regret minimization
(Lai, 1987), the leading term in the Bayesian simple regret derives from the
region where the gap between optimal and suboptimal arms is smaller than
$\sqrt{\frac{\log T}{T}}$. We propose a simple and easy-to-compute algorithm
with its leading term matching with the lower bound up to a constant factor;
simulation results support our theoretical findings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2201.11104">Combining optimal path search with task-dependent learning in a neural network. (arXiv:2201.11104v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kulvicius_T/0/1/0/all/0/1">Tomas Kulvicius</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamosiunaite_M/0/1/0/all/0/1">Minija Tamosiunaite</a>, <a href="http://arxiv.org/find/cs/1/au:+Worgotter_F/0/1/0/all/0/1">Florentin W&#xf6;rg&#xf6;tter</a></p>
<p>Finding optimal paths in connected graphs requires determining the smallest
total cost for traveling along the graph's edges. This problem can be solved by
several classical algorithms where, usually, costs are predefined for all
edges. Conventional planning methods can, thus, normally not be used when
wanting to change costs in an adaptive way following the requirements of some
task. Here we show that one can define a neural network representation of path
finding problems by transforming cost values into synaptic weights, which
allows for online weight adaptation using network learning mechanisms. When
starting with an initial activity value of one, activity propagation in this
network will lead to solutions, which are identical to those found by the
Bellman-Ford algorithm. The neural network has the same algorithmic complexity
as Bellman-Ford and, in addition, we can show that network learning mechanisms
(such as Hebbian learning) can adapt the weights in the network augmenting the
resulting paths according to some task at hand. We demonstrate this by learning
to navigate in an environment with obstacles as well as by learning to follow
certain sequences of path nodes. Hence, the here-presented novel algorithm may
open up a different regime of applications where path-augmentation (by
learning) is directly coupled with path finding in a natural way.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2202.12780">Model Comparison and Calibration Assessment: User Guide for Consistent Scoring Functions in Machine Learning and Actuarial Practice. (arXiv:2202.12780v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Fissler_T/0/1/0/all/0/1">Tobias Fissler</a>, <a href="http://arxiv.org/find/stat/1/au:+Lorentzen_C/0/1/0/all/0/1">Christian Lorentzen</a>, <a href="http://arxiv.org/find/stat/1/au:+Mayer_M/0/1/0/all/0/1">Michael Mayer</a></p>
<p>One of the main tasks of actuaries and data scientists is to build good
predictive models for certain phenomena such as the claim size or the number of
claims in insurance. These models ideally exploit given feature information to
enhance the accuracy of prediction. This user guide revisits and clarifies
statistical techniques to assess the calibration or adequacy of a model on the
one hand, and to compare and rank different models on the other hand. In doing
so, it emphasises the importance of specifying the prediction target functional
at hand a priori (e.g. the mean or a quantile) and of choosing the scoring
function in model comparison in line with this target functional. Guidance for
the practical choice of the scoring function is provided. Striving to bridge
the gap between science and daily practice in application, it focuses mainly on
the pedagogical presentation of existing results and of best practice. The
results are accompanied and illustrated by two real data case studies on
workers' compensation and customer churn.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.01482">MetaDT: Meta Decision Tree with Class Hierarchy for Interpretable Few-Shot Learning. (arXiv:2203.01482v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Baoquan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xutao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shanshan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yunming Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_R/0/1/0/all/0/1">Rui Ye</a></p>
<p>Few-Shot Learning (FSL) is a challenging task, which aims to recognize novel
classes with few examples. Recently, lots of methods have been proposed from
the perspective of meta-learning and representation learning. However, few
works focus on the interpretability of FSL decision process. In this paper, we
take a step towards the interpretable FSL by proposing a novel meta-learning
based decision tree framework, namely, MetaDT. In particular, the FSL
interpretability is achieved from two aspects, i.e., a concept aspect and a
visual aspect. On the concept aspect, we first introduce a tree-like concept
hierarchy as FSL prior. Then, resorting to the prior, we split each few-shot
task to a set of subtasks with different concept levels and then perform class
prediction via a model of decision tree. The advantage of such design is that a
sequence of high-level concept decisions that lead up to a final class
prediction can be obtained, which clarifies the FSL decision process. On the
visual aspect, a set of subtask-specific classifiers with visual attention
mechanism is designed to perform decision at each node of the decision tree. As
a result, a subtask-specific heatmap visualization can be obtained to achieve
the decision interpretability of each tree node. At last, to alleviate the data
scarcity issue of FSL, we regard the prior of concept hierarchy as an
undirected graph, and then design a graph convolution-based decision tree
inference network as our meta-learner to infer parameters of the decision tree.
Extensive experiments on performance comparison and interpretability analysis
show superiority of our MetaDT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.04317">MICDIR: Multi-scale Inverse-consistent Deformable Image Registration using UNetMSS with Self-Constructing Graph Latent. (arXiv:2203.04317v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Chatterjee_S/0/1/0/all/0/1">Soumick Chatterjee</a>, <a href="http://arxiv.org/find/eess/1/au:+Bajaj_H/0/1/0/all/0/1">Himanshi Bajaj</a>, <a href="http://arxiv.org/find/eess/1/au:+Siddiquee_I/0/1/0/all/0/1">Istiyak H. Siddiquee</a>, <a href="http://arxiv.org/find/eess/1/au:+Subbarayappa_N/0/1/0/all/0/1">Nandish Bandi Subbarayappa</a>, <a href="http://arxiv.org/find/eess/1/au:+Simon_S/0/1/0/all/0/1">Steve Simon</a>, <a href="http://arxiv.org/find/eess/1/au:+Shashidhar_S/0/1/0/all/0/1">Suraj Bangalore Shashidhar</a>, <a href="http://arxiv.org/find/eess/1/au:+Speck_O/0/1/0/all/0/1">Oliver Speck</a>, <a href="http://arxiv.org/find/eess/1/au:+Nurnberge_A/0/1/0/all/0/1">Andreas N&#xfc;rnberge</a></p>
<p>Image registration is the process of bringing different images into a common
coordinate system - a technique widely used in various applications of computer
vision, such as remote sensing, image retrieval, and, most commonly, medical
imaging. Deep learning based techniques have been applied successfully to
tackle various complex medical image processing problems, including medical
image registration. Over the years, several image registration techniques have
been proposed using deep learning. Deformable image registration techniques
such as Voxelmorph have been successful in capturing finer changes and
providing smoother deformations. However, Voxelmorph, as well as ICNet and
FIRE, do not explicitly encode global dependencies (i.e. the overall anatomical
view of the supplied image) and, therefore, cannot track large deformations. In
order to tackle the aforementioned problems, this paper extends the Voxelmorph
approach in three different ways. To improve the performance in case of small
as well as large deformations, supervision of the model at different
resolutions has been integrated using a multi-scale UNet. To support the
network to learn and encode the minute structural co-relations of the given
image-pairs, a self-constructing graph network (SCGNet) has been used as the
latent of the multi-scale UNet - which can improve the learning process of the
model and help the model to generalise better. And finally, to make the
deformations inverse-consistent, cycle consistency loss has been employed. On
the task of registration of brain MRIs, the proposed method achieved
significant improvements over ANTs and VoxelMorph, obtaining a Dice score of
0.8013 \pm 0.0243 for intramodal and 0.6211 \pm 0.0309 for intermodal, while
VoxelMorph achieved 0.7747 \pm 0.0260 and 0.6071 \pm 0.0510, respectively
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.05556">On Embeddings for Numerical Features in Tabular Deep Learning. (arXiv:2203.05556v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gorishniy_Y/0/1/0/all/0/1">Yury Gorishniy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubachev_I/0/1/0/all/0/1">Ivan Rubachev</a>, <a href="http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1">Artem Babenko</a></p>
<p>Recently, Transformer-like deep architectures have shown strong performance
on tabular data problems. Unlike traditional models, e.g., MLP, these
architectures map scalar values of numerical features to high-dimensional
embeddings before mixing them in the main backbone. In this work, we argue that
embeddings for numerical features are an underexplored degree of freedom in
tabular DL, which allows constructing more powerful DL models and competing
with GBDT on some traditionally GBDT-friendly benchmarks. We start by
describing two conceptually different approaches to building embedding modules:
the first one is based on a piecewise linear encoding of scalar values, and the
second one utilizes periodic activations. Then, we empirically demonstrate that
these two approaches can lead to significant performance boosts compared to the
embeddings based on conventional blocks such as linear layers and ReLU
activations. Importantly, we also show that embedding numerical features is
beneficial for many backbones, not only for Transformers. Specifically, after
proper embeddings, simple MLP-like models can perform on par with the
attention-based architectures. Overall, we highlight embeddings for numerical
features as an important design aspect with good potential for further
improvements in tabular DL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.10848">Robust Quantity-Aware Aggregation for Federated Learning. (arXiv:2205.10848v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1">Jingwei Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huishuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Bin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1">Tao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1">Guangzhong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a></p>
<p>Federated learning (FL) enables multiple clients to collaboratively train
models without sharing their local data, and becomes an important
privacy-preserving machine learning framework. However, classical FL faces
serious security and robustness problem, e.g., malicious clients can poison
model updates and at the same time claim large quantities to amplify the impact
of their model updates in the model aggregation. Existing defense methods for
FL, while all handling malicious model updates, either treat all quantities
benign or simply ignore/truncate the quantities of all clients. The former is
vulnerable to quantity-enhanced attack, while the latter leads to sub-optimal
performance since the local data on different clients is usually in
significantly different sizes. In this paper, we propose a robust
quantity-aware aggregation algorithm for federated learning, called FedRA, to
perform the aggregation with awareness of local data quantities while being
able to defend against quantity-enhanced attacks. More specifically, we propose
a method to filter malicious clients by jointly considering the uploaded model
updates and data quantities from different clients, and performing
quantity-aware weighted averaging on model updates from remaining clients.
Moreover, as the number of malicious clients participating in the federated
learning may dynamically change in different rounds, we also propose a
malicious client number estimator to predict how many suspicious clients should
be filtered in each round. Experiments on four public datasets demonstrate the
effectiveness of our FedRA method in defending FL against quantity-enhanced
attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.13619">Fairness in Recommendation: Foundations, Methods and Applications. (arXiv:2205.13619v5 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hanxiong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yingqiang Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Juntao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuchang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a></p>
<p>As one of the most pervasive applications of machine learning, recommender
systems are playing an important role on assisting human decision making. The
satisfaction of users and the interests of platforms are closely related to the
quality of the generated recommendation results. However, as a highly
data-driven system, recommender system could be affected by data or algorithmic
bias and thus generate unfair results, which could weaken the reliance of the
systems. As a result, it is crucial to address the potential unfairness
problems in recommendation settings. Recently, there has been growing attention
on fairness considerations in recommender systems with more and more literature
on approaches to promote fairness in recommendation. However, the studies are
rather fragmented and lack a systematic organization, thus making it difficult
to penetrate for new researchers to the domain. This motivates us to provide a
systematic survey of existing works on fairness in recommendation. This survey
focuses on the foundations for fairness in recommendation literature. It first
presents a brief introduction about fairness in basic machine learning tasks
such as classification and ranking in order to provide a general overview of
fairness research, as well as introduce the more complex situations and
challenges that need to be considered when studying fairness in recommender
systems. After that, the survey will introduce fairness in recommendation with
a focus on the taxonomies of current fairness definitions, the typical
techniques for improving fairness, as well as the datasets for fairness studies
in recommendation. The survey also talks about the challenges and opportunities
in fairness research with the hope of promoting the fair recommendation
research area and beyond.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.02789">Efficient and Accurate Physics-aware Multiplex Graph Neural Networks for 3D Small Molecules and Macromolecule Complexes. (arXiv:2206.02789v2 [q-bio.BM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_S/0/1/0/all/0/1">Shuo Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xie_L/0/1/0/all/0/1">Lei Xie</a></p>
<p>Recent advances in applying Graph Neural Networks (GNNs) to molecular science
have showcased the power of learning three-dimensional (3D) structure
representations with GNNs. However, most existing GNNs suffer from the
limitations of insufficient modeling of diverse interactions, computational
expensive operations, and ignorance of vectorial values. Here, we tackle these
limitations by proposing a novel GNN model, Physics-aware Multiplex Graph
Neural Network (PaxNet), to efficiently and accurately learn the
representations of 3D molecules for both small organic compounds and
macromolecule complexes. PaxNet separates the modeling of local and non-local
interactions inspired by molecular mechanics, and reduces the expensive
angle-related computations. Besides scalar properties, PaxNet can also predict
vectorial properties by learning an associated vector for each atom. To
evaluate the performance of PaxNet, we compare it with state-of-the-art
baselines in two tasks. On small molecule dataset for predicting quantum
chemical properties, PaxNet reduces the prediction error by 15% and uses 73%
less memory than the best baseline. On macromolecule dataset for predicting
protein-ligand binding affinities, PaxNet outperforms the best baseline while
reducing the memory consumption by 33% and the inference time by 85%. Thus,
PaxNet provides a universal, robust and accurate method for large-scale machine
learning of molecules. Our code is available at
https://github.com/zetayue/Physics-aware-Multiplex-GNN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.04140">TreeFlow: Going beyond Tree-based Gaussian Probabilistic Regression. (arXiv:2206.04140v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wielopolski_P/0/1/0/all/0/1">Patryk Wielopolski</a>, <a href="http://arxiv.org/find/cs/1/au:+Zieba_M/0/1/0/all/0/1">Maciej Zi&#x119;ba</a></p>
<p>The tree-based ensembles are known for their outstanding performance in
classification and regression problems characterized by feature vectors
represented by mixed-type variables from various ranges and domains. However,
considering regression problems, they are primarily designed to provide
deterministic responses or model the uncertainty of the output with Gaussian or
parametric distribution. In this work, we introduce TreeFlow, the tree-based
approach that combines the benefits of using tree ensembles with the
capabilities of modeling flexible probability distributions using normalizing
flows. The main idea of the solution is to use a tree-based model as a feature
extractor and combine it with a conditional variant of normalizing flow.
Consequently, our approach is capable of modeling complex distributions for the
regression outputs. We evaluate the proposed method on challenging regression
benchmarks with varying volume, feature characteristics, and target
dimensionality. We obtain the SOTA results for both probabilistic and
deterministic metrics on datasets with multi-modal target distributions and
competitive results on unimodal ones compared to tree-based regression
baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.04172">Beyond the Edge of Stability via Two-step Gradient Updates. (arXiv:2206.04172v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a></p>
<p>Gradient Descent (GD) is a powerful workhorse of modern machine learning
thanks to its scalability and efficiency in high-dimensional spaces. Its
ability to find local minimisers is only guaranteed for losses with Lipschitz
gradients, where it can be seen as a `bona-fide' discretisation of an
underlying gradient flow. Yet, many ML setups involving overparametrised models
do not fall into this problem class, which has motivated research beyond the
so-called ``Edge of Stability'' (EoS), where the step-size crosses the
admissibility threshold inversely proportional to the Lipschitz constant above.
Perhaps surprisingly, GD has been empirically observed to still converge
regardless of local instability and oscillatory behavior.
</p>
<p>The incipient theoretical analysis of this phenomena has mainly focused in
the overparametrised regime, where the effect of choosing a large learning rate
may be associated to a `Sharpness-Minimisation' implicit regularisation within
the manifold of minimisers, under appropriate asymptotic limits. In contrast,
in this work we directly examine the conditions for such unstable convergence,
focusing on simple, yet representative, learning problems, via analysis of
two-step gradient updates. Specifically, we characterize a local condition
involving third-order derivatives that guarantees existence and convergence to
fixed points of the two-step updates, and leverage such property in a
teacher-student setting, under population loss. Finally, starting from Matrix
Factorization, we provide observations of period-2 orbit of GD in
high-dimensional settings with intuition of its dynamics, along with
exploration into more general settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.07038">SHAP-XRT: The Shapley Value Meets Conditional Independence Testing. (arXiv:2207.07038v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Teneggi_J/0/1/0/all/0/1">Jacopo Teneggi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharti_B/0/1/0/all/0/1">Beepul Bharti</a>, <a href="http://arxiv.org/find/cs/1/au:+Romano_Y/0/1/0/all/0/1">Yaniv Romano</a>, <a href="http://arxiv.org/find/cs/1/au:+Sulam_J/0/1/0/all/0/1">Jeremias Sulam</a></p>
<p>The complex nature of artificial neural networks raises concerns on their
reliability, trustworthiness, and fairness in real-world scenarios. The Shapley
value -- a solution concept from game theory -- is one of the most popular
explanation methods for machine learning models. More traditionally, from a
statistical perspective, feature importance is defined in terms of conditional
independence. So far, these two approaches to interpretability and feature
importance have been considered separate and distinct. In this work, we show
that Shapley-based explanation methods and conditional independence testing are
closely related. We introduce the $\textbf{SHAP}$ley-E$\textbf{X}$planation
$\textbf{R}$andomization $\textbf{T}$est (SHAP-XRT), a testing procedure
inspired by the Conditional Randomization Test (CRT) for a specific notion of
local (i.e., on a sample) conditional independence. With it, we prove that for
binary classification problems, the marginal contributions in the Shapley value
provide lower and upper bounds to the $p$-values of their respective tests.
Furthermore, we show that the Shapley value itself provides an upper bound to
the $p$-value of a global (i.e., overall) null hypothesis. As a result, we
further our understanding of Shapley-based explanation methods from a novel
perspective and characterize under which conditions one can make statistically
valid claims about feature importance via the Shapley value.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.03143">AudioLM: a Language Modeling Approach to Audio Generation. (arXiv:2209.03143v2 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Borsos_Z/0/1/0/all/0/1">Zal&#xe1;n Borsos</a>, <a href="http://arxiv.org/find/cs/1/au:+Marinier_R/0/1/0/all/0/1">Rapha&#xeb;l Marinier</a>, <a href="http://arxiv.org/find/cs/1/au:+Vincent_D/0/1/0/all/0/1">Damien Vincent</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharitonov_E/0/1/0/all/0/1">Eugene Kharitonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1">Olivier Pietquin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharifi_M/0/1/0/all/0/1">Matt Sharifi</a>, <a href="http://arxiv.org/find/cs/1/au:+Roblek_D/0/1/0/all/0/1">Dominik Roblek</a>, <a href="http://arxiv.org/find/cs/1/au:+Teboul_O/0/1/0/all/0/1">Olivier Teboul</a>, <a href="http://arxiv.org/find/cs/1/au:+Grangier_D/0/1/0/all/0/1">David Grangier</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliasacchi_M/0/1/0/all/0/1">Marco Tagliasacchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeghidour_N/0/1/0/all/0/1">Neil Zeghidour</a></p>
<p>We introduce AudioLM, a framework for high-quality audio generation with
long-term consistency. AudioLM maps the input audio to a sequence of discrete
tokens and casts audio generation as a language modeling task in this
representation space. We show how existing audio tokenizers provide different
trade-offs between reconstruction quality and long-term structure, and we
propose a hybrid tokenization scheme to achieve both objectives. Namely, we
leverage the discretized activations of a masked language model pre-trained on
audio to capture long-term structure and the discrete codes produced by a
neural audio codec to achieve high-quality synthesis. By training on large
corpora of raw audio waveforms, AudioLM learns to generate natural and coherent
continuations given short prompts. When trained on speech, and without any
transcript or annotation, AudioLM generates syntactically and semantically
plausible speech continuations while also maintaining speaker identity and
prosody for unseen speakers. Furthermore, we demonstrate how our approach
extends beyond speech by generating coherent piano music continuations, despite
being trained without any symbolic representation of music.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.07028">Estimating large causal polytrees from small samples. (arXiv:2209.07028v2 [stat.ME] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Chatterjee_S/0/1/0/all/0/1">Sourav Chatterjee</a>, <a href="http://arxiv.org/find/stat/1/au:+Vidyasagar_M/0/1/0/all/0/1">Mathukumalli Vidyasagar</a></p>
<p>We consider the problem of estimating a large causal polytree from a
relatively small i.i.d. sample. This is motivated by the problem of determining
causal structure when the number of variables is very large compared to the
sample size, such as in gene regulatory networks. We give an algorithm that
recovers the tree with high accuracy in such settings. The algorithm works
under essentially no distributional or modeling assumptions other than some
mild non-degeneracy conditions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.03829">Early Detection of Bark Beetle Attack Using Remote Sensing and Machine Learning: A Review. (arXiv:2210.03829v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Marvasti_Zadeh_S/0/1/0/all/0/1">Seyed Mojtaba Marvasti-Zadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodsman_D/0/1/0/all/0/1">Devin Goodsman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_N/0/1/0/all/0/1">Nilanjan Ray</a>, <a href="http://arxiv.org/find/cs/1/au:+Erbilgin_N/0/1/0/all/0/1">Nadir Erbilgin</a></p>
<p>This paper provides a comprehensive review of past and current advances in
the early detection of bark beetle-induced tree mortality from three primary
perspectives: bark beetle &amp; host interactions, RS, and ML/DL. In contrast to
prior efforts, this review encompasses all RS systems and emphasizes ML/DL
methods to investigate their strengths and weaknesses. We parse existing
literature based on multi- or hyper-spectral analyses and distill their
knowledge based on: bark beetle species &amp; attack phases with a primary emphasis
on early stages of attacks, host trees, study regions, RS platforms &amp; sensors,
spectral/spatial/temporal resolutions, spectral signatures, spectral vegetation
indices (SVIs), ML approaches, learning schemes, task categories, models,
algorithms, classes/clusters, features, and DL networks &amp; architectures.
Although DL-based methods and the random forest (RF) algorithm showed promising
results, highlighting their potential to detect subtle changes across visible,
thermal, and short-wave infrared (SWIR) spectral regions, they still have
limited effectiveness and high uncertainties. To inspire novel solutions to
these shortcomings, we delve into the principal challenges &amp; opportunities from
different perspectives, enabling a deeper understanding of the current state of
research and guiding future research directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.07612">Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes. (arXiv:2210.07612v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Hodgkinson_L/0/1/0/all/0/1">Liam Hodgkinson</a>, <a href="http://arxiv.org/find/stat/1/au:+Heide_C/0/1/0/all/0/1">Chris van der Heide</a>, <a href="http://arxiv.org/find/stat/1/au:+Roosta_F/0/1/0/all/0/1">Fred Roosta</a>, <a href="http://arxiv.org/find/stat/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a></p>
<p>Despite their importance for assessing reliability of predictions,
uncertainty quantification (UQ) measures for machine learning models have only
recently begun to be rigorously characterized. One prominent issue is the curse
of dimensionality: it is commonly believed that the marginal likelihood should
be reminiscent of cross-validation metrics and that both should deteriorate
with larger input dimensions. We prove that by tuning hyperparameters to
maximize marginal likelihood (the empirical Bayes procedure), the performance,
as measured by the marginal likelihood, improves monotonically} with the input
dimension. On the other hand, we prove that cross-validation metrics exhibit
qualitatively different behavior that is characteristic of double descent. Cold
posteriors, which have recently attracted interest due to their improved
performance in certain settings, appear to exacerbate these phenomena. We
verify empirically that our results hold for real data, beyond our considered
assumptions, and we explore consequences involving synthetic covariates.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.13763">Teal: Learning-Accelerated Optimization of WAN Traffic Engineering. (arXiv:2210.13763v3 [cs.NI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiying Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_F/0/1/0/all/0/1">Francis Y. Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rachee Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_J/0/1/0/all/0/1">Justin T. Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1">Alexander M. Rush</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1">Minlan Yu</a></p>
<p>The rapid expansion of global cloud wide-area networks (WANs) has posed a
challenge for commercial optimization engines to efficiently solve network
traffic engineering (TE) problems at scale. Existing acceleration strategies
decompose TE optimization into concurrent subproblems but realize limited
parallelism due to an inherent tradeoff between run time and allocation
performance.
</p>
<p>We present Teal, a learning-based TE algorithm that leverages the parallel
processing power of GPUs to accelerate TE control. First, Teal designs a
flow-centric graph neural network (GNN) to capture WAN connectivity and network
flows, learning flow features as inputs to downstream allocation. Second, to
reduce the problem scale and make learning tractable, Teal employs a
multi-agent reinforcement learning (RL) algorithm to independently allocate
each traffic demand while optimizing a central TE objective. Finally, Teal
fine-tunes allocations with ADMM (Alternating Direction Method of Multipliers),
a highly parallelizable optimization algorithm for reducing constraint
violations such as overutilized links.
</p>
<p>We evaluate Teal using traffic matrices from Microsoft's WAN. On a large WAN
topology with &gt;1,700 nodes, Teal generates near-optimal flow allocations while
running several orders of magnitude faster than the production optimization
engine. Compared with other TE acceleration schemes, Teal satisfies 6--32% more
traffic demand and yields 197--625x speedups.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.15539">Multi-Target Tracking with Transferable Convolutional Neural Networks. (arXiv:2210.15539v4 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Owerko_D/0/1/0/all/0/1">Damian Owerko</a>, <a href="http://arxiv.org/find/eess/1/au:+Kanatsoulis_C/0/1/0/all/0/1">Charilaos I. Kanatsoulis</a>, <a href="http://arxiv.org/find/eess/1/au:+Bondarchuk_J/0/1/0/all/0/1">Jennifer Bondarchuk</a>, <a href="http://arxiv.org/find/eess/1/au:+Bucci_D/0/1/0/all/0/1">Donald J. Bucci Jr</a>, <a href="http://arxiv.org/find/eess/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a></p>
<p>Multi-target tracking (MTT) is a classical signal processing task, where the
goal is to estimate the states of an unknown number of moving targets from
noisy sensor measurements. In this paper, we revisit MTT from a deep learning
perspective and propose a convolutional neural network (CNN) architecture to
tackle it. We represent the target states and sensor measurements as images and
recast the problem as an image-to-image prediction task. Then we train a fully
convolutional model at small tracking areas and transfer it to much larger
areas with numerous targets and sensors. This transfer learning approach
enables MTT at a large scale and is also theoretically supported by our novel
analysis that bounds the generalization error. In practice, the proposed
transferable CNN architecture outperforms random finite set filters on the MTT
task with 10 targets and transfers without re-training to a larger MTT task
with 250 targets with a 29% performance improvement.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.01364">An optimal control perspective on diffusion-based generative modeling. (arXiv:2211.01364v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Berner_J/0/1/0/all/0/1">Julius Berner</a>, <a href="http://arxiv.org/find/cs/1/au:+Richter_L/0/1/0/all/0/1">Lorenz Richter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullrich_K/0/1/0/all/0/1">Karen Ullrich</a></p>
<p>We establish a connection between stochastic optimal control and generative
models based on stochastic differential equations (SDEs), such as recently
developed diffusion probabilistic models. In particular, we derive a
Hamilton-Jacobi-Bellman equation that governs the evolution of the
log-densities of the underlying SDE marginals. This perspective allows to
transfer methods from optimal control theory to generative modeling. First, we
show that the evidence lower bound is a direct consequence of the well-known
verification theorem from control theory. Further, we can formulate
diffusion-based generative modeling as a minimization of the Kullback-Leibler
divergence between suitable measures in path space. Finally, we develop a novel
diffusion-based method for sampling from unnormalized densities -- a problem
frequently occurring in statistics and computational sciences. We demonstrate
that our time-reversed diffusion sampler (DIS) can outperform other
diffusion-based sampling approaches on multiple numerical examples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.01549">Client Selection in Federated Learning: Principles, Challenges, and Opportunities. (arXiv:2211.01549v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_L/0/1/0/all/0/1">Lei Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huanle Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1">Ge Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a></p>
<p>As a privacy-preserving paradigm for training Machine Learning (ML) models,
Federated Learning (FL) has received tremendous attention from both industry
and academia. In a typical FL scenario, clients exhibit significant
heterogeneity in terms of data distribution and hardware configurations. Thus,
randomly sampling clients in each training round may not fully exploit the
local updates from heterogeneous clients, resulting in lower model accuracy,
slower convergence rate, degraded fairness, etc. To tackle the FL client
heterogeneity problem, various client selection algorithms have been developed,
showing promising performance improvement. In this paper, we systematically
present recent advances in the emerging field of FL client selection and its
challenges and research opportunities. We hope to facilitate practitioners in
choosing the most suitable client selection mechanisms for their applications,
as well as inspire researchers and newcomers to better understand this exciting
research topic.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.01226">Factor Fields: A Unified Framework for Neural Fields and Beyond. (arXiv:2302.01226v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Anpei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zexiang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xinyue Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Siyu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1">Andreas Geiger</a></p>
<p>We present Factor Fields, a novel framework for modeling and representing
signals. Factor Fields decomposes a signal into a product of factors, each of
which is represented by a neural or regular field representation operating on a
coordinate transformed input signal. We show that this decomposition yields a
unified framework that generalizes several recent signal representations
including NeRF, PlenOxels, EG3D, Instant-NGP, and TensoRF. Moreover, the
framework allows for the creation of powerful new signal representations, such
as the Coefficient-Basis Factorization (CoBaFa) which we propose in this paper.
As evidenced by our experiments, CoBaFa leads to improvements over previous
fast reconstruction methods in terms of the three critical goals in neural
signal representation: approximation quality, compactness and efficiency.
Experimentally, we demonstrate that our representation achieves better image
approximation quality on 2D image regression tasks, higher geometric quality
when reconstructing 3D signed distance fields and higher compactness for
radiance field reconstruction tasks compared to previous fast reconstruction
methods. Besides, our CoBaFa representation enables generalization by sharing
the basis across signals during training, enabling generalization tasks such as
image regression with sparse observations and few-shot radiance field
reconstruction. Project Page: https://apchenstu.github.io/FactorFields/
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.09013">Uniformity Testing over Hypergrids with Subcube Conditioning. (arXiv:2302.09013v2 [cs.DS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcussen_C/0/1/0/all/0/1">Cassandra Marcussen</a></p>
<p>We give an algorithm for testing uniformity of distributions supported on
hypergrids $[m_1] \times \cdots \times [m_n]$, which makes
$\smash{\widetilde{O}(\text{poly}(m)\sqrt{n}/\epsilon^2)}$ many queries to a
subcube conditional sampling oracle with $m=\max_i m_i$. When $m$ is a
constant, our algorithm is nearly optimal and strengthens the algorithm of
[CCK+21] which has the same query complexity but works for hypercubes $\{\pm
1\}^n$ only.
</p>
<p>A key technical contribution behind the analysis of our algorithm is a proof
of a robust version of Pisier's inequality for functions over hypergrids using
Fourier analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.12004">Knowledge Distillation-based Information Sharing for Online Process Monitoring in Decentralized Manufacturing System. (arXiv:2302.12004v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhangyue Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuxuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chenang Liu</a></p>
<p>In advanced manufacturing, the incorporation of sensing technology provides
an opportunity to achieve efficient in-situ process monitoring using machine
learning methods. Meanwhile, the advances of information technologies also
enable a connected and decentralized environment for manufacturing systems,
making different manufacturing units in the system collaborate more closely. In
a decentralized manufacturing system, the involved units may fabricate same or
similar products and deploy their own machine learning model for online process
monitoring. However, due to the possible inconsistency of task progress during
the operation, it is also common that some units have more informative data
while some have less informative data. Thus, the monitoring performance of
machine learning model for each unit may highly vary. Therefore, it is
extremely valuable to achieve efficient and secured knowledge sharing among the
units in a decentralized manufacturing system for enhancement of poorly
performed models. To realize this goal, this paper proposes a novel knowledge
distillation-based information sharing (KD-IS) framework, which could distill
informative knowledge from well performed models to improve the monitoring
performance of poorly performed models. To validate the effectiveness of this
method, a real-world case study is conducted in a connected fused filament
fabrication (FFF)-based additive manufacturing (AM) platform. The experimental
results show that the developed method is very efficient in improving model
monitoring performance at poorly performed models, with solid protection on
potential data privacy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.12247">Quantifying &amp; Modeling Multimodal Interactions: An Information Decomposition Framework. (arXiv:2302.12247v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Paul Pu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1">Chun Kai Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1">Suzanne Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Richard Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zihao Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Allen_N/0/1/0/all/0/1">Nicholas Allen</a>, <a href="http://arxiv.org/find/cs/1/au:+Auerbach_R/0/1/0/all/0/1">Randy Auerbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_F/0/1/0/all/0/1">Faisal Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1">Ruslan Salakhutdinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1">Louis-Philippe Morency</a></p>
<p>The recent explosion of interest in multimodal applications has resulted in a
wide selection of datasets and methods for representing and integrating
information from different modalities. Despite these empirical advances, there
remain fundamental research questions: How can we quantify the interactions
that are necessary to solve a multimodal task? Subsequently, what are the most
suitable multimodal models to capture these interactions? To answer these
questions, we propose an information-theoretic approach to quantify the degree
of redundancy, uniqueness, and synergy relating input modalities with an output
task. We term these three measures as the PID statistics of a multimodal
distribution (or PID for short), and introduce two new estimators for these PID
statistics that scale to high-dimensional distributions. To validate PID
estimation, we conduct extensive experiments on both synthetic datasets where
the PID is known and on large-scale multimodal benchmarks where PID estimations
are compared with human annotations. Finally, we demonstrate their usefulness
in (1) quantifying interactions within multimodal datasets, (2) quantifying
interactions captured by multimodal models, (3) principled approaches for model
selection, and (4) three real-world case studies engaging with domain experts
in pathology, mood prediction, and robotic perception where our framework helps
to recommend strong multimodal models for each application.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.14831">FacEDiM: A Face Embedding Distribution Model for Few-Shot Biometric Authentication of Cattle. (arXiv:2302.14831v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oveneke_M/0/1/0/all/0/1">Meshia C&#xe9;dric Oveneke</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaishampayan_R/0/1/0/all/0/1">Rucha Vaishampayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nsadisa_D/0/1/0/all/0/1">Deogratias Lukamba Nsadisa</a>, <a href="http://arxiv.org/find/cs/1/au:+Onya_J/0/1/0/all/0/1">Jenny Ambukiyenyi Onya</a></p>
<p>This work proposes to solve the problem of few-shot biometric authentication
by computing the Mahalanobis distance between testing embeddings and a
multivariate Gaussian distribution of training embeddings obtained using
pre-trained CNNs. Experimental results show that models pre-trained on the
ImageNet dataset significantly outperform models pre-trained on human faces.
With a VGG16 model, we obtain a FRR of 1.25% for a FAR of 1.18% on a dataset of
20 cattle identities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.16109">Multimodal Manoeuvre and Trajectory Prediction for Automated Driving on Highways Using Transformer Networks. (arXiv:2303.16109v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mozaffari_S/0/1/0/all/0/1">Sajjad Mozaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Sormoli_M/0/1/0/all/0/1">Mreza Alipour Sormoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Koufos_K/0/1/0/all/0/1">Konstantinos Koufos</a>, <a href="http://arxiv.org/find/cs/1/au:+Dianati_M/0/1/0/all/0/1">Mehrdad Dianati</a></p>
<p>Predicting the behaviour (i.e., manoeuvre/trajectory) of other road users,
including vehicles, is critical for the safe and efficient operation of
autonomous vehicles (AVs), a.k.a., automated driving systems (ADSs). Due to the
uncertain future behaviour of vehicles, multiple future behaviour modes are
often plausible for a vehicle in a given driving scene. Therefore, multimodal
prediction can provide richer information than single-mode prediction, enabling
AVs to perform a better risk assessment. To this end, we propose a novel
multimodal prediction framework that can predict multiple plausible behaviour
modes and their likelihoods. The proposed framework includes a bespoke problem
formulation for manoeuvre prediction, a novel transformer-based prediction
model, and a tailored training method for multimodal manoeuvre and trajectory
prediction. The performance of the framework is evaluated using three public
highway driving datasets, namely NGSIM, highD, and exiD. The results show that
our framework outperforms the state-of-the-art multimodal methods in terms of
prediction error and is capable of predicting plausible manoeuvre and
trajectory modes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.17595">Neglected Free Lunch -- Learning Image Classifiers Using Annotation Byproducts. (arXiv:2303.17595v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Dongyoon Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Choe_J/0/1/0/all/0/1">Junsuk Choe</a>, <a href="http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1">Seonghyeok Chun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">John Joon Young Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1">Minsuk Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Sangdoo Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jean Y. Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Seong Joon Oh</a></p>
<p>Supervised learning of image classifiers distills human knowledge into a
parametric model through pairs of images and corresponding labels (X,Y). We
argue that this simple and widely used representation of human knowledge
neglects rich auxiliary information from the annotation procedure, such as the
time-series of mouse traces and clicks left after image selection. Our insight
is that such annotation byproducts Z provide approximate human attention that
weakly guides the model to focus on the foreground cues, reducing spurious
correlations and discouraging shortcut learning. To verify this, we create
ImageNet-AB and COCO-AB. They are ImageNet and COCO training sets enriched with
sample-wise annotation byproducts, collected by replicating the respective
original annotation tasks. We refer to the new paradigm of training models with
annotation byproducts as learning using annotation byproducts (LUAB). We show
that a simple multitask loss for regressing Z together with Y already improves
the generalisability and robustness of the learned models. Compared to the
original supervised learning, LUAB does not require extra annotation costs.
ImageNet-AB and COCO-AB are at https://github.com/naver-ai/NeglectedFreeLunch.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.04660">Uncertainty-driven Trajectory Truncation for Data Augmentation in Offline Reinforcement Learning. (arXiv:2304.04660v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_J/0/1/0/all/0/1">Jiafei Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaoteng Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jiangpeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_L/0/1/0/all/0/1">Le Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiu Li</a></p>
<p>Equipped with the trained environmental dynamics, model-based offline
reinforcement learning (RL) algorithms can often successfully learn good
policies from fixed-sized datasets, even some datasets with poor quality.
Unfortunately, however, it can not be guaranteed that the generated samples
from the trained dynamics model are reliable (e.g., some synthetic samples may
lie outside of the support region of the static dataset). To address this
issue, we propose Trajectory Truncation with Uncertainty (TATU), which
adaptively truncates the synthetic trajectory if the accumulated uncertainty
along the trajectory is too large. We theoretically show the performance bound
of TATU to justify its benefits. To empirically show the advantages of TATU, we
first combine it with two classical model-based offline RL algorithms, MOPO and
COMBO. Furthermore, we integrate TATU with several off-the-shelf model-free
offline RL algorithms, e.g., BCQ. Experimental results on the D4RL benchmark
show that TATU significantly improves their performance, often by a large
margin. Code is available here.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.14989">Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards. (arXiv:2304.14989v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qin_H/0/1/0/all/0/1">Hao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jun_K/0/1/0/all/0/1">Kwang-Sung Jun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chicheng Zhang</a></p>
<p>We study $K$-armed bandit problems where the reward distributions of the arms
are all supported on the $[0,1]$ interval. It has been a challenge to design
regret-efficient randomized exploration algorithms in this setting. Maillard
sampling~\cite{maillard13apprentissage}, an attractive alternative to Thompson
sampling, has recently been shown to achieve competitive regret guarantees in
the sub-Gaussian reward setting~\cite{bian2022maillard} while maintaining
closed-form action probabilities, which is useful for offline policy
evaluation. In this work, we propose the Kullback-Leibler Maillard Sampling
(KL-MS) algorithm, a natural extension of Maillard sampling for achieving
KL-style gap-dependent regret bound. We show that KL-MS enjoys the asymptotic
optimality when the rewards are Bernoulli and has a worst-case regret bound of
the form $O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$, where $\mu^*$ is the
expected reward of the optimal arm, and $T$ is the time horizon length.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.06851">Policy Gradient Algorithms Implicitly Optimize by Continuation. (arXiv:2305.06851v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bolland_A/0/1/0/all/0/1">Adrien Bolland</a>, <a href="http://arxiv.org/find/cs/1/au:+Louppe_G/0/1/0/all/0/1">Gilles Louppe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ernst_D/0/1/0/all/0/1">Damien Ernst</a></p>
<p>Direct policy optimization in reinforcement learning is usually solved with
policy-gradient algorithms, which optimize policy parameters via stochastic
gradient ascent. This paper provides a new theoretical interpretation and
justification of these algorithms. First, we formulate direct policy
optimization in the optimization by continuation framework. The latter is a
framework for optimizing nonconvex functions where a sequence of surrogate
objective functions, called continuations, are locally optimized. Second, we
show that optimizing affine Gaussian policies and performing entropy
regularization can be interpreted as implicitly optimizing deterministic
policies by continuation. Based on these theoretical results, we argue that
exploration in policy-gradient algorithms consists in computing a continuation
of the return of the policy at hand, and that the variance of policies should
be history-dependent functions adapted to avoid local extrema rather than to
maximize the return of the policy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.11990">Productive Crop Field Detection: A New Dataset and Deep Learning Benchmark Results. (arXiv:2305.11990v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nascimento_E/0/1/0/all/0/1">Eduardo Nascimento</a>, <a href="http://arxiv.org/find/cs/1/au:+Just_J/0/1/0/all/0/1">John Just</a>, <a href="http://arxiv.org/find/cs/1/au:+Almeida_J/0/1/0/all/0/1">Jurandy Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Almeida_T/0/1/0/all/0/1">Tiago Almeida</a></p>
<p>In precision agriculture, detecting productive crop fields is an essential
practice that allows the farmer to evaluate operating performance separately
and compare different seed varieties, pesticides, and fertilizers. However,
manually identifying productive fields is often a time-consuming and
error-prone task. Previous studies explore different methods to detect crop
fields using advanced machine learning algorithms, but they often lack good
quality labeled data. In this context, we propose a high-quality dataset
generated by machine operation combined with Sentinel-2 images tracked over
time. As far as we know, it is the first one to overcome the lack of labeled
samples by using this technique. In sequence, we apply a semi-supervised
classification of unlabeled data and state-of-the-art supervised and
self-supervised deep learning methods to detect productive crop fields
automatically. Finally, the results demonstrate high accuracy in Positive
Unlabeled learning, which perfectly fits the problem where we have high
confidence in the positive samples. Best performances have been found in
Triplet Loss Siamese given the existence of an accurate dataset and Contrastive
Learning considering situations where we do not have a comprehensive labeled
dataset available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16573">Exploring Weight Balancing on Long-Tailed Recognition Problem. (arXiv:2305.16573v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hasegawa_N/0/1/0/all/0/1">Naoya Hasegawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1">Issei Sato</a></p>
<p>Recognition problems in long-tailed data, where the sample size per class is
heavily skewed, have recently gained importance because the distribution of the
sample size per class in a dataset is generally exponential unless the sample
size is intentionally adjusted. Various approaches have been devised to address
these problems. Recently, weight balancing, which combines well-known classical
regularization techniques with two-stage training, has been proposed. Despite
its simplicity, it is known for its high performance against existing methods
devised in various ways. However, there is a lack of understanding as to why
this approach is effective for long-tailed data. In this study, we analyze the
method focusing on neural collapse and cone effect at each training stage and
find that it can be decomposed into the increase in Fisher's discriminant ratio
of the feature extractor caused by weight decay and cross entropy loss and
implicit logit adjustment caused by weight decay and class-balanced loss. Our
analysis shows that the training method can be further simplified by reducing
the number of training stages to one while increasing accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.19442">SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning. (arXiv:2305.19442v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yifan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_P/0/1/0/all/0/1">Peiyao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_K/0/1/0/all/0/1">Kaiyi Ji</a></p>
<p>Federated bilevel optimization (FBO) has shown great potential recently in
machine learning and edge computing due to the emerging nested optimization
structure in meta-learning, fine-tuning, hyperparameter tuning, etc. However,
existing FBO algorithms often involve complicated computations and require
multiple sub-loops per iteration, each of which contains a number of
communication rounds. In this paper, we propose a simple and flexible FBO
framework named SimFBO, which is easy to implement without sub-loops, and
includes a generalized server-side aggregation and update for improving
communication efficiency. We further propose System-level heterogeneity robust
FBO (ShroFBO) as a variant of SimFBO with stronger resilience to heterogeneous
local computation. We show that SimFBO and ShroFBO provably achieve a linear
convergence speedup with partial client participation and client sampling
without replacement, as well as improved sample and communication complexities.
Experiments demonstrate the effectiveness of the proposed methods over existing
FBO algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02115">Table and Image Generation for Investigating Knowledge of Entities in Pre-trained Vision and Language Models. (arXiv:2306.02115v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kamigaito_H/0/1/0/all/0/1">Hidetaka Kamigaito</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_K/0/1/0/all/0/1">Katsuhiko Hayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1">Taro Watanabe</a></p>
<p>In this paper, we propose a table and image generation task to verify how the
knowledge about entities acquired from natural language is retained in Vision &amp;
Language (V&amp;L) models. This task consists of two parts: the first is to
generate a table containing knowledge about an entity and its related image,
and the second is to generate an image from an entity with a caption and a
table containing related knowledge of the entity. In both tasks, the model must
know the entities used to perform the generation properly. We created the
Wikipedia Table and Image Generation (WikiTIG) dataset from about 200,000
infoboxes in English Wikipedia articles to perform the proposed tasks. We
evaluated the performance on the tasks with respect to the above research
question using the V&amp;L model OFA, which has achieved state-of-the-art results
in multiple tasks. Experimental results show that OFA forgets part of its
entity knowledge by pre-training as a complement to improve the performance of
image related tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09790">The Information Bottleneck&#x27;s Ordinary Differential Equation: First-Order Root-Tracking for the IB. (arXiv:2306.09790v2 [cs.IT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Agmon_S/0/1/0/all/0/1">Shlomi Agmon</a></p>
<p>The Information Bottleneck (IB) is a method of lossy compression of relevant
information. Its rate-distortion (RD) curve describes the fundamental tradeoff
between input compression and the preservation of relevant information embedded
in the input. However, it conceals the underlying dynamics of optimal input
encodings. We argue that these typically follow a piecewise smooth trajectory
when input information is being compressed, as recently shown in RD. These
smooth dynamics are interrupted when an optimal encoding changes qualitatively,
at a bifurcation. By leveraging the IB's intimate relations with RD, we provide
substantial insights into its solution structure, highlighting caveats in its
finite-dimensional treatments. Sub-optimal solutions are seen to collide or
exchange optimality at its bifurcations.
</p>
<p>Despite the acceptance of the IB and its applications, there are surprisingly
few techniques to solve it numerically, even for finite problems whose
distribution is known. We derive anew the IB's first-order Ordinary
Differential Equation, which describes the dynamics underlying its optimal
tradeoff curve. To exploit these dynamics, we not only detect IB bifurcations
but also identify their type in order to handle them accordingly. Rather than
approaching the IB's optimal curve from sub-optimal directions, the latter
allows us to follow a solution's trajectory along the optimal curve under mild
assumptions. We thereby translate an understanding of IB bifurcations into a
surprisingly accurate numerical algorithm.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11650">FedNoisy: Federated Noisy Label Learning Benchmark. (arXiv:2306.11650v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1">Siqi Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jintao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Junyuan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1">Dun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiayu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a></p>
<p>Federated learning has gained popularity for distributed learning without
aggregating sensitive data from clients. But meanwhile, the distributed and
isolated nature of data isolation may be complicated by data quality, making it
more vulnerable to noisy labels. Many efforts exist to defend against the
negative impacts of noisy labels in centralized or federated settings. However,
there is a lack of a benchmark that comprehensively considers the impact of
noisy labels in a wide variety of typical FL settings. In this work, we serve
the first standardized benchmark that can help researchers fully explore
potential federated noisy settings. Also, we conduct comprehensive experiments
to explore the characteristics of these data settings and unravel challenging
scenarios on the federated noisy label learning, which may guide method
development in the future. We highlight the 20 basic settings for more than 5
datasets proposed in our benchmark and standardized simulation pipeline for
federated noisy label learning. We hope this benchmark can facilitate idea
verification in federated learning with noisy labels. \texttt{FedNoisy} is
available at \codeword{https://github.com/SMILELab-FL/FedNoisy}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04056">Manifold Filter-Combine Networks. (arXiv:2307.04056v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Chew_J/0/1/0/all/0/1">Joyce Chew</a>, <a href="http://arxiv.org/find/stat/1/au:+Brouwer_E/0/1/0/all/0/1">Edward De Brouwer</a>, <a href="http://arxiv.org/find/stat/1/au:+Krishnaswamy_S/0/1/0/all/0/1">Smita Krishnaswamy</a>, <a href="http://arxiv.org/find/stat/1/au:+Needell_D/0/1/0/all/0/1">Deanna Needell</a>, <a href="http://arxiv.org/find/stat/1/au:+Perlmutter_M/0/1/0/all/0/1">Michael Perlmutter</a></p>
<p>We introduce a class of manifold neural networks (MNNs) that we call Manifold
Filter-Combine Networks (MFCNs), that aims to further our understanding of
MNNs, analogous to how the aggregate-combine framework helps with the
understanding of graph neural networks (GNNs). This class includes a wide
variety of subclasses that can be thought of as the manifold analog of various
popular GNNs. We then consider a method, based on building a data-driven graph,
for implementing such networks when one does not have global knowledge of the
manifold, but merely has access to finitely many sample points. We provide
sufficient conditions for the network to provably converge to its continuum
limit as the number of sample points tends to infinity. Unlike previous work
(which focused on specific graph constructions), our rate of convergence does
not directly depend on the number of filters used. Moreover, it exhibits linear
dependence on the depth of the network rather than the exponential dependence
obtained previously. Additionally, we provide several examples of interesting
subclasses of MFCNs and of the rates of convergence that are obtained under
specific graph constructions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05915">Prompt Generate Train (PGT): Few-shot Domain Adaption of Retrieval Augmented Generation Models for Open Book Question-Answering. (arXiv:2307.05915v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Krishna_C/0/1/0/all/0/1">C. S. Krishna</a></p>
<p>We propose a framework - Prompt, Generate, Train (PGT) - to efficiently
develop a generative question-answering model for open-book question-answering
over a proprietary collection of text documents. The framework adapts a
retriever augmented generation (RAG) model to the target domain using
supervised fine-tuning and reinforcement learning with synthetic feedback in a
few-shot setting. This, we hypothesize, will yield an aligned, uncertainty
calibrated model that is competitive with GPT-4 based in-context retrieval
augmented generation in generating relevant answers at lower serving costs. The
framework's synthetic generation pipeline will generate synthetic training data
comprising &lt;passage, question, answer&gt; tuples using an open-source LLM and a
novel consistency filtering scheme. The pipeline will be designed to generate
both abstractive and extractive questions that span the entire corpus. The
framework proposes to fine-tune a smaller RAG model comprising a dense
retriever (ColBERTv2) and a smaller sized LLM on the synthetic dataset. In
parallel, the framework will train a Reward model to score domain grounded
answers higher than hallucinated answers using an a priori relevance ordering
of synthetically assembled samples. In the next phase, the framework will align
the RAG model with the target domain using reinforcement learning (Proximal
Policy Optimization). This step may improve the RAG model's ability to generate
grounded answers and ignore out of domain questions. In the final phase, the
framework will calibrate the model's uncertainty for extractive
question-answers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06440">No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models. (arXiv:2307.06440v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1">Jean Kaddour</a>, <a href="http://arxiv.org/find/cs/1/au:+Key_O/0/1/0/all/0/1">Oscar Key</a>, <a href="http://arxiv.org/find/cs/1/au:+Nawrot_P/0/1/0/all/0/1">Piotr Nawrot</a>, <a href="http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1">Pasquale Minervini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1">Matt J. Kusner</a></p>
<p>The computation necessary for training Transformer-based language models has
skyrocketed in recent years. This trend has motivated research on efficient
training algorithms designed to improve training, validation, and downstream
performance faster than standard training. In this work, we revisit three
categories of such algorithms: dynamic architectures (layer stacking, layer
dropping), batch selection (selective backprop, RHO loss), and efficient
optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed
computation budget using such methods, we find that their training, validation,
and downstream gains vanish compared to a baseline with a fully-decayed
learning rate. We define an evaluation protocol that enables computation to be
done on arbitrary machines by mapping all computation time to a reference
machine which we call reference system time. We discuss the limitations of our
proposed protocol and release our code to encourage rigorous research in
efficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.09469">Graph Representation of the Magnetic Field Topology in High-Fidelity Plasma Simulations for Machine Learning Applications. (arXiv:2307.09469v2 [physics.plasm-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Bouri_I/0/1/0/all/0/1">Ioanna Bouri</a>, <a href="http://arxiv.org/find/physics/1/au:+Franssila_F/0/1/0/all/0/1">Fanni Franssila</a>, <a href="http://arxiv.org/find/physics/1/au:+Alho_M/0/1/0/all/0/1">Markku Alho</a>, <a href="http://arxiv.org/find/physics/1/au:+Cozzani_G/0/1/0/all/0/1">Giulia Cozzani</a>, <a href="http://arxiv.org/find/physics/1/au:+Zaitsev_I/0/1/0/all/0/1">Ivan Zaitsev</a>, <a href="http://arxiv.org/find/physics/1/au:+Palmroth_M/0/1/0/all/0/1">Minna Palmroth</a>, <a href="http://arxiv.org/find/physics/1/au:+Roos_T/0/1/0/all/0/1">Teemu Roos</a></p>
<p>Topological analysis of the magnetic field in simulated plasmas allows the
study of various physical phenomena in a wide range of settings. One such
application is magnetic reconnection, a phenomenon related to the dynamics of
the magnetic field topology, which is difficult to detect and characterize in
three dimensions. We propose a scalable pipeline for topological data analysis
and spatiotemporal graph representation of three-dimensional magnetic vector
fields. We demonstrate our methods on simulations of the Earth's magnetosphere
produced by Vlasiator, a supercomputer-scale Vlasov theory-based simulation for
near-Earth space. The purpose of this work is to challenge the machine learning
community to explore graph-based machine learning approaches to address a
largely open scientific problem with wide-ranging potential impact.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.09916">TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations. (arXiv:2307.09916v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jianing Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1">Qing Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yilin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wei Zeng</a></p>
<p>Deep learning (DL) approaches are being increasingly used for time-series
forecasting, with many efforts devoted to designing complex DL models. Recent
studies have shown that the DL success is often attributed to effective data
representations, fostering the fields of feature engineering and representation
learning. However, automated approaches for feature learning are typically
limited with respect to incorporating prior knowledge, identifying interactions
among variables, and choosing evaluation metrics to ensure that the models are
reliable. To improve on these limitations, this paper contributes a novel
visual analytics framework, namely TimeTuner, designed to help analysts
understand how model behaviors are associated with localized correlations,
stationarity, and granularity of time-series representations. The system mainly
consists of the following two-stage technique: We first leverage counterfactual
explanations to connect the relationships among time-series representations,
multivariate features and model predictions. Next, we design multiple
coordinated views including a partition-based correlation matrix and juxtaposed
bivariate stripes, and provide a set of interactions that allow users to step
into the transformation selection process, navigate through the feature space,
and reason the model performance. We instantiate TimeTuner with two
transformation methods of smoothing and sampling, and demonstrate its
applicability on real-world time-series forecasting of univariate sunspots and
multivariate air pollutants. Feedback from domain experts indicates that our
system can help characterize time-series representations and guide the feature
engineering processes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10569">Deceptive Alignment Monitoring. (arXiv:2307.10569v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1">Andres Carranza</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_D/0/1/0/all/0/1">Dhruv Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaeffer_R/0/1/0/all/0/1">Rylan Schaeffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Tandon_A/0/1/0/all/0/1">Arnuv Tandon</a>, <a href="http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1">Sanmi Koyejo</a></p>
<p>As the capabilities of large machine learning models continue to grow, and as
the autonomy afforded to such models continues to expand, the spectre of a new
adversary looms: the models themselves. The threat that a model might behave in
a seemingly reasonable manner, while secretly and subtly modifying its behavior
for ulterior reasons is often referred to as deceptive alignment in the AI
Safety &amp; Alignment communities. Consequently, we call this new direction
Deceptive Alignment Monitoring. In this work, we identify emerging directions
in diverse machine learning subfields that we believe will become increasingly
important and intertwined in the near future for deceptive alignment
monitoring, and we argue that advances in these fields present both long-term
challenges and new research opportunities. We conclude by advocating for
greater involvement by the adversarial machine learning community in these
emerging directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12171">Learn to Compress (LtC): Efficient Learning-based Streaming Video Analytics. (arXiv:2307.12171v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Alam_Q/0/1/0/all/0/1">Quazi Mishkatul Alam</a>, <a href="http://arxiv.org/find/eess/1/au:+Haque_I/0/1/0/all/0/1">Israat Haque</a>, <a href="http://arxiv.org/find/eess/1/au:+Abu_Ghazaleh_N/0/1/0/all/0/1">Nael Abu-Ghazaleh</a></p>
<p>Video analytics are often performed as cloud services in edge settings,
mainly to offload computation, and also in situations where the results are not
directly consumed at the video sensors. Sending high-quality video data from
the edge devices can be expensive both in terms of bandwidth and power use. In
order to build a streaming video analytics pipeline that makes efficient use of
these resources, it is therefore imperative to reduce the size of the video
stream. Traditional video compression algorithms are unaware of the semantics
of the video, and can be both inefficient and harmful for the analytics
performance. In this paper, we introduce LtC, a collaborative framework between
the video source and the analytics server, that efficiently learns to reduce
the video streams within an analytics pipeline. Specifically, LtC uses the
full-fledged analytics algorithm at the server as a teacher to train a
lightweight student neural network, which is then deployed at the video source.
The student network is trained to comprehend the semantic significance of
various regions within the videos, which is used to differentially preserve the
crucial regions in high quality while the remaining regions undergo aggressive
compression. Furthermore, LtC also incorporates a novel temporal filtering
algorithm based on feature-differencing to omit transmitting frames that do not
contribute new information. Overall, LtC is able to use 28-35% less bandwidth
and has up to 45% shorter response delay compared to recently published state
of the art streaming frameworks while achieving similar analytics performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13421">On the Learning Dynamics of Attention Networks. (arXiv:2307.13421v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vashisht_R/0/1/0/all/0/1">Rahul Vashisht</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramaswamy_H/0/1/0/all/0/1">Harish G. Ramaswamy</a></p>
<p>Attention models are typically learned by optimizing one of three standard
loss functions that are variously called -- soft attention, hard attention, and
latent variable marginal likelihood (LVML) attention. All three paradigms are
motivated by the same goal of finding two models -- a `focus' model that
`selects' the right \textit{segment} of the input and a `classification' model
that processes the selected segment into the target label. However, they differ
significantly in the way the selected segments are aggregated, resulting in
distinct dynamics and final results. We observe a unique signature of models
learned using these paradigms and explain this as a consequence of the
evolution of the classification model under gradient descent when the focus
model is fixed. We also analyze these paradigms in a simple setting and derive
closed-form expressions for the parameter trajectory under gradient flow. With
the soft attention loss, the focus model improves quickly at initialization and
splutters later on. On the other hand, hard attention loss behaves in the
opposite fashion. Based on our observations, we propose a simple hybrid
approach that combines the advantages of the different loss functions and
demonstrates it on a collection of semi-synthetic and real-world datasets
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13494">Duet: efficient and scalable hybriD neUral rElation undersTanding. (arXiv:2307.13494v2 [cs.DB] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaixin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yabin Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_C/0/1/0/all/0/1">Chang Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Donghua Yang</a></p>
<p>Learned cardinality estimation methods have achieved high precision compared
to traditional methods. Among learned methods, query-driven approaches face the
data and workload drift problem for a long time. Although both query-driven and
hybrid methods are proposed to avoid this problem, even the state-of-art of
them suffer from high training and estimation costs, limited scalability,
instability, and long-tailed distribution problem on high cardinality and high
dimensional tables, which seriously affects the practical application of
learned cardinality estimators. In this paper, we prove that most of these
problems are directly caused by the widely used progressive sampling. We solve
this problem by introducing predicates into the autoregressive model and
propose Duet, a stable, efficient, and scalable hybrid method to estimate
cardinality directly without sampling or any non-differentiable process, which
can not only reduces the inference complexity from $O(n)$ to $O(1)$ compared to
Naru and UAE but also achieve higher accuracy on high cardinality and high
dimensional tables. Experimental results show that Duet can achieve all the
design goals above and be much more practical and even has a lower inference
cost on CPU than that of most learned methods on GPU.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10711">AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models. (arXiv:2307.10711v2 [cs.CV] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jiachun Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liew_J/0/1/0/all/0/1">Jun Hao Liew</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1">Vincent Y. F. Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiashi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hanshu Yan</a></p>
<p>Existing customization methods require access to multiple reference examples
to align pre-trained diffusion probabilistic models (DPMs) with user-provided
concepts. This paper aims to address the challenge of DPM customization when
the only available supervision is a differentiable metric defined on the
generated contents. Since the sampling procedure of DPMs involves recursive
calls to the denoising UNet, na\"ive gradient backpropagation requires storing
the intermediate states of all iterations, resulting in extremely high memory
consumption. To overcome this issue, we propose a novel method AdjointDPM,
which first generates new samples from diffusion models by solving the
corresponding probability-flow ODEs. It then uses the adjoint sensitivity
method to backpropagate the gradients of the loss to the models' parameters
(including conditioning signals, network weights, and initial noises) by
solving another augmented ODE. To reduce numerical errors in both the forward
generation and gradient backpropagation processes, we further reparameterize
the probability-flow ODE and augmented ODE as simple non-stiff ODEs using
exponential integration. Finally, we demonstrate the effectiveness of
AdjointDPM on three interesting tasks: converting visual effects into
identification text embeddings, finetuning DPMs for specific types of
stylization, and optimizing initial noise to generate adversarial samples for
security auditing.
</p>
</p>
</div>

    </div>
    </body>
    