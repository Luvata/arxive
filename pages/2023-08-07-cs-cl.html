<!DOCTYPE html>
<html>
<head>
<title>2023-08-07-cs-cl</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2308.01927">MultiEM: Efficient and Effective Unsupervised Multi-Table Entity Matching. (arXiv:2308.01927v1 [cs.DB])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiaocan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pengfei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuren Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoze Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yunjun Gao</a></p>
<p>Entity Matching (EM), which aims to identify all entity pairs referring to
the same real-world entity from relational tables, is one of the most important
tasks in real-world data management systems. Due to the labeling process of EM
being extremely labor-intensive, unsupervised EM is more applicable than
supervised EM in practical scenarios. Traditional unsupervised EM assumes that
all entities come from two tables; however, it is more common to match entities
from multiple tables in practical applications, that is, multi-table entity
matching (multi-table EM). Unfortunately, effective and efficient unsupervised
multi-table EM remains under-explored. To fill this gap, this paper formally
studies the problem of unsupervised multi-table entity matching and proposes an
effective and efficient solution, termed as MultiEM. MultiEM is a parallelable
pipeline of enhanced entity representation, table-wise hierarchical merging,
and density-based pruning. Extensive experimental results on six real-world
benchmark datasets demonstrate the superiority of MultiEM in terms of
effectiveness and efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01936">Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?. (arXiv:2308.01936v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wijesiriwardene_T/0/1/0/all/0/1">Thilini Wijesiriwardene</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1">Amit Sheth</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalin_V/0/1/0/all/0/1">Valerie L. Shalin</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1">Amitava Das</a></p>
<p>A hallmark of intelligence is the ability to use a familiar domain to make
inferences about a less familiar domain, known as analogical reasoning. In this
article, we delve into the performance of Large Language Models (LLMs) in
dealing with progressively complex analogies expressed in unstructured text. We
discuss analogies at four distinct levels of complexity: lexical analogies,
syntactic analogies, semantic analogies, and pragmatic analogies. As the
analogies become more complex, they require increasingly extensive, diverse
knowledge beyond the textual content, unlikely to be found in the lexical
co-occurrence statistics that power LLMs. To address this, we discuss the
necessity of employing Neuro-symbolic AI techniques that combine statistical
and symbolic AI, informing the representation of unstructured text to highlight
and augment relevant content, provide abstraction and guide the mapping
process. Our knowledge-informed approach maintains the efficiency of LLMs while
preserving the ability to explain analogies for pedagogical applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01966">DCTM: Dilated Convolutional Transformer Model for Multimodal Engagement Estimation in Conversation. (arXiv:2308.01966v1 [cs.MM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tu_V/0/1/0/all/0/1">Vu Ngoc Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_V/0/1/0/all/0/1">Van Thong Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hyung-Jeong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1">M. Zaigham Zaheer</a>, <a href="http://arxiv.org/find/cs/1/au:+Nawaz_S/0/1/0/all/0/1">Shah Nawaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Nandakumar_K/0/1/0/all/0/1">Karthik Nandakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soo-Hyung Kim</a></p>
<p>Conversational engagement estimation is posed as a regression problem,
entailing the identification of the favorable attention and involvement of the
participants in the conversation. This task arises as a crucial pursuit to gain
insights into human's interaction dynamics and behavior patterns within a
conversation. In this research, we introduce a dilated convolutional
Transformer for modeling and estimating human engagement in the MULTIMEDIATE
2023 competition. Our proposed system surpasses the baseline models, exhibiting
a noteworthy $7$\% improvement on test set and $4$\% on validation set.
Moreover, we employ different modality fusion mechanism and show that for this
type of data, a simple concatenated method with self-attention fusion gains the
best performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01976">Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces. (arXiv:2308.01976v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ubrangala_D/0/1/0/all/0/1">Dayananda Ubrangala</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_J/0/1/0/all/0/1">Juhi Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondapalli_R/0/1/0/all/0/1">Ravi Prasad Kondapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+R_K/0/1/0/all/0/1">Kiran R</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwala_A/0/1/0/all/0/1">Amit Agarwala</a>, <a href="http://arxiv.org/find/cs/1/au:+Boue_L/0/1/0/all/0/1">Laurent Bou&#xe9;</a></p>
<p>Typographical errors are a major source of frustration for visitors of online
marketplaces. Because of the domain-specific nature of these marketplaces and
the very short queries users tend to search for, traditional spell cheking
solutions do not perform well in correcting typos. We present a data
augmentation method to address the lack of annotated typo data and train a
recurrent neural network to learn context-limited domain-specific embeddings.
Those embeddings are deployed in a real-time inferencing API for the Microsoft
AppSource marketplace to find the closest match between a misspelled user query
and the available product names. Our data efficient solution shows that
controlled high quality synthetic data may be a powerful tool especially
considering the current climate of large language models which rely on
prohibitively huge and often uncontrolled datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01987">Bengali Fake Reviews: A Benchmark Dataset and Detection System. (arXiv:2308.01987v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shahariar_G/0/1/0/all/0/1">G. M. Shahariar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shawon_M/0/1/0/all/0/1">Md. Tanvir Rouf Shawon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_F/0/1/0/all/0/1">Faisal Muhammad Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1">Mohammad Shafiul Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahbub_M/0/1/0/all/0/1">Md. Shahriar Mahbub</a></p>
<p>The proliferation of fake reviews on various online platforms has created a
major concern for both consumers and businesses. Such reviews can deceive
customers and cause damage to the reputation of products or services, making it
crucial to identify them. Although the detection of fake reviews has been
extensively studied in English language, detecting fake reviews in non-English
languages such as Bengali is still a relatively unexplored research area. This
paper introduces the Bengali Fake Review Detection (BFRD) dataset, the first
publicly available dataset for identifying fake reviews in Bengali. The dataset
consists of 7710 non-fake and 1339 fake food-related reviews collected from
social media posts. To convert non-Bengali words in a review, a unique pipeline
has been proposed that translates English words to their corresponding Bengali
meaning and also back transliterates Romanized Bengali to Bengali. We have
conducted rigorous experimentation using multiple deep learning and pre-trained
transformer language models to develop a reliable detection system. Finally, we
propose a weighted ensemble model that combines four pre-trained transformers:
BanglaBERT, BanglaBERT Base, BanglaBERT Large, and BanglaBERT Generator .
According to the experiment results, the proposed ensemble model obtained a
weighted F1-score of 0.9843 on 13390 reviews, including 1339 actual fake
reviews and 5356 augmented fake reviews generated with the nlpaug library. The
remaining 6695 reviews were randomly selected from the 7710 non-fake instances.
The model achieved a 0.9558 weighted F1-score when the fake reviews were
augmented using the bnaug library.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02013">Federated Representation Learning for Automatic Speech Recognition. (arXiv:2308.02013v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rames_G/0/1/0/all/0/1">Guruprasad V Rames</a>, <a href="http://arxiv.org/find/cs/1/au:+Chennupati_G/0/1/0/all/0/1">Gopinath Chennupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_M/0/1/0/all/0/1">Milind Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahu_A/0/1/0/all/0/1">Anit Kumar Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastrow_A/0/1/0/all/0/1">Ariya Rastrow</a>, <a href="http://arxiv.org/find/cs/1/au:+Droppo_J/0/1/0/all/0/1">Jasha Droppo</a></p>
<p>Federated Learning (FL) is a privacy-preserving paradigm, allowing edge
devices to learn collaboratively without sharing data. Edge devices like Alexa
and Siri are prospective sources of unlabeled audio data that can be tapped to
learn robust audio representations. In this work, we bring Self-supervised
Learning (SSL) and FL together to learn representations for Automatic Speech
Recognition respecting data privacy constraints. We use the speaker and chapter
information in the unlabeled speech dataset, Libri-Light, to simulate non-IID
speaker-siloed data distributions and pre-train an LSTM encoder with the
Contrastive Predictive Coding framework with FedSGD. We show that the
pre-trained ASR encoder in FL performs as well as a centrally pre-trained model
and produces an improvement of 12-15% (WER) compared to no pre-training. We
further adapt the federated pre-trained models to a new language, French, and
show a 20% (WER) improvement over no pre-training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02019">Baby Llama: knowledge distillation from an ensemble of teachers trained on a small dataset with no performance penalty. (arXiv:2308.02019v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Timiryasov_I/0/1/0/all/0/1">Inar Timiryasov</a>, <a href="http://arxiv.org/find/cs/1/au:+Tastet_J/0/1/0/all/0/1">Jean-Loup Tastet</a></p>
<p>We present our proposed solution to the BabyLM challenge [<a href="/abs/2301.11796">arXiv:2301.11796</a>],
whose goal was to improve the sample efficiency of language models. We trained
an ensemble consisting of a GPT-2 and small LLaMA models on the
developmentally-plausible, 10M-word BabyLM dataset, then distilled it into a
small, 58M-parameter LLaMA model, which exceeds in performance both of its
teachers as well as a similar model trained without distillation. This suggests
that distillation can not only retain the full performance of the teacher model
when the latter is trained on a sufficiently small dataset; it can exceed it,
and lead to significantly better performance than direct training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02022">Efficient Sentiment Analysis: A Resource-Aware Evaluation of Feature Extraction Techniques, Ensembling, and Deep Learning Models. (arXiv:2308.02022v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kamruzzaman_M/0/1/0/all/0/1">Mahammed Kamruzzaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Gene Louis Kim</a></p>
<p>While reaching for NLP systems that maximize accuracy, other important
metrics of system performance are often overlooked. Prior models are easily
forgotten despite their possible suitability in settings where large computing
resources are unavailable or relatively more costly. In this paper, we perform
a broad comparative evaluation of document-level sentiment analysis models with
a focus on resource costs that are important for the feasibility of model
deployment and general climate consciousness. Our experiments consider
different feature extraction techniques, the effect of ensembling,
task-specific deep learning modeling, and domain-independent large language
models (LLMs). We find that while a fine-tuned LLM achieves the best accuracy,
some alternate configurations provide huge (up to 24, 283 *) resource savings
for a marginal (&lt;1%) loss in accuracy. Furthermore, we find that for smaller
datasets, the differences in accuracy shrink while the difference in resource
consumption grows further.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02035">What Twitter Data Tell Us about the Future?. (arXiv:2308.02035v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Landowska_A/0/1/0/all/0/1">Alina Landowska</a>, <a href="http://arxiv.org/find/cs/1/au:+Robak_M/0/1/0/all/0/1">Marek Robak</a>, <a href="http://arxiv.org/find/cs/1/au:+Skorski_M/0/1/0/all/0/1">Maciej Skorski</a></p>
<p>Anticipation is a fundamental human cognitive ability that involves thinking
about and living towards the future. While language markers reflect
anticipatory thinking, research on anticipation from the perspective of natural
language processing is limited. This study aims to investigate the futures
projected by futurists on Twitter and explore the impact of language cues on
anticipatory thinking among social media users. We address the research
questions of what futures Twitter's futurists anticipate and share, and how
these anticipated futures can be modeled from social data. To investigate this,
we review related works on anticipation, discuss the influence of language
markers and prestigious individuals on anticipatory thinking, and present a
taxonomy system categorizing futures into "present futures" and "future
present". This research presents a compiled dataset of over 1 million publicly
shared tweets by future influencers and develops a scalable NLP pipeline using
SOTA models. The study identifies 15 topics from the LDA approach and 100
distinct topics from the BERTopic approach within the futurists' tweets. These
findings contribute to the research on topic modelling and provide insights
into the futures anticipated by Twitter's futurists. The research demonstrates
the futurists' language cues signals futures-in-the-making that enhance social
media users to anticipate their own scenarios and respond to them in present.
The fully open-sourced dataset, interactive analysis, and reproducible source
code are available for further exploration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02037">Proposing a conceptual framework: social media listening for public health behavior. (arXiv:2308.02037v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tsao_S/0/1/0/all/0/1">Shu-Feng Tsao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Helen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyer_S/0/1/0/all/0/1">Samantha Meyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Butt_Z/0/1/0/all/0/1">Zahid A. Butt</a></p>
<p>Existing communications and behavioral theories have been adopted to address
health misinformation. Although various theories and models have been used to
investigate the COVID-19 pandemic, there is no framework specially designed for
social listening or misinformation studies using social media data and natural
language processing techniques. This study aimed to propose a novel yet
theory-based conceptual framework for misinformation research. We collected
theories and models used in COVID-19 related studies published in peer-reviewed
journals. The theories and models ranged from health behaviors, communications,
to misinformation. They are analyzed and critiqued for their components,
followed by proposing a conceptual framework with a demonstration. We reviewed
Health Belief Model, Theory of Planned Behavior/Reasoned Action, Communication
for Behavioral Impact, Transtheoretical Model, Uses and Gratifications Theory,
Social Judgment Theory, Risk Information Seeking and Processing Model,
Behavioral and Social Drivers, and Hype Loop. Accordingly, we proposed the
Social Media Listening for Public Health Behavior Conceptual Framework by not
only integrating important attributes of existing theories, but also adding new
attributes. The proposed conceptual framework was demonstrated in the Freedom
Convoy social media listening. The proposed conceptual framework can be used to
better understand public discourse on social media, and it can be integrated
with other data analyses to gather a more comprehensive picture. The framework
will continue to be revised and adopted as health misinformation evolves.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02044">Artificial Intelligence in archival and historical scholarship workflow: HTS and ChatGPT. (arXiv:2308.02044v1 [cs.DL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Spina_S/0/1/0/all/0/1">Salvatore Spina</a></p>
<p>This article examines the impact of Artificial Intelligence on the archival
heritage digitization processes, specifically regarding the manuscripts'
automatic transcription, their correction, and normalization. It highlights how
digitality has compelled scholars to redefine Archive and History field and has
facilitated the accessibility of analogue sources through digitization and
integration into big data. The study focuses on two AI systems, namely
Transkribus and ChatGPT, which enable efficient analysis and transcription of
digitized sources. The article presents a test of ChatGPT, which was utilized
to normalize the text of 366 letters stored in the Correspondence section of
the Biscari Archive (Catania). Although the AI exhibited some limitations that
resulted in inaccuracies, the corrected texts met expectations. Overall, the
article concludes that digitization and AI can significantly enhance archival
and historical research by allowing the analysis of vast amounts of data and
the application of computational linguistic tools.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02053">The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations. (arXiv:2308.02053v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Salinas_A/0/1/0/all/0/1">Abel Salinas</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_P/0/1/0/all/0/1">Parth Vipul Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuzhong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+McCormack_R/0/1/0/all/0/1">Robert McCormack</a>, <a href="http://arxiv.org/find/cs/1/au:+Morstatter_F/0/1/0/all/0/1">Fred Morstatter</a></p>
<p>Large Language Models (LLMs) have seen widespread deployment in various
real-world applications. Understanding these biases is crucial to comprehend
the potential downstream consequences when using LLMs to make decisions,
particularly for historically disadvantaged groups. In this work, we propose a
simple method for analyzing and comparing demographic bias in LLMs, through the
lens of job recommendations. We demonstrate the effectiveness of our method by
measuring intersectional biases within ChatGPT and LLaMA, two cutting-edge
LLMs. Our experiments primarily focus on uncovering gender identity and
nationality bias; however, our method can be extended to examine biases
associated with any intersection of demographic identities. We identify
distinct biases in both models toward various demographic identities, such as
both models consistently suggesting low-paying jobs for Mexican workers or
preferring to recommend secretarial roles to women. Our study highlights the
importance of measuring the bias of LLMs in downstream applications to
understand the potential for harm and inequitable outcomes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02055">Seasonality Based Reranking of E-commerce Autocomplete Using Natural Language Queries. (arXiv:2308.02055v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1">Prateek Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1">Shan Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajan_A/0/1/0/all/0/1">Adithya Rajan</a></p>
<p>Query autocomplete (QAC) also known as typeahead, suggests list of complete
queries as user types prefix in the search box. It is one of the key features
of modern search engines specially in e-commerce. One of the goals of typeahead
is to suggest relevant queries to users which are seasonally important. In this
paper we propose a neural network based natural language processing (NLP)
algorithm to incorporate seasonality as a signal and present end to end
evaluation of the QAC ranking model. Incorporating seasonality into
autocomplete ranking model can improve autocomplete relevance and business
metric.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02080">Causality Guided Disentanglement for Cross-Platform Hate Speech Detection. (arXiv:2308.02080v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1">Paras Sheth</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumarage_T/0/1/0/all/0/1">Tharindu Kumarage</a>, <a href="http://arxiv.org/find/cs/1/au:+Moraffah_R/0/1/0/all/0/1">Raha Moraffah</a>, <a href="http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1">Aman Chadha</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huan Liu</a></p>
<p>Social media platforms, despite their value in promoting open discourse, are
often exploited to spread harmful content. Current deep learning and natural
language processing models used for detecting this harmful content overly rely
on domain-specific terms affecting their capabilities to adapt to generalizable
hate speech detection. This is because they tend to focus too narrowly on
particular linguistic signals or the use of certain categories of words.
Another significant challenge arises when platforms lack high-quality annotated
data for training, leading to a need for cross-platform models that can adapt
to different distribution shifts. Our research introduces a cross-platform hate
speech detection model capable of being trained on one platform's data and
generalizing to multiple unseen platforms. To achieve good generalizability
across platforms, one way is to disentangle the input representations into
invariant and platform-dependent features. We also argue that learning causal
relationships, which remain constant across diverse environments, can
significantly aid in understanding invariant representations in hate speech. By
disentangling input into platform-dependent features (useful for predicting
hate targets) and platform-independent features (used to predict the presence
of hate), we learn invariant representations resistant to distribution shifts.
These features are then used to predict hate speech across unseen platforms.
Our extensive experiments across four platforms highlight our model's enhanced
efficacy compared to existing state-of-the-art methods in detecting generalized
hate speech.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02092">N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets. (arXiv:2308.02092v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wang Yau Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadig_S/0/1/0/all/0/1">Shreekantha Nadig</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Karol Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_Z/0/1/0/all/0/1">Zafarullah Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Riqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vandieken_S/0/1/0/all/0/1">Simon Vandieken</a>, <a href="http://arxiv.org/find/cs/1/au:+Robertson_J/0/1/0/all/0/1">Jonas Robertson</a>, <a href="http://arxiv.org/find/cs/1/au:+Mailhot_F/0/1/0/all/0/1">Fred Mailhot</a></p>
<p>Accurate transcription of proper names and technical terms is particularly
important in speech-to-text applications for business conversations. These
words, which are essential to understanding the conversation, are often rare
and therefore likely to be under-represented in text and audio training data,
creating a significant challenge in this domain. We present a two-step keyword
boosting mechanism that successfully works on normalized unigrams and n-grams
rather than just single tokens, which eliminates missing hits issues with
boosting raw targets. In addition, we show how adjusting the boosting weight
logic avoids over-boosting multi-token keywords. This improves our keyword
recognition rate by 26% relative on our proprietary in-domain dataset and 2% on
LibriSpeech. This method is particularly useful on targets that involve
non-alphabetic characters or have non-standard pronunciations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02103">Prompt2Gaussia: Uncertain Prompt-learning for Script Event Prediction. (arXiv:2308.02103v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shiyao Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1">Xin Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_J/0/1/0/all/0/1">Jiawei Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuebin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tingwen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jinqiao Shi</a></p>
<p>Script Event Prediction (SEP) aims to predict the subsequent event for a
given event chain from a candidate list. Prior research has achieved great
success by integrating external knowledge to enhance the semantics, but it is
laborious to acquisite the appropriate knowledge resources and retrieve the
script-related knowledge. In this paper, we regard public pre-trained language
models as knowledge bases and automatically mine the script-related knowledge
via prompt-learning. Still, the scenario-diversity and label-ambiguity in
scripts make it uncertain to construct the most functional prompt and label
token in prompt learning, i.e., prompt-uncertainty and verbalizer-uncertainty.
Considering the innate ability of Gaussian distribution to express uncertainty,
we deploy the prompt tokens and label tokens as random variables following
Gaussian distributions, where a prompt estimator and a verbalizer estimator are
proposed to estimate their probabilistic representations instead of
deterministic representations. We take the lead to explore prompt-learning in
SEP and provide a fresh perspective to enrich the script semantics. Our method
is evaluated on the most widely used benchmark and a newly proposed large-scale
one. Experiments show that our method, which benefits from knowledge evoked
from pre-trained language models, outperforms prior baselines by 1.46\% and
1.05\% on two benchmarks, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02113">Chinese Financial Text Emotion Mining: GCGTS -- A Character Relationship-based Approach for Simultaneous Aspect-Opinion Pair Extraction. (arXiv:2308.02113v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dexi Liu</a></p>
<p>Aspect-Opinion Pair Extraction (AOPE) from Chinese financial texts is a
specialized task in fine-grained text sentiment analysis. The main objective is
to extract aspect terms and opinion terms simultaneously from a diverse range
of financial texts. Previous studies have mainly focused on developing grid
annotation schemes within grid-based models to facilitate this extraction
process. However, these methods often rely on character-level (token-level)
feature encoding, which may overlook the logical relationships between Chinese
characters within words. To address this limitation, we propose a novel method
called Graph-based Character-level Grid Tagging Scheme (GCGTS). The GCGTS
method explicitly incorporates syntactic structure using Graph Convolutional
Networks (GCN) and unifies the encoding of characters within the same syntactic
semantic unit (Chinese word level). Additionally, we introduce an image
convolutional structure into the grid model to better capture the local
relationships between characters within evaluation units. This innovative
structure reduces the excessive reliance on pre-trained language models and
emphasizes the modeling of structure and local relationships, thereby improving
the performance of the model on Chinese financial texts. Through comparative
experiments with advanced models such as Synchronous Double-channel Recurrent
Network (SDRN) and Grid Tagging Scheme (GTS), the proposed GCGTS model
demonstrates significant improvements in performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02122">ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP. (arXiv:2308.02122v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1">Lu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_G/0/1/0/all/0/1">Guanhong Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaiyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_G/0/1/0/all/0/1">Guangyu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiangyu Zhang</a></p>
<p>Backdoor attacks have emerged as a prominent threat to natural language
processing (NLP) models, where the presence of specific triggers in the input
can lead poisoned models to misclassify these inputs to predetermined target
classes. Current detection mechanisms are limited by their inability to address
more covert backdoor strategies, such as style-based attacks. In this work, we
propose an innovative test-time poisoned sample detection framework that hinges
on the interpretability of model predictions, grounded in the semantic meaning
of inputs. We contend that triggers (e.g., infrequent words) are not supposed
to fundamentally alter the underlying semantic meanings of poisoned samples as
they want to stay stealthy. Based on this observation, we hypothesize that
while the model's predictions for paraphrased clean samples should remain
stable, predictions for poisoned samples should revert to their true labels
upon the mutations applied to triggers during the paraphrasing process. We
employ ChatGPT, a state-of-the-art large language model, as our paraphraser and
formulate the trigger-removal task as a prompt engineering problem. We adopt
fuzzing, a technique commonly used for unearthing software vulnerabilities, to
discover optimal paraphrase prompts that can effectively eliminate triggers
while concurrently maintaining input semantics. Experiments on 4 types of
backdoor attacks, including the subtle style backdoors, and 4 distinct datasets
demonstrate that our approach surpasses baseline methods, including STRIP, RAP,
and ONION, in precision and recall.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02142">Tweet Insights: A Visualization Platform to Extract Temporal Insights from Twitter. (arXiv:2308.02142v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Loureiro_D/0/1/0/all/0/1">Daniel Loureiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezaee_K/0/1/0/all/0/1">Kiamehr Rezaee</a>, <a href="http://arxiv.org/find/cs/1/au:+Riahi_T/0/1/0/all/0/1">Talayeh Riahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Barbieri_F/0/1/0/all/0/1">Francesco Barbieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Neves_L/0/1/0/all/0/1">Leonardo Neves</a>, <a href="http://arxiv.org/find/cs/1/au:+Anke_L/0/1/0/all/0/1">Luis Espinosa Anke</a>, <a href="http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1">Jose Camacho-Collados</a></p>
<p>This paper introduces a large collection of time series data derived from
Twitter, postprocessed using word embedding techniques, as well as specialized
fine-tuned language models. This data comprises the past five years and
captures changes in n-gram frequency, similarity, sentiment and topic
distribution. The interface built on top of this data enables temporal analysis
for detecting and characterizing shifts in meaning, including complementary
information to trending metrics, such as sentiment and topic association over
time. We release an online demo for easy experimentation, and we share code and
the underlying aggregated data for future work. In this paper, we also discuss
three case studies unlocked thanks to our platform, showcasing its potential
for temporal linguistic analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02151">Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization. (arXiv:2308.02151v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1">Weiran Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Heinecke_S/0/1/0/all/0/1">Shelby Heinecke</a>, <a href="http://arxiv.org/find/cs/1/au:+Niebles_J/0/1/0/all/0/1">Juan Carlos Niebles</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yihao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1">Le Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Murthy_R/0/1/0/all/0/1">Rithesh Murthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeyuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianguo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1">Devansh Arpit</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ran Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mui_P/0/1/0/all/0/1">Phil Mui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a></p>
<p>Recent months have seen the emergence of a powerful new trend in which large
language models (LLMs) are augmented to become autonomous language agents
capable of performing objective oriented multi-step tasks on their own, rather
than merely responding to queries from human users. Most existing language
agents, however, are not optimized using environment-specific rewards. Although
some agents enable iterative refinement through verbal feedback, they do not
reason and plan in ways that are compatible with gradient-based learning from
rewards. This paper introduces a principled framework for reinforcing large
language agents by learning a retrospective model, which automatically tunes
the language agent prompts from environment feedback through policy gradient.
Specifically, our proposed agent architecture learns from rewards across
multiple environments and tasks, for fine-tuning a pre-trained language model
which refines the language agent prompt by summarizing the root cause of prior
failed attempts and proposing action plans. Experimental results on various
tasks demonstrate that the language agents improve over time and that our
approach considerably outperforms baselines that do not properly leverage
gradients from the environment. This demonstrates that using policy gradient
optimization to improve language agents, for which we believe our work is one
of the first, seems promising and can be applied to optimize other models in
the agent architecture to enhance agent performances over time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02160">Speaker Diarization of Scripted Audiovisual Content. (arXiv:2308.02160v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Virkar_Y/0/1/0/all/0/1">Yogesh Virkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Thompson_B/0/1/0/all/0/1">Brian Thompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Paturi_R/0/1/0/all/0/1">Rohit Paturi</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Sundararajan Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Federico_M/0/1/0/all/0/1">Marcello Federico</a></p>
<p>The media localization industry usually requires a verbatim script of the
final film or TV production in order to create subtitles or dubbing scripts in
a foreign language. In particular, the verbatim script (i.e. as-broadcast
script) must be structured into a sequence of dialogue lines each including
time codes, speaker name and transcript. Current speech recognition technology
alleviates the transcription step. However, state-of-the-art speaker
diarization models still fall short on TV shows for two main reasons: (i) their
inability to track a large number of speakers, (ii) their low accuracy in
detecting frequent speaker changes. To mitigate this problem, we present a
novel approach to leverage production scripts used during the shooting process,
to extract pseudo-labeled data for the speaker diarization task. We propose a
novel semi-supervised approach and demonstrate improvements of 51.7% relative
to two unsupervised baseline models on our metrics on a 66 show test set.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02168">You talk what you read: Understanding News Comment Behavior by Dispositional and Situational Attribution. (arXiv:2308.02168v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuhang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuxiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1">Dongyuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1">Jitao Sang</a></p>
<p>Many news comment mining studies are based on the assumption that comment is
explicitly linked to the corresponding news. In this paper, we observed that
users' comments are also heavily influenced by their individual characteristics
embodied by the interaction history. Therefore, we position to understand news
comment behavior by considering both the dispositional factors from news
interaction history, and the situational factors from corresponding news. A
three-part encoder-decoder framework is proposed to model the generative
process of news comment. The resultant dispositional and situational
attribution contributes to understanding user focus and opinions, which are
validated in applications of reader-aware news summarization and news
aspect-opinion forecasting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02180">Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology. (arXiv:2308.02180v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1">Cliff Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Sheng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yu Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moung_C/0/1/0/all/0/1">Christine Moung</a>, <a href="http://arxiv.org/find/cs/1/au:+Abel_J/0/1/0/all/0/1">Jacob Abel</a>, <a href="http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1">Naoto Usuyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Weerasinghe_R/0/1/0/all/0/1">Roshanthi Weerasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Piening_B/0/1/0/all/0/1">Brian Piening</a>, <a href="http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1">Tristan Naumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bifulco_C/0/1/0/all/0/1">Carlo Bifulco</a>, <a href="http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1">Hoifung Poon</a></p>
<p>Clinical trial matching is a key process in health delivery and discovery. In
practice, it is plagued by overwhelming unstructured data and unscalable manual
processing. In this paper, we conduct a systematic study on scaling clinical
trial matching using large language models (LLMs), with oncology as the focus
area. Our study is grounded in a clinical trial matching system currently in
test deployment at a large U.S. health network. Initial findings are promising:
out of box, cutting-edge LLMs, such as GPT-4, can already structure elaborate
eligibility criteria of clinical trials and extract complex matching logic
(e.g., nested AND/OR/NOT). While still far from perfect, LLMs substantially
outperform prior strong baselines and may serve as a preliminary solution to
help triage patient-trial candidates with humans in the loop. Our study also
reveals a few significant growth areas for applying LLMs to end-to-end clinical
trial matching, such as context limitation and accuracy, especially in
structuring patient information from longitudinal medical records.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02185">From Fake to Hyperpartisan News Detection Using Domain Adaptation. (arXiv:2308.02185v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Smadu_R/0/1/0/all/0/1">R&#x103;zvan-Alexandru Sm&#x103;du</a>, <a href="http://arxiv.org/find/cs/1/au:+Echim_S/0/1/0/all/0/1">Sebastian-Vasile Echim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cercel_D/0/1/0/all/0/1">Dumitru-Clementin Cercel</a>, <a href="http://arxiv.org/find/cs/1/au:+Marin_I/0/1/0/all/0/1">Iuliana Marin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pop_F/0/1/0/all/0/1">Florin Pop</a></p>
<p>Unsupervised Domain Adaptation (UDA) is a popular technique that aims to
reduce the domain shift between two data distributions. It was successfully
applied in computer vision and natural language processing. In the current
work, we explore the effects of various unsupervised domain adaptation
techniques between two text classification tasks: fake and hyperpartisan news
detection. We investigate the knowledge transfer from fake to hyperpartisan
news detection without involving target labels during training. Thus, we
evaluate UDA, cluster alignment with a teacher, and cross-domain contrastive
learning. Extensive experiments show that these techniques improve performance,
while including data augmentation further enhances the results. In addition, we
combine clustering and topic modeling algorithms with UDA, resulting in
improved performances compared to the initial UDA setup.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02190">Emo-DNA: Emotion Decoupling and Alignment Learning for Cross-Corpus Speech Emotion Recognition. (arXiv:2308.02190v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jiaxin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yujie Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1">Xin-Cheng Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chenglong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhizhong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kunhong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1">Hongming Shan</a></p>
<p>Cross-corpus speech emotion recognition (SER) seeks to generalize the ability
of inferring speech emotion from a well-labeled corpus to an unlabeled one,
which is a rather challenging task due to the significant discrepancy between
two corpora. Existing methods, typically based on unsupervised domain
adaptation (UDA), struggle to learn corpus-invariant features by global
distribution alignment, but unfortunately, the resulting features are mixed
with corpus-specific features or not class-discriminative. To tackle these
challenges, we propose a novel Emotion Decoupling aNd Alignment learning
framework (EMO-DNA) for cross-corpus SER, a novel UDA method to learn
emotion-relevant corpus-invariant features. The novelties of EMO-DNA are
two-fold: contrastive emotion decoupling and dual-level emotion alignment. On
one hand, our contrastive emotion decoupling achieves decoupling learning via a
contrastive decoupling loss to strengthen the separability of emotion-relevant
features from corpus-specific ones. On the other hand, our dual-level emotion
alignment introduces an adaptive threshold pseudo-labeling to select confident
target samples for class-level alignment, and performs corpus-level alignment
to jointly guide model for learning class-discriminative corpus-invariant
features across corpora. Extensive experimental results demonstrate the
superior performance of EMO-DNA over the state-of-the-art methods in several
cross-corpus scenarios. Source code is available at
https://github.com/Jiaxin-Ye/Emo-DNA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02193">Explaining Relation Classification Models with Semantic Extents. (arXiv:2308.02193v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kloser_L/0/1/0/all/0/1">Lars Kl&#xf6;ser</a>, <a href="http://arxiv.org/find/cs/1/au:+Busgen_A/0/1/0/all/0/1">Andre B&#xfc;sgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohl_P/0/1/0/all/0/1">Philipp Kohl</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraft_B/0/1/0/all/0/1">Bodo Kraft</a>, <a href="http://arxiv.org/find/cs/1/au:+Zundorf_A/0/1/0/all/0/1">Albert Z&#xfc;ndorf</a></p>
<p>In recent years, the development of large pretrained language models, such as
BERT and GPT, significantly improved information extraction systems on various
tasks, including relation classification. State-of-the-art systems are highly
accurate on scientific benchmarks. A lack of explainability is currently a
complicating factor in many real-world applications. Comprehensible systems are
necessary to prevent biased, counterintuitive, or harmful decisions.
</p>
<p>We introduce semantic extents, a concept to analyze decision patterns for the
relation classification task. Semantic extents are the most influential parts
of texts concerning classification decisions. Our definition allows similar
procedures to determine semantic extents for humans and models. We provide an
annotation tool and a software framework to determine semantic extents for
humans and models conveniently and reproducibly. Comparing both reveals that
models tend to learn shortcut patterns from data. These patterns are hard to
detect with current interpretability methods, such as input reductions. Our
approach can help detect and eliminate spurious decision patterns during model
development. Semantic extents can increase the reliability and security of
natural language processing systems. Semantic extents are an essential step in
enabling applications in critical areas like healthcare or finance. Moreover,
our work opens new research directions for developing methods to explain deep
learning models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02199">A Survey of Spanish Clinical Language Models. (arXiv:2308.02199v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Subies_G/0/1/0/all/0/1">Guillem Garc&#xed;a Subies</a>, <a href="http://arxiv.org/find/cs/1/au:+Jimenez_A/0/1/0/all/0/1">&#xc1;lvaro Barbero Jim&#xe9;nez</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_P/0/1/0/all/0/1">Paloma Mart&#xed;nez Fern&#xe1;ndez</a></p>
<p>This survey focuses in encoder Language Models for solving tasks in the
clinical domain in the Spanish language. We review the contributions of 17
corpora focused mainly in clinical tasks, then list the most relevant Spanish
Language Models and Spanish Clinical Language models. We perform a thorough
comparison of these models by benchmarking them over a curated subset of the
available corpora, in order to find the best-performing ones; in total more
than 3000 models were fine-tuned for this study. All the tested corpora and the
best models are made publically available in an accessible way, so that the
results can be reproduced by independent teams or challenged in the future when
new Spanish Clinical Language models are created.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02223">ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. (arXiv:2308.02223v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chenglong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yimin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1">Yifu Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongran Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">Tong Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jingbo Zhu</a></p>
<p>Applying Reinforcement Learning (RL) to sequence generation models enables
the direct optimization of long-term rewards (\textit{e.g.,} BLEU and human
feedback), but typically requires large-scale sampling over a space of action
sequences. This is a computational challenge as presented by the practice of
sequence generation problems, such as machine translation, where we often deal
with a large action space (\textit{e.g.,} a vocabulary) and a long action
sequence (\textit{e.g.,} a translation). In this work, we introduce two-stage
sampling and dynamic sampling approaches to improve the sampling efficiency
during training sequence generation models via RL. We experiment with our
approaches on the traditional sequence generation tasks, including machine
translation and abstractive summarization. Furthermore, we evaluate our
approaches in RL from human feedback (RLHF) through training a large language
model using the reward model. Experimental results show that the efficient
sampling-based RL, referred to as ESRL, can outperform all baselines in terms
of both training efficiency and memory consumption. Notably, ESRL yields
consistent performance gains over the strong REINFORCE, minimum risk training,
and proximal policy optimization methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02226">Learning to Paraphrase Sentences to Different Complexity Levels. (arXiv:2308.02226v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chi_A/0/1/0/all/0/1">Alison Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li-Kuang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yi-Chen Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Shu-Hui Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1">Jason S. Chang</a></p>
<p>While sentence simplification is an active research topic in NLP, its
adjacent tasks of sentence complexification and same-level paraphrasing are
not. To train models on all three tasks, we present two new unsupervised
datasets. We compare these datasets, one labeled by a weak classifier and the
other by a rule-based approach, with a single supervised dataset. Using these
three datasets for training, we perform extensive experiments on both
multitasking and prompting strategies. Compared to other systems trained on
unsupervised parallel data, models trained on our weak classifier labeled
dataset achieve state-of-the-art performance on the ASSET simplification
benchmark. Our models also outperform previous work on sentence level
targeting. Finally, we establish how a handful of Large Language Models perform
on these tasks under a zero-shot setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02234">Sinhala-English Parallel Word Dictionary Dataset. (arXiv:2308.02234v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wickramasinghe_K/0/1/0/all/0/1">Kasun Wickramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_N/0/1/0/all/0/1">Nisansa de Silva</a></p>
<p>Parallel datasets are vital for performing and evaluating any kind of
multilingual task. However, in the cases where one of the considered language
pairs is a low-resource language, the existing top-down parallel data such as
corpora are lacking in both tally and quality due to the dearth of human
annotation. Therefore, for low-resource languages, it is more feasible to move
in the bottom-up direction where finer granular pairs such as dictionary
datasets are developed first. They may then be used for mid-level tasks such as
supervised multilingual word embedding alignment. These in turn can later guide
higher-level tasks in the order of aligning sentence or paragraph text corpora
used for Machine Translation (MT). Even though more approachable than
generating and aligning a massive corpus for a low-resource language, for the
same reason of apathy from larger research entities, even these finer granular
data sets are lacking for some low-resource languages. We have observed that
there is no free and open dictionary data set for the low-resource language,
Sinhala. Thus, in this work, we introduce three parallel English-Sinhala word
dictionaries (En-Si-dict-large, En-Si-dict-filtered, En-Si-dict-FastText) which
help in multilingual Natural Language Processing (NLP) tasks related to English
and Sinhala languages. In this paper, we explain the dataset creation pipeline
as well as the experimental results of the tests we have carried out to verify
the quality of the data sets. The data sets and the related scripts are
available at https://github.com/kasunw22/sinhala-para-dict.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02263">Efficient Monaural Speech Enhancement using Spectrum Attention Fusion. (arXiv:2308.02263v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1">Jinyu Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jetic G&#x16b;</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_B/0/1/0/all/0/1">Binhao Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhibo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1">Ping Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junli Li</a></p>
<p>Speech enhancement is a demanding task in automated speech processing
pipelines, focusing on separating clean speech from noisy channels. Transformer
based models have recently bested RNN and CNN models in speech enhancement,
however at the same time they are much more computationally expensive and
require much more high quality training data, which is always hard to come by.
In this paper, we present an improvement for speech enhancement models that
maintains the expressiveness of self-attention while significantly reducing
model complexity, which we have termed Spectrum Attention Fusion. We carefully
construct a convolutional module to replace several self-attention layers in a
speech Transformer, allowing the model to more efficiently fuse spectral
features. Our proposed model is able to achieve comparable or better results
against SOTA models but with significantly smaller parameters (0.58M) on the
Voice Bank + DEMAND dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02270">Redundancy Aware Multi-Reference Based Gainwise Evaluation of Extractive Summarization. (arXiv:2308.02270v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Akter_M/0/1/0/all/0/1">Mousumi Akter</a>, <a href="http://arxiv.org/find/cs/1/au:+Santu_S/0/1/0/all/0/1">Shubhra Kanti Karmaker Santu</a></p>
<p>While very popular for evaluating extractive summarization task, the ROUGE
metric has long been criticized for its lack of semantic awareness and its
ignorance about the ranking quality of the summarizer. Thanks to previous
research that has addressed these issues by proposing a gain-based automated
metric called Sem-nCG, which is both rank and semantic aware. However, Sem-nCG
does not consider the amount of redundancy present in a model-generated summary
and currently does not support evaluation with multiple reference summaries.
Unfortunately, addressing both these limitations simultaneously is not trivial.
Therefore, in this paper, we propose a redundancy-aware Sem-nCG metric and
demonstrate how this new metric can be used to evaluate model summaries against
multiple references. We also explore different ways of incorporating redundancy
into the original metric through extensive experiments. Experimental results
demonstrate that the new redundancy-aware metric exhibits a higher correlation
with human judgments than the original Sem-nCG metric for both single and
multiple reference scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02294">Learning to Select the Relevant History Turns in Conversational Question Answering. (arXiv:2308.02294v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zaib_M/0/1/0/all/0/1">Munazza Zaib</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Emma Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1">Quan Z. Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sagar_S/0/1/0/all/0/1">Subhash Sagar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1">Adnan Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a></p>
<p>The increasing demand for the web-based digital assistants has given a rapid
rise in the interest of the Information Retrieval (IR) community towards the
field of conversational question answering (ConvQA). However, one of the
critical aspects of ConvQA is the effective selection of conversational history
turns to answer the question at hand. The dependency between relevant history
selection and correct answer prediction is an intriguing but under-explored
area. The selected relevant context can better guide the system so as to where
exactly in the passage to look for an answer. Irrelevant context, on the other
hand, brings noise to the system, thereby resulting in a decline in the model's
performance. In this paper, we propose a framework, DHS-ConvQA (Dynamic History
Selection in Conversational Question Answering), that first generates the
context and question entities for all the history turns, which are then pruned
on the basis of similarity they share in common with the question at hand. We
also propose an attention-based mechanism to re-rank the pruned terms based on
their calculated weights of how useful they are in answering the question. In
the end, we further aid the model by highlighting the terms in the re-ranked
conversational history using a binary classification task and keeping the
useful terms (predicted as 1) and ignoring the irrelevant terms (predicted as
0). We demonstrate the efficacy of our proposed framework with extensive
experimental results on CANARD and QuAC -- the two popularly utilized datasets
in ConvQA. We demonstrate that selecting relevant turns works better than
rewriting the original question. We also investigate how adding the irrelevant
history turns negatively impacts the model's performance and discuss the
research challenges that demand more attention from the IR community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02323">Dataflow Dialogue Generation. (arXiv:2308.02323v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meron_J/0/1/0/all/0/1">Joram Meron</a>, <a href="http://arxiv.org/find/cs/1/au:+Guimaraes_V/0/1/0/all/0/1">Victor Guimar&#xe3;es</a></p>
<p>We demonstrate task-oriented dialogue generation within the dataflow dialogue
paradigm. We show an example of agenda driven dialogue generation for the
MultiWOZ domain, and an example of generation without an agenda for the
SMCalFlow domain, where we show an improvement in the accuracy of the
translation of user requests to dataflow expressions when the generated
dialogues are used to augment the translation training dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02357">Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text. (arXiv:2308.02357v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1">Nandana Mihindukulasooriya</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_S/0/1/0/all/0/1">Sanju Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Enguix_C/0/1/0/all/0/1">Carlos F. Enguix</a>, <a href="http://arxiv.org/find/cs/1/au:+Lata_K/0/1/0/all/0/1">Kusum Lata</a></p>
<p>The recent advances in large language models (LLM) and foundation models with
emergent capabilities have been shown to improve the performance of many NLP
tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs
can be used for KG construction or completion while existing KGs can be used
for different tasks such as making LLM outputs explainable or fact-checking in
Neuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to
evaluate the capabilities of language models to generate KGs from natural
language text guided by an ontology. Given an input ontology and a set of
sentences, the task is to extract facts from the text while complying with the
given ontology (concepts, relations, domain/range constraints) and being
faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen
with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19
ontologies and 4,860 sentences. We define seven evaluation metrics to measure
fact extraction performance, ontology conformance, and hallucinations by LLMs.
Furthermore, we provide results for two baseline models, Vicuna-13B and
Alpaca-LoRA-13B using automatic prompt generation from test cases. The baseline
results show that there is room for improvement using both Semantic Web and
Natural Language Processing techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02432">Performance of Large Language Models in a Computer Science Degree Program. (arXiv:2308.02432v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kruger_T/0/1/0/all/0/1">Tim Kr&#xfc;ger</a>, <a href="http://arxiv.org/find/cs/1/au:+Gref_M/0/1/0/all/0/1">Michael Gref</a></p>
<p>Large language models such as ChatGPT-3.5 and GPT-4.0 are ubiquitous and
dominate the current discourse. Their transformative capabilities have led to a
paradigm shift in how we interact with and utilize (text-based) information.
Each day, new possibilities to leverage the capabilities of these models
emerge. This paper presents findings on the performance of different large
language models in a university of applied sciences' undergraduate computer
science degree program. Our primary objective is to assess the effectiveness of
these models within the curriculum by employing them as educational aids. By
prompting the models with lecture material, exercise tasks, and past exams, we
aim to evaluate their proficiency across different computer science domains. We
showcase the strong performance of current large language models while
highlighting limitations and constraints within the context of such a degree
program. We found that ChatGPT-3.5 averaged 79.9% of the total score in 10
tested modules, BingAI achieved 68.4%, and LLaMa, in the 65 billion parameter
variant, 20%. Despite these convincing results, even GPT-4.0 would not pass the
degree program - due to limitations in mathematical calculations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02448">From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence. (arXiv:2308.02448v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1">David Oniani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilsman_J/0/1/0/all/0/1">Jordan Hilsman</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yifan Peng</a>, COL (Ret.) <a href="http://arxiv.org/find/cs/1/au:+Poropatich_R/0/1/0/all/0/1">Ronald K. Poropatich</a>, <a href="http://arxiv.org/find/cs/1/au:+Pamplin_C/0/1/0/all/0/1">COL Jeremy C. Pamplin</a>, <a href="http://arxiv.org/find/cs/1/au:+Legault_L/0/1/0/all/0/1">LTC Gary L. Legault</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanshan Wang</a></p>
<p>In 2020, the U.S. Department of Defense officially disclosed a set of ethical
principles to guide the use of Artificial Intelligence (AI) technologies on
future battlefields. Despite stark differences, there are core similarities
between the military and medical service. Warriors on battlefields often face
life-altering circumstances that require quick decision-making. Medical
providers experience similar challenges in a rapidly changing healthcare
environment, such as in the emergency department or during surgery treating a
life-threatening condition. Generative AI, an emerging technology designed to
efficiently generate valuable information, holds great promise. As computing
power becomes more accessible and the abundance of health data, such as
electronic health records, electrocardiograms, and medical images, increases,
it is inevitable that healthcare will be revolutionized by this technology.
Recently, generative AI has captivated the research community, leading to
debates about its application in healthcare, mainly due to concerns about
transparency and related issues. Meanwhile, concerns about the potential
exacerbation of health disparities due to modeling biases have raised notable
ethical concerns regarding the use of this technology in healthcare. However,
the ethical principles for generative AI in healthcare have been understudied,
and decision-makers often fail to consider the significance of generative AI.
In this paper, we propose GREAT PLEA ethical principles, encompassing
governance, reliability, equity, accountability, traceability, privacy,
lawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to
proactively address the ethical dilemmas and challenges posed by the
integration of generative AI in healthcare.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02463">Towards Generalist Foundation Model for Radiology. (arXiv:2308.02463v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chaoyi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoman Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ya Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Weidi Xie</a></p>
<p>In this study, we aim to initiate the development of Radiology Foundation
Model, termed as RadFM.We consider the construction of foundational models from
the perspectives of data, model design, and evaluation thoroughly. Our
contribution can be concluded as follows: (i), we construct a large-scale
Medical Multi-modal Dataset, MedMD, consisting of 16M 2D and 3D medical scans.
To the best of our knowledge, this is the first multi-modal dataset containing
3D medical scans. (ii), We propose an architecture that enables visually
conditioned generative pre-training, allowing for the integration of text input
interleaved with 2D or 3D medical scans to generate response for diverse
radiologic tasks. The model was initially pre-trained on MedMD and subsequently
domain-specific fine-tuned on RadMD, a radiologic cleaned version of MedMD,
containing 3M radiologic visual-language pairs. (iii), we propose a new
evaluation benchmark that comprises five tasks, aiming to comprehensively
assess the capability of foundation models in handling practical clinical
problems. Our experimental results confirm that RadFM significantly outperforms
existing multi-modal foundation models. The codes, data, and model checkpoint
will all be made publicly available to promote further research and development
in the field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02482">Adapting the NICT-JLE Corpus for Disfluency Detection Models. (arXiv:2308.02482v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Skidmore_L/0/1/0/all/0/1">Lucy Skidmore</a>, <a href="http://arxiv.org/find/cs/1/au:+Moore_R/0/1/0/all/0/1">Roger K. Moore</a></p>
<p>The detection of disfluencies such as hesitations, repetitions and false
starts commonly found in speech is a widely studied area of research. With a
standardised process for evaluation using the Switchboard Corpus, model
performance can be easily compared across approaches. This is not the case for
disfluency detection research on learner speech, however, where such datasets
have restricted access policies, making comparison and subsequent development
of improved models more challenging. To address this issue, this paper
describes the adaptation of the NICT-JLE corpus, containing approximately 300
hours of English learners' oral proficiency tests, to a format that is suitable
for disfluency detection model training and evaluation. Points of difference
between the NICT-JLE and Switchboard corpora are explored, followed by a
detailed overview of adaptations to the tag set and meta-features of the
NICT-JLE corpus. The result of this work provides a standardised train, heldout
and test set for use in future research on disfluency detection for learner
speech.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02490">MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1">Weihao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhengyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kevin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinchao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a></p>
<p>We propose MM-Vet, an evaluation benchmark that examines large multimodal
models (LMMs) on complicated multimodal tasks. Recent LMMs have shown various
intriguing abilities, such as solving math problems written on the blackboard,
reasoning about events and celebrities in news images, and explaining visual
jokes. Rapid model advancements pose challenges to evaluation benchmark
development. Problems include: (1) How to systematically structure and evaluate
the complicated multimodal tasks; (2) How to design evaluation metrics that
work well across question and answer types; and (3) How to give model insights
beyond a simple performance ranking. To this end, we present MM-Vet, designed
based on the insight that the intriguing ability to solve complicated tasks is
often achieved by a generalist model being able to integrate different core
vision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and
examines the 16 integrations of interest derived from the capability
combination. For evaluation metrics, we propose an LLM-based evaluator for
open-ended outputs. The evaluator enables the evaluation across different
question types and answer styles, resulting in a unified scoring metric. We
evaluate representative LMMs on MM-Vet, providing insights into the
capabilities of different LMM system paradigms and models. Code and data are
available at https://github.com/yuweihao/MM-Vet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2204.03251">Automatic WordNet Construction using Word Sense Induction through Sentence Embeddings. (arXiv:2204.03251v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Velasco_D/0/1/0/all/0/1">Dan John Velasco</a>, <a href="http://arxiv.org/find/cs/1/au:+Alba_A/0/1/0/all/0/1">Axel Alba</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelagio_T/0/1/0/all/0/1">Trisha Gail Pelagio</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramirez_B/0/1/0/all/0/1">Bryce Anthony Ramirez</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1">Jan Christian Blaise Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Charibeth Cheng</a></p>
<p>Language resources such as wordnets remain indispensable tools for different
natural language tasks and applications. However, for low-resource languages
such as Filipino, existing wordnets are old and outdated, and producing new
ones may be slow and costly in terms of time and resources. In this paper, we
propose an automatic method for constructing a wordnet from scratch using only
an unlabeled corpus and a sentence embeddings-based language model. Using this,
we produce FilWordNet, a new wordnet that supplants and improves the outdated
Filipino WordNet. We evaluate our automatically-induced senses and synsets by
matching them with senses from the Princeton WordNet, as well as comparing the
synsets to the old Filipino WordNet. We empirically show that our method can
induce existing, as well as potentially new, senses and synsets automatically
without the need for human supervision.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.09196">Emergent Analogical Reasoning in Large Language Models. (arXiv:2212.09196v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Webb_T/0/1/0/all/0/1">Taylor Webb</a>, <a href="http://arxiv.org/find/cs/1/au:+Holyoak_K/0/1/0/all/0/1">Keith J. Holyoak</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Hongjing Lu</a></p>
<p>The recent advent of large language models has reinvigorated debate over
whether human cognitive capacities might emerge in such generic models given
sufficient training data. Of particular interest is the ability of these models
to reason about novel problems zero-shot, without any direct training. In human
cognition, this capacity is closely tied to an ability to reason by analogy.
Here, we performed a direct comparison between human reasoners and a large
language model (the text-davinci-003 variant of GPT-3) on a range of analogical
tasks, including a non-visual matrix reasoning task based on the rule structure
of Raven's Standard Progressive Matrices. We found that GPT-3 displayed a
surprisingly strong capacity for abstract pattern induction, matching or even
surpassing human capabilities in most settings; preliminary tests of GPT-4
indicated even better performance. Our results indicate that large language
models such as GPT-3 have acquired an emergent ability to find zero-shot
solutions to a broad range of analogy problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.07992">Can ChatGPT Replace Traditional KBQA Models? An In-depth Analysis of GPT family LLMs&#x27; Question Answering Performance. (arXiv:2303.07992v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1">Yiming Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_D/0/1/0/all/0/1">Dehai Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenbo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_N/0/1/0/all/0/1">Nan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yongrui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1">Guilin Qi</a></p>
<p>ChatGPT is a powerful large language model (LLM) that covers knowledge
resources such as Wikipedia and supports natural language question answering
using its own knowledge. Therefore, there is growing interest in exploring
whether ChatGPT can replace traditional knowledge-based question answering
(KBQA) models. Although there have been some works analyzing the question
answering performance of ChatGPT, there is still a lack of large-scale,
comprehensive testing of various types of complex questions to analyze the
limitations of the model. In this paper, we present a framework that follows
the black-box testing specifications of CheckList proposed by Ribeiro et. al.
We evaluate ChatGPT and its family of LLMs on eight real-world KB-based complex
question answering datasets, which include six English datasets and two
multilingual datasets. The total number of test cases is approximately 190,000.
In addition to the GPT family of LLMs, we also evaluate the well-known FLAN-T5
to identify commonalities between the GPT family and other LLMs. The dataset
and code are available at
https://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-GPT-family.git
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.13035">SPeC: A Soft Prompt-Based Calibration on Performance Variability of Large Language Model in Clinical Notes Summarization. (arXiv:2303.13035v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yu-Neng Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Ruixiang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoqian Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a></p>
<p>Electronic health records (EHRs) store an extensive array of patient
information, encompassing medical histories, diagnoses, treatments, and test
outcomes. These records are crucial for enabling healthcare providers to make
well-informed decisions regarding patient care. Summarizing clinical notes
further assists healthcare professionals in pinpointing potential health risks
and making better-informed decisions. This process contributes to reducing
errors and enhancing patient outcomes by ensuring providers have access to the
most pertinent and current patient data. Recent research has shown that
incorporating prompts with large language models (LLMs) substantially boosts
the efficacy of summarization tasks. However, we show that this approach also
leads to increased output variance, resulting in notably divergent outputs even
when prompts share similar meanings. To tackle this challenge, we introduce a
model-agnostic Soft Prompt-Based Calibration (SPeC) pipeline that employs soft
prompts to diminish variance while preserving the advantages of prompt-based
summarization. Experimental findings on multiple clinical note tasks and LLMs
indicate that our method not only bolsters performance but also effectively
curbs variance for various LLMs, providing a more uniform and dependable
solution for summarizing vital medical information.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.16537">LMExplainer: a Knowledge-Enhanced Explainer for Language Models. (arXiv:2303.16537v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zichen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Ambuj K Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sra_M/0/1/0/all/0/1">Misha Sra</a></p>
<p>Large language models (LLMs) such as GPT-4 are very powerful and can process
different kinds of natural language processing (NLP) tasks. However, it can be
difficult to interpret the results due to the multi-layer nonlinear model
structure and millions of parameters. A lack of clarity and understanding of
how the language models (LMs) work can make them unreliable, difficult to
trust, and potentially dangerous for use in real-world scenarios. Most recent
works exploit attention weights to provide explanations for LM predictions.
However, pure attention-based explanations are unable to support the growing
complexity of LMs, and cannot reason about their decision-making processes. We
propose LMExplainer, a knowledge-enhanced explainer for LMs that can provide
human-understandable explanations. We use a knowledge graph (KG) and a graph
attention neural network to extract the key decision signals of the LM. We
further explore whether interpretation can also help the AI understand the task
better. Our experimental results show that LMExplainer outperforms existing
LM+KG methods on CommonsenseQA and OpenBookQA. We compare the explanation
results with generated explanation methods and human-annotated results. The
comparison shows our method can provide more comprehensive and clearer
explanations. LMExplainer demonstrates the potential to enhance model
performance and furnish explanations for the LM reasoning process in natural
language.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.17910">Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation. (arXiv:2303.17910v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Min Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1">Yu Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chengqi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shujian Huang</a></p>
<p>Benefiting from the sequence-level knowledge distillation, the
Non-Autoregressive Transformer (NAT) achieves great success in neural machine
translation tasks. However, existing knowledge distillation has side effects,
such as propagating errors from the teacher to NAT students, which may limit
further improvements of NAT models and are rarely discussed in existing
research. In this paper, we introduce selective knowledge distillation by
introducing an NAT evaluator to select NAT-friendly targets that are of high
quality and easy to learn. In addition, we introduce a simple yet effective
progressive distillation method to boost NAT performance. Experiment results on
multiple WMT language directions and several representative NAT models show
that our approach can realize a flexible trade-off between the quality and
complexity of training data for NAT models, achieving strong performances.
Further analysis shows that distilling only 5% of the raw translations can help
an NAT outperform its counterpart trained on raw data by about 2.4 BLEU.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.12680">G3Detector: General GPT-Generated Text Detector. (arXiv:2305.12680v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1">Haolan Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuanli He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiongkai Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuxiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stenetorp_P/0/1/0/all/0/1">Pontus Stenetorp</a></p>
<p>The burgeoning progress in the field of Large Language Models (LLMs) heralds
significant benefits due to their unparalleled capacities. However, it is
critical to acknowledge the potential misuse of these models, which could give
rise to a spectrum of social and ethical dilemmas. Despite numerous preceding
efforts centered around distinguishing synthetic text, most existing detection
systems fail to identify data synthesized by the latest LLMs, such as ChatGPT
and GPT-4. In response to this challenge, we introduce an unpretentious yet
potent detection approach proficient in identifying synthetic text across a
wide array of fields. Moreover, our detector demonstrates outstanding
performance uniformly across various model architectures and decoding
strategies. It also possesses the capability to identify text generated
utilizing a potent detection-evasion technique. Our comprehensive research
underlines our commitment to boosting the robustness and efficiency of
machine-generated text detection mechanisms, particularly in the context of
swiftly progressing and increasingly adaptive AI technologies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.18340">Mapping ChatGPT in Mainstream Media to Unravel Jobs and Diversity Challenges: Early Quantitative Insights through Sentiment Analysis and Word Frequency Analysis. (arXiv:2305.18340v2 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Karanouh_M/0/1/0/all/0/1">Maya Karanouh</a></p>
<p>The exponential growth in user acquisition and popularity of OpenAIs ChatGPT,
an artificial intelligence(AI) powered chatbot, was accompanied by widespread
mainstream media coverage. This article presents a quantitative data analysis
of the early trends and sentiments revealed by conducting text mining and NLP
methods onto a corpus of 10,902 mainstream news headlines related to the
subject of ChatGPT and artificial intelligence, from the launch of ChatGPT in
November 2022 to March 2023. The findings revealed in sentiment analysis,
ChatGPT and artificial intelligence, were perceived more positively than
negatively in the mainstream media. In regards to word frequency results, over
sixty-five percent of the top frequency words were focused on Big Tech issues
and actors while topics such as jobs, diversity, ethics, copyright, gender and
women were poorly represented or completely absent and only accounted for six
percent of the total corpus. This article is a critical analysis into the power
structures and collusions between Big Tech and Big Media in their hegemonic
exclusion of diversity and job challenges from mainstream media.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.19148">Mitigating Label Biases for In-context Learning. (arXiv:2305.19148v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fei_Y/0/1/0/all/0/1">Yu Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yifan Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1">Antoine Bosselut</a></p>
<p>Various design settings for in-context learning (ICL), such as the choice and
order of the in-context examples, can bias a model toward a particular
prediction without being reflective of an understanding of the task. While many
studies discuss these design choices, there have been few systematic
investigations into categorizing them and mitigating their impact. In this
work, we define a typology for three types of label biases in ICL for text
classification: vanilla-label bias, context-label bias, and domain-label bias
(which we conceptualize and detect for the first time).
</p>
<p>Our analysis demonstrates that prior label bias calibration methods fall
short of addressing all three types of biases. Specifically, domain-label bias
restricts LLMs to random-level performance on many tasks regardless of the
choice of in-context examples. To mitigate the effect of these biases, we
propose a simple bias calibration method that estimates a language model's
label bias using random in-domain words from the task corpus. After controlling
for this estimated bias when making predictions, our novel domain-context
calibration significantly improves the ICL performance of GPT-J and GPT-3 on a
wide range of tasks. The gain is substantial on tasks with large domain-label
bias (up to 37% in Macro-F1). Furthermore, our results generalize to models
with different scales, pretraining methods, and manually-designed task
instructions, showing the prevalence of label biases in ICL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.06548">Inductive reasoning in humans and large language models. (arXiv:2306.06548v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Simon J. Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ransom_K/0/1/0/all/0/1">Keith Ransom</a>, <a href="http://arxiv.org/find/cs/1/au:+Perfors_A/0/1/0/all/0/1">Andrew Perfors</a>, <a href="http://arxiv.org/find/cs/1/au:+Kemp_C/0/1/0/all/0/1">Charles Kemp</a></p>
<p>The impressive recent performance of large language models has led many to
wonder to what extent they can serve as models of general intelligence or are
similar to human cognition. We address this issue by applying GPT-3.5 and GPT-4
to a classic problem in human inductive reasoning known as property induction.
Over two experiments, we elicit human judgments on a range of property
induction tasks spanning multiple domains. Although GPT-3.5 struggles to
capture many aspects of human behaviour, GPT-4 is much more successful: for the
most part, its performance qualitatively matches that of humans, and the only
notable exception is its failure to capture the phenomenon of premise
non-monotonicity. Our work demonstrates that property induction allows for
interesting comparisons between human and machine intelligence and provides two
large datasets that can serve as benchmarks for future work in this vein.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00925">Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution. (arXiv:2307.00925v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Martinez_Gil_J/0/1/0/all/0/1">Jorge Martinez-Gil</a></p>
<p>Semantic similarity measures are widely used in natural language processing
to catalyze various computer-related tasks. However, no single semantic
similarity measure is the most appropriate for all tasks, and researchers often
use ensemble strategies to ensure performance. This research work proposes a
method for automatically designing semantic similarity ensembles. In fact, our
proposed method uses grammatical evolution, for the first time, to
automatically select and aggregate measures from a pool of candidates to create
an ensemble that maximizes correlation to human judgment. The method is
evaluated on several benchmark datasets and compared to state-of-the-art
ensembles, showing that it can significantly improve similarity assessment
accuracy and outperform existing methods in some cases. As a result, our
research demonstrates the potential of using grammatical evolution to
automatically compare text and prove the benefits of using ensembles for
semantic similarity tasks. The source code that illustrates our approach can be
downloaded from https://github.com/jorge-martinez-gil/sesige.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14850">Turkish Native Language Identification. (arXiv:2307.14850v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Uluslu_A/0/1/0/all/0/1">Ahmet Yavuz Uluslu</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_G/0/1/0/all/0/1">Gerold Schneider</a></p>
<p>In this paper, we present the first application of Native Language
Identification (NLI) for the Turkish language. NLI involves predicting the
writer's first language by analysing their writing in different languages.
While most NLI research has focused on English, our study extends its scope to
Turkish. We used the recently constructed Turkish Learner Corpus and employed a
combination of three syntactic features (CFG production rules, part-of-speech
n-grams, and function words) with L2 texts to demonstrate their effectiveness
in this task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01236">Grounded Image Text Matching with Mismatched Relation Reasoning. (arXiv:2308.01236v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yana Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haozhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sibei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuming He</a></p>
<p>This paper introduces Grounded Image Text Matching with Mismatched Relation
(GITM-MR), a novel visual-linguistic joint task that evaluates the relation
understanding capabilities of transformer-based pre-trained models. GITM-MR
requires a model to first determine if an expression describes an image, then
localize referred objects or ground the mismatched parts of the text. We
provide a benchmark for evaluating pre-trained models on this task, with a
focus on the challenging settings of limited data and out-of-distribution
sentence lengths. Our evaluation demonstrates that pre-trained models lack data
efficiency and length generalization ability. To address this, we propose the
Relation-sensitive Correspondence Reasoning Network (RCRN), which incorporates
relation-aware reasoning via bi-directional message propagation guided by
language structure. RCRN can be interpreted as a modular program and delivers
strong performance in both length generalization and data efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01404">Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models. (arXiv:2308.01404v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+OGara_A/0/1/0/all/0/1">Aidan O&#x27;Gara</a></p>
<p>Are current language models capable of deception and lie detection? We study
this question by introducing a text-based game called $\textit{Hoodwinked}$,
inspired by Mafia and Among Us. Players are locked in a house and must find a
key to escape, but one player is tasked with killing the others. Each time a
murder is committed, the surviving players have a natural language discussion
then vote to banish one player from the game. We conduct experiments with
agents controlled by GPT-3, GPT-3.5, and GPT-4 and find evidence of deception
and lie detection capabilities. The killer often denies their crime and accuses
others, leading to measurable effects on voting outcomes. More advanced models
are more effective killers, outperforming smaller models in 18 of 24 pairwise
comparisons. Secondary metrics provide evidence that this improvement is not
mediated by different actions, but rather by stronger persuasive skills during
discussions. To evaluate the ability of AI agents to deceive humans, we make
this game publicly available at h https://hoodwinked.ai/ .
</p>
</p>
</div>

    </div>
    </body>
    