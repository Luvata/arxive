<!DOCTYPE html>
<html>
<head>
<title>2024-01-24-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.10899">Concrete Problems in AI Safety, Revisited. (arXiv:2401.10899v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Raji_I/0/1/0/all/0/1">Inioluwa Deborah Raji</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobbe_R/0/1/0/all/0/1">Roel Dobbe</a></p>
<p>As AI systems proliferate in society, the AI community is increasingly
preoccupied with the concept of AI Safety, namely the prevention of failures
due to accidents that arise from an unanticipated departure of a system's
behavior from designer intent in AI deployment. We demonstrate through an
analysis of real world cases of such incidents that although current vocabulary
captures a range of the encountered issues of AI deployment, an expanded
socio-technical framing will be required for a more complete understanding of
how AI systems and implemented safety mechanisms fail and succeed in real life.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10904">A Review of Findings from Neuroscience and Cognitive Psychology as Possible Inspiration for the Path to Artificial General Intelligence. (arXiv:2401.10904v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Leon_F/0/1/0/all/0/1">Florin Leon</a></p>
<p>This review aims to contribute to the quest for artificial general
intelligence by examining neuroscience and cognitive psychology methods for
potential inspiration. Despite the impressive advancements achieved by deep
learning models in various domains, they still have shortcomings in abstract
reasoning and causal understanding. Such capabilities should be ultimately
integrated into artificial intelligence systems in order to surpass data-driven
limitations and support decision making in a way more similar to human
intelligence. This work is a vertical review that attempts a wide-ranging
exploration of brain function, spanning from lower-level biological neurons,
spiking neural networks, and neuronal ensembles to higher-level concepts such
as brain anatomy, vector symbolic architectures, cognitive and categorization
models, and cognitive architectures. The hope is that these concepts may offer
insights for solutions in artificial general intelligence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10910">Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior. (arXiv:2401.10910v1 [q-bio.NC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Toy_J/0/1/0/all/0/1">Jason Toy</a>, <a href="http://arxiv.org/find/q-bio/1/au:+MacAdam_J/0/1/0/all/0/1">Josh MacAdam</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tabor_P/0/1/0/all/0/1">Phil Tabor</a></p>
<p>Recent advances in Large Language Models (LLMs) have shown impressive
capabilities in various applications, yet LLMs face challenges such as limited
context windows and difficulties in generalization. In this paper, we introduce
a metacognition module for generative agents, enabling them to observe their
own thought processes and actions. This metacognitive approach, designed to
emulate System 1 and System 2 cognitive processes, allows agents to
significantly enhance their performance by modifying their strategy. We tested
the metacognition module on a variety of scenarios, including a situation where
generative agents must survive a zombie apocalypse, and observe that our system
outperform others, while agents adapt and improve their strategies to complete
tasks over time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10917">Artificial intelligence to automate the systematic review of scientific literature. (arXiv:2401.10917v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Torre_Lopez_J/0/1/0/all/0/1">Jos&#xe9; de la Torre-L&#xf3;pez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramirez_A/0/1/0/all/0/1">Aurora Ram&#xed;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_J/0/1/0/all/0/1">Jos&#xe9; Ra&#xfa;l Romero</a></p>
<p>Artificial intelligence (AI) has acquired notorious relevance in modern
computing as it effectively solves complex tasks traditionally done by humans.
AI provides methods to represent and infer knowledge, efficiently manipulate
texts and learn from vast amount of data. These characteristics are applicable
in many activities that human find laborious or repetitive, as is the case of
the analysis of scientific literature. Manually preparing and writing a
systematic literature review (SLR) takes considerable time and effort, since it
requires planning a strategy, conducting the literature search and analysis,
and reporting the findings. Depending on the area under study, the number of
papers retrieved can be of hundreds or thousands, meaning that filtering those
relevant ones and extracting the key information becomes a costly and
error-prone process. However, some of the involved tasks are repetitive and,
therefore, subject to automation by means of AI. In this paper, we present a
survey of AI techniques proposed in the last 15 years to help researchers
conduct systematic analyses of scientific literature. We describe the tasks
currently supported, the types of algorithms applied, and available tools
proposed in 34 primary studies. This survey also provides a historical
perspective of the evolution of the field and the role that humans can play in
an increasingly automated SLR process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10934">A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model. (arXiv:2401.10934v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Jianxin Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Linhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1">Shuo Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yifan Zeng</a></p>
<p>In online advertising scenario, sellers often create multiple creatives to
provide comprehensive demonstrations, making it essential to present the most
appealing design to maximize the Click-Through Rate (CTR). However, sellers
generally struggle to consider users preferences for creative design, leading
to the relatively lower aesthetics and quantities compared to Artificial
Intelligence (AI)-based approaches. Traditional AI-based approaches still face
the same problem of not considering user information while having limited
aesthetic knowledge from designers. In fact that fusing the user information,
the generated creatives can be more attractive because different users may have
different preferences. To optimize the results, the generated creatives in
traditional methods are then ranked by another module named creative ranking
model. The ranking model can predict the CTR score for each creative
considering user features. However, the two above stages are regarded as two
different tasks and are optimized separately. In this paper, we proposed a new
automated Creative Generation pipeline for Click-Through Rate (CG4CTR) with the
goal of improving CTR during the creative generation stage. Our contributions
have 4 parts: 1) The inpainting mode in stable diffusion is firstly applied to
creative generation task in online advertising scene. A self-cyclic generation
pipeline is proposed to ensure the convergence of training. 2) Prompt model is
designed to generate individualized creatives for different user groups, which
can further improve the diversity and quality. 3) Reward model comprehensively
considers the multimodal features of image and text to improve the
effectiveness of creative ranking task, and it is also critical in self-cyclic
pipeline. 4) The significant benefits obtained in online and offline
experiments verify the significance of our proposed method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10935">SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents. (arXiv:2401.10935v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1">Kanzhi Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Qiushi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_Y/0/1/0/all/0/1">Yougang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Fangzhi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yantao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianbing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiyong Wu</a></p>
<p>Graphical User Interface (GUI) agents are designed to automate complex tasks
on digital devices, such as smartphones and desktops. Most existing GUI agents
interact with the environment through extracted structured data, which can be
notably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops).
To alleviate this issue, we propose a visual GUI agent -- SeeClick, which only
relies on screenshots for task automation. In our preliminary study, we have
discovered a key challenge in developing visual GUI agents: GUI grounding --
the capacity to accurately locate screen elements based on instructions. To
tackle this challenge, we propose to enhance SeeClick with GUI grounding
pre-training and devise a method to automate the curation of GUI grounding
data. Along with the efforts above, we have also created ScreenSpot, the first
realistic GUI grounding dataset that encompasses mobile, desktop, and web
environments. After pre-training, SeeClick demonstrates significant improvement
in ScreenSpot over various baselines. Moreover, comprehensive evaluations on
three widely used benchmarks consistently support our finding that advancements
in GUI grounding directly correlate with enhanced performance in downstream GUI
agent tasks. The model, data and code are available at
https://github.com/njucckevin/SeeClick.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10937">Subjective Causality. (arXiv:2401.10937v1 [econ.TH])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Halpern_J/0/1/0/all/0/1">Joseph Y. Halpern</a>, <a href="http://arxiv.org/find/econ/1/au:+Piermont_E/0/1/0/all/0/1">Evan Piermont</a></p>
<p>We show that it is possible to understand and identify a decision maker's
subjective causal judgements by observing her preferences over interventions.
Following Pearl [2000], we represent causality using causal models (also called
structural equations models), where the world is described by a collection of
variables, related by equations. We show that if a preference relation over
interventions satisfies certain axioms (related to standard axioms regarding
counterfactuals), then we can define (i) a causal model, (ii) a probability
capturing the decision-maker's uncertainty regarding the external factors in
the world and (iii) a utility on outcomes such that each intervention is
associated with an expected utility and such that intervention $A$ is preferred
to $B$ iff the expected utility of $A$ is greater than that of $B$. In
addition, we characterize when the causal model is unique. Thus, our results
allow a modeler to test the hypothesis that a decision maker's preferences are
consistent with some causal model and to identify causal judgements from
observed behavior.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10938">Even-if Explanations: Formal Foundations, Priorities and Complexity. (arXiv:2401.10938v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alfano_G/0/1/0/all/0/1">Gianvincenzo Alfano</a>, <a href="http://arxiv.org/find/cs/1/au:+Greco_S/0/1/0/all/0/1">Sergio Greco</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandaglio_D/0/1/0/all/0/1">Domenico Mandaglio</a>, <a href="http://arxiv.org/find/cs/1/au:+Parisi_F/0/1/0/all/0/1">Francesco Parisi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahbazian_R/0/1/0/all/0/1">Reza Shahbazian</a>, <a href="http://arxiv.org/find/cs/1/au:+Trubitsyna_I/0/1/0/all/0/1">Irina Trubitsyna</a></p>
<p>EXplainable AI has received significant attention in recent years. Machine
learning models often operate as black boxes, lacking explainability and
transparency while supporting decision-making processes. Local post-hoc
explainability queries attempt to answer why individual inputs are classified
in a certain way by a given model. While there has been important work on
counterfactual explanations, less attention has been devoted to semifactual
ones. In this paper, we focus on local post-hoc explainability queries within
the semifactual `even-if' thinking and their computational complexity among
different classes of models, and show that both linear and tree-based models
are strictly more interpretable than neural networks. After this, we introduce
a preference-based framework that enables users to personalize explanations
based on their preferences, both in the case of semifactuals and
counterfactuals, enhancing interpretability and user-centricity. Finally, we
explore the complexity of several interpretability problems in the proposed
preference-based framework and provide algorithms for polynomial cases.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10942">Machine Unlearning for Recommendation Systems: An Insight. (arXiv:2401.10942v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sachdeva_B/0/1/0/all/0/1">Bhavika Sachdeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Rathee_H/0/1/0/all/0/1">Harshita Rathee</a>, <a href="http://arxiv.org/find/cs/1/au:+Sristi/0/1/0/all/0/1">Sristi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Arun Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wydmanski_W/0/1/0/all/0/1">Witold Wydma&#x144;ski</a></p>
<p>This review explores machine unlearning (MUL) in recommendation systems,
addressing adaptability, personalization, privacy, and bias challenges. Unlike
traditional models, MUL dynamically adjusts system knowledge based on shifts in
user preferences and ethical considerations. The paper critically examines
MUL's basics, real-world applications, and challenges like algorithmic
transparency. It sifts through literature, offering insights into how MUL could
transform recommendations, discussing user trust, and suggesting paths for
future research in responsible and user-focused artificial intelligence (AI).
The document guides researchers through challenges involving the trade-off
between personalization and privacy, encouraging contributions to meet
practical demands for targeted data removal. Emphasizing MUL's role in secure
and adaptive machine learning, the paper proposes ways to push its boundaries.
The novelty of this paper lies in its exploration of the limitations of the
methods, which highlights exciting prospects for advancing the field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10946">Self context-aware emotion perception on human-robot interaction. (arXiv:2401.10946v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zihan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruz_F/0/1/0/all/0/1">Francisco Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandoval_E/0/1/0/all/0/1">Eduardo Benitez Sandoval</a></p>
<p>Emotion recognition plays a crucial role in various domains of human-robot
interaction. In long-term interactions with humans, robots need to respond
continuously and accurately, however, the mainstream emotion recognition
methods mostly focus on short-term emotion recognition, disregarding the
context in which emotions are perceived. Humans consider that contextual
information and different contexts can lead to completely different emotional
expressions. In this paper, we introduce self context-aware model (SCAM) that
employs a two-dimensional emotion coordinate system for anchoring and
re-labeling distinct emotions. Simultaneously, it incorporates its distinctive
information retention structure and contextual loss. This approach has yielded
significant improvements across audio, video, and multimodal. In the auditory
modality, there has been a notable enhancement in accuracy, rising from 63.10%
to 72.46%. Similarly, the visual modality has demonstrated improved accuracy,
increasing from 77.03% to 80.82%. In the multimodal, accuracy has experienced
an elevation from 77.48% to 78.93%. In the future, we will validate the
reliability and usability of SCAM on robots through psychology experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10956">AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment. (arXiv:2401.10956v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Sida Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Swiatek_W/0/1/0/all/0/1">Wojciech Swiatek</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_A/0/1/0/all/0/1">Allen Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cullivan_P/0/1/0/all/0/1">Paul Cullivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Haoge Chang</a></p>
<p>In recent years, generative AI has undergone major advancements,
demonstrating significant promise in augmenting human productivity. Notably,
large language models (LLM), with ChatGPT-4 as an example, have drawn
considerable attention. Numerous articles have examined the impact of LLM-based
tools on human productivity in lab settings and designed tasks or in
observational studies. Despite recent advances, field experiments applying
LLM-based tools in realistic settings are limited. This paper presents the
findings of a field randomized controlled trial assessing the effectiveness of
LLM-based tools in providing unmonitored support services for information
retrieval.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10965">Decentralizing Coordination in Open Vehicle Fleets for Scalable and Dynamic Task Allocation. (arXiv:2401.10965v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lujak_M/0/1/0/all/0/1">Marin Lujak</a>, <a href="http://arxiv.org/find/cs/1/au:+Giordani_S/0/1/0/all/0/1">Stefano Giordani</a>, <a href="http://arxiv.org/find/cs/1/au:+Omicini_A/0/1/0/all/0/1">Andrea Omicini</a>, <a href="http://arxiv.org/find/cs/1/au:+Ossowski_S/0/1/0/all/0/1">Sascha Ossowski</a></p>
<p>One of the major challenges in the coordination of large, open,
collaborative, and commercial vehicle fleets is dynamic task allocation.
Self-concerned individually rational vehicle drivers have both local and global
objectives, which require coordination using some fair and efficient task
allocation method. In this paper, we review the literature on scalable and
dynamic task allocation focusing on deterministic and dynamic two-dimensional
linear assignment problems. We focus on multiagent system representation of
open vehicle fleets where dynamically appearing vehicles are represented by
software agents that should be allocated to a set of dynamically appearing
tasks. We give a comparison and critical analysis of recent research results
focusing on centralized, distributed, and decentralized solution approaches.
Moreover, we propose mathematical models for dynamic versions of the following
assignment problems well known in combinatorial optimization: the assignment
problem, bottleneck assignment problem, fair matching problem, dynamic minimum
deviation assignment problem, $\sum_{k}$-assignment problem, the semiassignment
problem, the assignment problem with side constraints, and the assignment
problem while recognizing agent qualification; all while considering the main
aspect of open vehicle fleets: random arrival of tasks and vehicles (agents)
that may become available after assisting previous tasks or by participating in
the fleet at times based on individual interest.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10969">MacroSwarm: A Field-based Compositional Framework for Swarm Programming. (arXiv:2401.10969v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Aguzzi_G/0/1/0/all/0/1">Gianluca Aguzzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Casadei_R/0/1/0/all/0/1">Roberto Casadei</a>, <a href="http://arxiv.org/find/cs/1/au:+Viroli_M/0/1/0/all/0/1">Mirko Viroli</a></p>
<p>Swarm behaviour engineering is an area of research that seeks to investigate
methods and techniques for coordinating computation and action within groups of
simple agents to achieve complex global goals like pattern formation,
collective movement, clustering, and distributed sensing. Despite recent
progress in the analysis and engineering of swarms (of drones, robots,
vehicles), there is still a need for general design and implementation methods
and tools that can be used to define complex swarm behaviour in a principled
way. To contribute to this quest, this article proposes a new field-based
coordination approach, called MacroSwarm, to design and program swarm behaviour
in terms of reusable and fully composable functional blocks embedding
collective computation and coordination. Based on the macroprogramming paradigm
of aggregate computing, MacroSwarm builds on the idea of expressing each swarm
behaviour block as a pure function mapping sensing fields into actuation goal
fields, e.g. including movement vectors. In order to demonstrate the
expressiveness, compositionality, and practicality of MacroSwarm as a framework
for collective intelligence, we perform a variety of simulations covering
common patterns of flocking, morphogenesis, and collective decision-making.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11002">Fast Registration of Photorealistic Avatars for VR Facial Animation. (arXiv:2401.11002v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Patel_C/0/1/0/all/0/1">Chaitanya Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1">Shaojie Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Te-Li Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Saragih_J/0/1/0/all/0/1">Jason Saragih</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1">Shih-En Wei</a></p>
<p>Virtual Reality (VR) bares promise of social interactions that can feel more
immersive than other media. Key to this is the ability to accurately animate a
photorealistic avatar of one's likeness while wearing a VR headset. Although
high quality registration of person-specific avatars to headset-mounted camera
(HMC) images is possible in an offline setting, the performance of generic
realtime models are significantly degraded. Online registration is also
challenging due to oblique camera views and differences in modality. In this
work, we first show that the domain gap between the avatar and headset-camera
images is one of the primary sources of difficulty, where a transformer-based
architecture achieves high accuracy on domain-consistent data, but degrades
when the domain-gap is re-introduced. Building on this finding, we develop a
system design that decouples the problem into two parts: 1) an iterative
refinement module that takes in-domain inputs, and 2) a generic avatar-guided
image-to-image style transfer module that is conditioned on current estimation
of expression and head pose. These two modules reinforce each other, as image
style transfer becomes easier when close-to-ground-truth examples are shown,
and better domain-gap removal helps registration. Our system produces
high-quality results efficiently, obviating the need for costly offline
registration to generate personalized labels. We validate the accuracy and
efficiency of our approach through extensive experiments on a commodity
headset, demonstrating significant improvements over direct regression methods
as well as offline registration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11021">Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning. (arXiv:2401.11021v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1">Arijit Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Nandy_S/0/1/0/all/0/1">Somashree Nandy</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1">Rupam Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Srijan Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_D/0/1/0/all/0/1">Diganta Saha</a></p>
<p>Hate speech is harmful content that directly attacks or promotes hatred
against members of groups or individuals based on actual or perceived aspects
of identity, such as racism, religion, or sexual orientation. This can affect
social life on social media platforms as hateful content shared through social
media can harm both individuals and communities. As the prevalence of hate
speech increases online, the demand for automated detection as an NLP task is
increasing. In this work, the proposed method is using transformer-based model
to detect hate speech in social media, like twitter, Facebook, WhatsApp,
Instagram, etc. The proposed model is independent of languages and has been
tested on Italian, English, German, Bengali. The Gold standard datasets were
collected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel,
and Rezaul Karim. The success rate of the proposed model for hate speech
detection is higher than the existing baseline and state-of-the-art models with
accuracy in Bengali dataset is 89%, in English: 91%, in German dataset 91% and
in Italian dataset it is 77%. The proposed algorithm shows substantial
improvement to the benchmark method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11044">The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making. (arXiv:2401.11044v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Capala_K/0/1/0/all/0/1">Karol Capa&#x142;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Tworek_P/0/1/0/all/0/1">Paulina Tworek</a>, <a href="http://arxiv.org/find/cs/1/au:+Sousa_J/0/1/0/all/0/1">Jose Sousa</a></p>
<p>The applicability of widely adopted machine learning (ML) methods to
classification is circumscribed by the imperatives of explicability and
uncertainty, particularly evident in domains such as healthcare, behavioural
sciences, and finances, wherein accountability assumes priority. Recently,
Small and Incomplete Dataset Analyser (SaNDA) has been proposed to enhance the
ability to perform classification in such domains, by developing a data
abstraction protocol using a ROC curve-based method. This paper focuses on
column-wise data transformations called abstractions, which are crucial for
SaNDA's classification process and explores alternative abstractions protocols,
such as constant binning and quantiles. The best-performing methods have been
compared against Random Forest as a baseline for explainable methods. The
results suggests that SaNDA can be a viable substitute for Random Forest when
data is incomplete, even with minimal missing values. It consistently maintains
high accuracy even when half of the dataset is missing, unlike Random Forest
which experiences a significant decline in accuracy under similar conditions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11061">PhotoBot: Reference-Guided Interactive Photography via Natural Language. (arXiv:2401.11061v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Limoyo_O/0/1/0/all/0/1">Oliver Limoyo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jimmy Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivkin_D/0/1/0/all/0/1">Dmitriy Rivkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1">Jonathan Kelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1">Gregory Dudek</a></p>
<p>We introduce PhotoBot, a framework for automated photo acquisition based on
an interplay between high-level human language guidance and a robot
photographer. We propose to communicate photography suggestions to the user via
a reference picture that is retrieved from a curated gallery. We exploit a
visual language model (VLM) and an object detector to characterize reference
pictures via textual descriptions and use a large language model (LLM) to
retrieve relevant reference pictures based on a user's language query through
text-based reasoning. To correspond the reference picture and the observed
scene, we exploit pre-trained features from a vision transformer capable of
capturing semantic similarity across significantly varying images. Using these
features, we compute pose adjustments for an RGB-D camera by solving a
Perspective-n-Point (PnP) problem. We demonstrate our approach on a real-world
manipulator equipped with a wrist camera. Our user studies show that photos
taken by PhotoBot are often more aesthetically pleasing than those taken by
users themselves, as measured by human feedback.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11081">Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions. (arXiv:2401.11081v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Javanmard_A/0/1/0/all/0/1">Adel Javanmard</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>, <a href="http://arxiv.org/find/cs/1/au:+Badanidiyuru_A/0/1/0/all/0/1">Ashwinkumar Badanidiyuru</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_G/0/1/0/all/0/1">Gang Fu</a></p>
<p>Due to the rise of privacy concerns, in many practical applications the
training data is aggregated before being shared with the learner, in order to
protect privacy of users' sensitive responses. In an aggregate learning
framework, the dataset is grouped into bags of samples, where each bag is
available only with an aggregate response, providing a summary of individuals'
responses in that bag. In this paper, we study two natural loss functions for
learning from aggregate responses: bag-level loss and the instance-level loss.
In the former, the model is learnt by minimizing a loss between aggregate
responses and aggregate model predictions, while in the latter the model aims
to fit individual predictions to the aggregate responses. In this work, we show
that the instance-level loss can be perceived as a regularized form of the
bag-level loss. This observation lets us compare the two approaches with
respect to bias and variance of the resulting estimators, and introduce a novel
interpolating estimator which combines the two approaches. For linear
regression tasks, we provide a precise characterization of the risk of the
interpolating estimator in an asymptotic regime where the size of the training
set grows in proportion to the features dimension. Our analysis allows us to
theoretically understand the effect of different factors, such as bag size on
the model prediction risk. In addition, we propose a mechanism for
differentially private learning from aggregate responses and derive the optimal
bag size in terms of prediction risk-privacy trade-off. We also carry out
thorough experiments to corroborate our theory and show the efficacy of the
interpolating estimator.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11085">Adaptive Global-Local Representation Learning and Selection for Cross-Domain Facial Expression Recognition. (arXiv:2401.11085v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yuefang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuhao Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zeke Zexi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianshui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a></p>
<p>Domain shift poses a significant challenge in Cross-Domain Facial Expression
Recognition (CD-FER) due to the distribution variation across different
domains. Current works mainly focus on learning domain-invariant features
through global feature adaptation, while neglecting the transferability of
local features. Additionally, these methods lack discriminative supervision
during training on target datasets, resulting in deteriorated feature
representation in target domain. To address these limitations, we propose an
Adaptive Global-Local Representation Learning and Selection (AGLRLS) framework.
The framework incorporates global-local adversarial adaptation and
semantic-aware pseudo label generation to enhance the learning of
domain-invariant and discriminative feature during training. Meanwhile, a
global-local prediction consistency learning is introduced to improve
classification results during inference. Specifically, the framework consists
of separate global-local adversarial learning modules that learn
domain-invariant global and local features independently. We also design a
semantic-aware pseudo label generation module, which computes semantic labels
based on global and local features. Moreover, a novel dynamic threshold
strategy is employed to learn the optimal thresholds by leveraging independent
prediction of global and local features, ensuring filtering out the unreliable
pseudo labels while retaining reliable ones. These labels are utilized for
model optimization through the adversarial learning process in an end-to-end
manner. During inference, a global-local prediction consistency module is
developed to automatically learn an optimal result from multiple predictions.
We conduct comprehensive experiments and analysis based on a fair evaluation
benchmark. The results demonstrate that the proposed framework outperforms the
current competing methods by a substantial margin.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11089">FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement. (arXiv:2401.11089v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yao_D/0/1/0/all/0/1">Dezhong Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongtong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1">Qi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Hai Jin</a></p>
<p>Federated Learning (FL) has emerged as a promising approach for preserving
data privacy in recommendation systems by training models locally. Recently,
Graph Neural Networks (GNN) have gained popularity in recommendation tasks due
to their ability to capture high-order interactions between users and items.
However, privacy concerns prevent the global sharing of the entire user-item
graph. To address this limitation, some methods create pseudo-interacted items
or users in the graph to compensate for missing information for each client.
Unfortunately, these methods introduce random noise and raise privacy concerns.
In this paper, we propose FedRKG, a novel federated recommendation system,
where a global knowledge graph (KG) is constructed and maintained on the server
using publicly available item information, enabling higher-order user-item
interactions. On the client side, a relation-aware GNN model leverages diverse
KG relationships. To protect local interaction items and obscure gradients, we
employ pseudo-labeling and Local Differential Privacy (LDP). Extensive
experiments conducted on three real-world datasets demonstrate the competitive
performance of our approach compared to centralized algorithms while ensuring
privacy preservation. Moreover, FedRKG achieves an average accuracy improvement
of 4% compared to existing federated learning baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11094">TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation. (arXiv:2401.11094v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1">Shishi Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liangwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaojuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wei Zeng</a></p>
<p>Semantic typographic logos harmoniously blend typeface and imagery to
represent semantic concepts while maintaining legibility. Conventional methods
using spatial composition and shape substitution are hindered by the
conflicting requirement for achieving seamless spatial fusion between
geometrically dissimilar typefaces and semantics. While recent advances made AI
generation of semantic typography possible, the end-to-end approaches exclude
designer involvement and disregard personalized design. This paper presents
TypeDance, an AI-assisted tool incorporating design rationales with the
generative model for personalized semantic typographic logo design. It
leverages combinable design priors extracted from uploaded image exemplars and
supports type-imagery mapping at various structural granularity, achieving
diverse aesthetic designs with flexible control. Additionally, we instantiate a
comprehensive design workflow in TypeDance, including ideation, selection,
generation, evaluation, and iteration. A two-task user evaluation, including
imitation and creation, confirmed the usability of TypeDance in design across
different usage scenarios
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11113">SPAND: Sleep Prediction Architecture using Network Dynamics. (arXiv:2401.11113v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khalid_M/0/1/0/all/0/1">Maryam Khalid</a>, <a href="http://arxiv.org/find/cs/1/au:+Klerman_E/0/1/0/all/0/1">Elizabeth B. Klerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Mchill_A/0/1/0/all/0/1">Andrew W. Mchill</a>, <a href="http://arxiv.org/find/cs/1/au:+Phillips_A/0/1/0/all/0/1">Andrew J. K. Phillips</a>, <a href="http://arxiv.org/find/cs/1/au:+Sano_A/0/1/0/all/0/1">Akane Sano</a></p>
<p>Sleep behavior significantly impacts health and acts as an indicator of
physical and mental well-being. Monitoring and predicting sleep behavior with
ubiquitous sensors may therefore assist in both sleep management and tracking
of related health conditions. While sleep behavior depends on, and is reflected
in the physiology of a person, it is also impacted by external factors such as
digital media usage, social network contagion, and the surrounding weather. In
this work, we propose SPAND (Sleep Prediction Architecture using Network
Dynamics), a system that exploits social contagion in sleep behavior through
graph networks and integrates it with physiological and phone data extracted
from ubiquitous mobile and wearable devices for predicting next-day sleep
labels about sleep duration. Our architecture overcomes the limitations of
large-scale graphs containing connections irrelevant to sleep behavior by
devising an attention mechanism. The extensive experimental evaluation
highlights the improvement provided by incorporating social networks in the
model. Additionally, we conduct robustness analysis to demonstrate the system's
performance in real-life conditions. The outcomes affirm the stability of SPAND
against perturbations in input data. Further analyses emphasize the
significance of network topology in prediction performance revealing that users
with higher eigenvalue centrality are more vulnerable to data perturbations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11120">Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines. (arXiv:2401.11120v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1">David Oniani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xizhi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Visweswaran_S/0/1/0/all/0/1">Shyam Visweswaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1">Sumit Kapoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Kooragayalu_S/0/1/0/all/0/1">Shravan Kooragayalu</a>, <a href="http://arxiv.org/find/cs/1/au:+Polanska_K/0/1/0/all/0/1">Katelyn Polanska</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanshan Wang</a></p>
<p>Background Large Language Models (LLMs), enhanced with Clinical Practice
Guidelines (CPGs), can significantly improve Clinical Decision Support (CDS).
However, methods for incorporating CPGs into LLMs are not well studied. Methods
We develop three distinct methods for incorporating CPGs into LLMs: Binary
Decision Tree (BDT), Program-Aided Graph Construction (PAGC), and
Chain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of
the proposed methods, we create a set of synthetic patient descriptions and
conduct both automatic and human evaluation of the responses generated by four
LLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was
used as the baseline method. We focus on CDS for COVID-19 outpatient treatment
as the case study. Results All four LLMs exhibit improved performance when
enhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP
and PAGC in automatic evaluation. All of the proposed methods demonstrated high
performance in human evaluation. Conclusion LLMs enhanced with CPGs demonstrate
superior performance, as compared to plain LLMs with ZSP, in providing accurate
recommendations for COVID-19 outpatient treatment, which also highlights the
potential for broader applications beyond the case study.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11140">Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection. (arXiv:2401.11140v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yuantao Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1">Ping Yin</a></p>
<p>Few-shot object detection(FSOD) aims to design methods to adapt object
detectors efficiently with only few annotated samples. Fine-tuning has been
shown to be an effective and practical approach. However, previous works often
take the classical base-novel two stage fine-tuning procedure but ignore the
implicit stability-plasticity contradiction among different modules.
Specifically, the random re-initialized classifiers need more plasticity to
adapt to novel samples. The other modules inheriting pre-trained weights demand
more stability to reserve their class-agnostic knowledge. Regular fine-tuning
which couples the optimization of these two parts hurts the model
generalization in FSOD scenarios. In this paper, we find that this problem is
prominent in the end-to-end object detector Sparse R-CNN for its
multi-classifier cascaded architecture. We propose to mitigate this
contradiction by a new three-stage fine-tuning procedure by introducing an
addtional plasticity classifier fine-tuning(PCF) stage. We further design the
multi-source ensemble(ME) technique to enhance the generalization of the model
in the final fine-tuning stage. Extensive experiments verify that our method is
effective in regularizing Sparse R-CNN, outperforming previous methods in the
FSOD benchmark.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11143">Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities. (arXiv:2401.11143v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ioannides_G/0/1/0/all/0/1">Georgios Ioannides</a>, <a href="http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1">Aman Chadha</a>, <a href="http://arxiv.org/find/cs/1/au:+Elkins_A/0/1/0/all/0/1">Aaron Elkins</a></p>
<p>We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a
novel probabilistic attention framework, and the Gaussian Adaptive Transformer
(GAT), designed to enhance information aggregation across multiple modalities,
including Speech, Text and Vision. GAAM integrates learnable mean and variance
into its attention mechanism, implemented in a Multi-Headed framework enabling
it to collectively model any Probability Distribution for dynamic recalibration
of feature significance. This method demonstrates significant improvements,
especially with highly non-stationary data, surpassing the state-of-the-art
attention techniques in model performance (up to approximately +20% in
accuracy) by identifying key elements within the feature space. GAAM's
compatibility with dot-product-based attention models and relatively low number
of parameters showcases its adaptability and potential to boost existing
attention frameworks. Empirically, GAAM exhibits superior adaptability and
efficacy across a diverse range of tasks, including emotion recognition in
speech, image classification, and text classification, thereby establishing its
robustness and versatility in handling multi-modal data. Furthermore, we
introduce the Importance Factor (IF), a new learning-based metric that enhances
the explainability of models trained with GAAM-based methods. Overall, GAAM
represents an advancement towards development of better performing and more
explainable attention models across multiple modalities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11156">Generalizing Speaker Verification for Spoof Awareness in the Embedding Space. (arXiv:2401.11156v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuechen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahidullah_M/0/1/0/all/0/1">Md Sahidullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kong Aik Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kinnunen_T/0/1/0/all/0/1">Tomi Kinnunen</a></p>
<p>It is now well-known that automatic speaker verification (ASV) systems can be
spoofed using various types of adversaries. The usual approach to counteract
ASV systems against such attacks is to develop a separate spoofing
countermeasure (CM) module to classify speech input either as a bonafide, or a
spoofed utterance. Nevertheless, such a design requires additional computation
and utilization efforts at the authentication stage. An alternative strategy
involves a single monolithic ASV system designed to handle both zero-effort
imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have
the potential to provide stronger protections and more economic computations.
To this end, we propose to generalize the standalone ASV (G-SASV) against
spoofing attacks, where we leverage limited training data from CM to enhance a
simple backend in the embedding space, without the involvement of a separate CM
module during the test (authentication) phase. We propose a novel yet simple
backend classifier based on deep neural networks and conduct the study via
domain adaptation and multi-task integration of spoof embeddings at the
training stage. Experiments are conducted on the ASVspoof 2019 logical access
dataset, where we improve the performance of statistical ASV backends on the
joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and
49.8% in terms of equal error rates, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11174">Pixel-Wise Recognition for Holistic Surgical Scene Understanding. (arXiv:2401.11174v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ayobi_N/0/1/0/all/0/1">Nicol&#xe1;s Ayobi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_S/0/1/0/all/0/1">Santiago Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_A/0/1/0/all/0/1">Alejandra P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_I/0/1/0/all/0/1">Isabela Hern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Aparicio_N/0/1/0/all/0/1">Nicol&#xe1;s Aparicio</a>, <a href="http://arxiv.org/find/cs/1/au:+Dessevres_E/0/1/0/all/0/1">Eug&#xe9;nie Dessevres</a>, <a href="http://arxiv.org/find/cs/1/au:+Pena_S/0/1/0/all/0/1">Sebasti&#xe1;n Pe&#xf1;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Santander_J/0/1/0/all/0/1">Jessica Santander</a>, <a href="http://arxiv.org/find/cs/1/au:+Caicedo_J/0/1/0/all/0/1">Juan Ignacio Caicedo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_N/0/1/0/all/0/1">Nicol&#xe1;s Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbel&#xe1;ez</a></p>
<p>This paper presents the Holistic and Multi-Granular Surgical Scene
Understanding of Prostatectomies (GraSP) dataset, a curated benchmark that
models surgical scene understanding as a hierarchy of complementary tasks with
varying levels of granularity. Our approach enables a multi-level comprehension
of surgical activities, encompassing long-term tasks such as surgical phases
and steps recognition and short-term tasks including surgical instrument
segmentation and atomic visual actions detection. To exploit our proposed
benchmark, we introduce the Transformers for Actions, Phases, Steps, and
Instrument Segmentation (TAPIS) model, a general architecture that combines a
global video feature extractor with localized region proposals from an
instrument segmentation model to tackle the multi-granularity of our benchmark.
Through extensive experimentation, we demonstrate the impact of including
segmentation annotations in short-term recognition tasks, highlight the varying
granularity requirements of each task, and establish TAPIS's superiority over
previously proposed baselines and conventional CNN-based models. Additionally,
we validate the robustness of our method across multiple public benchmarks,
confirming the reliability and applicability of our dataset. This work
represents a significant step forward in Endoscopic Vision, offering a novel
and comprehensive framework for future research towards a holistic
understanding of surgical procedures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11188">Fast and Exact Enumeration of Deep Networks Partitions Regions. (arXiv:2401.11188v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1">Randall Balestriero</a>, <a href="http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1">Yann LeCun</a></p>
<p>One fruitful formulation of Deep Networks (DNs) enabling their theoretical
study and providing practical guidelines to practitioners relies on Piecewise
Affine Splines. In that realm, a DN's input-mapping is expressed as per-region
affine mapping where those regions are implicitly determined by the model's
architecture and form a partition of their input space. That partition -- which
is involved in all the results spanned from this line of research -- has so far
only been computed on $2/3$-dimensional slices of the DN's input space or
estimated by random sampling. In this paper, we provide the first parallel
algorithm that does exact enumeration of the DN's partition regions. The
proposed algorithm enables one to finally assess the closeness of the commonly
employed approximations methods, e.g. based on random sampling of the DN input
space. One of our key finding is that if one is only interested in regions with
``large'' volume, then uniform sampling of the space is highly efficient, but
that if one is also interested in discovering the ``small'' regions of the
partition, then uniform sampling is exponentially costly with the DN's input
space dimension. On the other hand, our proposed method has complexity scaling
linearly with input dimension and the number of regions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11201">Navigating the Thin Line: Examining User Behavior in Search to Detect Engagement and Backfire Effects. (arXiv:2401.11201v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cau_F/0/1/0/all/0/1">F. M. Cau</a>, <a href="http://arxiv.org/find/cs/1/au:+Tintarev_N/0/1/0/all/0/1">N. Tintarev</a></p>
<p>Opinionated users often seek information that aligns with their preexisting
beliefs while dismissing contradictory evidence due to confirmation bias. This
conduct hinders their ability to consider alternative stances when searching
the web. Despite this, few studies have analyzed how the diversification of
search results on disputed topics influences the search behavior of highly
opinionated users. To this end, we present a preregistered user study (n = 257)
investigating whether different levels (low and high) of bias metrics and
search results presentation (with or without AI-predicted stances labels) can
affect the stance diversity consumption and search behavior of opinionated
users on three debated topics (i.e., atheism, intellectual property rights, and
school uniforms). Our results show that exposing participants to
(counter-attitudinally) biased search results increases their consumption of
attitude-opposing content, but we also found that bias was associated with a
trend toward overall fewer interactions within the search page. We also found
that 19% of users interacted with queries and search pages but did not select
any search results. When we removed these participants in a post-hoc analysis,
we found that stance labels increased the diversity of stances consumed by
users, particularly when the search results were biased. Our findings highlight
the need for future research to explore distinct search scenario settings to
gain insight into opinionated users' behavior.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11212">Programming Distributed Collective Processes in the eXchange Calculus. (arXiv:2401.11212v1 [cs.DC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Audrito_G/0/1/0/all/0/1">Giorgio Audrito</a>, <a href="http://arxiv.org/find/cs/1/au:+Casadei_R/0/1/0/all/0/1">Roberto Casadei</a>, <a href="http://arxiv.org/find/cs/1/au:+Damiani_F/0/1/0/all/0/1">Ferruccio Damiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Torta_G/0/1/0/all/0/1">Gianluca Torta</a>, <a href="http://arxiv.org/find/cs/1/au:+Viroli_M/0/1/0/all/0/1">Mirko Viroli</a></p>
<p>Recent trends like the Internet of Things (IoT) suggest a vision of dense and
multi-scale deployments of computing devices in nearly all kinds of
environments. A prominent engineering challenge revolves around programming the
collective adaptive behaviour of such computational ecosystems. This requires
abstractions able to capture concepts like ensembles (dynamic groups of
cooperating devices) and collective tasks (joint activities carried out by
ensembles). In this work, we consider collections of devices interacting with
neighbours and that execute in nearly-synchronised sense-compute-interact
rounds, where the computation is given by a single program mapping sensing
values and incoming messages to output and outcoming messages. To support
programming whole computational collectives, we propose the abstraction of a
distributed collective process, which can be used to define at once the
ensemble formation logic and its collective task. We formalise the abstraction
in the eXchange Calculus (XC), a core functional language based on neighbouring
values (maps from neighbours to values) where state and interaction is handled
through a single primitive, exchange, and provide a corresponding
implementation in the FCPP language. Then, we exercise distributed collective
processes using two case studies: multi-hop message propagation and distributed
monitoring of spatial properties. Finally, we discuss the features of the
abstraction and its suitability for different kinds of distributed computing
applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11217">A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant. (arXiv:2401.11217v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Koksal_E/0/1/0/all/0/1">Ece S. Koksal</a>, <a href="http://arxiv.org/find/cs/1/au:+Aydin_E/0/1/0/all/0/1">Erdal Aydin</a></p>
<p>Constructing first principles models is a challenging task for nonlinear and
complex systems such as a wastewater treatment unit. In recent years,
data-driven models are widely used to overcome the complexity. However, they
often suffer from issues such as missing, low quality or noisy data. Transfer
learning is a solution for this issue where knowledge from another task is
transferred to target one to increase the prediction performance. In this work,
the objective is increasing the prediction performance of an industrial
wastewater treatment plant by transferring the knowledge of (i) an open-source
simulation model that captures the underlying physics of the process, albeit
with dissimilarities to the target plant, (ii) another industrial plant
characterized by noisy and limited data but located in the same refinery, and
(iii) the model in (ii) and making the objective function of the training
problem physics informed where the physics information derived from the
open-source model in (ii). The results have shown that test and validation
performance are improved up to 27% and 59%, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11235">TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision. (arXiv:2401.11235v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shibo He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haoyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shizhong Li</a></p>
<p>Time series anomaly detection (TSAD) plays a vital role in various domains
such as healthcare, networks, and industry. Considering labels are crucial for
detection but difficult to obtain, we turn to TSAD with inexact supervision:
only series-level labels are provided during the training phase, while
point-level anomalies are predicted during the testing phase. Previous works
follow a traditional multi-instance learning (MIL) approach, which focuses on
encouraging high anomaly scores at individual time steps. However, time series
anomalies are not only limited to individual point anomalies, they can also be
collective anomalies, typically exhibiting abnormal patterns over subsequences.
To address the challenge of collective anomalies, in this paper, we propose a
tree-based MIL framework (TreeMIL). We first adopt an N-ary tree structure to
divide the entire series into multiple nodes, where nodes at different levels
represent subsequences with different lengths. Then, the subsequence features
are extracted to determine the presence of collective anomalies. Finally, we
calculate point-level anomaly scores by aggregating features from nodes at
different levels. Experiments conducted on seven public datasets and eight
baselines demonstrate that TreeMIL achieves an average 32.3% improvement in F1-
score compared to previous state-of-the-art methods. The code is available at
https://github.com/fly-orange/TreeMIL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11249">Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI. (arXiv:2401.11249v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zarifis_A/0/1/0/all/0/1">Alex Zarifis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawalek_P/0/1/0/all/0/1">Peter Kawalek</a>, <a href="http://arxiv.org/find/cs/1/au:+Azadegan_A/0/1/0/all/0/1">Aida Azadegan</a></p>
<p>Trust and privacy have emerged as significant concerns in online
transactions. Sharing information on health is especially sensitive but it is
necessary for purchasing and utilizing health insurance. Evidence shows that
consumers are increasingly comfortable with technology in place of humans, but
the expanding use of AI potentially changes this. This research explores
whether trust and privacy concern are barriers to the adoption of AI in health
insurance. Two scenarios are compared: The first scenario has limited AI that
is not in the interface and its presence is not explicitly revealed to the
consumer. In the second scenario there is an AI interface and AI evaluation,
and this is explicitly revealed to the consumer. The two scenarios were modeled
and compared using SEM PLS-MGA. The findings show that trust is significantly
lower in the second scenario where AI is visible. Privacy concerns are higher
with AI but the difference is not statistically significant within the model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11252">Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions. (arXiv:2401.11252v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Suhan Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yuan Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Han Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Ting Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1">Fenglong Ma</a></p>
<p>The widespread adoption of Electronic Health Record (EHR) systems in
healthcare institutes has generated vast amounts of medical data, offering
significant opportunities for improving healthcare services through deep
learning techniques. However, the complex and diverse modalities and feature
structures in real-world EHR data pose great challenges for deep learning model
design. To address the multi-modality challenge in EHR data, current approaches
primarily rely on hand-crafted model architectures based on intuition and
empirical experiences, leading to sub-optimal model architectures and limited
performance. Therefore, to automate the process of model design for mining EHR
data, we propose a novel neural architecture search (NAS) framework named
AutoFM, which can automatically search for the optimal model architectures for
encoding diverse input modalities and fusion strategies. We conduct thorough
experiments on real-world multi-modal EHR data and prediction tasks, and the
results demonstrate that our framework not only achieves significant
performance improvement over existing state-of-the-art methods but also
discovers meaningful network architectures effectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11257">Measuring Policy Distance for Multi-Agent Reinforcement Learning. (arXiv:2401.11257v1 [cs.MA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1">Tianyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_Z/0/1/0/all/0/1">Zhiqiang Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_X/0/1/0/all/0/1">Xiaolin Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_T/0/1/0/all/0/1">Tenghai Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1">Jianqiang Yi</a></p>
<p>Diversity plays a crucial role in improving the performance of multi-agent
reinforcement learning (MARL). Currently, many diversity-based methods have
been developed to overcome the drawbacks of excessive parameter sharing in
traditional MARL. However, there remains a lack of a general metric to quantify
policy differences among agents. Such a metric would not only facilitate the
evaluation of the diversity evolution in multi-agent systems, but also provide
guidance for the design of diversity-based MARL algorithms. In this paper, we
propose the multi-agent policy distance (MAPD), a general tool for measuring
policy differences in MARL. By learning the conditional representations of
agents' decisions, MAPD can computes the policy distance between any pair of
agents. Furthermore, we extend MAPD to a customizable version, which can
quantify differences among agent policies on specified aspects. Based on the
online deployment of MAPD, we design a multi-agent dynamic parameter sharing
(MADPS) algorithm as an example of the MAPD's applications. Extensive
experiments demonstrate that our method is effective in measuring differences
in agent policies and specific behavioral tendencies. Moreover, in comparison
to other methods of parameter sharing, MADPS exhibits superior performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11284">Evaluating Driver Readiness in Conditionally Automated Vehicles from Eye-Tracking Data and Head Pose. (arXiv:2401.11284v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kazemi_M/0/1/0/all/0/1">Mostafa Kazemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezaei_M/0/1/0/all/0/1">Mahdi Rezaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Azarmi_M/0/1/0/all/0/1">Mohsen Azarmi</a></p>
<p>As automated driving technology advances, the role of the driver to resume
control of the vehicle in conditionally automated vehicles becomes increasingly
critical. In the SAE Level 3 or partly automated vehicles, the driver needs to
be available and ready to intervene when necessary. This makes it essential to
evaluate their readiness accurately. This article presents a comprehensive
analysis of driver readiness assessment by combining head pose features and
eye-tracking data. The study explores the effectiveness of predictive models in
evaluating driver readiness, addressing the challenges of dataset limitations
and limited ground truth labels. Machine learning techniques, including LSTM
architectures, are utilised to model driver readiness based on the
Spatio-temporal status of the driver's head pose and eye gaze. The experiments
in this article revealed that a Bidirectional LSTM architecture, combining both
feature sets, achieves a mean absolute error of 0.363 on the DMD dataset,
demonstrating superior performance in assessing driver readiness. The modular
architecture of the proposed model also allows the integration of additional
driver-specific features, such as steering wheel activity, enhancing its
adaptability and real-world applicability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2002.11503">Wavelet-based temporal models of human activity for anomaly detection in smart robot-assisted environments. (arXiv:2002.11503v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Carmona_M/0/1/0/all/0/1">Manuel Fernandez-Carmona</a>, <a href="http://arxiv.org/find/cs/1/au:+Mghames_S/0/1/0/all/0/1">Sariah Mghames</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellotto_N/0/1/0/all/0/1">Nicola Bellotto</a></p>
<p>Abstract. Detecting anomalies in patterns of sensor data is important in many
practical applications, including domestic activity monitoring for Active
Assisted Living (AAL). How to represent and analyse these patterns, however,
remains a challenging task, especially when data is relatively scarce and an
explicit model is required to be fine-tuned for specific scenarios. This paper,
therefore, presents a new approach for temporal modelling of long-term human
activities with smart-home sensors, which is used to detect anomalous
situations in a robot-assisted environment. The model is based on wavelet
transforms and used to forecast smart sensor data, providing a temporal prior
to detect unexpected events in human environments. To this end, a new extension
of Hybrid Markov Logic Networks has been developed that merges different
anomaly indicators, including activities detected by binary sensors, expert
logic rules, and wavelet-based temporal models. The latter in particular allows
the inference system to discover deviations from long-term activity patterns,
which cannot be detected by simpler frequency-based models. Two new publicly
available datasets were collected using several smart-sensors to evaluate the
approach in office and domestic scenarios. The experimental results demonstrate
the effectiveness of the proposed solutions and their successful deployment in
complex human environments, showing their potential for future smart-home and
robot integrated services.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2207.00067">Rethinking Unsupervised Domain Adaptation for Semantic Segmentation. (arXiv:2207.00067v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhijie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Suganuma_M/0/1/0/all/0/1">Masanori Suganuma</a>, <a href="http://arxiv.org/find/cs/1/au:+Okatani_T/0/1/0/all/0/1">Takayuki Okatani</a></p>
<p>Unsupervised domain adaptation (UDA) adapts a model trained on one domain
(called source) to a novel domain (called target) using only unlabeled data.
Due to its high annotation cost, researchers have developed many UDA methods
for semantic segmentation, which assume no labeled sample is available in the
target domain. We question the practicality of this assumption for two reasons.
First, after training a model with a UDA method, we must somehow verify the
model before deployment. Second, UDA methods have at least a few
hyper-parameters that need to be determined. The surest solution to these is to
evaluate the model using validation data, i.e., a certain amount of labeled
target-domain samples. This question about the basic assumption of UDA leads us
to rethink UDA from a data-centric point of view. Specifically, we assume we
have access to a minimum level of labeled data. Then, we ask how much is
necessary to find good hyper-parameters of existing UDA methods. We then
consider what if we use the same data for supervised training of the same
model, e.g., finetuning. We conducted experiments to answer these questions
with popular scenarios, {GTA5, SYNTHIA}$\rightarrow$Cityscapes. We found that
i) choosing good hyper-parameters needs only a few labeled images for some UDA
methods whereas a lot more for others; and ii) simple finetuning works
surprisingly well; it outperforms many UDA methods if only several dozens of
labeled images are available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.04957">Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution. (arXiv:2208.04957v2 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xue_K/0/1/0/all/0/1">Ke Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yutong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cong Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lei Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1">Haobo Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1">Qiang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1">Chao Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yang Yu</a></p>
<p>Generating agents that can achieve zero-shot coordination (ZSC) with unseen
partners is a new challenge in cooperative multi-agent reinforcement learning
(MARL). Recently, some studies have made progress in ZSC by exposing the agents
to diverse partners during the training process. They usually involve self-play
when training the partners, implicitly assuming that the tasks are homogeneous.
However, many real-world tasks are heterogeneous, and hence previous methods
may be inefficient. In this paper, we study the heterogeneous ZSC problem for
the first time and propose a general method based on coevolution, which
coevolves two populations of agents and partners through three sub-processes:
pairing, updating and selection. Experimental results on various heterogeneous
tasks highlight the necessity of considering the heterogeneous setting and
demonstrate that our proposed method is a promising solution for heterogeneous
ZSC tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.01751">Proportional structures. (arXiv:2210.01751v5 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Antic_C/0/1/0/all/0/1">Christian Anti&#x107;</a></p>
<p>Analogical proportions are expressions of the form ``$a$ is to $b$ what $c$
is to $d$'' at the core of analogical reasoning which itself is at the core of
artificial intelligence. This paper contributes to the mathematical foundations
of analogical proportions in the axiomatic tradition as initiated by Yves
Lepage two decades ago. For this we consider proportional structures as sets
endowed with a 4-ary analogical proportion relation $a:b::c:d$ satisfying a
suitable set of axioms and study different kinds of proportion-preserving
mappings and relations and their properties. In a broader sense, this paper is
a further step towards a mathematical theory of analogical proportions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.01168">Towards Cross Domain Generalization of Hamiltonian Representation via Meta Learning. (arXiv:2212.01168v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yeongwoo Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1">Hawoong Jeong</a></p>
<p>Recent advances in deep learning for physics have focused on discovering
shared representations of target systems by incorporating physics priors or
inductive biases into neural networks. While effective, these methods are
limited to the system domain, where the type of system remains consistent and
thus cannot ensure the adaptation to new, or unseen physical systems governed
by different laws. For instance, a neural network trained on a mass-spring
system cannot guarantee accurate predictions for the behavior of a two-body
system or any other system with different physical laws. In this work, we take
a significant leap forward by targeting cross domain generalization within the
field of Hamiltonian dynamics. We model our system with a graph neural network
and employ a meta learning algorithm to enable the model to gain experience
over a distribution of tasks and make it adapt to new physics. Our approach
aims to learn a unified Hamiltonian representation that is generalizable across
multiple system domains, thereby overcoming the limitations of system-specific
models. Our results demonstrate that the meta-trained model not only adapts
effectively to new systems but also captures a generalized Hamiltonian
representation that is consistent across different physical domains. Overall,
through the use of meta learning, we offer a framework that achieves cross
domain generalization, providing a step towards a unified model for
understanding a wide array of dynamical systems via deep learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.06419">AV-data2vec: Self-supervised Learning of Audio-Visual Speech Representations with Contextualized Target Representations. (arXiv:2302.06419v2 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Lian_J/0/1/0/all/0/1">Jiachen Lian</a>, <a href="http://arxiv.org/find/eess/1/au:+Baevski_A/0/1/0/all/0/1">Alexei Baevski</a>, <a href="http://arxiv.org/find/eess/1/au:+Hsu_W/0/1/0/all/0/1">Wei-Ning Hsu</a>, <a href="http://arxiv.org/find/eess/1/au:+Auli_M/0/1/0/all/0/1">Michael Auli</a></p>
<p>Self-supervision has shown great potential for audio-visual speech
recognition by vastly reducing the amount of labeled data required to build
good systems. However, existing methods are either not entirely end-to-end or
do not train joint representations of both modalities. In this paper, we
introduce AV-data2vec which addresses these challenges and builds audio-visual
representations based on predicting contextualized representations which has
been successful in the uni-modal case. The model uses a shared transformer
encoder for both audio and video and can combine both modalities to improve
speech recognition. Results on LRS3 show that AV-data2vec consistently
outperforms existing methods under all settings with the same amount of data
and model size.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.11337">Bayesian Matrix Decomposition and Applications. (arXiv:2302.11337v2 [math.NA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a></p>
<p>The sole aim of this book is to give a self-contained introduction to
concepts and mathematical tools in Bayesian matrix decomposition in order to
seamlessly introduce matrix decomposition techniques and their applications in
subsequent sections. However, we clearly realize our inability to cover all the
useful and interesting results concerning Bayesian matrix decomposition and
given the paucity of scope to present this discussion, e.g., the separated
analysis of variational inference for conducting the optimization. We refer the
reader to literature in the field of Bayesian analysis for a more detailed
introduction to the related fields.
</p>
<p>This book is primarily a summary of purpose, significance of important
Bayesian matrix decomposition methods, e.g., real-valued decomposition,
nonnegative matrix factorization, Bayesian interpolative decomposition, and the
origin and complexity of the methods which shed light on their applications.
The mathematical prerequisite is a first course in statistics and linear
algebra. Other than this modest background, the development is self-contained,
with rigorous proof provided throughout.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.05479">Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning. (arXiv:2303.05479v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nakamoto_M/0/1/0/all/0/1">Mitsuhiko Nakamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1">Yuexiang Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Anikait Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mark_M/0/1/0/all/0/1">Max Sobol Mark</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Aviral Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a></p>
<p>A compelling use case of offline reinforcement learning (RL) is to obtain a
policy initialization from existing datasets followed by fast online
fine-tuning with limited interaction. However, existing offline RL methods tend
to behave poorly during fine-tuning. In this paper, we devise an approach for
learning an effective initialization from offline data that also enables fast
online fine-tuning capabilities. Our approach, calibrated Q-learning (Cal-QL),
accomplishes this by learning a conservative value function initialization that
underestimates the value of the learned policy from offline data, while also
being calibrated, in the sense that the learned Q-values are at a reasonable
scale. We refer to this property as calibration, and define it formally as
providing a lower bound on the true value function of the learned policy and an
upper bound on the value of some other (suboptimal) reference policy, which may
simply be the behavior policy. We show that offline RL algorithms that learn
such calibrated value functions lead to effective online fine-tuning, enabling
us to take the benefits of offline initializations in online fine-tuning. In
practice, Cal-QL can be implemented on top of the conservative Q learning (CQL)
for offline RL within a one-line code change. Empirically, Cal-QL outperforms
state-of-the-art methods on 9/11 fine-tuning benchmark tasks that we study in
this paper. Code and video are available at https://nakamotoo.github.io/Cal-QL
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.07064">A Generalized Multi-Modal Fusion Detection Framework. (arXiv:2303.07064v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Leichao Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiuxian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_M/0/1/0/all/0/1">Min Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_X/0/1/0/all/0/1">Xiaoyu Mo</a></p>
<p>LiDAR point clouds have become the most common data source in autonomous
driving. However, due to the sparsity of point clouds, accurate and reliable
detection cannot be achieved in specific scenarios. Because of their
complementarity with point clouds, images are getting increasing attention.
Although with some success, existing fusion methods either perform hard fusion
or do not fuse in a direct manner. In this paper, we propose a generic 3D
detection framework called MMFusion, using multi-modal features. The framework
aims to achieve accurate fusion between LiDAR and images to improve 3D
detection in complex scenes. Our framework consists of two separate streams:
the LiDAR stream and the camera stream, which can be compatible with any
single-modal feature extraction network. The Voxel Local Perception Module in
the LiDAR stream enhances local feature representation, and then the
Multi-modal Feature Fusion Module selectively combines feature output from
different streams to achieve better fusion. Extensive experiments have shown
that our framework not only outperforms existing benchmarks but also improves
their detection, especially for detecting cyclists and pedestrians on KITTI
benchmarks, with strong robustness and generalization capabilities. Hopefully,
our work will stimulate more research into multi-modal fusion for autonomous
driving tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.11249">What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement. (arXiv:2303.11249v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alexander_Y/0/1/0/all/0/1">Yotam Alexander</a>, <a href="http://arxiv.org/find/cs/1/au:+Vega_N/0/1/0/all/0/1">Nimrod De La Vega</a>, <a href="http://arxiv.org/find/cs/1/au:+Razin_N/0/1/0/all/0/1">Noam Razin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Nadav Cohen</a></p>
<p>The question of what makes a data distribution suitable for deep learning is
a fundamental open problem. Focusing on locally connected neural networks (a
prevalent family of architectures that includes convolutional and recurrent
neural networks as well as local self-attention models), we address this
problem by adopting theoretical tools from quantum physics. Our main
theoretical result states that a certain locally connected neural network is
capable of accurate prediction over a data distribution if and only if the data
distribution admits low quantum entanglement under certain canonical partitions
of features. As a practical application of this result, we derive a
preprocessing method for enhancing the suitability of a data distribution to
locally connected neural networks. Experiments with widespread models over
various datasets demonstrate our findings. We hope that our use of quantum
entanglement will encourage further adoption of tools from physics for formally
reasoning about the relation between deep learning and real-world data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.13472">Promptable Game Models: Text-Guided Game Simulation via Masked Diffusion Models. (arXiv:2303.13472v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Menapace_W/0/1/0/all/0/1">Willi Menapace</a>, <a href="http://arxiv.org/find/cs/1/au:+Siarohin_A/0/1/0/all/0/1">Aliaksandr Siarohin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lathuiliere_S/0/1/0/all/0/1">St&#xe9;phane Lathuili&#xe8;re</a>, <a href="http://arxiv.org/find/cs/1/au:+Achlioptas_P/0/1/0/all/0/1">Panos Achlioptas</a>, <a href="http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1">Vladislav Golyanik</a>, <a href="http://arxiv.org/find/cs/1/au:+Tulyakov_S/0/1/0/all/0/1">Sergey Tulyakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Ricci_E/0/1/0/all/0/1">Elisa Ricci</a></p>
<p>Neural video game simulators emerged as powerful tools to generate and edit
videos. Their idea is to represent games as the evolution of an environment's
state driven by the actions of its agents. While such a paradigm enables users
to play a game action-by-action, its rigidity precludes more semantic forms of
control. To overcome this limitation, we augment game models with prompts
specified as a set of natural language actions and desired states. The result-a
Promptable Game Model (PGM)-makes it possible for a user to play the game by
prompting it with high- and low-level action sequences. Most captivatingly, our
PGM unlocks the director's mode, where the game is played by specifying goals
for the agents in the form of a prompt. This requires learning "game AI",
encapsulated by our animation model, to navigate the scene using high-level
constraints, play against an adversary, and devise a strategy to win a point.
To render the resulting state, we use a compositional NeRF representation
encapsulated in our synthesis model. To foster future research, we present
newly collected, annotated and calibrated Tennis and Minecraft datasets. Our
method significantly outperforms existing neural video game simulators in terms
of rendering quality and unlocks applications beyond the capabilities of the
current state of the art. Our framework, data, and models are available at
https://snap-research.github.io/promptable-game-models/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.14317">ICE-Score: Instructing Large Language Models to Evaluate Code. (arXiv:2304.14317v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhuo_T/0/1/0/all/0/1">Terry Yue Zhuo</a></p>
<p>Recent advancements in the field of natural language generation have
facilitated the use of large language models to assess the quality of generated
text. Although these models have shown promising results in tasks such as
machine translation and summarization, their applicability in code intelligence
tasks remains limited without human involvement. The complexity of programming
concepts required for such tasks makes it difficult to develop evaluation
metrics that align with human judgment. Token-matching-based metrics, such as
BLEU, have demonstrated weak correlations with human practitioners in code
intelligence tasks. Moreover, utilizing human-written test suites to evaluate
functional correctness can be challenging in domains with low resources. To
overcome these obstacles, we propose \texttt{ICE-Score}, a new evaluation
metric via instructing large language models (LLMs) for code assessments. Our
metric addresses the limitations of existing approaches by achieving superior
correlations with functional correctness and human preferences, without the
need for test oracles or references. We evaluate the efficacy of our metric on
two different aspects (\textit{human preference} and \textit{execution
success}) and four programming languages. Our results demonstrate that our
metric surpasses state-of-the-art metrics for code generation, delivering high
levels of accuracy and consistency across various programming languages and
tasks. We also make our evaluation metric and datasets available to the
public\footnote{\url{https://github.com/terryyz/ice-score}}, encouraging
further research in evaluating code intelligence tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.04073">Explaining RL Decisions with Trajectories. (arXiv:2305.04073v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deshmukh_S/0/1/0/all/0/1">Shripad Vilasrao Deshmukh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasgupta_A/0/1/0/all/0/1">Arpan Dasgupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1">Balaji Krishnamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1">Chirag Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Theocharous_G/0/1/0/all/0/1">Georgios Theocharous</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_J/0/1/0/all/0/1">Jayakumar Subramanian</a></p>
<p>Explanation is a key component for the adoption of reinforcement learning
(RL) in many real-world decision-making problems. In the literature, the
explanation is often provided by saliency attribution to the features of the RL
agent's state. In this work, we propose a complementary approach to these
explanations, particularly for offline RL, where we attribute the policy
decisions of a trained RL agent to the trajectories encountered by it during
training. To do so, we encode trajectories in offline training data
individually as well as collectively (encoding a set of trajectories). We then
attribute policy decisions to a set of trajectories in this encoded space by
estimating the sensitivity of the decision with respect to that set. Further,
we demonstrate the effectiveness of the proposed approach in terms of quality
of attributions as well as practical scalability in diverse environments that
involve both discrete and continuous state and action spaces such as
grid-worlds, video games (Atari) and continuous control (MuJoCo). We also
conduct a human study on a simple navigation task to observe how their
understanding of the task compares with data attributed for a trained RL
policy. Keywords -- Explainable AI, Verifiability of AI Decisions, Explainable
RL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.05352">A Taxonomy of Foundation Model based Systems through the Lens of Software Architecture. (arXiv:2305.05352v6 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1">Qinghua Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Liming Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yue Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1">Zhenchang Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Whittle_J/0/1/0/all/0/1">Jon Whittle</a></p>
<p>The recent release of large language model (LLM) based chatbots, such as
ChatGPT, has attracted huge interest in foundation models. It is widely
believed that foundation models will serve as the fundamental building blocks
for future AI systems. As foundation models are in their early stages, the
design of foundation model based systems has not yet been systematically
explored. There is limited understanding about the impact of introducing
foundation models in software architecture. Therefore, in this paper, we
propose a taxonomy of foundation model based systems, which classifies and
compares the characteristics of foundation models and design options of
foundation model based systems. Our taxonomy comprises three categories: the
pretraining and adaptation of foundation models, the architecture design of
foundation model based systems, and responsible-AI-by-design. This taxonomy can
serve as concrete guidance for making major architectural design decisions when
designing foundation model based systems and highlights trade-offs arising from
design decisions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.12997">Evaluating Privacy Leakage in Split Learning. (arXiv:2305.12997v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xinchi Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Leontiadis_I/0/1/0/all/0/1">Ilias Leontiadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Melis_L/0/1/0/all/0/1">Luca Melis</a>, <a href="http://arxiv.org/find/cs/1/au:+Sablayrolles_A/0/1/0/all/0/1">Alex Sablayrolles</a>, <a href="http://arxiv.org/find/cs/1/au:+Stock_P/0/1/0/all/0/1">Pierre Stock</a></p>
<p>Privacy-Preserving machine learning (PPML) can help us train and deploy
models that utilize private information. In particular, on-device machine
learning allows us to avoid sharing raw data with a third-party server during
inference. On-device models are typically less accurate when compared to their
server counterparts due to the fact that (1) they typically only rely on a
small set of on-device features and (2) they need to be small enough to run
efficiently on end-user devices. Split Learning (SL) is a promising approach
that can overcome these limitations. In SL, a large machine learning model is
divided into two parts, with the bigger part residing on the server side and a
smaller part executing on-device, aiming to incorporate the private features.
However, end-to-end training of such models requires exchanging gradients at
the cut layer, which might encode private features or labels. In this paper, we
provide insights into potential privacy risks associated with SL. Furthermore,
we also investigate the effectiveness of various mitigation strategies. Our
results indicate that the gradients significantly improve the attackers'
effectiveness in all tested datasets reaching almost perfect reconstruction
accuracy for some features. However, a small amount of differential privacy
(DP) can effectively mitigate this risk without causing significant training
degradation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.16326">Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qingyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1">Jingcheng Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Keloth_V/0/1/0/all/0/1">Vipina Kuttichi Keloth</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xueqing Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Raja_K/0/1/0/all/0/1">Kalpana Raja</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhiyong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hua Xu</a></p>
<p>Biomedical literature is growing rapidly, making it challenging to curate and
extract knowledge manually. Biomedical natural language processing (BioNLP)
techniques that can automatically extract information from biomedical
literature help alleviate this burden. Recently, large Language Models (LLMs),
such as GPT-3 and GPT-4, have gained significant attention for their impressive
performance. However, their effectiveness in BioNLP tasks and impact on method
development and downstream users remain understudied. This pilot study (1)
establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and
one-shot settings in eight BioNLP datasets across four applications: named
entity recognition, relation extraction, multi-label document classification,
and semantic similarity and reasoning, (2) examines the errors produced by the
LLMs and categorized the errors into three types: missingness, inconsistencies,
and unwanted artificial content, and (3) provides suggestions for using LLMs in
BioNLP applications. We make the datasets, baselines, and results publicly
available to the community via
https://github.com/qingyu-qc/gpt_bionlp_benchmark.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.19604">Medication Recommendation via Domain Knowledge Informed Deep Learning. (arXiv:2305.19604v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sicen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xianbing Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a></p>
<p>Medication recommendation is a fundamental yet crucial branch of healthcare,
which provides opportunities to support clinical physicians with more accurate
medication prescriptions for patients with complex health conditions. Learning
from electronic health records (EHR) to recommend medications is the most
common way in previous studies. However, most of them neglect incorporating
domain knowledge according to the clinical manifestations in the EHR of the
patient. To address these issues, we propose a novel \textbf{D}omain
\textbf{K}nowledge \textbf{I}nformed \textbf{Net}work (DKINet) to integrate
domain knowledge with observable clinical manifestations of the patient, which
is the first dynamic domain knowledge informed framework toward medication
recommendation. In particular, we first design a knowledge-driven encoder to
capture the domain information and then develop a data-driven encoder to
integrate domain knowledge into the observable EHR. To endow the model with the
capability of temporal decision, we design an explicit medication encoder for
learning the longitudinal dependence of the patient. Extensive experiments on
three publicly available datasets verify the superiority of our method. The
code will be public upon acceptance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.01631">Bi-level Contrastive Learning for Knowledge-Enhanced Molecule Representations. (arXiv:2306.01631v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1">Pengcheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Cao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1">Tianfan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jimeng Sun</a></p>
<p>Molecule representation learning is crucial for various downstream
applications, such as understanding and predicting molecular properties and
side effects. In this paper, we propose a novel method called GODE, which takes
into account the two-level structure of individual molecules. We recognize that
molecules have an intrinsic graph structure as well as being a node in a larger
molecule knowledge graph. GODE integrates graph representations of individual
molecules with multidomain biochemical data from knowledge graphs. By
pre-training two graph neural networks (GNNs) on different graph structures,
combined with contrastive learning, GODE fuses molecular structures with their
corresponding knowledge graph substructures. This fusion results in a more
robust and informative representation, which enhances molecular property
prediction by harnessing both chemical and biological information. When
fine-tuned across 11 chemical property tasks, our model outperforms existing
benchmarks, registering an average ROC-AUC uplift of 13.8% for classification
tasks and an average RMSE/MAE enhancement of 35.1% for regression tasks.
Impressively, it surpasses the current leading model in molecule property
predictions with average advancements of 2.1% in classification and 6.4% in
regression tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02869">Data-Driven Regret Balancing for Online Model Selection in Bandits. (arXiv:2306.02869v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1">Aldo Pacchiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Dann_C/0/1/0/all/0/1">Christoph Dann</a>, <a href="http://arxiv.org/find/cs/1/au:+Gentile_C/0/1/0/all/0/1">Claudio Gentile</a></p>
<p>We consider model selection for sequential decision making in stochastic
environments with bandit feedback, where a meta-learner has at its disposal a
pool of base learners, and decides on the fly which action to take based on the
policies recommended by each base learner. Model selection is performed by
regret balancing but, unlike the recent literature on this subject, we do not
assume any prior knowledge about the base learners like candidate regret
guarantees; instead, we uncover these quantities in a data-driven manner. The
meta-learner is therefore able to leverage the realized regret incurred by each
base learner for the learning environment at hand (as opposed to the expected
regret), and single out the best such regret. We design two model selection
algorithms operating with this more ambitious notion of regret and, besides
proving model selection guarantees via regret balancing, we experimentally
demonstrate the compelling practical benefits of dealing with actual regrets
instead of candidate regret bounds.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.16001">Streamlining Social Media Information Extraction for Public Health Research with Deep Learning. (arXiv:2306.16001v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1">Yining Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shixu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Minghui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yujie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Foer_D/0/1/0/all/0/1">Dinah Foer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Siwen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Peilin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Li Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jie Yang</a></p>
<p>Objective: Social media-based public health research is crucial for epidemic
surveillance, but most studies identify relevant corpora with keyword matching.
This study develops a system to streamline the process of curating colloquial
medical dictionaries. We demonstrate the pipeline by curating a UMLS-colloquial
symptom dictionary from COVID-19-related tweets as proof of concept. Methods:
COVID-19-related tweets from February 1, 2020, to April 30, 2022 were used. The
pipeline includes three modules: a named entity recognition module to detect
symptoms in tweets; an entity normalization module to aggregate detected
entities; and a mapping module that iteratively maps entities to Unified
Medical Language System concepts. A random 500 entity sample were drawn from
the final dictionary for accuracy validation. Additionally, we conducted a
symptom frequency distribution analysis to compare our dictionary to a
pre-defined lexicon from previous research. Results: We identified 498,480
unique symptom entity expressions from the tweets. Pre-processing reduces the
number to 18,226. The final dictionary contains 38,175 unique expressions of
symptoms that can be mapped to 966 UMLS concepts (accuracy = 95%). Symptom
distribution analysis found that our dictionary detects more symptoms and is
effective at identifying psychiatric disorders like anxiety and depression,
often missed by pre-defined lexicons. Conclusion: This study advances public
health research by implementing a novel, systematic pipeline for curating
symptom lexicons from social media data. The final lexicon's high accuracy,
validated by medical professionals, underscores the potential of this
methodology to reliably interpret and categorize vast amounts of unstructured
social media data into actionable medical insights across diverse linguistic
and regional landscapes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06564">Prescriptive Process Monitoring Under Resource Constraints: A Reinforcement Learning Approach. (arXiv:2307.06564v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shoush_M/0/1/0/all/0/1">Mahmoud Shoush</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumas_M/0/1/0/all/0/1">Marlon Dumas</a></p>
<p>Prescriptive process monitoring methods seek to optimize the performance of
business processes by triggering interventions at runtime, thereby increasing
the probability of positive case outcomes. These interventions are triggered
according to an intervention policy. Reinforcement learning has been put
forward as an approach to learning intervention policies through trial and
error. Existing approaches in this space assume that the number of resources
available to perform interventions in a process is unlimited, an unrealistic
assumption in practice. This paper argues that, in the presence of resource
constraints, a key dilemma in the field of prescriptive process monitoring is
to trigger interventions based not only on predictions of their necessity,
timeliness, or effect but also on the uncertainty of these predictions and the
level of resource utilization. Indeed, committing scarce resources to an
intervention when the necessity or effects of this intervention are highly
uncertain may intuitively lead to suboptimal intervention effects. Accordingly,
the paper proposes a reinforcement learning approach for prescriptive process
monitoring that leverages conformal prediction techniques to consider the
uncertainty of the predictions upon which an intervention decision is based. An
evaluation using real-life datasets demonstrates that explicitly modeling
uncertainty using conformal predictions helps reinforcement learning agents
converge towards policies with higher net intervention gain
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12620">Past-present temporal programs over finite traces. (arXiv:2307.12620v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cabalar_P/0/1/0/all/0/1">Pedro Cabalar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dieguez_M/0/1/0/all/0/1">Mart&#xed;n Di&#xe9;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Laferriere_F/0/1/0/all/0/1">Fran&#xe7;ois Laferri&#xe8;re</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaub_T/0/1/0/all/0/1">Torsten Schaub</a></p>
<p>Extensions of Answer Set Programming with language constructs from temporal
logics, such as temporal equilibrium logic over finite traces (TELf), provide
an expressive computational framework for modeling dynamic applications. In
this paper, we study the so-called past-present syntactic subclass, which
consists of a set of logic programming rules whose body references to the past
and head to the present. Such restriction ensures that the past remains
independent of the future, which is the case in most dynamic domains. We extend
the definitions of completion and loop formulas to the case of past-present
formulas, which allows capturing the temporal stable models of a set of
past-present temporal programs by means of an LTLf expression.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.13716">FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning. (arXiv:2307.13716v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Leiming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1">Cihao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1">Sibo Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Ziling Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1">Yuming Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1">Zhaoxiang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Chee Wei Tan</a></p>
<p>Traditional federated learning uses the number of samples to calculate the
weights of each client model and uses this fixed weight value to fusion the
global model. However, in practical scenarios, each client's device and data
heterogeneity leads to differences in the quality of each client's model. Thus
the contribution to the global model is not wholly determined by the sample
size. In addition, if clients intentionally upload low-quality or malicious
models, using these models for aggregation will lead to a severe decrease in
global model accuracy. Traditional federated learning algorithms do not address
these issues. To solve this probelm, we propose FedDRL, a model fusion approach
using reinforcement learning based on a two staged approach. In the first
stage, Our method could filter out malicious models and selects trusted client
models to participate in the model fusion. In the second stage, the FedDRL
algorithm adaptively adjusts the weights of the trusted client models and
aggregates the optimal global model. We also define five model fusion scenarios
and compare our method with two baseline algorithms in those scenarios. The
experimental results show that our algorithm has higher reliability than other
algorithms while maintaining accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04292">Engineering LaCAM$^\ast$: Towards Real-Time, Large-Scale, and Near-Optimal Multi-Agent Pathfinding. (arXiv:2308.04292v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Okumura_K/0/1/0/all/0/1">Keisuke Okumura</a></p>
<p>This paper addresses the challenges of real-time, large-scale, and
near-optimal multi-agent pathfinding (MAPF) through enhancements to the
recently proposed LaCAM* algorithm. LaCAM* is a scalable search-based algorithm
that guarantees the eventual finding of optimal solutions for cumulative
transition costs. While it has demonstrated remarkable planning success rates,
surpassing various state-of-the-art MAPF methods, its initial solution quality
is far from optimal, and its convergence speed to the optimum is slow. To
overcome these limitations, this paper introduces several improvement
techniques, partly drawing inspiration from other MAPF methods. We provide
empirical evidence that the fusion of these techniques significantly improves
the solution quality of LaCAM*, thus further pushing the boundaries of MAPF
algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04586">Bootstrapping Developmental AIs: From Simple Competences to Intelligent Human-Compatible AIs. (arXiv:2308.04586v17 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Stefik_M/0/1/0/all/0/1">Mark Stefik</a>, <a href="http://arxiv.org/find/cs/1/au:+Price_R/0/1/0/all/0/1">Robert Price</a></p>
<p>Developmental AI is a bootstrapping approach where embodied AIs start with
innate competences and learn by interacting with the world. They develop
abilities in small steps along a bio-inspired trajectory. However,
developmental AIs have not yet reached the abilities of young children. In
contrast, mainstream approaches for creating AIs have led to valuable AI
systems and impressive feats. These approaches include deep learning and
generative approaches (e.g., large language models) and manually constructed
symbolic approaches. Manually constructed AIs are brittle even in circumscribed
domains. Generative AIs can make strange mistakes and not notice them. Taken
together, mainstream approaches lack common sense, curiosity, and social
alignment. This position paper lays out prospects, gaps, and challenges for
augmenting the AI mainstream approaches with developmental AI. The ambition is
to create data-rich experientially based foundation models for
human-compatible, resilient, and trustworthy AIs. This research aims to produce
developmental AIs that learn to communicate, establish common ground, read
critically, consider the provenance of information, test hypotheses, and
collaborate. A virtuous multidisciplinary research cycle has led to
developmental AIs with capabilities for multimodal perception, object
recognition, and manipulation. Computational models for hierarchical planning,
abstraction discovery, curiosity, and language acquisition exist but need to be
adapted to an embodied learning approach. They need to bridge competence gaps
involving nonverbal communication, speech, reading, and writing.
Aspirationally, developmental AIs would learn, share what they learn, and
collaborate to achieve high standards. The approach would make the creation of
AIs more democratic, enabling more people to train, test, build on, and
replicate AIs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04942">Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation. (arXiv:2308.04942v2 [cs.NI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1">Hongyang Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1">Dusit Niyato</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jiawen Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1">Zehui Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong In Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Xuemin/0/1/0/all/0/1">Xuemin</a> (Sherman) <a href="http://arxiv.org/find/cs/1/au:+Shen/0/1/0/all/0/1">Shen</a></p>
<p>Artificial Intelligence Generated Content (AIGC) Services have significant
potential in digital content creation. The distinctive abilities of AIGC, such
as content generation based on minimal input, hold huge potential, especially
when integrating with semantic communication (SemCom). In this paper, a novel
comprehensive conceptual model for the integration of AIGC and SemCom is
developed. Particularly, a content generation level is introduced on top of the
semantic level that provides a clear outline of how AIGC and SemCom interact
with each other to produce meaningful and effective content. Moreover, a novel
framework that employs AIGC technology is proposed as an encoder and decoder
for semantic information, considering the joint optimization of semantic
extraction and evaluation metrics tailored to AIGC services. The framework can
adapt to different types of content generated, the required quality, and the
semantic information utilized. By employing a Deep Q Network (DQN), a case
study is presented that provides useful insights into the feasibility of the
optimization problem and its convergence characteristics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.09647">Robust Uncertainty Quantification Using Conformalised Monte Carlo Prediction. (arXiv:2308.09647v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bethell_D/0/1/0/all/0/1">Daniel Bethell</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerasimou_S/0/1/0/all/0/1">Simos Gerasimou</a>, <a href="http://arxiv.org/find/cs/1/au:+Calinescu_R/0/1/0/all/0/1">Radu Calinescu</a></p>
<p>Deploying deep learning models in safety-critical applications remains a very
challenging task, mandating the provision of assurances for the dependable
operation of these models. Uncertainty quantification (UQ) methods estimate the
model's confidence per prediction, informing decision-making by considering the
effect of randomness and model misspecification. Despite the advances of
state-of-the-art UQ methods, they are computationally expensive or produce
conservative prediction sets/intervals. We introduce MC-CP, a novel hybrid UQ
method that combines a new adaptive Monte Carlo (MC) dropout method with
conformal prediction (CP). MC-CP adaptively modulates the traditional MC
dropout at runtime to save memory and computation resources, enabling
predictions to be consumed by CP, yielding robust prediction sets/intervals.
Throughout comprehensive experiments, we show that MC-CP delivers significant
improvements over advanced UQ methods, like MC dropout, RAPS and CQR, both in
classification and regression benchmarks. MC-CP can be easily added to existing
models, making its deployment simple.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.13507">Large Language Models Should Ask Clarifying Questions to Increase Confidence in Generated Code. (arXiv:2308.13507v2 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jie JW Wu</a></p>
<p>Large language models (LLMs) have significantly improved the ability to
perform tasks in the field of code generation. However, there is still a gap
between LLMs being capable coders and being top-tier software engineers. Based
on the observation that toplevel software engineers often ask clarifying
questions to reduce ambiguity in both requirements and coding solutions, I
argue that the same should be applied to LLMs for code generation tasks. By
asking probing questions in various topics before generating the final code,
the challenges of programming with LLMs, such as unclear intent specification,
lack of computational thinking, and undesired code quality, may be alleviated.
This, in turn, increases confidence in the generated code. In this work, I
explore how to leverage better communication skills to achieve greater
confidence in generated code. I propose a communication-centered process that
uses an LLM-generated communicator to identify issues with high ambiguity or
low confidence in problem descriptions and generated code. I then ask
clarifying questions to obtain responses from users for refining the code.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.13894">FwdLLM: Efficient FedLLM using Forward Gradient. (arXiv:2308.13894v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1">Dongqi Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yaozong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shangguang Wang</a></p>
<p>Large Language Models (LLMs) are transforming the landscape of mobile
intelligence. Federated Learning (FL), a method to preserve user data privacy,
is often employed in fine-tuning LLMs to downstream mobile tasks, an approach
known as FedLLM. Though recent efforts have addressed the network issue induced
by the vast model size, they have not practically mitigated vital challenges
concerning integration with mobile devices, such as significant memory
consumption and sluggish model convergence.
</p>
<p>In response to these challenges, this work introduces FwdLLM, an innovative
FL protocol designed to enhance the FedLLM efficiency. The key idea of FwdLLM
to employ backpropagation (BP)-free training methods, requiring devices only to
execute ``perturbed inferences''. Consequently, FwdLLM delivers way better
memory efficiency and time efficiency (expedited by mobile NPUs and an expanded
array of participant devices). FwdLLM centers around three key designs: (1) it
combines BP-free training with parameter-efficient training methods, an
essential way to scale the approach to the LLM era; (2) it systematically and
adaptively allocates computational loads across devices, striking a careful
balance between convergence speed and accuracy; (3) it discriminatively samples
perturbed predictions that are more valuable to model convergence.
Comprehensive experiments with five LLMs and three NLP tasks illustrate
FwdLLM's significant advantages over conventional methods, including up to
three orders of magnitude faster convergence and a 14.6x reduction in memory
footprint. Uniquely, FwdLLM paves the way for federated learning of
billion-parameter LLMs such as LLaMA on COTS mobile devices -- a feat
previously unattained.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.01538">ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning. (arXiv:2309.01538v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1">Linhao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_J/0/1/0/all/0/1">Jiaxin Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_B/0/1/0/all/0/1">Bo Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuan-Fang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1">Gholamreza Haffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shirui Pan</a></p>
<p>Logical rules are essential for uncovering the logical connections between
relations, which could improve reasoning performance and provide interpretable
results on knowledge graphs (KGs). Although there have been many efforts to
mine meaningful logical rules over KGs, existing methods suffer from
computationally intensive searches over the rule space and a lack of
scalability for large-scale KGs. Besides, they often ignore the semantics of
relations which is crucial for uncovering logical connections. Recently, large
language models (LLMs) have shown impressive performance in the field of
natural language processing and various applications, owing to their emergent
ability and generalizability. In this paper, we propose a novel framework,
ChatRule, unleashing the power of large language models for mining logical
rules over knowledge graphs. Specifically, the framework is initiated with an
LLM-based rule generator, leveraging both the semantic and structural
information of KGs to prompt LLMs to generate logical rules. To refine the
generated rules, a rule ranking module estimates the rule quality by
incorporating facts from existing KGs. Last, the ranked rules can be used to
conduct reasoning over KGs. ChatRule is evaluated on four large-scale KGs,
w.r.t. different rule quality metrics and downstream tasks, showing the
effectiveness and scalability of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.05030">Decolonial AI Alignment: Openness, Vi\&#x27;{s}e\d{s}a-Dharma, and Including Excluded Knowledges. (arXiv:2309.05030v2 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1">Kush R. Varshney</a></p>
<p>Prior work has explicated the coloniality of artificial intelligence (AI)
development and deployment through mechanisms such as extractivism, automation,
sociological essentialism, surveillance, and containment. However, that work
has not engaged much with alignment: teaching behaviors to a large language
model (LLM) in line with desired values, and has not considered a mechanism
that arises within that process: moral absolutism -- a part of the coloniality
of knowledge. Colonialism has a history of altering the beliefs and values of
colonized peoples; in this paper, I argue that this history is recapitulated in
current LLM alignment practices and technologies. Furthermore, I suggest that
AI alignment be decolonialized using three forms of openness: openness of
models, openness to society, and openness to excluded knowledges. This
suggested approach to decolonial AI alignment uses ideas from the argumentative
moral philosophical tradition of Hinduism, which has been described as an
open-source religion. One concept used is vi\'{s}e\d{s}a-dharma, or particular
context-specific notions of right and wrong. At the end of the paper, I provide
a suggested reference architecture to work toward the proposed framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.05173">DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning. (arXiv:2309.05173v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhengxiang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipani_A/0/1/0/all/0/1">Aldo Lipani</a></p>
<p>Prompt tuning (PT), where a small amount of trainable soft (continuous)
prompt vectors is affixed to the input of language models (LM), has shown
promising results across various tasks and models for parameter-efficient
fine-tuning (PEFT). PT stands out from other PEFT approaches because it
maintains competitive performance with fewer trainable parameters and does not
drastically scale up its parameters as the model size expands. However, PT
introduces additional soft prompt tokens, leading to longer input sequences,
which significantly impacts training and inference time and memory usage due to
the Transformer's quadratic complexity. Particularly concerning for Large
Language Models (LLMs) that face heavy daily querying. To address this issue,
we propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt
into a shorter soft prompt and a pair of low-rank matrices that are then
optimised with two different learning rates. This allows DePT to achieve better
performance while saving substantial memory and time costs compared to vanilla
PT and its variants, without changing trainable parameter sizes. Through
extensive experiments on 23 natural language processing (NLP) and
vision-language (VL) tasks, we demonstrate that DePT outperforms
state-of-the-art PEFT approaches, including the full fine-tuning baseline, in
some scenarios. Additionally, we empirically show that DEPT grows more
efficient as the model size increases. Our further study reveals that DePT
integrates seamlessly with parameter-efficient transfer learning in the
few-shot learning setting and highlights its adaptability to various model
architectures and sizes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.06629">The Relational Bottleneck as an Inductive Bias for Efficient Abstraction. (arXiv:2309.06629v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Webb_T/0/1/0/all/0/1">Taylor W. Webb</a>, <a href="http://arxiv.org/find/cs/1/au:+Frankland_S/0/1/0/all/0/1">Steven M. Frankland</a>, <a href="http://arxiv.org/find/cs/1/au:+Altabaa_A/0/1/0/all/0/1">Awni Altabaa</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_K/0/1/0/all/0/1">Kamesh Krishnamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1">Declan Campbell</a>, <a href="http://arxiv.org/find/cs/1/au:+Russin_J/0/1/0/all/0/1">Jacob Russin</a>, <a href="http://arxiv.org/find/cs/1/au:+OReilly_R/0/1/0/all/0/1">Randall O&#x27;Reilly</a>, <a href="http://arxiv.org/find/cs/1/au:+Lafferty_J/0/1/0/all/0/1">John Lafferty</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1">Jonathan D. Cohen</a></p>
<p>A central challenge for cognitive science is to explain how abstract concepts
are acquired from limited experience. This effort has often been framed in
terms of a dichotomy between connectionist and symbolic cognitive models. Here,
we highlight a recently emerging line of work that suggests a novel
reconciliation of these approaches, by exploiting an inductive bias that we
term the relational bottleneck. We review a family of models that employ this
approach to induce abstractions in a data-efficient manner, emphasizing their
potential as candidate models for the acquisition of abstract concepts in the
human mind and brain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.07525">SingFake: Singing Voice Deepfake Detection. (arXiv:2309.07525v2 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zang_Y/0/1/0/all/0/1">Yongyi Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">You Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Heydari_M/0/1/0/all/0/1">Mojtaba Heydari</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhiyao Duan</a></p>
<p>The rise of singing voice synthesis presents critical challenges to artists
and industry stakeholders over unauthorized voice usage. Unlike synthesized
speech, synthesized singing voices are typically released in songs containing
strong background music that may hide synthesis artifacts. Additionally,
singing voices present different acoustic and linguistic characteristics from
speech utterances. These unique properties make singing voice deepfake
detection a relevant but significantly different problem from synthetic speech
detection. In this work, we propose the singing voice deepfake detection task.
We first present SingFake, the first curated in-the-wild dataset consisting of
28.93 hours of bonafide and 29.40 hours of deepfake song clips in five
languages from 40 singers. We provide a train/validation/test split where the
test sets include various scenarios. We then use SingFake to evaluate four
state-of-the-art speech countermeasure systems trained on speech utterances. We
find these systems lag significantly behind their performance on speech test
data. When trained on SingFake, either using separated vocal tracks or song
mixtures, these systems show substantial improvement. However, our evaluations
also identify challenges associated with unseen singers, communication codecs,
languages, and musical contexts, calling for dedicated research into singing
voice deepfake detection. The SingFake dataset and related resources are
available at https://www.singfake.org/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.11680">Federated Learning with Neural Graphical Models. (arXiv:2309.11680v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chajewska_U/0/1/0/all/0/1">Urszula Chajewska</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_H/0/1/0/all/0/1">Harsh Shrivastava</a></p>
<p>Federated Learning (FL) addresses the need to create models based on
proprietary data in such a way that multiple clients retain exclusive control
over their data, while all benefit from improved model accuracy due to pooled
resources. Recently proposed Neural Graphical Models (NGMs) are Probabilistic
Graphical models that utilize the expressive power of neural networks to learn
complex non-linear dependencies between the input features. They learn to
capture the underlying data distribution and have efficient algorithms for
inference and sampling. We develop a FL framework which maintains a global NGM
model that learns the averaged information from the local NGM models while
keeping the training data within the client's environment. Our design, FedNGMs,
avoids the pitfalls and shortcomings of neuron matching frameworks like
Federated Matched Averaging that suffers from model parameter explosion. Our
global model size remains constant throughout the process. In the cases where
clients have local variables that are not part of the combined global
distribution, we propose a `Stitching' algorithm, which personalizes the global
NGM models by merging the additional variables using the client's data. FedNGM
is robust to data heterogeneity, large number of participants, and limited
communication bandwidth.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12244">ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events. (arXiv:2309.12244v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Seo_W/0/1/0/all/0/1">Woosuk Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chanmo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Young-Ho Kim</a></p>
<p>Children typically learn to identify and express emotions through sharing
their stories and feelings with others, particularly their family. However, it
is challenging for parents or siblings to have emotional communication with
children since children are still developing their communication skills. We
present ChaCha, a chatbot that encourages and guides children to share personal
events and associated emotions. ChaCha combines a state machine and large
language models (LLMs) to keep the dialogue on track while carrying on
free-form conversations. Through an exploratory study with 20 children (aged
8-12), we examine how ChaCha prompts children to share personal events and
guides them to describe associated emotions. Participants perceived ChaCha as a
close friend and shared their stories on various topics, such as family trips
and personal achievements. Based on the findings, we discuss opportunities for
leveraging LLMs to design child-friendly chatbots to support children in
sharing emotions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.12247">Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. (arXiv:2309.12247v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Beizhe Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1">Qiang Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Juan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yuhui Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Danding Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_P/0/1/0/all/0/1">Peng Qi</a></p>
<p>Detecting fake news requires both a delicate sense of diverse clues and a
profound understanding of the real-world background, which remains challenging
for detectors based on small language models (SLMs) due to their knowledge and
capability limitations. Recent advances in large language models (LLMs) have
shown remarkable performance in various tasks, but whether and how LLMs could
help with fake news detection remains underexplored. In this paper, we
investigate the potential of LLMs in fake news detection. First, we conduct an
empirical study and find that a sophisticated LLM such as GPT 3.5 could
generally expose fake news and provide desirable multi-perspective rationales
but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis
attributes such a gap to the LLM's inability to select and integrate rationales
properly to conclude. Based on these findings, we propose that current LLMs may
not substitute fine-tuned SLMs in fake news detection but can be a good advisor
for SLMs by providing multi-perspective instructive rationales. To instantiate
this proposal, we design an adaptive rationale guidance network for fake news
detection (ARG), in which SLMs selectively acquire insights on news analysis
from the LLMs' rationales. We further derive a rationale-free version of ARG by
distillation, namely ARG-D, which services cost-sensitive scenarios without
querying LLMs. Experiments on two real-world datasets demonstrate that ARG and
ARG-D outperform three types of baseline methods, including SLM-based,
LLM-based, and combinations of small and large language models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.13365">Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs. (arXiv:2309.13365v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kohler_H/0/1/0/all/0/1">Hector Kohler</a>, <a href="http://arxiv.org/find/cs/1/au:+Akrour_R/0/1/0/all/0/1">Riad Akrour</a>, <a href="http://arxiv.org/find/cs/1/au:+Preux_P/0/1/0/all/0/1">Philippe Preux</a></p>
<p>Interpretability of AI models allows for user safety checks to build trust in
such AIs. In particular, Decision Trees (DTs) provide a global look at the
learned model and transparently reveal which features of the input are critical
for making a decision. However, interpretability is hindered if the DT is too
large. To learn compact trees, a recent Reinforcement Learning (RL) framework
has been proposed to explore the space of DTs using deep RL. This framework
augments a decision problem (e.g. a supervised classification task) with
additional actions that gather information about the features of an otherwise
hidden input. By appropriately penalizing these actions, the agent learns to
optimally trade-off size and performance of DTs. In practice, a reactive policy
for a partially observable Markov decision process (MDP) needs to be learned,
which is still an open problem. We show in this paper that deep RL can fail
even on simple toy tasks of this class. However, when the underlying decision
problem is a supervised classification task, we show that finding the optimal
tree can be cast as a fully observable Markov decision problem and be solved
efficiently, giving rise to a new family of algorithms for learning DTs that go
beyond the classical greedy maximization ones.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.00106">FashionFlow: Leveraging Diffusion Models for Dynamic Fashion Video Synthesis from Static Imagery. (arXiv:2310.00106v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1">Tasin Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Miron_A/0/1/0/all/0/1">Alina Miron</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">XiaoHui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yongmin Li</a></p>
<p>Our study introduces a new image-to-video generator called FashionFlow to
generate fashion videos. By utilising a diffusion model, we are able to create
short videos from still fashion images. Our approach involves developing and
connecting relevant components with the diffusion model, which results in the
creation of high-fidelity videos that are aligned with the conditional image.
The components include the use of pseudo-3D convolutional layers to generate
videos efficiently. VAE and CLIP encoders capture vital characteristics from
still images to condition the diffusion model at a global level. Our research
demonstrates a successful synthesis of fashion videos featuring models posing
from various angles, showcasing the fit and appearance of the garment. Our
findings hold great promise for improving and enhancing the shopping experience
for the online fashion industry.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.01852">LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment. (arXiv:2310.01852v7 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Bin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ning_M/0/1/0/all/0/1">Munan Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jiaxi Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">HongFa Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">Yatian Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wenhao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junwu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zongwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wancai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Li Yuan</a></p>
<p>The video-language (VL) pretraining has achieved remarkable improvement in
multiple downstream tasks. However, the current VL pretraining framework is
hard to extend to multiple modalities (N modalities, N&gt;=3) beyond vision and
language. We thus propose LanguageBind, taking the language as the bind across
different modalities because the language modality is well-explored and
contains rich semantics. Specifically, we freeze the language encoder acquired
by VL pretraining, then train encoders for other modalities with contrastive
learning. As a result, all modalities are mapped to a shared feature space,
implementing multi-modal semantic alignment. While LanguageBind ensures that we
can extend VL modalities to N modalities, we also need a high-quality dataset
with alignment data pairs centered on language. We thus propose VIDAL-10M with
Video, Infrared, Depth, Audio and their corresponding Language, naming as
VIDAL-10M. In our VIDAL-10M, all videos are from short video platforms with
complete semantics rather than truncated segments from long videos, and all the
video, depth, infrared, and audio modalities are aligned to their textual
descriptions. LanguageBind has achieved superior performance on a wide range of
15 benchmarks covering video, audio, depth, and infrared. Moreover, multiple
experiments have provided evidence for the effectiveness of LanguageBind in
achieving indirect alignment and complementarity among diverse modalities. Code
address: https://github.com/PKU-YuanGroup/LanguageBind
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02118">TWIZ-v2: The Wizard of Multimodal Conversational-Stimulus. (arXiv:2310.02118v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ferreira_R/0/1/0/all/0/1">Rafael Ferreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Tavares_D/0/1/0/all/0/1">Diogo Tavares</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_D/0/1/0/all/0/1">Diogo Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Valerio_R/0/1/0/all/0/1">Rodrigo Val&#xe9;rio</a>, <a href="http://arxiv.org/find/cs/1/au:+Bordalo_J/0/1/0/all/0/1">Jo&#xe3;o Bordalo</a>, <a href="http://arxiv.org/find/cs/1/au:+Simoes_I/0/1/0/all/0/1">In&#xea;s Sim&#xf5;es</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_V/0/1/0/all/0/1">Vasco Ramos</a>, <a href="http://arxiv.org/find/cs/1/au:+Semedo_D/0/1/0/all/0/1">David Semedo</a>, <a href="http://arxiv.org/find/cs/1/au:+Magalhaes_J/0/1/0/all/0/1">Jo&#xe3;o Magalh&#xe3;es</a></p>
<p>In this report, we describe the vision, challenges, and scientific
contributions of the Task Wizard team, TWIZ, in the Alexa Prize TaskBot
Challenge 2022. Our vision, is to build TWIZ bot as an helpful, multimodal,
knowledgeable, and engaging assistant that can guide users towards the
successful completion of complex manual tasks. To achieve this, we focus our
efforts on three main research questions: (1) Humanly-Shaped Conversations, by
providing information in a knowledgeable way; (2) Multimodal Stimulus, making
use of various modalities including voice, images, and videos; and (3)
Zero-shot Conversational Flows, to improve the robustness of the interaction to
unseen scenarios. TWIZ is an assistant capable of supporting a wide range of
tasks, with several innovative features such as creative cooking, video
navigation through voice, and the robust TWIZ-LLM, a Large Language Model
trained for dialoguing about complex manual tasks. Given ratings and feedback
provided by users, we observed that TWIZ bot is an effective and robust system,
capable of guiding users through tasks while providing several multimodal
stimuli.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02255">MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts. (arXiv:2310.02255v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_H/0/1/0/all/0/1">Hritik Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1">Tony Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiacheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Hao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1">Michel Galley</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a></p>
<p>Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit
impressive problem-solving skills in many tasks and domains, but their ability
in mathematical reasoning in visual contexts has not been systematically
studied. To bridge this gap, we present MathVista, a benchmark designed to
combine challenges from diverse mathematical and visual tasks. It consists of
6,141 examples, derived from 28 existing multimodal datasets involving
mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and
PaperQA). Completing these tasks requires fine-grained, deep visual
understanding and compositional reasoning, which all state-of-the-art
foundation models find challenging. With MathVista, we have conducted a
comprehensive, quantitative evaluation of 12 prominent foundation models. The
best-performing GPT-4V model achieves an overall accuracy of 49.9%,
substantially outperforming Bard, the second-best performer, by 15.1%. Our
in-depth analysis reveals that the superiority of GPT-4V is mainly attributed
to its enhanced visual perception and mathematical reasoning. However, GPT-4V
still falls short of human performance by 10.4%, as it often struggles to
understand complex figures and perform rigorous reasoning. This significant gap
underscores the critical role that MathVista will play in the development of
general-purpose AI agents capable of tackling mathematically intensive and
visually rich real-world tasks. We further explore the new ability of
self-verification, the application of self-consistency, and the interactive
chatbot capabilities of GPT-4V, highlighting its promising potential for future
research. The project is available at https://mathvista.github.io/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.05916">Interpreting CLIP&#x27;s Image Representation via Text-Based Decomposition. (arXiv:2310.05916v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gandelsman_Y/0/1/0/all/0/1">Yossi Gandelsman</a>, <a href="http://arxiv.org/find/cs/1/au:+Efros_A/0/1/0/all/0/1">Alexei A. Efros</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1">Jacob Steinhardt</a></p>
<p>We investigate the CLIP image encoder by analyzing how individual model
components affect the final representation. We decompose the image
representation as a sum across individual image patches, model layers, and
attention heads, and use CLIP's text representation to interpret the summands.
Interpreting the attention heads, we characterize each head's role by
automatically finding text representations that span its output space, which
reveals property-specific roles for many heads (e.g. location or shape). Next,
interpreting the image patches, we uncover an emergent spatial localization
within CLIP. Finally, we use this understanding to remove spurious features
from CLIP and to create a strong zero-shot image segmenter. Our results
indicate that a scalable understanding of transformer models is attainable and
can be used to repair and improve models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.11036">Radio Map Estimation: Empirical Validation and Analysis. (arXiv:2310.11036v2 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Shrestha_R/0/1/0/all/0/1">Raju Shrestha</a>, <a href="http://arxiv.org/find/eess/1/au:+Ha_T/0/1/0/all/0/1">Tien Ngoc Ha</a>, <a href="http://arxiv.org/find/eess/1/au:+Viet_P/0/1/0/all/0/1">Pham Q. Viet</a>, <a href="http://arxiv.org/find/eess/1/au:+Romero_D/0/1/0/all/0/1">Daniel Romero</a></p>
<p>Radio maps quantify magnitudes such as the received signal strength at every
location of a geographical region. Although the estimation of radio maps has
attracted widespread interest, the vast majority of works rely on simulated
data and, therefore, cannot establish the effectiveness and relative
performance of existing algorithms in practice. To fill this gap, this paper
presents the first comprehensive and rigorous study of radio map estimation
(RME) in the real world. The main features of the RME problem are analyzed and
the capabilities of existing estimators are compared using large measurement
datasets collected in this work. By studying four performance metrics, recent
theoretical findings are empirically corroborated and a large number of
conclusions are drawn. Remarkably, the estimation error is seen to be
reasonably small even with few measurements, which establishes the viability of
RME in practice. Besides, from extensive comparisons, it is concluded that
estimators based on deep neural networks necessitate large volumes of training
data to exhibit a significant advantage over more traditional methods.
Combining both types of schemes is seen to result in a novel estimator that
features the best performance in most situations. The acquired datasets are
made publicly available to enable further studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.12817">2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision. (arXiv:2310.12817v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng-Kun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Min-Hung Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yung-Yu Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yen-Yu Lin</a></p>
<p>We present a Multimodal Interlaced Transformer (MIT) that jointly considers
2D and 3D data for weakly supervised point cloud segmentation. Research studies
have shown that 2D and 3D features are complementary for point cloud
segmentation. However, existing methods require extra 2D annotations to achieve
2D-3D information fusion. Considering the high annotation cost of point clouds,
effective 2D and 3D feature fusion based on weakly supervised learning is in
great demand. To this end, we propose a transformer model with two encoders and
one decoder for weakly supervised point cloud segmentation using only
scene-level class tags. Specifically, the two encoders compute the
self-attended features for 3D point clouds and 2D multi-view images,
respectively. The decoder implements interlaced 2D-3D cross-attention and
carries out implicit 2D and 3D feature fusion. We alternately switch the roles
of queries and key-value pairs in the decoder layers. It turns out that the 2D
and 3D features are iteratively enriched by each other. Experiments show that
it performs favorably against existing weakly supervised point cloud
segmentation methods by a large margin on the S3DIS and ScanNet benchmarks. The
project page will be available at https://jimmy15923.github.io/mit_web/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.15823">Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment. (arXiv:2310.15823v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+ElBakry_A/0/1/0/all/0/1">Ahmed ElBakry</a>, <a href="http://arxiv.org/find/cs/1/au:+Gabr_M/0/1/0/all/0/1">Mohamed Gabr</a>, <a href="http://arxiv.org/find/cs/1/au:+ElNokrashy_M/0/1/0/all/0/1">Muhammad ElNokrashy</a>, <a href="http://arxiv.org/find/cs/1/au:+AlKhamissi_B/0/1/0/all/0/1">Badr AlKhamissi</a></p>
<p>A Reverse Dictionary is a tool enabling users to discover a word based on its
provided definition, meaning, or description. Such a technique proves valuable
in various scenarios, aiding language learners who possess a description of a
word without its identity, and benefiting writers seeking precise terminology.
These scenarios often encapsulate what is referred to as the
"Tip-of-the-Tongue" (TOT) phenomena. In this work, we present our winning
solution for the Arabic Reverse Dictionary shared task. This task focuses on
deriving a vector representation of an Arabic word from its accompanying
description. The shared task encompasses two distinct subtasks: the first
involves an Arabic definition as input, while the second employs an English
definition. For the first subtask, our approach relies on an ensemble of
finetuned Arabic BERT-based models, predicting the word embedding for a given
definition. The final representation is obtained through averaging the output
embeddings from each model within the ensemble. In contrast, the most effective
solution for the second subtask involves translating the English test
definitions into Arabic and applying them to the finetuned models originally
trained for the first subtask. This straightforward method achieves the highest
score across both subtasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.20381">A Systematic Evaluation of GPT-4V&#x27;s Multimodal Capability for Medical Image Analysis. (arXiv:2310.20381v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yunyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhanyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xinyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingqiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Leyang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhaopeng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Longyue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Luping Zhou</a></p>
<p>This work conducts an evaluation of GPT-4V's multimodal capability for
medical image analysis, with a focus on three representative tasks of radiology
report generation, medical visual question answering, and medical visual
grounding. For the evaluation, a set of prompts is designed for each task to
induce the corresponding capability of GPT-4V to produce sufficiently good
outputs. Three evaluation ways including quantitative analysis, human
evaluation, and case study are employed to achieve an in-depth and extensive
evaluation. Our evaluation shows that GPT-4V excels in understanding medical
images and is able to generate high-quality radiology reports and effectively
answer questions about medical images. Meanwhile, it is found that its
performance for medical visual grounding needs to be substantially improved. In
addition, we observe the discrepancy between the evaluation outcome from
quantitative analysis and that from human evaluation. This discrepancy suggests
the limitations of conventional metrics in assessing the performance of large
language models like GPT-4V and the necessity of developing new metrics for
automatic quantitative analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.06101">In-Context Learning for MIMO Equalization Using Transformer-Based Sequence Models. (arXiv:2311.06101v2 [cs.IT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zecchin_M/0/1/0/all/0/1">Matteo Zecchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1">Kai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1">Osvaldo Simeone</a></p>
<p>Large pre-trained sequence models, such as transformer-based architectures,
have been recently shown to have the capacity to carry out in-context learning
(ICL). In ICL, a decision on a new input is made via a direct mapping of the
input and of a few examples from the given task, serving as the task's context,
to the output variable. No explicit updates of the model parameters are needed
to tailor the decision to a new task. Pre-training, which amounts to a form of
meta-learning, is based on the observation of examples from several related
tasks. Prior work has shown ICL capabilities for linear regression. In this
study, we leverage ICL to address the inverse problem of multiple-input and
multiple-output (MIMO) equalization based on a context given by pilot symbols.
A task is defined by the unknown fading channel and by the signal-to-noise
ratio (SNR) level, which may be known. To highlight the practical potential of
the approach, we allow the presence of quantization of the received signals. We
demonstrate via numerical results that transformer-based ICL has a threshold
behavior, whereby, as the number of pre-training tasks grows, the performance
switches from that of a minimum mean squared error (MMSE) equalizer with a
prior determined by the pre-trained tasks to that of an MMSE equalizer with the
true data-generating prior.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.06979">Assessing the Interpretability of Programmatic Policies with Large Language Models. (arXiv:2311.06979v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bashir_Z/0/1/0/all/0/1">Zahra Bashir</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowling_M/0/1/0/all/0/1">Michael Bowling</a>, <a href="http://arxiv.org/find/cs/1/au:+Lelis_L/0/1/0/all/0/1">Levi H. S. Lelis</a></p>
<p>Although the synthesis of programs encoding policies often carries the
promise of interpretability, systematic evaluations were never performed to
assess the interpretability of these policies, likely because of the complexity
of such an evaluation. In this paper, we introduce a novel metric that uses
large-language models (LLM) to assess the interpretability of programmatic
policies. For our metric, an LLM is given both a program and a description of
its associated programming language. The LLM then formulates a natural language
explanation of the program. This explanation is subsequently fed into a second
LLM, which tries to reconstruct the program from the natural-language
explanation. Our metric then measures the behavioral similarity between the
reconstructed program and the original. We validate our approach with
synthesized and human-crafted programmatic policies for playing a real-time
strategy game, comparing the interpretability scores of these programmatic
policies to obfuscated versions of the same programs. Our LLM-based
interpretability score consistently ranks less interpretable programs lower and
more interpretable ones higher. These findings suggest that our metric could
serve as a reliable and inexpensive tool for evaluating the interpretability of
programmatic policies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.07989">Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code. (arXiv:2311.07989v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziyin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bingchang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1">Cong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1">Zi Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a></p>
<p>In this work we systematically review the recent advancements in code
processing with language models, covering 50+ models, 30+ evaluation tasks,
170+ datasets, and 700+ related works. We break down code processing models
into general language models represented by the GPT family and specialized
models that are specifically pretrained on code, often with tailored
objectives. We discuss the relations and differences between these models, and
highlight the historical transition of code modeling from statistical models
and RNNs to pretrained Transformers and LLMs, which is exactly the same course
that had been taken by NLP. We also discuss code-specific features such as AST,
CFG, and unit tests, along with their application in training code language
models, and identify key challenges and potential future directions in this
domain. We keep the survey open and updated on GitHub at
https://github.com/codefuse-ai/Awesome-Code-LLM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.09127">Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts. (arXiv:2311.09127v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuanwei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a></p>
<p>Existing work on jailbreak Multimodal Large Language Models (MLLMs) has
focused primarily on adversarial examples in model inputs, with less attention
to vulnerabilities, especially in model API. To fill the research gap, we carry
out the following work: 1) We discover a system prompt leakage vulnerability in
GPT-4V. Through carefully designed dialogue, we successfully extract the
internal system prompts of GPT-4V. This finding indicates potential exploitable
security risks in MLLMs; 2) Based on the acquired system prompts, we propose a
novel MLLM jailbreaking attack method termed SASP (Self-Adversarial Attack via
System Prompt). By employing GPT-4 as a red teaming tool against itself, we aim
to search for potential jailbreak prompts leveraging stolen system prompts.
Furthermore, in pursuit of better performance, we also add human modification
based on GPT-4's analysis, which further improves the attack success rate to
98.7\%; 3) We evaluated the effect of modifying system prompts to defend
against jailbreaking attacks. Results show that appropriately designed system
prompts can significantly reduce jailbreak success rates. Overall, our work
provides new insights into enhancing MLLM security, demonstrating the important
role of system prompts in jailbreaking. This finding could be leveraged to
greatly facilitate jailbreak success rates while also holding the potential for
defending against jailbreaks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13373">Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents. (arXiv:2311.13373v4 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zihao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chenyang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bin Liu</a></p>
<p>Recent studies have uncovered the potential of Large Language Models (LLMs)
in addressing complex sequential decision-making tasks through the provision of
high-level instructions. However, LLM-based agents lack specialization in
tackling specific target problems, particularly in real-time dynamic
environments. Additionally, deploying an LLM-based agent in practical scenarios
can be both costly and time-consuming. On the other hand, reinforcement
learning (RL) approaches train agents that specialize in the target task but
often suffer from low sampling efficiency and high exploration costs. In this
paper, we introduce a novel framework that addresses these challenges by
training a smaller, specialized student RL agent using instructions from an
LLM-based teacher agent. By incorporating the guidance from the teacher agent,
the student agent can distill the prior knowledge of the LLM into its own
model. Consequently, the student agent can be trained with significantly less
data. Moreover, through further training with environment feedback, the student
agent surpasses the capabilities of its teacher for completing the target task.
We conducted experiments on challenging MiniGrid and Habitat environments,
specifically designed for embodied AI research, to evaluate the effectiveness
of our framework. The results clearly demonstrate that our approach achieves
superior performance compared to strong baseline methods. Our code is available
at https://github.com/ZJLAB-AMMI/LLM4Teach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.16141">Criticality-Guided Efficient Pruning in Spiking Neural Networks Inspired by Critical Brain Hypothesis. (arXiv:2311.16141v2 [cs.NE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Boxiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1">Haihang You</a></p>
<p>Spiking Neural Networks (SNNs) have gained considerable attention due to the
energy-efficient and multiplication-free characteristics. The continuous growth
in scale of deep SNNs poses challenges for model deployment. Network pruning
reduces hardware resource requirements of model deployment by compressing the
network scale. However, existing SNN pruning methods cause high pruning costs
and performance loss because the pruning iterations amplify the training
difficulty of SNNs. In this paper, inspired by the critical brain hypothesis in
neuroscience, we propose a regeneration mechanism based on the neuron
criticality for SNN pruning to enhance feature extraction and accelerate the
pruning process. Firstly, we propose a low-cost metric for the criticality in
SNNs. Then, we re-rank the pruned structures after pruning and regenerate those
with higher criticality to obtain the critical network. Our method achieves
higher performance than the current state-of-the-art (SOTA) method with up to
95.26% reduction of pruning cost. Moreover, we investigate the underlying
mechanism of our method and find that it efficiently selects potential
structures and learns the consistent feature representation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.02317">GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge Graphs. (arXiv:2312.02317v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruijie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossetto_L/0/1/0/all/0/1">Luca Rossetto</a>, <a href="http://arxiv.org/find/cs/1/au:+Cochez_M/0/1/0/all/0/1">Michael Cochez</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernstein_A/0/1/0/all/0/1">Abraham Bernstein</a></p>
<p>Most current methods for multi-hop question answering (QA) over knowledge
graphs (KGs) only provide final conclusive answers without explanations, such
as a set of KG entities that is difficult for normal users to review and
comprehend. This issue severely limits the application of KG-based QA in
real-world scenarios. However, it is non-trivial to solve due to two
challenges: First, annotations of reasoning chains of multi-hop questions,
which could serve as supervision for explanation generation, are usually
lacking. Second, it is difficult to maintain high efficiency when explicit KG
triples need to be retrieved to generate explanations. In this paper, we
propose a novel Graph Neural Network-based Two-Step Reasoning model (GNN2R) to
solve this issue. GNN2R can provide both final answers and reasoning subgraphs
as a rationale behind final answers efficiently with only weak supervision that
is available through question-final answer pairs. We extensively evaluated
GNN2R with detailed analyses in experiments. The results demonstrate that, in
terms of effectiveness, efficiency, and quality of generated explanations,
GNN2R outperforms existing state-of-the-art methods that are applicable to this
task. Our code and pre-trained models are available at
https://github.com/ruijie-wang-uzh/GNN2R.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.06261">Survey on Foundation Models for Prognostics and Health Management in Industrial Cyber-Physical Systems. (arXiv:2312.06261v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruonan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Quanhu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1">Te Han</a></p>
<p>Industrial Cyber-Physical Systems (ICPS) integrate the disciplines of
computer science, communication technology, and engineering, and have emerged
as integral components of contemporary manufacturing and industries. However,
ICPS encounters various challenges in long-term operation, including equipment
failures, performance degradation, and security threats. To achieve efficient
maintenance and management, prognostics and health management (PHM) finds
widespread application in ICPS for critical tasks, including failure
prediction, health monitoring, and maintenance decision-making. The emergence
of large-scale foundation models (LFMs) like BERT and GPT signifies a
significant advancement in AI technology, and ChatGPT stands as a remarkable
accomplishment within this research paradigm, harboring potential for General
Artificial Intelligence. Considering the ongoing enhancement in data
acquisition technology and data processing capability, LFMs are anticipated to
assume a crucial role in the PHM domain of ICPS. However, at present, a
consensus is lacking regarding the application of LFMs to PHM in ICPS,
necessitating systematic reviews and roadmaps to elucidate future directions.
To bridge this gap, this paper elucidates the key components and recent
advances in the underlying model.A comprehensive examination and comprehension
of the latest advances in grand modeling for PHM in ICPS can offer valuable
references for decision makers and researchers in the industrial field while
facilitating further enhancements in the reliability, availability, and safety
of ICPS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07178">Beyond Expected Return: Accounting for Policy Reproducibility when Evaluating Reinforcement Learning Algorithms. (arXiv:2312.07178v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Flageat_M/0/1/0/all/0/1">Manon Flageat</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_B/0/1/0/all/0/1">Bryan Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1">Antoine Cully</a></p>
<p>Many applications in Reinforcement Learning (RL) usually have noise or
stochasticity present in the environment. Beyond their impact on learning,
these uncertainties lead the exact same policy to perform differently, i.e.
yield different return, from one roll-out to another. Common evaluation
procedures in RL summarise the consequent return distributions using solely the
expected return, which does not account for the spread of the distribution. Our
work defines this spread as the policy reproducibility: the ability of a policy
to obtain similar performance when rolled out many times, a crucial property in
some real-world applications. We highlight that existing procedures that only
use the expected return are limited on two fronts: first an infinite number of
return distributions with a wide range of performance-reproducibility
trade-offs can have the same expected return, limiting its effectiveness when
used for comparing policies; second, the expected return metric does not leave
any room for practitioners to choose the best trade-off value for considered
applications. In this work, we address these limitations by recommending the
use of Lower Confidence Bound, a metric taken from Bayesian optimisation that
provides the user with a preference parameter to choose a desired
performance-reproducibility trade-off. We also formalise and quantify policy
reproducibility, and demonstrate the benefit of our metrics using extensive
experiments of popular RL algorithms on common uncertain RL tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.07343">Can ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?. (arXiv:2312.07343v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Anishka/0/1/0/all/0/1">Anishka</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_A/0/1/0/all/0/1">Atharva Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Nipun Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Balachandran_A/0/1/0/all/0/1">Aarav Balachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_D/0/1/0/all/0/1">Dhruv Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Jalote_P/0/1/0/all/0/1">Pankaj Jalote</a></p>
<p>The emergence of Large language models (LLMs) is expected to have a major
impact on education. This paper explores the potential of using ChatGPT, an
LLM, as a virtual Teaching Assistant (TA) in an Introductory Programming
Course. We evaluate ChatGPT's capabilities by comparing its performance with
that of human TAs in some of the important TA functions. The TA functions which
we focus on include (1) grading student code submissions, and (2) providing
feedback to undergraduate students in an introductory programming course.
Firstly, we assess ChatGPT's proficiency in grading student code submissions
using a given grading rubric and compare its performance with the grades
assigned by human TAs. Secondly, we analyze the quality and relevance of the
feedback provided by ChatGPT. This evaluation considers how well ChatGPT
addresses mistakes and offers suggestions for improvement in student solutions
from both code correctness and code quality perspectives. We conclude with a
discussion on the implications of integrating ChatGPT into computing education
for automated grading, personalized learning experiences, and instructional
support.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10269">The DSA Transparency Database: Auditing Self-reported Moderation Actions by Social Media. (arXiv:2312.10269v2 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Trujillo_A/0/1/0/all/0/1">Amaury Trujillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fagni_T/0/1/0/all/0/1">Tiziano Fagni</a>, <a href="http://arxiv.org/find/cs/1/au:+Cresci_S/0/1/0/all/0/1">Stefano Cresci</a></p>
<p>Since September 2023, the Digital Services Act (DSA) obliges large online
platforms to submit detailed data on each moderation action they take within
the European Union (EU) to the DSA Transparency Database. From its inception,
this centralized database has sparked scholarly interest as an unprecedented
and potentially unique trove of data on real-world online moderation. Here, we
thoroughly analyze all 353.12M records submitted by the eight largest social
media platforms in the EU during the first 100 days of the database.
Specifically, we conduct a platform-wise comparative study of their: volume of
moderation actions, grounds for decision, types of applied restrictions, types
of moderated content, timeliness in undertaking and submitting moderation
actions, and use of automation. Furthermore, we systematically cross-check the
contents of the database with the platforms' own transparency reports. Our
analyses reveal that (i) the platforms adhered only in part to the philosophy
and structure of the database, (ii) the structure of the database is partially
inadequate for the platforms' reporting needs, (iii) the platforms exhibited
substantial differences in their moderation actions, (iv) a remarkable fraction
of the database data is inconsistent, (v) the platform X (formerly Twitter)
presents the most inconsistencies. Our findings have far-reaching implications
for policymakers and scholars across diverse disciplines. They offer guidance
for future regulations that cater to the reporting needs of online platforms in
general, but also highlight opportunities to improve and refine the database
itself.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.10305">Self-Supervised Disentangled Representation Learning for Robust Target Speech Extraction. (arXiv:2312.10305v2 [cs.SD] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mu_Z/0/1/0/all/0/1">Zhaoxi Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xinyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Sining Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qing Yang</a></p>
<p>Speech signals are inherently complex as they encompass both global acoustic
characteristics and local semantic information. However, in the task of target
speech extraction, certain elements of global and local semantic information in
the reference speech, which are irrelevant to speaker identity, can lead to
speaker confusion within the speech extraction network. To overcome this
challenge, we propose a self-supervised disentangled representation learning
method. Our approach tackles this issue through a two-phase process, utilizing
a reference speech encoding network and a global information disentanglement
network to gradually disentangle the speaker identity information from other
irrelevant factors. We exclusively employ the disentangled speaker identity
information to guide the speech extraction network. Moreover, we introduce the
adaptive modulation Transformer to ensure that the acoustic representation of
the mixed signal remains undisturbed by the speaker embeddings. This component
incorporates speaker embeddings as conditional information, facilitating
natural and efficient guidance for the speech extraction network. Experimental
results substantiate the effectiveness of our meticulously crafted approach,
showcasing a substantial reduction in the likelihood of speaker confusion.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11413">DeRDaVa: Deletion-Robust Data Valuation for Machine Learning. (arXiv:2312.11413v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1">Xiao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1">Rachael Hwee Ling Sim</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Jue Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Low_B/0/1/0/all/0/1">Bryan Kian Hsiang Low</a></p>
<p>Data valuation is concerned with determining a fair valuation of data from
data sources to compensate them or to identify training examples that are the
most or least useful for predictions. With the rising interest in personal data
ownership and data protection regulations, model owners will likely have to
fulfil more data deletion requests. This raises issues that have not been
addressed by existing works: Are the data valuation scores still fair with
deletions? Must the scores be expensively recomputed? The answer is no. To
avoid recomputations, we propose using our data valuation framework DeRDaVa
upfront for valuing each data source's contribution to preserving robust model
performance after anticipated data deletions. DeRDaVa can be efficiently
approximated and will assign higher values to data that are more useful or less
likely to be deleted. We further generalize DeRDaVa to Risk-DeRDaVa to cater to
risk-averse/seeking model owners who are concerned with the worst/best-cases
model utility. We also empirically demonstrate the practicality of our
solutions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11532">Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation. (arXiv:2312.11532v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1">YoungJoon Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jongwon Choi</a></p>
<p>This paper introduces a novel approach for topic modeling utilizing latent
codebooks from Vector-Quantized Variational Auto-Encoder~(VQ-VAE), discretely
encapsulating the rich information of the pre-trained embeddings such as the
pre-trained language model. From the novel interpretation of the latent
codebooks and embeddings as conceptual bag-of-words, we propose a new
generative topic model called Topic-VQ-VAE~(TVQ-VAE) which inversely generates
the original documents related to the respective latent codebook. The TVQ-VAE
can visualize the topics with various generative distributions including the
traditional BoW distribution and the autoregressive image generation. Our
experimental results on document analysis and image generation demonstrate that
TVQ-VAE effectively captures the topic context which reveals the underlying
structures of the dataset and supports flexible forms of document generation.
Official implementation of the proposed TVQ-VAE is available at
https://github.com/clovaai/TVQ-VAE.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.11976">When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection. (arXiv:2312.11976v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongmin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a></p>
<p>Time-series anomaly detection deals with the problem of detecting anomalous
timesteps by learning normality from the sequence of observations. However, the
concept of normality evolves over time, leading to a "new normal problem",
where the distribution of normality can be changed due to the distribution
shifts between training and test data. This paper highlights the prevalence of
the new normal problem in unsupervised time-series anomaly detection studies.
To tackle this issue, we propose a simple yet effective test-time adaptation
strategy based on trend estimation and a self-supervised approach to learning
new normalities during inference. Extensive experiments on real-world
benchmarks demonstrate that incorporating the proposed strategy into the
anomaly detector consistently improves the model's performance compared to the
baselines, leading to robustness to the distribution shifts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.16113">Task-Driven Causal Feature Distillation: Towards Trustworthy Risk Prediction. (arXiv:2312.16113v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1">Zhixuan Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Mengxuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Q/0/1/0/all/0/1">Qing Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Longfei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sheng Li</a></p>
<p>Since artificial intelligence has seen tremendous recent successes in many
areas, it has sparked great interest in its potential for trustworthy and
interpretable risk prediction. However, most models lack causal reasoning and
struggle with class imbalance, leading to poor precision and recall. To address
this, we propose a Task-Driven Causal Feature Distillation model (TDCFD) to
transform original feature values into causal feature attributions for the
specific risk prediction task. The causal feature attribution helps describe
how much contribution the value of this feature can make to the risk prediction
result. After the causal feature distillation, a deep neural network is applied
to produce trustworthy prediction results with causal interpretability and high
precision/recall. We evaluate the performance of our TDCFD method on several
synthetic and real datasets, and the results demonstrate its superiority over
the state-of-the-art methods regarding precision, recall, interpretability, and
causality.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.01841">Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes. (arXiv:2401.01841v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1">Baiting Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yunuo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1">Abhishek Dubey</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_A/0/1/0/all/0/1">Ayan Mukhopadhyay</a></p>
<p>A fundamental (and largely open) challenge in sequential decision-making is
dealing with non-stationary environments, where exogenous environmental
conditions change over time. Such problems are traditionally modeled as
non-stationary Markov decision processes (NSMDP). However, existing approaches
for decision-making in NSMDPs have two major shortcomings: first, they assume
that the updated environmental dynamics at the current time are known (although
future dynamics can change); and second, planning is largely pessimistic, i.e.,
the agent acts ``safely'' to account for the non-stationary evolution of the
environment. We argue that both these assumptions are invalid in practice --
updated environmental conditions are rarely known, and as the agent interacts
with the environment, it can learn about the updated dynamics and avoid being
pessimistic, at least in states whose dynamics it is confident about. We
present a heuristic search algorithm called \textit{Adaptive Monte Carlo Tree
Search (ADA-MCTS)} that addresses these challenges. We show that the agent can
learn the updated dynamics of the environment over time and then act as it
learns, i.e., if the agent is in a region of the state space about which it has
updated knowledge, it can avoid being pessimistic. To quantify ``updated
knowledge,'' we disintegrate the aleatoric and epistemic uncertainty in the
agent's updated belief and show how the agent can use these estimates for
decision-making. We compare the proposed approach with the multiple
state-of-the-art approaches in decision-making across multiple well-established
open-source problems and empirically show that our approach is faster and
highly adaptive without sacrificing safety.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.02500">On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS). (arXiv:2401.02500v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pallagani_V/0/1/0/all/0/1">Vishal Pallagani</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1">Kaushik Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Muppasani_B/0/1/0/all/0/1">Bharath Muppasani</a>, <a href="http://arxiv.org/find/cs/1/au:+Fabiano_F/0/1/0/all/0/1">Francesco Fabiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Loreggia_A/0/1/0/all/0/1">Andrea Loreggia</a>, <a href="http://arxiv.org/find/cs/1/au:+Murugesan_K/0/1/0/all/0/1">Keerthiram Murugesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_B/0/1/0/all/0/1">Biplav Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossi_F/0/1/0/all/0/1">Francesca Rossi</a>, <a href="http://arxiv.org/find/cs/1/au:+Horesh_L/0/1/0/all/0/1">Lior Horesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1">Amit Sheth</a></p>
<p>Automated Planning and Scheduling is among the growing areas in Artificial
Intelligence (AI) where mention of LLMs has gained popularity. Based on a
comprehensive review of 126 papers, this paper investigates eight categories
based on the unique applications of LLMs in addressing various aspects of
planning problems: language translation, plan generation, model construction,
multi-agent planning, interactive planning, heuristics optimization, tool
integration, and brain-inspired planning. For each category, we articulate the
issues considered and existing gaps. A critical insight resulting from our
review is that the true potential of LLMs unfolds when they are integrated with
traditional symbolic planners, pointing towards a promising neuro-symbolic
approach. This approach effectively combines the generative aspects of LLMs
with the precision of classical planning methods. By synthesizing insights from
existing literature, we underline the potential of this integration to address
complex planning challenges. Our goal is to encourage the ICAPS community to
recognize the complementary strengths of LLMs and symbolic planners, advocating
for a direction in automated planning that leverages these synergistic
capabilities to develop more advanced and intelligent planning systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03197">Decision Making in Non-Stationary Environments with Policy-Augmented Search. (arXiv:2401.03197v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pettet_A/0/1/0/all/0/1">Ava Pettet</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yunuo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1">Baiting Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wray_K/0/1/0/all/0/1">Kyle Wray</a>, <a href="http://arxiv.org/find/cs/1/au:+Baier_H/0/1/0/all/0/1">Hendrik Baier</a>, <a href="http://arxiv.org/find/cs/1/au:+Laszka_A/0/1/0/all/0/1">Aron Laszka</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1">Abhishek Dubey</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_A/0/1/0/all/0/1">Ayan Mukhopadhyay</a></p>
<p>Sequential decision-making under uncertainty is present in many important
problems. Two popular approaches for tackling such problems are reinforcement
learning and online search (e.g., Monte Carlo tree search). While the former
learns a policy by interacting with the environment (typically done before
execution), the latter uses a generative model of the environment to sample
promising action trajectories at decision time. Decision-making is particularly
challenging in non-stationary environments, where the environment in which an
agent operates can change over time. Both approaches have shortcomings in such
settings -- on the one hand, policies learned before execution become stale
when the environment changes and relearning takes both time and computational
effort. Online search, on the other hand, can return sub-optimal actions when
there are limitations on allowed runtime. In this paper, we introduce
\textit{Policy-Augmented Monte Carlo tree search} (PA-MCTS), which combines
action-value estimates from an out-of-date policy with an online search using
an up-to-date model of the environment. We prove theoretical results showing
conditions under which PA-MCTS selects the one-step optimal action and also
bound the error accrued while following PA-MCTS as a policy. We compare and
contrast our approach with AlphaZero, another hybrid planning approach, and
Deep Q Learning on several OpenAI Gym environments. Through extensive
experiments, we show that under non-stationary settings with limited time
constraints, PA-MCTS outperforms these baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04620">Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shimin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tianxiang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a></p>
<p>Agents based on Large Language Models (LLMs) are increasingly permeating
various domains of human production and life, highlighting the importance of
aligning them with human values. The current alignment of AI systems primarily
focuses on passively aligning LLMs through human intervention. However, agents
possess characteristics like receiving environmental feedback and
self-evolution, rendering the LLM alignment methods inadequate. In response, we
propose an evolutionary framework for agent evolution and alignment, named
EvolutionaryAgent, which transforms agent alignment into a process of evolution
and selection under the principle of survival of the fittest. In an environment
where social norms continuously evolve, agents better adapted to the current
social norms will have a higher probability of survival and proliferation,
while those inadequately aligned dwindle over time. Experimental results
assessing the agents from multiple perspectives in aligning with social norms
demonstrate that EvolutionaryAgent can align progressively better with the
evolving social norms while maintaining its proficiency in general tasks.
Effectiveness tests conducted on various open and closed-source LLMs as the
foundation for agents also prove the applicability of our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04846">The inherent goodness of well educated intelligence. (arXiv:2401.04846v3 [econ.TH] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/econ/1/au:+Glinsky_M/0/1/0/all/0/1">Michael E. Glinsky</a>, <a href="http://arxiv.org/find/econ/1/au:+Sievert_S/0/1/0/all/0/1">Sharon Sievert</a></p>
<p>This paper will examine what makes a being intelligent, whether that be a
biological being or an artificial silicon being on a computer. Special
attention will be paid to the being having the ability to characterize and
control a collective system of many identical conservative sub-systems
conservatively interacting. The essence of intelligence will be found to be the
golden rule -- "the collective acts as one" or "knowing the global consequences
of local actions". The flow of the collective is a small set of twinkling
textures, that are governed by a puppeteer who is pulling a small number of
strings according to a geodesic motion of least action, determined by the
symmetries. Controlling collective conservative systems is difficult and has
historically been done by adding significant viscosity to the system to
stabilize the desirable meta stable equilibriums of maximum performance, but it
degrades or destroys them in the process. There is an alternative. Once the
optimum twinkling textures of the meta stable equilibriums are identified by
the intelligent being (that is the collective system is characterized), the
collective system can be moved by the intelligent being to the optimum
twinkling textures, then quickly vibrated by the intelligent being according to
the textures so that the collective system remains at the meta stable
equilibrium. Well educated intelligence knows the global consequences of its
local actions so that it will not take short term actions that will lead to
poor long term outcomes. In contrast, trained intelligence or trained stupidity
will optimize its short term actions, leading to poor long term outcomes. Well
educated intelligence is inherently good, but trained stupidity is inherently
evil and should be feared. Particular attention is paid to the control and
optimization of economic and social collectives.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04925">The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1">Mingyu Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qinkai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_D/0/1/0/all/0/1">Dong Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haiyan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1">Wenyue Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1">Yanda Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1">Mengnan Du</a></p>
<p>Chain of Thought (CoT) is significant in improving the reasoning abilities of
large language models (LLMs). However, the correlation between the
effectiveness of CoT and the length of reasoning steps in prompts remains
largely unknown. To shed light on this, we have conducted several empirical
experiments to explore the relations. Specifically, we design experiments that
expand and compress the rationale reasoning steps within CoT demonstrations,
while keeping all other factors constant. We have the following key findings.
First, the results indicate that lengthening the reasoning steps in prompts,
even without adding new information into the prompt, considerably enhances
LLMs' reasoning abilities across multiple datasets. Alternatively, shortening
the reasoning steps, even while preserving the key information, significantly
diminishes the reasoning abilities of models. This finding highlights the
importance of the number of steps in CoT prompts and provides practical
guidance to make better use of LLMs' potential in complex problem-solving
scenarios. Second, we also investigated the relationship between the
performance of CoT and the rationales used in demonstrations. Surprisingly, the
result shows that even incorrect rationales can yield favorable outcomes if
they maintain the requisite length of inference. Third, we observed that the
advantages of increasing reasoning steps are task-dependent: simpler tasks
require fewer steps, whereas complex tasks gain significantly from longer
inference sequences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.05949">Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks. (arXiv:2401.05949v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shuai Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1">Meihuizi Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1">Luu Anh Tuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Jinming Wen</a></p>
<p>In-context learning, a paradigm bridging the gap between pre-training and
fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in
few-shot settings. Unlike traditional fine-tuning methods, in-context learning
adapts pre-trained models to unseen tasks without updating any parameters.
Despite being widely applied, in-context learning is vulnerable to malicious
attacks. In this work, we raise security concerns regarding this paradigm. Our
studies demonstrate that an attacker can manipulate the behavior of large
language models by poisoning the demonstration context, without the need for
fine-tuning the model. Specifically, we have designed a new backdoor attack
method, named ICLAttack, to target large language models based on in-context
learning. Our method encompasses two types of attacks: poisoning demonstration
examples and poisoning prompts, which can make models behave in accordance with
predefined intentions. ICLAttack does not require additional fine-tuning to
implant a backdoor, thus preserving the model's generality. Furthermore, the
poisoned examples are correctly labeled, enhancing the natural stealth of our
attack method. Extensive experimental results across several language models,
ranging in size from 1.3B to 40B parameters, demonstrate the effectiveness of
our attack method, exemplified by a high average attack success rate of 95.0%
across the three datasets on OPT models. Our findings highlight the
vulnerabilities of language models, and we hope this work will raise awareness
of the possible security threats associated with in-context learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.06256">A Universal Knowledge Model and Cognitive Architecture for Prototyping AGI. (arXiv:2401.06256v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sukhobokov_A/0/1/0/all/0/1">Artem Sukhobokov</a>, <a href="http://arxiv.org/find/cs/1/au:+Belousov_E/0/1/0/all/0/1">Evgeny Belousov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gromozdov_D/0/1/0/all/0/1">Danila Gromozdov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zenger_A/0/1/0/all/0/1">Anna Zenger</a>, <a href="http://arxiv.org/find/cs/1/au:+Popov_I/0/1/0/all/0/1">Ilya Popov</a></p>
<p>The article identified 42 cognitive architectures for creating general
artificial intelligence (AGI) and proposed a set of interrelated functional
blocks that an agent approaching AGI in its capabilities should possess. Since
the required set of blocks is not found in any of the existing architectures,
the article proposes a new cognitive architecture for intelligent systems
approaching AGI in their capabilities. As one of the key solutions within the
framework of the architecture, a universal method of knowledge representation
is proposed, which allows combining various non-formalized, partially and fully
formalized methods of knowledge representation in a single knowledge base, such
as texts in natural languages, images, audio and video recordings, graphs,
algorithms, databases, neural networks, knowledge graphs, ontologies, frames,
essence-property-relation models, production systems, predicate calculus
models, conceptual models, and others. To combine and structure various
fragments of knowledge, archigraph models are used, constructed as a
development of annotated metagraphs. As components, the cognitive architecture
being developed includes machine consciousness, machine subconsciousness,
blocks of interaction with the external environment, a goal management block,
an emotional control system, a block of social interaction, a block of
reflection, an ethics block and a worldview block, a learning block, a
monitoring block, blocks of statement and solving problems, self-organization
and meta learning block.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07278">Semi-supervised Semantic Segmentation using Redesigned Self-Training for White Blood Cell. (arXiv:2401.07278v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luu_V/0/1/0/all/0/1">Vinh Quoc Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1">Duy Khanh Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy Thanh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Minh Thanh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thinh Tien Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dinh_V/0/1/0/all/0/1">Vinh Quang Dinh</a></p>
<p>Artificial Intelligence (AI) in healthcare, especially in white blood cell
cancer diagnosis, is hindered by two primary challenges: the lack of
large-scale labeled datasets for white blood cell (WBC) segmentation and
outdated segmentation methods. To address the first challenge, a
semi-supervised learning framework should be brought to efficiently annotate
the large dataset. In this work, we address this issue by proposing a novel
self-training pipeline with the incorporation of FixMatch. We discover that by
incorporating FixMatch in the self-training pipeline, the performance improves
in the majority of cases. Our performance achieved the best performance with
the self-training scheme with consistency on DeepLab-V3 architecture and
ResNet-50, reaching 90.69%, 87.37%, and 76.49% on Zheng 1, Zheng 2, and LISC
datasets, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07364">PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar Nonlinear Conservation Laws. (arXiv:2401.07364v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Liu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1">Stanley J. Osher</a></p>
<p>Can we build a single large model for a wide range of PDE-related scientific
learning tasks? Can this model generalize to new PDEs, even of new forms,
without any fine-tuning? In-context operator learning and the corresponding
model In-Context Operator Networks (ICON) represent an initial exploration of
these questions. The capability of ICON regarding the first question has been
demonstrated previously. In this paper, we present a detailed methodology for
solving PDE problems with ICON, and show how a single ICON model can make
forward and reverse predictions for different equations with different strides,
provided with appropriately designed data prompts. We show the positive
evidence to the second question, i.e., ICON can generalize well to some PDEs
with new forms without any fine-tuning. This is exemplified through a study on
1D scalar nonlinear conservation laws, a family of PDEs with temporal
evolution. We also show how to broaden the range of problems that an ICON model
can address, by transforming functions and equations to ICON's capability
scope. We believe that the progress in this paper is a significant step towards
the goal of training a foundation model for PDE-related tasks under the
in-context operator learning framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07378">Efficient approximation of Earth Mover&#x27;s Distance Based on Nearest Neighbor Search. (arXiv:2401.07378v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meng_G/0/1/0/all/0/1">Guangyu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1">Ruyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Peixian Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Danny Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Niemier_M/0/1/0/all/0/1">Michael Niemier</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">X.Sharon Hu</a></p>
<p>Earth Mover's Distance (EMD) is an important similarity measure between two
distributions, used in computer vision and many other application domains.
However, its exact calculation is computationally and memory intensive, which
hinders its scalability and applicability for large-scale problems. Various
approximate EMD algorithms have been proposed to reduce computational costs,
but they suffer lower accuracy and may require additional memory usage or
manual parameter tuning. In this paper, we present a novel approach, NNS-EMD,
to approximate EMD using Nearest Neighbor Search (NNS), in order to achieve
high accuracy, low time complexity, and high memory efficiency. The NNS
operation reduces the number of data points compared in each NNS iteration and
offers opportunities for parallel processing. We further accelerate NNS-EMD via
vectorization on GPU, which is especially beneficial for large datasets. We
compare NNS-EMD with both the exact EMD and state-of-the-art approximate EMD
algorithms on image classification and retrieval tasks. We also apply NNS-EMD
to calculate transport mapping and realize color transfer between images.
NNS-EMD can be 44x to 135x faster than the exact EMD implementation, and
achieves superior accuracy, speedup, and memory efficiency over existing
approximate EMD methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07450">Hierarchical Fashion Design with Multi-stage Diffusion Models. (arXiv:2401.07450v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhifeng Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Huiming Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mengtian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Ying Cao</a></p>
<p>Cross-modal fashion synthesis and editing offer intelligent support to
fashion designers by enabling the automatic generation and local modification
of design drafts.While current diffusion models demonstrate commendable
stability and controllability in image synthesis,they still face significant
challenges in generating fashion design from abstract design elements and
fine-grained editing.Abstract sensory expressions, \eg office, business, and
party, form the high-level design concepts, while measurable aspects like
sleeve length, collar type, and pant length are considered the low-level
attributes of clothing.Controlling and editing fashion images using lengthy
text descriptions poses a difficulty.In this paper, we propose HieraFashDiff,a
novel fashion design method using the shared multi-stage diffusion model
encompassing high-level design concepts and low-level clothing attributes in a
hierarchical structure.Specifically, we categorized the input text into
different levels and fed them in different time step to the diffusion model
according to the criteria of professional clothing designers.HieraFashDiff
allows designers to add low-level attributes after high-level prompts for
interactive editing incrementally.In addition, we design a differentiable loss
function in the sampling process with a mask to keep non-edit
areas.Comprehensive experiments performed on our newly conducted Hierarchical
fashion dataset,demonstrate that our proposed method outperforms other
state-of-the-art competitors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07510">Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering. (arXiv:2401.07510v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a></p>
<p>ChatGPT explores a strategic blueprint of question answering (QA) in
delivering medical diagnosis, treatment recommendations, and other healthcare
support. This is achieved through the increasing incorporation of medical
domain data via natural language processing (NLP) and multimodal paradigms. By
transitioning the distribution of text, images, videos, and other modalities
from the general domain to the medical domain, these techniques have expedited
the progress of medical domain question answering (MDQA). They bridge the gap
between human natural language and sophisticated medical domain knowledge or
expert manual annotations, handling large-scale, diverse, unbalanced, or even
unlabeled data analysis scenarios in medical contexts. Central to our focus is
the utilizing of language models and multimodal paradigms for medical question
answering, aiming to guide the research community in selecting appropriate
mechanisms for their specific medical research requirements. Specialized tasks
such as unimodal-related question answering, reading comprehension, reasoning,
diagnosis, relation extraction, probability modeling, and others, as well as
multimodal-related tasks like vision question answering, image caption,
cross-modal retrieval, report summarization, and generation, are discussed in
detail. Each section delves into the intricate specifics of the respective
method under consideration. This paper highlights the structures and
advancements of medical domain explorations against general domain methods,
emphasizing their applications across different tasks and datasets. It also
outlines current challenges and opportunities for future medical domain
research, paving the way for continued innovation and application in this
rapidly evolving field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07656">Learning Explainable and Better Performing Representations of POMDP Strategies. (arXiv:2401.07656v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bork_A/0/1/0/all/0/1">Alexander Bork</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1">Debraj Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Grover_K/0/1/0/all/0/1">Kush Grover</a>, <a href="http://arxiv.org/find/cs/1/au:+Kretinsky_J/0/1/0/all/0/1">Jan Kretinsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohr_S/0/1/0/all/0/1">Stefanie Mohr</a></p>
<p>Strategies for partially observable Markov decision processes (POMDP)
typically require memory. One way to represent this memory is via automata. We
present a method to learn an automaton representation of a strategy using a
modification of the L*-algorithm. Compared to the tabular representation of a
strategy, the resulting automaton is dramatically smaller and thus also more
explainable. Moreover, in the learning process, our heuristics may even improve
the strategy's performance. In contrast to approaches that synthesize an
automaton directly from the POMDP thereby solving it, our approach is
incomparably more scalable.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.07890">A Strategy for Implementing description Temporal Dynamic Algorithms in Dynamic Knowledge Graphs by SPIN. (arXiv:2401.07890v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shahbazi_A/0/1/0/all/0/1">Alireza Shahbazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirsanei_S/0/1/0/all/0/1">Seyyed Ahmad Mirsanei</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarraf_M/0/1/0/all/0/1">Malikeh Haj Khan Mirzaye Sarraf</a>, <a href="http://arxiv.org/find/cs/1/au:+Bidgoli_B/0/1/0/all/0/1">Behrouz Minaei Bidgoli</a></p>
<p>Planning and reasoning about actions and processes, in addition to reasoning
about propositions, are important issues in recent logical and computer science
studies. The widespread use of actions in everyday life such as IoT, semantic
web services, etc., and the limitations and issues in the action formalisms are
two factors that lead us to study how actions are represented.
</p>
<p>Since 2007, there have been some ideas to integrate Description Logic (DL)
and action formalisms for representing both static and dynamic knowledge.
Meanwhile, time is an important factor in dynamic situations, and actions
change states over time. In this study, on the one hand, we examined related
logical structures such as extensions of description logics (DLs), temporal
formalisms, and action formalisms. On the other hand, we analyzed possible
tools for designing and developing the Knowledge and Action Base (KAB).
</p>
<p>For representation and reasoning about actions, we embedded actions into DLs
(such as Dynamic-ALC and its extensions). We propose a terminable algorithm for
action projection, planning, checking the satisfiability, consistency,
realizability, and executability, and also querying from KAB. Actions in this
framework were modeled with SPIN and added to state space. This framework has
also been implemented as a plugin for the Prot\'eg\'e ontology editor.
</p>
<p>During the last two decades, various algorithms have been presented, but due
to the high computational complexity, we face many problems in implementing
dynamic ontologies. In addition, an algorithm to detect the inconsistency of
actions' effects was not explicitly stated. In the proposed strategy, the
interactions of actions with other parts of modeled knowledge, and a method to
check consistency between the effects of actions are presented. With this
framework, the ramification problem can be well handled in future works.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09003">Augmenting Math Word Problems via Iterative Question Composing. (arXiv:2401.09003v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haoxiong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1">Andrew Chi-Chih Yao</a></p>
<p>Despite recent progress in improving the mathematical reasoning ability of
large language models(LLMs), solving competition-level math problems without
the use of external tools remains challenging for open-source LLMs. In this
work, we introduce the MMIQC dataset, a mixture of processed web data and
synthetic question-response pairs, to equip base models with better
mathematical reasoning skills. In different model sizes, the models fine-tuned
on MMIQC consistently outperform their counterparts by a clear margin on MATH
test set. Notably, DeepSeek-67B-MMIQC achieves a 41.0% accuracy, 4.2% higher
than the previous open-source SOTA. Our experiments also show that a large part
of the improvement can be attributed to our novel augmentation method
IQC(Iterative Question Composing), where we iteratively ask an LLM to compose
new questions from the given seed problems and do rejection sampling from
another LLM. MMIQC has now been released on
https://huggingface.co/datasets/Vivacem/MMIQC.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09074">Code Simulation Challenges for Large Language Models. (arXiv:2401.09074v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Malfa_E/0/1/0/all/0/1">Emanuele La Malfa</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinhuber_C/0/1/0/all/0/1">Christoph Weinhuber</a>, <a href="http://arxiv.org/find/cs/1/au:+Torre_O/0/1/0/all/0/1">Orazio Torre</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Fangru Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohn_A/0/1/0/all/0/1">Anthony Cohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Shadbolt_N/0/1/0/all/0/1">Nigel Shadbolt</a>, <a href="http://arxiv.org/find/cs/1/au:+Wooldridge_M/0/1/0/all/0/1">Michael Wooldridge</a></p>
<p>We investigate the extent to which Large Language Models (LLMs) can simulate
the execution of computer code and algorithms. We begin by looking at straight
line programs, and show that current LLMs demonstrate poor performance even
with such simple programs -- performance rapidly degrades with the length of
code. We then investigate the ability of LLMs to simulate programs that contain
critical paths and redundant instructions. We also go beyond straight line
program simulation with sorting algorithms and nested loops, and we show the
computational complexity of a routine directly affects the ability of an LLM to
simulate its execution. We observe that LLMs execute instructions sequentially
and with a low error margin only for short programs or standard procedures.
LLMs' code simulation is in tension with their pattern recognition and
memorisation capabilities: on tasks where memorisation is detrimental, we
propose a novel prompting method to simulate code execution line by line.
Empirically, our new Chain of Simulation (CoSm) method improves on the standard
Chain of Thought prompting approach by avoiding the pitfalls of memorisation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09451">Diffusion-Driven Generative Framework for Molecular Conformation Prediction. (arXiv:2401.09451v2 [q-bio.BM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Yang_B/0/1/0/all/0/1">Bobin Yang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Deng_J/0/1/0/all/0/1">Jie Deng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_Z/0/1/0/all/0/1">Zhenghan Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wu_R/0/1/0/all/0/1">Ruoxue Wu</a></p>
<p>The task of deducing three-dimensional molecular configurations from their
two-dimensional graph representations holds paramount importance in the fields
of computational chemistry and pharmaceutical development. The rapid
advancement of machine learning, particularly within the domain of deep
generative networks, has revolutionized the precision of predictive modeling in
this context. Traditional approaches often adopt a two-step strategy: initially
estimating interatomic distances and subsequently refining the spatial
molecular structure by solving a distance geometry problem. However, this
sequential approach occasionally falls short in accurately capturing the
intricacies of local atomic arrangements, thereby compromising the fidelity of
the resulting structural models. Addressing these limitations, this research
introduces a cutting-edge generative framework named \method{}. This framework
is grounded in the principles of diffusion observed in classical
non-equilibrium thermodynamics. \method{} views atoms as discrete entities and
excels in guiding the reversal of diffusion, transforming a distribution of
stochastic noise back into coherent molecular structures through a process akin
to a Markov chain. This transformation commences with the initial
representation of a molecular graph in an abstract latent space, culminating in
the realization of three-dimensional structures via a sophisticated bilevel
optimization scheme meticulously tailored to meet the specific requirements of
the task. One of the formidable challenges in this modeling endeavor involves
preserving roto-translational invariance to ensure that the generated molecular
conformations adhere to the laws of physics. Extensive experimental evaluations
confirm the efficacy of the proposed \method{} in comparison to
state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09671">Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach. (arXiv:2401.09671v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shrestha_S/0/1/0/all/0/1">Sagar Shrestha</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xiao Fu</a></p>
<p>Unsupervised domain translation (UDT) aims to find functions that convert
samples from one domain (e.g., sketches) to another domain (e.g., photos)
without changing the high-level semantic meaning (also referred to as
``content''). The translation functions are often sought by probability
distribution matching of the transformed source domain and target domain.
CycleGAN stands as arguably the most representative approach among this line of
work. However, it was noticed in the literature that CycleGAN and variants
could fail to identify the desired translation functions and produce
content-misaligned translations. This limitation arises due to the presence of
multiple translation functions -- referred to as ``measure-preserving
automorphism" (MPA) -- in the solution space of the learning criteria. Despite
awareness of such identifiability issues, solutions have remained elusive. This
study delves into the core identifiability inquiry and introduces an MPA
elimination theory. Our analysis shows that MPA is unlikely to exist, if
multiple pairs of diverse cross-domain conditional distributions are matched by
the learning function. Our theory leads to a UDT learner using distribution
matching over auxiliary variable-induced subsets of the domains -- other than
over the entire data domains as in the classical approaches. The proposed
framework is the first to rigorously establish translation identifiability
under reasonable UDT settings, to our best knowledge. Experiments corroborate
with our theoretical claims.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.09798">All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks. (arXiv:2401.09798v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Takemoto_K/0/1/0/all/0/1">Kazuhiro Takemoto</a></p>
<p>Large Language Models (LLMs) like ChatGPT face `jailbreak' challenges, where
safeguards are bypassed to produce ethically harmful prompts. This study
proposes a simple black-box method to effectively generate jailbreak prompts,
overcoming the high complexity and computational costs associated with existing
methods. The proposed technique iteratively rewrites harmful prompts into
non-harmful expressions using the target LLM itself, based on the hypothesis
that LLMs can directly sample expressions that bypass safeguards. Demonstrated
through experiments with ChatGPT (GPT-3.5 and GPT-4) and Gemini-Pro, this
method achieved an attack success rate of over 80% within an average of 5
iterations and remained effective despite model updates. The generated
jailbreak prompts were naturally-worded and concise; moreover, they were
difficult-to-defend. These results indicate that creating effective jailbreak
prompts is simpler than previously considered, suggesting that black-box
jailbreak attacks pose a more serious threat.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10189">Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction. (arXiv:2401.10189v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongxiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Huimin Zhao</a></p>
<p>Fine-grained few-shot entity extraction in the chemical domain faces two
unique challenges. First, compared with entity extraction tasks in the general
domain, sentences from chemical papers usually contain more entities. Moreover,
entity extraction models usually have difficulty extracting entities of
long-tailed types. In this paper, we propose Chem-FINESE, a novel
sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to
address these two challenges. Our Chem-FINESE has two components: a seq2seq
entity extractor to extract named entities from the input sentence and a
seq2seq self-validation module to reconstruct the original input sentence from
extracted entities. Inspired by the fact that a good entity extraction system
needs to extract entities faithfully, our new self-validation module leverages
entity extraction results to reconstruct the original input sentence. Besides,
we design a new contrastive loss to reduce excessive copying during the
extraction process. Finally, we release ChemNER+, a new fine-grained chemical
entity extraction dataset that is annotated by domain experts with the ChemNER
schema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets
show that our newly proposed framework has contributed up to 8.26% and 6.84%
absolute F1-score gains respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10273">Revolutionizing Pharma: Unveiling the AI and LLM Trends in the Pharmaceutical Industry. (arXiv:2401.10273v2 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1">Jingwen Tao</a></p>
<p>This document offers a critical overview of the emerging trends and
significant advancements in artificial intelligence (AI) within the
pharmaceutical industry. Detailing its application across key operational
areas, including research and development, animal testing, clinical trials,
hospital clinical stages, production, regulatory affairs, quality control and
other supporting areas, the paper categorically examines AI's role in each
sector. Special emphasis is placed on cutting-edge AI technologies like machine
learning algorithms and their contributions to various aspects of
pharmaceutical operations. Through this comprehensive analysis, the paper
highlights the transformative potential of AI in reshaping the pharmaceutical
industry's future.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10337">Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tu Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Srndic_N/0/1/0/all/0/1">Nedim Srndic</a>, <a href="http://arxiv.org/find/cs/1/au:+Neth_A/0/1/0/all/0/1">Alexander Neth</a></p>
<p>Tactics, Techniques and Procedures (TTPs) represent sophisticated attack
patterns in the cybersecurity domain, described encyclopedically in textual
knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP
mapping, is an important and challenging task. Conventional learning approaches
often target the problem in the classical multi-class or multilabel
classification setting. This setting hinders the learning ability of the model
due to a large number of classes (i.e., TTPs), the inevitable skewness of the
label distribution and the complex hierarchical structure of the label space.
We formulate the problem in a different learning paradigm, where the assignment
of a text to a TTP label is decided by the direct semantic similarity between
the two, thus reducing the complexity of competing solely over the large
labeling space. To that end, we propose a neural matching architecture with an
effective sampling-based learn-to-compare mechanism, facilitating the learning
process of the matching model despite constrained resources.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10393">Catastrophic Interference is Mitigated in Naturalistic Power-Law Learning Environments. (arXiv:2401.10393v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gandhi_A/0/1/0/all/0/1">Atith Gandhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1">Raj Sanjay Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Marupudi_V/0/1/0/all/0/1">Vijay Marupudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Varma_S/0/1/0/all/0/1">Sashank Varma</a></p>
<p>Neural networks often suffer from catastrophic interference (CI): performance
on previously learned tasks drops off significantly when learning a new task.
This contrasts strongly with humans, who can sequentially learn new tasks
without appreciably forgetting previous tasks. Prior work has explored various
techniques for mitigating CI such as regularization, rehearsal, generative
replay, and distillation methods. The current work takes a different approach,
one guided by cognitive science research showing that in naturalistic
environments, the probability of encountering a task decreases as a power-law
of the time since it was last performed. We argue that a realistic evaluation
of techniques for the mitigation of CI should be performed in simulated
naturalistic learning environments. Thus, we evaluate the extent of mitigation
of CI when training simple rehearsal-based methods in power-law environments
similar to the ones humans face. Our work explores this novel rehearsal-based
approach for a domain-incremental task: learning permutations in the MNIST
task. We compare our rehearsal environment with other baselines to show its
efficacy in promoting continual learning. Additionally, we investigate whether
this environment shows forward facilitation, i.e., faster learning of later
tasks. Next, we explore the robustness of our learning environment to the
number of tasks, model size, and amount of data rehearsed after each task.
Notably, our results show that the performance is comparable or superior to
that of models trained using popular regularization methods and also to
rehearsals in non-power-law environments. The benefits of this training
paradigm include simplicity and the lack of a need for extra neural circuitry.
In addition, because our method is orthogonal to other methods, future research
can combine training in power-law environments with other continual learning
mechanisms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10586">PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks. (arXiv:2401.10586v1 [cs.CR] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1">Ping Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhiyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qingchuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingfu Zhang</a></p>
<p>Black-box query-based attacks constitute significant threats to Machine
Learning as a Service (MLaaS) systems since they can generate adversarial
examples without accessing the target model's architecture and parameters.
Traditional defense mechanisms, such as adversarial training, gradient masking,
and input transformations, either impose substantial computational costs or
compromise the test accuracy of non-adversarial inputs. To address these
challenges, we propose an efficient defense mechanism, PuriDefense, that
employs random patch-wise purifications with an ensemble of lightweight
purification models at a low level of inference cost. These models leverage the
local implicit function and rebuild the natural image manifold. Our theoretical
analysis suggests that this approach slows down the convergence of query-based
attacks by incorporating randomness into purifications. Extensive experiments
on CIFAR-10 and ImageNet validate the effectiveness of our proposed
purifier-based defense mechanism, demonstrating significant improvements in
robustness against query-based attacks.
</p>
</p>
</div>

    </div>
    </body>
    