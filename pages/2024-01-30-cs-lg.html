<!DOCTYPE html>
<html>
<head>
<title>2024-01-30-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2401.14411">Precision Mars Entry Navigation with Atmospheric Density Adaptation via Neural Networks. (arXiv:2401.14411v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Giraldo_Grueso_F/0/1/0/all/0/1">Felipe Giraldo-Grueso</a>, <a href="http://arxiv.org/find/cs/1/au:+Popov_A/0/1/0/all/0/1">Andrey A. Popov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanetti_R/0/1/0/all/0/1">Renato Zanetti</a></p>
<p>Discrepancies between the true Martian atmospheric density and the onboard
density model can significantly impair the performance of spacecraft entry
navigation filters. This work introduces a new approach to online filtering for
Martian entry by using a neural network to estimate atmospheric density and
employing a consider analysis to account for the uncertainty in the estimate.
The network is trained on an exponential atmospheric density model, and its
parameters are dynamically adapted in real time to account for any mismatches
between the true and estimated densities. The adaptation of the network is
formulated as a maximum likelihood problem, leveraging the measurement
innovations of the filter to identify optimal network parameters. The
incorporation of a neural network enables the use of stochastic optimizers
known for their efficiency in the machine learning domain within the context of
the maximum likelihood approach. Performance comparisons against previous
approaches are conducted in various realistic Mars entry navigation scenarios,
resulting in superior estimation accuracy and precise alignment of the
estimated density with a broad selection of realistic Martian atmospheres
sampled from perturbed Mars-GRAM data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14412">Harnessing Neuron Stability to Improve DNN Verification. (arXiv:2401.14412v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Duong_H/0/1/0/all/0/1">Hai Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">ThanhVu Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwyer_M/0/1/0/all/0/1">Matthew B. Dwyer</a></p>
<p>Deep Neural Networks (DNN) have emerged as an effective approach to tackling
real-world problems. However, like human-written software, DNNs are susceptible
to bugs and attacks. This has generated significant interests in developing
effective and scalable DNN verification techniques and tools. In this paper, we
present VeriStable, a novel extension of recently proposed DPLL-based
constraint DNN verification approach. VeriStable leverages the insight that
while neuron behavior may be non-linear across the entire DNN input space, at
intermediate states computed during verification many neurons may be
constrained to have linear behavior - these neurons are stable. Efficiently
detecting stable neurons reduces combinatorial complexity without compromising
the precision of abstractions. Moreover, the structure of clauses arising in
DNN verification problems shares important characteristics with industrial SAT
benchmarks. We adapt and incorporate multi-threading and restart optimizations
targeting those characteristics to further optimize DPLL-based DNN
verification. We evaluate the effectiveness of VeriStable across a range of
challenging benchmarks including fully-connected feedforward networks (FNNs),
convolutional neural networks (CNNs) and residual networks (ResNets) applied to
the standard MNIST and CIFAR datasets. Preliminary results show that VeriStable
is competitive and outperforms state-of-the-art DNN verification tools,
including $\alpha$-$\beta$-CROWN and MN-BaB, the first and second performers of
the VNN-COMP, respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14413">Aprendizado de m\&#x27;aquina aplicado na eletroqu\&#x27;imica. (arXiv:2401.14413v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Araujo_C/0/1/0/all/0/1">Carlos Eduardo do Egito Ara&#xfa;jo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sgobbi_L/0/1/0/all/0/1">L&#xed;via F. Sgobbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sene_I/0/1/0/all/0/1">Iwens Gervasio Sene Jr</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_S/0/1/0/all/0/1">Sergio Teixeira de Carvalho</a></p>
<p>This systematic review focuses on analyzing the use of machine learning
techniques for identifying and quantifying analytes in various electrochemical
applications, presenting the available applications in the literature. Machine
learning is a tool that can facilitate the analysis and enhance the
understanding of processes involving various analytes. In electrochemical
biosensors, it increases the precision of medical diagnostics, improving the
identification of biomarkers and pathogens with high reliability. It can be
effectively used for the classification of complex chemical products; in
environmental monitoring, using low-cost sensors; in portable devices and
wearable systems; among others. Currently, the analysis of some analytes is
still performed manually, requiring the expertise of a specialist in the field
and thus hindering the generalization of results. In light of the advancements
in artificial intelligence today, this work proposes to carry out a systematic
review of the literature on the applications of artificial intelligence
techniques. A set of articles has been identified that address electrochemical
problems using machine learning techniques, more specifically, supervised
learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14416">Acoustic characterization of speech rhythm: going beyond metrics with recurrent neural networks. (arXiv:2401.14416v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Deloche_F/0/1/0/all/0/1">Fran&#xe7;ois Deloche</a>, <a href="http://arxiv.org/find/eess/1/au:+Bonnasse_Gahot_L/0/1/0/all/0/1">Laurent Bonnasse-Gahot</a>, <a href="http://arxiv.org/find/eess/1/au:+Gervain_J/0/1/0/all/0/1">Judit Gervain</a></p>
<p>Languages have long been described according to their perceived rhythmic
attributes. The associated typologies are of interest in psycholinguistics as
they partly predict newborns' abilities to discriminate between languages and
provide insights into how adult listeners process non-native languages. Despite
the relative success of rhythm metrics in supporting the existence of
linguistic rhythmic classes, quantitative studies have yet to capture the full
complexity of temporal regularities associated with speech rhythm. We argue
that deep learning offers a powerful pattern-recognition approach to advance
the characterization of the acoustic bases of speech rhythm. To explore this
hypothesis, we trained a medium-sized recurrent neural network on a language
identification task over a large database of speech recordings in 21 languages.
The network had access to the amplitude envelopes and a variable identifying
the voiced segments, assuming that this signal would poorly convey phonetic
information but preserve prosodic features. The network was able to identify
the language of 10-second recordings in 40% of the cases, and the language was
in the top-3 guesses in two-thirds of the cases. Visualization methods show
that representations built from the network activations are consistent with
speech rhythm typologies, although the resulting maps are more complex than two
separated clusters between stress and syllable-timed languages. We further
analyzed the model by identifying correlations between network activations and
known speech rhythm metrics. The findings illustrate the potential of deep
learning tools to advance our understanding of speech rhythm through the
identification and exploration of linguistically relevant acoustic feature
spaces.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14417">Fuzzy Logic Function as a Post-hoc Explanator of the Nonlinear Classifier. (arXiv:2401.14417v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Klimo_M/0/1/0/all/0/1">Martin Klimo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kralik_L/0/1/0/all/0/1">Lubomir Kralik</a></p>
<p>Pattern recognition systems implemented using deep neural networks achieve
better results than linear models. However, their drawback is the black box
property. This property means that one with no experience utilising nonlinear
systems may need help understanding the outcome of the decision. Such a
solution is unacceptable to the user responsible for the final decision. He
must not only believe in the decision but also understand it. Therefore,
recognisers must have an architecture that allows interpreters to interpret the
findings. The idea of post-hoc explainable classifiers is to design an
interpretable classifier parallel to the black box classifier, giving the same
decisions as the black box classifier. This paper shows that the explainable
classifier completes matching classification decisions with the black box
classifier on the MNIST and FashionMNIST databases if Zadeh`s fuzzy logic
function forms the classifier and DeconvNet importance gives the truth values.
Since the other tested significance measures achieved lower performance than
DeconvNet, it is the optimal transformation of the feature values to their
truth values as inputs to the fuzzy logic function for the databases and
recogniser architecture used.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14421">Multi-Agent Based Transfer Learning for Data-Driven Air Traffic Applications. (arXiv:2401.14421v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1">Chuhao Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1">Hong-Cheol Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hyunsang Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_I/0/1/0/all/0/1">Inseok Hwang</a></p>
<p>Research in developing data-driven models for Air Traffic Management (ATM)
has gained a tremendous interest in recent years. However, data-driven models
are known to have long training time and require large datasets to achieve good
performance. To address the two issues, this paper proposes a Multi-Agent
Bidirectional Encoder Representations from Transformers (MA-BERT) model that
fully considers the multi-agent characteristic of the ATM system and learns air
traffic controllers' decisions, and a pre-training and fine-tuning transfer
learning framework. By pre-training the MA-BERT on a large dataset from a major
airport and then fine-tuning it to other airports and specific air traffic
applications, a large amount of the total training time can be saved. In
addition, for newly adopted procedures and constructed airports where no
historical data is available, this paper shows that the pre-trained MA-BERT can
achieve high performance by updating regularly with little data. The proposed
transfer learning framework and MA-BERT are tested with the automatic dependent
surveillance-broadcast data recorded in 3 airports in South Korea in 2019.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14422">Location Agnostic Source-Free Domain Adaptive Learning to Predict Solar Power Generation. (arXiv:2401.14422v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Md Shazid Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">A S M Jahid Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Md Saydur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Yusuf_J/0/1/0/all/0/1">Jubair Yusuf</a>, <a href="http://arxiv.org/find/cs/1/au:+Sajol_M/0/1/0/all/0/1">Md Saiful Islam Sajol</a>, <a href="http://arxiv.org/find/cs/1/au:+Tumpa_F/0/1/0/all/0/1">Farhana Akter Tumpa</a></p>
<p>The prediction of solar power generation is a challenging task due to its
dependence on climatic characteristics that exhibit spatial and temporal
variability. The performance of a prediction model may vary across different
places due to changes in data distribution, resulting in a model that works
well in one region but not in others. Furthermore, as a consequence of global
warming, there is a notable acceleration in the alteration of weather patterns
on an annual basis. This phenomenon introduces the potential for diminished
efficacy of existing models, even within the same geographical region, as time
progresses. In this paper, a domain adaptive deep learning-based framework is
proposed to estimate solar power generation using weather features that can
solve the aforementioned challenges. A feed-forward deep convolutional network
model is trained for a known location dataset in a supervised manner and
utilized to predict the solar power of an unknown location later. This adaptive
data-driven approach exhibits notable advantages in terms of computing speed,
storage efficiency, and its ability to improve outcomes in scenarios where
state-of-the-art non-adaptive methods fail. Our method has shown an improvement
of $10.47 \%$, $7.44 \%$, $5.11\%$ in solar power prediction accuracy compared
to best performing non-adaptive method for California (CA), Florida (FL) and
New York (NY), respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14423">Prompt Design and Engineering: Introduction and Advanced Methods. (arXiv:2401.14423v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amatriain_X/0/1/0/all/0/1">Xavier Amatriain</a></p>
<p>Prompt design and engineering has become an important discipline in just the
past few months. In this paper, we provide an introduction to the main concepts
as well as review basic and more advanced approaches to prompt design and
engineering.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14424">Discovering Mathematical Formulas from Data via GPT-guided Monte Carlo Tree Search. (arXiv:2401.14424v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weijun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Lina Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Min Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_M/0/1/0/all/0/1">Meilan Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1">Shu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yusong Deng</a></p>
<p>Finding a concise and interpretable mathematical formula that accurately
describes the relationship between each variable and the predicted value in the
data is a crucial task in scientific research, as well as a significant
challenge in artificial intelligence. This problem is referred to as symbolic
regression, which is an NP-hard problem. Last year, a symbolic regression
method based on Monte Carlo Tree Search (MCTS) was proposed and sota was
obtained on multiple datasets. While this algorithm has shown considerable
improvement in recovering target expressions compared to previous methods, the
lack of guidance during the MCTS process severely hampers its search
efficiency. Recently, some algorithms have added a pre-trained policy network
to guide the search of MCTS, but the pre-trained policy network generalizes
poorly. To balance efficiency and generality, we propose SR-GPT combining ideas
from AlphaZero. SR-GPT is a new symbolic regression algorithm that combines
MCTS with a Generative Pre-Trained Transformer (GPT). By using GPT to guide the
MCTS process, the search efficiency of MCTS is significantly improved. Next, we
utilize the MCTS results to further refine the GPT, enhancing its capabilities
and providing more accurate guidance for the MCTS process. MCTS and GPT are
coupled together and optimize each other until the target expression is
successfully determined. We conducted extensive evaluations of SR-GPT using 222
expressions sourced from over 10 different symbolic regression datasets. The
experimental results demonstrate that SR-GPT outperforms existing
state-of-the-art algorithms in accurately recovering symbolic expressions both
with and without added noise.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14426">M$^3$TN: Multi-gate Mixture-of-Experts based Multi-valued Treatment Network for Uplift Modeling. (arXiv:2401.14426v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zexu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a></p>
<p>Uplift modeling is a technique used to predict the effect of a treatment
(e.g., discounts) on an individual's response. Although several methods have
been proposed for multi-valued treatment, they are extended from binary
treatment methods. There are still some limitations. Firstly, existing methods
calculate uplift based on predicted responses, which may not guarantee a
consistent uplift distribution between treatment and control groups. Moreover,
this may cause cumulative errors for multi-valued treatment. Secondly, the
model parameters become numerous with many prediction heads, leading to reduced
efficiency. To address these issues, we propose a novel \underline{M}ulti-gate
\underline{M}ixture-of-Experts based \underline{M}ulti-valued
\underline{T}reatment \underline{N}etwork (M$^3$TN). M$^3$TN consists of two
components: 1) a feature representation module with Multi-gate
Mixture-of-Experts to improve the efficiency; 2) a reparameterization module by
modeling uplift explicitly to improve the effectiveness. We also conduct
extensive experiments to demonstrate the effectiveness and efficiency of our
M$^3$TN.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14427">Beimingwu: A Learnware Dock System. (arXiv:2401.14427v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zhi-Hao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jian-Dong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_X/0/1/0/all/0/1">Xiao-Dong Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_P/0/1/0/all/0/1">Peng Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1">Qin-Cheng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hai-Tian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1">Xiao-Chuan Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhi-Hua Zhou</a></p>
<p>The learnware paradigm proposed by Zhou [2016] aims to enable users to reuse
numerous existing well-trained models instead of building machine learning
models from scratch, with the hope of solving new user tasks even beyond
models' original purposes. In this paradigm, developers worldwide can submit
their high-performing models spontaneously to the learnware dock system
(formerly known as learnware market) without revealing their training data.
Once the dock system accepts the model, it assigns a specification and
accommodates the model. This specification allows the model to be adequately
identified and assembled to reuse according to future users' needs, even if
they have no prior knowledge of the model. This paradigm greatly differs from
the current big model direction and it is expected that a learnware dock system
housing millions or more high-performing models could offer excellent
capabilities for both planned tasks where big models are applicable; and
unplanned, specialized, data-sensitive scenarios where big models are not
present or applicable.
</p>
<p>This paper describes Beimingwu, the first open-source learnware dock system
providing foundational support for future research of learnware paradigm.The
system significantly streamlines the model development for new user tasks,
thanks to its integrated architecture and engine design, extensive engineering
implementations and optimizations, and the integration of various algorithms
for learnware identification and reuse. Notably, this is possible even for
users with limited data and minimal expertise in machine learning, without
compromising the raw data's security. Beimingwu supports the entire process of
learnware paradigm. The system lays the foundation for future research in
learnware-related algorithms and systems, and prepares the ground for hosting a
vast array of learnwares and establishing a learnware ecosystem.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14429">[Re] The Discriminative Kalman Filter for Bayesian Filtering with Nonlinear and Non-Gaussian Observation Models. (arXiv:2401.14429v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Casco_Rodriguez_J/0/1/0/all/0/1">Josue Casco-Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Kemere_C/0/1/0/all/0/1">Caleb Kemere</a>, <a href="http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1">Richard G. Baraniuk</a></p>
<p>Kalman filters provide a straightforward and interpretable means to estimate
hidden or latent variables, and have found numerous applications in control,
robotics, signal processing, and machine learning. One such application is
neural decoding for neuroprostheses. In 2020, Burkhart et al. thoroughly
evaluated their new version of the Kalman filter that leverages Bayes' theorem
to improve filter performance for highly non-linear or non-Gaussian observation
models. This work provides an open-source Python alternative to the authors'
MATLAB algorithm. Specifically, we reproduce their most salient results for
neuroscientific contexts and further examine the efficacy of their filter using
multiple random seeds and previously unused trials from the authors' dataset.
All experiments were performed offline on a single computer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14432">A2C: A Modular Multi-stage Collaborative Decision Framework for Human-AI Teams. (arXiv:2401.14432v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tariq_S/0/1/0/all/0/1">Shahroz Tariq</a>, <a href="http://arxiv.org/find/cs/1/au:+Chhetri_M/0/1/0/all/0/1">Mohan Baruwal Chhetri</a>, <a href="http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1">Surya Nepal</a>, <a href="http://arxiv.org/find/cs/1/au:+Paris_C/0/1/0/all/0/1">Cecile Paris</a></p>
<p>This paper introduces A2C, a multi-stage collaborative decision framework
designed to enable robust decision-making within human-AI teams. Drawing
inspiration from concepts such as rejection learning and learning to defer, A2C
incorporates AI systems trained to recognise uncertainty in their decisions and
defer to human experts when needed. Moreover, A2C caters to scenarios where
even human experts encounter limitations, such as in incident detection and
response in cyber Security Operations Centres (SOC). In such scenarios, A2C
facilitates collaborative explorations, enabling collective resolution of
complex challenges. With support for three distinct decision-making modes in
human-AI teams: Automated, Augmented, and Collaborative, A2C offers a flexible
platform for developing effective strategies for human-AI collaboration. By
harnessing the strengths of both humans and AI, it significantly improves the
efficiency and effectiveness of complex decision-making in dynamic and evolving
environments. To validate A2C's capabilities, we conducted extensive simulative
experiments using benchmark datasets. The results clearly demonstrate that all
three modes of decision-making can be effectively supported by A2C. Most
notably, collaborative exploration by (simulated) human experts and AI achieves
superior performance compared to AI in isolation, underscoring the framework's
potential to enhance decision-making within human-AI teams.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14434">Transforming gradient-based techniques into interpretable methods. (arXiv:2401.14434v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rodrigues_C/0/1/0/all/0/1">Caroline Mazini Rodrigues</a> (LRDE, LIGM), <a href="http://arxiv.org/find/cs/1/au:+Boutry_N/0/1/0/all/0/1">Nicolas Boutry</a> (LRDE), <a href="http://arxiv.org/find/cs/1/au:+Najman_L/0/1/0/all/0/1">Laurent Najman</a> (LIGM)</p>
<p>The explication of Convolutional Neural Networks (CNN) through xAI techniques
often poses challenges in interpretation. The inherent complexity of input
features, notably pixels extracted from images, engenders complex correlations.
Gradient-based methodologies, exemplified by Integrated Gradients (IG),
effectively demonstrate the significance of these features. Nevertheless, the
conversion of these explanations into images frequently yields considerable
noise. Presently, we introduce GAD (Gradient Artificial Distancing) as a
supportive framework for gradient-based techniques. Its primary objective is to
accentuate influential regions by establishing distinctions between classes.
The essence of GAD is to limit the scope of analysis during visualization and,
consequently reduce image noise. Empirical investigations involving occluded
images have demonstrated that the identified regions through this methodology
indeed play a pivotal role in facilitating class differentiation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14439">Incremental Affinity Propagation based on Cluster Consolidation and Stratification. (arXiv:2401.14439v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Castano_S/0/1/0/all/0/1">Silvana Castano</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrara_A/0/1/0/all/0/1">Alfio Ferrara</a>, <a href="http://arxiv.org/find/cs/1/au:+Montanelli_S/0/1/0/all/0/1">Stefano Montanelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Periti_F/0/1/0/all/0/1">Francesco Periti</a></p>
<p>Modern data mining applications require to perform incremental clustering
over dynamic datasets by tracing temporal changes over the resulting clusters.
In this paper, we propose A-Posteriori affinity Propagation (APP), an
incremental extension of Affinity Propagation (AP) based on cluster
consolidation and cluster stratification to achieve faithfulness and
forgetfulness. APP enforces incremental clustering where i) new arriving
objects are dynamically consolidated into previous clusters without the need to
re-execute clustering over the entire dataset of objects, and ii) a faithful
sequence of clustering results is produced and maintained over time, while
allowing to forget obsolete clusters with decremental learning functionalities.
Four popular labeled datasets are used to test the performance of APP with
respect to benchmark clustering performances obtained by conventional AP and
Incremental Affinity Propagation based on Nearest neighbor Assignment (IAPNA)
algorithms. Experimental results show that APP achieves comparable clustering
performance while enforcing scalability at the same time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14440">Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models. (arXiv:2401.14440v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arakelyan_E/0/1/0/all/0/1">Erik Arakelyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhaoqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1">Isabelle Augenstein</a></p>
<p>Recent studies of the emergent capabilities of transformer-based Natural
Language Understanding (NLU) models have indicated that they have an
understanding of lexical and compositional semantics. We provide evidence that
suggests these claims should be taken with a grain of salt: we find that
state-of-the-art Natural Language Inference (NLI) models are sensitive towards
minor semantics preserving surface-form variations, which lead to sizable
inconsistent model decisions during inference. Notably, this behaviour differs
from valid and in-depth comprehension of compositional semantics, however does
neither emerge when evaluating model accuracy on standard benchmarks nor when
probing for syntactic, monotonic, and logically robust reasoning. We propose a
novel framework to measure the extent of semantic sensitivity. To this end, we
evaluate NLI models on adversarially generated examples containing minor
semantics-preserving surface-form input noise. This is achieved using
conditional text generation, with the explicit condition that the NLI model
predicts the relationship between the original and adversarial inputs as a
symmetric equivalence entailment. We systematically study the effects of the
phenomenon across NLI models for \emph{in-} and \emph{out-of} domain settings.
Our experiments show that semantic sensitivity causes performance degradations
of $12.92\%$ and $23.71\%$ average over \emph{in-} and \emph{out-of-} domain
settings, respectively. We further perform ablation studies, analysing this
phenomenon across models, datasets, and variations in inference and show that
semantic sensitivity can lead to major inconsistency within model predictions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14442">Improving Antibody Humanness Prediction using Patent Data. (arXiv:2401.14442v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Ucar_T/0/1/0/all/0/1">Talip Ucar</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ramon_A/0/1/0/all/0/1">Aubin Ramon</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Oglic_D/0/1/0/all/0/1">Dino Oglic</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Croasdale_Wood_R/0/1/0/all/0/1">Rebecca Croasdale-Wood</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Diethe_T/0/1/0/all/0/1">Tom Diethe</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sormanni_P/0/1/0/all/0/1">Pietro Sormanni</a></p>
<p>We investigate the potential of patent data for improving the antibody
humanness prediction using a multi-stage, multi-loss training process.
Humanness serves as a proxy for the immunogenic response to antibody
therapeutics, one of the major causes of attrition in drug discovery and a
challenging obstacle for their use in clinical settings. We pose the initial
learning stage as a weakly-supervised contrastive-learning problem, where each
antibody sequence is associated with possibly multiple identifiers of function
and the objective is to learn an encoder that groups them according to their
patented properties. We then freeze a part of the contrastive encoder and
continue training it on the patent data using the cross-entropy loss to predict
the humanness score of a given antibody sequence. We illustrate the utility of
the patent data and our approach by performing inference on three different
immunogenicity datasets, unseen during training. Our empirical results
demonstrate that the learned model consistently outperforms the alternative
baselines and establishes new state-of-the-art on five out of six inference
tasks, irrespective of the used metric.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14447">Wordflow: Social Prompt Engineering for Large Language Models. (arXiv:2401.14447v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zijie J. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthy_A/0/1/0/all/0/1">Aishwarya Chakravarthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Munechika_D/0/1/0/all/0/1">David Munechika</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1">Duen Horng Chau</a></p>
<p>Large language models (LLMs) require well-crafted prompts for effective use.
Prompt engineering, the process of designing prompts, is challenging,
particularly for non-experts who are less familiar with AI technologies. While
researchers have proposed techniques and tools to assist LLM users in prompt
design, these works primarily target AI application developers rather than
non-experts. To address this research gap, we propose social prompt
engineering, a novel paradigm that leverages social computing techniques to
facilitate collaborative prompt design. To investigate social prompt
engineering, we introduce Wordflow, an open-source and social text editor that
enables everyday users to easily create, run, share, and discover LLM prompts.
Additionally, by leveraging modern web technologies, Wordflow allows users to
run LLMs locally and privately in their browsers. Two usage scenarios highlight
how social prompt engineering and our tool can enhance laypeople's interaction
with LLMs. Wordflow is publicly accessible at
https://poloclub.github.io/wordflow.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14461">Marabou 2.0: A Versatile Formal Analyzer of Neural Networks. (arXiv:2401.14461v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Haoze Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Isac_O/0/1/0/all/0/1">Omri Isac</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeljic_A/0/1/0/all/0/1">Aleksandar Zelji&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagomori_T/0/1/0/all/0/1">Teruhiro Tagomori</a>, <a href="http://arxiv.org/find/cs/1/au:+Daggitt_M/0/1/0/all/0/1">Matthew Daggitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokke_W/0/1/0/all/0/1">Wen Kokke</a>, <a href="http://arxiv.org/find/cs/1/au:+Refaeli_I/0/1/0/all/0/1">Idan Refaeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Amir_G/0/1/0/all/0/1">Guy Amir</a>, <a href="http://arxiv.org/find/cs/1/au:+Julian_K/0/1/0/all/0/1">Kyle Julian</a>, <a href="http://arxiv.org/find/cs/1/au:+Bassan_S/0/1/0/all/0/1">Shahaf Bassan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Pei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lahav_O/0/1/0/all/0/1">Ori Lahav</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Min Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Komendantskaya_E/0/1/0/all/0/1">Ekaterina Komendantskaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1">Guy Katz</a>, <a href="http://arxiv.org/find/cs/1/au:+Barrett_C/0/1/0/all/0/1">Clark Barrett</a></p>
<p>This paper serves as a comprehensive system description of version 2.0 of the
Marabou framework for formal analysis of neural networks. We discuss the tool's
architectural design and highlight the major features and components introduced
since its initial release.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14469">Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels. (arXiv:2401.14469v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Babaiee_Z/0/1/0/all/0/1">Zahra Babaiee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiasari_P/0/1/0/all/0/1">Peyman M. Kiasari</a>, <a href="http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1">Daniela Rus</a>, <a href="http://arxiv.org/find/cs/1/au:+Grosu_R/0/1/0/all/0/1">Radu Grosu</a></p>
<p>Recent advances in depthwise-separable convolutional neural networks
(DS-CNNs) have led to novel architectures, that surpass the performance of
classical CNNs, by a considerable scalability and accuracy margin. This paper
reveals another striking property of DS-CNN architectures: discernible and
explainable patterns emerge in their trained depthwise convolutional kernels in
all layers. Through an extensive analysis of millions of trained filters, with
different sizes and from various models, we employed unsupervised clustering
with autoencoders, to categorize these filters. Astonishingly, the patterns
converged into a few main clusters, each resembling the difference of Gaussian
(DoG) functions, and their first and second-order derivatives. Notably, we were
able to classify over 95\% and 90\% of the filters from state-of-the-art
ConvNextV2 and ConvNeXt models, respectively. This finding is not merely a
technological curiosity; it echoes the foundational models neuroscientists have
long proposed for the vision systems of mammals. Our results thus deepen our
understanding of the emergent properties of trained DS-CNNs and provide a
bridge between artificial and biological visual processing systems. More
broadly, they pave the way for more interpretable and biologically-inspired
neural network designs in the future.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14483">Four Facets of Forecast Felicity: Calibration, Predictiveness, Randomness and Regret. (arXiv:2401.14483v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Derr_R/0/1/0/all/0/1">Rabanus Derr</a>, <a href="http://arxiv.org/find/cs/1/au:+Williamson_R/0/1/0/all/0/1">Robert C. Williamson</a></p>
<p>Machine learning is about forecasting. Forecasts, however, obtain their
usefulness only through their evaluation. Machine learning has traditionally
focused on types of losses and their corresponding regret. Currently, the
machine learning community regained interest in calibration. In this work, we
show the conceptual equivalence of calibration and regret in evaluating
forecasts. We frame the evaluation problem as a game between a forecaster, a
gambler and nature. Putting intuitive restrictions on gambler and forecaster,
calibration and regret naturally fall out of the framework. In addition, this
game links evaluation of forecasts to randomness of outcomes. Random outcomes
with respect to forecasts are equivalent to good forecasts with respect to
outcomes. We call those dual aspects, calibration and regret, predictiveness
and randomness, the four facets of forecast felicity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14486">CloudTracks: A Dataset for Localizing Ship Tracks in Satellite Images of Clouds. (arXiv:2401.14486v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chaudhry_M/0/1/0/all/0/1">Muhammad Ahmed Chaudhry</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_L/0/1/0/all/0/1">Lyna Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Irvin_J/0/1/0/all/0/1">Jeremy Irvin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ido_Y/0/1/0/all/0/1">Yuzu Ido</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_S/0/1/0/all/0/1">Sonia Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Isobe_J/0/1/0/all/0/1">Jared Thomas Isobe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1">Andrew Y. Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Watson_Parris_D/0/1/0/all/0/1">Duncan Watson-Parris</a></p>
<p>Clouds play a significant role in global temperature regulation through their
effect on planetary albedo. Anthropogenic emissions of aerosols can alter the
albedo of clouds, but the extent of this effect, and its consequent impact on
temperature change, remains uncertain. Human-induced clouds caused by ship
aerosol emissions, commonly referred to as ship tracks, provide visible
manifestations of this effect distinct from adjacent cloud regions and
therefore serve as a useful sandbox to study human-induced clouds. However, the
lack of large-scale ship track data makes it difficult to deduce their general
effects on cloud formation. Towards developing automated approaches to localize
ship tracks at scale, we present CloudTracks, a dataset containing 3,560
satellite images labeled with more than 12,000 ship track instance annotations.
We train semantic segmentation and instance segmentation model baselines on our
dataset and find that our best model substantially outperforms previous
state-of-the-art for ship track localization (61.29 vs. 48.65 IoU). We also
find that the best instance segmentation model is able to identify the number
of ship tracks in each image more accurately than the previous state-of-the-art
(1.64 vs. 4.99 MAE). However, we identify cases where the best model struggles
to accurately localize and count ship tracks, so we believe CloudTracks will
stimulate novel machine learning approaches to better detect elongated and
overlapping features in satellite images. We release our dataset openly at
{zenodo.org/records/10042922}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14488">Scilab-RL: A software framework for efficient reinforcement learning and cognitive modeling research. (arXiv:2401.14488v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dohmen_J/0/1/0/all/0/1">Jan Dohmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Roder_F/0/1/0/all/0/1">Frank R&#xf6;der</a>, <a href="http://arxiv.org/find/cs/1/au:+Eppe_M/0/1/0/all/0/1">Manfred Eppe</a></p>
<p>One problem with researching cognitive modeling and reinforcement learning
(RL) is that researchers spend too much time on setting up an appropriate
computational framework for their experiments. Many open source implementations
of current RL algorithms exist, but there is a lack of a modular suite of tools
combining different robotic simulators and platforms, data visualization,
hyperparameter optimization, and baseline experiments. To address this problem,
we present Scilab-RL, a software framework for efficient research in cognitive
modeling and reinforcement learning for robotic agents. The framework focuses
on goal-conditioned reinforcement learning using Stable Baselines 3 and the
OpenAI gym interface. It enables native possibilities for experiment
visualizations and hyperparameter optimization. We describe how these features
enable researchers to conduct experiments with minimal time effort, thus
maximizing research output.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14493">K-QA: A Real-World Medical Q&amp;A Benchmark. (arXiv:2401.14493v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Manes_I/0/1/0/all/0/1">Itay Manes</a>, <a href="http://arxiv.org/find/cs/1/au:+Ronn_N/0/1/0/all/0/1">Naama Ronn</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_D/0/1/0/all/0/1">David Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ber_R/0/1/0/all/0/1">Ran Ilan Ber</a>, <a href="http://arxiv.org/find/cs/1/au:+Horowitz_Kugler_Z/0/1/0/all/0/1">Zehavi Horowitz-Kugler</a>, <a href="http://arxiv.org/find/cs/1/au:+Stanovsky_G/0/1/0/all/0/1">Gabriel Stanovsky</a></p>
<p>Ensuring the accuracy of responses provided by large language models (LLMs)
is crucial, particularly in clinical settings where incorrect information may
directly impact patient health. To address this challenge, we construct K-QA, a
dataset containing 1,212 patient questions originating from real-world
conversations held on K Health (an AI-driven clinical platform). We employ a
panel of in-house physicians to answer and manually decompose a subset of K-QA
into self-contained statements. Additionally, we formulate two NLI-based
evaluation metrics approximating recall and precision: (1) comprehensiveness,
measuring the percentage of essential clinical information in the generated
answer and (2) hallucination rate, measuring the number of statements from the
physician-curated response contradicted by the LLM answer. Finally, we use K-QA
along with these metrics to evaluate several state-of-the-art models, as well
as the effect of in-context learning and medically-oriented augmented retrieval
schemes developed by the authors. Our findings indicate that in-context
learning improves the comprehensiveness of the models, and augmented retrieval
is effective in reducing hallucinations. We make K-QA available to to the
community to spur research into medically accurate NLP applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14497">Investigating the Quality of DermaMNIST and Fitzpatrick17k Dermatological Image Datasets. (arXiv:2401.14497v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abhishek_K/0/1/0/all/0/1">Kumar Abhishek</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Aditi Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamarneh_G/0/1/0/all/0/1">Ghassan Hamarneh</a></p>
<p>The remarkable progress of deep learning in dermatological tasks has brought
us closer to achieving diagnostic accuracies comparable to those of human
experts. However, while large datasets play a crucial role in the development
of reliable deep neural network models, the quality of data therein and their
correct usage are of paramount importance. Several factors can impact data
quality, such as the presence of duplicates, data leakage across train-test
partitions, mislabeled images, and the absence of a well-defined test
partition. In this paper, we conduct meticulous analyses of two popular
dermatological image datasets: DermaMNIST and Fitzpatrick17k, uncovering these
data quality issues, measure the effects of these problems on the benchmark
results, and propose corrections to the datasets. Besides ensuring the
reproducibility of our analysis, by making our analysis pipeline and the
accompanying code publicly available, we aim to encourage similar explorations
and to facilitate the identification and addressing of potential data quality
issues in other large datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14498">Predictive Analysis for Optimizing Port Operations. (arXiv:2401.14498v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Aniruddha Rajendra Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haiyan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1">Chetan Gupta</a></p>
<p>Maritime transport is a pivotal logistics mode for the long-distance and bulk
transportation of goods. However, the intricate planning involved in this mode
is often hindered by uncertainties, including weather conditions, cargo
diversity, and port dynamics, leading to increased costs. Consequently,
accurately estimating vessel total (stay) time at port and potential delays
becomes imperative for effective planning and scheduling in port operations.
This study aims to develop a port operation solution with competitive
prediction and classification capabilities for estimating vessel Total and
Delay times. This research addresses a significant gap in port analysis models
for vessel Stay and Delay times, offering a valuable contribution to the field
of maritime logistics. The proposed solution is designed to assist
decision-making in port environments and predict service delays. This is
demonstrated through a case study on Brazil ports. Additionally, feature
analysis is used to understand the key factors impacting maritime logistics,
enhancing the overall understanding of the complexities involved in port
operations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14502">MResT: Multi-Resolution Sensing for Real-Time Control with Vision-Language Models. (arXiv:2401.14502v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1">Saumya Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1">Mohit Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kroemer_O/0/1/0/all/0/1">Oliver Kroemer</a></p>
<p>Leveraging sensing modalities across diverse spatial and temporal resolutions
can improve performance of robotic manipulation tasks. Multi-spatial resolution
sensing provides hierarchical information captured at different spatial scales
and enables both coarse and precise motions. Simultaneously multi-temporal
resolution sensing enables the agent to exhibit high reactivity and real-time
control. In this work, we propose a framework, MResT (Multi-Resolution
Transformer), for learning generalizable language-conditioned multi-task
policies that utilize sensing at different spatial and temporal resolutions
using networks of varying capacities to effectively perform real time control
of precise and reactive tasks. We leverage off-the-shelf pretrained
vision-language models to operate on low-frequency global features along with
small non-pretrained models to adapt to high frequency local feedback. Through
extensive experiments in 3 domains (coarse, precise and dynamic manipulation
tasks), we show that our approach significantly improves (2X on average) over
recent multi-task baselines. Further, our approach generalizes well to visual
and geometric variations in target objects and to varying interaction forces.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14504">Learning When to See for Long-term Traffic Data Collection on Power-constrained Devices. (arXiv:2401.14504v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1">Ruixuan Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_W/0/1/0/all/0/1">Wenyu Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Bian_Z/0/1/0/all/0/1">Zilin Bian</a>, <a href="http://arxiv.org/find/eess/1/au:+Ozbay_K/0/1/0/all/0/1">Kaan Ozbay</a>, <a href="http://arxiv.org/find/eess/1/au:+Feng_C/0/1/0/all/0/1">Chen Feng</a></p>
<p>Collecting traffic data is crucial for transportation systems and urban
planning, and is often more desirable through easy-to-deploy but
power-constrained devices, due to the unavailability or high cost of power and
network infrastructure. The limited power means an inevitable trade-off between
data collection duration and accuracy/resolution. We introduce a novel
learning-based framework that strategically decides observation timings for
battery-powered devices and reconstructs the full data stream from sparsely
sampled observations, resulting in minimal performance loss and a significantly
prolonged system lifetime. Our framework comprises a predictor, a controller,
and an estimator. The predictor utilizes historical data to forecast future
trends within a fixed time horizon. The controller uses the forecasts to
determine the next optimal timing for data collection. Finally, the estimator
reconstructs the complete data profile from the sampled observations. We
evaluate the performance of the proposed method on PeMS data by an RNN
(Recurrent Neural Network) predictor and estimator, and a DRQN (Deep Recurrent
Q-Network) controller, and compare it against the baseline that uses Kalman
filter and uniform sampling. The results indicate that our method outperforms
the baseline, primarily due to the inclusion of more representative data points
in the profile, resulting in an overall 10\% improvement in estimation
accuracy. Source code will be publicly available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14512">Who Are We Missing? A Principled Approach to Characterizing the Underrepresented Population. (arXiv:2401.14512v1 [stat.ME])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Parikh_H/0/1/0/all/0/1">Harsh Parikh</a>, <a href="http://arxiv.org/find/stat/1/au:+Ross_R/0/1/0/all/0/1">Rachael Ross</a>, <a href="http://arxiv.org/find/stat/1/au:+Stuart_E/0/1/0/all/0/1">Elizabeth Stuart</a>, <a href="http://arxiv.org/find/stat/1/au:+Rudolph_K/0/1/0/all/0/1">Kara Rudolph</a></p>
<p>Randomized controlled trials (RCTs) serve as the cornerstone for
understanding causal effects, yet extending inferences to target populations
presents challenges due to effect heterogeneity and underrepresentation. Our
paper addresses the critical issue of identifying and characterizing
underrepresented subgroups in RCTs, proposing a novel framework for refining
target populations to improve generalizability. We introduce an
optimization-based approach, Rashomon Set of Optimal Trees (ROOT), to
characterize underrepresented groups. ROOT optimizes the target subpopulation
distribution by minimizing the variance of the target average treatment effect
estimate, ensuring more precise treatment effect estimations. Notably, ROOT
generates interpretable characteristics of the underrepresented population,
aiding researchers in effective communication. Our approach demonstrates
improved precision and interpretability compared to alternatives, as
illustrated with synthetic data experiments. We apply our methodology to extend
inferences from the Starting Treatment with Agonist Replacement Therapies
(START) trial -- investigating the effectiveness of medication for opioid use
disorder -- to the real-world population represented by the Treatment Episode
Dataset: Admissions (TEDS-A). By refining target populations using ROOT, our
framework offers a systematic approach to enhance decision-making accuracy and
inform future trials in diverse populations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14521">Towards Interpretable Physical-Conceptual Catchment-Scale Hydrological Modeling using the Mass-Conserving-Perceptron. (arXiv:2401.14521v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuan-Heng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1">Hoshin V. Gupta</a></p>
<p>We investigate the applicability of machine learning technologies to the
development of parsimonious, interpretable, catchment-scale hydrologic models
using directed-graph architectures based on the mass-conserving perceptron
(MCP) as the fundamental computational unit. Here, we focus on architectural
complexity (depth) at a single location, rather than universal applicability
(breadth) across large samples of catchments. The goal is to discover a minimal
representation (numbers of cell-states and flow paths) that represents the
dominant processes that can explain the input-state-output behaviors of a given
catchment, with particular emphasis given to simulating the full range (high,
medium, and low) of flow dynamics. We find that a HyMod-like architecture with
three cell-states and two major flow pathways achieves such a representation at
our study location, but that the additional incorporation of an input-bypass
mechanism significantly improves the timing and shape of the hydrograph, while
the inclusion of bi-directional groundwater mass exchanges significantly
enhances the simulation of baseflow. Overall, our results demonstrate the
importance of using multiple diagnostic metrics for model evaluation, while
highlighting the need for designing training metrics that are better suited to
extracting information across the full range of flow dynamics. Further, they
set the stage for interpretable regional-scale MCP-based hydrological modeling
(using large sample data) by using neural architecture search to determine
appropriate minimal representations for catchments in different hydroclimatic
regimes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14530">Relative Value Biases in Large Language Models. (arXiv:2401.14530v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hayes_W/0/1/0/all/0/1">William M. Hayes</a>, <a href="http://arxiv.org/find/cs/1/au:+Yax_N/0/1/0/all/0/1">Nicolas Yax</a>, <a href="http://arxiv.org/find/cs/1/au:+Palminteri_S/0/1/0/all/0/1">Stefano Palminteri</a></p>
<p>Studies of reinforcement learning in humans and animals have demonstrated a
preference for options that yielded relatively better outcomes in the past,
even when those options are associated with lower absolute reward. The present
study tested whether large language models would exhibit a similar bias. We had
gpt-4-1106-preview (GPT-4 Turbo) and Llama-2-70B make repeated choices between
pairs of options with the goal of maximizing payoffs. A complete record of
previous outcomes was included in each prompt. Both models exhibited relative
value decision biases similar to those observed in humans and animals. Making
relative comparisons among outcomes more explicit magnified the bias, whereas
prompting the models to estimate expected outcomes caused the bias to
disappear. These results have implications for the potential mechanisms that
contribute to context-dependent choice in human agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14534">Meta-Learning Linear Quadratic Regulators: A Policy Gradient MAML Approach for the Model-free LQR. (arXiv:2401.14534v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Toso_L/0/1/0/all/0/1">Leonardo F. Toso</a>, <a href="http://arxiv.org/find/math/1/au:+Zhan_D/0/1/0/all/0/1">Donglin Zhan</a>, <a href="http://arxiv.org/find/math/1/au:+Anderson_J/0/1/0/all/0/1">James Anderson</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1">Han Wang</a></p>
<p>We investigate the problem of learning Linear Quadratic Regulators (LQR) in a
multi-task, heterogeneous, and model-free setting. We characterize the
stability and personalization guarantees of a Policy Gradient-based (PG)
Model-Agnostic Meta-Learning (MAML) (Finn et al., 2017) approach for the LQR
problem under different task-heterogeneity settings. We show that the MAML-LQR
approach produces a stabilizing controller close to each task-specific optimal
controller up to a task-heterogeneity bias for both model-based and model-free
settings. Moreover, in the model-based setting, we show that this controller is
achieved with a linear convergence rate, which improves upon sub-linear rates
presented in existing MAML-LQR work. In contrast to existing MAML-LQR results,
our theoretical guarantees demonstrate that the learned controller can
efficiently adapt to unseen LQR tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14535">CaRiNG: Learning Temporal Causal Representation under Non-Invertible Generation Process. (arXiv:2401.14535v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guangyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yifan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xiangchen Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuewen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1">Weiran Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a></p>
<p>Identifying the underlying time-delayed latent causal processes in sequential
data is vital for grasping temporal dynamics and making downstream reasoning.
While some recent methods can robustly identify these latent causal variables,
they rely on strict assumptions about the invertible generation process from
latent variables to observed data. However, these assumptions are often hard to
satisfy in real-world applications containing information loss. For instance,
the visual perception process translates a 3D space into 2D images, or the
phenomenon of persistence of vision incorporates historical data into current
perceptions. To address this challenge, we establish an identifiability theory
that allows for the recovery of independent latent components even when they
come from a nonlinear and non-invertible mix. Using this theory as a
foundation, we propose a principled approach, CaRiNG, to learn the CAusal
RepresentatIon of Non-invertible Generative temporal data with identifiability
guarantees. Specifically, we utilize temporal context to recover lost latent
information and apply the conditions in our theory to guide the training
process. Through experiments conducted on synthetic datasets, we validate that
our CaRiNG method reliably identifies the causal process, even when the
generation process is non-invertible. Moreover, we demonstrate that our
approach considerably improves temporal understanding and reasoning in
practical applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14539">Understanding Disparities in Post Hoc Machine Learning Explanation. (arXiv:2401.14539v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mhasawade_V/0/1/0/all/0/1">Vishwali Mhasawade</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_S/0/1/0/all/0/1">Salman Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Haskell_Craig_Z/0/1/0/all/0/1">Zoe Haskell-Craig</a>, <a href="http://arxiv.org/find/cs/1/au:+Chunara_R/0/1/0/all/0/1">Rumi Chunara</a></p>
<p>Previous work has highlighted that existing post-hoc explanation methods
exhibit disparities in explanation fidelity (across 'race' and 'gender' as
sensitive attributes), and while a large body of work focuses on mitigating
these issues at the explanation metric level, the role of the data generating
process and black box model in relation to explanation disparities remains
largely unexplored. Accordingly, through both simulations as well as
experiments on a real-world dataset, we specifically assess challenges to
explanation disparities that originate from properties of the data: limited
sample size, covariate shift, concept shift, omitted variable bias, and
challenges based on model properties: inclusion of the sensitive attribute and
appropriate functional form. Through controlled simulation analyses, our study
demonstrates that increased covariate shift, concept shift, and omission of
covariates increase explanation disparities, with the effect pronounced higher
for neural network models that are better able to capture the underlying
functional form in comparison to linear models. We also observe consistent
findings regarding the effect of concept shift and omitted variable bias on
explanation disparities in the Adult income dataset. Overall, results indicate
that disparities in model explanations can also depend on data and model
properties. Based on this systematic investigation, we provide recommendations
for the design of explanation methods that mitigate undesirable disparities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14544">Bayesian Optimization through Gaussian Cox Process Models for Spatio-temporal Data. (arXiv:2401.14544v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mei_Y/0/1/0/all/0/1">Yongsheng Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Imani_M/0/1/0/all/0/1">Mahdi Imani</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_T/0/1/0/all/0/1">Tian Lan</a></p>
<p>Bayesian optimization (BO) has established itself as a leading strategy for
efficiently optimizing expensive-to-evaluate functions. Existing BO methods
mostly rely on Gaussian process (GP) surrogate models and are not applicable to
(doubly-stochastic) Gaussian Cox processes, where the observation process is
modulated by a latent intensity function modeled as a GP. In this paper, we
propose a novel maximum a posteriori inference of Gaussian Cox processes. It
leverages the Laplace approximation and change of kernel technique to transform
the problem into a new reproducing kernel Hilbert space, where it becomes more
tractable computationally. It enables us to obtain both a functional posterior
of the latent intensity function and the covariance of the posterior, thus
extending existing works that often focus on specific link functions or
estimating the posterior mean. Using the result, we propose a BO framework
based on the Gaussian Cox process model and further develop a Nystr\"om
approximation for efficient computation. Extensive evaluations on various
synthetic and real-world datasets demonstrate significant improvement over
state-of-the-art inference solutions for Gaussian Cox processes, as well as
effective BO with a wide range of acquisition functions designed through the
underlying Gaussian Cox process model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14555">Revisiting Active Learning in the Era of Vision Foundation Models. (arXiv:2401.14555v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gupte_S/0/1/0/all/0/1">Sanket Rajan Gupte</a>, <a href="http://arxiv.org/find/cs/1/au:+Aklilu_J/0/1/0/all/0/1">Josiah Aklilu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nirschl_J/0/1/0/all/0/1">Jeffrey J. Nirschl</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_Levy_S/0/1/0/all/0/1">Serena Yeung-Levy</a></p>
<p>Foundation vision or vision-language models are trained on large unlabeled or
noisy data and learn robust representations that can achieve impressive zero-
or few-shot performance on diverse tasks. Given these properties, they are a
natural fit for active learning (AL), which aims to maximize labeling
efficiency, but the full potential of foundation models has not been explored
in the context of AL, specifically in the low-budget regime. In this work, we
evaluate how foundation models influence three critical components of effective
AL, namely, 1) initial labeled pool selection, 2) ensuring diverse sampling,
and 3) the trade-off between representative and uncertainty sampling. We
systematically study how the robust representations of foundation models
(DINOv2, OpenCLIP) challenge existing findings in active learning. Our
observations inform the principled construction of a new simple and elegant AL
strategy that balances uncertainty estimated via dropout with sample diversity.
We extensively test our strategy on many challenging image classification
benchmarks, including natural images as well as out-of-domain biomedical images
that are relatively understudied in the AL literature. Source code will be made
available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14557">Extension of Recurrent Kernels to different Reservoir Computing topologies. (arXiv:2401.14557v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+DInverno_G/0/1/0/all/0/1">Giuseppe Alessio D&#x27;Inverno</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jonathan Dong</a></p>
<p>Reservoir Computing (RC) has become popular in recent years due to its fast
and efficient computational capabilities. Standard RC has been shown to be
equivalent in the asymptotic limit to Recurrent Kernels, which helps in
analyzing its expressive power. However, many well-established RC paradigms,
such as Leaky RC, Sparse RC, and Deep RC, are yet to be analyzed in such a way.
This study aims to fill this gap by providing an empirical analysis of the
equivalence of specific RC architectures with their corresponding Recurrent
Kernel formulation. We conduct a convergence study by varying the activation
function implemented in each architecture. Our study also sheds light on the
role of sparse connections in RC architectures and propose an optimal sparsity
level that depends on the reservoir size. Furthermore, our systematic analysis
shows that in Deep RC models, convergence is better achieved with successive
reservoirs of decreasing sizes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14577">PrivStream: An Algorithm for Streaming Differentially Private Data. (arXiv:2401.14577v1 [cs.DB])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1">Girish Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Strohmer_T/0/1/0/all/0/1">Thomas Strohmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Vershynin_R/0/1/0/all/0/1">Roman Vershynin</a></p>
<p>Much of the research in differential privacy has focused on offline
applications with the assumption that all data is available at once. When these
algorithms are applied in practice to streams where data is collected over
time, this either violates the privacy guarantees or results in poor utility.
We derive an algorithm for differentially private synthetic streaming data
generation, especially curated towards spatial datasets. Furthermore, we
provide a general framework for online selective counting among a collection of
queries which forms a basis for many tasks such as query answering and
synthetic data generation. The utility of our algorithm is verified on both
real-world and simulated datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14578">GOAt: Explaining Graph Neural Networks via Graph Output Attribution. (arXiv:2401.14578v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shengyao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1">Keith G. Mills</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jiao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1">Di Niu</a></p>
<p>Understanding the decision-making process of Graph Neural Networks (GNNs) is
crucial to their interpretability. Most existing methods for explaining GNNs
typically rely on training auxiliary models, resulting in the explanations
remain black-boxed. This paper introduces Graph Output Attribution (GOAt), a
novel method to attribute graph outputs to input graph features, creating GNN
explanations that are faithful, discriminative, as well as stable across
similar samples. By expanding the GNN as a sum of scalar products involving
node features, edge features and activation patterns, we propose an efficient
analytical method to compute contribution of each node or edge feature to each
scalar product and aggregate the contributions from all scalar products in the
expansion form to derive the importance of each node and edge. Through
extensive experiments on synthetic and real-world data, we show that our method
not only outperforms various state-ofthe-art GNN explainers in terms of the
commonly used fidelity metric, but also exhibits stronger discriminability, and
stability by a remarkable margin.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14580">Design Your Own Universe: A Physics-Informed Agnostic Method for Enhancing Graph Neural Networks. (arXiv:2401.14580v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1">Dai Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_A/0/1/0/all/0/1">Andi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Lequan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiyong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Junbin Gao</a></p>
<p>Physics-informed Graph Neural Networks have achieved remarkable performance
in learning through graph-structured data by mitigating common GNN challenges
such as over-smoothing, over-squashing, and heterophily adaption. Despite these
advancements, the development of a simple yet effective paradigm that
appropriately integrates previous methods for handling all these challenges is
still underway. In this paper, we draw an analogy between the propagation of
GNNs and particle systems in physics, proposing a model-agnostic enhancement
framework. This framework enriches the graph structure by introducing
additional nodes and rewiring connections with both positive and negative
weights, guided by node labeling information. We theoretically verify that GNNs
enhanced through our approach can effectively circumvent the over-smoothing
issue and exhibit robustness against over-squashing. Moreover, we conduct a
spectral analysis on the rewired graph to demonstrate that the corresponding
GNNs can fit both homophilic and heterophilic graphs. Empirical validations on
benchmarks for homophilic, heterophilic graphs, and long-term graph datasets
show that GNNs enhanced by our method significantly outperform their original
counterparts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14585">Diffusion Stochastic Optimization for Min-Max Problems. (arXiv:2401.14585v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Haoyuan Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Alghunaim_S/0/1/0/all/0/1">Sulaiman A. Alghunaim</a>, <a href="http://arxiv.org/find/cs/1/au:+Sayed_A/0/1/0/all/0/1">Ali H. Sayed</a></p>
<p>The optimistic gradient method is useful in addressing minimax optimization
problems. Motivated by the observation that the conventional stochastic version
suffers from the need for a large batch size on the order of
$\mathcal{O}(\varepsilon^{-2})$ to achieve an $\varepsilon$-stationary
solution, we introduce and analyze a new formulation termed Diffusion
Stochastic Same-Sample Optimistic Gradient (DSS-OG). We prove its convergence
and resolve the large batch issue by establishing a tighter upper bound, under
the more general setting of nonconvex Polyak-Lojasiewicz (PL) risk functions.
We also extend the applicability of the proposed method to the distributed
scenario, where agents communicate with their neighbors via a left-stochastic
protocol. To implement DSS-OG, we can query the stochastic gradient oracles in
parallel with some extra memory overhead, resulting in a complexity comparable
to its conventional counterpart. To demonstrate the efficacy of the proposed
algorithm, we conduct tests by training generative adversarial networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14591">Ricci flow-guided autoencoders in learning time-dependent dynamics. (arXiv:2401.14591v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gracyk_A/0/1/0/all/0/1">Andrew Gracyk</a></p>
<p>We present a manifold-based autoencoder method for learning nonlinear
dynamics in time, notably partial differential equations (PDEs), in which the
manifold latent space evolves according to Ricci flow. This can be accomplished
by simulating Ricci flow in a physics-informed setting, and manifold quantities
can be matched so that Ricci flow is empirically achieved. With our
methodology, the manifold is learned as part of the training procedure, so
ideal geometries may be discerned, while the evolution simultaneously induces a
more accommodating latent representation over static methods. We present our
method on a range of numerical experiments consisting of PDEs that encompass
desirable characteristics such as periodicity and randomness, remarking error
on in-distribution and extrapolation scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14609">Physically Informed Synchronic-adaptive Learning for Industrial Systems Modeling in Heterogeneous Media with Unavailable Time-varying Interface. (arXiv:2401.14609v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Aina Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_P/0/1/0/all/0/1">Pan Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xi-Ming Sun</a></p>
<p>Partial differential equations (PDEs) are commonly employed to model complex
industrial systems characterized by multivariable dependence. Existing
physics-informed neural networks (PINNs) excel in solving PDEs in a homogeneous
medium. However, their feasibility is diminished when PDE parameters are
unknown due to a lack of physical attributions and time-varying interface is
unavailable arising from heterogeneous media. To this end, we propose a
data-physics-hybrid method, physically informed synchronic-adaptive learning
(PISAL), to solve PDEs for industrial systems modeling in heterogeneous media.
First, Net1, Net2, and NetI, are constructed to approximate the solutions
satisfying PDEs and the interface. Net1 and Net2 are utilized to synchronously
learn each solution satisfying PDEs with diverse parameters, while NetI is
employed to adaptively learn the unavailable time-varying interface. Then, a
criterion combined with NetI is introduced to adaptively distinguish the
attributions of measurements and collocation points. Furthermore, NetI is
integrated into a data-physics-hybrid loss function. Accordingly, a
synchronic-adaptive learning (SAL) strategy is proposed to decompose and
optimize each subdomain. Besides, we theoretically prove the approximation
capability of PISAL. Extensive experimental results verify that the proposed
PISAL can be used for industrial systems modeling in heterogeneous media, which
faces the challenges of lack of physical attributions and unavailable
time-varying interface.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14619">Resilient Practical Test-Time Adaptation: Soft Batch Normalization Alignment and Entropy-driven Memory Bank. (arXiv:2401.14619v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xingzhi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhiliang Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheung_K/0/1/0/all/0/1">Ka Chun Cheung</a>, <a href="http://arxiv.org/find/cs/1/au:+See_S/0/1/0/all/0/1">Simon See</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Nevin L. Zhang</a></p>
<p>Test-time domain adaptation effectively adjusts the source domain model to
accommodate unseen domain shifts in a target domain during inference. However,
the model performance can be significantly impaired by continuous distribution
changes in the target domain and non-independent and identically distributed
(non-i.i.d.) test samples often encountered in practical scenarios. While
existing memory bank methodologies use memory to store samples and mitigate
non-i.i.d. effects, they do not inherently prevent potential model degradation.
To address this issue, we propose a resilient practical test-time adaptation
(ResiTTA) method focused on parameter resilience and data quality.
Specifically, we develop a resilient batch normalization with estimation on
normalization statistics and soft alignments to mitigate overfitting and model
degradation. We use an entropy-driven memory bank that accounts for timeliness,
the persistence of over-confident samples, and sample uncertainty for
high-quality data in adaptation. Our framework periodically adapts the source
domain model using a teacher-student model through a self-training loss on the
memory samples, incorporating soft alignment losses on batch normalization. We
empirically validate ResiTTA across various benchmark datasets, demonstrating
state-of-the-art performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14628">Inferring Data Preconditions from Deep Learning Models for Trustworthy Prediction in Deployment. (arXiv:2401.14628v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1">Shibbir Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Hongyang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajan_H/0/1/0/all/0/1">Hridesh Rajan</a></p>
<p>Deep learning models are trained with certain assumptions about the data
during the development stage and then used for prediction in the deployment
stage. It is important to reason about the trustworthiness of the model's
predictions with unseen data during deployment. Existing methods for specifying
and verifying traditional software are insufficient for this task, as they
cannot handle the complexity of DNN model architecture and expected outcomes.
In this work, we propose a novel technique that uses rules derived from neural
network computations to infer data preconditions for a DNN model to determine
the trustworthiness of its predictions. Our approach, DeepInfer involves
introducing a novel abstraction for a trained DNN model that enables weakest
precondition reasoning using Dijkstra's Predicate Transformer Semantics. By
deriving rules over the inductive type of neural network abstract
representation, we can overcome the matrix dimensionality issues that arise
from the backward non-linear computation from the output layer to the input
layer. We utilize the weakest precondition computation using rules of each kind
of activation function to compute layer-wise precondition from the given
postcondition on the final output of a deep neural network. We extensively
evaluated DeepInfer on 29 real-world DNN models using four different datasets
collected from five different sources and demonstrated the utility,
effectiveness, and performance improvement over closely related work. DeepInfer
efficiently detects correct and incorrect predictions of high-accuracy models
with high recall (0.98) and high F-1 score (0.84) and has significantly
improved over prior technique, SelfChecker. The average runtime overhead of
DeepInfer is low, 0.22 sec for all unseen datasets. We also compared runtime
overhead using the same hardware settings and found that DeepInfer is 3.27
times faster than SelfChecker.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14645">Omnipredictors for Regression and the Approximate Rank of Convex Functions. (arXiv:2401.14645v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gopalan_P/0/1/0/all/0/1">Parikshit Gopalan</a>, <a href="http://arxiv.org/find/cs/1/au:+Okoroafor_P/0/1/0/all/0/1">Princewill Okoroafor</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghavendra_P/0/1/0/all/0/1">Prasad Raghavendra</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_A/0/1/0/all/0/1">Abhishek Shetty</a>, <a href="http://arxiv.org/find/cs/1/au:+Singhal_M/0/1/0/all/0/1">Mihir Singhal</a></p>
<p>Consider the supervised learning setting where the goal is to learn to
predict labels $\mathbf y$ given points $\mathbf x$ from a distribution. An
\textit{omnipredictor} for a class $\mathcal L$ of loss functions and a class
$\mathcal C$ of hypotheses is a predictor whose predictions incur less expected
loss than the best hypothesis in $\mathcal C$ for every loss in $\mathcal L$.
Since the work of [GKR+21] that introduced the notion, there has been a large
body of work in the setting of binary labels where $\mathbf y \in \{0, 1\}$,
but much less is known about the regression setting where $\mathbf y \in [0,1]$
can be continuous. Our main conceptual contribution is the notion of
\textit{sufficient statistics} for loss minimization over a family of loss
functions: these are a set of statistics about a distribution such that knowing
them allows one to take actions that minimize the expected loss for any loss in
the family. The notion of sufficient statistics relates directly to the
approximate rank of the family of loss functions.
</p>
<p>Our key technical contribution is a bound of $O(1/\varepsilon^{2/3})$ on the
$\epsilon$-approximate rank of convex, Lipschitz functions on the interval
$[0,1]$, which we show is tight up to a factor of $\mathrm{polylog}
(1/\epsilon)$. This yields improved runtimes for learning omnipredictors for
the class of all convex, Lipschitz loss functions under weak learnability
assumptions about the class $\mathcal C$. We also give efficient omnipredictors
when the loss families have low-degree polynomial approximations, or arise from
generalized linear models (GLMs). This translation from sufficient statistics
to faster omnipredictors is made possible by lifting the technique of loss
outcome indistinguishability introduced by [GKH+23] for Boolean labels to the
regression setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14654">A Korean Legal Judgment Prediction Dataset for Insurance Disputes. (arXiv:2401.14654v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kwak_A/0/1/0/all/0/1">Alice Saebom Kwak</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_C/0/1/0/all/0/1">Cheonkam Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1">Ji Weon Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_B/0/1/0/all/0/1">Byeongcheol Min</a></p>
<p>This paper introduces a Korean legal judgment prediction (LJP) dataset for
insurance disputes. Successful LJP models on insurance disputes can benefit
insurance companies and their customers. It can save both sides' time and money
by allowing them to predict how the result would come out if they proceed to
the dispute mediation process. As is often the case with low-resource
languages, there is a limitation on the amount of data available for this
specific task. To mitigate this issue, we investigate how one can achieve a
good performance despite the limitation in data. In our experiment, we
demonstrate that Sentence Transformer Fine-tuning (SetFit, Tunstall et al.,
2022) is a good alternative to standard fine-tuning when training data are
limited. The models fine-tuned with the SetFit approach on our data show
similar performance to the Korean LJP benchmark models (Hwang et al., 2022)
despite the much smaller data size.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14657">Validating Climate Models with Spherical Convolutional Wasserstein Distance. (arXiv:2401.14657v1 [physics.ao-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Garrett_R/0/1/0/all/0/1">Robert C. Garrett</a>, <a href="http://arxiv.org/find/physics/1/au:+Harris_T/0/1/0/all/0/1">Trevor Harris</a>, <a href="http://arxiv.org/find/physics/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1">Zhuo Wang</a></p>
<p>The validation of global climate models is crucial to ensure the accuracy and
efficacy of model output. We introduce the spherical convolutional Wasserstein
distance to more comprehensively measure differences between climate models and
reanalysis data. This new similarity measure accounts for spatial variability
using convolutional projections and quantifies local differences in the
distribution of climate variables. We apply this method to evaluate the
historical model outputs of the Coupled Model Intercomparison Project (CMIP)
members by comparing them to observational and reanalysis data products.
Additionally, we investigate the progression from CMIP phase 5 to phase 6 and
find modest improvements in the phase 6 models regarding their ability to
produce realistic climatologies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14661">From Blurry to Brilliant Detection: YOLOv5-Based Aerial Object Detection with Super Resolution. (arXiv:2401.14661v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nihal_R/0/1/0/all/0/1">Ragib Amin Nihal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yen_B/0/1/0/all/0/1">Benjamin Yen</a>, <a href="http://arxiv.org/find/cs/1/au:+Itoyama_K/0/1/0/all/0/1">Katsutoshi Itoyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakadai_K/0/1/0/all/0/1">Kazuhiro Nakadai</a></p>
<p>The demand for accurate object detection in aerial imagery has surged with
the widespread use of drones and satellite technology. Traditional object
detection models, trained on datasets biased towards large objects, struggle to
perform optimally in aerial scenarios where small, densely clustered objects
are prevalent. To address this challenge, we present an innovative approach
that combines super-resolution and an adapted lightweight YOLOv5 architecture.
We employ a range of datasets, including VisDrone-2023, SeaDroneSee, VEDAI, and
NWPU VHR-10, to evaluate our model's performance. Our Super Resolved YOLOv5
architecture features Transformer encoder blocks, allowing the model to capture
global context and context information, leading to improved detection results,
especially in high-density, occluded conditions. This lightweight model not
only delivers improved accuracy but also ensures efficient resource
utilization, making it well-suited for real-time applications. Our experimental
results demonstrate the model's superior performance in detecting small and
densely clustered objects, underlining the significance of dataset choice and
architectural adaptation for this specific task. In particular, the method
achieves 52.5% mAP on VisDrone, exceeding top prior works. This approach
promises to significantly advance object detection in aerial imagery,
contributing to more accurate and reliable results in a variety of real-world
applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14694">TA-RNN: an Attention-based Time-aware Recurrent Neural Network Architecture for Electronic Health Records. (arXiv:2401.14694v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Olaimat_M/0/1/0/all/0/1">Mohammad Al Olaimat</a> (1, 3), <a href="http://arxiv.org/find/cs/1/au:+Bozdag_S/0/1/0/all/0/1">Serdar Bozdag</a> (1, 2 and 3), the <a href="http://arxiv.org/find/cs/1/au:+Initiative_A/0/1/0/all/0/1">Alzheimer&#x27;s Disease Neuroimaging Initiative</a> ((1) Dept. of Computer Science and Engineering, University of North Texas, Denton, USA, (2) Dept. of Mathematics, University of North Texas, Denton, USA, (3) BioDiscovery Institute, University of North Texas, Denton, USA)</p>
<p>Motivation: Electronic Health Records (EHR) represent a comprehensive
resource of a patient's medical history. EHR are essential for utilizing
advanced technologies such as deep learning (DL), enabling healthcare providers
to analyze extensive data, extract valuable insights, and make precise and
data-driven clinical decisions. DL methods such as Recurrent Neural Networks
(RNN) have been utilized to analyze EHR to model disease progression and
predict diagnosis. However, these methods do not address some inherent
irregularities in EHR data such as irregular time intervals between clinical
visits. Furthermore, most DL models are not interpretable. In this study, we
propose two interpretable DL architectures based on RNN, namely Time-Aware RNN
(TA-RNN) and TA-RNN-Autoencoder (TA-RNN-AE) to predict patient's clinical
outcome in EHR at next visit and multiple visits ahead, respectively. To
mitigate the impact of irregular time intervals, we propose incorporating time
embedding of the elapsed times between visits. For interpretability, we propose
employing a dual-level attention mechanism that operates between visits and
features within each visit.
</p>
<p>Results: The results of the experiments conducted on Alzheimer's Disease
Neuroimaging Initiative (ADNI) and National Alzheimer's Coordinating Center
(NACC) datasets indicated superior performance of proposed models for
predicting Alzheimer's Disease (AD) compared to state-of-the-art and baseline
approaches based on F2 and sensitivity. Additionally, TA-RNN showed superior
performance on Medical Information Mart for Intensive Care (MIMIC-III) dataset
for mortality prediction. In our ablation study, we observed enhanced
predictive performance by incorporating time embedding and attention
mechanisms. Finally, investigating attention weights helped identify
influential visits and features in predictions.
</p>
<p>Availability: https://github.com/bozdaglab/TA-RNN
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14695">Continuously Evolving Graph Neural Controlled Differential Equations for Traffic Forecasting. (arXiv:2401.14695v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajia Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Ling Chen</a></p>
<p>As a crucial technique for developing a smart city, traffic forecasting has
become a popular research focus in academic and industrial communities for
decades. This task is highly challenging due to complex and dynamic
spatial-temporal dependencies in traffic networks. Existing works ignore
continuous temporal dependencies and spatial dependencies evolving over time.
In this paper, we propose Continuously Evolving Graph Neural Controlled
Differential Equations (CEGNCDE) to capture continuous temporal dependencies
and spatial dependencies over time simultaneously. Specifically, a continuously
evolving graph generator (CEGG) based on NCDE is introduced to generate the
spatial dependencies graph that continuously evolves over time from discrete
historical observations. Then, a graph neural controlled differential equations
(GNCDE) framework is introduced to capture continuous temporal dependencies and
spatial dependencies over time simultaneously. Extensive experiments
demonstrate that CEGNCDE outperforms the SOTA methods by average 2.34% relative
MAE reduction, 0.97% relative RMSE reduction, and 3.17% relative MAPE
reduction.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14696">Asymptotic Midpoint Mixup for Margin Balancing and Moderate Broadening. (arXiv:2401.14696v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hoyong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Semi Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kangil Kim</a></p>
<p>In the feature space, the collapse between features invokes critical problems
in representation learning by remaining the features undistinguished.
Interpolation-based augmentation methods such as mixup have shown their
effectiveness in relieving the collapse problem between different classes,
called inter-class collapse. However, intra-class collapse raised in
coarse-to-fine transfer learning has not been discussed in the augmentation
approach. To address them, we propose a better feature augmentation method,
asymptotic midpoint mixup. The method generates augmented features by
interpolation but gradually moves them toward the midpoint of inter-class
feature pairs. As a result, the method induces two effects: 1) balancing the
margin for all classes and 2) only moderately broadening the margin until it
holds maximal confidence. We empirically analyze the collapse effects by
measuring alignment and uniformity with visualizing representations. Then, we
validate the intra-class collapse effects in coarse-to-fine transfer learning
and the inter-class collapse effects in imbalanced learning on long-tailed
datasets. In both tasks, our method shows better performance than other
augmentation methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14702">FairSample: Training Fair and Accurate Graph Convolutional Neural Networks Efficiently. (arXiv:2401.14702v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cong_Z/0/1/0/all/0/1">Zicun Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Baoxu_S/0/1/0/all/0/1">Shi Baoxu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jaewon Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1">Qi He</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jian Pei</a></p>
<p>Fairness in Graph Convolutional Neural Networks (GCNs) becomes a more and
more important concern as GCNs are adopted in many crucial applications.
Societal biases against sensitive groups may exist in many real world graphs.
GCNs trained on those graphs may be vulnerable to being affected by such
biases. In this paper, we adopt the well-known fairness notion of demographic
parity and tackle the challenge of training fair and accurate GCNs efficiently.
We present an in-depth analysis on how graph structure bias, node attribute
bias, and model parameters may affect the demographic parity of GCNs. Our
insights lead to FairSample, a framework that jointly mitigates the three types
of biases. We employ two intuitive strategies to rectify graph structures.
First, we inject edges across nodes that are in different sensitive groups but
similar in node features. Second, to enhance model fairness and retain model
quality, we develop a learnable neighbor sampling policy using reinforcement
learning. To address the bias in node features and model parameters, FairSample
is complemented by a regularization objective to optimize fairness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14707">Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement. (arXiv:2401.14707v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_N/0/1/0/all/0/1">Nuoyan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Dawei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Decheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xinbo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Nannan Wang</a></p>
<p>Deep neural networks are vulnerable to adversarial samples. Adversarial
fine-tuning methods aim to enhance adversarial robustness through fine-tuning
the naturally pre-trained model in an adversarial training manner. However, we
identify that some latent features of adversarial samples are confused by
adversarial perturbation and lead to an unexpectedly increasing gap between
features in the last hidden layer of natural and adversarial samples. To
address this issue, we propose a disentanglement-based approach to explicitly
model and further remove the latent features that cause the feature gap.
Specifically, we introduce a feature disentangler to separate out the latent
features from the features of the adversarial samples, thereby boosting
robustness by eliminating the latent features. Besides, we align features in
the pre-trained model with features of adversarial samples in the fine-tuned
model, to further benefit from the features from natural samples without
confusion. Empirical evaluations on three benchmark datasets demonstrate that
our approach surpasses existing adversarial fine-tuning methods and adversarial
training baselines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14717">Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion. (arXiv:2401.14717v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jinhan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Long Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Khare_A/0/1/0/all/0/1">Aparna Khare</a>, <a href="http://arxiv.org/find/cs/1/au:+Raju_A/0/1/0/all/0/1">Anirudh Raju</a>, <a href="http://arxiv.org/find/cs/1/au:+Dheram_P/0/1/0/all/0/1">Pranav Dheram</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Di He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Minhua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1">Andreas Stolcke</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_V/0/1/0/all/0/1">Venkatesh Ravichandran</a></p>
<p>We propose an approach for continuous prediction of turn-taking and
backchanneling locations in spoken dialogue by fusing a neural acoustic model
with a large language model (LLM). Experiments on the Switchboard human-human
conversation dataset demonstrate that our approach consistently outperforms the
baseline models with single modality. We also develop a novel multi-task
instruction fine-tuning strategy to further benefit from LLM-encoded knowledge
for understanding the tasks and conversational contexts, leading to additional
improvements. Our approach demonstrates the potential of combined LLMs and
acoustic models for a more natural and conversational interaction between
humans and speech-enabled AI agents.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14722">A Nonparametric Bayes Approach to Online Activity Prediction. (arXiv:2401.14722v1 [stat.ME])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Beraha_M/0/1/0/all/0/1">Mario Beraha</a>, <a href="http://arxiv.org/find/stat/1/au:+Masoero_L/0/1/0/all/0/1">Lorenzo Masoero</a>, <a href="http://arxiv.org/find/stat/1/au:+Favaro_S/0/1/0/all/0/1">Stefano Favaro</a>, <a href="http://arxiv.org/find/stat/1/au:+Richardson_T/0/1/0/all/0/1">Thomas S. Richardson</a></p>
<p>Accurately predicting the onset of specific activities within defined
timeframes holds significant importance in several applied contexts. In
particular, accurate prediction of the number of future users that will be
exposed to an intervention is an important piece of information for
experimenters running online experiments (A/B tests). In this work, we propose
a novel approach to predict the number of users that will be active in a given
time period, as well as the temporal trajectory needed to attain a desired user
participation threshold. We model user activity using a Bayesian nonparametric
approach which allows us to capture the underlying heterogeneity in user
engagement. We derive closed-form expressions for the number of new users
expected in a given period, and a simple Monte Carlo algorithm targeting the
posterior distribution of the number of days needed to attain a desired number
of users; the latter is important for experimental planning. We illustrate the
performance of our approach via several experiments on synthetic and real world
data, in which we show that our novel method outperforms existing competitors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14732">Residual Quantization with Implicit Neural Codebooks. (arXiv:2401.14732v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huijben_I/0/1/0/all/0/1">Iris Huijben</a>, <a href="http://arxiv.org/find/cs/1/au:+Douze_M/0/1/0/all/0/1">Matthijs Douze</a>, <a href="http://arxiv.org/find/cs/1/au:+Muckley_M/0/1/0/all/0/1">Matthew Muckley</a>, <a href="http://arxiv.org/find/cs/1/au:+Sloun_R/0/1/0/all/0/1">Ruud van Sloun</a>, <a href="http://arxiv.org/find/cs/1/au:+Verbeek_J/0/1/0/all/0/1">Jakob Verbeek</a></p>
<p>Vector quantization is a fundamental operation for data compression and
vector search. To obtain high accuracy, multi-codebook methods increase the
rate by representing each vector using codewords across multiple codebooks.
Residual quantization (RQ) is one such method, which increases accuracy by
iteratively quantizing the error of the previous step. The error distribution
is dependent on previously selected codewords. This dependency is, however, not
accounted for in conventional RQ as it uses a generic codebook per quantization
step. In this paper, we propose QINCo, a neural RQ variant which predicts
specialized codebooks per vector using a neural network that is conditioned on
the approximation of the vector from previous steps. Experiments show that
QINCo outperforms state-of-the-art methods by a large margin on several
datasets and code sizes. For example, QINCo achieves better nearest-neighbor
search accuracy using 12 bytes codes than other methods using 16 bytes on the
BigANN and Deep1B dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14749">Topology-Aware Exploration of Energy-Based Models Equilibrium: Toric QC-LDPC Codes and Hyperbolic MET QC-LDPC Codes. (arXiv:2401.14749v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Usatyuk_V/0/1/0/all/0/1">Vasiliy Usatyuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Sapozhnikov_D/0/1/0/all/0/1">Denis Sapozhnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Egorov_S/0/1/0/all/0/1">Sergey Egorov</a></p>
<p>This paper presents a method for achieving equilibrium in the ISING
Hamiltonian when confronted with unevenly distributed charges on an irregular
grid. Employing (Multi-Edge) QC-LDPC codes and the Boltzmann machine, our
approach involves dimensionally expanding the system, substituting charges with
circulants, and representing distances through circulant shifts. This results
in a systematic mapping of the charge system onto a space, transforming the
irregular grid into a uniform configuration, applicable to Torical and Circular
Hyperboloid Topologies. The paper covers fundamental definitions and notations
related to QC-LDPC Codes, Multi-Edge QC-LDPC codes, and the Boltzmann machine.
It explores the marginalization problem in code on the graph probabilistic
models for evaluating the partition function, encompassing exact and
approximate estimation techniques. Rigorous proof is provided for the
attainability of equilibrium states for the Boltzmann machine under Torical and
Circular Hyperboloid, paving the way for the application of our methodology.
Practical applications of our approach are investigated in Finite Geometry
QC-LDPC Codes, specifically in Material Science. The paper further explores its
effectiveness in the realm of Natural Language Processing Transformer Deep
Neural Networks, examining Generalized Repeat Accumulate Codes,
Spatially-Coupled and Cage-Graph QC-LDPC Codes. The versatile and impactful
nature of our topology-aware hardware-efficient quasi-cycle codes equilibrium
method is showcased across diverse scientific domains without the use of
specific section delineations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14758">Off-Policy Primal-Dual Safe Reinforcement Learning. (arXiv:2401.14758v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zifan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1">Bo Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1">Qian Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Chao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1">Shangqin Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1">Qianlong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xingxing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a></p>
<p>Primal-dual safe RL methods commonly perform iterations between the primal
update of the policy and the dual update of the Lagrange Multiplier. Such a
training paradigm is highly susceptible to the error in cumulative cost
estimation since this estimation serves as the key bond connecting the primal
and dual update processes. We show that this problem causes significant
underestimation of cost when using off-policy methods, leading to the failure
to satisfy the safety constraint. To address this issue, we propose
\textit{conservative policy optimization}, which learns a policy in a
constraint-satisfying area by considering the uncertainty in cost estimation.
This improves constraint satisfaction but also potentially hinders reward
maximization. We then introduce \textit{local policy convexification} to help
eliminate such suboptimality by gradually reducing the estimation uncertainty.
We provide theoretical interpretations of the joint coupling effect of these
two ingredients and further verify them by extensive experiments. Results on
benchmark tasks show that our method not only achieves an asymptotic
performance comparable to state-of-the-art on-policy methods while using much
fewer samples, but also significantly reduces constraint violation during
training. Our code is available at https://github.com/ZifanWu/CAL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14792">Deep Variational Privacy Funnel: General Modeling with Applications in Face Recognition. (arXiv:2401.14792v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Razeghi_B/0/1/0/all/0/1">Behrooz Razeghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahimi_P/0/1/0/all/0/1">Parsa Rahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcel_S/0/1/0/all/0/1">S&#xe9;bastien Marcel</a></p>
<p>In this study, we harness the information-theoretic Privacy Funnel (PF) model
to develop a method for privacy-preserving representation learning using an
end-to-end training framework. We rigorously address the trade-off between
obfuscation and utility. Both are quantified through the logarithmic loss, a
measure also recognized as self-information loss. This exploration deepens the
interplay between information-theoretic privacy and representation learning,
offering substantive insights into data protection mechanisms for both
discriminative and generative models. Importantly, we apply our model to
state-of-the-art face recognition systems. The model demonstrates adaptability
across diverse inputs, from raw facial images to both derived or refined
embeddings, and is competent in tasks such as classification, reconstruction,
and generation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14810">Cyclic Group Projection for Enumerating Quasi-Cyclic Codes Trapping Sets. (arXiv:2401.14810v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Usatyuk_V/0/1/0/all/0/1">Vasiliy Usatyuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuznetsov_Y/0/1/0/all/0/1">Yury Kuznetsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Egorov_S/0/1/0/all/0/1">Sergey Egorov</a></p>
<p>This paper introduces a novel approach to enumerate and assess Trapping sets
in quasi-cyclic codes, those with circulant sizes that are non-prime numbers.
Leveraging the quasi-cyclic properties, the method employs a tabular technique
to streamline the importance sampling step for estimating the pseudo-codeword
weight of Trapping sets. The presented methodology draws on the mathematical
framework established in the provided theorem, which elucidates the behavior of
projection and lifting transformations on pseudo-codewords
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14811">On the Limitations of Markovian Rewards to Express Multi-Objective, Risk-Sensitive, and Modal Tasks. (arXiv:2401.14811v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Skalse_J/0/1/0/all/0/1">Joar Skalse</a>, <a href="http://arxiv.org/find/cs/1/au:+Abate_A/0/1/0/all/0/1">Alessandro Abate</a></p>
<p>In this paper, we study the expressivity of scalar, Markovian reward
functions in Reinforcement Learning (RL), and identify several limitations to
what they can express. Specifically, we look at three classes of RL tasks;
multi-objective RL, risk-sensitive RL, and modal RL. For each class, we derive
necessary and sufficient conditions that describe when a problem in this class
can be expressed using a scalar, Markovian reward. Moreover, we find that
scalar, Markovian rewards are unable to express most of the instances in each
of these three classes. We thereby contribute to a more complete understanding
of what standard reward functions can and cannot express. In addition to this,
we also call attention to modal problems as a new class of problems, since they
have so far not been given any systematic treatment in the RL literature. We
also briefly outline some approaches for solving some of the problems we
discuss, by means of bespoke RL algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14819">Endowing Protein Language Models with Structural Knowledge. (arXiv:2401.14819v1 [q-bio.QM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Chen_D/0/1/0/all/0/1">Dexiong Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hartout_P/0/1/0/all/0/1">Philip Hartout</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pellizzoni_P/0/1/0/all/0/1">Paolo Pellizzoni</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Oliver_C/0/1/0/all/0/1">Carlos Oliver</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Borgwardt_K/0/1/0/all/0/1">Karsten Borgwardt</a></p>
<p>Understanding the relationships between protein sequence, structure and
function is a long-standing biological challenge with manifold implications
from drug design to our understanding of evolution. Recently, protein language
models have emerged as the preferred method for this challenge, thanks to their
ability to harness large sequence databases. Yet, their reliance on expansive
sequence data and parameter sets limits their flexibility and practicality in
real-world scenarios. Concurrently, the recent surge in computationally
predicted protein structures unlocks new opportunities in protein
representation learning. While promising, the computational burden carried by
such complex data still hinders widely-adopted practical applications. To
address these limitations, we introduce a novel framework that enhances protein
language models by integrating protein structural data. Drawing from recent
advances in graph transformers, our approach refines the self-attention
mechanisms of pretrained language transformers by integrating structural
information with structure extractor modules. This refined model, termed
Protein Structure Transformer (PST), is further pretrained on a small protein
structure database, using the same masked language modeling objective as
traditional protein language models. Empirical evaluations of PST demonstrate
its superior parameter efficiency relative to protein language models, despite
being pretrained on a dataset comprising only 542K structures. Notably, PST
consistently outperforms the state-of-the-art foundation model for protein
sequences, ESM-2, setting a new benchmark in protein function prediction. Our
findings underscore the potential of integrating structural information into
protein language models, paving the way for more effective and efficient
protein modeling Code and pretrained models are available at
https://github.com/BorgwardtLab/PST.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14840">GuardML: Efficient Privacy-Preserving Machine Learning Services Through Hybrid Homomorphic Encryption. (arXiv:2401.14840v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Frimpong_E/0/1/0/all/0/1">Eugene Frimpong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Khoa Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Budzys_M/0/1/0/all/0/1">Mindaugas Budzys</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1">Tanveer Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Michalas_A/0/1/0/all/0/1">Antonis Michalas</a></p>
<p>Machine Learning (ML) has emerged as one of data science's most
transformative and influential domains. However, the widespread adoption of ML
introduces privacy-related concerns owing to the increasing number of malicious
attacks targeting ML models. To address these concerns, Privacy-Preserving
Machine Learning (PPML) methods have been introduced to safeguard the privacy
and security of ML models. One such approach is the use of Homomorphic
Encryption (HE). However, the significant drawbacks and inefficiencies of
traditional HE render it impractical for highly scalable scenarios.
Fortunately, a modern cryptographic scheme, Hybrid Homomorphic Encryption
(HHE), has recently emerged, combining the strengths of symmetric cryptography
and HE to surmount these challenges. Our work seeks to introduce HHE to ML by
designing a PPML scheme tailored for end devices. We leverage HHE as the
fundamental building block to enable secure learning of classification outcomes
over encrypted data, all while preserving the privacy of the input data and ML
model. We demonstrate the real-world applicability of our construction by
developing and evaluating an HHE-based PPML application for classifying heart
disease based on sensitive ECG data. Notably, our evaluations revealed a slight
reduction in accuracy compared to inference on plaintext data. Additionally,
both the analyst and end devices experience minimal communication and
computation costs, underscoring the practical viability of our approach. The
successful integration of HHE into PPML provides a glimpse into a more secure
and privacy-conscious future for machine learning on relatively constrained end
devices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14845">Adaptive Point Transformer. (arXiv:2401.14845v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Baiocchi_A/0/1/0/all/0/1">Alessandro Baiocchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Spinelli_I/0/1/0/all/0/1">Indro Spinelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicolosi_A/0/1/0/all/0/1">Alessandro Nicolosi</a>, <a href="http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1">Simone Scardapane</a></p>
<p>The recent surge in 3D data acquisition has spurred the development of
geometric deep learning models for point cloud processing, boosted by the
remarkable success of transformers in natural language processing. While point
cloud transformers (PTs) have achieved impressive results recently, their
quadratic scaling with respect to the point cloud size poses a significant
scalability challenge for real-world applications. To address this issue, we
propose the Adaptive Point Cloud Transformer (AdaPT), a standard PT model
augmented by an adaptive token selection mechanism. AdaPT dynamically reduces
the number of tokens during inference, enabling efficient processing of large
point clouds. Furthermore, we introduce a budget mechanism to flexibly adjust
the computational cost of the model at inference time without the need for
retraining or fine-tuning separate models. Our extensive experimental
evaluation on point cloud classification tasks demonstrates that AdaPT
significantly reduces computational complexity while maintaining competitive
accuracy compared to standard PTs. The code for AdaPT is made publicly
available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14846">Understanding Domain Generalization: A Noise Robustness Perspective. (arXiv:2401.14846v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qiao_R/0/1/0/all/0/1">Rui Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Low_B/0/1/0/all/0/1">Bryan Kian Hsiang Low</a></p>
<p>Despite the rapid development of machine learning algorithms for domain
generalization (DG), there is no clear empirical evidence that the existing DG
algorithms outperform the classic empirical risk minimization (ERM) across
standard benchmarks. To better understand this phenomenon, we investigate
whether there are benefits of DG algorithms over ERM through the lens of label
noise. Specifically, our finite-sample analysis reveals that label noise
exacerbates the effect of spurious correlations for ERM, undermining
generalization. Conversely, we illustrate that DG algorithms exhibit implicit
label-noise robustness during finite-sample training even when spurious
correlation is present. Such desirable property helps mitigate spurious
correlations and improve generalization in synthetic experiments. However,
additional comprehensive experiments on real-world benchmark datasets indicate
that label-noise robustness does not necessarily translate to better
performance compared to ERM. We conjecture that the failure mode of ERM arising
from spurious correlations may be less pronounced in practice.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14847">Extracting Process-Aware Decision Models from Object-Centric Process Data. (arXiv:2401.14847v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Goossens_A/0/1/0/all/0/1">Alexandre Goossens</a>, <a href="http://arxiv.org/find/cs/1/au:+Smedt_J/0/1/0/all/0/1">Johannes De Smedt</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanthienen_J/0/1/0/all/0/1">Jan Vanthienen</a></p>
<p>Organizations execute decisions within business processes on a daily basis
whilst having to take into account multiple stakeholders who might require
multiple point of views of the same process. Moreover, the complexity of the
information systems running these business processes is generally high as they
are linked to databases storing all the relevant data and aspects of the
processes. Given the presence of multiple objects within an information system
which support the processes in their enactment, decisions are naturally
influenced by both these perspectives, logged in object-centric process logs.
However, the discovery of such decisions from object-centric process logs is
not straightforward as it requires to correctly link the involved objects
whilst considering the sequential constraints that business processes impose as
well as correctly discovering what a decision actually does. This paper
proposes the first object-centric decision-mining algorithm called Integrated
Object-centric Decision Discovery Algorithm (IODDA). IODDA is able to discover
how a decision is structured as well as how a decision is made. Moreover, IODDA
is able to discover which activities and object types are involved in the
decision-making process. Next, IODDA is demonstrated with the first artificial
knowledge-intensive process logs whose log generators are provided to the
research community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14876">Cross-Space Adaptive Filter: Integrating Graph Topology and Node Attributes for Alleviating the Over-smoothing Problem. (arXiv:2401.14876v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1">Wenqiang Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1">Jiancheng Lv</a></p>
<p>The vanilla Graph Convolutional Network (GCN) uses a low-pass filter to
extract low-frequency signals from graph topology, which may lead to the
over-smoothing problem when GCN goes deep. To this end, various methods have
been proposed to create an adaptive filter by incorporating an extra filter
(e.g., a high-pass filter) extracted from the graph topology. However, these
methods heavily rely on topological information and ignore the node attribute
space, which severely sacrifices the expressive power of the deep GCNs,
especially when dealing with disassortative graphs. In this paper, we propose a
cross-space adaptive filter, called CSF, to produce the adaptive-frequency
information extracted from both the topology and attribute spaces.
Specifically, we first derive a tailored attribute-based high-pass filter that
can be interpreted theoretically as a minimizer for semi-supervised kernel
ridge regression. Then, we cast the topology-based low-pass filter as a
Mercer's kernel within the context of GCNs. This serves as a foundation for
combining it with the attribute-based filter to capture the adaptive-frequency
information. Finally, we derive the cross-space filter via an effective
multiple-kernel learning strategy, which unifies the attribute-based high-pass
filter and the topology-based low-pass filter. This helps to address the
over-smoothing problem while maintaining effectiveness. Extensive experiments
demonstrate that CSF not only successfully alleviates the over-smoothing
problem but also promotes the effectiveness of the node classification task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14884">P3LS: Partial Least Squares under Privacy Preservation. (arXiv:2401.14884v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Duy_D/0/1/0/all/0/1">Du Nguyen Duy</a>, <a href="http://arxiv.org/find/stat/1/au:+Nikzad_Langerodi_R/0/1/0/all/0/1">Ramin Nikzad-Langerodi</a></p>
<p>Modern manufacturing value chains require intelligent orchestration of
processes across company borders in order to maximize profits while fostering
social and environmental sustainability. However, the implementation of
integrated, systems-level approaches for data-informed decision-making along
value chains is currently hampered by privacy concerns associated with
cross-organizational data exchange and integration. We here propose
Privacy-Preserving Partial Least Squares (P3LS) regression, a novel federated
learning technique that enables cross-organizational data integration and
process modeling with privacy guarantees. P3LS involves a singular value
decomposition (SVD) based PLS algorithm and employs removable, random masks
generated by a trusted authority in order to protect the privacy of the data
contributed by each data holder. We demonstrate the capability of P3LS to
vertically integrate process data along a hypothetical value chain consisting
of three parties and to improve the prediction performance on several
process-related key performance indicators. Furthermore, we show the numerical
equivalence of P3LS and PLS model components on simulated data and provide a
thorough privacy analysis of the former. Moreover, we propose a mechanism for
determining the relevance of the contributed data to the problem being
addressed, thus creating a basis for quantifying the contribution of
participants.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14893">A structured regression approach for evaluating model performance across intersectional subgroups. (arXiv:2401.14893v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Herlihy_C/0/1/0/all/0/1">Christine Herlihy</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_K/0/1/0/all/0/1">Kimberly Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chouldechova_A/0/1/0/all/0/1">Alexandra Chouldechova</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudik_M/0/1/0/all/0/1">Miroslav Dudik</a></p>
<p>Disaggregated evaluation is a central task in AI fairness assessment, with
the goal to measure an AI system's performance across different subgroups
defined by combinations of demographic or other sensitive attributes. The
standard approach is to stratify the evaluation data across subgroups and
compute performance metrics separately for each group. However, even for
moderately-sized evaluation datasets, sample sizes quickly get small once
considering intersectional subgroups, which greatly limits the extent to which
intersectional groups are considered in many disaggregated evaluations. In this
work, we introduce a structured regression approach to disaggregated evaluation
that we demonstrate can yield reliable system performance estimates even for
very small subgroups. We also provide corresponding inference strategies for
constructing confidence intervals and explore how goodness-of-fit testing can
yield insight into the structure of fairness-related harms experienced by
intersectional groups. We evaluate our approach on two publicly available
datasets, and several variants of semi-synthetic data. The results show that
our method is considerably more accurate than the standard approach, especially
for small subgroups, and goodness-of-fit testing helps identify the key factors
that drive differences in performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14907">Learning Local Control Barrier Functions for Safety Control of Hybrid Systems. (arXiv:2401.14907v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xiang Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mangharam_R/0/1/0/all/0/1">Rahul Mangharam</a></p>
<p>Hybrid dynamical systems are ubiquitous as practical robotic applications
often involve both continuous states and discrete switchings. Safety is a
primary concern for hybrid robotic systems. Existing safety-critical control
approaches for hybrid systems are either computationally inefficient,
detrimental to system performance, or limited to small-scale systems. To amend
these drawbacks, in this paper, we propose a learningenabled approach to
construct local Control Barrier Functions (CBFs) to guarantee the safety of a
wide class of nonlinear hybrid dynamical systems. The end result is a safe
neural CBFbased switching controller. Our approach is computationally
efficient, minimally invasive to any reference controller, and applicable to
large-scale systems. We empirically evaluate our framework and demonstrate its
efficacy and flexibility through two robotic examples including a
high-dimensional autonomous racing case, against other CBF-based approaches and
model predictive control.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14923">Reinforcement Learning Interventions on Boundedly Rational Human Agents in Frictionful Tasks. (arXiv:2401.14923v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nofshin_E/0/1/0/all/0/1">Eura Nofshin</a>, <a href="http://arxiv.org/find/cs/1/au:+Swaroop_S/0/1/0/all/0/1">Siddharth Swaroop</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Weiwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Murphy_S/0/1/0/all/0/1">Susan Murphy</a>, <a href="http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1">Finale Doshi-Velez</a></p>
<p>Many important behavior changes are frictionful; they require individuals to
expend effort over a long period with little immediate gratification. Here, an
artificial intelligence (AI) agent can provide personalized interventions to
help individuals stick to their goals. In these settings, the AI agent must
personalize rapidly (before the individual disengages) and interpretably, to
help us understand the behavioral interventions. In this paper, we introduce
Behavior Model Reinforcement Learning (BMRL), a framework in which an AI agent
intervenes on the parameters of a Markov Decision Process (MDP) belonging to a
boundedly rational human agent. Our formulation of the human decision-maker as
a planning agent allows us to attribute undesirable human policies (ones that
do not lead to the goal) to their maladapted MDP parameters, such as an
extremely low discount factor. Furthermore, we propose a class of tractable
human models that captures fundamental behaviors in frictionful tasks.
Introducing a notion of MDP equivalence specific to BMRL, we theoretically and
empirically show that AI planning with our human models can lead to helpful
policies on a wide range of more complex, ground-truth humans.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14948">Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training. (arXiv:2401.14948v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gowda_S/0/1/0/all/0/1">Shruthi Gowda</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1">Bahram Zonooz</a>, <a href="http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1">Elahe Arani</a></p>
<p>Adversarial training improves the robustness of neural networks against
adversarial attacks, albeit at the expense of the trade-off between standard
and robust generalization. To unveil the underlying factors driving this
phenomenon, we examine the layer-wise learning capabilities of neural networks
during the transition from a standard to an adversarial setting. Our empirical
findings demonstrate that selectively updating specific layers while preserving
others can substantially enhance the network's learning capacity. We therefore
propose CURE, a novel training framework that leverages a gradient prominence
criterion to perform selective conservation, updating, and revision of weights.
Importantly, CURE is designed to be dataset- and architecture-agnostic,
ensuring its applicability across various scenarios. It effectively tackles
both memorization and overfitting issues, thus enhancing the trade-off between
robustness and generalization and additionally, this training approach also
aids in mitigating "robust overfitting". Furthermore, our study provides
valuable insights into the mechanisms of selective adversarial training and
offers a promising avenue for future research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14953">Learning Universal Predictors. (arXiv:2401.14953v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Grau_Moya_J/0/1/0/all/0/1">Jordi Grau-Moya</a>, <a href="http://arxiv.org/find/cs/1/au:+Genewein_T/0/1/0/all/0/1">Tim Genewein</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1">Marcus Hutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Orseau_L/0/1/0/all/0/1">Laurent Orseau</a>, <a href="http://arxiv.org/find/cs/1/au:+Deletang_G/0/1/0/all/0/1">Gr&#xe9;goire Del&#xe9;tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Catt_E/0/1/0/all/0/1">Elliot Catt</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruoss_A/0/1/0/all/0/1">Anian Ruoss</a>, <a href="http://arxiv.org/find/cs/1/au:+Wenliang_L/0/1/0/all/0/1">Li Kevin Wenliang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattern_C/0/1/0/all/0/1">Christopher Mattern</a>, <a href="http://arxiv.org/find/cs/1/au:+Aitchison_M/0/1/0/all/0/1">Matthew Aitchison</a>, <a href="http://arxiv.org/find/cs/1/au:+Veness_J/0/1/0/all/0/1">Joel Veness</a></p>
<p>Meta-learning has emerged as a powerful approach to train neural networks to
learn new tasks quickly from limited data. Broad exposure to different tasks
leads to versatile representations enabling general problem solving. But, what
are the limits of meta-learning? In this work, we explore the potential of
amortizing the most powerful universal predictor, namely Solomonoff Induction
(SI), into neural networks via leveraging meta-learning to its limits. We use
Universal Turing Machines (UTMs) to generate training data used to expose
networks to a broad range of patterns. We provide theoretical analysis of the
UTM data generation processes and meta-training protocols. We conduct
comprehensive experiments with neural architectures (e.g. LSTMs, Transformers)
and algorithmic data generators of varying complexity and universality. Our
results suggest that UTM data is a valuable resource for meta-learning, and
that it can be used to train neural networks capable of learning universal
prediction strategies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14961">End-To-End Set-Based Training for Neural Network Verification. (arXiv:2401.14961v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Koller_L/0/1/0/all/0/1">Lukas Koller</a>, <a href="http://arxiv.org/find/cs/1/au:+Ladner_T/0/1/0/all/0/1">Tobias Ladner</a>, <a href="http://arxiv.org/find/cs/1/au:+Althoff_M/0/1/0/all/0/1">Matthias Althoff</a></p>
<p>Neural networks are vulnerable to adversarial attacks, i.e., small input
perturbations can result in substantially different outputs of a neural
network. Safety-critical environments require neural networks that are robust
against input perturbations. However, training and formally verifying robust
neural networks is challenging. We address this challenge by employing, for the
first time, a end-to-end set-based training procedure that trains robust neural
networks for formal verification. Our training procedure drastically simplifies
the subsequent formal robustness verification of the trained neural network.
While previous research has predominantly focused on augmenting neural network
training with adversarial attacks, our approach leverages set-based computing
to train neural networks with entire sets of perturbed inputs. Moreover, we
demonstrate that our set-based training procedure effectively trains robust
neural networks, which are easier to verify. In many cases, set-based trained
neural networks outperform neural networks trained with state-of-the-art
adversarial attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14973">Discovering group dynamics in synchronous time series via hierarchical recurrent switching-state models. (arXiv:2401.14973v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Wojnowicz_M/0/1/0/all/0/1">Michael Wojnowicz</a>, <a href="http://arxiv.org/find/stat/1/au:+Rath_P/0/1/0/all/0/1">Preetish Rath</a>, <a href="http://arxiv.org/find/stat/1/au:+Miller_E/0/1/0/all/0/1">Eric Miller</a>, <a href="http://arxiv.org/find/stat/1/au:+Miller_J/0/1/0/all/0/1">Jeffrey Miller</a>, <a href="http://arxiv.org/find/stat/1/au:+Hancock_C/0/1/0/all/0/1">Clifford Hancock</a>, <a href="http://arxiv.org/find/stat/1/au:+ODonovan_M/0/1/0/all/0/1">Meghan O&#x27;Donovan</a>, <a href="http://arxiv.org/find/stat/1/au:+Elkin_Frankston_S/0/1/0/all/0/1">Seth Elkin-Frankston</a>, <a href="http://arxiv.org/find/stat/1/au:+Brunye_T/0/1/0/all/0/1">Thaddeus Brunye</a>, <a href="http://arxiv.org/find/stat/1/au:+Hughes_M/0/1/0/all/0/1">Michael C. Hughes</a></p>
<p>We seek to model a collection of time series arising from multiple entities
interacting over the same time period. Recent work focused on modeling
individual time series is inadequate for our intended applications, where
collective system-level behavior influences the trajectories of individual
entities. To address such problems, we present a new hierarchical
switching-state model that can be trained in an unsupervised fashion to
simultaneously explain both system-level and individual-level dynamics. We
employ a latent system-level discrete state Markov chain that drives latent
entity-level chains which in turn govern the dynamics of each observed time
series. Feedback from the observations to the chains at both the entity and
system levels improves flexibility via context-dependent state transitions. Our
hierarchical switching recurrent dynamical models can be learned via
closed-form variational coordinate ascent updates to all latent chains that
scale linearly in the number of individual time series. This is asymptotically
no more costly than fitting separate models for each entity. Experiments on
synthetic and real datasets show that our model can produce better forecasts of
future entity behavior than existing methods. Moreover, the availability of
latent state chains at both the entity and system level enables interpretation
of group dynamics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14975">Embedding-based search in JetBrains IDEs. (arXiv:2401.14975v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abramov_E/0/1/0/all/0/1">Evgeny Abramov</a>, <a href="http://arxiv.org/find/cs/1/au:+Palchikov_N/0/1/0/all/0/1">Nikolai Palchikov</a></p>
<p>Most modern Integrated Development Environments (IDEs) and code editors have
a feature to search across available functionality and items in an open
project. In JetBrains IDEs, this feature is called Search Everywhere: it allows
users to search for files, actions, classes, symbols, settings, and anything
from VCS history from a single entry point. However, it works with the
candidates obtained by algorithms that don't account for semantics, e.g.,
synonyms, complex word permutations, part of the speech modifications, and
typos. In this work, we describe the machine learning approach we implemented
to improve the discoverability of search items. We also share the obstacles
encountered during this process and how we overcame them.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14989">Mapping-to-Parameter Nonlinear Functional Regression with Novel B-spline Free Knot Placement Algorithm. (arXiv:2401.14989v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Chengdong Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_C/0/1/0/all/0/1">Ching-Hsun Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiao-Jun Zeng</a></p>
<p>We propose a novel approach to nonlinear functional regression, called the
Mapping-to-Parameter function model, which addresses complex and nonlinear
functional regression problems in parameter space by employing any supervised
learning technique. Central to this model is the mapping of function data from
an infinite-dimensional function space to a finite-dimensional parameter space.
This is accomplished by concurrently approximating multiple functions with a
common set of B-spline basis functions by any chosen order, with their knot
distribution determined by the Iterative Local Placement Algorithm, a newly
proposed free knot placement algorithm. In contrast to the conventional
equidistant knot placement strategy that uniformly distributes knot locations
based on a predefined number of knots, our proposed algorithms determine knot
location according to the local complexity of the input or output functions.
The performance of our knot placement algorithms is shown to be robust in both
single-function approximation and multiple-function approximation contexts.
Furthermore, the effectiveness and advantage of the proposed prediction model
in handling both function-on-scalar regression and function-on-function
regression problems are demonstrated through several real data applications, in
comparison with four groups of state-of-the-art methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14992">Graph-based Active Learning for Entity Cluster Repair. (arXiv:2401.14992v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Christen_V/0/1/0/all/0/1">Victor Christen</a>, <a href="http://arxiv.org/find/cs/1/au:+Obraczka_D/0/1/0/all/0/1">Daniel Obraczka</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofer_M/0/1/0/all/0/1">Marvin Hofer</a>, <a href="http://arxiv.org/find/cs/1/au:+Franke_M/0/1/0/all/0/1">Martin Franke</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahm_E/0/1/0/all/0/1">Erhard Rahm</a></p>
<p>Cluster repair methods aim to determine errors in clusters and modify them so
that each cluster consists of records representing the same entity. Current
cluster repair methodologies primarily assume duplicate-free data sources,
where each record from one source corresponds to a unique record from another.
However, real-world data often deviates from this assumption due to quality
issues. Recent approaches apply clustering methods in combination with link
categorization methods so they can be applied to data sources with duplicates.
Nevertheless, the results do not show a clear picture since the quality highly
varies depending on the configuration and dataset. In this study, we introduce
a novel approach for cluster repair that utilizes graph metrics derived from
the underlying similarity graphs. These metrics are pivotal in constructing a
classification model to distinguish between correct and incorrect edges. To
address the challenge of limited training data, we integrate an active learning
mechanism tailored to cluster-specific attributes. The evaluation shows that
the method outperforms existing cluster repair methods without distinguishing
between duplicate-free or dirty data sources. Notably, our modified active
learning strategy exhibits enhanced performance when dealing with datasets
containing duplicates, showcasing its effectiveness in such scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.15018">Enhancement of a Text-Independent Speaker Verification System by using Feature Combination and Parallel-Structure Classifiers. (arXiv:2401.15018v1 [eess.AS])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Abdalmalak_K/0/1/0/all/0/1">Kerlos Atia Abdalmalak</a>, <a href="http://arxiv.org/find/eess/1/au:+Gallardo_Antolin_A/0/1/0/all/0/1">Ascensi&#xf3;n Gallardo-Antol&#x27;in</a></p>
<p>Speaker Verification (SV) systems involve mainly two individual stages:
feature extraction and classification. In this paper, we explore these two
modules with the aim of improving the performance of a speaker verification
system under noisy conditions. On the one hand, the choice of the most
appropriate acoustic features is a crucial factor for performing robust speaker
verification. The acoustic parameters used in the proposed system are: Mel
Frequency Cepstral Coefficients (MFCC), their first and second derivatives
(Deltas and Delta- Deltas), Bark Frequency Cepstral Coefficients (BFCC),
Perceptual Linear Predictive (PLP), and Relative Spectral Transform -
Perceptual Linear Predictive (RASTA-PLP). In this paper, a complete comparison
of different combinations of the previous features is discussed. On the other
hand, the major weakness of a conventional Support Vector Machine (SVM)
classifier is the use of generic traditional kernel functions to compute the
distances among data points. However, the kernel function of an SVM has great
influence on its performance. In this work, we propose the combination of two
SVM-based classifiers with different kernel functions: Linear kernel and
Gaussian Radial Basis Function (RBF) kernel with a Logistic Regression (LR)
classifier. The combination is carried out by means of a parallel structure
approach, in which different voting rules to take the final decision are
considered. Results show that significant improvement in the performance of the
SV system is achieved by using the combined features with the combined
classifiers either with clean speech or in the presence of noise. Finally, to
enhance the system more in noisy environments, the inclusion of the multiband
noise removal technique as a preprocessing stage is proposed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.15022">Machine learning-based analysis of glioma tissue sections: a review. (arXiv:2401.15022v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Redlich_J/0/1/0/all/0/1">Jan-Philipp Redlich</a>, <a href="http://arxiv.org/find/eess/1/au:+Feuerhake_F/0/1/0/all/0/1">Friedrich Feuerhake</a>, <a href="http://arxiv.org/find/eess/1/au:+Weis_J/0/1/0/all/0/1">Joachim Weis</a>, <a href="http://arxiv.org/find/eess/1/au:+Schaadt_N/0/1/0/all/0/1">Nadine S. Schaadt</a>, <a href="http://arxiv.org/find/eess/1/au:+Teuber_Hanselmann_S/0/1/0/all/0/1">Sarah Teuber-Hanselmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Buck_C/0/1/0/all/0/1">Christoph Buck</a>, <a href="http://arxiv.org/find/eess/1/au:+Luttmann_S/0/1/0/all/0/1">Sabine Luttmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Eberle_A/0/1/0/all/0/1">Andrea Eberle</a>, <a href="http://arxiv.org/find/eess/1/au:+Nikolin_S/0/1/0/all/0/1">Stefan Nikolin</a>, <a href="http://arxiv.org/find/eess/1/au:+Appenzeller_A/0/1/0/all/0/1">Arno Appenzeller</a>, <a href="http://arxiv.org/find/eess/1/au:+Portmann_A/0/1/0/all/0/1">Andreas Portmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Homeyer_A/0/1/0/all/0/1">Andr&#xe9; Homeyer</a></p>
<p>In recent years, the diagnosis of gliomas has become increasingly complex.
Histological assessment of glioma tissue using modern machine learning
techniques offers new opportunities to support diagnosis and outcome
prediction. To give an overview of the current state of research, this review
examines 70 publicly available research studies on machine learning-based
analysis of stained human glioma tissue sections, covering the diagnostic tasks
of subtyping (16/70), grading (23/70), molecular marker prediction (13/70), and
survival prediction (27/70). All studies were reviewed with regard to
methodological aspects as well as clinical applicability. It was found that the
focus of current research is the assessment of hematoxylin and eosin-stained
tissue sections of adult-type diffuse gliomas. The majority of studies (49/70)
are based on the publicly available glioblastoma and low-grade glioma datasets
from The Cancer Genome Atlas (TCGA) and only a few studies employed other
datasets in isolation (10/70) or in addition to the TCGA datasets (11/70).
Current approaches mostly rely on convolutional neural networks (53/70) for
analyzing tissue at 20x magnification (30/70). A new field of research is the
integration of clinical data, omics data, or magnetic resonance imaging
(27/70). So far, machine learning-based methods have achieved promising
results, but are not yet used in real clinical settings. Future work should
focus on the independent validation of methods on larger, multi-site datasets
with high-quality and up-to-date clinical and molecular pathology annotations
to demonstrate routine applicability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.15024">SliceGPT: Compress Large Language Models by Deleting Rows and Columns. (arXiv:2401.15024v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ashkboos_S/0/1/0/all/0/1">Saleh Ashkboos</a>, <a href="http://arxiv.org/find/cs/1/au:+Croci_M/0/1/0/all/0/1">Maximilian L. Croci</a>, <a href="http://arxiv.org/find/cs/1/au:+Nascimento_M/0/1/0/all/0/1">Marcelo Gennari do Nascimento</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1">Torsten Hoefler</a>, <a href="http://arxiv.org/find/cs/1/au:+Hensman_J/0/1/0/all/0/1">James Hensman</a></p>
<p>Large language models have become the cornerstone of natural language
processing, but their use comes with substantial costs in terms of compute and
memory resources. Sparsification provides a solution to alleviate these
resource constraints, and recent works have shown that trained models can be
sparsified post-hoc. Existing sparsification techniques face challenges as they
need additional data structures and offer constrained speedup with current
hardware. In this paper we present SliceGPT, a new post-training sparsification
scheme which replaces each weight matrix with a smaller (dense) matrix,
reducing the embedding dimension of the network. Through extensive
experimentation, we show that SliceGPT can remove up to 25% of the model
parameters (including embeddings) for LLAMA2-70B, OPT 66B and Phi-2 models
while maintaining 99%, 99% and 90% zero-shot task performance of the dense
model respectively. Our sliced models run on fewer GPUs and run faster without
any additional code optimization: on 24GB consumer GPUs we reduce the total
compute for inference on LLAMA2-70B to 64% of that of the dense model; on 40GB
A100 GPUs we reduce it to 66%. We offer a new insight, computational invariance
in transformer networks, which enables SliceGPT and we hope it will inspire and
enable future avenues to reduce memory and computation demands for pre-trained
models. Code is available at:
https://github.com/microsoft/TransformerCompression
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.15030">On the generalization capacity of neural networks during generic multimodal reasoning. (arXiv:2401.15030v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1">Takuya Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1">Soham Dan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigotti_M/0/1/0/all/0/1">Mattia Rigotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozloski_J/0/1/0/all/0/1">James Kozloski</a>, <a href="http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1">Murray Campbell</a></p>
<p>The advent of the Transformer has led to the development of large language
models (LLM), which appear to demonstrate human-like capabilities. To assess
the generality of this class of models and a variety of other base neural
network architectures to multimodal domains, we evaluated and compared their
capacity for multimodal generalization. We introduce a multimodal
question-answer benchmark to evaluate three specific types of
out-of-distribution (OOD) generalization performance: distractor generalization
(generalization in the presence of distractors), systematic compositional
generalization (generalization to new task permutations), and productive
compositional generalization (generalization to more complex tasks structures).
We found that across model architectures (e.g., RNNs, Transformers, Perceivers,
etc.), models with multiple attention layers, or models that leveraged
cross-attention mechanisms between input domains, fared better. Our positive
results demonstrate that for multimodal distractor and systematic
generalization, either cross-modal attention or models with deeper attention
layers are key architectural features required to integrate multimodal inputs.
On the other hand, neither of these architectural features led to productive
generalization, suggesting fundamental limitations of existing architectures
for specific types of multimodal generalization. These results demonstrate the
strengths and limitations of specific architectural components underlying
modern neural models for multimodal reasoning. Finally, we provide Generic COG
(gCOG), a configurable benchmark with several multimodal generalization splits,
for future studies to explore.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.15043">Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning. (arXiv:2401.15043v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Md Mushfiqur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Irbaz_M/0/1/0/all/0/1">Mohammad Sabik Irbaz</a>, <a href="http://arxiv.org/find/cs/1/au:+North_K/0/1/0/all/0/1">Kai North</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_M/0/1/0/all/0/1">Michelle S. Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1">Marcos Zampieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Lybarger_K/0/1/0/all/0/1">Kevin Lybarger</a></p>
<p>Objective: The reading level of health educational materials significantly
influences information understandability and accessibility, particularly for
minoritized populations. Many patient educational resources surpass the reading
level and complexity of widely accepted standards. There is a critical need for
high-performing text simplification models in health information to enhance
dissemination and literacy. This need is particularly acute in cancer
education, where effective prevention and screening education can substantially
reduce morbidity and mortality.
</p>
<p>Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel
corpus of cancer education materials tailored for health text simplification
research. Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore
Large Language Model (LLM)-based simplification methods, including fine-tuning,
reinforcement learning (RL), reinforcement learning with human feedback (RLHF),
domain adaptation, and prompt-based approaches. Our experimentation encompasses
Llama 2 and GPT-4. A novel RLHF reward function is introduced, featuring a
lightweight model adept at distinguishing between original and simplified
texts, thereby enhancing the model's effectiveness with unlabeled data.
</p>
<p>Results: Fine-tuned Llama 2 models demonstrated high performance across
various metrics. Our innovative RLHF reward function surpassed existing RL text
simplification reward functions in effectiveness. The results underscore that
RL/RLHF can augment fine-tuning, facilitating model training on unlabeled text
and improving performance. Additionally, these methods effectively adapt
out-of-domain text simplification models to targeted domains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.15059">Fully Independent Communication in Multi-Agent Reinforcement Learning. (arXiv:2401.15059v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pina_R/0/1/0/all/0/1">Rafael Pina</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_V/0/1/0/all/0/1">Varuna De Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Artaud_C/0/1/0/all/0/1">Corentin Artaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaolan Liu</a></p>
<p>Multi-Agent Reinforcement Learning (MARL) comprises a broad area of research
within the field of multi-agent systems. Several recent works have focused
specifically on the study of communication approaches in MARL. While multiple
communication methods have been proposed, these might still be too complex and
not easily transferable to more practical contexts. One of the reasons for that
is due to the use of the famous parameter sharing trick. In this paper, we
investigate how independent learners in MARL that do not share parameters can
communicate. We demonstrate that this setting might incur into some problems,
to which we propose a new learning scheme as a solution. Our results show that,
despite the challenges, independent agents can still learn communication
strategies following our method. Additionally, we use this method to
investigate how communication in MARL is affected by different network
capacities, both for sharing and not sharing parameters. We observe that
communication may not always be needed and that the chosen agent network sizes
need to be considered when used together with communication in order to achieve
efficient learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.15062">Expert with Clustering: Hierarchical Online Preference Learning Framework. (arXiv:2401.15062v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tianyue Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jung-Hoon Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Ardabili_B/0/1/0/all/0/1">Babak Rahimi Ardabili</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabkhi_H/0/1/0/all/0/1">Hamed Tabkhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Cathy Wu</a></p>
<p>Emerging mobility systems are increasingly capable of recommending options to
mobility users, to guide them towards personalized yet sustainable system
outcomes. Even more so than the typical recommendation system, it is crucial to
minimize regret, because 1) the mobility options directly affect the lives of
the users, and 2) the system sustainability relies on sufficient user
participation. In this study, we consider accelerating user preference learning
by exploiting a low-dimensional latent space that captures the mobility
preferences of users. We introduce a hierarchical contextual bandit framework
named Expert with Clustering (EWC), which integrates clustering techniques and
prediction with expert advice. EWC efficiently utilizes hierarchical user
information and incorporates a novel Loss-guided Distance metric. This metric
is instrumental in generating more representative cluster centroids. In a
recommendation scenario with $N$ users, $T$ rounds per user, and $K$ options,
our algorithm achieves a regret bound of $O(N\sqrt{T\log K} + NT)$. This bound
consists of two parts: the first term is the regret from the Hedge algorithm,
and the second term depends on the average loss from clustering. The algorithm
performs with low regret, especially when a latent hierarchical structure
exists among users. This regret bound underscores the theoretical and
experimental efficacy of EWC, particularly in scenarios that demand rapid
learning and adaptation. Experimental results highlight that EWC can
substantially reduce regret by 27.57% compared to the LinUCB baseline. Our work
offers a data-efficient approach to capturing both individual and collective
behaviors, making it highly applicable to contexts with hierarchical
structures. We expect the algorithm to be applicable to other settings with
layered nuances of user preferences and information.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.15077">EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty. (arXiv:2401.15077v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Fangyun Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongyang Zhang</a></p>
<p>Auto-regressive decoding makes the inference of Large Language Models (LLMs)
time-consuming. We propose a simple framework, EAGLE (Extrapolation Algorithm
for Greater Language-model Efficiency), for lossless acceleration. Unlike
traditional speculative sampling methods, EAGLE operates the drafting process
auto-regressively at the more regular (second-top-layer) feature level and
addresses the sampling uncertainty issues in the next-feature prediction
problems by integrating tokens from one time step ahead. The acceleration
provided by EAGLE is lossless: it involves no fine-tuning of the target LLM,
and the generated text maintains the same distribution as that of vanilla
auto-regressive decoding. As of the submission of this paper, EAGLE is the
fastest known framework within the speculative sampling family. On MT-bench,
EAGLE is 3x faster than vanilla decoding, 2x faster than Lookahead, and 1.6x
faster than Medusa. Using gpt-fast, EAGLE attains on average 160 tokens/s with
LLaMA2-Chat 13B on a single RTX 3090 GPU, compared to 24 tokens/s of
Huggingface's implementations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2103.15010">On the Stability of Nonlinear Receding Horizon Control: A Geometric Perspective. (arXiv:2103.15010v3 [math.OC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Westenbroek_T/0/1/0/all/0/1">Tyler Westenbroek</a>, <a href="http://arxiv.org/find/math/1/au:+Simchowitz_M/0/1/0/all/0/1">Max Simchowitz</a>, <a href="http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>, <a href="http://arxiv.org/find/math/1/au:+Sastry_S/0/1/0/all/0/1">S. Shankar Sastry</a></p>
<p>%!TEX root = LCSS_main_max.tex
</p>
<p>The widespread adoption of nonlinear Receding Horizon Control (RHC)
strategies by industry has led to more than 30 years of intense research
efforts to provide stability guarantees for these methods. However, current
theoretical guarantees require that each (generally nonconvex) planning problem
can be solved to (approximate) global optimality, which is an unrealistic
requirement for the derivative-based local optimization methods generally used
in practical implementations of RHC. This paper takes the first step towards
understanding stability guarantees for nonlinear RHC when the inner planning
problem is solved to first-order stationary points, but not necessarily global
optima. Special attention is given to feedback linearizable systems, and a
mixture of positive and negative results are provided. We establish that, under
certain strong conditions, first-order solutions to RHC exponentially stabilize
linearizable systems. Surprisingly, these conditions can hold even in
situations where there may be \textit{spurious local minima.} Crucially, this
guarantee requires that state costs applied to the planning problems are in a
certain sense `compatible' with the global geometry of the system, and a simple
counter-example demonstrates the necessity of this condition. These results
highlight the need to rethink the role of global geometry in the context of
optimization-based control.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2105.02487">High-dimensional Functional Graphical Model Structure Learning via Neighborhood Selection Approach. (arXiv:2105.02487v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Zhao_B/0/1/0/all/0/1">Boxin Zhao</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhai_P/0/1/0/all/0/1">Percy S. Zhai</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1">Y. Samuel Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Kolar_M/0/1/0/all/0/1">Mladen Kolar</a></p>
<p>Undirected graphical models are widely used to model the conditional
independence structure of vector-valued data. However, in many modern
applications, for example those involving EEG and fMRI data, observations are
more appropriately modeled as multivariate random functions rather than
vectors. Functional graphical models have been proposed to model the
conditional independence structure of such functional data. We propose a
neighborhood selection approach to estimate the structure of Gaussian
functional graphical models, where we first estimate the neighborhood of each
node via a function-on-function regression and subsequently recover the entire
graph structure by combining the estimated neighborhoods. Our approach only
requires assumptions on the conditional distributions of random functions, and
we estimate the conditional independence structure directly. We thus circumvent
the need for a well-defined precision operator that may not exist when the
functions are infinite dimensional. Additionally, the neighborhood selection
approach is computationally efficient and can be easily parallelized. The
statistical consistency of the proposed method in the high-dimensional setting
is supported by both theory and experimental results. In addition, we study the
effect of the choice of the function basis used for dimensionality reduction in
an intermediate step. We give a heuristic criterion for choosing a function
basis and motivate two practically useful choices, which we justify by both
theory and experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2111.08452">On minimizers and convolutional filters: theoretical connections and applications to genome analysis. (arXiv:2111.08452v6 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yun William Yu</a></p>
<p>Minimizers and convolutional neural networks (CNNs) are two quite distinct
popular techniques that have both been employed to analyze categorical
biological sequences. At face value, the methods seem entirely dissimilar.
Minimizers use min-wise hashing on a rolling window to extract a single
important k-mer feature per window. CNNs start with a wide array of randomly
initialized convolutional filters, paired with a pooling operation, and then
multiple additional neural layers to learn both the filters themselves and how
they can be used to classify the sequence.
</p>
<p>Here, our main result is a careful mathematical analysis of hash function
properties showing that for sequences over a categorical alphabet, random
Gaussian initialization of convolutional filters with max-pooling is equivalent
to choosing a minimizer ordering such that selected k-mers are (in Hamming
distance) far from the k-mers within the sequence but close to other
minimizers. In empirical experiments, we find that this property manifests as
decreased density in repetitive regions, both in simulation and on real human
telomeres. We additionally train from scratch a CNN embedding of synthetic
short-reads from the SARS-CoV-2 genome into 3D Euclidean space that locally
recapitulates the linear sequence distance of the read origins, a modest step
towards building a deep learning assembler, though it is at present too slow to
be practical. In total, this manuscript provides a partial explanation for the
effectiveness of CNNs in categorical sequence analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2112.03183">Modification-Fair Cluster Editing. (arXiv:2112.03183v2 [cs.DS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Froese_V/0/1/0/all/0/1">Vincent Froese</a>, <a href="http://arxiv.org/find/cs/1/au:+Kellerhals_L/0/1/0/all/0/1">Leon Kellerhals</a>, <a href="http://arxiv.org/find/cs/1/au:+Niedermeier_R/0/1/0/all/0/1">Rolf Niedermeier</a></p>
<p>The classic Cluster Editing problem (also known as Correlation Clustering)
asks to transform a given graph into a disjoint union of cliques (clusters) by
a small number of edge modifications. When applied to vertex-colored graphs
(the colors representing subgroups), standard algorithms for the NP-hard
Cluster Editing problem may yield solutions that are biased towards subgroups
of data (e.g., demographic groups), measured in the number of modifications
incident to the members of the subgroups. We propose a modification fairness
constraint which ensures that the number of edits incident to each subgroup is
proportional to its size. To start with, we study Modification-Fair Cluster
Editing for graphs with two vertex colors. We show that the problem is NP-hard
even if one may only insert edges within a subgroup; note that in the classic
"non-fair" setting, this case is trivially polynomial-time solvable. However,
in the more general editing form, the modification-fair variant remains
fixed-parameter tractable with respect to the number of edge edits. We
complement these and further theoretical results with an empirical analysis of
our model on real-world social networks where we find that the price of
modification-fairness is surprisingly low, that is, the cost of optimal
modification-fair solutions differs from the cost of optimal "non-fair"
solutions only by a small percentage.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.14674">Signature Methods in Machine Learning. (arXiv:2206.14674v5 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Lyons_T/0/1/0/all/0/1">Terry Lyons</a>, <a href="http://arxiv.org/find/stat/1/au:+McLeod_A/0/1/0/all/0/1">Andrew D. McLeod</a></p>
<p>Signature-based techniques give mathematical insight into the interactions
between complex streams of evolving data. These insights can be quite naturally
translated into numerical approaches to understanding streamed data, and
perhaps because of their mathematical precision, have proved useful in
analysing streamed data in situations where the data is irregular, and not
stationary, and the dimension of the data and the sample sizes are both
moderate. Understanding streamed multi-modal data is exponential: a word in $n$
letters from an alphabet of size $d$ can be any one of $d^n$ messages.
Signatures remove the exponential amount of noise that arises from sampling
irregularity, but an exponential amount of information still remain. This
survey aims to stay in the domain where that exponential scaling can be managed
directly. Scalability issues are an important challenge in many problems but
would require another survey article and further ideas. This survey describes a
range of contexts where the data sets are small enough to remove the
possibility of massive machine learning, and the existence of small sets of
context free and principled features can be used effectively. The mathematical
nature of the tools can make their use intimidating to non-mathematicians. The
examples presented in this article are intended to bridge this communication
gap and provide tractable working examples drawn from the machine learning
context. Notebooks are available online for several of these examples. This
survey builds on the earlier paper of Ilya Chevryev and Andrey Kormilitzin
which had broadly similar aims at an earlier point in the development of this
machinery. This article illustrates how the theoretical insights offered by
signatures are simply realised in the analysis of application data in a way
that is largely agnostic to the data type.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.09921">Finite-time analysis of single-timescale actor-critic. (arXiv:2210.09921v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuyang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Lin Zhao</a></p>
<p>Actor-critic methods have achieved significant success in many challenging
applications. However, its finite-time convergence is still poorly understood
in the most practical single-timescale form. Existing works on analyzing
single-timescale actor-critic have been limited to i.i.d. sampling or tabular
setting for simplicity. We investigate the more practical online
single-timescale actor-critic algorithm on continuous state space, where the
critic assumes linear function approximation and updates with a single
Markovian sample per actor step. Previous analysis has been unable to establish
the convergence for such a challenging scenario. We demonstrate that the online
single-timescale actor-critic method provably finds an $\epsilon$-approximate
stationary point with $\widetilde{\mathcal{O}}(\epsilon^{-2})$ sample
complexity under standard assumptions, which can be further improved to
$\mathcal{O}(\epsilon^{-2})$ under the i.i.d. sampling. Our novel framework
systematically evaluates and controls the error propagation between the actor
and critic. It offers a promising approach for analyzing other single-timescale
reinforcement learning algorithms as well.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.16380">Incorporating Crowdsourced Annotator Distributions into Ensemble Modeling to Improve Classification Trustworthiness for Ancient Greek Papyri. (arXiv:2210.16380v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+West_G/0/1/0/all/0/1">Graham West</a>, <a href="http://arxiv.org/find/cs/1/au:+Swindall_M/0/1/0/all/0/1">Matthew I. Swindall</a>, <a href="http://arxiv.org/find/cs/1/au:+Keener_B/0/1/0/all/0/1">Ben Keener</a>, <a href="http://arxiv.org/find/cs/1/au:+Player_T/0/1/0/all/0/1">Timothy Player</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1">Alex C. Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Brusuelas_J/0/1/0/all/0/1">James H. Brusuelas</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallin_J/0/1/0/all/0/1">John F. Wallin</a></p>
<p>Performing classification on noisy, crowdsourced image datasets can prove
challenging even for the best neural networks. Two issues which complicate the
problem on such datasets are class imbalance and ground-truth uncertainty in
labeling. The AL-ALL and AL-PUB datasets - consisting of tightly cropped,
individual characters from images of ancient Greek papyri - are strongly
affected by both issues. The application of ensemble modeling to such datasets
can help identify images where the ground-truth is questionable and quantify
the trustworthiness of those samples. As such, we apply stacked generalization
consisting of nearly identical ResNets with different loss functions: one
utilizing sparse cross-entropy (CXE) and the other Kullback-Liebler Divergence
(KLD). Both networks use labels drawn from a crowd-sourced consensus. This
consensus is derived from a Normalized Distribution of Annotations (NDA) based
on all annotations for a given character in the dataset. For the second
network, the KLD is calculated with respect to the NDA. For our ensemble model,
we apply a k-nearest neighbors model to the outputs of the CXE and KLD
networks. Individually, the ResNet models have approximately 93% accuracy,
while the ensemble model achieves an accuracy of &gt; 95%, increasing the
classification trustworthiness. We also perform an analysis of the Shannon
entropy of the various models' output distributions to measure classification
uncertainty. Our results suggest that entropy is useful for predicting model
misclassifications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.16468">Linear-Time Algorithms for Front-Door Adjustment in Causal Graphs. (arXiv:2211.16468v4 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wienobst_M/0/1/0/all/0/1">Marcel Wien&#xf6;bst</a>, <a href="http://arxiv.org/find/cs/1/au:+Zander_B/0/1/0/all/0/1">Benito van der Zander</a>, <a href="http://arxiv.org/find/cs/1/au:+Liskiewicz_M/0/1/0/all/0/1">Maciej Li&#x15b;kiewicz</a></p>
<p>Causal effect estimation from observational data is a fundamental task in
empirical sciences. It becomes particularly challenging when unobserved
confounders are involved in a system. This paper focuses on front-door
adjustment -- a classic technique which, using observed mediators allows to
identify causal effects even in the presence of unobserved confounding. While
the statistical properties of the front-door estimation are quite well
understood, its algorithmic aspects remained unexplored for a long time. In
2022, Jeong, Tian, and Bareinboim presented the first polynomial-time algorithm
for finding sets satisfying the front-door criterion in a given directed
acyclic graph (DAG), with an $O(n^3(n+m))$ run time, where $n$ denotes the
number of variables and $m$ the number of edges of the causal graph. In our
work, we give the first linear-time, i.e., $O(n+m)$, algorithm for this task,
which thus reaches the asymptotically optimal time complexity. This result
implies an $O(n(n+m))$ delay enumeration algorithm of all front-door adjustment
sets, again improving previous work by a factor of $n^3$. Moreover, we provide
the first linear-time algorithm for finding a minimal front-door adjustment
set. We offer implementations of our algorithms in multiple programming
languages to facilitate practical usage and empirically validate their
feasibility, even for large graphs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.08560">Dual RL: Unification and New Methods for Reinforcement and Imitation Learning. (arXiv:2302.08560v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sikchi_H/0/1/0/all/0/1">Harshit Sikchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1">Qinqing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Amy Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a></p>
<p>The goal of reinforcement learning (RL) is to find a policy that maximizes
the expected cumulative return. It has been shown that this objective can be
represented as an optimization problem of state-action visitation distribution
under linear constraints. The dual problem of this formulation, which we refer
to as dual RL, is unconstrained and easier to optimize. In this work, we first
cast several state-of-the-art offline RL and offline imitation learning (IL)
algorithms as instances of dual RL approaches with shared structures. Such
unification allows us to identify the root cause of the shortcomings of prior
methods. For offline IL, our analysis shows that prior methods are based on a
restrictive coverage assumption that greatly limits their performance in
practice. To fix this limitation, we propose a new discriminator-free method
ReCOIL that learns to imitate from arbitrary off-policy data to obtain
near-expert performance. For offline RL, our analysis frames a recent offline
RL method XQL in the dual framework, and we further propose a new method f-DVL
that provides alternative choices to the Gumbel regression loss that fixes the
known training instability issue of XQL. The performance improvements by both
of our proposed methods, ReCOIL and f-DVL, in IL and RL are validated on an
extensive suite of simulated robot locomotion and manipulation tasks. Project
code and details can be found at this https://hari-sikchi.github.io/dual-rl.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.00128">Representation Disentaglement via Regularization by Causal Identification. (arXiv:2303.00128v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Castorena_J/0/1/0/all/0/1">Juan Castorena</a></p>
<p>In this work, we propose the use of a causal collider structured model to
describe the underlying data generative process assumptions in disentangled
representation learning. This extends the conventional i.i.d. factorization
assumption model $p(\mathbf{y}) = \prod_{i} p(\mathbf{y}_i )$, inadequate to
handle learning from biased datasets (e.g., with sampling selection bias). The
collider structure, explains that conditional dependencies between the
underlying generating variables may be exist, even when these are in reality
unrelated, complicating disentanglement. Under the rubric of causal inference,
we show this issue can be reconciled under the condition of causal
identification; attainable from data and a combination of constraints, aimed at
controlling the dependencies characteristic of the \textit{collider} model. For
this, we propose regularization by identification (ReI), a modular
regularization engine designed to align the behavior of large scale generative
models with the disentanglement constraints imposed by causal identification.
Empirical evidence on standard benchmarks demonstrates the superiority of ReI
in learning disentangled representations in a variational framework. In a
real-world dataset we additionally show that our framework, results in
interpretable representations robust to out-of-distribution examples and that
align with the true expected effect from domain knowledge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.03714">Generative Modeling with Flow-Guided Density Ratio Learning. (arXiv:2303.03714v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Heng_A/0/1/0/all/0/1">Alvin Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ansari_A/0/1/0/all/0/1">Abdul Fatir Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Soh_H/0/1/0/all/0/1">Harold Soh</a></p>
<p>We present Flow-Guided Density Ratio Learning (FDRL), a simple and scalable
approach to generative modeling which builds on the stale (time-independent)
approximation of the gradient flow of entropy-regularized f-divergences
introduced in DGflow. In DGflow, the intractable time-dependent density ratio
is approximated by a stale estimator given by a GAN discriminator. This is
sufficient in the case of sample refinement, where the source and target
distributions of the flow are close to each other. However, this assumption is
invalid for generation and a naive application of the stale estimator fails due
to the large chasm between the two distributions. FDRL proposes to train a
density ratio estimator such that it learns from progressively improving
samples during the training process. We show that this simple method alleviates
the density chasm problem, allowing FDRL to generate images of dimensions as
high as $128\times128$, as well as outperform existing gradient flow baselines
on quantitative benchmarks. We also show the flexibility of FDRL with two use
cases. First, unconditional FDRL can be easily composed with external
classifiers to perform class-conditional generation. Second, FDRL can be
directly applied to unpaired image-to-image translation with no modifications
needed to the framework. Code is publicly available at
https://github.com/ajrheng/FDRL.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.05752">Function Space and Critical Points of Linear Convolutional Networks. (arXiv:2304.05752v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kohn_K/0/1/0/all/0/1">Kathl&#xe9;n Kohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Montufar_G/0/1/0/all/0/1">Guido Mont&#xfa;far</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahverdi_V/0/1/0/all/0/1">Vahid Shahverdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Trager_M/0/1/0/all/0/1">Matthew Trager</a></p>
<p>We study the geometry of linear networks with one-dimensional convolutional
layers. The function spaces of these networks can be identified with
semi-algebraic families of polynomials admitting sparse factorizations. We
analyze the impact of the network's architecture on the function space's
dimension, boundary, and singular points. We also describe the critical points
of the network's parameterization map. Furthermore, we study the optimization
problem of training a network with the squared error loss. We prove that for
architectures where all strides are larger than one and generic data, the
non-zero critical points of that optimization problem are smooth interior
points of the function space. This property is known to be false for dense
linear networks and linear convolutional networks with stride one.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.06787">A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions. (arXiv:2304.06787v4 [cs.DS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singhal_V/0/1/0/all/0/1">Vikrant Singhal</a></p>
<p>We present the first $\varepsilon$-differentially private, computationally
efficient algorithm that estimates the means of product distributions over
$\{0,1\}^d$ accurately in total-variation distance, whilst attaining the
optimal sample complexity to within polylogarithmic factors. The prior work had
either solved this problem efficiently and optimally under weaker notions of
privacy, or had solved it optimally while having exponential running times.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.11043">Can Perturbations Help Reduce Investment Risks? Risk-Aware Stock Recommendation via Split Variational Adversarial Training. (arXiv:2304.11043v2 [q-fin.RM] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Cheng_J/0/1/0/all/0/1">Jiezhu Cheng</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zheng_Z/0/1/0/all/0/1">Zibin Zheng</a></p>
<p>In the stock market, a successful investment requires a good balance between
profits and risks. Based on the learning to rank paradigm, stock recommendation
has been widely studied in quantitative finance to recommend stocks with higher
return ratios for investors. Despite the efforts to make profits, many existing
recommendation approaches still have some limitations in risk control, which
may lead to intolerable paper losses in practical stock investing. To
effectively reduce risks, we draw inspiration from adversarial learning and
propose a novel Split Variational Adversarial Training (SVAT) method for
risk-aware stock recommendation. Essentially, SVAT encourages the stock model
to be sensitive to adversarial perturbations of risky stock examples and
enhances the model's risk awareness by learning from perturbations. To generate
representative adversarial examples as risk indicators, we devise a variational
perturbation generator to model diverse risk factors. Particularly, the
variational architecture enables our method to provide a rough risk
quantification for investors, showing an additional advantage of
interpretability. Experiments on several real-world stock market datasets
demonstrate the superiority of our SVAT method. By lowering the volatility of
the stock recommendation model, SVAT effectively reduces investment risks and
outperforms state-of-the-art baselines by more than 30% in terms of
risk-adjusted profits. All the experimental data and source code are available
at
https://drive.google.com/drive/folders/14AdM7WENEvIp5x5bV3zV_i4Aev21C9g6?usp=sharing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.00393">DynaVol: Unsupervised Learning for Dynamic Scenes through Object-Centric Voxelization. (arXiv:2305.00393v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yanpeng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Siyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunbo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a></p>
<p>Unsupervised learning of object-centric representations in dynamic visual
scenes is challenging. Unlike most previous approaches that learn to decompose
2D images, we present DynaVol, a 3D scene generative model that unifies
geometric structures and object-centric learning in a differentiable volume
rendering framework. The key idea is to perform object-centric voxelization to
capture the 3D nature of the scene, which infers the probability distribution
over objects at individual spatial locations. These voxel features evolve over
time through a canonical-space deformation function, forming the basis for
global representation learning via slot attention. The voxel features and
global features are complementary and are both leveraged by a compositional
NeRF decoder for volume rendering. DynaVol remarkably outperforms existing
approaches for unsupervised dynamic scene decomposition. Once trained, the
explicitly meaningful voxel features enable additional capabilities that 2D
scene decomposition methods cannot achieve: it is possible to freely edit the
geometric shapes or manipulate the motion trajectories of the objects.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.01747">Expectation Maximization Pseudo Labels. (arXiv:2305.01747v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Moucheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yukun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Chen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Groot_M/0/1/0/all/0/1">Marius de Groot</a>, <a href="http://arxiv.org/find/cs/1/au:+Alexander_D/0/1/0/all/0/1">Daniel C. Alexander</a>, <a href="http://arxiv.org/find/cs/1/au:+Oxtoby_N/0/1/0/all/0/1">Neil P. Oxtoby</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yipeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacob_J/0/1/0/all/0/1">Joseph Jacob</a></p>
<p>In this paper, we study pseudo-labelling. Pseudo-labelling employs raw
inferences on unlabelled data as pseudo-labels for self-training. We elucidate
the empirical successes of pseudo-labelling by establishing a link between this
technique and the Expectation Maximisation algorithm. Through this, we realise
that the original pseudo-labelling serves as an empirical estimation of its
more comprehensive underlying formulation. Following this insight, we present a
full generalisation of pseudo-labels under Bayes' theorem, termed Bayesian
Pseudo Labels. Subsequently, we introduce a variational approach to generate
these Bayesian Pseudo Labels, involving the learning of a threshold to
automatically select high-quality pseudo labels. In the remainder of the paper,
we showcase the applications of pseudo-labelling and its generalised form,
Bayesian Pseudo-Labelling, in the semi-supervised segmentation of medical
images. Specifically, we focus on: 1) 3D binary segmentation of lung vessels
from CT volumes; 2) 2D multi-class segmentation of brain tumours from MRI
volumes; 3) 3D binary segmentation of whole brain tumours from MRI volumes; and
4) 3D binary segmentation of prostate from MRI volumes. We further demonstrate
that pseudo-labels can enhance the robustness of the learned representations.
The code is released in the following GitHub repository:
https://github.com/moucheng2017/EMSSL
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.12292">Optimal Low-Rank Matrix Completion: Semidefinite Relaxations and Eigenvector Disjunctions. (arXiv:2305.12292v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1">Dimitris Bertsimas</a>, <a href="http://arxiv.org/find/cs/1/au:+Cory_Wright_R/0/1/0/all/0/1">Ryan Cory-Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1">Sean Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pauphilet_J/0/1/0/all/0/1">Jean Pauphilet</a></p>
<p>Low-rank matrix completion consists of computing a matrix of minimal
complexity that recovers a given set of observations as accurately as possible.
Unfortunately, existing methods for matrix completion are heuristics that,
while highly scalable and often identifying high-quality solutions, do not
possess any optimality guarantees. We reexamine matrix completion with an
optimality-oriented eye. We reformulate these low-rank problems as convex
problems over the non-convex set of projection matrices and implement a
disjunctive branch-and-bound scheme that solves them to certifiable optimality.
Further, we derive a novel and often tight class of convex relaxations by
decomposing a low-rank matrix as a sum of rank-one matrices and incentivizing
that two-by-two minors in each rank-one matrix have determinant zero. In
numerical experiments, our new convex relaxations decrease the optimality gap
by two orders of magnitude compared to existing attempts, and our disjunctive
branch-and-bound scheme solves nxn rank-r matrix completion problems to
certifiable optimality in hours for n&lt;=150 and r&lt;=5.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.15260">Making Offline RL Online: Collaborative World Models for Offline Visual Reinforcement Learning. (arXiv:2305.15260v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Junming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunbo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a></p>
<p>Training offline reinforcement learning (RL) models using visual inputs poses
two significant challenges, i.e., the overfitting problem in representation
learning and the overestimation bias for expected future rewards. Recent work
has attempted to alleviate the overestimation bias by encouraging conservative
behaviors. This paper, in contrast, tries to build more flexible constraints
for value estimation without impeding the exploration of potential advantages.
The key idea is to leverage off-the-shelf RL simulators, which can be easily
interacted with in an online manner, as the "test bed" for offline policies. To
enable effective online-to-offline knowledge transfer, we introduce CoWorld, a
model-based RL approach that mitigates cross-domain discrepancies in state and
reward spaces. Experimental results demonstrate the effectiveness of CoWorld,
outperforming existing RL approaches by large margins.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.17191">MT-SLVR: Multi-Task Self-Supervised Learning for Transformation In(Variant) Representations. (arXiv:2305.17191v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Heggan_C/0/1/0/all/0/1">Calum Heggan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1">Tim Hospedales</a>, <a href="http://arxiv.org/find/cs/1/au:+Budgett_S/0/1/0/all/0/1">Sam Budgett</a>, <a href="http://arxiv.org/find/cs/1/au:+Yaghoobi_M/0/1/0/all/0/1">Mehrdad Yaghoobi</a></p>
<p>Contrastive self-supervised learning has gained attention for its ability to
create high-quality representations from large unlabelled data sets. A key
reason that these powerful features enable data-efficient learning of
downstream tasks is that they provide augmentation invariance, which is often a
useful inductive bias. However, the amount and type of invariances preferred is
not known apriori, and varies across different downstream tasks. We therefore
propose a multi-task self-supervised framework (MT-SLVR) that learns both
variant and invariant features in a parameter-efficient manner. Our multi-task
representation provides a strong and flexible feature that benefits diverse
downstream tasks. We evaluate our approach on few-shot classification tasks
drawn from a variety of audio domains and demonstrate improved classification
performance on all of them
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.19956">MicroSegNet: A Deep Learning Approach for Prostate Segmentation on Micro-Ultrasound Images. (arXiv:2305.19956v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hongxu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Imran_M/0/1/0/all/0/1">Muhammad Imran</a>, <a href="http://arxiv.org/find/cs/1/au:+Muralidharan_P/0/1/0/all/0/1">Preethika Muralidharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1">Anjali Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Pensa_J/0/1/0/all/0/1">Jake Pensa</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_M/0/1/0/all/0/1">Muxuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Benidir_T/0/1/0/all/0/1">Tarik Benidir</a>, <a href="http://arxiv.org/find/cs/1/au:+Grajo_J/0/1/0/all/0/1">Joseph R. Grajo</a>, <a href="http://arxiv.org/find/cs/1/au:+Joseph_J/0/1/0/all/0/1">Jason P. Joseph</a>, <a href="http://arxiv.org/find/cs/1/au:+Terry_R/0/1/0/all/0/1">Russell Terry</a>, <a href="http://arxiv.org/find/cs/1/au:+DiBianco_J/0/1/0/all/0/1">John Michael DiBianco</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1">Li-Ming Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuyin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Brisbane_W/0/1/0/all/0/1">Wayne G. Brisbane</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1">Wei Shao</a></p>
<p>Micro-ultrasound (micro-US) is a novel 29-MHz ultrasound technique that
provides 3-4 times higher resolution than traditional ultrasound, potentially
enabling low-cost, accurate diagnosis of prostate cancer. Accurate prostate
segmentation is crucial for prostate volume measurement, cancer diagnosis,
prostate biopsy, and treatment planning. However, prostate segmentation on
micro-US is challenging due to artifacts and indistinct borders between the
prostate, bladder, and urethra in the midline. This paper presents MicroSegNet,
a multi-scale annotation-guided transformer UNet model designed specifically to
tackle these challenges. During the training process, MicroSegNet focuses more
on regions that are hard to segment (hard regions), characterized by
discrepancies between expert and non-expert annotations. We achieve this by
proposing an annotation-guided binary cross entropy (AG-BCE) loss that assigns
a larger weight to prediction errors in hard regions and a lower weight to
prediction errors in easy regions. The AG-BCE loss was seamlessly integrated
into the training process through the utilization of multi-scale deep
supervision, enabling MicroSegNet to capture global contextual dependencies and
local information at various scales. We trained our model using micro-US images
from 55 patients, followed by evaluation on 20 patients. Our MicroSegNet model
achieved a Dice coefficient of 0.939 and a Hausdorff distance of 2.02 mm,
outperforming several state-of-the-art segmentation methods, as well as three
human annotators with different experience levels. Our code is publicly
available at https://github.com/mirthAI/MicroSegNet and our dataset is publicly
available at https://zenodo.org/records/10475293.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02719">Multiple output samples per input in a single-output Gaussian process. (arXiv:2306.02719v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1">Jeremy H. M. Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huayun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nancy F. Chen</a></p>
<p>The standard Gaussian Process (GP) only considers a single output sample per
input in the training set. Datasets for subjective tasks, such as spoken
language assessment, may be annotated with output labels from multiple human
raters per input. This paper proposes to generalise the GP to allow for these
multiple output samples in the training set, and thus make use of available
output uncertainty information. This differs from a multi-output GP, as all
output samples are from the same task here. The output density function is
formulated to be the joint likelihood of observing all output samples, and
latent variables are not repeated to reduce computation cost. The test set
predictions are inferred similarly to a standard GP, with a difference being in
the optimised hyper-parameters. This is evaluated on speechocean762, showing
that it allows the GP to compute a test set output distribution that is more
similar to the collection of reference outputs from the multiple human raters.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.02766">Networked Communication for Decentralised Agents in Mean-Field Games. (arXiv:2306.02766v2 [cs.MA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Benjamin_P/0/1/0/all/0/1">Patrick Benjamin</a>, <a href="http://arxiv.org/find/cs/1/au:+Abate_A/0/1/0/all/0/1">Alessandro Abate</a></p>
<p>We introduce networked communication to the mean-field game framework, in
particular to oracle-free settings where $N$ decentralised agents learn along a
single, non-episodic evolution path of the empirical system. We prove that our
architecture, with only a few reasonable assumptions about network structure,
has sample guarantees bounded between those of the centralised- and
independent-learning cases. We discuss how the sample guarantees of the three
theoretical algorithms do not actually result in practical convergence.
Accordingly, we show that in practical settings where the theoretical
parameters are not observed (leading to poor estimation of the Q-function), our
communication scheme significantly accelerates convergence over the independent
case, without relying on the undesirable assumption of a centralised
controller. We contribute several further practical enhancements to all three
theoretical algorithms, allowing us to showcase their first empirical
demonstrations. Our experiments confirm that we can remove several of the key
theoretical assumptions of the algorithms, and display the empirical
convergence benefits brought by our new networked communication. We
additionally show that the networked approach has significant advantages, over
both the centralised and independent alternatives, in terms of robustness to
unexpected learning failures and to changes in population size.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.05412">Decoupled Prioritized Resampling for Offline RL. (arXiv:2306.05412v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yang Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_B/0/1/0/all/0/1">Bingyi Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qisen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shiji Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shuicheng Yan</a></p>
<p>Offline reinforcement learning (RL) is challenged by the distributional shift
problem. To address this problem, existing works mainly focus on designing
sophisticated policy constraints between the learned policy and the behavior
policy. However, these constraints are applied equally to well-performing and
inferior actions through uniform sampling, which might negatively affect the
learned policy. To alleviate this issue, we propose Offline Prioritized
Experience Replay (OPER), featuring a class of priority functions designed to
prioritize highly-rewarding transitions, making them more frequently visited
during training. Through theoretical analysis, we show that this class of
priority functions induce an improved behavior policy, and when constrained to
this improved policy, a policy-constrained offline RL algorithm is likely to
yield a better solution. We develop two practical strategies to obtain priority
weights by estimating advantages based on a fitted value network (OPER-A) or
utilizing trajectory returns (OPER-R) for quick computation. OPER is a
plug-and-play component for offline RL algorithms. As case studies, we evaluate
OPER on five different algorithms, including BC, TD3+BC, Onestep RL, CQL, and
IQL. Extensive experiments demonstrate that both OPER-A and OPER-R
significantly improve the performance for all baseline methods. Codes and
priority weights are availiable at https://github.com/sail-sg/OPER.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.05879">FedWon: Triumphing Multi-domain Federated Learning Without Normalization. (arXiv:2306.05879v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Weiming Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1">Lingjuan Lyu</a></p>
<p>Federated learning (FL) enhances data privacy with collaborative in-situ
training on decentralized clients. Nevertheless, FL encounters challenges due
to non-independent and identically distributed (non-i.i.d) data, leading to
potential performance degradation and hindered convergence. While prior studies
predominantly addressed the issue of skewed label distribution, our research
addresses a crucial yet frequently overlooked problem known as multi-domain FL.
In this scenario, clients' data originate from diverse domains with distinct
feature distributions, instead of label distributions. To address the
multi-domain problem in FL, we propose a novel method called Federated learning
Without normalizations (FedWon). FedWon draws inspiration from the observation
that batch normalization (BN) faces challenges in effectively modeling the
statistics of multiple domains, while existing normalization techniques possess
their own limitations. In order to address these issues, FedWon eliminates the
normalization layers in FL and reparameterizes convolution layers with scaled
weight standardization. Through extensive experimentation on five datasets and
five models, our comprehensive experimental results demonstrate that FedWon
surpasses both FedAvg and the current state-of-the-art method (FedBN) across
all experimental setups, achieving notable accuracy improvements of more than
10% in certain domains. Furthermore, FedWon is versatile for both cross-silo
and cross-device FL, exhibiting robust domain generalization capability,
showcasing strong performance even with a batch size as small as 1, thereby
catering to resource-constrained devices. Additionally, FedWon can also
effectively tackle the challenge of skewed label distribution.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.07331">Splitting and Parallelizing of Quantum Convolutional Neural Networks for Learning Translationally Symmetric Data. (arXiv:2306.07331v2 [quant-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Chinzei_K/0/1/0/all/0/1">Koki Chinzei</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tran_Q/0/1/0/all/0/1">Quoc Hoan Tran</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Maruyama_K/0/1/0/all/0/1">Kazunori Maruyama</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Oshima_H/0/1/0/all/0/1">Hirotaka Oshima</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sato_S/0/1/0/all/0/1">Shintaro Sato</a></p>
<p>The quantum convolutional neural network (QCNN) is a promising quantum
machine learning (QML) model that is expected to achieve quantum advantages in
classically intractable problems. However, the QCNN requires a large number of
measurements for data learning, limiting its practical applications in
large-scale problems. To alleviate this requirement, we propose a novel
architecture called split-parallelizing QCNN (sp-QCNN), which exploits the
prior knowledge of quantum data to design an efficient model. This architecture
draws inspiration from geometric quantum machine learning and targets
translationally symmetric quantum data commonly encountered in physics and
quantum computing science. By splitting the quantum circuit based on
translational symmetry, the sp-QCNN can substantially parallelize the
conventional QCNN without increasing the number of qubits and improve the
measurement efficiency by an order of the number of qubits. To demonstrate its
effectiveness, we apply the sp-QCNN to a quantum phase recognition task and
show that it can achieve comparable classification accuracy to the conventional
QCNN while considerably reducing the measurement resources required. Due to its
high measurement efficiency, the sp-QCNN can mitigate statistical errors in
estimating the gradient of the loss function, thereby accelerating the learning
process. These results open up new possibilities for incorporating the prior
data knowledge into the efficient design of QML models, leading to practical
quantum advantages.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.11305">Progressive Fourier Neural Representation for Sequential Video Compilation. (arXiv:2306.11305v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1">Haeyong Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1">Jaehong Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">DaHyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1">Chang D Yoo</a></p>
<p>Neural Implicit Representation (NIR) has recently gained significant
attention due to its remarkable ability to encode complex and high-dimensional
data into representation space and easily reconstruct it through a trainable
mapping function. However, NIR methods assume a one-to-one mapping between the
target data and representation models regardless of data relevancy or
similarity. This results in poor generalization over multiple complex data and
limits their efficiency and scalability. Motivated by continual learning, this
work investigates how to accumulate and transfer neural implicit
representations for multiple complex video data over sequential encoding
sessions. To overcome the limitation of NIR, we propose a novel method,
Progressive Fourier Neural Representation (PFNR), that aims to find an adaptive
and compact sub-module in Fourier space to encode videos in each training
session. This sparsified neural encoding allows the neural network to hold free
weights, enabling an improved adaptation for future videos. In addition, when
learning a representation for a new video, PFNR transfers the representation of
previous videos with frozen weights. This design allows the model to
continuously accumulate high-quality neural representations for multiple videos
while ensuring lossless decoding that perfectly preserves the learned
representations for previous videos. We validate our PFNR method on the UVG8/17
and DAVIS50 video sequence benchmarks and achieve impressive performance gains
over strong continual learning baselines. The PFNR code is available at
https://github.com/ihaeyong/PFNR.git.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.01946">ECG-Image-Kit: A Synthetic Image Generation Toolbox to Facilitate Deep Learning-Based Electrocardiogram Digitization. (arXiv:2307.01946v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shivashankara_K/0/1/0/all/0/1">Kshama Kodthalu Shivashankara</a>, <a href="http://arxiv.org/find/cs/1/au:+Deepanshi/0/1/0/all/0/1">Deepanshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shervedani_A/0/1/0/all/0/1">Afagh Mehri Shervedani</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifford_G/0/1/0/all/0/1">Gari D. Clifford</a>, <a href="http://arxiv.org/find/cs/1/au:+Reyna_M/0/1/0/all/0/1">Matthew A. Reyna</a>, <a href="http://arxiv.org/find/cs/1/au:+Sameni_R/0/1/0/all/0/1">Reza Sameni</a></p>
<p>We introduce ECG-Image-Kit, an open-source toolbox for generating synthetic
ECG images with realistic artifacts from time-series data, and showcase its
application in developing algorithms for data augmentation and ECG image
digitization. Synthetic data is generated by producing distortionless ECG
images on a standard ECG paper background. Subsequently, various distortions,
including handwritten text artifacts, wrinkles, creases, and perspective
transformations, are applied to these ECG images. The artifacts and text are
synthetically generated, excluding personally identifiable information. The
toolbox is used for data augmentation in the 2024 PhysioNet Challenge on
Digitization and Classification of ECG Images.
</p>
<p>As a case study, we employed ECG-Image-Kit to create an ECG image dataset of
21,801 records from the PhysioNet QT database. A denoising convolutional neural
network (DnCNN)-based model was developed and trained on this synthetic dataset
and used to convert the synthetically generated images back into time-series
data for evaluation. SNR was calculated to assess the quality of image
digitization compared to the ground truth ECG time-series. The results show an
average signal recovery SNR of 11.17 +/- 9.19 dB, indicating the synthetic ECG
image dataset's significance for training deep learning models. For clinical
evaluation, we measured the error between the estimated and ground-truth
time-series data's RR and QT-intervals. The accuracy of the estimated RR and
QT-intervals also suggests that the respective clinical parameters are
maintained. These results demonstrate the effectiveness of a deep
learning-based pipeline in accurately digitizing paper ECGs and highlight a
generative approach to digitization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06618">Learning IMM Filter Parameters from Measurements using Gradient Descent. (arXiv:2307.06618v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Brandenburger_A/0/1/0/all/0/1">Andr&#xe9; Brandenburger</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_F/0/1/0/all/0/1">Folker Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Charlish_A/0/1/0/all/0/1">Alexander Charlish</a></p>
<p>The performance of data fusion and tracking algorithms often depends on
parameters that not only describe the sensor system, but can also be
task-specific. While for the sensor system tuning these variables is
time-consuming and mostly requires expert knowledge, intrinsic parameters of
targets under track can even be completely unobservable until the system is
deployed. With state-of-the-art sensor systems growing more and more complex,
the number of parameters naturally increases, necessitating the automatic
optimization of the model variables. In this paper, the parameters of an
interacting multiple model (IMM) filter are optimized solely using
measurements, thus without necessity for any ground-truth data. The resulting
method is evaluated through an ablation study on simulated data, where the
trained model manages to match the performance of a filter parametrized with
ground-truth values.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.09060">Extreme heatwave sampling and prediction with analog Markov chain and comparisons with deep learning. (arXiv:2307.09060v2 [physics.ao-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Miloshevich_G/0/1/0/all/0/1">George Miloshevich</a>, <a href="http://arxiv.org/find/physics/1/au:+Lucente_D/0/1/0/all/0/1">Dario Lucente</a>, <a href="http://arxiv.org/find/physics/1/au:+Yiou_P/0/1/0/all/0/1">Pascal Yiou</a>, <a href="http://arxiv.org/find/physics/1/au:+Bouchet_F/0/1/0/all/0/1">Freddy Bouchet</a></p>
<p>We present a data-driven emulator, stochastic weather generator (SWG),
suitable for estimating probabilities of prolonged heatwaves in France and
Scandinavia. This emulator is based on the method of analogs of circulation to
which we add temperature and soil moisture as predictor fields. We train the
emulator on an intermediate complexity climate model run and show that it is
capable of predicting conditional probabilities (forecasting) of heatwaves out
of sample. Special attention is payed that this prediction is evaluated using
proper score appropriate for rare events. To accelerate the computation of
analogs dimensionality reduction techniques are applied and the performance is
evaluated. The probabilistic prediction achieved with SWG is compared with the
one achieved with
</p>
<p>Convolutional Neural Network (CNN). With the availability of hundreds of
years of training data CNNs perform better at the task of probabilistic
prediction. In addition, we show that the SWG emulator trained on 80 years of
data is capable of estimating extreme return times of order of thousands of
years for heatwaves longer than several days more precisely than the fit based
on generalised extreme value distribution. Finally, the quality of its
synthetic extreme teleconnection patterns obtained with stochastic weather
generator is studied. We showcase two examples of such synthetic teleconnection
patterns for heatwaves in France and Scandinavia that compare favorably to the
very long climate model control run.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.09357">Using the IBM Analog In-Memory Hardware Acceleration Kit for Neural Network Training and Inference. (arXiv:2307.09357v2 [cs.ET] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gallo_M/0/1/0/all/0/1">Manuel Le Gallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lammie_C/0/1/0/all/0/1">Corey Lammie</a>, <a href="http://arxiv.org/find/cs/1/au:+Buechel_J/0/1/0/all/0/1">Julian Buechel</a>, <a href="http://arxiv.org/find/cs/1/au:+Carta_F/0/1/0/all/0/1">Fabio Carta</a>, <a href="http://arxiv.org/find/cs/1/au:+Fagbohungbe_O/0/1/0/all/0/1">Omobayode Fagbohungbe</a>, <a href="http://arxiv.org/find/cs/1/au:+Mackin_C/0/1/0/all/0/1">Charles Mackin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_H/0/1/0/all/0/1">Hsinyu Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_V/0/1/0/all/0/1">Vijay Narayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastian_A/0/1/0/all/0/1">Abu Sebastian</a>, <a href="http://arxiv.org/find/cs/1/au:+Maghraoui_K/0/1/0/all/0/1">Kaoutar El Maghraoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasch_M/0/1/0/all/0/1">Malte J. Rasch</a></p>
<p>Analog In-Memory Computing (AIMC) is a promising approach to reduce the
latency and energy consumption of Deep Neural Network (DNN) inference and
training. However, the noisy and non-linear device characteristics, and the
non-ideal peripheral circuitry in AIMC chips, require adapting DNNs to be
deployed on such hardware to achieve equivalent accuracy to digital computing.
In this tutorial, we provide a deep dive into how such adaptations can be
achieved and evaluated using the recently released IBM Analog Hardware
Acceleration Kit (AIHWKit), freely available at https://github.com/IBM/aihwkit.
The AIHWKit is a Python library that simulates inference and training of DNNs
using AIMC. We present an in-depth description of the AIHWKit design,
functionality, and best practices to properly perform inference and training.
We also present an overview of the Analog AI Cloud Composer, a platform that
provides the benefits of using the AIHWKit simulation in a fully managed cloud
setting along with physical AIMC hardware access, freely available at
https://aihw-composer.draco.res.ibm.com. Finally, we show examples on how users
can expand and customize AIHWKit for their own needs. This tutorial is
accompanied by comprehensive Jupyter Notebook code examples that can be run
using AIHWKit, which can be downloaded from
https://github.com/IBM/aihwkit/tree/master/notebooks/tutorial.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10219">Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge. (arXiv:2307.10219v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zifeng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingcheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingpei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yan Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1">Volker Tresp</a></p>
<p>There has been an increasing interest in studying graph reasoning over
hyper-relational KGs (HKGs). Compared with traditional knowledge graphs (KGs),
HKGs introduce additional factual information in the form of qualifiers
(key-value pairs) for each KG fact that helps to better restrict the fact
validity. Meanwhile, due to the ever-evolving nature of world knowledge,
extensive parallel works have been studying temporal KG (TKG) reasoning. Each
TKG fact can be viewed as a KG fact coupled with a timestamp (or time period)
specifying its time validity. The existing HKG reasoning approaches do not
consider temporal information because it is not explicitly specified in
previous benchmark datasets. Besides, traditional TKG reasoning methods only
focus on temporal reasoning and have no way to learn from qualifiers. To this
end, we aim to fill the gap between TKG and HKG reasoning. We develop two new
benchmark hyper-relational TKG (HTKG) datasets, i.e., Wiki-hy and YAGO-hy, and
propose an HTKG reasoning model that efficiently models both temporal facts and
qualifiers. We further exploit additional time-invariant relational knowledge
from the Wikidata knowledge base to improve HTKG reasoning. Time-invariant
relational knowledge serves as the knowledge that remains unchanged in time
(e.g., Sasha Obama is the child of Barack Obama). Experimental results show
that our model achieves strong performance on HTKG link prediction and can be
enhanced by jointly leveraging both temporal and time-invariant relational
knowledge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.12044">A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amakor_A/0/1/0/all/0/1">Augustina C. Amakor</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonntag_K/0/1/0/all/0/1">Konstantin Sonntag</a>, <a href="http://arxiv.org/find/cs/1/au:+Peitz_S/0/1/0/all/0/1">Sebastian Peitz</a></p>
<p>Sparsity is a highly desired feature in deep neural networks (DNNs) since it
ensures numerical efficiency, improves the interpretability of models (due to
the smaller number of relevant features), and robustness. In machine learning
approaches based on linear models, it is well known that there exists a
connecting path between the sparsest solution in terms of the $\ell^1$
norm,i.e., zero weights and the non-regularized solution, which is called the
regularization path. Very recently, there was a first attempt to extend the
concept of regularization paths to DNNs by means of treating the empirical loss
and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the
resulting multiobjective optimization problem. However, due to the
non-smoothness of the $\ell^1$ norm and the high number of parameters, this
approach is not very efficient from a computational perspective. To overcome
this limitation, we present an algorithm that allows for the approximation of
the entire Pareto front for the above-mentioned objectives in a very efficient
manner. We present numerical examples using both deterministic and stochastic
gradients. We furthermore demonstrate that knowledge of the regularization path
allows for a well-generalizing network parametrization.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.04655">Intelligent upper-limb exoskeleton integrated with soft wearable bioelectronics and deep-learning for human intention-driven strength augmentation based on sensory feedback. (arXiv:2309.04655v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jinwoo Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_K/0/1/0/all/0/1">Kangkyu Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltis_I/0/1/0/all/0/1">Ira Soltis</a>, <a href="http://arxiv.org/find/cs/1/au:+Matthews_J/0/1/0/all/0/1">Jared Matthews</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yoonjae Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hojoong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_L/0/1/0/all/0/1">Lissette Romero</a>, <a href="http://arxiv.org/find/cs/1/au:+Zavanelli_N/0/1/0/all/0/1">Nathan Zavanelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1">Youngjin Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1">Shinjae Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jimin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Na_Y/0/1/0/all/0/1">Yewon Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sung Hoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1">Ki Jun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shinohara_M/0/1/0/all/0/1">Minoru Shinohara</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammond_F/0/1/0/all/0/1">Frank L. Hammond</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_W/0/1/0/all/0/1">Woon-Hong Yeo</a></p>
<p>The age and stroke-associated decline in musculoskeletal strength degrades
the ability to perform daily human tasks using the upper extremities. Although
there are a few examples of exoskeletons, they need manual operations due to
the absence of sensor feedback and no intention prediction of movements. Here,
we introduce an intelligent upper-limb exoskeleton system that uses cloud-based
deep learning to predict human intention for strength augmentation. The
embedded soft wearable sensors provide sensory feedback by collecting real-time
muscle signals, which are simultaneously computed to determine the user's
intended movement. The cloud-based deep-learning predicts four upper-limb joint
motions with an average accuracy of 96.2% at a 200-250 millisecond response
rate, suggesting that the exoskeleton operates just by human intention. In
addition, an array of soft pneumatics assists the intended movements by
providing 897 newton of force and 78.7 millimeter of displacement at maximum.
Collectively, the intent-driven exoskeleton can augment human strength by 5.15
times on average compared to the unassisted exoskeleton. This report
demonstrates an exoskeleton robot that augments the upper-limb joint movements
by human intention based on a machine-learning cloud computing and sensory
feedback.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.07200">Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck. (arXiv:2309.07200v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Federici_M/0/1/0/all/0/1">Marco Federici</a>, <a href="http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1">Patrick Forr&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomioka_R/0/1/0/all/0/1">Ryota Tomioka</a>, <a href="http://arxiv.org/find/cs/1/au:+Veeling_B/0/1/0/all/0/1">Bastiaan S. Veeling</a></p>
<p>Markov processes are widely used mathematical models for describing dynamic
systems in various fields. However, accurately simulating large-scale systems
at long time scales is computationally expensive due to the short time steps
required for accurate integration. In this paper, we introduce an inference
process that maps complex systems into a simplified representational space and
models large jumps in time. To achieve this, we propose Time-lagged Information
Bottleneck (T-IB), a principled objective rooted in information theory, which
aims to capture relevant temporal features while discarding high-frequency
information to simplify the simulation task and minimize the inference error.
Our experiments demonstrate that T-IB learns information-optimal
representations for accurately modeling the statistical properties and dynamics
of the original process at a selected time lag, outperforming existing
time-lagged dimensionality reduction methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.07703">Causal Entropy and Information Gain for Measuring Causal Control. (arXiv:2309.07703v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Simoes_F/0/1/0/all/0/1">Francisco Nunes Ferreira Quialheiro Simoes</a>, <a href="http://arxiv.org/find/cs/1/au:+Dastani_M/0/1/0/all/0/1">Mehdi Dastani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ommen_T/0/1/0/all/0/1">Thijs van Ommen</a></p>
<p>Artificial intelligence models and methods commonly lack causal
interpretability. Despite the advancements in interpretable machine learning
(IML) methods, they frequently assign importance to features which lack causal
influence on the outcome variable. Selecting causally relevant features among
those identified as relevant by these methods, or even before model training,
would offer a solution. Feature selection methods utilizing information
theoretical quantities have been successful in identifying statistically
relevant features. However, the information theoretical quantities they are
based on do not incorporate causality, rendering them unsuitable for such
scenarios. To address this challenge, this article proposes information
theoretical quantities that incorporate the causal structure of the system,
which can be used to evaluate causal importance of features for some given
outcome variable. Specifically, we introduce causal versions of entropy and
mutual information, termed causal entropy and causal information gain, which
are designed to assess how much control a feature provides over the outcome
variable. These newly defined quantities capture changes in the entropy of a
variable resulting from interventions on other variables. Fundamental results
connecting these quantities to the existence of causal effects are derived. The
use of causal information gain in feature selection is demonstrated,
highlighting its superiority over standard mutual information in revealing
which features provide control over a chosen outcome variable. Our
investigation paves the way for the development of methods with improved
interpretability in domains involving causation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.13223">Causal Reasoning: Charting a Revolutionary Course for Next-Generation AI-Native Wireless Networks. (arXiv:2309.13223v2 [cs.IT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thomas_C/0/1/0/all/0/1">Christo Kurisummoottil Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaccour_C/0/1/0/all/0/1">Christina Chaccour</a>, <a href="http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1">Walid Saad</a>, <a href="http://arxiv.org/find/cs/1/au:+Debbah_M/0/1/0/all/0/1">Merouane Debbah</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1">Choong Seon Hong</a></p>
<p>Despite the basic premise that next-generation wireless networks (e.g., 6G)
will be artificial intelligence (AI)-native, to date, most existing efforts
remain either qualitative or incremental extensions to existing "AI for
wireless" paradigms. Indeed, creating AI-native wireless networks faces
significant technical challenges due to the limitations of data-driven,
training-intensive AI. These limitations include the black-box nature of the AI
models, their curve-fitting nature, which can limit their ability to reason and
adapt, their reliance on large amounts of training data, and the energy
inefficiency of large neural networks. In response to these limitations, this
article presents a comprehensive, forward-looking vision that addresses these
shortcomings by introducing a novel framework for building AI-native wireless
networks; grounded in the emerging field of causal reasoning. Causal reasoning,
founded on causal discovery, causal representation learning, and causal
inference, can help build explainable, reasoning-aware, and sustainable
wireless networks. Towards fulfilling this vision, we first highlight several
wireless networking challenges that can be addressed by causal discovery and
representation, including ultra-reliable beamforming for terahertz (THz)
systems, near-accurate physical twin modeling for digital twins, training data
augmentation, and semantic communication. We showcase how incorporating causal
discovery can assist in achieving dynamic adaptability, resilience, and
cognition in addressing these challenges. Furthermore, we outline potential
frameworks that leverage causal inference to achieve the overarching objectives
of future-generation networks, including intent management, dynamic
adaptability, human-level cognition, reasoning, and the critical element of
time sensitivity.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.13736">Geometry of Linear Neural Networks: Equivariance and Invariance under Permutation Groups. (arXiv:2309.13736v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kohn_K/0/1/0/all/0/1">Kathl&#xe9;n Kohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sattelberger_A/0/1/0/all/0/1">Anna-Laura Sattelberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahverdi_V/0/1/0/all/0/1">Vahid Shahverdi</a></p>
<p>The set of functions parameterized by a linear fully-connected neural network
is a determinantal variety. We investigate the subvariety of functions that are
equivariant or invariant under the action of a permutation group. Examples of
such group actions are translations or $90^\circ$ rotations on images. We
describe such equivariant or invariant subvarieties as direct products of
determinantal varieties, from which we deduce their dimension, degree,
Euclidean distance degree, and their singularities. We fully characterize
invariance for arbitrary permutation groups, and equivariance for cyclic
groups. We draw conclusions for the parameterization and the design of
equivariant and invariant linear networks in terms of sparsity and
weight-sharing properties. We prove that all invariant linear functions can be
parameterized by a single linear autoencoder with a weight-sharing property
imposed by the cycle decomposition of the considered permutation. The space of
rank-bounded equivariant functions has several irreducible components, so it
can {\em not} be parameterized by a single network -- but each irreducible
component can. Finally, we show that minimizing the squared-error loss on our
invariant or equivariant networks reduces to minimizing the Euclidean distance
from determinantal varieties via the Eckart--Young theorem.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2309.15965">TraCE: Trajectory Counterfactual Explanation Scores. (arXiv:2309.15965v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1">Jeffrey N. Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+Small_E/0/1/0/all/0/1">Edward A. Small</a>, <a href="http://arxiv.org/find/cs/1/au:+Keshtmand_N/0/1/0/all/0/1">Nawid Keshtmand</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_M/0/1/0/all/0/1">Michelle W.L. Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayoral_E/0/1/0/all/0/1">Elena Fillola Mayoral</a>, <a href="http://arxiv.org/find/cs/1/au:+Werner_E/0/1/0/all/0/1">Enrico Werner</a>, <a href="http://arxiv.org/find/cs/1/au:+Bourdeaux_C/0/1/0/all/0/1">Christopher P. Bourdeaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1">Raul Santos-Rodriguez</a></p>
<p>Counterfactual explanations, and their associated algorithmic recourse, are
typically leveraged to understand, explain, and potentially alter a prediction
coming from a black-box classifier. In this paper, we propose to extend the use
of counterfactuals to evaluate progress in sequential decision making tasks. To
this end, we introduce a model-agnostic modular framework, TraCE (Trajectory
Counterfactual Explanation) scores, which is able to distill and condense
progress in highly complex scenarios into a single value. We demonstrate
TraCE's utility across domains by showcasing its main properties in two case
studies spanning healthcare and climate change.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.01262">Non-Exchangeable Conformal Risk Control. (arXiv:2310.01262v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Farinhas_A/0/1/0/all/0/1">Ant&#xf3;nio Farinhas</a>, <a href="http://arxiv.org/find/cs/1/au:+Zerva_C/0/1/0/all/0/1">Chrysoula Zerva</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1">Dennis Ulmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1">Andr&#xe9; F. T. Martins</a></p>
<p>Split conformal prediction has recently sparked great interest due to its
ability to provide formally guaranteed uncertainty sets or intervals for
predictions made by black-box neural models, ensuring a predefined probability
of containing the actual ground truth. While the original formulation assumes
data exchangeability, some extensions handle non-exchangeable data, which is
often the case in many real-world scenarios. In parallel, some progress has
been made in conformal methods that provide statistical guarantees for a
broader range of objectives, such as bounding the best $F_1$-score or
minimizing the false negative rate in expectation. In this paper, we leverage
and extend these two lines of work by proposing non-exchangeable conformal risk
control, which allows controlling the expected value of any monotone loss
function when the data is not exchangeable. Our framework is flexible, makes
very few assumptions, and allows weighting the data based on its relevance for
a given test example; a careful choice of weights may result on tighter bounds,
making our framework useful in the presence of change points, time series, or
other forms of distribution drift. Experiments with both synthetic and real
world data show the usefulness of our method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.02998">ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models. (arXiv:2310.02998v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1">Yi-Lin Sung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1">Jaehong Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a></p>
<p>Large Vision-Language Models (LVLMs) can understand the world comprehensively
by integrating rich information from different modalities, achieving remarkable
advancements on various multimodal downstream tasks. However, deploying LVLMs
is often problematic due to their massive computational/energy costs and carbon
consumption. Such issues make it infeasible to adopt conventional iterative
global pruning, which is costly due to computing the Hessian matrix of the
entire large model for sparsification. Alternatively, several studies have
recently proposed layer-wise pruning approaches to avoid the expensive
computation of global pruning and efficiently compress model weights according
to their importance within a layer. However, they often suffer from suboptimal
model compression due to their lack of a global perspective. To address this
limitation in recent efficient pruning methods for large models, we propose
Efficient Coarse-to-Fine LayerWise Pruning (ECoFLaP), a two-stage
coarse-to-fine weight pruning approach for LVLMs. We first determine the
sparsity ratios of different layers or blocks by leveraging the global
importance score, which is efficiently computed based on the zeroth-order
approximation of the global model gradients. Then, the model performs local
layer-wise unstructured weight pruning based on globally-informed sparsity
ratios. We validate our proposed method across various multimodal and unimodal
models and datasets, demonstrating significant performance improvements over
prevalent pruning techniques in the high-sparsity regime.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08602">Safe Deep Policy Adaptation. (arXiv:2310.08602v2 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Wenli Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1">Tairan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolan_J/0/1/0/all/0/1">John Dolan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1">Guanya Shi</a></p>
<p>A critical goal of autonomy and artificial intelligence is enabling
autonomous robots to rapidly adapt in dynamic and uncertain environments.
Classic adaptive control and safe control provide stability and safety
guarantees but are limited to specific system classes. In contrast, policy
adaptation based on reinforcement learning (RL) offers versatility and
generalizability but presents safety and robustness challenges. We propose
SafeDPA, a novel RL and control framework that simultaneously tackles the
problems of policy adaptation and safe reinforcement learning. SafeDPA jointly
learns adaptive policy and dynamics models in simulation, predicts environment
configurations, and fine-tunes dynamics models with few-shot real-world data. A
safety filter based on the Control Barrier Function (CBF) on top of the RL
policy is introduced to ensure safety during real-world deployment. We provide
theoretical safety guarantees of SafeDPA and show the robustness of SafeDPA
against learning errors and extra perturbations. Comprehensive experiments on
(1) classic control problems (Inverted Pendulum), (2) simulation benchmarks
(Safety Gym), and (3) a real-world agile robotics platform (RC Car) demonstrate
great superiority of SafeDPA in both safety and task performance, over
state-of-the-art baselines. Particularly, SafeDPA demonstrates notable
generalizability, achieving a 300% increase in safety rate compared to the
baselines, under unseen disturbances in real-world experiments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.08876">Gesture Recognition for FMCW Radar on the Edge. (arXiv:2310.08876v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Strobel_M/0/1/0/all/0/1">Maximilian Strobel</a>, <a href="http://arxiv.org/find/cs/1/au:+Schoenfeldt_S/0/1/0/all/0/1">Stephan Schoenfeldt</a>, <a href="http://arxiv.org/find/cs/1/au:+Daugalas_J/0/1/0/all/0/1">Jonas Daugalas</a></p>
<p>This paper introduces a lightweight gesture recognition system based on 60
GHz frequency modulated continuous wave (FMCW) radar. We show that gestures can
be characterized efficiently by a set of five features, and propose a slim
radar processing algorithm to extract these features. In contrast to previous
approaches, we avoid heavy 2D processing, i.e. range-Doppler imaging, and
perform instead an early target detection - this allows us to port the system
to fully embedded platforms with tight constraints on memory, compute and power
consumption. A recurrent neural network (RNN) based architecture exploits these
features to jointly detect and classify five different gestures. The proposed
system recognizes gestures with an F1 score of 98.4% on our hold-out test
dataset, it runs on an Arm Cortex-M4 microcontroller requiring less than 280 kB
of flash memory, 120 kB of RAM, and consuming 75 mW of power.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.09392">Machine Learning Estimation of Maximum Vertical Velocity from Radar. (arXiv:2310.09392v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chase_R/0/1/0/all/0/1">Randy J. Chase</a>, <a href="http://arxiv.org/find/cs/1/au:+McGovern_A/0/1/0/all/0/1">Amy McGovern</a>, <a href="http://arxiv.org/find/cs/1/au:+Homeyer_C/0/1/0/all/0/1">Cameron Homeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Marinescu_P/0/1/0/all/0/1">Peter Marinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Potvin_C/0/1/0/all/0/1">Corey Potvin</a></p>
<p>The quantification of storm updrafts remains unavailable for operational
forecasting despite their inherent importance to convection and its associated
severe weather hazards. Updraft proxies, like overshooting top area from
satellite images, have been linked to severe weather hazards but only relate to
a limited portion of the total storm updraft. This study investigates if a
machine learning model, namely U-Nets, can skillfully retrieve maximum vertical
velocity and its areal extent from 3-dimensional gridded radar reflectivity
alone. The machine learning model is trained using simulated radar reflectivity
and vertical velocity from the National Severe Storm Laboratory's convection
permitting Warn on Forecast System (WoFS). A parametric regression technique
using the sinh-arcsinh-normal distribution is adapted to run with U-Nets,
allowing for both deterministic and probabilistic predictions of maximum
vertical velocity. The best models after hyperparameter search provided less
than 50% root mean squared error, a coefficient of determination greater than
0.65 and an intersection over union (IoU) of more than 0.45 on the independent
test set composed of WoFS data. Beyond the WoFS analysis, a case study was
conducted using real radar data and corresponding dual-Doppler analyses of
vertical velocity within a supercell. The U-Net consistently underestimates the
dual-Doppler updraft speed estimates by 50$\%$. Meanwhile, the area of the 5
and 10 m s^-1 updraft cores show an IoU of 0.25. While the above statistics are
not exceptional, the machine learning model enables quick distillation of 3D
radar data that is related to the maximum vertical velocity which could be
useful in assessing a storm's severe potential.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18564">A General Framework for Robust G-Invariance in G-Equivariant Networks. (arXiv:2310.18564v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sanborn_S/0/1/0/all/0/1">Sophia Sanborn</a>, <a href="http://arxiv.org/find/cs/1/au:+Miolane_N/0/1/0/all/0/1">Nina Miolane</a></p>
<p>We introduce a general method for achieving robust group-invariance in
group-equivariant convolutional neural networks ($G$-CNNs), which we call the
$G$-triple-correlation ($G$-TC) layer. The approach leverages the theory of the
triple-correlation on groups, which is the unique, lowest-degree polynomial
invariant map that is also complete. Many commonly used invariant maps--such as
the max--are incomplete: they remove both group and signal structure. A
complete invariant, by contrast, removes only the variation due to the actions
of the group, while preserving all information about the structure of the
signal. The completeness of the triple correlation endows the $G$-TC layer with
strong robustness, which can be observed in its resistance to invariance-based
adversarial attacks. In addition, we observe that it yields measurable
improvements in classification accuracy over standard Max $G$-Pooling in
$G$-CNN architectures. We provide a general and efficient implementation of the
method for any discretized group, which requires only a table defining the
group's product structure. We demonstrate the benefits of this method for
$G$-CNNs defined on both commutative and non-commutative groups--$SO(2)$,
$O(2)$, $SO(3)$, and $O(3)$ (discretized as the cyclic $C8$, dihedral $D16$,
chiral octahedral $O$ and full octahedral $O_h$ groups)--acting on
$\mathbb{R}^2$ and $\mathbb{R}^3$ on both $G$-MNIST and $G$-ModelNet10
datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.18628">Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation. (arXiv:2310.18628v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hailin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1">Amrita Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1">Steven Hoi</a>, <a href="http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1">Shafiq Joty</a></p>
<p>With the rise of powerful closed-sourced LLMs (ChatGPT, GPT-4), there are
increasing interests in distilling the capabilies of close-sourced LLMs to
smaller open-sourced LLMs. Previous distillation methods usually prompt ChatGPT
to generate a set of instructions and answers, for the student model to learn.
However, such standard distillation approach neglects the merits and conditions
of the student model. Inspired by modern teaching principles, we design a
personalised distillation process, in which the student attempts to solve a
task first, then the teacher provides an adaptive refinement for the student to
improve. Instead of feeding the student with teacher's prior, personalised
distillation enables personalised learning for the student model, as it only
learns on examples it makes mistakes upon and learns to improve its own
solution. On code generation, personalised distillation consistently
outperforms standard distillation with only one third of the data. With only
2.5-3K personalised examples that incur a data-collection cost of 4-6$, we
boost CodeGen-mono-16B by 7% to achieve 36.4% pass@1 and StarCoder by 12.2% to
achieve 45.8% pass@1 on HumanEval.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2310.19731">ViR: Towards Efficient Vision Retention Backbones. (arXiv:2310.19731v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hatamizadeh_A/0/1/0/all/0/1">Ali Hatamizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranzinger_M/0/1/0/all/0/1">Michael Ranzinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1">Shiyi Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1">Jose M. Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1">Sanja Fidler</a>, <a href="http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1">Jan Kautz</a></p>
<p>Vision Transformers (ViTs) have attracted a lot of popularity in recent
years, due to their exceptional capabilities in modeling long-range spatial
dependencies and scalability for large scale training. Although the training
parallelism of self-attention mechanism plays an important role in retaining
great performance, its quadratic complexity baffles the application of ViTs in
many scenarios which demand fast inference. This effect is even more pronounced
in applications in which autoregressive modeling of input features is required.
In Natural Language Processing (NLP), a new stream of efforts has proposed
parallelizable models with recurrent formulation that allows for efficient
inference in generative applications. Inspired by this trend, we propose a new
class of computer vision models, dubbed Vision Retention Networks (ViR), with
dual parallel and recurrent formulations, which strike an optimal balance
between fast inference and parallel training with competitive performance. In
particular, ViR scales favorably for image throughput and memory consumption in
tasks that require higher-resolution images due to its flexible formulation in
processing large sequence lengths. The ViR is the first attempt to realize dual
parallel and recurrent equivalency in a general vision backbone for recognition
tasks. We have validated the effectiveness of ViR through extensive experiments
with different dataset sizes and various image resolutions and achieved
competitive performance. Code: https://github.com/NVlabs/ViR
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.08053">Communication-Constrained Bayesian Active Knowledge Distillation. (arXiv:2311.08053v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Croisfelt_V/0/1/0/all/0/1">Victor Croisfelt</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1">Shashi Raj Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1">Osvaldo Simeone</a>, <a href="http://arxiv.org/find/cs/1/au:+Popovski_P/0/1/0/all/0/1">Petar Popovski</a></p>
<p>Conventional retransmission (ARQ) protocols are designed with the goal of
ensuring the correct reception of all the individual transmitter's packets at
the receiver. When the transmitter is a learner communicating with a teacher,
this goal is at odds with the actual aim of the learner, which is that of
eliciting the most relevant label information from the teacher. Taking an
active learning perspective, this paper addresses the following key protocol
design questions: (i) Active batch selection: Which batch of inputs should be
sent to the teacher to acquire the most useful information and thus reduce the
number of required communication rounds? (ii) Batch encoding: Can batches of
data points be combined to reduce the communication resources required at each
communication round? Specifically, this work introduces
Communication-Constrained Bayesian Active Knowledge Distillation (CC-BAKD), a
novel protocol that integrates Bayesian active learning with compression via a
linear mix-up mechanism. Comparisons with existing active learning protocols
demonstrate the advantages of the proposed approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.04402">Semi-Supervised Active Learning for Semantic Segmentation in Unknown Environments Using Informative Path Planning. (arXiv:2312.04402v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ruckin_J/0/1/0/all/0/1">Julius R&#xfc;ckin</a>, <a href="http://arxiv.org/find/cs/1/au:+Magistri_F/0/1/0/all/0/1">Federico Magistri</a>, <a href="http://arxiv.org/find/cs/1/au:+Stachniss_C/0/1/0/all/0/1">Cyrill Stachniss</a>, <a href="http://arxiv.org/find/cs/1/au:+Popovic_M/0/1/0/all/0/1">Marija Popovi&#x107;</a></p>
<p>Semantic segmentation enables robots to perceive and reason about their
environments beyond geometry. Most of such systems build upon deep learning
approaches. As autonomous robots are commonly deployed in initially unknown
environments, pre-training on static datasets cannot always capture the variety
of domains and limits the robot's perception performance during missions.
Recently, self-supervised and fully supervised active learning methods emerged
to improve a robot's vision. These approaches rely on large in-domain
pre-training datasets or require substantial human labelling effort. We propose
a planning method for semi-supervised active learning of semantic segmentation
that substantially reduces human labelling requirements compared to fully
supervised approaches. We leverage an adaptive map-based planner guided towards
the frontiers of unexplored space with high model uncertainty collecting
training data for human labelling. A key aspect of our approach is to combine
the sparse high-quality human labels with pseudo labels automatically extracted
from highly certain environment map areas. Experimental results show that our
method reaches segmentation performance close to fully supervised approaches
with drastically reduced human labelling effort while outperforming
self-supervised approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.05398">Generative Network Layer for Communication Systems with Artificial Intelligence. (arXiv:2312.05398v3 [cs.IT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thorsager_M/0/1/0/all/0/1">Mathias Thorsager</a>, <a href="http://arxiv.org/find/cs/1/au:+Leyva_Mayorga_I/0/1/0/all/0/1">Israel Leyva-Mayorga</a>, <a href="http://arxiv.org/find/cs/1/au:+Soret_B/0/1/0/all/0/1">Beatriz Soret</a>, <a href="http://arxiv.org/find/cs/1/au:+Popovski_P/0/1/0/all/0/1">Petar Popovski</a></p>
<p>The traditional role of the network layer is the transfer of packet replicas
from source to destination through intermediate network nodes. We present a
generative network layer that uses Generative AI (GenAI) at intermediate or
edge network nodes and analyze its impact on the required data rates in the
network. We conduct a case study where the GenAI-aided nodes generate images
from prompts that consist of substantially compressed latent representations.
The results from network flow analyses under image quality constraints show
that the generative network layer can achieve an improvement of more than 100%
in terms of the required data rate.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2312.13628">Where and How to Attack? A Causality-Inspired Recipe for Generating Counterfactual Adversarial Examples. (arXiv:2312.13628v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1">Ruichu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuxuan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_J/0/1/0/all/0/1">Jie Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1">Zefeng Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Furui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1">Zhifeng Hao</a></p>
<p>Deep neural networks (DNNs) have been demonstrated to be vulnerable to
well-crafted \emph{adversarial examples}, which are generated through either
well-conceived $\mathcal{L}_p$-norm restricted or unrestricted attacks.
Nevertheless, the majority of those approaches assume that adversaries can
modify any features as they wish, and neglect the causal generating process of
the data, which is unreasonable and unpractical. For instance, a modification
in income would inevitably impact features like the debt-to-income ratio within
a banking system. By considering the underappreciated causal generating
process, first, we pinpoint the source of the vulnerability of DNNs via the
lens of causality, then give theoretical results to answer \emph{where to
attack}. Second, considering the consequences of the attack interventions on
the current state of the examples to generate more realistic adversarial
examples, we propose CADE, a framework that can generate
\textbf{C}ounterfactual \textbf{AD}versarial \textbf{E}xamples to answer
\emph{how to attack}. The empirical results demonstrate CADE's effectiveness,
as evidenced by its competitive performance across diverse attack scenarios,
including white-box, transfer-based, and random intervention attacks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.03568">Agent AI: Surveying the Horizons of Multimodal Interaction. (arXiv:2401.03568v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Durante_Z/0/1/0/all/0/1">Zane Durante</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qiuyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wake_N/0/1/0/all/0/1">Naoki Wake</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1">Ran Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jae Sung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_B/0/1/0/all/0/1">Bidipta Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Taori_R/0/1/0/all/0/1">Rohan Taori</a>, <a href="http://arxiv.org/find/cs/1/au:+Noda_Y/0/1/0/all/0/1">Yusuke Noda</a>, <a href="http://arxiv.org/find/cs/1/au:+Terzopoulos_D/0/1/0/all/0/1">Demetri Terzopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikeuchi_K/0/1/0/all/0/1">Katsushi Ikeuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_H/0/1/0/all/0/1">Hoi Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a></p>
<p>Multi-modal AI systems will likely become a ubiquitous presence in our
everyday lives. A promising approach to making these systems more interactive
is to embody them as agents within physical and virtual environments. At
present, systems leverage existing foundation models as the basic building
blocks for the creation of embodied agents. Embedding agents within such
environments facilitates the ability of models to process and interpret visual
and contextual data, which is critical for the creation of more sophisticated
and context-aware AI systems. For example, a system that can perceive user
actions, human behavior, environmental objects, audio expressions, and the
collective sentiment of a scene can be used to inform and direct agent
responses within the given environment. To accelerate research on agent-based
multimodal intelligence, we define "Agent AI" as a class of interactive systems
that can perceive visual stimuli, language inputs, and other
environmentally-grounded data, and can produce meaningful embodied actions. In
particular, we explore systems that aim to improve agents based on
next-embodied action prediction by incorporating external knowledge,
multi-sensory inputs, and human feedback. We argue that by developing agentic
AI systems in grounded environments, one can also mitigate the hallucinations
of large foundation models and their tendency to generate environmentally
incorrect outputs. The emerging field of Agent AI subsumes the broader embodied
and agentic aspects of multimodal interactions. Beyond agents acting and
interacting in the physical world, we envision a future where people can easily
create any virtual reality or simulated scene and interact with agents embodied
within the virtual environment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.04139">CCNETS: A Novel Brain-Inspired Approach for Enhanced Pattern Recognition in Imbalanced Datasets. (arXiv:2401.04139v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hanbeot Park</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1">Yunjeong Cho</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hoon-Hee Kim</a> (3)</p>
<p>This study introduces CCNETS (Causal Learning with Causal Cooperative Nets),
a novel generative model-based classifier designed to tackle the challenge of
generating data for imbalanced datasets in pattern recognition. CCNETS is
uniquely crafted to emulate brain-like information processing and comprises
three main components: Explainer, Producer, and Reasoner. Each component is
designed to mimic specific brain functions, which aids in generating
high-quality datasets and enhancing classification performance.
</p>
<p>The model is particularly focused on addressing the common and significant
challenge of handling imbalanced datasets in machine learning. CCNETS's
effectiveness is demonstrated through its application to a "fraud dataset,"
where normal transactions significantly outnumber fraudulent ones (99.83% vs.
0.17%). Traditional methods often struggle with such imbalances, leading to
skewed performance metrics. However, CCNETS exhibits superior classification
ability, as evidenced by its performance metrics. Specifically, it achieved an
F1-score of 0.7992, outperforming traditional models like Autoencoders and
Multi-layer Perceptrons (MLP) in the same context. This performance indicates
CCNETS's proficiency in more accurately distinguishing between normal and
fraudulent patterns.
</p>
<p>The innovative structure of CCNETS enhances the coherence between generative
and classification models, helping to overcome the limitations of pattern
recognition that rely solely on generative models. This study emphasizes
CCNETS's potential in diverse applications, especially where quality data
generation and pattern recognition are key. It proves effective in machine
learning, particularly for imbalanced datasets. CCNETS overcomes current
challenges in these datasets and advances machine learning with brain-inspired
approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.08534">DiConStruct: Causal Concept-based Explanations through Black-Box Distillation. (arXiv:2401.08534v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moreira_R/0/1/0/all/0/1">Ricardo Moreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Bono_J/0/1/0/all/0/1">Jacopo Bono</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardoso_M/0/1/0/all/0/1">M&#xe1;rio Cardoso</a>, <a href="http://arxiv.org/find/cs/1/au:+Saleiro_P/0/1/0/all/0/1">Pedro Saleiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Figueiredo_M/0/1/0/all/0/1">M&#xe1;rio A. T. Figueiredo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bizarro_P/0/1/0/all/0/1">Pedro Bizarro</a></p>
<p>Model interpretability plays a central role in human-AI decision-making
systems. Ideally, explanations should be expressed using human-interpretable
semantic concepts. Moreover, the causal relations between these concepts should
be captured by the explainer to allow for reasoning about the explanations.
Lastly, explanation methods should be efficient and not compromise the
performance of the predictive task. Despite the rapid advances in AI
explainability in recent years, as far as we know to date, no method fulfills
these three properties. Indeed, mainstream methods for local concept
explainability do not produce causal explanations and incur a trade-off between
explainability and prediction performance. We present DiConStruct, an
explanation method that is both concept-based and causal, with the goal of
creating more interpretable local explanations in the form of structural causal
models and concept attributions. Our explainer works as a distillation model to
any black-box machine learning model by approximating its predictions while
producing the respective explanations. Because of this, DiConStruct generates
explanations efficiently while not impacting the black-box prediction task. We
validate our method on an image dataset and a tabular dataset, showing that
DiConStruct approximates the black-box models with higher fidelity than other
concept explainability baselines, while providing explanations that include the
causal relations between the concepts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.10189">Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction. (arXiv:2401.10189v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongxiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Huimin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a></p>
<p>Fine-grained few-shot entity extraction in the chemical domain faces two
unique challenges. First, compared with entity extraction tasks in the general
domain, sentences from chemical papers usually contain more entities. Moreover,
entity extraction models usually have difficulty extracting entities of
long-tailed types. In this paper, we propose Chem-FINESE, a novel
sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to
address these two challenges. Our Chem-FINESE has two components: a seq2seq
entity extractor to extract named entities from the input sentence and a
seq2seq self-validation module to reconstruct the original input sentence from
extracted entities. Inspired by the fact that a good entity extraction system
needs to extract entities faithfully, our new self-validation module leverages
entity extraction results to reconstruct the original input sentence. Besides,
we design a new contrastive loss to reduce excessive copying during the
extraction process. Finally, we release ChemNER+, a new fine-grained chemical
entity extraction dataset that is annotated by domain experts with the ChemNER
schema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets
show that our newly proposed framework has contributed up to 8.26% and 6.84%
absolute F1-score gains respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11143">Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities. (arXiv:2401.11143v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ioannides_G/0/1/0/all/0/1">Georgios Ioannides</a>, <a href="http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1">Aman Chadha</a>, <a href="http://arxiv.org/find/cs/1/au:+Elkins_A/0/1/0/all/0/1">Aaron Elkins</a></p>
<p>We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a
novel probabilistic attention framework, and the Gaussian Adaptive Transformer
(GAT), designed to enhance information aggregation across multiple modalities,
including Speech, Text and Vision. GAAM integrates learnable mean and variance
into its attention mechanism, implemented in a Multi-Headed framework enabling
it to collectively model any Probability Distribution for dynamic recalibration
of feature significance. This method demonstrates significant improvements,
especially with highly non-stationary data, surpassing the state-of-the-art
attention techniques in model performance (up to approximately +20% in
accuracy) by identifying key elements within the feature space. GAAM's
compatibility with dot-product-based attention models and relatively low number
of parameters showcases its adaptability and potential to boost existing
attention frameworks. Empirically, GAAM exhibits superior adaptability and
efficacy across a diverse range of tasks, including emotion recognition in
speech, image classification, and text classification, thereby establishing its
robustness and versatility in handling multi-modal data. Furthermore, we
introduce the Importance Factor (IF), a new learning-based metric that enhances
the explainability of models trained with GAAM-based methods. Overall, GAAM
represents an advancement towards development of better performing and more
explainable attention models across multiple modalities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.11174">Pixel-Wise Recognition for Holistic Surgical Scene Understanding. (arXiv:2401.11174v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ayobi_N/0/1/0/all/0/1">Nicol&#xe1;s Ayobi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_S/0/1/0/all/0/1">Santiago Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_A/0/1/0/all/0/1">Alejandra P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_I/0/1/0/all/0/1">Isabela Hern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Aparicio_N/0/1/0/all/0/1">Nicol&#xe1;s Aparicio</a>, <a href="http://arxiv.org/find/cs/1/au:+Dessevres_E/0/1/0/all/0/1">Eug&#xe9;nie Dessevres</a>, <a href="http://arxiv.org/find/cs/1/au:+Pena_S/0/1/0/all/0/1">Sebasti&#xe1;n Pe&#xf1;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Santander_J/0/1/0/all/0/1">Jessica Santander</a>, <a href="http://arxiv.org/find/cs/1/au:+Caicedo_J/0/1/0/all/0/1">Juan Ignacio Caicedo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_N/0/1/0/all/0/1">Nicol&#xe1;s Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbel&#xe1;ez</a></p>
<p>This paper presents the Holistic and Multi-Granular Surgical Scene
Understanding of Prostatectomies (GraSP) dataset, a curated benchmark that
models surgical scene understanding as a hierarchy of complementary tasks with
varying levels of granularity. Our approach enables a multi-level comprehension
of surgical activities, encompassing long-term tasks such as surgical phases
and steps recognition and short-term tasks including surgical instrument
segmentation and atomic visual actions detection. To exploit our proposed
benchmark, we introduce the Transformers for Actions, Phases, Steps, and
Instrument Segmentation (TAPIS) model, a general architecture that combines a
global video feature extractor with localized region proposals from an
instrument segmentation model to tackle the multi-granularity of our benchmark.
Through extensive experimentation, we demonstrate the impact of including
segmentation annotations in short-term recognition tasks, highlight the varying
granularity requirements of each task, and establish TAPIS's superiority over
previously proposed baselines and conventional CNN-based models. Additionally,
we validate the robustness of our method across multiple public benchmarks,
confirming the reliability and applicability of our dataset. This work
represents a significant step forward in Endoscopic Vision, offering a novel
and comprehensive framework for future research towards a holistic
understanding of surgical procedures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.13721">Uncertainty-Guided Alignment for Unsupervised Domain Adaptation in Regression. (arXiv:2401.13721v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nejjar_I/0/1/0/all/0/1">Ismail Nejjar</a>, <a href="http://arxiv.org/find/cs/1/au:+Frusque_G/0/1/0/all/0/1">Gaetan Frusque</a>, <a href="http://arxiv.org/find/cs/1/au:+Forest_F/0/1/0/all/0/1">Florent Forest</a>, <a href="http://arxiv.org/find/cs/1/au:+Fink_O/0/1/0/all/0/1">Olga Fink</a></p>
<p>Unsupervised Domain Adaptation for Regression (UDAR) aims to adapt a model
from a labeled source domain to an unlabeled target domain for regression
tasks. Recent successful works in UDAR mostly focus on subspace alignment,
involving the alignment of a selected subspace within the entire feature space.
This contrasts with the feature alignment methods used for classification,
which aim at aligning the entire feature space and have proven effective but
are less so in regression settings. Specifically, while classification aims to
identify separate clusters across the entire embedding dimension, regression
induces less structure in the data representation, necessitating additional
guidance for efficient alignment. In this paper, we propose an effective method
for UDAR by incorporating guidance from uncertainty. Our approach serves a dual
purpose: providing a measure of confidence in predictions and acting as a
regularization of the embedding space. Specifically, we leverage the Deep
Evidential Learning framework, which outputs both predictions and uncertainties
for each input sample. We propose aligning the parameters of higher-order
evidential distributions between the source and target domains using
traditional alignment methods at the feature or posterior level. Additionally,
we propose to augment the feature space representation by mixing source samples
with pseudo-labeled target samples based on label similarity. This cross-domain
mixing strategy produces more realistic samples than random mixing and
introduces higher uncertainty, facilitating further alignment. We demonstrate
the effectiveness of our approach on four benchmarks for UDAR, on which we
outperform existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2401.14196">DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence. (arXiv:2401.14196v2 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1">Daya Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qihao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Dejian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhenda Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_K/0/1/0/all/0/1">Kai Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wentao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guanting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_X/0/1/0/all/0/1">Xiao Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Y. Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Y.K. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1">Fuli Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yingfei Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1">Wenfeng Liang</a></p>
<p>The rapid development of large language models has revolutionized code
intelligence in software development. However, the predominance of
closed-source models has restricted extensive research and development. To
address this, we introduce the DeepSeek-Coder series, a range of open-source
code models with sizes from 1.3B to 33B, trained from scratch on 2 trillion
tokens. These models are pre-trained on a high-quality project-level code
corpus and employ a fill-in-the-blank task with a 16K window to enhance code
generation and infilling. Our extensive evaluations demonstrate that
DeepSeek-Coder not only achieves state-of-the-art performance among open-source
code models across multiple benchmarks but also surpasses existing
closed-source models like Codex and GPT-3.5. Furthermore, DeepSeek-Coder models
are under a permissive license that allows for both research and unrestricted
commercial use.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2311.13544">Piecewise polynomial regression of tame functions via integer programming. (arXiv:2311.13544v1 [math.OC] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Nemecek_J/0/1/0/all/0/1">Jiri Nemecek</a>, <a href="http://arxiv.org/find/math/1/au:+Bareilles_G/0/1/0/all/0/1">Gilles Bareilles</a>, <a href="http://arxiv.org/find/math/1/au:+Aspman_J/0/1/0/all/0/1">Johannes Aspman</a>, <a href="http://arxiv.org/find/math/1/au:+Marecek_J/0/1/0/all/0/1">Jakub Marecek</a></p>
<p>We consider the task of estimating functions belonging to a specific class of
nonsmooth functions, namely so-called tame functions. These functions appear in
a wide range of applications: training deep learning, value functions of
mixed-integer programs, or wave functions of small molecules. We show that tame
functions are approximable by piecewise polynomials on any full-dimensional
cube. We then present the first ever mixed-integer programming formulation of
piecewise polynomial regression. Together, these can be used to estimate tame
functions. We demonstrate promising computational results.
</p>
</p>
</div>

    </div>
    </body>
    