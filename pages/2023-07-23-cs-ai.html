<!DOCTYPE html>
<html>
<head>
<title>2023-07-23-cs-ai</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2307.10182">Enhancing Super-Resolution Networks through Realistic Thick-Slice CT Simulation. (arXiv:2307.10182v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Tang_Z/0/1/0/all/0/1">Zeyu Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xing_X/0/1/0/all/0/1">Xiaodan Xing</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_G/0/1/0/all/0/1">Guang Yang</a></p>
<p>This study aims to develop and evaluate an innovative simulation algorithm
for generating thick-slice CT images that closely resemble actual images in the
AAPM-Mayo's 2016 Low Dose CT Grand Challenge dataset. The proposed method was
evaluated using Peak Signal-to-Noise Ratio (PSNR) and Root Mean Square Error
(RMSE) metrics, with the hypothesis that our simulation would produce images
more congruent with their real counterparts. Our proposed method demonstrated
substantial enhancements in terms of both PSNR and RMSE over other simulation
methods. The highest PSNR values were obtained with the proposed method,
yielding 49.7369 $\pm$ 2.5223 and 48.5801 $\pm$ 7.3271 for D45 and B30
reconstruction kernels, respectively. The proposed method also registered the
lowest RMSE with values of 0.0068 $\pm$ 0.0020 and 0.0108 $\pm$ 0.0099 for D45
and B30, respectively, indicating a distribution more closely aligned with the
authentic thick-slice image. Further validation of the proposed simulation
algorithm was conducted using the TCIA LDCT-and-Projection-data dataset. The
generated images were then leveraged to train four distinct super-resolution
(SR) models, which were subsequently evaluated using the real thick-slice
images from the 2016 Low Dose CT Grand Challenge dataset. When trained with
data produced by our novel algorithm, all four SR models exhibited enhanced
performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10184">A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives. (arXiv:2307.10184v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yudong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Honglong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_P/0/1/0/all/0/1">Peng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junjian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Anqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhibo Wang</a></p>
<p>Backdoor attacks pose serious security threats to deep neural networks
(DNNs). Backdoored models make arbitrarily (targeted) incorrect predictions on
inputs embedded with well-designed triggers while behaving normally on clean
inputs. Many works have explored the invisibility of backdoor triggers to
improve attack stealthiness. However, most of them only consider the
invisibility in the spatial domain without explicitly accounting for the
generation of invisible triggers in the frequency domain, making the generated
poisoned images be easily detected by recent defense methods. To address this
issue, in this paper, we propose a DUal stealthy BAckdoor attack method named
DUBA, which simultaneously considers the invisibility of triggers in both the
spatial and frequency domains, to achieve desirable attack performance, while
ensuring strong stealthiness. Specifically, we first use Discrete Wavelet
Transform to embed the high-frequency information of the trigger image into the
clean image to ensure attack effectiveness. Then, to attain strong
stealthiness, we incorporate Fourier Transform and Discrete Cosine Transform to
mix the poisoned image and clean image in the frequency domain. Moreover, the
proposed DUBA adopts a novel attack strategy, in which the model is trained
with weak triggers and attacked with strong triggers to further enhance the
attack performance and stealthiness. We extensively evaluate DUBA against
popular image classifiers on four datasets. The results demonstrate that it
significantly outperforms the state-of-the-art backdoor attacks in terms of the
attack success rate and stealthiness
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10195">ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown. (arXiv:2307.10195v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Scanlon_M/0/1/0/all/0/1">Mark Scanlon</a>, <a href="http://arxiv.org/find/cs/1/au:+Breitinger_F/0/1/0/all/0/1">Frank Breitinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Hargreaves_C/0/1/0/all/0/1">Christopher Hargreaves</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilgert_J/0/1/0/all/0/1">Jan-Niclas Hilgert</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheppard_J/0/1/0/all/0/1">John Sheppard</a></p>
<p>The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety of
domains has become a topic of much discussion in the scientific community and
society at large. Large Language Models (LLMs), e.g., BERT, Bard, Generative
Pre-trained Transformers (GPTs), LLaMA, etc., have the ability to take
instructions, or prompts, from users and generate answers and solutions based
on very large volumes of text-based training data. This paper assesses the
impact and potential impact of ChatGPT on the field of digital forensics,
specifically looking at its latest pre-trained LLM, GPT-4. A series of
experiments are conducted to assess its capability across several digital
forensic use cases including artefact understanding, evidence searching, code
generation, anomaly detection, incident response, and education. Across these
topics, its strengths and risks are outlined and a number of general
conclusions are drawn. Overall this paper concludes that while there are some
potential low-risk applications of ChatGPT within digital forensics, many are
either unsuitable at present, since the evidence would need to be uploaded to
the service, or they require sufficient knowledge of the topic being asked of
the tool to identify incorrect assumptions, inaccuracies, and mistakes.
However, to an appropriately knowledgeable user, it could act as a useful
supporting tool in some circumstances.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10198">Has China caught up to the US in AI research? An exploration of mimetic isomorphism as a model for late industrializers. (arXiv:2307.10198v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Min_C/0/1/0/all/0/1">Chao Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bu_Y/0/1/0/all/0/1">Yi Bu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Ying Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_C/0/1/0/all/0/1">Caroline S. Wagner</a></p>
<p>Artificial Intelligence (AI), a cornerstone of 21st-century technology, has
seen remarkable growth in China. In this paper, we examine China's AI
development process, demonstrating that it is characterized by rapid learning
and differentiation, surpassing the export-oriented growth propelled by Foreign
Direct Investment seen in earlier Asian industrializers.
</p>
<p>Our data indicates that China currently leads the USA in the volume of
AI-related research papers. However, when we delve into the quality of these
papers based on specific metrics, the USA retains a slight edge. Nevertheless,
the pace and scale of China's AI development remain noteworthy.
</p>
<p>We attribute China's accelerated AI progress to several factors, including
global trends favoring open access to algorithms and research papers,
contributions from China's broad diaspora and returnees, and relatively lax
data protection policies.
</p>
<p>In the vein of our research, we have developed a novel measure for gauging
China's imitation of US research. Our analysis shows that by 2018, the time lag
between China and the USA in addressing AI research topics had evaporated. This
finding suggests that China has effectively bridged a significant knowledge gap
and could potentially be setting out on an independent research trajectory.
</p>
<p>While this study compares China and the USA exclusively, it's important to
note that research collaborations between these two nations have resulted in
more highly cited work than those produced by either country independently.
This underscores the power of international cooperation in driving scientific
progress in AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10200">Disentangling Societal Inequality from Model Biases: Gender Inequality in Divorce Court Proceedings. (arXiv:2307.10200v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Sujan Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_P/0/1/0/all/0/1">Parth Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Solunke_V/0/1/0/all/0/1">Vaishnavi Solunke</a>, <a href="http://arxiv.org/find/cs/1/au:+Nath_S/0/1/0/all/0/1">Swaprava Nath</a>, <a href="http://arxiv.org/find/cs/1/au:+KhudaBukhsh_A/0/1/0/all/0/1">Ashiqur R. KhudaBukhsh</a></p>
<p>Divorce is the legal dissolution of a marriage by a court. Since this is
usually an unpleasant outcome of a marital union, each party may have reasons
to call the decision to quit which is generally documented in detail in the
court proceedings. Via a substantial corpus of 17,306 court proceedings, this
paper investigates gender inequality through the lens of divorce court
proceedings. While emerging data sources (e.g., public court records) on
sensitive societal issues hold promise in aiding social science research,
biases present in cutting-edge natural language processing (NLP) methods may
interfere with or affect such studies. We thus require a thorough analysis of
potential gaps and limitations present in extant NLP resources. In this paper,
on the methodological side, we demonstrate that existing NLP resources required
several non-trivial modifications to quantify societal inequalities. On the
substantive side, we find that while a large number of court cases perhaps
suggest changing norms in India where women are increasingly challenging
patriarchy, AI-powered analyses of these court proceedings indicate striking
gender inequality with women often subjected to domestic violence.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10213">Mitigating Bias in Conversations: A Hate Speech Classifier and Debiaser with Prompts. (arXiv:2307.10213v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1">Shaina Raza</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Chen Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandya_D/0/1/0/all/0/1">Deval Pandya</a></p>
<p>Discriminatory language and biases are often present in hate speech during
conversations, which usually lead to negative impacts on targeted groups such
as those based on race, gender, and religion. To tackle this issue, we propose
an approach that involves a two-step process: first, detecting hate speech
using a classifier, and then utilizing a debiasing component that generates
less biased or unbiased alternatives through prompts. We evaluated our approach
on a benchmark dataset and observed reduction in negativity due to hate speech
comments. The proposed method contributes to the ongoing efforts to reduce
biases in online discourse and promote a more inclusive and fair environment
for communication.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10219">Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge. (arXiv:2307.10219v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zifeng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingcheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingpei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yan Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1">Volker Tresp</a></p>
<p>Stemming from traditional knowledge graphs (KGs), hyper-relational KGs (HKGs)
provide additional key-value pairs (i.e., qualifiers) for each KG fact that
help to better restrict the fact validity. In recent years, there has been an
increasing interest in studying graph reasoning over HKGs. In the meantime, due
to the ever-evolving nature of world knowledge, extensive parallel works have
been focusing on reasoning over temporal KGs (TKGs), where each TKG fact can be
viewed as a KG fact coupled with a timestamp (or time period) specifying its
time validity. The existing HKG reasoning approaches do not consider temporal
information because it is not explicitly specified in previous benchmark
datasets. Besides, all the previous TKG reasoning methods only lay emphasis on
temporal reasoning and have no way to learn from qualifiers. To this end, we
aim to fill the gap between TKG reasoning and HKG reasoning. We develop two new
benchmark hyper-relational TKG (HTKG) datasets, i.e., Wiki-hy and YAGO-hy, and
propose a HTKG reasoning model that efficiently models both temporal facts and
qualifiers. We further exploit additional time-invariant relational knowledge
from the Wikidata knowledge base and study its effectiveness in HTKG reasoning.
Time-invariant relational knowledge serves as the knowledge that remains
unchanged in time (e.g., Sasha Obama is the child of Barack Obama), and it has
never been fully explored in previous TKG reasoning benchmarks and approaches.
Experimental results show that our model substantially outperforms previous
related methods on HTKG link prediction and can be enhanced by jointly
leveraging both temporal and time-invariant relational knowledge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10221">`It is currently hodgepodge&#x27;&#x27;: Examining AI/ML Practitioners&#x27; Challenges during Co-production of Responsible AI Values. (arXiv:2307.10221v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Varanasi_R/0/1/0/all/0/1">Rama Adithya Varanasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1">Nitesh Goyal</a></p>
<p>Recently, the AI/ML research community has indicated an urgent need to
establish Responsible AI (RAI) values and practices as part of the AI/ML
lifecycle. Several organizations and communities are responding to this call by
sharing RAI guidelines. However, there are gaps in awareness, deliberation, and
execution of such practices for multi-disciplinary ML practitioners. This work
contributes to the discussion by unpacking co-production challenges faced by
practitioners as they align their RAI values. We interviewed 23 individuals,
across 10 organizations, tasked to ship AI/ML based products while upholding
RAI norms and found that both top-down and bottom-up institutional structures
create burden for different roles preventing them from upholding RAI values, a
challenge that is further exacerbated when executing conflicted values. We
share multiple value levers used as strategies by the practitioners to resolve
their challenges. We end our paper with recommendations for inclusive and
equitable RAI value-practices, creating supportive organizational structures
and opportunities to further aid practitioners.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10223">Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms. (arXiv:2307.10223v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+QueerInAI_O/0/1/0/all/0/1">Organizers of QueerInAI</a>, <a href="http://arxiv.org/find/cs/1/au:+Dennler_N/0/1/0/all/0/1">Nathan Dennler</a>, <a href="http://arxiv.org/find/cs/1/au:+Ovalle_A/0/1/0/all/0/1">Anaelia Ovalle</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Ashwin Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Soldaini_L/0/1/0/all/0/1">Luca Soldaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramonian_A/0/1/0/all/0/1">Arjun Subramonian</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_H/0/1/0/all/0/1">Huy Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Agnew_W/0/1/0/all/0/1">William Agnew</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Avijit Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yee_K/0/1/0/all/0/1">Kyra Yee</a>, <a href="http://arxiv.org/find/cs/1/au:+Peradejordi_I/0/1/0/all/0/1">Irene Font Peradejordi</a>, <a href="http://arxiv.org/find/cs/1/au:+Talat_Z/0/1/0/all/0/1">Zeerak Talat</a>, <a href="http://arxiv.org/find/cs/1/au:+Russo_M/0/1/0/all/0/1">Mayra Russo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinhal_J/0/1/0/all/0/1">Jess de Jesus de Pinho Pinhal</a></p>
<p>Bias evaluation benchmarks and dataset and model documentation have emerged
as central processes for assessing the biases and harms of artificial
intelligence (AI) systems. However, these auditing processes have been
criticized for their failure to integrate the knowledge of marginalized
communities and consider the power dynamics between auditors and the
communities. Consequently, modes of bias evaluation have been proposed that
engage impacted communities in identifying and assessing the harms of AI
systems (e.g., bias bounties). Even so, asking what marginalized communities
want from such auditing processes has been neglected. In this paper, we ask
queer communities for their positions on, and desires from, auditing processes.
To this end, we organized a participatory workshop to critique and redesign
bias bounties from queer perspectives. We found that when given space, the
scope of feedback from workshop participants goes far beyond what bias bounties
afford, with participants questioning the ownership, incentives, and efficacy
of bounties. We conclude by advocating for community ownership of bounties and
complementing bounties with participatory processes (e.g., co-creation).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10224">RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization. (arXiv:2307.10224v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhecheng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sizhe Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_P/0/1/0/all/0/1">Pu Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Can Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Kaizhe Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huazhe Xu</a></p>
<p>Visual Reinforcement Learning (Visual RL), coupled with high-dimensional
observations, has consistently confronted the long-standing challenge of
generalization. Despite the focus on algorithms aimed at resolving visual
generalization problems, we argue that the devil is in the existing benchmarks
as they are restricted to isolated tasks and generalization categories,
undermining a comprehensive evaluation of agents' visual generalization
capabilities. To bridge this gap, we introduce RL-ViGen: a novel Reinforcement
Learning Benchmark for Visual Generalization, which contains diverse tasks and
a wide spectrum of generalization types, thereby facilitating the derivation of
more reliable conclusions. Furthermore, RL-ViGen incorporates the latest
generalization visual RL algorithms into a unified framework, under which the
experiment results indicate that no single existing algorithm has prevailed
universally across tasks. Our aspiration is that RL-ViGen will serve as a
catalyst in this area, and lay a foundation for the future creation of
universal visual generalization RL agents suitable for real-world scenarios.
Access to our code and implemented algorithms is provided at
https://gemcollector.github.io/RL-ViGen/.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10225">First-Order Stable Model Semantics with Intensional Functions. (arXiv:2307.10225v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bartholomew_M/0/1/0/all/0/1">Michael Bartholomew</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Joohyung Lee</a></p>
<p>In classical logic, nonBoolean fluents, such as the location of an object,
can be naturally described by functions. However, this is not the case in
answer set programs, where the values of functions are pre-defined, and
nonmonotonicity of the semantics is related to minimizing the extents of
predicates but has nothing to do with functions. We extend the first-order
stable model semantics by Ferraris, Lee, and Lifschitz to allow intensional
functions -- functions that are specified by a logic program just like
predicates are specified. We show that many known properties of the stable
model semantics are naturally extended to this formalism and compare it with
other related approaches to incorporating intensional functions. Furthermore,
we use this extension as a basis for defining Answer Set Programming Modulo
Theories (ASPMT), analogous to the way that Satisfiability Modulo Theories
(SMT) is defined, allowing for SMT-like effective first-order reasoning in the
context of ASP. Using SMT solving techniques involving functions, ASPMT can be
applied to domains containing real numbers and alleviates the grounding
problem. We show that other approaches to integrating ASP and CSP/SMT can be
related to special cases of ASPMT in which functions are limited to
non-intensional ones.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10226">On Loop Formulas with Variables. (arXiv:2307.10226v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Joohyung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1">Yunsong Meng</a></p>
<p>Recently Ferraris, Lee and Lifschitz proposed a new definition of stable
models that does not refer to grounding, which applies to the syntax of
arbitrary first-order sentences. We show its relation to the idea of loop
formulas with variables by Chen, Lin, Wang and Zhang, and generalize their loop
formulas to disjunctive programs and to arbitrary first-order sentences. We
also extend the syntax of logic programs to allow explicit quantifiers, and
define its semantics as a subclass of the new language of stable models by
Ferraris et al. Such programs inherit from the general language the ability to
handle nonmonotonic reasoning under the stable model semantics even in the
absence of the unique name and the domain closure assumptions, while yielding
more succinct loop formulas than the general language due to the restricted
syntax. We also show certain syntactic conditions under which query answering
for an extended program can be reduced to entailment checking in first-order
logic, providing a way to apply first-order theorem provers to reasoning about
non-Herbrand stable models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10227">Causal Laws and Multi-Valued Fluents. (arXiv:2307.10227v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Giunchiglia_E/0/1/0/all/0/1">Enrico Giunchiglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Joohyung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lifschitz_V/0/1/0/all/0/1">Vladimir Lifschitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_H/0/1/0/all/0/1">Hudson Turner</a></p>
<p>This paper continues the line of work on representing properties of actions
in nonmonotonic formalisms that stresses the distinction between being "true"
and being "caused", as in the system of causal logic introduced by McCain and
Turner and in the action language C proposed by Giunchiglia and Lifschitz. The
only fluents directly representable in language C+ are truth-valued fluents,
which is often inconvenient. We show that both causal logic and language C can
be extended to allow values from arbitrary nonempty sets. Our extension of
language C, called C+, also makes it possible to describe actions in terms of
their attributes, which is important from the perspective of elaboration
tolerance. We describe an embedding of C+ in causal theories with multi-valued
constants, relate C+ to Pednault's action language ADL, and show how
multi-valued constants can be eliminated in favor of Boolean constants.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10231">Automated Knowledge Modeling for Cancer Clinical Practice Guidelines. (arXiv:2307.10231v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ta_P/0/1/0/all/0/1">Pralaypati Ta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_B/0/1/0/all/0/1">Bhumika Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Arihant Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+C_S/0/1/0/all/0/1">Sneha Sree C</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1">Arunima Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ram_K/0/1/0/all/0/1">Keerthi Ram</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivaprakasam_M/0/1/0/all/0/1">Mohanasankar Sivaprakasam</a></p>
<p>Clinical Practice Guidelines (CPGs) for cancer diseases evolve rapidly due to
new evidence generated by active research. Currently, CPGs are primarily
published in a document format that is ill-suited for managing this developing
knowledge. A knowledge model of the guidelines document suitable for
programmatic interaction is required. This work proposes an automated method
for extraction of knowledge from National Comprehensive Cancer Network (NCCN)
CPGs in Oncology and generating a structured model containing the retrieved
knowledge. The proposed method was tested using two versions of NCCN Non-Small
Cell Lung Cancer (NSCLC) CPG to demonstrate the effectiveness in faithful
extraction and modeling of knowledge. Three enrichment strategies using Cancer
staging information, Unified Medical Language System (UMLS) Metathesaurus &amp;
National Cancer Institute thesaurus (NCIt) concepts, and Node classification
are also presented to enhance the model towards enabling programmatic traversal
and querying of cancer care guidelines. The Node classification was performed
using a Support Vector Machine (SVM) model, achieving a classification accuracy
of 0.81 with 10-fold cross-validation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10234">SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning. (arXiv:2307.10234v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kheiri_K/0/1/0/all/0/1">Kiana Kheiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Karimi_H/0/1/0/all/0/1">Hamid Karimi</a></p>
<p>This study presents a thorough examination of various Generative Pretrained
Transformer (GPT) methodologies in sentiment analysis, specifically in the
context of Task 4 on the SemEval 2017 dataset. Three primary strategies are
employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2)
fine-tuning GPT models, and 3) an inventive approach to embedding
classification. The research yields detailed comparative insights among these
strategies and individual GPT models, revealing their unique strengths and
potential limitations. Additionally, the study compares these GPT-based
methodologies with other contemporary, high-performing models previously used
with the same dataset. The results illustrate the significant superiority of
the GPT approaches in terms of predictive performance, more than 22% in
F1-score compared to the state-of-the-art. Further, the paper addresses common
challenges in sentiment analysis tasks, such as understanding context and
detecting sarcasm. It underscores the enhanced capabilities of the GPT models
to effectively navigate these complexities. Collectively, these findings
highlight the promising potential of GPT models in sentiment analysis, setting
the stage for future research in this field. The code can be found at
https://github.com/DSAatUSU/SentimentGPT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10236">Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models. (arXiv:2307.10236v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuheng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jiayang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhijie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huaming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lei Ma</a></p>
<p>The recent performance leap of Large Language Models (LLMs) opens up new
opportunities across numerous industrial applications and domains. However,
erroneous generations, such as false predictions, misinformation, and
hallucination made by LLMs, have also raised severe concerns for the
trustworthiness of LLMs', especially in safety-, security- and
reliability-sensitive scenarios, potentially hindering real-world adoptions.
While uncertainty estimation has shown its potential for interpreting the
prediction risks made by general machine learning (ML) models, little is known
about whether and to what extent it can help explore an LLM's capabilities and
counteract its undesired behavior. To bridge the gap, in this paper, we
initiate an exploratory study on the risk assessment of LLMs from the lens of
uncertainty. In particular, we experiment with twelve uncertainty estimation
methods and four LLMs on four prominent natural language processing (NLP) tasks
to investigate to what extent uncertainty estimation techniques could help
characterize the prediction risks of LLMs. Our findings validate the
effectiveness of uncertainty estimation for revealing LLMs'
uncertain/non-factual predictions. In addition to general NLP tasks, we
extensively conduct experiments with four LLMs for code generation on two
datasets. We find that uncertainty estimation can potentially uncover buggy
programs generated by LLMs. Insights from our study shed light on future design
and development for reliable LLMs, facilitating further research toward
enhancing the trustworthiness of LLMs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10237">CoNAN: Conditional Neural Aggregation Network For Unconstrained Face Feature Fusion. (arXiv:2307.10237v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jawade_B/0/1/0/all/0/1">Bhavin Jawade</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_D/0/1/0/all/0/1">Deen Dayal Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fedorishin_D/0/1/0/all/0/1">Dennis Fedorishin</a>, <a href="http://arxiv.org/find/cs/1/au:+Setlur_S/0/1/0/all/0/1">Srirangaraj Setlur</a>, <a href="http://arxiv.org/find/cs/1/au:+Govindaraju_V/0/1/0/all/0/1">Venu Govindaraju</a></p>
<p>Face recognition from image sets acquired under unregulated and uncontrolled
settings, such as at large distances, low resolutions, varying viewpoints,
illumination, pose, and atmospheric conditions, is challenging. Face feature
aggregation, which involves aggregating a set of N feature representations
present in a template into a single global representation, plays a pivotal role
in such recognition systems. Existing works in traditional face feature
aggregation either utilize metadata or high-dimensional intermediate feature
representations to estimate feature quality for aggregation. However,
generating high-quality metadata or style information is not feasible for
extremely low-resolution faces captured in long-range and high altitude
settings. To overcome these limitations, we propose a feature distribution
conditioning approach called CoNAN for template aggregation. Specifically, our
method aims to learn a context vector conditioned over the distribution
information of the incoming feature set, which is utilized to weigh the
features based on their estimated informativeness. The proposed method produces
state-of-the-art results on long-range unconstrained face recognition datasets
such as BTS, and DroneSURF, validating the advantages of such an aggregation
strategy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10246">Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey). (arXiv:2307.10246v1 [q-bio.NC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Oota_S/0/1/0/all/0/1">Subba Reddy Oota</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gupta_M/0/1/0/all/0/1">Manish Gupta</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bapi_R/0/1/0/all/0/1">Raju S. Bapi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Jobard_G/0/1/0/all/0/1">Gael Jobard</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Alexandre_F/0/1/0/all/0/1">Frederic Alexandre</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hinaut_X/0/1/0/all/0/1">Xavier Hinaut</a></p>
<p>How does the brain represent different modes of information? Can we design a
system that automatically understands what the user is thinking? Such questions
can be answered by studying brain recordings like functional magnetic resonance
imaging (fMRI). As a first step, the neuroscience community has contributed
several large cognitive neuroscience datasets related to passive
reading/listening/viewing of concept words, narratives, pictures and movies.
Encoding and decoding models using these datasets have also been proposed in
the past two decades. These models serve as additional tools for basic research
in cognitive science and neuroscience. Encoding models aim at generating fMRI
brain representations given a stimulus automatically. They have several
practical applications in evaluating and diagnosing neurological conditions and
thus also help design therapies for brain damage. Decoding models solve the
inverse problem of reconstructing the stimuli given the fMRI. They are useful
for designing brain-machine or brain-computer interfaces. Inspired by the
effectiveness of deep learning models for natural language processing, computer
vision, and speech, recently several neural encoding and decoding models have
been proposed. In this survey, we will first discuss popular representations of
language, vision and speech stimuli, and present a summary of neuroscience
datasets. Further, we will review popular deep learning based encoding and
decoding architectures and note their benefits and limitations. Finally, we
will conclude with a brief summary and discussion about future trends. Given
the large amount of recently published work in the `computational cognitive
neuroscience' community, we believe that this survey nicely organizes the
plethora of work and presents it as a coherent story.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10250">Abductive Reasoning with the GPT-4 Language Model: Case studies from criminal investigation, medical practice, scientific research. (arXiv:2307.10250v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pareschi_R/0/1/0/all/0/1">Remo Pareschi</a></p>
<p>This study evaluates the GPT-4 Large Language Model's abductive reasoning in
complex fields like medical diagnostics, criminology, and cosmology. Using an
interactive interview format, the AI assistant demonstrated reliability in
generating and selecting hypotheses. It inferred plausible medical diagnoses
based on patient data and provided potential causes and explanations in
criminology and cosmology. The results highlight the potential of LLMs in
complex problem-solving and the need for further research to maximize their
practical applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10262">Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotPython. (arXiv:2307.10262v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bartz_Beielstein_T/0/1/0/all/0/1">Thomas Bartz-Beielstein</a></p>
<p>This document provides a comprehensive guide to hyperparameter tuning using
spotPython for scikit-learn, PyTorch, and river. The first part introduces
spotPython's surrogate model-based optimization process, while the second part
focuses on hyperparameter tuning. Several case studies are presented, including
hyperparameter tuning for sklearn models such as Support Vector Classification,
Random Forests, Gradient Boosting (XGB), and K-nearest neighbors (KNN), as well
as a Hoeffding Adaptive Tree Regressor from river. The integration of
spotPython into the PyTorch and PyTorch Lightning training workflow is also
discussed. With a hands-on approach and step-by-step explanations, this
cookbook serves as a practical starting point for anyone interested in
hyperparameter tuning with Python. Highlights include the interplay between
Tensorboard, PyTorch Lightning, spotPython, and river. This publication is
under development, with updates available on the corresponding webpage.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10265">AI empowering research: 10 ways how science can benefit from AI. (arXiv:2307.10265v1 [cs.GL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Franca_C/0/1/0/all/0/1">C&#xe9;sar Fran&#xe7;a</a></p>
<p>This article explores the transformative impact of artificial intelligence
(AI) on scientific research. It highlights ten ways in which AI is
revolutionizing the work of scientists, including powerful referencing tools,
improved understanding of research problems, enhanced research question
generation, optimized research design, stub data generation, data
transformation, advanced data analysis, and AI-assisted reporting. While AI
offers numerous benefits, challenges such as bias, privacy concerns, and the
need for human-AI collaboration must be considered. The article emphasizes that
AI can augment human creativity in science but not replace it.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10267">On the Real-Time Semantic Segmentation of Aphid Clusters in the Wild. (arXiv:2307.10267v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rahman_R/0/1/0/all/0/1">Raiyan Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Indris_C/0/1/0/all/0/1">Christopher Indris</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianxiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kaidong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+McCornack_B/0/1/0/all/0/1">Brian McCornack</a>, <a href="http://arxiv.org/find/cs/1/au:+Flippo_D/0/1/0/all/0/1">Daniel Flippo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharda_A/0/1/0/all/0/1">Ajay Sharda</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanghui Wang</a></p>
<p>Aphid infestations can cause extensive damage to wheat and sorghum fields and
spread plant viruses, resulting in significant yield losses in agriculture. To
address this issue, farmers often rely on chemical pesticides, which are
inefficiently applied over large areas of fields. As a result, a considerable
amount of pesticide is wasted on areas without pests, while inadequate amounts
are applied to areas with severe infestations. The paper focuses on the urgent
need for an intelligent autonomous system that can locate and spray
infestations within complex crop canopies, reducing pesticide use and
environmental impact. We have collected and labeled a large aphid image dataset
in the field, and propose the use of real-time semantic segmentation models to
segment clusters of aphids. A multiscale dataset is generated to allow for
learning the clusters at different scales. We compare the segmentation speeds
and accuracy of four state-of-the-art real-time semantic segmentation models on
the aphid cluster dataset, benchmarking them against nonreal-time models. The
study results show the effectiveness of a real-time solution, which can reduce
inefficient pesticide use and increase crop yields, paving the way towards an
autonomous pest detection system.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10292">The Language Labyrinth: Constructive Critique on the Terminology Used in the AI Discourse. (arXiv:2307.10292v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rehak_R/0/1/0/all/0/1">Rainer Rehak</a></p>
<p>In the interdisciplinary field of artificial intelligence (AI) the problem of
clear terminology is especially momentous. This paper claims, that AI debates
are still characterised by a lack of critical distance to metaphors like
'training', 'learning' or 'deciding'. As consequence, reflections regarding
responsibility or potential use-cases are greatly distorted. Yet, if relevant
decision-makers are convinced that AI can develop an 'understanding' or
properly 'interpret' issues, its regular use for sensitive tasks like deciding
about social benefits or judging court cases looms. The chapter argues its
claim by analysing central notions of the AI debate and tries to contribute by
proposing more fitting terminology and hereby enabling more fruitful debates.
It is a conceptual work at the intersection of critical computer science and
philosophy of language.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10315">Absolutist AI. (arXiv:2307.10315v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Barrington_M/0/1/0/all/0/1">Mitchell Barrington</a></p>
<p>This paper argues that training AI systems with absolute constraints -- which
forbid certain acts irrespective of the amount of value they might produce --
may make considerable progress on many AI safety problems in principle. First,
it provides a guardrail for avoiding the very worst outcomes of misalignment.
Second, it could prevent AIs from causing catastrophes for the sake of very
valuable consequences, such as replacing humans with a much larger number of
beings living at a higher welfare level. Third, it makes systems more
corrigible, allowing creators to make corrective interventions in them, such as
altering their objective functions or shutting them down. And fourth, it helps
systems explore their environment more safely by prohibiting them from
exploring especially dangerous acts. I offer a decision-theoretic formalization
of an absolute constraints, improving on existing models in the literature, and
use this model to prove some results about the training and behavior of
absolutist AIs. I conclude by showing that, although absolutist AIs will not
maximize expected value, they will not be susceptible to behave irrationally,
and they will not (contra coherence arguments) face environmental pressure to
become expected-value maximizers.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10317">FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning. (arXiv:2307.10317v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kao_C/0/1/0/all/0/1">Chia-Hsiang Kao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Chiang Frank Wang</a></p>
<p>Federated Learning (FL) offers a collaborative training framework, allowing
multiple clients to contribute to a shared model without compromising data
privacy. Due to the heterogeneous nature of local datasets, updated client
models may overfit and diverge from one another, commonly known as the problem
of client drift. In this paper, we propose FedBug (Federated Learning with
Bottom-Up Gradual Unfreezing), a novel FL framework designed to effectively
mitigate client drift. FedBug adaptively leverages the client model parameters,
distributed by the server at each global round, as the reference points for
cross-client alignment. Specifically, on the client side, FedBug begins by
freezing the entire model, then gradually unfreezes the layers, from the input
layer to the output layer. This bottom-up approach allows models to train the
newly thawed layers to project data into a latent space, wherein the separating
hyperplanes remain consistent across all clients. We theoretically analyze
FedBug in a novel over-parameterization FL setup, revealing its superior
convergence rate compared to FedAvg. Through comprehensive experiments,
spanning various datasets, training conditions, and network architectures, we
validate the efficacy of FedBug. Our contributions encompass a novel FL
framework, theoretical analysis, and empirical validation, demonstrating the
wide potential and applicability of FedBug.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10318">Eliminating Label Leakage in Tree-Based Vertical Federated Learning. (arXiv:2307.10318v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Takahashi_H/0/1/0/all/0/1">Hideaki Takahashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a></p>
<p>Vertical federated learning (VFL) enables multiple parties with disjoint
features of a common user set to train a machine learning model without sharing
their private data. Tree-based models have become prevalent in VFL due to their
interpretability and efficiency. However, the vulnerability of tree-based VFL
has not been sufficiently investigated. In this study, we first introduce a
novel label inference attack, ID2Graph, which utilizes the sets of record-IDs
assigned to each node (i.e., instance space) to deduce private training labels.
The ID2Graph attack generates a graph structure from training samples, extracts
communities from the graph, and clusters the local dataset using community
information. To counteract label leakage from the instance space, we propose an
effective defense mechanism, ID-LMID, which prevents label leakage by focusing
on mutual information regularization. Comprehensive experiments conducted on
various datasets reveal that the ID2Graph attack presents significant risks to
tree-based models such as Random Forest and XGBoost. Further evaluations on
these benchmarks demonstrate that ID-LMID effectively mitigates label leakage
in such instances.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10404">Interpreting and Correcting Medical Image Classification with PIP-Net. (arXiv:2307.10404v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nauta_M/0/1/0/all/0/1">Meike Nauta</a>, <a href="http://arxiv.org/find/cs/1/au:+Hegeman_J/0/1/0/all/0/1">Johannes H. Hegeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Geerdink_J/0/1/0/all/0/1">Jeroen Geerdink</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlotterer_J/0/1/0/all/0/1">J&#xf6;rg Schl&#xf6;tterer</a>, <a href="http://arxiv.org/find/cs/1/au:+Keulen_M/0/1/0/all/0/1">Maurice van Keulen</a>, <a href="http://arxiv.org/find/cs/1/au:+Seifert_C/0/1/0/all/0/1">Christin Seifert</a></p>
<p>Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10405">Generative Visual Question Answering. (arXiv:2307.10405v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shen_E/0/1/0/all/0/1">Ethan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Scotty Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_B/0/1/0/all/0/1">Bhavesh Kumar</a></p>
<p>Multi-modal tasks involving vision and language in deep learning continue to
rise in popularity and are leading to the development of newer models that can
generalize beyond the extent of their training data. The current models lack
temporal generalization which enables models to adapt to changes in future
data. This paper discusses a viable approach to creating an advanced Visual
Question Answering (VQA) model which can produce successful results on temporal
generalization. We propose a new data set, GenVQA, utilizing images and
captions from the VQAv2 and MS-COCO dataset to generate new images through
stable diffusion. This augmented dataset is then used to test a combination of
seven baseline and cutting edge VQA models. Performance evaluation focuses on
questions mirroring the original VQAv2 dataset, with the answers having been
adjusted to the new images. This paper's purpose is to investigate the
robustness of several successful VQA models to assess their performance on
future data distributions. Model architectures are analyzed to identify common
stylistic choices that improve generalization under temporal distribution
shifts. This research highlights the importance of creating a large-scale
future shifted dataset. This data can enhance the robustness of VQA models,
allowing their future peers to have improved ability to adapt to temporal
distribution shifts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10408">Explaining Autonomous Driving Actions with Visual Question Answering. (arXiv:2307.10408v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Atakishiyev_S/0/1/0/all/0/1">Shahin Atakishiyev</a>, <a href="http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1">Mohammad Salameh</a>, <a href="http://arxiv.org/find/cs/1/au:+Babiker_H/0/1/0/all/0/1">Housam Babiker</a>, <a href="http://arxiv.org/find/cs/1/au:+Goebel_R/0/1/0/all/0/1">Randy Goebel</a></p>
<p>The end-to-end learning ability of self-driving vehicles has achieved
significant milestones over the last decade owing to rapid advances in deep
learning and computer vision algorithms. However, as autonomous driving
technology is a safety-critical application of artificial intelligence (AI),
road accidents and established regulatory principles necessitate the need for
the explainability of intelligent action choices for self-driving vehicles. To
facilitate interpretability of decision-making in autonomous driving, we
present a Visual Question Answering (VQA) framework, which explains driving
actions with question-answering-based causal reasoning. To do so, we first
collect driving videos in a simulation environment using reinforcement learning
(RL) and extract consecutive frames from this log data uniformly for five
selected action categories. Further, we manually annotate the extracted frames
using question-answer pairs as justifications for the actions chosen in each
scenario. Finally, we evaluate the correctness of the VQA-predicted answers for
actions on unseen driving scenes. The empirical results suggest that the VQA
mechanism can provide support to interpret real-time decisions of autonomous
vehicles and help enhance overall driving safety.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10420">GOOSE Algorithm: A Powerful Optimization Tool for Real-World Engineering Challenges and Beyond. (arXiv:2307.10420v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hamad_R/0/1/0/all/0/1">Rebwar Khalid Hamad</a>, <a href="http://arxiv.org/find/cs/1/au:+Rashid_T/0/1/0/all/0/1">Tarik A. Rashid</a></p>
<p>This study proposes the GOOSE algorithm as a novel metaheuristic algorithm
based on the goose's behavior during rest and foraging. The goose stands on one
leg and keeps his balance to guard and protect other individuals in the flock.
The GOOSE algorithm is benchmarked on 19 well-known benchmark test functions,
and the results are verified by a comparative study with genetic algorithm
(GA), particle swarm optimization (PSO), dragonfly algorithm (DA), and fitness
dependent optimizer (FDO). In addition, the proposed algorithm is tested on 10
modern benchmark functions, and the gained results are compared with three
recent algorithms, such as the dragonfly algorithm, whale optimization
algorithm (WOA), and salp swarm algorithm (SSA). Moreover, the GOOSE algorithm
is tested on 5 classical benchmark functions, and the obtained results are
evaluated with six algorithms, such as fitness dependent optimizer (FDO), FOX
optimizer, butterfly optimization algorithm (BOA), whale optimization
algorithm, dragonfly algorithm, and chimp optimization algorithm (ChOA). The
achieved findings attest to the proposed algorithm's superior performance
compared to the other algorithms that were utilized in the current study. The
technique is then used to optimize Welded beam design and Economic Load
Dispatch Problem, three renowned real-world engineering challenges, and the
Pathological IgG Fraction in the Nervous System. The outcomes of the
engineering case studies illustrate how well the suggested approach can
optimize issues that arise in the real-world.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10422">PreDiff: Precipitation Nowcasting with Latent Diffusion Models. (arXiv:2307.10422v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zhihan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xingjian Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Boran Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xiaoyong Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddix_D/0/1/0/all/0/1">Danielle Maddix</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a></p>
<p>Earth system forecasting has traditionally relied on complex physical models
that are computationally expensive and require significant domain expertise. In
the past decade, the unprecedented increase in spatiotemporal Earth observation
data has enabled data-driven forecasting models using deep learning techniques.
These models have shown promise for diverse Earth system forecasting tasks but
either struggle with handling uncertainty or neglect domain-specific prior
knowledge, resulting in averaging possible futures to blurred forecasts or
generating physically implausible predictions. To address these limitations, we
propose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1)
We develop PreDiff, a conditional latent diffusion model capable of
probabilistic forecasts. 2) We incorporate an explicit knowledge control
mechanism to align forecasts with domain-specific physical constraints. This is
achieved by estimating the deviation from imposed constraints at each denoising
step and adjusting the transition distribution accordingly. We conduct
empirical studies on two datasets: N-body MNIST, a synthetic dataset with
chaotic behavior, and SEVIR, a real-world precipitation nowcasting dataset.
Specifically, we impose the law of conservation of energy in N-body MNIST and
anticipated precipitation intensity in SEVIR. Experiments demonstrate the
effectiveness of PreDiff in handling uncertainty, incorporating domain-specific
prior knowledge, and generating forecasts that exhibit high operational
utility.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10434">Learning Formal Specifications from Membership and Preference Queries. (arXiv:2307.10434v1 [cs.FL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1">Ameesh Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazquez_Chanlatte_M/0/1/0/all/0/1">Marcell Vazquez-Chanlatte</a>, <a href="http://arxiv.org/find/cs/1/au:+Junges_S/0/1/0/all/0/1">Sebastian Junges</a>, <a href="http://arxiv.org/find/cs/1/au:+Seshia_S/0/1/0/all/0/1">Sanjit A. Seshia</a></p>
<p>Active learning is a well-studied approach to learning formal specifications,
such as automata. In this work, we extend active specification learning by
proposing a novel framework that strategically requests a combination of
membership labels and pair-wise preferences, a popular alternative to
membership labels. The combination of pair-wise preferences and membership
labels allows for a more flexible approach to active specification learning,
which previously relied on membership labels only. We instantiate our framework
in two different domains, demonstrating the generality of our approach. Our
results suggest that learning from both modalities allows us to robustly and
conveniently identify specifications via membership and preferences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10455">A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect Dataset. (arXiv:2307.10455v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gharaee_Z/0/1/0/all/0/1">Zahra Gharaee</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1">ZeMing Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pellegrino_N/0/1/0/all/0/1">Nicholas Pellegrino</a>, <a href="http://arxiv.org/find/cs/1/au:+Zarubiieva_I/0/1/0/all/0/1">Iuliia Zarubiieva</a>, <a href="http://arxiv.org/find/cs/1/au:+Haurum_J/0/1/0/all/0/1">Joakim Bruslund Haurum</a>, <a href="http://arxiv.org/find/cs/1/au:+Lowe_S/0/1/0/all/0/1">Scott C. Lowe</a>, <a href="http://arxiv.org/find/cs/1/au:+McKeown_J/0/1/0/all/0/1">Jaclyn T.A. McKeown</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_C/0/1/0/all/0/1">Chris C.Y. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+McLeod_J/0/1/0/all/0/1">Joschka McLeod</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yi-Yun C Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Agda_J/0/1/0/all/0/1">Jireh Agda</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratnasingham_S/0/1/0/all/0/1">Sujeevan Ratnasingham</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinke_D/0/1/0/all/0/1">Dirk Steinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_A/0/1/0/all/0/1">Angel X. Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1">Graham W. Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Fieguth_P/0/1/0/all/0/1">Paul Fieguth</a></p>
<p>In an effort to catalog insect biodiversity, we propose a new large dataset
of hand-labelled insect images, the BIOSCAN-Insect Dataset. Each record is
taxonomically classified by an expert, and also has associated genetic
information including raw nucleotide barcode sequences and assigned barcode
index numbers, which are genetically-based proxies for species classification.
This paper presents a curated million-image dataset, primarily to train
computer-vision models capable of providing image-based taxonomic assessment,
however, the dataset also presents compelling characteristics, the study of
which would be of interest to the broader machine learning community. Driven by
the biological nature inherent to the dataset, a characteristic long-tailed
class-imbalance distribution is exhibited. Furthermore, taxonomic labelling is
a hierarchical classification scheme, presenting a highly fine-grained
classification problem at lower levels. Beyond spurring interest in
biodiversity research within the machine learning community, progress on
creating an image-based taxonomic classifier will also further the ultimate
goal of all BIOSCAN research: to lay the foundation for a comprehensive survey
of global biodiversity. This paper introduces the dataset and explores the
classification task through the implementation and analysis of a baseline
classifier.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10458">Complying with the EU AI Act. (arXiv:2307.10458v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Walters_J/0/1/0/all/0/1">Jacintha Walters</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_D/0/1/0/all/0/1">Diptish Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhaumik_D/0/1/0/all/0/1">Debarati Bhaumik</a>, <a href="http://arxiv.org/find/cs/1/au:+Horsman_S/0/1/0/all/0/1">Sophie Horsman</a></p>
<p>The EU AI Act is the proposed EU legislation concerning AI systems. This
paper identifies several categories of the AI Act. Based on this
categorization, a questionnaire is developed that serves as a tool to offer
insights by creating quantitative data. Analysis of the data shows various
challenges for organizations in different compliance categories. The influence
of organization characteristics, such as size and sector, is examined to
determine the impact on compliance. The paper will also share qualitative data
on which questions were prevalent among respondents, both on the content of the
AI Act as the application. The paper concludes by stating that there is still
room for improvement in terms of compliance with the AIA and refers to a
related project that examines a solution to help these organizations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10459">A New Computationally Simple Approach for Implementing Neural Networks with Output Hard Constraints. (arXiv:2307.10459v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Konstantinov_A/0/1/0/all/0/1">Andrei V. Konstantinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Utkin_L/0/1/0/all/0/1">Lev V. Utkin</a></p>
<p>A new computationally simple method of imposing hard convex constraints on
the neural network output values is proposed. The key idea behind the method is
to map a vector of hidden parameters of the network to a point that is
guaranteed to be inside the feasible set defined by a set of constraints. The
mapping is implemented by the additional neural network layer with constraints
for output. The proposed method is simply extended to the case when constraints
are imposed not only on the output vectors, but also on joint constraints
depending on inputs. The projection approach to imposing constraints on outputs
can simply be implemented in the framework of the proposed method. It is shown
how to incorporate different types of constraints into the proposed method,
including linear and quadratic constraints, equality constraints, and dynamic
constraints, constraints in the form of boundaries. An important feature of the
method is its computational simplicity. Complexities of the forward pass of the
proposed neural network layer by linear and quadratic constraints are O(n*m)
and O(n^2*m), respectively, where n is the number of variables, m is the number
of constraints. Numerical experiments illustrate the method by solving
optimization and classification problems. The code implementing the method is
publicly available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10460">A data science axiology: the nature, value, and risks of data science. (arXiv:2307.10460v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Brodie_M/0/1/0/all/0/1">Michael L. Brodie</a></p>
<p>Data science is not a science. It is a research paradigm with an unfathomed
scope, scale, complexity, and power for knowledge discovery that is not
otherwise possible and can be beyond human reasoning. It is changing our world
practically and profoundly already widely deployed in tens of thousands of
applications in every discipline in an AI Arms Race that, due to its
inscrutability, can lead to unfathomed risks. This paper presents an axiology
of data science, its purpose, nature, importance, risks, and value for problem
solving, by exploring and evaluating its remarkable, definitive features. As
data science is in its infancy, this initial, speculative axiology is intended
to aid in understanding and defining data science to recognize its potential
benefits, risks, and open research challenges. AI based data science is
inherently about uncertainty that may be more realistic than our preference for
the certainty of science. Data science will have impacts far beyond knowledge
discovery and will take us into new ways of understanding the world.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10471">Classification of Visualization Types and Perspectives in Patents. (arXiv:2307.10471v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghauri_J/0/1/0/all/0/1">Junaid Ahmed Ghauri</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_Budack_E/0/1/0/all/0/1">Eric M&#xfc;ller-Budack</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a></p>
<p>Due to the swift growth of patent applications each year, information and
multimedia retrieval approaches that facilitate patent exploration and
retrieval are of utmost importance. Different types of visualizations (e.g.,
graphs, technical drawings) and perspectives (e.g., side view, perspective) are
used to visualize details of innovations in patents. The classification of
these images enables a more efficient search and allows for further analysis.
So far, datasets for image type classification miss some important
visualization types for patents. Furthermore, related work does not make use of
recent deep learning approaches including transformers. In this paper, we adopt
state-of-the-art deep learning methods for the classification of visualization
types and perspectives in patent images. We extend the CLEF-IP dataset for
image type classification in patents to ten classes and provide manual ground
truth annotations. In addition, we derive a set of hierarchical classes from a
dataset that provides weakly-labeled data for image perspectives. Experimental
results have demonstrated the feasibility of the proposed approaches. Source
code, models, and dataset will be made publicly available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10472">Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting?. (arXiv:2307.10472v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dige_O/0/1/0/all/0/1">Omkar Dige</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1">Jacob-Junqi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Emerson_D/0/1/0/all/0/1">David Emerson</a>, <a href="http://arxiv.org/find/cs/1/au:+Khattak_F/0/1/0/all/0/1">Faiza Khan Khattak</a></p>
<p>As the breadth and depth of language model applications continue to expand
rapidly, it is increasingly important to build efficient frameworks for
measuring and mitigating the learned or inherited social biases of these
models. In this paper, we present our work on evaluating instruction fine-tuned
language models' ability to identify bias through zero-shot prompting,
including Chain-of-Thought (CoT) prompts. Across LLaMA and its two instruction
fine-tuned versions, Alpaca 7B performs best on the bias identification task
with an accuracy of 56.7%. We also demonstrate that scaling up LLM size and
data diversity could lead to further performance gain. This is a
work-in-progress presenting the first component of our bias mitigation
framework. We will keep updating this work as we get more results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10487">Backdoor Attack against Object Detection with Clean Annotation. (arXiv:2307.10487v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yize Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wenbin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Minhao Cheng</a></p>
<p>Deep neural networks (DNNs) have shown unprecedented success in object
detection tasks. However, it was also discovered that DNNs are vulnerable to
multiple kinds of attacks, including Backdoor Attacks. Through the attack, the
attacker manages to embed a hidden backdoor into the DNN such that the model
behaves normally on benign data samples, but makes attacker-specified judgments
given the occurrence of a predefined trigger. Although numerous backdoor
attacks have been experimented on image classification, backdoor attacks on
object detection tasks have not been properly investigated and explored. As
object detection has been adopted as an important module in multiple
security-sensitive applications such as autonomous driving, backdoor attacks on
object detection could pose even more severe threats. Inspired by the inherent
property of deep learning-based object detectors, we propose a simple yet
effective backdoor attack method against object detection without modifying the
ground truth annotations, specifically focusing on the object disappearance
attack and object generation attack. Extensive experiments and ablation studies
prove the effectiveness of our attack on two benchmark object detection
datasets, PASCAL VOC07+12 and MSCOCO, on which we achieve an attack success
rate of more than 92% with a poison rate of only 5%.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10490">(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bagdasaryan_E/0/1/0/all/0/1">Eugene Bagdasaryan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_T/0/1/0/all/0/1">Tsung-Yin Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nassi_B/0/1/0/all/0/1">Ben Nassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shmatikov_V/0/1/0/all/0/1">Vitaly Shmatikov</a></p>
<p>We demonstrate how images and sounds can be used for indirect prompt and
instruction injection in multi-modal LLMs. An attacker generates an adversarial
perturbation corresponding to the prompt and blends it into an image or audio
recording. When the user asks the (unmodified, benign) model about the
perturbed image or audio, the perturbation steers the model to output the
attacker-chosen text and/or make the subsequent dialog follow the attacker's
instruction. We illustrate this attack with several proof-of-concept examples
targeting LLaVa and PandaGPT.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10491">Markov Decision Processes with Time-Varying Geometric Discounting. (arXiv:2307.10491v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gan_J/0/1/0/all/0/1">Jiarui Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennes_A/0/1/0/all/0/1">Annika Hennes</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumdar_R/0/1/0/all/0/1">Rupak Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandal_D/0/1/0/all/0/1">Debmalya Mandal</a>, <a href="http://arxiv.org/find/cs/1/au:+Radanovic_G/0/1/0/all/0/1">Goran Radanovic</a></p>
<p>Canonical models of Markov decision processes (MDPs) usually consider
geometric discounting based on a constant discount factor. While this standard
modeling approach has led to many elegant results, some recent studies indicate
the necessity of modeling time-varying discounting in certain applications.
This paper studies a model of infinite-horizon MDPs with time-varying discount
factors. We take a game-theoretic perspective -- whereby each time step is
treated as an independent decision maker with their own (fixed) discount factor
-- and we study the subgame perfect equilibrium (SPE) of the resulting game as
well as the related algorithmic problems. We present a constructive proof of
the existence of an SPE and demonstrate the EXPTIME-hardness of computing an
SPE. We also turn to the approximate notion of $\epsilon$-SPE and show that an
$\epsilon$-SPE exists under milder assumptions. An algorithm is presented to
compute an $\epsilon$-SPE, of which an upper bound of the time complexity, as a
function of the convergence property of the time-varying discount factor, is
provided.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10512">IvyGPT: InteractiVe Chinese pathwaY language model in medical domain. (arXiv:2307.10512v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rongsheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1">Yaofei Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_C/0/1/0/all/0/1">ChanTong Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiexi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiangsheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaohong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_P/0/1/0/all/0/1">Patrick Cheong-Iao Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Tao Tan</a></p>
<p>General large language models (LLMs) such as ChatGPT have shown remarkable
success. However, such LLMs have not been widely adopted for medical purposes,
due to poor accuracy and inability to provide medical advice. We propose
IvyGPT, an LLM based on LLaMA that is trained and fine-tuned with high-quality
medical question-answer (QA) instances and Reinforcement Learning from Human
Feedback (RLHF). After supervised fine-tuning, IvyGPT has good multi-turn
conversation capabilities, but it cannot perform like a doctor in other
aspects, such as comprehensive diagnosis. Through RLHF, IvyGPT can output
richer diagnosis and treatment answers that are closer to human. In the
training, we used QLoRA to train 33 billion parameters on a small number of
NVIDIA A100 (80GB) GPUs. Experimental results show that IvyGPT has outperformed
other medical GPT models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10514">Building Socio-culturally Inclusive Stereotype Resources with Community Engagement. (arXiv:2307.10514v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dev_S/0/1/0/all/0/1">Sunipa Dev</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_J/0/1/0/all/0/1">Jaya Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Tewari_D/0/1/0/all/0/1">Dinesh Tewari</a>, <a href="http://arxiv.org/find/cs/1/au:+Dave_S/0/1/0/all/0/1">Shachi Dave</a>, <a href="http://arxiv.org/find/cs/1/au:+Prabhakaran_V/0/1/0/all/0/1">Vinodkumar Prabhakaran</a></p>
<p>With rapid development and deployment of generative language models in global
settings, there is an urgent need to also scale our measurements of harm, not
just in the number and types of harms covered, but also how well they account
for local cultural contexts, including marginalized identities and the social
biases experienced by them. Current evaluation paradigms are limited in their
abilities to address this, as they are not representative of diverse, locally
situated but global, socio-cultural perspectives. It is imperative that our
evaluation resources are enhanced and calibrated by including people and
experiences from different cultures and societies worldwide, in order to
prevent gross underestimations or skews in measurements of harm. In this work,
we demonstrate a socio-culturally aware expansion of evaluation resources in
the Indian societal context, specifically for the harm of stereotyping. We
devise a community engaged effort to build a resource which contains
stereotypes for axes of disparity that are uniquely present in India. The
resultant resource increases the number of stereotypes known for and in the
Indian context by over 1000 stereotypes across many unique identities. We also
demonstrate the utility and effectiveness of such expanded resources for
evaluations of language models. CONTENT WARNING: This paper contains examples
of stereotypes that may be offensive.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10529">Fast Unsupervised Deep Outlier Model Selection with Hypernetworks. (arXiv:2307.10529v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xueying Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yue Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1">Leman Akoglu</a></p>
<p>Outlier detection (OD) finds many applications with a rich literature of
numerous techniques. Deep neural network based OD (DOD) has seen a recent surge
of attention thanks to the many advances in deep learning. In this paper, we
consider a critical-yet-understudied challenge with unsupervised DOD, that is,
effective hyperparameter (HP) tuning/model selection. While several prior work
report the sensitivity of OD models to HPs, it becomes ever so critical for the
modern DOD models that exhibit a long list of HPs. We introduce HYPER for
tuning DOD models, tackling two fundamental challenges: (1) validation without
supervision (due to lack of labeled anomalies), and (2) efficient search of the
HP/model space (due to exponential growth in the number of HPs). A key idea is
to design and train a novel hypernetwork (HN) that maps HPs onto optimal
weights of the main DOD model. In turn, HYPER capitalizes on a single HN that
can dynamically generate weights for many DOD models (corresponding to varying
HPs), which offers significant speed-up. In addition, it employs meta-learning
on historical OD tasks with labels to train a proxy validation function,
likewise trained with our proposed HN efficiently. Extensive experiments on 35
OD tasks show that HYPER achieves high performance against 8 baselines with
significant efficiency gains.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10543">TREA: Tree-Structure Reasoning Schema for Conversational Recommendation. (arXiv:2307.10543v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wendi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1">Xiaoye Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xian-Ling Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Ye Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Wenfeng Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dangyang Chen</a></p>
<p>Conversational recommender systems (CRS) aim to timely trace the dynamic
interests of users through dialogues and generate relevant responses for item
recommendations. Recently, various external knowledge bases (especially
knowledge graphs) are incorporated into CRS to enhance the understanding of
conversation contexts. However, recent reasoning-based models heavily rely on
simplified structures such as linear structures or fixed-hierarchical
structures for causality reasoning, hence they cannot fully figure out
sophisticated relationships among utterances with external knowledge. To
address this, we propose a novel Tree structure Reasoning schEmA named TREA.
TREA constructs a multi-hierarchical scalable tree as the reasoning structure
to clarify the causal relationships between mentioned entities, and fully
utilizes historical conversations to generate more reasonable and suitable
responses for recommended results. Extensive experiments on two public CRS
datasets have demonstrated the effectiveness of our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10549">Dynamic Large Language Models on Blockchains. (arXiv:2307.10549v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yuanhao Gong</a></p>
<p>Training and deploying the large language models requires a large mount of
computational resource because the language models contain billions of
parameters and the text has thousands of tokens. Another problem is that the
large language models are static. They are fixed after the training process. To
tackle these issues, in this paper, we propose to train and deploy the dynamic
large language model on blockchains, which have high computation performance
and are distributed across a network of computers. A blockchain is a secure,
decentralized, and transparent system that allows for the creation of a
tamper-proof ledger for transactions without the need for intermediaries. The
dynamic large language models can continuously learn from the user input after
the training process. Our method provides a new way to develop the large
language models and also sheds a light on the next generation artificial
intelligence systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10551">PPN: Parallel Pointer-based Network for Key Information Extraction with Complex Layouts. (arXiv:2307.10551v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wei_K/0/1/0/all/0/1">Kaiwen Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jie Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1">Yangyang Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Fubang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yating Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changlong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xin Zhang</a></p>
<p>Key Information Extraction (KIE) is a challenging multimodal task that aims
to extract structured value semantic entities from visually rich documents.
Although significant progress has been made, there are still two major
challenges that need to be addressed. Firstly, the layout of existing datasets
is relatively fixed and limited in the number of semantic entity categories,
creating a significant gap between these datasets and the complex real-world
scenarios. Secondly, existing methods follow a two-stage pipeline strategy,
which may lead to the error propagation problem. Additionally, they are
difficult to apply in situations where unseen semantic entity categories
emerge. To address the first challenge, we propose a new large-scale
human-annotated dataset named Complex Layout form for key information
EXtraction (CLEX), which consists of 5,860 images with 1,162 semantic entity
categories. To solve the second challenge, we introduce Parallel Pointer-based
Network (PPN), an end-to-end model that can be applied in zero-shot and
few-shot scenarios. PPN leverages the implicit clues between semantic entities
to assist extracting, and its parallel extraction mechanism allows it to
extract multiple results simultaneously and efficiently. Experiments on the
CLEX dataset demonstrate that PPN outperforms existing state-of-the-art methods
while also offering a much faster inference speed.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10554">EMQ: Evolving Training-free Proxies for Automated Mixed Precision Quantization. (arXiv:2307.10554v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dong_P/0/1/0/all/0/1">Peijie Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lujun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zimian Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_X/0/1/0/all/0/1">Xin Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhiliang Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Hengyue Pan</a></p>
<p>Mixed-Precision Quantization~(MQ) can achieve a competitive
accuracy-complexity trade-off for models. Conventional training-based search
methods require time-consuming candidate training to search optimized per-layer
bit-width configurations in MQ. Recently, some training-free approaches have
presented various MQ proxies and significantly improve search efficiency.
However, the correlation between these proxies and quantization accuracy is
poorly understood. To address the gap, we first build the MQ-Bench-101, which
involves different bit configurations and quantization results. Then, we
observe that the existing training-free proxies perform weak correlations on
the MQ-Bench-101. To efficiently seek superior proxies, we develop an automatic
search of proxies framework for MQ via evolving algorithms. In particular, we
devise an elaborate search space involving the existing proxies and perform an
evolution search to discover the best correlated MQ proxy. We proposed a
diversity-prompting selection strategy and compatibility screening protocol to
avoid premature convergence and improve search efficiency. In this way, our
Evolving proxies for Mixed-precision Quantization~(EMQ) framework allows the
auto-generation of proxies without heavy tuning and expert knowledge. Extensive
experiments on ImageNet with various ResNet and MobileNet families demonstrate
that our EMQ obtains superior performance than state-of-the-art mixed-precision
methods at a significantly reduced cost. The code will be released.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10559">Air Traffic Controller Workload Level Prediction using Conformalized Dynamical Graph Learning. (arXiv:2307.10559v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">Yutian Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jueming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lieber_C/0/1/0/all/0/1">Christopher S. Lieber</a>, <a href="http://arxiv.org/find/cs/1/au:+Cooke_N/0/1/0/all/0/1">Nancy J. Cooke</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongming Liu</a></p>
<p>Air traffic control (ATC) is a safety-critical service system that demands
constant attention from ground air traffic controllers (ATCos) to maintain
daily aviation operations. The workload of the ATCos can have negative effects
on operational safety and airspace usage. To avoid overloading and ensure an
acceptable workload level for the ATCos, it is important to predict the ATCos'
workload accurately for mitigation actions. In this paper, we first perform a
review of research on ATCo workload, mostly from the air traffic perspective.
Then, we briefly introduce the setup of the human-in-the-loop (HITL)
simulations with retired ATCos, where the air traffic data and workload labels
are obtained. The simulations are conducted under three Phoenix approach
scenarios while the human ATCos are requested to self-evaluate their workload
ratings (i.e., low-1 to high-7). Preliminary data analysis is conducted. Next,
we propose a graph-based deep-learning framework with conformal prediction to
identify the ATCo workload levels. The number of aircraft under the
controller's control varies both spatially and temporally, resulting in
dynamically evolving graphs. The experiment results suggest that (a) besides
the traffic density feature, the traffic conflict feature contributes to the
workload prediction capabilities (i.e., minimum horizontal/vertical separation
distance); (b) directly learning from the spatiotemporal graph layout of
airspace with graph neural network can achieve higher prediction accuracy,
compare to hand-crafted traffic complexity features; (c) conformal prediction
is a valuable tool to further boost model prediction accuracy, resulting a
range of predicted workload labels. The code used is available at
\href{https://github.com/ymlasu/para-atm-collection/blob/master/air-traffic-prediction/ATC-Workload-Prediction/}{$\mathsf{Link}$}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10563">FACADE: A Framework for Adversarial Circuit Anomaly Detection and Evaluation. (arXiv:2307.10563v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pai_D/0/1/0/all/0/1">Dhruv Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1">Andres Carranza</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaeffer_R/0/1/0/all/0/1">Rylan Schaeffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Tandon_A/0/1/0/all/0/1">Arnuv Tandon</a>, <a href="http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1">Sanmi Koyejo</a></p>
<p>We present FACADE, a novel probabilistic and geometric framework designed for
unsupervised mechanistic anomaly detection in deep neural networks. Its primary
goal is advancing the understanding and mitigation of adversarial attacks.
FACADE aims to generate probabilistic distributions over circuits, which
provide critical insights to their contribution to changes in the manifold
properties of pseudo-classes, or high-dimensional modes in activation space,
yielding a powerful tool for uncovering and combating adversarial attacks. Our
approach seeks to improve model robustness, enhance scalable model oversight,
and demonstrates promising applications in real-world deployment settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10569">Deceptive Alignment Monitoring. (arXiv:2307.10569v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1">Andres Carranza</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_D/0/1/0/all/0/1">Dhruv Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaeffer_R/0/1/0/all/0/1">Rylan Schaeffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Tandon_A/0/1/0/all/0/1">Arnuv Tandon</a>, <a href="http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1">Sanmi Koyejo</a></p>
<p>As the capabilities of large machine learning models continue to grow, and as
the autonomy afforded to such models continues to expand, the spectre of a new
adversary looms: the models themselves. The threat that a model might behave in
a seemingly reasonable manner, while secretly and subtly modifying its behavior
for ulterior reasons is often referred to as deceptive alignment in the AI
Safety &amp; Alignment communities. Consequently, we call this new direction
Deceptive Alignment Monitoring. In this work, we identify emerging directions
in diverse machine learning subfields that we believe will become increasingly
important and intertwined in the near future for deceptive alignment
monitoring, and we argue that advances in these fields present both long-term
challenges and new research opportunities. We conclude by advocating for
greater involvement by the adversarial machine learning community in these
emerging directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10573">Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting. (arXiv:2307.10573v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schaeffer_R/0/1/0/all/0/1">Rylan Schaeffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pistunova_K/0/1/0/all/0/1">Kateryna Pistunova</a>, <a href="http://arxiv.org/find/cs/1/au:+Khanna_S/0/1/0/all/0/1">Samar Khanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Consul_S/0/1/0/all/0/1">Sarthak Consul</a>, <a href="http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1">Sanmi Koyejo</a></p>
<p>Language models can be prompted to reason through problems in a manner that
significantly improves performance. However, \textit{why} such prompting
improves performance is unclear. Recent work showed that using logically
\textit{invalid} Chain-of-Thought (CoT) prompting improves performance almost
as much as logically \textit{valid} CoT prompting, and that editing CoT prompts
to replace problem-specific information with abstract information or
out-of-distribution information typically doesn't harm performance. Critics
have responded that these findings are based on too few and too easy tasks to
draw meaningful conclusions. To resolve this dispute, we test whether logically
invalid CoT prompts offer the same level of performance gains as logically
valid prompts on the hardest tasks in the BIG-Bench benchmark, termed BIG-Bench
Hard (BBH). We find that the logically \textit{invalid} reasoning prompts do
indeed achieve similar performance gains on BBH tasks as logically valid
reasoning prompts. We also discover that some CoT prompts used by previous
works contain logical errors. This suggests that covariates beyond logically
valid reasoning are responsible for performance improvements.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10574">Adaptive Control of Resource Flow to Optimize Construction Work and Cash Flow via Online Deep Reinforcement Learning. (arXiv:2307.10574v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Can Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jia-Rui Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhiliang Ma</a></p>
<p>Due to complexity and dynamics of construction work, resource, and cash
flows, poor management of them usually leads to time and cost overruns,
bankruptcy, even project failure. Existing approaches in construction failed to
achieve optimal control of resource flow in a dynamic environment with
uncertainty. Therefore, this paper introducess a model and method to adaptive
control the resource flows to optimize the work and cash flows of construction
projects. First, a mathematical model based on a partially observable Markov
decision process is established to formulate the complex interactions of
construction work, resource, and cash flows as well as uncertainty and
variability of diverse influence factors. Meanwhile, to efficiently find the
optimal solutions, a deep reinforcement learning (DRL) based method is
introduced to realize the continuous adaptive optimal control of labor and
material flows, thereby optimizing the work and cash flows. To assist the
training process of DRL, a simulator based on discrete event simulation is also
developed to mimic the dynamic features and external environments of a project.
Experiments in simulated scenarios illustrate that our method outperforms the
vanilla empirical method and genetic algorithm, possesses remarkable capability
in diverse projects and external environments, and a hybrid agent of DRL and
empirical method leads to the best result. This paper contributes to adaptive
control and optimization of coupled work, resource, and cash flows, and may
serve as a step stone for adopting DRL technology in construction project
management.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10575">Boosting Federated Learning Convergence with Prototype Regularization. (arXiv:2307.10575v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Huy Q. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1">Choong Seon Hong</a></p>
<p>As a distributed machine learning technique, federated learning (FL) requires
clients to collaboratively train a shared model with an edge server without
leaking their local data. However, the heterogeneous data distribution among
clients often leads to a decrease in model performance. To tackle this issue,
this paper introduces a prototype-based regularization strategy to address the
heterogeneity in the data distribution. Specifically, the regularization
process involves the server aggregating local prototypes from distributed
clients to generate a global prototype, which is then sent back to the
individual clients to guide their local training. The experimental results on
MNIST and Fashion-MNIST show that our proposal achieves improvements of 3.3%
and 8.9% in average test accuracy, respectively, compared to the most popular
baseline FedAvg. Furthermore, our approach has a fast convergence rate in
heterogeneous settings.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10577">Ethosight: A Joint-Embedding Based System for Nuanced Perception Using Contextual Label Affinity Metric and Reasoning Based Iterative Learning. (arXiv:2307.10577v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1">Hugo Latapie</a>, <a href="http://arxiv.org/find/cs/1/au:+Thorisson_K/0/1/0/all/0/1">Kristinn R. Thorisson</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrosyan_V/0/1/0/all/0/1">Vahagn Petrosyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammer_P/0/1/0/all/0/1">Patrick Hammer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kynoch_B/0/1/0/all/0/1">Brandon Kynoch</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hanning Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tangrui Li</a></p>
<p>Traditional computer vision models often require extensive manual effort for
data acquisition and validation, particularly when detecting subtle behavioral
nuances or events. The difficulty in distinguishing routine behaviors from
potential risks in real-world applications, like differentiating routine
shopping from potential shoplifting, further complicates the process.
</p>
<p>We present Ethosight, a novel zero-shot computer vision algorithm. Ethosight
eradicates the need for pre-existing symbolic knowledge, initiating from a
clean slate based on user requirements and semantic knowledge of interest.
Using localized label affinity calculations and a reasoning-guided iterative
learning loop, Ethosight infers scene details and iteratively refines the label
set. Reasoning mechanisms can be derived from large language models like GPT4,
symbolic reasoners like OpenNARS, or hybrid systems.
</p>
<p>Ethosight further capitalizes on the capabilities of a pre-trained
multi-modal model, ImageBind, generating accurate semantic knowledge of images
within a few cycles. It successfully captures both explicit and nuanced
elements efficiently. We also introduce the implementation of Korzybski's
"time-binding" concept in machines, which allows for generational learning and
knowledge sharing across deployments.
</p>
<p>Our evaluations demonstrate Ethosight's efficacy across 40 complex use cases.
It has exhibited an exceptional ability to discern new areas of interest,
consistently generating high-affinity scores within the top five labels from a
set of a thousand. Tests conducted across diverse environments attest to
Ethosight's robust performance. Detailed results and case studies within the
main body of this paper and an appendix underscore a promising trajectory
towards enhancing the adaptability and resilience of computer vision models in
detecting and extracting subtle and nuanced behaviors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10588">Forecasting Battery Electric Vehicle Charging Behavior: A Deep Learning Approach Equipped with Micro-Clustering and SMOTE Techniques. (arXiv:2307.10588v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tayarani_H/0/1/0/all/0/1">Hanif Tayarani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramadoss_T/0/1/0/all/0/1">Trisha V. Ramadoss</a>, <a href="http://arxiv.org/find/cs/1/au:+Karanam_V/0/1/0/all/0/1">Vaishnavi Karanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tal_G/0/1/0/all/0/1">Gil Tal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nitta_C/0/1/0/all/0/1">Christopher Nitta</a></p>
<p>Energy systems, climate change, and public health are among the primary
reasons for moving toward electrification in transportation. Transportation
electrification is being promoted worldwide to reduce emissions. As a result,
many automakers will soon start making only battery electric vehicles (BEVs).
BEV adoption rates are rising in California, mainly due to climate change and
air pollution concerns. While great for climate and pollution goals, improperly
managed BEV charging can lead to insufficient charging infrastructure and power
outages. This study develops a novel Micro Clustering Deep Neural Network
(MCDNN), an artificial neural network algorithm that is highly effective at
learning BEVs trip and charging data to forecast BEV charging events,
information that is essential for electricity load aggregators and utility
managers to provide charging stations and electricity capacity effectively. The
MCDNN is configured using a robust dataset of trips and charges that occurred
in California between 2015 and 2020 from 132 BEVs, spanning 5 BEV models for a
total of 1570167 vehicle miles traveled. The numerical findings revealed that
the proposed MCDNN is more effective than benchmark approaches in this field,
such as support vector machine, k nearest neighbors, decision tree, and other
neural network-based models in predicting the charging events.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10590">Boundary State Generation for Testing and Improvement of Autonomous Driving Systems. (arXiv:2307.10590v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Biagiola_M/0/1/0/all/0/1">Matteo Biagiola</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonella_P/0/1/0/all/0/1">Paolo Tonella</a></p>
<p>Recent advances in Deep Neural Networks (DNNs) and sensor technologies are
enabling autonomous driving systems (ADSs) with an ever-increasing level of
autonomy. However, assessing their dependability remains a critical concern.
State-of-the-art ADS testing approaches modify the controllable attributes of a
simulated driving environment until the ADS misbehaves. Such approaches have
two main drawbacks: (1) modifications to the simulated environment might not be
easily transferable to the in-field test setting (e.g., changing the road
shape); (2) environment instances in which the ADS is successful are discarded,
despite the possibility that they could contain hidden driving conditions in
which the ADS may misbehave.
</p>
<p>In this paper, we present GenBo (GENerator of BOundary state pairs), a novel
test generator for ADS testing. GenBo mutates the driving conditions of the ego
vehicle (position, velocity and orientation), collected in a failure-free
environment instance, and efficiently generates challenging driving conditions
at the behavior boundary (i.e., where the model starts to misbehave) in the
same environment. We use such boundary conditions to augment the initial
training dataset and retrain the DNN model under test. Our evaluation results
show that the retrained model has up to 16 higher success rate on a separate
set of evaluation tracks with respect to the original DNN model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10594">Exploiting Structure for Optimal Multi-Agent Bayesian Decentralized Estimation. (arXiv:2307.10594v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Funk_C/0/1/0/all/0/1">Christopher Funk</a>, <a href="http://arxiv.org/find/cs/1/au:+Dagan_O/0/1/0/all/0/1">Ofer Dagan</a>, <a href="http://arxiv.org/find/cs/1/au:+Noack_B/0/1/0/all/0/1">Benjamin Noack</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1">Nisar R. Ahmed</a></p>
<p>A key challenge in Bayesian decentralized data fusion is the `rumor
propagation' or `double counting' phenomenon, where previously sent data
circulates back to its sender. It is often addressed by approximate methods
like covariance intersection (CI) which takes a weighted average of the
estimates to compute the bound. The problem is that this bound is not tight,
i.e. the estimate is often over-conservative. In this paper, we show that by
exploiting the probabilistic independence structure in multi-agent
decentralized fusion problems a tighter bound can be found using (i) an
expansion to the CI algorithm that uses multiple (non-monolithic) weighting
factors instead of one (monolithic) factor in the original CI and (ii) a
general optimization scheme that is able to compute optimal bounds and fully
exploit an arbitrary dependency structure. We compare our methods and show that
on a simple problem, they converge to the same solution. We then test our new
non-monolithic CI algorithm on a large-scale target tracking simulation and
show that it achieves a tighter bound and a more accurate estimate compared to
the original monolithic CI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10600">Challenges and Solutions in AI for All. (arXiv:2307.10600v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shams_R/0/1/0/all/0/1">Rifat Ara Shams</a>, <a href="http://arxiv.org/find/cs/1/au:+Zowghi_D/0/1/0/all/0/1">Didar Zowghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bano_M/0/1/0/all/0/1">Muneera Bano</a></p>
<p>Artificial Intelligence (AI)'s pervasive presence and variety necessitate
diversity and inclusivity (D&amp;I) principles in its design for fairness, trust,
and transparency. Yet, these considerations are often overlooked, leading to
issues of bias, discrimination, and perceived untrustworthiness. In response,
we conducted a Systematic Review to unearth challenges and solutions relating
to D&amp;I in AI. Our rigorous search yielded 48 research articles published
between 2017 and 2022. Open coding of these papers revealed 55 unique
challenges and 33 solutions for D&amp;I in AI, as well as 24 unique challenges and
23 solutions for enhancing such practices using AI. This study, by offering a
deeper understanding of these issues, will enlighten researchers and
practitioners seeking to integrate these principles into future AI systems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10616">Heterogeneous Federated Learning: State-of-the-art and Research Challenges. (arXiv:2307.10616v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Mang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xiuwen Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bo Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuen_P/0/1/0/all/0/1">Pong C. Yuen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a></p>
<p>Federated learning (FL) has drawn increasing attention owing to its potential
use in large-scale industrial applications. Existing federated learning works
mainly focus on model homogeneous settings. However, practical federated
learning typically faces the heterogeneity of data distributions, model
architectures, network environments, and hardware devices among participant
clients. Heterogeneous Federated Learning (HFL) is much more challenging, and
corresponding solutions are diverse and complex. Therefore, a systematic survey
on this topic about the research challenges and state-of-the-art is essential.
In this survey, we firstly summarize the various research challenges in HFL
from five aspects: statistical heterogeneity, model heterogeneity,
communication heterogeneity, device heterogeneity, and additional challenges.
In addition, recent advances in HFL are reviewed and a new taxonomy of existing
HFL methods is proposed with an in-depth analysis of their pros and cons. We
classify existing methods from three different levels according to the HFL
procedure: data-level, model-level, and server-level. Finally, several critical
and promising future research directions in HFL are discussed, which may
facilitate further developments in this field. A periodically updated
collection on HFL is available at https://github.com/marswhu/HFL_Survey.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10617">Detecting deceptive reviews using text classification. (arXiv:2307.10617v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Baby_A/0/1/0/all/0/1">Anusuya Baby</a></p>
<p>In recent years, online reviews play a vital role for promoting any kind of
product or services. Businesses may embed fake reviews in order to attract
customers to purchase their products. They may even highlight the benefits of
their own product or criticize the competition's product. Marketers,
advertisers, and other online business users have incentive to create fake
positive reviews for products which they want to promote or give fake negative
reviews for products which they really don't like. So now-a-days writing a
deceptive review is inevitable thing for promoting their own business or
degrading competitor's reputation. Thus, identifying deceptive reviews is an
intense and on-going research area. This research paper proposes machine
learning model approach to identify deceptive reviews. The paper investigates
the performance of the several experiments done on a Deceptive Opinion Spam
Corpus dataset of restaurants reviews. We developed a n-gram model and max
features to identify deceptive contents with a particular focus on fake
reviews. Further, we conduct a benchmark study to investigate the performance
of two different features extraction techniques and apply five machine learning
classification techniques. The experimental results show that passive
aggressive classifier outperforms other algorithms, and it reaches the highest
accuracy not only in text classification but also to fake reviews. We also
study the data augmentation and implement different deep learning techniques.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10631">Pluvio: Assembly Clone Search for Out-of-domain Architectures and Libraries through Transfer Learning and Conditional Variational Information Bottleneck. (arXiv:2307.10631v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zhiwei Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Steven H. H. Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Alaca_F/0/1/0/all/0/1">Furkan Alaca</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_B/0/1/0/all/0/1">Benjamin C. M. Fung</a>, <a href="http://arxiv.org/find/cs/1/au:+Charland_P/0/1/0/all/0/1">Philippe Charland</a></p>
<p>The practice of code reuse is crucial in software development for a faster
and more efficient development lifecycle. In reality, however, code reuse
practices lack proper control, resulting in issues such as vulnerability
propagation and intellectual property infringements. Assembly clone search, a
critical shift-right defence mechanism, has been effective in identifying
vulnerable code resulting from reuse in released executables. Recent studies on
assembly clone search demonstrate a trend towards using machine learning-based
methods to match assembly code variants produced by different toolchains.
However, these methods are limited to what they learn from a small number of
toolchain variants used in training, rendering them inapplicable to unseen
architectures and their corresponding compilation toolchain variants.
</p>
<p>This paper presents the first study on the problem of assembly clone search
with unseen architectures and libraries. We propose incorporating human common
knowledge through large-scale pre-trained natural language models, in the form
of transfer learning, into current learning-based approaches for assembly clone
search. Transfer learning can aid in addressing the limitations of the existing
approaches, as it can bring in broader knowledge from human experts in assembly
code. We further address the sequence limit issue by proposing a reinforcement
learning agent to remove unnecessary and redundant tokens. Coupled with a new
Variational Information Bottleneck learning strategy, the proposed system
minimizes the reliance on potential indicators of architectures and
optimization settings, for a better generalization of unseen architectures. We
simulate the unseen architecture clone search scenarios and the experimental
results show the effectiveness of the proposed approach against the
state-of-the-art solutions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10635">SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models. (arXiv:2307.10635v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Ziniu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanqiao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jieyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramaniam_S/0/1/0/all/0/1">Satyen Subramaniam</a>, <a href="http://arxiv.org/find/cs/1/au:+Loomba_A/0/1/0/all/0/1">Arjun R. Loomba</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shichang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yizhou Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a></p>
<p>Recent advances in large language models (LLMs) have demonstrated notable
progress on many mathematical benchmarks. However, most of these benchmarks
only feature problems grounded in junior and senior high school subjects,
contain only multiple-choice questions, and are confined to a limited scope of
elementary arithmetic operations. To address these issues, this paper
introduces an expansive benchmark suite SciBench that aims to systematically
examine the reasoning capabilities required for complex scientific problem
solving. SciBench contains two carefully curated datasets: an open set
featuring a range of collegiate-level scientific problems drawn from
mathematics, chemistry, and physics textbooks, and a closed set comprising
problems from undergraduate-level exams in computer science and mathematics.
Based on the two datasets, we conduct an in-depth benchmark study of two
representative LLMs with various prompting strategies. The results reveal that
current LLMs fall short of delivering satisfactory performance, with an overall
score of merely 35.80%. Furthermore, through a detailed user study, we
categorize the errors made by LLMs into ten problem-solving abilities. Our
analysis indicates that no single prompting strategy significantly outperforms
others and some strategies that demonstrate improvements in certain
problem-solving skills result in declines in other skills. We envision that
SciBench will catalyze further developments in the reasoning abilities of LLMs,
thereby ultimately contributing to scientific research and discovery.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10680">A Personalized Recommender System Based-on Knowledge Graph Embeddings. (arXiv:2307.10680v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Ngoc Luyen Le</a> (Heudiasyc), <a href="http://arxiv.org/find/cs/1/au:+Abel_M/0/1/0/all/0/1">Marie-H&#xe9;l&#xe8;ne Abel</a> (Heudiasyc), <a href="http://arxiv.org/find/cs/1/au:+Gouspillou_P/0/1/0/all/0/1">Philippe Gouspillou</a></p>
<p>Knowledge graphs have proven to be effective for modeling entities and their
relationships through the use of ontologies. The recent emergence in interest
for using knowledge graphs as a form of information modeling has led to their
increased adoption in recommender systems. By incorporating users and items
into the knowledge graph, these systems can better capture the implicit
connections between them and provide more accurate recommendations. In this
paper, we investigate and propose the construction of a personalized
recommender system via knowledge graphs embedding applied to the vehicle
purchase/sale domain. The results of our experimentation demonstrate the
efficacy of the proposed method in providing relevant recommendations that are
consistent with individual users.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10688">Bounded Combinatorial Reconfiguration with Answer Set Programming. (arXiv:2307.10688v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yamada_Y/0/1/0/all/0/1">Yuya Yamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Banbara_M/0/1/0/all/0/1">Mutsunori Banbara</a>, <a href="http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1">Katsumi Inoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaub_T/0/1/0/all/0/1">Torsten Schaub</a></p>
<p>We develop an approach called bounded combinatorial reconfiguration for
solving combinatorial reconfiguration problems based on Answer Set Programming
(ASP). The general task is to study the solution spaces of source combinatorial
problems and to decide whether or not there are sequences of feasible solutions
that have special properties. The resulting recongo solver covers all metrics
of the solver track in the most recent international competition on
combinatorial reconfiguration (CoRe Challenge 2022). recongo ranked first in
the shortest metric of the single-engine solvers track. In this paper, we
present the design and implementation of bounded combinatorial reconfiguration,
and present an ASP encoding of the independent set reconfiguration problem that
is one of the most studied combinatorial reconfiguration problems. Finally, we
present empirical analysis considering all instances of CoRe Challenge 2022.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10693">Towards an architectural framework for intelligent virtual agents using probabilistic programming. (arXiv:2307.10693v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Andreev_A/0/1/0/all/0/1">Anton Andreev</a> (GIPSA-Services), <a href="http://arxiv.org/find/cs/1/au:+Cattan_G/0/1/0/all/0/1">Gr&#xe9;goire Cattan</a></p>
<p>We present a new framework called KorraAI for conceiving and building
embodied conversational agents (ECAs). Our framework models ECAs' behavior
considering contextual information, for example, about environment and
interaction time, and uncertain information provided by the human interaction
partner. Moreover, agents built with KorraAI can show proactive behavior, as
they can initiate interactions with human partners. For these purposes, KorraAI
exploits probabilistic programming. Probabilistic models in KorraAI are used to
model its behavior and interactions with the user. They enable adaptation to
the user's preferences and a certain degree of indeterminism in the ECAs to
achieve more natural behavior. Human-like internal states, such as moods,
preferences, and emotions (e.g., surprise), can be modeled in KorraAI with
distributions and Bayesian networks. These models can evolve over time, even
without interaction with the user. ECA models are implemented as plugins and
share a common interface. This enables ECA designers to focus more on the
character they are modeling and less on the technical details, as well as to
store and exchange ECA models. Several applications of KorraAI ECAs are
possible, such as virtual sales agents, customer service agents, virtual
companions, entertainers, or tutors.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10711">AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models. (arXiv:2307.10711v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jiachun Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hanshu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liew_J/0/1/0/all/0/1">Jun Hao Liew</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1">Vincent Y. F. Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiashi Feng</a></p>
<p>Existing customization methods require access to multiple reference examples
to align pre-trained diffusion probabilistic models (DPMs) with user-provided
concepts. This paper aims to address the challenge of DPM customization when
the only available supervision is a differentiable metric defined on the
generated contents. Since the sampling procedure of DPMs involves recursive
calls to the denoising UNet, na\"ive gradient backpropagation requires storing
the intermediate states of all iterations, resulting in extremely high memory
consumption. To overcome this issue, we propose a novel method AdjointDPM,
which first generates new samples from diffusion models by solving the
corresponding probability-flow ODEs. It then uses the adjoint sensitivity
method to backpropagate the gradients of the loss to the models' parameters
(including conditioning signals, network weights, and initial noises) by
solving another augmented ODE. To reduce numerical errors in both the forward
generation and gradient backpropagation processes, we further reparameterize
the probability-flow ODE and augmented ODE as simple non-stiff ODEs using
exponential integration. Finally, we demonstrate the effectiveness of
AdjointDPM on three interesting tasks: converting visual effects into
identification text embeddings, finetuning DPMs for specific types of
stylization, and optimizing initial noise to generate adversarial samples for
security auditing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10713">Kick Back &amp; Relax: Learning to Reconstruct the World by Watching SlowTV. (arXiv:2307.10713v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Spencer_J/0/1/0/all/0/1">Jaime Spencer</a>, <a href="http://arxiv.org/find/cs/1/au:+Russell_C/0/1/0/all/0/1">Chris Russell</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadfield_S/0/1/0/all/0/1">Simon Hadfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowden_R/0/1/0/all/0/1">Richard Bowden</a></p>
<p>Self-supervised monocular depth estimation (SS-MDE) has the potential to
scale to vast quantities of data. Unfortunately, existing approaches limit
themselves to the automotive domain, resulting in models incapable of
generalizing to complex environments such as natural or indoor settings.
</p>
<p>To address this, we propose a large-scale SlowTV dataset curated from
YouTube, containing an order of magnitude more data than existing automotive
datasets. SlowTV contains 1.7M images from a rich diversity of environments,
such as worldwide seasonal hiking, scenic driving and scuba diving. Using this
dataset, we train an SS-MDE model that provides zero-shot generalization to a
large collection of indoor/outdoor datasets. The resulting model outperforms
all existing SSL approaches and closes the gap on supervised SoTA, despite
using a more efficient architecture.
</p>
<p>We additionally introduce a collection of best-practices to further maximize
performance and zero-shot generalization. This includes 1) aspect ratio
augmentation, 2) camera intrinsic estimation, 3) support frame randomization
and 4) flexible motion estimation. Code is available at
https://github.com/jspenmar/slowtv_monodepth.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10714">Introducing Risk Shadowing For Decisive and Comfortable Behavior Planning. (arXiv:2307.10714v1 [eess.SY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Puphal_T/0/1/0/all/0/1">Tim Puphal</a>, <a href="http://arxiv.org/find/eess/1/au:+Eggert_J/0/1/0/all/0/1">Julian Eggert</a></p>
<p>We consider the problem of group interactions in urban driving.
State-of-the-art behavior planners for self-driving cars mostly consider each
single agent-to-agent interaction separately in a cost function in order to
find an optimal behavior for the ego agent, such as not colliding with any of
the other agents. In this paper, we develop risk shadowing, a situation
understanding method that allows us to go beyond single interactions by
analyzing group interactions between three agents. Concretely, the presented
method can find out which first other agent does not need to be considered in
the behavior planner of an ego agent, because this first other agent cannot
reach the ego agent due to a second other agent obstructing its way. In
experiments, we show that using risk shadowing as an upstream filter module for
a behavior planner allows to plan more decisive and comfortable driving
strategies than state of the art, given that safety is ensured in these cases.
The usability of the approach is demonstrated for different intersection
scenarios and longitudinal driving.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10719">LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?. (arXiv:2307.10719v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Glukhov_D/0/1/0/all/0/1">David Glukhov</a>, <a href="http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1">Ilia Shumailov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1">Nicolas Papernot</a>, <a href="http://arxiv.org/find/cs/1/au:+Papyan_V/0/1/0/all/0/1">Vardan Papyan</a></p>
<p>Large language models (LLMs) have exhibited impressive capabilities in
comprehending complex instructions. However, their blind adherence to provided
instructions has led to concerns regarding risks of malicious use. Existing
defence mechanisms, such as model fine-tuning or output censorship using LLMs,
have proven to be fallible, as LLMs can still generate problematic responses.
Commonly employed censorship approaches treat the issue as a machine learning
problem and rely on another LM to detect undesirable content in LLM outputs. In
this paper, we present the theoretical limitations of such semantic censorship
approaches. Specifically, we demonstrate that semantic censorship can be
perceived as an undecidable problem, highlighting the inherent challenges in
censorship that arise due to LLMs' programmatic and instruction-following
capabilities. Furthermore, we argue that the challenges extend beyond semantic
censorship, as knowledgeable attackers can reconstruct impermissible outputs
from a collection of permissible ones. As a result, we propose that the problem
of censorship needs to be reevaluated; it should be treated as a security
problem which warrants the adaptation of security-based approaches to mitigate
potential risks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10738">Fairness-Aware Client Selection for Federated Learning. (arXiv:2307.10738v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yuxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zelei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhuan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Han Yu</a></p>
<p>Federated learning (FL) has enabled multiple data owners (a.k.a. FL clients)
to train machine learning models collaboratively without revealing private
data. Since the FL server can only engage a limited number of clients in each
training round, FL client selection has become an important research problem.
Existing approaches generally focus on either enhancing FL model performance or
enhancing the fair treatment of FL clients. The problem of balancing
performance and fairness considerations when selecting FL clients remains open.
To address this problem, we propose the Fairness-aware Federated Client
Selection (FairFedCS) approach. Based on Lyapunov optimization, it dynamically
adjusts FL clients' selection probabilities by jointly considering their
reputations, times of participation in FL tasks and contributions to the
resulting model performance. By not using threshold-based reputation filtering,
it provides FL clients with opportunities to redeem their reputations after a
perceived poor performance, thereby further enhancing fair client treatment.
Extensive experiments based on real-world multimedia datasets show that
FairFedCS achieves 19.6% higher fairness and 0.73% higher test accuracy on
average than the best-performing state-of-the-art approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10751">Exploring Perspectives on the Impact of Artificial Intelligence on the Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots. (arXiv:2307.10751v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1">Advait Sarkar</a></p>
<p>Artificial Intelligence (AI), and in particular generative models, are
transformative tools for knowledge work. They problematise notions of
creativity, originality, plagiarism, the attribution of credit, and copyright
ownership. Critics of generative models emphasise the reliance on large amounts
of training data, and view the output of these models as no more than
randomised plagiarism, remix, or collage of the source data. On these grounds,
many have argued for stronger regulations on the deployment, use, and
attribution of the output of these models. However, these issues are not new or
unique to artificial intelligence. In this position paper, using examples from
literary criticism, the history of art, and copyright law, I show how
creativity and originality resist definition as a notatable or
information-theoretic property of an object, and instead can be seen as the
property of a process, an author, or a viewer. Further alternative views hold
that all creative work is essentially reuse (mostly without attribution), or
that randomness itself can be creative. I suggest that creativity is ultimately
defined by communities of creators and receivers, and the deemed sources of
creativity in a workflow often depend on which parts of the workflow can be
automated. Using examples from recent studies of AI in creative knowledge work,
I suggest that AI shifts knowledge work from material production to critical
integration. This position paper aims to begin a conversation around a more
nuanced approach to the problems of creativity and credit assignment for
generative models, one which more fully recognises the importance of the
creative and curatorial voice of the users of these models and moves away from
simpler notational or information-theoretic views.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10763">MSQNet: Actor-agnostic Action Recognition with Multi-modal Query. (arXiv:2307.10763v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mondal_A/0/1/0/all/0/1">Anindya Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1">Sauradip Nag</a>, <a href="http://arxiv.org/find/cs/1/au:+Prada_J/0/1/0/all/0/1">Joaquin M Prada</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiatian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_A/0/1/0/all/0/1">Anjan Dutta</a></p>
<p>Existing action recognition methods are typically actor-specific due to the
intrinsic topological and apparent differences among the actors. This requires
actor-specific pose estimation (e.g., humans vs. animals), leading to
cumbersome model design complexity and high maintenance costs. Moreover, they
often focus on learning the visual modality alone and single-label
classification whilst neglecting other available information sources (e.g.,
class name text) and the concurrent occurrence of multiple actions. To overcome
these limitations, we propose a new approach called 'actor-agnostic multi-modal
multi-label action recognition,' which offers a unified solution for various
types of actors, including humans and animals. We further formulate a novel
Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object
detection framework (e.g., DETR), characterized by leveraging visual and
textual modalities to represent the action classes better. The elimination of
actor-specific model designs is a key advantage, as it removes the need for
actor pose estimation altogether. Extensive experiments on five publicly
available benchmarks show that our MSQNet consistently outperforms the prior
arts of actor-specific alternatives on human and animal single- and multi-label
action recognition tasks by up to 50%. Code will be released at
https://github.com/mondalanindya/MSQNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10768">Decoding the Enigma: Benchmarking Humans and AIs on the Many Facets of Working Memory. (arXiv:2307.10768v1 [q-bio.NC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Sikarwar_A/0/1/0/all/0/1">Ankur Sikarwar</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_M/0/1/0/all/0/1">Mengmi Zhang</a></p>
<p>Working memory (WM), a fundamental cognitive process facilitating the
temporary storage, integration, manipulation, and retrieval of information,
plays a vital role in reasoning and decision-making tasks. Robust benchmark
datasets that capture the multifaceted nature of WM are crucial for the
effective development and evaluation of AI WM models. Here, we introduce a
comprehensive Working Memory (WorM) benchmark dataset for this purpose. WorM
comprises 10 tasks and a total of 1 million trials, assessing 4
functionalities, 3 domains, and 11 behavioral and neural characteristics of WM.
We jointly trained and tested state-of-the-art recurrent neural networks and
transformers on all these tasks. We also include human behavioral benchmarks as
an upper bound for comparison. Our results suggest that AI models replicate
some characteristics of WM in the brain, most notably primacy and recency
effects, and neural clusters and correlates specialized for different domains
and functionalities of WM. In the experiments, we also reveal some limitations
in existing models to approximate human behavior. This dataset serves as a
valuable resource for communities in cognitive psychology, neuroscience, and
AI, offering a standardized framework to compare and enhance WM models,
investigate WM's neural underpinnings, and develop WM models with human-like
capabilities. Our source code and data are available at
https://github.com/ZhangLab-DeepNeuroCogLab/WorM.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10792">Optimizing PatchCore for Few/many-shot Anomaly Detection. (arXiv:2307.10792v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jo&#xe3;o Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1">Triet Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Rippel_O/0/1/0/all/0/1">Oliver Rippel</a></p>
<p>Few-shot anomaly detection (AD) is an emerging sub-field of general AD, and
tries to distinguish between normal and anomalous data using only few selected
samples. While newly proposed few-shot AD methods do compare against
pre-existing algorithms developed for the full-shot domain as baselines, they
do not dedicatedly optimize them for the few-shot setting. It thus remains
unclear if the performance of such pre-existing algorithms can be further
improved. We address said question in this work. Specifically, we present a
study on the AD/anomaly segmentation (AS) performance of PatchCore, the current
state-of-the-art full-shot AD/AS algorithm, in both the few-shot and the
many-shot settings. We hypothesize that further performance improvements can be
realized by (I) optimizing its various hyperparameters, and by (II)
transferring techniques known to improve few-shot supervised learning to the AD
domain. Exhaustive experiments on the public VisA and MVTec AD datasets reveal
that (I) significant performance improvements can be realized by optimizing
hyperparameters such as the underlying feature extractor, and that (II)
image-level augmentations can, but are not guaranteed, to improve performance.
Based on these findings, we achieve a new state of the art in few-shot AD on
VisA, further demonstrating the merit of adapting pre-existing AD/AS methods to
the few-shot setting. Last, we identify the investigation of feature extractors
with a strong inductive bias as a potential future research direction for
(few-shot) AD/AS.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10802">Meta-Transformer: A Unified Framework for Multimodal Learning. (arXiv:2307.10802v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yiyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_K/0/1/0/all/0/1">Kaixiong Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaipeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1">Xiangyu Yue</a></p>
<p>Multimodal learning aims to build models that can process and relate
information from multiple modalities. Despite years of development in this
field, it still remains challenging to design a unified network for processing
various modalities ($\textit{e.g.}$ natural language, 2D images, 3D point
clouds, audio, video, time series, tabular data) due to the inherent gaps among
them. In this work, we propose a framework, named Meta-Transformer, that
leverages a $\textbf{frozen}$ encoder to perform multimodal perception without
any paired multimodal training data. In Meta-Transformer, the raw input data
from various modalities are mapped into a shared token space, allowing a
subsequent encoder with frozen parameters to extract high-level semantic
features of the input data. Composed of three main components: a unified data
tokenizer, a modality-shared encoder, and task-specific heads for downstream
tasks, Meta-Transformer is the first framework to perform unified learning
across 12 modalities with unpaired data. Experiments on different benchmarks
reveal that Meta-Transformer can handle a wide range of tasks including
fundamental perception (text, image, point cloud, audio, video), practical
application (X-Ray, infrared, hyperspectral, and IMU), and data mining (graph,
tabular, and time-series). Meta-Transformer indicates a promising future for
developing unified multimodal intelligence with transformers. Code will be
available at https://github.com/invictus717/MetaTransformer
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10805">Communication-Efficient Split Learning via Adaptive Feature-Wise Compression. (arXiv:2307.10805v1 [cs.DC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1">Yongjeong Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jaeho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1">Christopher G. Brinton</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_Y/0/1/0/all/0/1">Yo-Seb Jeon</a></p>
<p>This paper proposes a novel communication-efficient split learning (SL)
framework, named SplitFC, which reduces the communication overhead required for
transmitting intermediate feature and gradient vectors during the SL training
process. The key idea of SplitFC is to leverage different dispersion degrees
exhibited in the columns of the matrices. SplitFC incorporates two compression
strategies: (i) adaptive feature-wise dropout and (ii) adaptive feature-wise
quantization. In the first strategy, the intermediate feature vectors are
dropped with adaptive dropout probabilities determined based on the standard
deviation of these vectors. Then, by the chain rule, the intermediate gradient
vectors associated with the dropped feature vectors are also dropped. In the
second strategy, the non-dropped intermediate feature and gradient vectors are
quantized using adaptive quantization levels determined based on the ranges of
the vectors. To minimize the quantization error, the optimal quantization
levels of this strategy are derived in a closed-form expression. Simulation
results on the MNIST, CIFAR-10, and CelebA datasets demonstrate that SplitFC
provides more than a 5.6% increase in classification accuracy compared to
state-of-the-art SL frameworks, while they require 320 times less communication
overhead compared to the vanilla SL framework without compression.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10810">On Combining Expert Demonstrations in Imitation Learning via Optimal Transport. (arXiv:2307.10810v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sebag_I/0/1/0/all/0/1">Ilana Sebag</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Samuel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deisenroth_M/0/1/0/all/0/1">Marc Peter Deisenroth</a></p>
<p>Imitation learning (IL) seeks to teach agents specific tasks through expert
demonstrations. One of the key approaches to IL is to define a distance between
agent and expert and to find an agent policy that minimizes that distance.
Optimal transport methods have been widely used in imitation learning as they
provide ways to measure meaningful distances between agent and expert
trajectories. However, the problem of how to optimally combine multiple expert
demonstrations has not been widely studied. The standard method is to simply
concatenate state (-action) trajectories, which is problematic when
trajectories are multi-modal. We propose an alternative method that uses a
multi-marginal optimal transport distance and enables the combination of
multiple and diverse state-trajectories in the OT sense, providing a more
sensible geometric average of the demonstrations. Our approach enables an agent
to learn from several experts, and its efficiency is analyzed on OpenAI Gym
control environments and demonstrates that the standard method is not always
optimal.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10811">&quot;It Felt Like Having a Second Mind&quot;: Investigating Human-AI Co-creativity in Prewriting with Large Language Models. (arXiv:2307.10811v1 [cs.HC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wan_Q/0/1/0/all/0/1">Qian Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Siying Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Piaohong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_B/0/1/0/all/0/1">Bo Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhicong Lu</a></p>
<p>Prewriting is the process of discovering and developing ideas before a first
draft, which requires divergent thinking and often implies unstructured
strategies such as diagramming, outlining, free-writing, etc. Although large
language models (LLMs) have been demonstrated to be useful for a variety of
tasks including creative writing, little is known about how users would
collaborate with LLMs to support prewriting. The preferred collaborative role
and initiative of LLMs during such a creativity process is also unclear. To
investigate human-LLM collaboration patterns and dynamics during prewriting, we
conducted a three-session qualitative study with 15 participants in two
creative tasks: story writing and slogan writing. The findings indicated that
during collaborative prewriting, there appears to be a three-stage iterative
Human-AI Co-creativity process that includes Ideation, Illumination, and
Implementation stages. This collaborative process champions the human in a
dominant role, in addition to mixed and shifting levels of initiative that
exist between humans and LLMs. This research also reports on collaboration
breakdowns that occur during this process, user perceptions of using existing
LLMs during Human-AI Co-creativity, and discusses design implications to
support this co-creativity process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10832">Modifications of the Miller definition of contrastive (counterfactual) explanations. (arXiv:2307.10832v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+McAreavey_K/0/1/0/all/0/1">Kevin McAreavey</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiru Liu</a></p>
<p>Miller recently proposed a definition of contrastive (counterfactual)
explanations based on the well-known Halpern-Pearl (HP) definitions of causes
and (non-contrastive) explanations. Crucially, the Miller definition was based
on the original HP definition of explanations, but this has since been modified
by Halpern; presumably because the original yields counterintuitive results in
many standard examples. More recently Borner has proposed a third definition,
observing that this modified HP definition may also yield counterintuitive
results. In this paper we show that the Miller definition inherits issues found
in the original HP definition. We address these issues by proposing two
improved variants based on the more robust modified HP and Borner definitions.
We analyse our new definitions and show that they retain the spirit of the
Miller definition where all three variants satisfy an alternative unified
definition that is modular with respect to an underlying definition of
non-contrastive explanations. To the best of our knowledge this paper also
provides the first explicit comparison between the original and modified HP
definitions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10846">Goal-Conditioned Reinforcement Learning with Disentanglement-based Reachability Planning. (arXiv:2307.10846v1 [cs.RO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qian_Z/0/1/0/all/0/1">Zhifeng Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+You_M/0/1/0/all/0/1">Mingyu You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hongjun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xuanhui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Bin He</a></p>
<p>Goal-Conditioned Reinforcement Learning (GCRL) can enable agents to
spontaneously set diverse goals to learn a set of skills. Despite the excellent
works proposed in various fields, reaching distant goals in temporally extended
tasks remains a challenge for GCRL. Current works tackled this problem by
leveraging planning algorithms to plan intermediate subgoals to augment GCRL.
Their methods need two crucial requirements: (i) a state representation space
to search valid subgoals, and (ii) a distance function to measure the
reachability of subgoals. However, they struggle to scale to high-dimensional
state space due to their non-compact representations. Moreover, they cannot
collect high-quality training data through standard GC policies, which results
in an inaccurate distance function. Both affect the efficiency and performance
of planning and policy learning. In the paper, we propose a goal-conditioned RL
algorithm combined with Disentanglement-based Reachability Planning (REPlan) to
solve temporally extended tasks. In REPlan, a Disentangled Representation
Module (DRM) is proposed to learn compact representations which disentangle
robot poses and object positions from high-dimensional observations in a
self-supervised manner. A simple REachability discrimination Module (REM) is
also designed to determine the temporal distance of subgoals. Moreover, REM
computes intrinsic bonuses to encourage the collection of novel states for
training. We evaluate our REPlan in three vision-based simulation tasks and one
real-world task. The experiments demonstrate that our REPlan significantly
outperforms the prior state-of-the-art methods in solving temporally extended
tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10864">Divide &amp; Bind Your Attention for Improved Generative Semantic Nursing. (arXiv:2307.10864v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yumeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1">Margret Keuper</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Khoreva_A/0/1/0/all/0/1">Anna Khoreva</a></p>
<p>Emerging large-scale text-to-image generative models, e.g., Stable Diffusion
(SD), have exhibited overwhelming results with high fidelity. Despite the
magnificent progress, current state-of-the-art models still struggle to
generate images fully adhering to the input prompt. Prior work, Attend &amp;
Excite, has introduced the concept of Generative Semantic Nursing (GSN), aiming
to optimize cross-attention during inference time to better incorporate the
semantics. It demonstrates promising results in generating simple prompts,
e.g., ``a cat and a dog''. However, its efficacy declines when dealing with
more complex prompts, and it does not explicitly address the problem of
improper attribute binding. To address the challenges posed by complex prompts
or scenarios involving multiple entities and to achieve improved attribute
binding, we propose Divide &amp; Bind. We introduce two novel loss objectives for
GSN: a novel attendance loss and a binding loss. Our approach stands out in its
ability to faithfully synthesize desired objects with improved attribute
alignment from complex prompts and exhibits superior performance across
multiple evaluation benchmarks. More videos and updates can be found on the
project page \url{https://sites.google.com/view/divide-and-bind}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10891">Syntactic vs Semantic Linear Abstraction and Refinement of Neural Networks. (arXiv:2307.10891v1 [cs.LO])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chau_C/0/1/0/all/0/1">Calvin Chau</a>, <a href="http://arxiv.org/find/cs/1/au:+Kretinsky_J/0/1/0/all/0/1">Jan K&#x159;et&#xed;nsk&#xfd;</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohr_S/0/1/0/all/0/1">Stefanie Mohr</a></p>
<p>Abstraction is a key verification technique to improve scalability. However,
its use for neural networks is so far extremely limited. Previous approaches
for abstracting classification networks replace several neurons with one of
them that is similar enough. We can classify the similarity as defined either
syntactically (using quantities on the connections between neurons) or
semantically (on the activation values of neurons for various inputs).
Unfortunately, the previous approaches only achieve moderate reductions, when
implemented at all. In this work, we provide a more flexible framework where a
neuron can be replaced with a linear combination of other neurons, improving
the reduction. We apply this approach both on syntactic and semantic
abstractions, and implement and evaluate them experimentally. Further, we
introduce a refinement method for our abstractions, allowing for finding a
better balance between reduction and precision.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2012.07881">Perceptron Theory Can Predict the Accuracy of Neural Networks. (arXiv:2012.07881v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kleyko_D/0/1/0/all/0/1">Denis Kleyko</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosato_A/0/1/0/all/0/1">Antonello Rosato</a>, <a href="http://arxiv.org/find/cs/1/au:+Frady_E/0/1/0/all/0/1">E. Paxon Frady</a>, <a href="http://arxiv.org/find/cs/1/au:+Panella_M/0/1/0/all/0/1">Massimo Panella</a>, <a href="http://arxiv.org/find/cs/1/au:+Sommer_F/0/1/0/all/0/1">Friedrich T. Sommer</a></p>
<p>Multilayer neural networks set the current state of the art for many
technical classification problems. But, these networks are still, essentially,
black boxes in terms of analyzing them and predicting their performance. Here,
we develop a statistical theory for the one-layer perceptron and show that it
can predict performances of a surprisingly large variety of neural networks
with different architectures. A general theory of classification with
perceptrons is developed by generalizing an existing theory for analyzing
reservoir computing models and connectionist models for symbolic reasoning
known as vector symbolic architectures. Our statistical theory offers three
formulas leveraging the signal statistics with increasing detail. The formulas
are analytically intractable, but can be evaluated numerically. The description
level that captures maximum details requires stochastic sampling methods.
Depending on the network model, the simpler formulas already yield high
prediction accuracy. The quality of the theory predictions is assessed in three
experimental settings, a memorization task for echo state networks (ESNs) from
reservoir computing literature, a collection of classification datasets for
shallow randomly connected networks, and the ImageNet dataset for deep
convolutional neural networks. We find that the second description level of the
perceptron theory can predict the performance of types of ESNs, which could not
be described previously. The theory can predict deep multilayer neural networks
by being applied to their output layer. While other methods for prediction of
neural networks performance commonly require to train an estimator model, the
proposed theory requires only the first two moments of the distribution of the
postsynaptic sums in the output neurons. The perceptron theory compares
favorably to other methods that do not rely on training an estimator model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.04066">Semantically Adversarial Scenario Generation with Explicit Knowledge Guidance. (arXiv:2106.04066v6 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenhao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Haohong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a></p>
<p>Generating adversarial scenarios, which have the potential to fail autonomous
driving systems, provides an effective way to improve robustness. Extending
purely data-driven generative models, recent specialized models satisfy
additional controllable requirements such as embedding a traffic sign in a
driving scene by manipulating patterns implicitly in the neuron level. In this
paper, we introduce a method to incorporate domain knowledge explicitly in the
generation process to achieve the Semantically Adversarial Generation (SAG). To
be consistent with the composition of driving scenes, we first categorize the
knowledge into two types, the property of objects and the relationship among
objects. We then propose a tree-structured variational auto-encoder (T-VAE) to
learn hierarchical scene representation. By imposing semantic rules on the
properties of nodes and edges in the tree structure, explicit knowledge
integration enables controllable generation. We construct a synthetic example
to illustrate the controllability and explainability of our method in a
succinct setting. We further extend to realistic environments for autonomous
vehicles: our method efficiently identifies adversarial driving scenes against
different state-of-the-art 3D point cloud segmentation models and satisfies the
traffic rules specified as the explicit knowledge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2106.05268">Vector Symbolic Architectures as a Computing Framework for Emerging Hardware. (arXiv:2106.05268v2 [cs.AR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kleyko_D/0/1/0/all/0/1">Denis Kleyko</a>, <a href="http://arxiv.org/find/cs/1/au:+Davies_M/0/1/0/all/0/1">Mike Davies</a>, <a href="http://arxiv.org/find/cs/1/au:+Frady_E/0/1/0/all/0/1">E. Paxon Frady</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanerva_P/0/1/0/all/0/1">Pentti Kanerva</a>, <a href="http://arxiv.org/find/cs/1/au:+Kent_S/0/1/0/all/0/1">Spencer J. Kent</a>, <a href="http://arxiv.org/find/cs/1/au:+Olshausen_B/0/1/0/all/0/1">Bruno A. Olshausen</a>, <a href="http://arxiv.org/find/cs/1/au:+Osipov_E/0/1/0/all/0/1">Evgeny Osipov</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabaey_J/0/1/0/all/0/1">Jan M. Rabaey</a>, <a href="http://arxiv.org/find/cs/1/au:+Rachkovskij_D/0/1/0/all/0/1">Dmitri A. Rachkovskij</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahimi_A/0/1/0/all/0/1">Abbas Rahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sommer_F/0/1/0/all/0/1">Friedrich T. Sommer</a></p>
<p>This article reviews recent progress in the development of the computing
framework vector symbolic architectures (VSA) (also known as hyperdimensional
computing). This framework is well suited for implementation in stochastic,
emerging hardware, and it naturally expresses the types of cognitive operations
required for artificial intelligence (AI). We demonstrate in this article that
the field-like algebraic structure of VSA offers simple but powerful operations
on high-dimensional vectors that can support all data structures and
manipulations relevant to modern computing. In addition, we illustrate the
distinguishing feature of VSA, "computing in superposition," which sets it
apart from conventional computing. It also opens the door to efficient
solutions to the difficult combinatorial search problems inherent in AI
applications. We sketch ways of demonstrating that VSA are computationally
universal. We see them acting as a framework for computing with distributed
representations that can play a role of an abstraction layer for emerging
computing hardware. This article serves as a reference for computer architects
by illustrating the philosophy behind VSA, techniques of distributed computing
with them, and their relevance to emerging computing hardware, such as
neuromorphic computing.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2109.12509">Deep Exploration for Recommendation Systems. (arXiv:2109.12509v3 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zheqing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Benjamin Van Roy</a></p>
<p>Modern recommendation systems ought to benefit by probing for and learning
from delayed feedback. Research has tended to focus on learning from a user's
response to a single recommendation. Such work, which leverages methods of
supervised and bandit learning, forgoes learning from the user's subsequent
behavior. Where past work has aimed to learn from subsequent behavior, there
has been a lack of effective methods for probing to elicit informative delayed
feedback. Effective exploration through probing for delayed feedback becomes
particularly challenging when rewards are sparse. To address this, we develop
deep exploration methods for recommendation systems. In particular, we
formulate recommendation as a sequential decision problem and demonstrate
benefits of deep exploration over single-step exploration. Our experiments are
carried out with high-fidelity industrial-grade simulators and establish large
improvements over existing algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2111.06390">Full Characterization of Adaptively Strong Majority Voting in Crowdsourcing. (arXiv:2111.06390v2 [stat.AP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Boyarskaya_M/0/1/0/all/0/1">Margarita Boyarskaya</a>, <a href="http://arxiv.org/find/stat/1/au:+Ipeirotis_P/0/1/0/all/0/1">Panos Ipeirotis</a></p>
<p>In crowdsourcing, quality control is commonly achieved by having workers
examine items and vote on their correctness. To minimize the impact of
unreliable worker responses, a $\delta$-margin voting process is utilized,
where additional votes are solicited until a predetermined threshold $\delta$
for agreement between workers is exceeded. The process is widely adopted but
only as a heuristic. Our research presents a modeling approach using absorbing
Markov chains to analyze the characteristics of this voting process that matter
in crowdsourced processes. We provide closed-form equations for the quality of
resulting consensus vote, the expected number of votes required for consensus,
the variance of vote requirements, and other distribution moments. Our findings
demonstrate how the threshold $\delta$ can be adjusted to achieve quality
equivalence across voting processes that employ workers with varying accuracy
levels. We also provide efficiency-equalizing payment rates for voting
processes with different expected response accuracy levels. Additionally, our
model considers items with varying degrees of difficulty and uncertainty about
the difficulty of each example. Our simulations, using real-world crowdsourced
vote data, validate the effectiveness of our theoretical model in
characterizing the consensus aggregation process. The results of our study can
be effectively employed in practical crowdsourcing applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2112.03896">Gradient and Projection Free Distributed Online Min-Max Resource Optimization. (arXiv:2112.03896v3 [cs.IT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingrong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1">Ben Liang</a></p>
<p>We consider distributed online min-max resource allocation with a set of
parallel agents and a parameter server. Our goal is to minimize the pointwise
maximum over a set of time-varying and decreasing cost functions, without a
priori information about these functions. We propose a novel online algorithm,
termed Distributed Online resource Re-Allocation (DORA), where non-stragglers
learn to relinquish resource and share resource with stragglers. A notable
feature of DORA is that it does not require gradient calculation or projection
operation, unlike most existing online optimization strategies. This allows it
to substantially reduce the computation overhead in large-scale and distributed
networks. We analyze the worst-case performance of DORA and derive an upper
bound on its dynamic regret for non-convex functions. We further consider an
application to the bandwidth allocation problem in distributed online machine
learning. Our numerical study demonstrates the efficacy of the proposed
solution and its performance advantage over gradient- and/or projection-based
resource allocation algorithms in reducing wall-clock time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.09753">HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding. (arXiv:2205.09753v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xiaosong Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Penghao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a></p>
<p>Encoding a driving scene into vector representations has been an essential
task for autonomous driving that can benefit downstream tasks e.g. trajectory
prediction. The driving scene often involves heterogeneous elements such as the
different types of objects (agents, lanes, traffic signs) and the semantic
relations between objects are rich and diverse. Meanwhile, there also exist
relativity across elements, which means that the spatial relation is a relative
concept and need be encoded in a ego-centric manner instead of in a global
coordinate system. Based on these observations, we propose Heterogeneous
Driving Graph Transformer (HDGT), a backbone modelling the driving scene as a
heterogeneous graph with different types of nodes and edges. For heterogeneous
graph construction, we connect different types of nodes according to diverse
semantic relations. For spatial relation encoding, the coordinates of the node
as well as its in-edges are in the local node-centric coordinate system. For
the aggregation module in the graph neural network (GNN), we adopt the
transformer structure in a hierarchical way to fit the heterogeneous nature of
inputs. Experimental results show that HDGT achieves state-of-the-art
performance for the task of trajectory prediction, on INTERACTION Prediction
Challenge and Waymo Open Motion Challenge.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2205.11498">Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval. (arXiv:2205.11498v2 [cs.IR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1">Nandan Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1">Nils Reimers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jimmy Lin</a></p>
<p>Dense retrieval overcome the lexical gap and has shown great success in
ad-hoc information retrieval (IR). Despite their success, dense retrievers are
expensive to serve across practical use cases. For use cases requiring to
search from millions of documents, the dense index becomes bulky and requires
high memory usage for storing the index. More recently, learning-to-hash (LTH)
techniques, for e.g., BPR and JPQ, produce binary document vectors, thereby
reducing the memory requirement to efficiently store the dense index. LTH
techniques are supervised and finetune the retriever using a ranking loss. They
outperform their counterparts, i.e., traditional out-of-the-box vector
compression techniques such as PCA or PQ. A missing piece from prior work is
that existing techniques have been evaluated only in-domain, i.e., on a single
dataset such as MS MARCO. In our work, we evaluate LTH and vector compression
techniques for improving the downstream zero-shot retrieval accuracy of the
TAS-B dense retriever while maintaining efficiency at inference. Our results
demonstrate that, unlike prior work, LTH strategies when applied naively can
underperform the zero-shot TAS-B dense retriever on average by up to 14%
nDCG@10 on the BEIR benchmark. To solve this limitation, in our work, we
propose an easy yet effective solution of injecting domain adaptation with
existing supervised LTH techniques. We experiment with two well-known
unsupervised domain adaptation techniques: GenQ and GPL. Our domain adaptation
injection technique can improve the downstream zero-shot retrieval
effectiveness for both BPR and JPQ variants of the TAS-B model by on average
11.5% and 8.2% nDCG@10 while both maintaining 32$\times$ memory efficiency and
14$\times$ and 2$\times$ speedup respectively in CPU retrieval latency on BEIR.
All our code, models, and data are publicly available at
https://github.com/thakur-nandan/income.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.06501">ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs. (arXiv:2208.06501v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zifeng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zongyue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_R/0/1/0/all/0/1">Ruoxia Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingpei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Bailan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yunpu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1">Zhao Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1">Ruotong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhen Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1">Volker Tresp</a></p>
<p>Question answering over temporal knowledge graphs (TKGQA) has recently found
increasing interest. TKGQA requires temporal reasoning techniques to extract
the relevant information from temporal knowledge bases. The only existing TKGQA
dataset, i.e., CronQuestions, consists of temporal questions based on the facts
from a fixed time period, where a temporal knowledge graph (TKG) spanning the
same period can be fully used for answer inference, allowing the TKGQA models
to use even the future knowledge to answer the questions based on the past
facts. In real-world scenarios, however, it is also common that given the
knowledge until now, we wish the TKGQA systems to answer the questions asking
about the future. As humans constantly seek plans for the future, building
TKGQA systems for answering such forecasting questions is important.
Nevertheless, this has still been unexplored in previous research. In this
paper, we propose a novel task: forecasting question answering over temporal
knowledge graphs. We also propose a large-scale TKGQA benchmark dataset, i.e.,
ForecastTKGQuestions, for this task. It includes three types of questions,
i.e., entity prediction, yes-no, and fact reasoning questions. For every
forecasting question in our dataset, QA models can only have access to the TKG
information before the timestamp annotated in the given question for answer
inference. We find that the state-of-the-art TKGQA methods perform poorly on
forecasting questions, and they are unable to answer yes-no questions and fact
reasoning questions. To this end, we propose ForecastTKGQA, a TKGQA model that
employs a TKG forecasting module for future inference, to answer all three
types of questions. Experimental results show that ForecastTKGQA outperforms
recent TKGQA methods on the entity prediction questions, and it also shows
great effectiveness in answering the other two types of questions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.09418">SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability. (arXiv:2208.09418v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xingyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_G/0/1/0/all/0/1">Gaojie Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaowei Huang</a></p>
<p>Interpretability of Deep Learning (DL) is a barrier to trustworthy AI.
Despite great efforts made by the Explainable AI (XAI) community, explanations
lack robustness -- indistinguishable input perturbations may lead to different
XAI results. Thus, it is vital to assess how robust DL interpretability is,
given an XAI method. In this paper, we identify several challenges that the
state-of-the-art is unable to cope with collectively: i) existing metrics are
not comprehensive; ii) XAI techniques are highly heterogeneous; iii)
misinterpretations are normally rare events. To tackle these challenges, we
introduce two black-box evaluation methods, concerning the worst-case
interpretation discrepancy and a probabilistic notion of how robust in general,
respectively. Genetic Algorithm (GA) with bespoke fitness function is used to
solve constrained optimisation for efficient worst-case evaluation. Subset
Simulation (SS), dedicated to estimate rare event probabilities, is used for
evaluating overall robustness. Experiments show that the accuracy, sensitivity,
and efficiency of our methods outperform the state-of-the-arts. Finally, we
demonstrate two applications of our methods: ranking robust XAI methods and
selecting training schemes to improve both classification and interpretation
robustness.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2208.09998">Antecedent Predictions Are More Important Than You Think: An Effective Method for Tree-Based Code Generation. (arXiv:2208.09998v3 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yihong Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Ge Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xue Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhi Jin</a></p>
<p>Code generation focuses on the automatic conversion of natural language (NL)
utterances into code snippets. The sequence-to-tree (Seq2Tree) approaches are
proposed for code generation, with the guarantee of the grammatical correctness
of the generated code, which generate the subsequent Abstract Syntax Tree (AST)
node relying on antecedent predictions of AST nodes. Existing Seq2Tree methods
tend to treat both antecedent predictions and subsequent predictions equally.
However, under the AST constraints, it is difficult for Seq2Tree models to
produce the correct subsequent prediction based on incorrect antecedent
predictions. Thus, antecedent predictions ought to receive more attention than
subsequent predictions. To this end, in this paper, we propose an effective
method, named Antecedent Prioritized (AP) Loss, that helps the model attach
importance to antecedent predictions by exploiting the position information of
the generated AST nodes. We design an AST-to-Vector (AST2Vec) method, that maps
AST node positions to two-dimensional vectors, to model the position
information of AST nodes. To evaluate the effectiveness of our proposed loss,
we implement and train an Antecedent Prioritized Tree-based code generation
model called APT. With better antecedent predictions and accompanying
subsequent predictions, APT significantly improves the performance. We conduct
extensive experiments on four benchmark datasets, and the experimental results
demonstrate the superiority and generality of our proposed method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.04974">Leveraging Offline Data in Online Reinforcement Learning. (arXiv:2211.04974v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wagenmaker_A/0/1/0/all/0/1">Andrew Wagenmaker</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1">Aldo Pacchiano</a></p>
<p>Two central paradigms have emerged in the reinforcement learning (RL)
community: online RL and offline RL. In the online RL setting, the agent has no
prior knowledge of the environment, and must interact with it in order to find
an $\epsilon$-optimal policy. In the offline RL setting, the learner instead
has access to a fixed dataset to learn from, but is unable to otherwise
interact with the environment, and must obtain the best policy it can from this
offline data. Practical scenarios often motivate an intermediate setting: if we
have some set of offline data and, in addition, may also interact with the
environment, how can we best use the offline data to minimize the number of
online interactions necessary to learn an $\epsilon$-optimal policy?
</p>
<p>In this work, we consider this setting, which we call the \textsf{FineTuneRL}
setting, for MDPs with linear structure. We characterize the necessary number
of online samples needed in this setting given access to some offline dataset,
and develop an algorithm, \textsc{FTPedel}, which is provably optimal, up to
$H$ factors. We show through an explicit example that combining offline data
with online interactions can lead to a provable improvement over either purely
offline or purely online RL. Finally, our results illustrate the distinction
between \emph{verifiable} learning, the typical setting considered in online
RL, and \emph{unverifiable} learning, the setting often considered in offline
RL, and show that there is a formal separation between these regimes.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.05939">pyRDDLGym: From RDDL to Gym Environments. (arXiv:2211.05939v4 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Taitler_A/0/1/0/all/0/1">Ayal Taitler</a>, <a href="http://arxiv.org/find/cs/1/au:+Gimelfarb_M/0/1/0/all/0/1">Michael Gimelfarb</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1">Jihwan Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gopalakrishnan_S/0/1/0/all/0/1">Sriram Gopalakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mladenov_M/0/1/0/all/0/1">Martin Mladenov</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaotian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanner_S/0/1/0/all/0/1">Scott Sanner</a></p>
<p>We present pyRDDLGym, a Python framework for auto-generation of OpenAI Gym
environments from RDDL declerative description. The discrete time step
evolution of variables in RDDL is described by conditional probability
functions, which fits naturally into the Gym step scheme. Furthermore, since
RDDL is a lifted description, the modification and scaling up of environments
to support multiple entities and different configurations becomes trivial
rather than a tedious process prone to errors. We hope that pyRDDLGym will
serve as a new wind in the reinforcement learning community by enabling easy
and rapid development of benchmarks due to the unique expressive power of RDDL.
By providing explicit access to the model in the RDDL description, pyRDDLGym
can also facilitate research on hybrid approaches for learning from interaction
while leveraging model knowledge. We present the design and built-in examples
of pyRDDLGym, and the additions made to the RDDL language that were
incorporated into the framework.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.11596">ThoughtSource: A central hub for large language model reasoning data. (arXiv:2301.11596v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ott_S/0/1/0/all/0/1">Simon Ott</a>, <a href="http://arxiv.org/find/cs/1/au:+Hebenstreit_K/0/1/0/all/0/1">Konstantin Hebenstreit</a>, <a href="http://arxiv.org/find/cs/1/au:+Lievin_V/0/1/0/all/0/1">Valentin Li&#xe9;vin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hother_C/0/1/0/all/0/1">Christoffer Egeberg Hother</a>, <a href="http://arxiv.org/find/cs/1/au:+Moradi_M/0/1/0/all/0/1">Milad Moradi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayrhauser_M/0/1/0/all/0/1">Maximilian Mayrhauser</a>, <a href="http://arxiv.org/find/cs/1/au:+Praas_R/0/1/0/all/0/1">Robert Praas</a>, <a href="http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1">Ole Winther</a>, <a href="http://arxiv.org/find/cs/1/au:+Samwald_M/0/1/0/all/0/1">Matthias Samwald</a></p>
<p>Large language models (LLMs) such as GPT-4 have recently demonstrated
impressive results across a wide range of tasks. LLMs are still limited,
however, in that they frequently fail at complex reasoning, their reasoning
processes are opaque, they are prone to 'hallucinate' facts, and there are
concerns about their underlying biases. Letting models verbalize reasoning
steps as natural language, a technique known as chain-of-thought prompting, has
recently been proposed as a way to address some of these issues. Here we
present ThoughtSource, a meta-dataset and software library for chain-of-thought
(CoT) reasoning. The goal of ThoughtSource is to improve future artificial
intelligence systems by facilitating qualitative understanding of CoTs,
enabling empirical evaluations, and providing training data. This first release
of ThoughtSource integrates six scientific/medical, three general-domain and
five math word question answering datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.13816">Execution-based Code Generation using Deep Reinforcement Learning. (arXiv:2301.13816v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shojaee_P/0/1/0/all/0/1">Parshin Shojaee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Aneesh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Tipirneni_S/0/1/0/all/0/1">Sindhu Tipirneni</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1">Chandan K. Reddy</a></p>
<p>The utilization of programming language (PL) models, pre-trained on
large-scale code corpora, as a means of automating software engineering
processes has demonstrated considerable potential in streamlining various code
generation tasks such as code completion, code translation, and program
synthesis. However, current approaches mainly rely on supervised fine-tuning
objectives borrowed from text generation, neglecting unique sequence-level
characteristics of code, including but not limited to compilability as well as
syntactic and functional correctness. To address this limitation, we propose
PPOCoder, a new framework for code generation that synergistically combines
pre-trained PL models with Proximal Policy Optimization (PPO) which is a widely
used deep reinforcement learning technique. By utilizing non-differentiable
feedback from code execution and structure alignment, PPOCoder seamlessly
integrates external code-specific knowledge into the model optimization
process. It's important to note that PPOCoder is a task-agnostic and
model-agnostic framework that can be used across different code generation
tasks and PLs. Extensive experiments on three code generation tasks demonstrate
the effectiveness of our proposed approach compared to SOTA methods, achieving
significant improvements in compilation success rates and functional
correctness across different PLs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.13867">Mathematical Capabilities of ChatGPT. (arXiv:2301.13867v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Frieder_S/0/1/0/all/0/1">Simon Frieder</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinchetti_L/0/1/0/all/0/1">Luca Pinchetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Chevalier_A/0/1/0/all/0/1">Alexis Chevalier</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_R/0/1/0/all/0/1">Ryan-Rhys Griffiths</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvatori_T/0/1/0/all/0/1">Tommaso Salvatori</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1">Thomas Lukasiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_P/0/1/0/all/0/1">Philipp Christian Petersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Berner_J/0/1/0/all/0/1">Julius Berner</a></p>
<p>We investigate the mathematical capabilities of two iterations of ChatGPT
(released 9-January-2023 and 30-January-2023) and of GPT-4 by testing them on
publicly available datasets, as well as hand-crafted ones, using a novel
methodology. In contrast to formal mathematics, where large databases of formal
proofs are available (e.g., the Lean Mathematical Library), current datasets of
natural-language mathematics, used to benchmark language models, either cover
only elementary mathematics or are very small. We address this by publicly
releasing two new datasets: GHOSTS and miniGHOSTS. These are the first
natural-language datasets curated by working researchers in mathematics that
(1) aim to cover graduate-level mathematics, (2) provide a holistic overview of
the mathematical capabilities of language models, and (3) distinguish multiple
dimensions of mathematical reasoning. These datasets also test whether ChatGPT
and GPT-4 can be helpful assistants to professional mathematicians by emulating
use cases that arise in the daily professional activities of mathematicians. We
benchmark the models on a range of fine-grained performance metrics. For
advanced mathematics, this is the most detailed evaluation effort to date. We
find that ChatGPT can be used most successfully as a mathematical assistant for
querying facts, acting as a mathematical search engine and knowledge base
interface. GPT-4 can additionally be used for undergraduate-level mathematics
but fails on graduate-level difficulty. Contrary to many positive reports in
the media about GPT-4 and ChatGPT's exam-solving abilities (a potential case of
selection bias), their overall mathematical performance is well below the level
of a graduate student. Hence, if your goal is to use ChatGPT to pass a
graduate-level math exam, you would be better off copying from your average
peer!
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.03087">Dividing Good and Better Items Among Agents with Bivalued Submodular Valuations. (arXiv:2302.03087v3 [cs.GT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cousins_C/0/1/0/all/0/1">Cyrus Cousins</a>, <a href="http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1">Vignesh Viswanathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zick_Y/0/1/0/all/0/1">Yair Zick</a></p>
<p>We study the problem of fairly allocating a set of indivisible goods among
agents with {\em bivalued submodular valuations} -- each good provides a
marginal gain of either $a$ or $b$ ($a &lt; b$) and goods have decreasing marginal
gains. This is a natural generalization of two well-studied valuation classes
-- bivalued additive valuations and binary submodular valuations. We present a
simple sequential algorithmic framework, based on the recently introduced
Yankee Swap mechanism, that can be adapted to compute a variety of solution
concepts, including max Nash welfare (MNW), leximin and $p$-mean welfare
maximizing allocations when $a$ divides $b$. This result is complemented by an
existing result on the computational intractability of MNW and leximin
allocations when $a$ does not divide $b$. We show that MNW and leximin
allocations guarantee each agent at least $\frac25$ and $\frac{a}{b+2a}$ of
their maximin share, respectively, when $a$ divides $b$. We also show that
neither the leximin nor the MNW allocation is guaranteed to be envy free up to
one good (EF1). This is surprising since for the simpler classes of bivalued
additive valuations and binary submodular valuations, MNW allocations are known
to be envy free up to any good (EFX).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.10106">A multidomain relational framework to guide institutional AI research and adoption. (arXiv:2303.10106v2 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Straub_V/0/1/0/all/0/1">Vincent J. Straub</a>, <a href="http://arxiv.org/find/cs/1/au:+Morgan_D/0/1/0/all/0/1">Deborah Morgan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashem_Y/0/1/0/all/0/1">Youmna Hashem</a>, <a href="http://arxiv.org/find/cs/1/au:+Francis_J/0/1/0/all/0/1">John Francis</a>, <a href="http://arxiv.org/find/cs/1/au:+Esnaashari_S/0/1/0/all/0/1">Saba Esnaashari</a>, <a href="http://arxiv.org/find/cs/1/au:+Bright_J/0/1/0/all/0/1">Jonathan Bright</a></p>
<p>Calls for new metrics, technical standards and governance mechanisms to guide
the adoption of Artificial Intelligence (AI) in institutions and public
administration are now commonplace. Yet, most research and policy efforts aimed
at understanding the implications of adopting AI tend to prioritize only a
handful of ideas; they do not fully connect all the different perspectives and
topics that are potentially relevant. In this position paper, we contend that
this omission stems, in part, from what we call the relational problem in
socio-technical discourse: fundamental ontological issues have not yet been
settled--including semantic ambiguity, a lack of clear relations between
concepts and differing standard terminologies. This contributes to the
persistence of disparate modes of reasoning to assess institutional AI systems,
and the prevalence of conceptual isolation in the fields that study them
including ML, human factors, social science and policy. After developing this
critique, we offer a way forward by proposing a simple policy and research
design tool in the form of a conceptual framework to organize terms across
fields--consisting of three horizontal domains for grouping relevant concepts
and related methods: Operational, Epistemic, and Normative. We first situate
this framework against the backdrop of recent socio-technical discourse at two
premier academic venues, AIES and FAccT, before illustrating how developing
suitable metrics, standards, and mechanisms can be aided by operationalizing
relevant concepts in each of these domains. Finally, we outline outstanding
questions for developing this relational approach to institutional AI research
and adoption.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.12112">Positive-Augmented Contrastive Learning for Image and Video Captioning Evaluation. (arXiv:2303.12112v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sarto_S/0/1/0/all/0/1">Sara Sarto</a>, <a href="http://arxiv.org/find/cs/1/au:+Barraco_M/0/1/0/all/0/1">Manuele Barraco</a>, <a href="http://arxiv.org/find/cs/1/au:+Cornia_M/0/1/0/all/0/1">Marcella Cornia</a>, <a href="http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1">Lorenzo Baraldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1">Rita Cucchiara</a></p>
<p>The CLIP model has been recently proven to be very effective for a variety of
cross-modal tasks, including the evaluation of captions generated from
vision-and-language architectures. In this paper, we propose a new recipe for a
contrastive-based evaluation metric for image captioning, namely
Positive-Augmented Contrastive learning Score (PAC-S), that in a novel way
unifies the learning of a contrastive visual-semantic space with the addition
of generated images and text on curated data. Experiments spanning several
datasets demonstrate that our new metric achieves the highest correlation with
human judgments on both images and videos, outperforming existing
reference-based metrics like CIDEr and SPICE and reference-free metrics like
CLIP-Score. Finally, we test the system-level correlation of the proposed
metric when considering popular image captioning approaches, and assess the
impact of employing different cross-modal features. Our source code and trained
models are publicly available at: https://github.com/aimagelab/pacscore.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.16200">Natural Selection Favors AIs over Humans. (arXiv:2303.16200v4 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1">Dan Hendrycks</a></p>
<p>For billions of years, evolution has been the driving force behind the
development of life, including humans. Evolution endowed humans with high
intelligence, which allowed us to become one of the most successful species on
the planet. Today, humans aim to create artificial intelligence systems that
surpass even our own intelligence. As artificial intelligences (AIs) evolve and
eventually surpass us in all domains, how might evolution shape our relations
with AIs? By analyzing the environment that is shaping the evolution of AIs, we
argue that the most successful AI agents will likely have undesirable traits.
Competitive pressures among corporations and militaries will give rise to AI
agents that automate human roles, deceive others, and gain power. If such
agents have intelligence that exceeds that of humans, this could lead to
humanity losing control of its future. More abstractly, we argue that natural
selection operates on systems that compete and vary, and that selfish species
typically have an advantage over species that are altruistic to other species.
This Darwinian logic could also apply to artificial agents, as agents may
eventually be better able to persist into the future if they behave selfishly
and pursue their own interests with little regard for humans, which could pose
catastrophic risks. To counteract these risks and evolutionary forces, we
consider interventions such as carefully designing AI agents' intrinsic
motivations, introducing constraints on their actions, and institutions that
encourage cooperation. These steps, or others that resolve the problems we
pose, will be necessary in order to ensure the development of artificial
intelligence is a positive one.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.07880">Sabi\&#x27;a: Portuguese Large Language Models. (arXiv:2304.07880v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pires_R/0/1/0/all/0/1">Ramon Pires</a>, <a href="http://arxiv.org/find/cs/1/au:+Abonizio_H/0/1/0/all/0/1">Hugo Abonizio</a>, <a href="http://arxiv.org/find/cs/1/au:+Almeida_T/0/1/0/all/0/1">Thales Sales Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Nogueira_R/0/1/0/all/0/1">Rodrigo Nogueira</a></p>
<p>As the capabilities of language models continue to advance, it is conceivable
that "one-size-fits-all" model will remain as the main paradigm. For instance,
given the vast number of languages worldwide, many of which are low-resource,
the prevalent practice is to pretrain a single model on multiple languages. In
this paper, we add to the growing body of evidence that challenges this
practice, demonstrating that monolingual pretraining on the target language
significantly improves models already extensively trained on diverse corpora.
More specifically, we further pretrain GPT-J and LLaMA models on Portuguese
texts using 3% or less of their original pretraining budget. Few-shot
evaluations on Poeta, a suite of 14 Portuguese datasets, reveal that our models
outperform English-centric and multilingual counterparts by a significant
margin. Our best model, Sabi\'a-65B, performs on par with GPT-3.5-turbo. By
evaluating on datasets originally conceived in the target language as well as
translated ones, we study the contributions of language-specific pretraining in
terms of 1) capturing linguistic nuances and structures inherent to the target
language, and 2) enriching the model's knowledge about a domain or culture. Our
results indicate that the majority of the benefits stem from the
domain-specific knowledge acquired through monolingual pretraining.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.09826">Fairness in AI and Its Long-Term Implications on Society. (arXiv:2304.09826v2 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bohdal_O/0/1/0/all/0/1">Ondrej Bohdal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1">Timothy Hospedales</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1">Fazl Barez</a></p>
<p>Successful deployment of artificial intelligence (AI) in various settings has
led to numerous positive outcomes for individuals and society. However, AI
systems have also been shown to harm parts of the population due to biased
predictions. AI fairness focuses on mitigating such biases to ensure AI
decision making is not discriminatory towards certain groups. We take a closer
look at AI fairness and analyze how lack of AI fairness can lead to deepening
of biases over time and act as a social stressor. More specifically, we discuss
how biased models can lead to more negative real-world outcomes for certain
groups, which may then become more prevalent by deploying new AI models trained
on increasingly biased data, resulting in a feedback loop. If the issues
persist, they could be reinforced by interactions with other risks and have
severe implications on society in the form of social unrest. We examine current
strategies for improving AI fairness, assess their limitations in terms of
real-world deployment, and explore potential paths forward to ensure we reap
AI's benefits without causing society's collapse.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.10159">Deep-Q Learning with Hybrid Quantum Neural Network on Solving Maze Problems. (arXiv:2304.10159v2 [quant-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Chen_H/0/1/0/all/0/1">Hao-Yuan Chen</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chang_Y/0/1/0/all/0/1">Yen-Jui Chang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chang_C/0/1/0/all/0/1">Ching-Ray Chang</a></p>
<p>Quantum computing holds great potential for advancing the limitations of
machine learning algorithms to handle higher data dimensions and reduce overall
training parameters in deep neural network (DNN) models. This study uses a
parameterized quantum circuit (PQC) on a gate-based quantum computer to
investigate the potential for quantum advantage in a model-free reinforcement
learning problem. Through a comprehensive investigation and evaluation of the
current model and capabilities of quantum computers, we designed and trained a
novel hybrid Quantum neural network based on the latest Qiskit and PyTorch
framework. We compared its performance with a full-classical DNN with and
without an integrated PQC. Our research provides insights into the potential of
deep quantum learning to solve a maze problem and, potentially, other
reinforcement learning problems. We conclude that various reinforcement
learning problems can be effective with reasonable training epochs. Moreover, a
comparative discussion of the various quantum reinforcement learning model on
maze problems is discussed to evaluate our research's overall potential and
advantages.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02442">Tackling Universal Properties of Minimal Trap Spaces of Boolean Networks. (arXiv:2305.02442v2 [cs.LO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Riva_S/0/1/0/all/0/1">Sara Riva</a>, <a href="http://arxiv.org/find/cs/1/au:+Lagniez_J/0/1/0/all/0/1">Jean-Marie Lagniez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_G/0/1/0/all/0/1">Gustavo Maga&#xf1;a L&#xf3;pez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pauleve_L/0/1/0/all/0/1">Lo&#xef;c Paulev&#xe9;</a></p>
<p>Minimal trap spaces (MTSs) capture subspaces in which the Boolean dynamics is
trapped, whatever the update mode. They correspond to the attractors of the
most permissive mode. Due to their versatility, the computation of MTSs has
recently gained traction, essentially by focusing on their enumeration. In this
paper, we address the logical reasoning on universal properties of MTSs in the
scope of two problems: the reprogramming of Boolean networks for identifying
the permanent freeze of Boolean variables that enforce a given property on all
the MTSs, and the synthesis of Boolean networks from universal properties on
their MTSs. Both problems reduce to solving the satisfiability of quantified
propositional logic formula with 3 levels of quantifiers
($\exists\forall\exists$). In this paper, we introduce a Counter-Example Guided
Refinement Abstraction (CEGAR) to efficiently solve these problems by coupling
the resolution of two simpler formulas. We provide a prototype relying on
Answer-Set Programming for each formula and show its tractability on a wide
range of Boolean models of biological networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.03017">Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study. (arXiv:2305.03017v3 [cs.SE] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rahmani_S/0/1/0/all/0/1">Sajjad Rahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Naghshzan_A/0/1/0/all/0/1">AmirHossein Naghshzan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerrouj_L/0/1/0/all/0/1">Latifa Guerrouj</a></p>
<p>Our research investigates the recommendation of code examples to aid software
developers, a practice that saves developers significant time by providing
ready-to-use code snippets. The focus of our study is Stack Overflow, a
commonly used resource for coding discussions and solutions, particularly in
the context of the Java programming language. We applied BERT, a powerful Large
Language Model (LLM) that enables us to transform code examples into numerical
vectors by extracting their semantic information. Once these numerical
representations are prepared, we identify Approximate Nearest Neighbors (ANN)
using Locality-Sensitive Hashing (LSH). Our research employed two variants of
LSH: Random Hyperplane-based LSH and Query-Aware LSH. We rigorously compared
these two approaches across four parameters: HitRate, Mean Reciprocal Rank
(MRR), Average Execution Time, and Relevance. Our study revealed that the
Query-Aware (QA) approach showed superior performance over the Random
Hyperplane-based (RH) method. Specifically, it exhibited a notable improvement
of 20% to 35% in HitRate for query pairs compared to the RH approach.
Furthermore, the QA approach proved significantly more time-efficient, with its
speed in creating hashing tables and assigning data samples to buckets being at
least four times faster. It can return code examples within milliseconds,
whereas the RH approach typically requires several seconds to recommend code
examples. Due to the superior performance of the QA approach, we tested it
against PostFinder and FaCoY, the state-of-the-art baselines. Our QA method
showed comparable efficiency proving its potential for effective code
recommendation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.06112">The Compositional Structure of Bayesian Inference. (arXiv:2305.06112v2 [math.CT] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Braithwaite_D/0/1/0/all/0/1">Dylan Braithwaite</a>, <a href="http://arxiv.org/find/math/1/au:+Hedges_J/0/1/0/all/0/1">Jules Hedges</a>, <a href="http://arxiv.org/find/math/1/au:+Smithe_T/0/1/0/all/0/1">Toby St Clere Smithe</a></p>
<p>Bayes' rule tells us how to invert a causal process in order to update our
beliefs in light of new evidence. If the process is believed to have a complex
compositional structure, we may observe that the inversion of the whole can be
computed piecewise in terms of the component processes. We study the structure
of this compositional rule, noting that it relates to the lens pattern in
functional programming. Working in a suitably general axiomatic presentation of
a category of Markov kernels, we see how we can think of Bayesian inversion as
a particular instance of a state-dependent morphism in a fibred category. We
discuss the compositional nature of this, formulated as a functor on the
underlying category and explore how this can used for a more type-driven
approach to statistical inference.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.13426">Evaluating Model Performance in Medical Datasets Over Time. (arXiv:2305.13426v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Helen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuwen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a></p>
<p>Machine learning (ML) models deployed in healthcare systems must face data
drawn from continually evolving environments. However, researchers proposing
such models typically evaluate them in a time-agnostic manner, splitting
datasets according to patients sampled randomly throughout the entire study
time period. This work proposes the Evaluation on Medical Datasets Over Time
(EMDOT) framework, which evaluates the performance of a model class across
time. Inspired by the concept of backtesting, EMDOT simulates possible training
procedures that practitioners might have been able to execute at each point in
time and evaluates the resulting models on all future time points. Evaluating
both linear and more complex models on six distinct medical data sources
(tabular and imaging), we show how depending on the dataset, using all
historical data may be ideal in many cases, whereas using a window of the most
recent data could be advantageous in others. In datasets where models suffer
from sudden degradations in performance, we investigate plausible explanations
for these shocks. We release the EMDOT package to help facilitate further works
in deployment-oriented evaluation over time.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.15299">Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond. (arXiv:2305.15299v2 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pournaras_E/0/1/0/all/0/1">Evangelos Pournaras</a></p>
<p>Large language models of artificial intelligence (AI), such as ChatGPT, find
remarkable but controversial applicability in science and research. This paper
reviews epistemological challenges, ethical and integrity risks in science
conduct in the advent of generative AI. This is with the aim to lay new timely
foundations for a high-quality research ethics review. The role of AI language
models as a research instrument and subject is scrutinized along with ethical
implications for scientists, participants and reviewers. New emerging practices
for research ethics review are discussed, concluding with ten recommendations
that shape a response for a more responsible research conduct in the era of AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.12619">Class-Incremental Learning based on Label Generation. (arXiv:2306.12619v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1">Yijia Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yiduo Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dongyan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bing Liu</a></p>
<p>Despite the great success of pre-trained language models, it is still a
challenge to use these models for continual learning, especially for the
class-incremental learning (CIL) setting due to catastrophic forgetting (CF).
This paper reports our finding that if we formulate CIL as a continual label
generation problem, CF is drastically reduced and the generalizable
representations of pre-trained models can be better retained. We thus propose a
new CIL method (VAG) that also leverages the sparsity of vocabulary to focus
the generation and creates pseudo-replay samples by using label semantics.
Experimental results show that VAG outperforms baselines by a large margin.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.13805">Potential Benefits of Employing Large Language Models in Research in Moral Education and Development. (arXiv:2306.13805v2 [cs.CY] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Hyemin Han</a></p>
<p>Recently, computer scientists have developed large language models (LLMs) by
training prediction models with large-scale language corpora and human
reinforcements. The LLMs have become one promising way to implement artificial
intelligence with accuracy in various fields. Interestingly, recent LLMs
possess emergent functional features that emulate sophisticated human
cognition, especially in-context learning and the chain of thought, which were
unavailable in previous prediction models. In this paper, I will examine how
LLMs might contribute to moral education and development research. To achieve
this goal, I will review the most recently published conference papers and
ArXiv preprints to overview the novel functional features implemented in LLMs.
I also intend to conduct brief experiments with ChatGPT to investigate how LLMs
behave while addressing ethical dilemmas and external feedback. The results
suggest that LLMs might be capable of solving dilemmas based on reasoning and
revising their reasoning process with external input. Furthermore, a
preliminary experimental result from the moral exemplar test may demonstrate
that exemplary stories can elicit moral elevation in LLMs as do they among
human participants. I will discuss the potential implications of LLMs on
research on moral education and development with the results.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.13960">Regular SE(3) Group Convolutions for Volumetric Medical Image Analysis. (arXiv:2306.13960v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kuipers_T/0/1/0/all/0/1">Thijs P. Kuipers</a>, <a href="http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1">Erik J. Bekkers</a></p>
<p>Regular group convolutional neural networks (G-CNNs) have been shown to
increase model performance and improve equivariance to different geometrical
symmetries. This work addresses the problem of SE(3), i.e., roto-translation
equivariance, on volumetric data. Volumetric image data is prevalent in many
medical settings. Motivated by the recent work on separable group convolutions,
we devise a SE(3) group convolution kernel separated into a continuous SO(3)
(rotation) kernel and a spatial kernel. We approximate equivariance to the
continuous setting by sampling uniform SO(3) grids. Our continuous SO(3) kernel
is parameterized via RBF interpolation on similarly uniform grids. We
demonstrate the advantages of our approach in volumetric medical image
analysis. Our SE(3) equivariant models consistently outperform CNNs and regular
discrete G-CNNs on challenging medical classification tasks and show
significantly improved generalization capabilities. Our approach achieves up to
a 16.5% gain in accuracy over regular CNNs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.17582">ChatGPT for Robotics: Design Principles and Model Abilities. (arXiv:2306.17582v2 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vemprala_S/0/1/0/all/0/1">Sai Vemprala</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonatti_R/0/1/0/all/0/1">Rogerio Bonatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Bucker_A/0/1/0/all/0/1">Arthur Bucker</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapoor_A/0/1/0/all/0/1">Ashish Kapoor</a></p>
<p>This paper presents an experimental study regarding the use of OpenAI's
ChatGPT for robotics applications. We outline a strategy that combines design
principles for prompt engineering and the creation of a high-level function
library which allows ChatGPT to adapt to different robotics tasks, simulators,
and form factors. We focus our evaluations on the effectiveness of different
prompt engineering techniques and dialog strategies towards the execution of
various types of robotics tasks. We explore ChatGPT's ability to use free-form
dialog, parse XML tags, and to synthesize code, in addition to the use of
task-specific prompting functions and closed-loop reasoning through dialogues.
Our study encompasses a range of tasks within the robotics domain, from basic
logical, geometrical, and mathematical reasoning all the way to complex domains
such as aerial navigation, manipulation, and embodied agents. We show that
ChatGPT can be effective at solving several of such tasks, while allowing users
to interact with it primarily via natural language instructions. In addition to
these studies, we introduce an open-sourced research tool called PromptCraft,
which contains a platform where researchers can collaboratively upload and vote
on examples of good prompting schemes for robotics applications, as well as a
sample robotics simulator with ChatGPT integration, making it easier for users
to get started with using ChatGPT for robotics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00470">PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation. (arXiv:2307.00470v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Le Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_X/0/1/0/all/0/1">Xin Shan</a></p>
<p>Large language models(LLMS)have shown excellent text generation capabilities,
capable of generating fluent human-like responses for many downstream tasks.
However, applying large language models to real-world critical tasks remains
challenging due to their susceptibility to hallucinations and inability to
directly use external knowledge. To cope with the above challenges, this paper
proposes PatternGPT, a pattern-driven text generation framework for Large
Language Models. Firstly, the framework utilizes the extraction capability of
Large Language Models to generate rich and diversified structured and
formalized patterns, which facilitates the introduction of external knowledge
to do the computation, and then draws on the idea of federated learning to use
multiple agents to achieve the sharing in order to obtain more diversified
patterns, and finally uses judgment criteria and optimization algorithm to
search for high-quality patterns to guide the generation of models. Finally,
external knowledge such as judgment criteria and optimization algorithms are
used to search for high-quality patterns, and the searched patterns are used to
guide model generation. This framework has the advantages of generating
diversified patterns, protecting data privacy, combining external knowledge,
and improving the quality of generation, which provides an effective method to
optimize the text generation capability of large language models, and make it
better applied to the field of intelligent dialogue and content generation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04005">Proceedings Nineteenth conference on Theoretical Aspects of Rationality and Knowledge. (arXiv:2307.04005v2 [cs.LO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Verbrugge_R/0/1/0/all/0/1">Rineke Verbrugge</a> (University of Groningen)</p>
<p>The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a
conference that aims to bring together researchers from a wide variety of
fields, including computer science, artificial intelligence, game theory,
decision theory, philosophy, logic, linguistics, and cognitive science. Its
goal is to further our understanding of interdisciplinary issues involving
reasoning about rationality and knowledge.
</p>
<p>Previous conferences have been held biennially around the world since 1986,
on the initiative of Joe Halpern (Cornell University). Topics of interest
include, but are not limited to, semantic models for knowledge, belief,
awareness and uncertainty, bounded rationality and resource-bounded reasoning,
commonsense epistemic reasoning, epistemic logic, epistemic game theory,
knowledge and action, applications of reasoning about knowledge and other
mental states, belief revision, computational social choice, algorithmic game
theory, and foundations of multi-agent systems. Information about TARK,
including conference proceedings, is available at <a href="http://www.tark.org/">this http URL</a>
</p>
<p>These proceedings contain the papers that have been accepted for presentation
at the Nineteenth Conference on Theoretical Aspects of Rationality and
Knowledge (TARK 2023), held between June 28 and June 30, 2023, at the
University of Oxford, United Kingdom. The conference website can be found at
https://sites.google.com/view/tark-2023
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.04668">Quantifying the Echo Chamber Effect: An Embedding Distance-based Approach. (arXiv:2307.04668v2 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Alatawi_F/0/1/0/all/0/1">Faisal Alatawi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1">Paras Sheth</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huan Liu</a></p>
<p>The rise of social media platforms has facilitated the formation of echo
chambers, which are online spaces where users predominantly encounter
viewpoints that reinforce their existing beliefs while excluding dissenting
perspectives. This phenomenon significantly hinders information dissemination
across communities and fuels societal polarization. Therefore, it is crucial to
develop methods for quantifying echo chambers. In this paper, we present the
Echo Chamber Score (ECS), a novel metric that assesses the cohesion and
separation of user communities by measuring distances between users in the
embedding space. In contrast to existing approaches, ECS is able to function
without labels for user ideologies and makes no assumptions about the structure
of the interaction graph. To facilitate measuring distances between users, we
propose EchoGAE, a self-supervised graph autoencoder-based user embedding model
that leverages users' posts and the interaction graph to embed them in a manner
that reflects their ideological similarity. To assess the effectiveness of ECS,
we use a Twitter dataset consisting of four topics - two polarizing and two
non-polarizing. Our results showcase ECS's effectiveness as a tool for
quantifying echo chambers and shedding light on the dynamics of online
discourse.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.05921">Reading Radiology Imaging Like The Radiologist. (arXiv:2307.05921v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuhao Wang</a></p>
<p>Automated radiology report generation aims to generate radiology reports that
contain rich, fine-grained descriptions of radiology imaging. Compared with
image captioning in the natural image domain, medical images are very similar
to each other, with only minor differences in the occurrence of diseases. Given
the importance of these minor differences in the radiology report, it is
crucial to encourage the model to focus more on the subtle regions of disease
occurrence. Secondly, the problem of visual and textual data biases is serious.
Not only do normal cases make up the majority of the dataset, but sentences
describing areas with pathological changes also constitute only a small part of
the paragraph. Lastly, generating medical image reports involves the challenge
of long text generation, which requires more expertise and empirical training
in medical knowledge. As a result, the difficulty of generating such reports is
increased. To address these challenges, we propose a disease-oriented retrieval
framework that utilizes similar reports as prior knowledge references. We
design a factual consistency captioning generator to generate more accurate and
factually consistent disease descriptions. Our framework can find most similar
reports for a given disease from the CXR database by retrieving a
disease-oriented mask consisting of the position and morphological
characteristics. By referencing the disease-oriented similar report and the
visual features, the factual consistency model can generate a more accurate
radiology report.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06092">Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Favaro_S/0/1/0/all/0/1">Stefano Favaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1">Boris Hanin</a>, <a href="http://arxiv.org/find/cs/1/au:+Marinucci_D/0/1/0/all/0/1">Domenico Marinucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Nourdin_I/0/1/0/all/0/1">Ivan Nourdin</a>, <a href="http://arxiv.org/find/cs/1/au:+Peccati_G/0/1/0/all/0/1">Giovanni Peccati</a></p>
<p>We study the distribution of a fully connected neural network with random
Gaussian weights and biases in which the hidden layer widths are proportional
to a large constant $n$. Under mild assumptions on the non-linearity, we obtain
quantitative bounds on normal approximations valid at large but finite $n$ and
any fixed network depth. Our theorems show both for the finite-dimensional
distributions and the entire process, that the distance between a random fully
connected network (and its derivatives) to the corresponding infinite width
Gaussian process scales like $n^{-\gamma}$ for $\gamma&gt;0$, with the exponent
depending on the metric used to measure discrepancy. Our bounds are strictly
stronger in terms of their dependence on network width than any previously
available in the literature; in the one-dimensional case, we also prove that
they are optimal, i.e., we establish matching lower bounds.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.07666">Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty. (arXiv:2307.07666v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guanlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhihan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Han Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1">Lifeng Lai</a></p>
<p>Robust reinforcement learning (RL) aims to find a policy that optimizes the
worst-case performance in the face of uncertainties. In this paper, we focus on
action robust RL with the probabilistic policy execution uncertainty, in which,
instead of always carrying out the action specified by the policy, the agent
will take the action specified by the policy with probability $1-\rho$ and an
alternative adversarial action with probability $\rho$. We establish the
existence of an optimal policy on the action robust MDPs with probabilistic
policy execution uncertainty and provide the action robust Bellman optimality
equation for its solution. Furthermore, we develop Action Robust Reinforcement
Learning with Certificates (ARRLC) algorithm that achieves minimax optimal
regret and sample complexity. Furthermore, we conduct numerical experiments to
validate our approach's robustness, demonstrating that ARRLC outperforms
non-robust RL algorithms and converges faster than the robust TD algorithm in
the presence of action perturbations.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08930">Unsupervised Deep Graph Matching Based on Cycle Consistency. (arXiv:2307.08930v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tourani_S/0/1/0/all/0/1">Siddharth Tourani</a>, <a href="http://arxiv.org/find/cs/1/au:+Rother_C/0/1/0/all/0/1">Carsten Rother</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Muhammad Haris Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Savchynskyy_B/0/1/0/all/0/1">Bogdan Savchynskyy</a></p>
<p>We contribute to the sparsely populated area of unsupervised deep graph
matching with application to keypoint matching in images. Contrary to the
standard \emph{supervised} approach, our method does not require ground truth
correspondences between keypoint pairs. Instead, it is self-supervised by
enforcing consistency of matchings between images of the same object category.
As the matching and the consistency loss are discrete, their derivatives cannot
be straightforwardly used for learning. We address this issue in a principled
way by building our method upon the recent results on black-box differentiation
of combinatorial solvers. This makes our method exceptionally flexible, as it
is compatible with arbitrary network architectures and combinatorial solvers.
Our experimental evaluation suggests that our technique sets a new
state-of-the-art for unsupervised graph matching.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.09906">Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation. (arXiv:2307.09906v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hong_F/0/1/0/all/0/1">Fa-Ting Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dan Xu</a></p>
<p>Talking head video generation aims to animate a human face in a still image
with dynamic poses and expressions using motion information derived from a
target-driving video, while maintaining the person's identity in the source
image. However, dramatic and complex motions in the driving video cause
ambiguous generation, because the still source image cannot provide sufficient
appearance information for occluded regions or delicate expression variations,
which produces severe artifacts and significantly degrades the generation
quality. To tackle this problem, we propose to learn a global facial
representation space, and design a novel implicit identity representation
conditioned memory compensation network, coined as MCNet, for high-fidelity
talking head generation.~Specifically, we devise a network module to learn a
unified spatial facial meta-memory bank from all training samples, which can
provide rich facial structure and appearance priors to compensate warped source
facial features for the generation. Furthermore, we propose an effective query
mechanism based on implicit identity representations learned from the discrete
keypoints of the source image. It can greatly facilitate the retrieval of more
correlated information from the memory bank for the compensation. Extensive
experiments demonstrate that MCNet can learn representative and complementary
facial memory, and can clearly outperform previous state-of-the-art talking
head generation methods on VoxCeleb1 and CelebV datasets. Please check our
\href{https://github.com/harlanhong/ICCV2023-MCNET}{Project}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10172">DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI. (arXiv:2307.10172v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianguo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1">Kun Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Heinecke_S/0/1/0/all/0/1">Shelby Heinecke</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1">Rui Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Ye Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhou Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a></p>
<p>Despite advancements in conversational AI, language models encounter
challenges to handle diverse conversational tasks, and existing dialogue
dataset collections often lack diversity and comprehensiveness. To tackle these
issues, we introduce DialogStudio: the largest and most diverse collection of
dialogue datasets, unified under a consistent format while preserving their
original information. Our collection encompasses data from open-domain
dialogues, task-oriented dialogues, natural language understanding,
conversational recommendation, dialogue summarization, and knowledge-grounded
dialogues, making it an incredibly rich and diverse resource for dialogue
research and model training. To further enhance the utility of DialogStudio, we
identify the licenses for each dataset and design domain-aware prompts for
selected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we
develop conversational AI models using the dataset collection, and our
experiments in both zero-shot and few-shot learning scenarios demonstrate the
superiority of DialogStudio. To improve transparency and support dataset and
task-based research, as well as language model pre-training, all datasets,
licenses, codes, and models associated with DialogStudio are made publicly
accessible at https://github.com/salesforce/DialogStudio
</p>
</p>
</div>

    </div>
    </body>
    