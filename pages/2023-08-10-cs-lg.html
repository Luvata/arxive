<!DOCTYPE html>
<html>
<head>
<title>2023-08-10-cs-lg</title>

    <style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        display: flex;
        justify-content: center;
        background-color: #f2f2f2;
    }
    .container {
        width: 60%;
        max-width: 900px;
        min-width: 300px;
        background-color: #fff;
        padding: 20px;
        margin: 20px;
        border-radius: 10px;
        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.05);
        font-size: 0.9em;
    }
    h1 {
        color: #333;
        font-size: 1.6em;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding: 10px 0;
    }
    .article a {
        color: #007BFF;
        text-decoration: none;
    }
    .article a:hover {
        color: #0056b3;
    }
    @media (max-width: 768px) {
        .container {
            width: 90%;
            font-size: 0.8em;
        }
        h1 {
            font-size: 1.4em;
        }
    }
    </style>
    </head>
    <body>
    <div class="container">
    <div class="article">
<h1><a href="http://arxiv.org/abs/2308.04444">Changes in Policy Preferences in German Tweets during the COVID Pandemic. (arXiv:2308.04444v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Biessmann_F/0/1/0/all/0/1">Felix Biessmann</a></p>
<p>Online social media have become an important forum for exchanging political
opinions. In response to COVID measures citizens expressed their policy
preferences directly on these platforms. Quantifying political preferences in
online social media remains challenging: The vast amount of content requires
scalable automated extraction of political preferences -- however fine grained
political preference extraction is difficult with current machine learning (ML)
technology, due to the lack of data sets. Here we present a novel data set of
tweets with fine grained political preference annotations. A text
classification model trained on this data is used to extract policy preferences
in a German Twitter corpus ranging from 2019 to 2022. Our results indicate that
in response to the COVID pandemic, expression of political opinions increased.
Using a well established taxonomy of policy preferences we analyse fine grained
political views and highlight changes in distinct political categories. These
analyses suggest that the increase in policy preference expression is dominated
by the categories pro-welfare, pro-education and pro-governmental
administration efficiency. All training data and code used in this study are
made publicly available to encourage other researchers to further improve
automated policy preference extraction methods. We hope that our findings
contribute to a better understanding of political statements in online social
media and to a better assessment of how COVID measures impact political
preferences.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04445">Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc. (arXiv:2308.04445v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lenat_D/0/1/0/all/0/1">Doug Lenat</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcus_G/0/1/0/all/0/1">Gary Marcus</a></p>
<p>Generative AI, the most popular current approach to AI, consists of large
language models (LLMs) that are trained to produce outputs that are plausible,
but not necessarily correct. Although their abilities are often uncanny, they
are lacking in aspects of reasoning, leading LLMs to be less than completely
trustworthy. Furthermore, their results tend to be both unpredictable and
uninterpretable.
</p>
<p>We lay out 16 desiderata for future AI, and discuss an alternative approach
to AI which could theoretically address many of the limitations associated with
current approaches: AI educated with curated pieces of explicit knowledge and
rules of thumb, enabling an inference engine to automatically deduce the
logical entailments of all that knowledge. Even long arguments produced this
way can be both trustworthy and interpretable, since the full step-by-step line
of reasoning is always available, and for each step the provenance of the
knowledge used can be documented and audited. There is however a catch: if the
logical language is expressive enough to fully represent the meaning of
anything we can say in English, then the inference engine runs much too slowly.
That's why symbolic AI systems typically settle for some fast but much less
expressive logic, such as knowledge graphs. We describe how one AI system, Cyc,
has developed ways to overcome that tradeoff and is able to reason in higher
order logic in real time.
</p>
<p>We suggest that any trustworthy general AI will need to hybridize the
approaches, the LLM approach and more formal approach, and lay out a path to
realizing that dream.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04448">Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI. (arXiv:2308.04448v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Avijit Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakshmi_D/0/1/0/all/0/1">Dhanya Lakshmi</a></p>
<p>Generative Artificial Intelligence (AI) has seen mainstream adoption lately,
especially in the form of consumer-facing, open-ended, text and image
generating models. However, the use of such systems raises significant ethical
and safety concerns, including privacy violations, misinformation and
intellectual property theft. The potential for generative AI to displace human
creativity and livelihoods has also been under intense scrutiny. To mitigate
these risks, there is an urgent need of policies and regulations responsible
and ethical development in the field of generative AI. Existing and proposed
centralized regulations by governments to rein in AI face criticisms such as
not having sufficient clarity or uniformity, lack of interoperability across
lines of jurisdictions, restricting innovation, and hindering free market
competition. Decentralized protections via crowdsourced safety tools and
mechanisms are a potential alternative. However, they have clear deficiencies
in terms of lack of adequacy of oversight and difficulty of enforcement of
ethical and safety standards, and are thus not enough by themselves as a
regulation mechanism. We propose a marriage of these two strategies via a
framework we call Dual Governance. This framework proposes a cooperative
synergy between centralized government regulations in a U.S. specific context
and safety mechanisms developed by the community to protect stakeholders from
the harms of generative AI. By implementing the Dual Governance framework, we
posit that innovation and creativity can be promoted while ensuring safe and
ethical deployment of generative AI.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04450">High-Accuracy Prediction of Metal-Insulator-Metal Metasurface with Deep Learning. (arXiv:2308.04450v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kaizhu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chui_H/0/1/0/all/0/1">Hsiang-Chen Chui</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changsen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xue Han</a></p>
<p>Deep learning prediction of electromagnetic software calculation results has
been a widely discussed issue in recent years. But the prediction accuracy was
still one of the challenges to be solved. In this work, we proposed that the
ResNets-10 model was used for predicting plasmonic metasurface S11 parameters.
The two-stage training was performed by the k-fold cross-validation and small
learning rate. After the training was completed, the prediction loss for
aluminum, gold, and silver metal-insulator-metal metasurfaces was -48.45,
-46.47, and -35.54, respectively. Due to the ultralow error value, the proposed
network can replace the traditional electromagnetic computing method for
calculation within a certain structural range. Besides, this network can finish
the training process less than 1,100 epochs. This means that the network
training process can effectively lower the design process time. The ResNets-10
model we proposed can also be used to design meta-diffractive devices and
biosensors, thereby reducing the time required for the calculation process. The
ultralow error of the network indicates that this work contributes to the
development of future artificial intelligence electromagnetic computing
software.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04457">A Critical Review of Physics-Informed Machine Learning Applications in Subsurface Energy Systems. (arXiv:2308.04457v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Latrach_A/0/1/0/all/0/1">Abdeldjalil Latrach</a>, <a href="http://arxiv.org/find/cs/1/au:+Malki_M/0/1/0/all/0/1">Mohamed Lamine Malki</a>, <a href="http://arxiv.org/find/cs/1/au:+Morales_M/0/1/0/all/0/1">Misael Morales</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehana_M/0/1/0/all/0/1">Mohamed Mehana</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabiei_M/0/1/0/all/0/1">Minou Rabiei</a></p>
<p>Machine learning has emerged as a powerful tool in various fields, including
computer vision, natural language processing, and speech recognition. It can
unravel hidden patterns within large data sets and reveal unparalleled
insights, revolutionizing many industries and disciplines. However, machine and
deep learning models lack interpretability and limited domain-specific
knowledge, especially in applications such as physics and engineering.
Alternatively, physics-informed machine learning (PIML) techniques integrate
physics principles into data-driven models. By combining deep learning with
domain knowledge, PIML improves the generalization of the model, abidance by
the governing physical laws, and interpretability. This paper comprehensively
reviews PIML applications related to subsurface energy systems, mainly in the
oil and gas industry. The review highlights the successful utilization of PIML
for tasks such as seismic applications, reservoir simulation, hydrocarbons
production forecasting, and intelligent decision-making in the exploration and
production stages. Additionally, it demonstrates PIML's capabilities to
revolutionize the oil and gas industry and other emerging areas of interest,
such as carbon and hydrogen storage; and geothermal systems by providing more
accurate and reliable predictions for resource management and operational
efficiency.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04459">MCTS guided Genetic Algorithm for optimization of neural network weights. (arXiv:2308.04459v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hebbar_A/0/1/0/all/0/1">Akshay Hebbar</a></p>
<p>In this research, we investigate the possibility of applying a search
strategy to genetic algorithms to explore the entire genetic tree structure.
Several methods aid in performing tree searches; however, simpler algorithms
such as breadth-first, depth-first, and iterative techniques are
computation-heavy and often result in a long execution time. Adversarial
techniques are often the preferred mechanism when performing a probabilistic
search, yielding optimal results more quickly. The problem we are trying to
tackle in this paper is the optimization of neural networks using genetic
algorithms. Genetic algorithms (GA) form a tree of possible states and provide
a mechanism for rewards via the fitness function. Monte Carlo Tree Search
(MCTS) has proven to be an effective tree search strategy given states and
rewards; therefore, we will combine these approaches to optimally search for
the best result generated with genetic algorithms.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04460">The Compatibility between the Pangu Weather Forecasting Model and Meteorological Operational Data. (arXiv:2308.04460v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1">Wencong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yan Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1">Jiangjiang Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_C/0/1/0/all/0/1">Chang Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhigang Wang</a></p>
<p>Recently, multiple data-driven models based on machine learning for weather
forecasting have emerged. These models are highly competitive in terms of
accuracy compared to traditional numerical weather prediction (NWP) systems. In
particular, the Pangu-Weather model, which is open source for non-commercial
use, has been validated for its forecasting performance by the European Centre
for Medium-Range Weather Forecasts (ECMWF) and has recently been published in
the journal "Nature". In this paper, we evaluate the compatibility of the
Pangu-Weather model with several commonly used NWP operational analyses through
case studies. The results indicate that the Pangu-Weather model is compatible
with different operational analyses from various NWP systems as the model
initial conditions, and it exhibits a relatively stable forecasting capability.
Furthermore, we have verified that improving the quality of global or local
initial conditions significantly contributes to enhancing the forecasting
performance of the Pangu-Weather model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04462">Characterization of Human Balance through a Reinforcement Learning-based Muscle Controller. (arXiv:2308.04462v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Akbas_K/0/1/0/all/0/1">K&#xfc;bra Akba&#x15f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Mummolo_C/0/1/0/all/0/1">Carlotta Mummolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xianlian Zhou</a></p>
<p>Balance assessment during physical rehabilitation often relies on
rubric-oriented battery tests to score a patient's physical capabilities,
leading to subjectivity. While some objective balance assessments exist, they
are often limited to tracking the center of pressure (COP), which does not
fully capture the whole-body postural stability. This study explores the use of
the center of mass (COM) state space and presents a promising avenue for
monitoring the balance capabilities in humans. We employ a musculoskeletal
model integrated with a balance controller, trained through reinforcement
learning (RL), to investigate balancing capabilities. The RL framework consists
of two interconnected neural networks governing balance recovery and muscle
coordination respectively, trained using Proximal Policy Optimization (PPO)
with reference state initialization, early termination, and multiple training
strategies. By exploring recovery from random initial COM states (position and
velocity) space for a trained controller, we obtain the final BR enclosing
successful balance recovery trajectories. Comparing the BRs with analytical
postural stability limits from a linear inverted pendulum model, we observe a
similar trend in successful COM states but more limited ranges in the
recoverable areas. We further investigate the effect of muscle weakness and
neural excitation delay on the BRs, revealing reduced balancing capability in
different regions. Overall, our approach of learning muscular balance
controllers presents a promising new method for establishing balance recovery
limits and objectively assessing balance capability in bipedal systems,
particularly in humans.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04466">Backdoor Federated Learning by Poisoning Backdoor-Critical Layers. (arXiv:2308.04466v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhuang_H/0/1/0/all/0/1">Haomin Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1">Mingxian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1">Yang Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1">Xu Yuan</a></p>
<p>Federated learning (FL) has been widely deployed to enable machine learning
training on sensitive data across distributed devices. However, the
decentralized learning paradigm and heterogeneity of FL further extend the
attack surface for backdoor attacks. Existing FL attack and defense
methodologies typically focus on the whole model. None of them recognizes the
existence of backdoor-critical (BC) layers-a small subset of layers that
dominate the model vulnerabilities. Attacking the BC layers achieves equivalent
effects as attacking the whole model but at a far smaller chance of being
detected by state-of-the-art (SOTA) defenses. This paper proposes a general
in-situ approach that identifies and verifies BC layers from the perspective of
attackers. Based on the identified BC layers, we carefully craft a new backdoor
attack methodology that adaptively seeks a fundamental balance between
attacking effects and stealthiness under various defense strategies. Extensive
experiments show that our BC layer-aware backdoor attacks can successfully
backdoor FL under seven SOTA defenses with only 10% malicious clients and
outperform the latest backdoor attack methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04469">Correlating Medi- Claim Service by Deep Learning Neural Networks. (arXiv:2308.04469v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vajiram_J/0/1/0/all/0/1">Jayanthi Vajiram</a>, <a href="http://arxiv.org/find/cs/1/au:+Senthil_N/0/1/0/all/0/1">Negha Senthil</a>, <a href="http://arxiv.org/find/cs/1/au:+P_N/0/1/0/all/0/1">Nean Adhith.P</a></p>
<p>Medical insurance claims are of organized crimes related to patients,
physicians, diagnostic centers, and insurance providers, forming a chain
reaction that must be monitored constantly. These kinds of frauds affect the
financial growth of both insured people and health insurance companies. The
Convolution Neural Network architecture is used to detect fraudulent claims
through a correlation study of regression models, which helps to detect money
laundering on different claims given by different providers. Supervised and
unsupervised classifiers are used to detect fraud and non-fraud claims.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04470">D-Score: A Synapse-Inspired Approach for Filter Pruning. (arXiv:2308.04470v1 [cs.NE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Doyoung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jinsoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Nam_J/0/1/0/all/0/1">Jina Nam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1">Jooyoung Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sang Min Park</a></p>
<p>This paper introduces a new aspect for determining the rank of the
unimportant filters for filter pruning on convolutional neural networks (CNNs).
In the human synaptic system, there are two important channels known as
excitatory and inhibitory neurotransmitters that transmit a signal from a
neuron to a cell. Adopting the neuroscientific perspective, we propose a
synapse-inspired filter pruning method, namely Dynamic Score (D-Score). D-Score
analyzes the independent importance of positive and negative weights in the
filters and ranks the independent importance by assigning scores. Filters
having low overall scores, and thus low impact on the accuracy of neural
networks are pruned. The experimental results on CIFAR-10 and ImageNet datasets
demonstrate the effectiveness of our proposed method by reducing notable
amounts of FLOPs and Params without significant Acc. Drop.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04493">Efficient option pricing with unary-based photonic computing chip and generative adversarial learning. (arXiv:2308.04493v1 [quant-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Zhang_H/0/1/0/all/0/1">Hui Zhang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wan_L/0/1/0/all/0/1">Lingxiao Wan</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ramos_Calderer_S/0/1/0/all/0/1">Sergi Ramos-Calderer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhan_Y/0/1/0/all/0/1">Yuancheng Zhan</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Mok_W/0/1/0/all/0/1">Wai-Keong Mok</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Cai_H/0/1/0/all/0/1">Hong Cai</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gao_F/0/1/0/all/0/1">Feng Gao</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Luo_X/0/1/0/all/0/1">Xianshu Luo</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Lo_G/0/1/0/all/0/1">Guo-Qiang Lo</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kwek_L/0/1/0/all/0/1">Leong Chuan Kwek</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Latorre_J/0/1/0/all/0/1">Jos&#xe9; Ignacio Latorre</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Liu_A/0/1/0/all/0/1">Ai Qun Liu</a></p>
<p>In the modern financial industry system, the structure of products has become
more and more complex, and the bottleneck constraint of classical computing
power has already restricted the development of the financial industry. Here,
we present a photonic chip that implements the unary approach to European
option pricing, in combination with the quantum amplitude estimation algorithm,
to achieve a quadratic speedup compared to classical Monte Carlo methods. The
circuit consists of three modules: a module loading the distribution of asset
prices, a module computing the expected payoff, and a module performing the
quantum amplitude estimation algorithm to introduce speed-ups. In the
distribution module, a generative adversarial network is embedded for efficient
learning and loading of asset distributions, which precisely capture the market
trends. This work is a step forward in the development of specialized photonic
processors for applications in finance, with the potential to improve the
efficiency and quality of financial services.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04501">Investigation of compressor cascade flow based on physics-informed neural networks. (arXiv:2308.04501v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhihui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Montomoli_F/0/1/0/all/0/1">Francesco Montomoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Sanjiv Sharma</a></p>
<p>In this study, we utilize the emerging Physics Informed Neural Networks
(PINNs) approach for the first time to predict the flow field of a compressor
cascade. The approach is demonstrated on a two-dimensional problem,
incorporating Navier-Stokes equations in both the forward and inverse problems.
In the forward problem, PINNs effectively predict the flow field of the
compressor. The key advantage over Deep Neural Networks (DNNs) is that the
PINNs model incorporates a physical relationship between the relevant
quantities, resulting in more precise predictions. PINNs show obvious
advantages over the traditional CFD approaches when dealing with inverse
problems in the absence of partial boundary conditions. PINNs successfully
reconstruct the flow field of the compressor cascade solely based on partial
velocity vectors and wall pressure information. This research provides
compelling evidence that PINNs offer turbomachinery designers a promising
alternative to the current dominant CFD methods, delivering higher accuracy
compared to DNNs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04511">MT-IceNet -- A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting. (arXiv:2308.04511v1 [physics.ao-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Ali_S/0/1/0/all/0/1">Sahara Ali</a>, <a href="http://arxiv.org/find/physics/1/au:+Wang_J/0/1/0/all/0/1">Jianwu Wang</a></p>
<p>Arctic amplification has altered the climate patterns both regionally and
globally, resulting in more frequent and more intense extreme weather events in
the past few decades. The essential part of Arctic amplification is the
unprecedented sea ice loss as demonstrated by satellite observations.
Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales has
been a major research question with fundamental challenges at play. In addition
to physics-based Earth system models, researchers have been applying multiple
statistical and machine learning models for sea ice forecasting. Looking at the
potential of data-driven approaches to study sea ice variations, we propose
MT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning model
for forecasting Arctic sea ice concentration (SIC). The model uses an
encoder-decoder architecture with skip connections and processes multi-temporal
input streams to regenerate spatial maps at future timesteps. Using bi-monthly
and monthly satellite retrieved sea ice data from NSIDC as well as atmospheric
and oceanic variables from ERA5 reanalysis product during 1979-2021, we show
that our proposed model provides promising predictive performance for per-pixel
SIC forecasting with up to 60% decrease in prediction error for a lead time of
6 months as compared to its state-of-the-art counterparts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04522">Deep Learning for Diverse Data Types Steganalysis: A Review. (arXiv:2308.04522v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kheddar_H/0/1/0/all/0/1">Hamza Kheddar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hemis_M/0/1/0/all/0/1">Mustapha Hemis</a>, <a href="http://arxiv.org/find/cs/1/au:+Himeur_Y/0/1/0/all/0/1">Yassine Himeur</a>, <a href="http://arxiv.org/find/cs/1/au:+Megias_D/0/1/0/all/0/1">David Meg&#xed;as</a>, <a href="http://arxiv.org/find/cs/1/au:+Amira_A/0/1/0/all/0/1">Abbes Amira</a></p>
<p>Steganography and steganalysis are two interrelated aspects of the field of
information security. Steganography seeks to conceal communications, whereas
steganalysis is aimed to either find them or even, if possible, recover the
data they contain. Steganography and steganalysis have attracted a great deal
of interest, particularly from law enforcement. Steganography is often used by
cybercriminals and even terrorists to avoid being captured while in possession
of incriminating evidence, even encrypted, since cryptography is prohibited or
restricted in many countries. Therefore, knowledge of cutting-edge techniques
to uncover concealed information is crucial in exposing illegal acts. Over the
last few years, a number of strong and reliable steganography and steganalysis
techniques have been introduced in the literature. This review paper provides a
comprehensive overview of deep learning-based steganalysis techniques used to
detect hidden information within digital media. The paper covers all types of
cover in steganalysis, including image, audio, and video, and discusses the
most commonly used deep learning techniques. In addition, the paper explores
the use of more advanced deep learning techniques, such as deep transfer
learning (DTL) and deep reinforcement learning (DRL), to enhance the
performance of steganalysis systems. The paper provides a systematic review of
recent research in the field, including data sets and evaluation metrics used
in recent studies. It also presents a detailed analysis of DTL-based
steganalysis approaches and their performance on different data sets. The
review concludes with a discussion on the current state of deep learning-based
steganalysis, challenges, and future research directions.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04524">Who should I Collaborate with? A Comparative Study of Academia and Industry Research Collaboration in NLP. (arXiv:2308.04524v1 [cs.DL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Abuwala_H/0/1/0/all/0/1">Hussain Sadiq Abuwala</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mushi Wang</a></p>
<p>The goal of our research was to investigate the effects of collaboration
between academia and industry on Natural Language Processing (NLP). To do this,
we created a pipeline to extract affiliations and citations from NLP papers and
divided them into three categories: academia, industry, and hybrid
(collaborations between academia and industry). Our empirical analysis found
that there is a trend towards an increase in industry and academia-industry
collaboration publications and that these types of publications tend to have a
higher impact compared to those produced solely within academia.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04539">Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures. (arXiv:2308.04539v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Madireddy_S/0/1/0/all/0/1">Sandeep Madireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Yanguas_Gil_A/0/1/0/all/0/1">Angel Yanguas-Gil</a>, <a href="http://arxiv.org/find/cs/1/au:+Balaprakash_P/0/1/0/all/0/1">Prasanna Balaprakash</a></p>
<p>The ability to learn continuously from an incoming data stream without
catastrophic forgetting is critical to designing intelligent systems. Many
approaches to continual learning rely on stochastic gradient descent and its
variants that employ global error updates, and hence need to adopt strategies
such as memory buffers or replay to circumvent its stability, greed, and
short-term memory limitations. To address this limitation, we have developed a
biologically inspired lightweight neural network architecture that incorporates
synaptic plasticity mechanisms and neuromodulation and hence learns through
local error signals to enable online continual learning without stochastic
gradient descent.
</p>
<p>Our approach leads to superior online continual learning performance on
Split-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to other
memory-constrained learning approaches and matches that of the state-of-the-art
memory-intensive replay-based approaches. We further demonstrate the
effectiveness of our approach by integrating key design concepts into other
backpropagation-based continual learning algorithms, significantly improving
their accuracy. Our results provide compelling evidence for the importance of
incorporating biological principles into machine learning models and offer
insights into how we can leverage them to design more efficient and robust
systems for online continual learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04551">Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining. (arXiv:2308.04551v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Khanal_B/0/1/0/all/0/1">Bidur Khanal</a>, <a href="http://arxiv.org/find/eess/1/au:+Bhattarai_B/0/1/0/all/0/1">Binod Bhattarai</a>, <a href="http://arxiv.org/find/eess/1/au:+Khanal_B/0/1/0/all/0/1">Bishesh Khanal</a>, <a href="http://arxiv.org/find/eess/1/au:+Linte_C/0/1/0/all/0/1">Cristian A. Linte</a></p>
<p>Noisy labels hurt deep learning-based supervised image classification
performance as the models may overfit the noise and learn corrupted feature
extractors. For natural image classification training with noisy labeled data,
model initialization with contrastive self-supervised pretrained weights has
shown to reduce feature corruption and improve classification performance.
However, no works have explored: i) how other self-supervised approaches, such
as pretext task-based pretraining, impact the learning with noisy label, and
ii) any self-supervised pretraining methods alone for medical images in noisy
label settings. Medical images often feature smaller datasets and subtle inter
class variations, requiring human expertise to ensure correct classification.
Thus, it is not clear if the methods improving learning with noisy labels in
natural image datasets such as CIFAR would also help with medical images. In
this work, we explore contrastive and pretext task-based self-supervised
pretraining to initialize the weights of a deep learning classification model
for two medical datasets with self-induced noisy labels -- NCT-CRC-HE-100K
tissue histological images and COVID-QU-Ex chest X-ray images. Our results show
that models initialized with pretrained weights obtained from self-supervised
learning can effectively learn better features and improve robustness against
noisy labels.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04553">From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data. (arXiv:2308.04553v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qraitem_M/0/1/0/all/0/1">Maan Qraitem</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Plummer_B/0/1/0/all/0/1">Bryan A. Plummer</a></p>
<p>Visual recognition models are prone to learning spurious correlations induced
by an imbalanced training set where certain groups (\eg Females) are
under-represented in certain classes (\eg Programmers). Generative models offer
a promising direction in mitigating this bias by generating synthetic data for
the minority samples and thus balancing the training set. However, prior work
that uses these approaches overlooks that visual recognition models could often
learn to differentiate between real and synthetic images and thus fail to
unlearn the bias in the original dataset. In our work, we propose a novel
two-stage pipeline to mitigate this issue where 1) we pre-train a model on a
balanced synthetic dataset and then 2) fine-tune on the real data. Using this
pipeline, we avoid training on both real and synthetic data, thus avoiding the
bias between real and synthetic data. Moreover, we learn robust features
against the bias in the first step that mitigate the bias in the second step.
Moreover, our pipeline naturally integrates with bias mitigation methods; they
can be simply applied to the fine-tuning step. As our experiments prove, our
pipeline can further improve the performance of bias mitigation methods
obtaining state-of-the-art performance on three large-scale datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04579">RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose Recommendation System?. (arXiv:2308.04579v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pesaranghader_A/0/1/0/all/0/1">Ali Pesaranghader</a>, <a href="http://arxiv.org/find/cs/1/au:+Sajed_T/0/1/0/all/0/1">Touqir Sajed</a></p>
<p>Over the past two decades, recommendation systems (RSs) have used machine
learning (ML) solutions to recommend items, e.g., movies, books, and
restaurants, to clients of a business or an online platform. Recipe
recommendation, however, has not yet received much attention compared to those
applications. We introduce RECipe as a multi-purpose recipe recommendation
framework with a multi-modal knowledge graph (MMKG) backbone. The motivation
behind RECipe is to go beyond (deep) neural collaborative filtering (NCF) by
recommending recipes to users when they query in natural language or by
providing an image. RECipe consists of 3 subsystems: (1) behavior-based
recommender, (2) review-based recommender, and (3) image-based recommender.
Each subsystem relies on the embedding representations of entities and
relations in the graph. We first obtain (pre-trained) embedding representations
of textual entities, such as reviews or ingredients, from a fine-tuned model of
Microsoft's MPNet. We initialize the weights of the entities with these
embeddings to train our knowledge graph embedding (KGE) model. For the visual
component, i.e., recipe images, we develop a KGE-Guided variational autoencoder
(KG-VAE) to learn the distribution of images and their latent representations.
Once KGE and KG-VAE models are fully trained, we use them as a multi-purpose
recommendation framework. For benchmarking, we created two knowledge graphs
(KGs) from public datasets on Kaggle for recipe recommendation. Our experiments
show that the KGE models have comparable performance to the neural solutions.
We also present pre-trained NLP embeddings to address important applications
such as zero-shot inference for new users (or the cold start problem) and
conditional recommendation with respect to recipe categories. We eventually
demonstrate the application of RECipe in a multi-purpose recommendation
setting.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04585">Kernel Single Proxy Control for Deterministic Confounding. (arXiv:2308.04585v1 [stat.ML])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Xu_L/0/1/0/all/0/1">Liyuan Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a></p>
<p>We consider the problem of causal effect estimation with an unobserved
confounder, where we observe a proxy variable that is associated with the
confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to
recover the true causal effect, we show that a single proxy variable is
sufficient for causal estimation if the outcome is generated deterministically,
generalizing Control Outcome Calibration Approach (COCA). We propose two
kernel-based methods for this setting: the first based on the two-stage
regression approach, and the second based on a maximum moment restriction
approach. We prove that both approaches can consistently estimate the causal
effect, and we empirically demonstrate that we can successfully recover the
causal effect on a synthetic dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04588">ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems. (arXiv:2308.04588v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Harry Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jorgensen_S/0/1/0/all/0/1">Steven Jorgensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Holodnak_J/0/1/0/all/0/1">John Holodnak</a>, <a href="http://arxiv.org/find/cs/1/au:+Wollaber_A/0/1/0/all/0/1">Allan Wollaber</a></p>
<p>Recently, uncertainty-aware deep learning methods for multiclass labeling
problems have been developed that provide calibrated class prediction
probabilities and out-of-distribution (OOD) indicators, letting machine
learning (ML) consumers and engineers gauge a model's confidence in its
predictions. However, this extra neural network prediction information is
challenging to scalably convey visually for arbitrary data sources under
multiple uncertainty contexts. To address these challenges, we present
ScatterUQ, an interactive system that provides targeted visualizations to allow
users to better understand model performance in context-driven uncertainty
settings. ScatterUQ leverages recent advances in distance-aware neural
networks, together with dimensionality reduction techniques, to construct
robust, 2-D scatter plots explaining why a model predicts a test example to be
(1) in-distribution and of a particular class, (2) in-distribution but unsure
of the class, and (3) out-of-distribution. ML consumers and engineers can
visually compare the salient features of test samples with training examples
through the use of a ``hover callback'' to understand model uncertainty
performance and decide follow up courses of action. We demonstrate the
effectiveness of ScatterUQ to explain model uncertainty for a multiclass image
classification on a distance-aware neural network trained on Fashion-MNIST and
tested on Fashion-MNIST (in distribution) and MNIST digits (out of
distribution), as well as a deep learning model for a cyber dataset. We
quantitatively evaluate dimensionality reduction techniques to optimize our
contextually driven UQ visualizations. Our results indicate that the ScatterUQ
system should scale to arbitrary, multiclass datasets. Our code is available at
https://github.com/mit-ll-responsible-ai/equine-webapp
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04595">Quantization Aware Factorization for Deep Neural Network Compression. (arXiv:2308.04595v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cherniuk_D/0/1/0/all/0/1">Daria Cherniuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Abukhovich_S/0/1/0/all/0/1">Stanislav Abukhovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_A/0/1/0/all/0/1">Anh-Huy Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1">Ivan Oseledets</a>, <a href="http://arxiv.org/find/cs/1/au:+Cichocki_A/0/1/0/all/0/1">Andrzej Cichocki</a>, <a href="http://arxiv.org/find/cs/1/au:+Gusak_J/0/1/0/all/0/1">Julia Gusak</a></p>
<p>Tensor decomposition of convolutional and fully-connected layers is an
effective way to reduce parameters and FLOP in neural networks. Due to memory
and power consumption limitations of mobile or embedded devices, the
quantization step is usually necessary when pre-trained models are deployed. A
conventional post-training quantization approach applied to networks with
decomposed weights yields a drop in accuracy. This motivated us to develop an
algorithm that finds tensor approximation directly with quantized factors and
thus benefit from both compression techniques while keeping the prediction
quality of the model. Namely, we propose to use Alternating Direction Method of
Multipliers (ADMM) for Canonical Polyadic (CP) decomposition with factors whose
elements lie on a specified quantization grid. We compress neural network
weights with a devised algorithm and evaluate it's prediction quality and
performance. We compare our approach to state-of-the-art post-training
quantization methods and demonstrate competitive results and high flexibility
in achiving a desirable quality-performance tradeoff.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04603">Deep Learning based Image Watermarking: A Brief Survey. (arXiv:2308.04603v1 [cs.MM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhong_X/0/1/0/all/0/1">Xin Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1">Arjon Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Alrasheedi_F/0/1/0/all/0/1">Fahad Alrasheedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanvir_A/0/1/0/all/0/1">Abdullah Tanvir</a></p>
<p>The act of secretly embedding and extracting a watermark on a cover image to
protect it is known as image watermarking. In recent years, deep learning-based
image watermarking techniques have been emerging one after another. To study
the state-of-the-art, this survey categorizes cutting-edge deep learning-based
image watermarking techniques into Embedder-Extractor Joint Training, Deep
Networks as a Feature Transformation, and Hybrid schemes. Research directions
in each category are also analyzed and summarized. Additionally, potential
future research directions are discussed to envision future studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04604">A Survey on Decentralized Federated Learning. (arXiv:2308.04604v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gabrielli_E/0/1/0/all/0/1">Edoardo Gabrielli</a>, <a href="http://arxiv.org/find/cs/1/au:+Pica_G/0/1/0/all/0/1">Giovanni Pica</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolomei_G/0/1/0/all/0/1">Gabriele Tolomei</a></p>
<p>In recent years, federated learning (FL) has become a very popular paradigm
for training distributed, large-scale, and privacy-preserving machine learning
(ML) systems. In contrast to standard ML, where data must be collected at the
exact location where training is performed, FL takes advantage of the
computational capabilities of millions of edge devices to collaboratively train
a shared, global model without disclosing their local private data.
Specifically, in a typical FL system, the central server acts only as an
orchestrator; it iteratively gathers and aggregates all the local models
trained by each client on its private data until convergence. Although FL
undoubtedly has several benefits over traditional ML (e.g., it protects private
data ownership by design), it suffers from several weaknesses. One of the most
critical challenges is to overcome the centralized orchestration of the
classical FL client-server architecture, which is known to be vulnerable to
single-point-of-failure risks and man-in-the-middle attacks, among others. To
mitigate such exposure, decentralized FL solutions have emerged where all FL
clients cooperate and communicate without a central server. This survey
comprehensively summarizes and reviews existing decentralized FL approaches
proposed in the literature. Furthermore, it identifies emerging challenges and
suggests promising research directions in this under-explored domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04605">PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data. (arXiv:2308.04605v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Shen_J/0/1/0/all/0/1">Jingyi Shen</a>, <a href="http://arxiv.org/find/eess/1/au:+Shen_H/0/1/0/all/0/1">Han-Wei Shen</a></p>
<p>Although many deep-learning-based super-resolution approaches have been
proposed in recent years, because no ground truth is available in the inference
stage, few can quantify the errors and uncertainties of the super-resolved
results. For scientific visualization applications, however, conveying
uncertainties of the results to scientists is crucial to avoid generating
misleading or incorrect information. In this paper, we propose PSRFlow, a novel
normalizing flow-based generative model for scientific data super-resolution
that incorporates uncertainty quantification into the super-resolution process.
PSRFlow learns the conditional distribution of the high-resolution data based
on the low-resolution counterpart. By sampling from a Gaussian latent space
that captures the missing information in the high-resolution data, one can
generate different plausible super-resolution outputs. The efficient sampling
in the Gaussian latent space allows our model to perform uncertainty
quantification for the super-resolved results. During model training, we
augment the training data with samples across various scales to make the model
adaptable to data of different scales, achieving flexible super-resolution for
a given input. Our results demonstrate superior performance and robust
uncertainty quantification compared with existing methods such as interpolation
and GAN-based super-resolution networks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04611">Deep Learning Driven Detection of Tsunami Related Internal GravityWaves: a path towards open-ocean natural hazards detection. (arXiv:2308.04611v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Constantinou_V/0/1/0/all/0/1">Valentino Constantinou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravanelli_M/0/1/0/all/0/1">Michela Ravanelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hamlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bortnik_J/0/1/0/all/0/1">Jacob Bortnik</a></p>
<p>Tsunamis can trigger internal gravity waves (IGWs) in the ionosphere,
perturbing the Total Electron Content (TEC) - referred to as Traveling
Ionospheric Disturbances (TIDs) that are detectable through the Global
Navigation Satellite System (GNSS). The GNSS are constellations of satellites
providing signals from Earth orbit - Europe's Galileo, the United States'
Global Positioning System (GPS), Russia's Global'naya Navigatsionnaya
Sputnikovaya Sistema (GLONASS) and China's BeiDou. The real-time detection of
TIDs provides an approach for tsunami detection, enhancing early warning
systems by providing open-ocean coverage in geographic areas not serviceable by
buoy-based warning systems. Large volumes of the GNSS data is leveraged by deep
learning, which effectively handles complex non-linear relationships across
thousands of data streams. We describe a framework leveraging slant total
electron content (sTEC) from the VARION (Variometric Approach for Real-Time
Ionosphere Observation) algorithm by Gramian Angular Difference Fields (from
Computer Vision) and Convolutional Neural Networks (CNNs) to detect TIDs in
near-real-time. Historical data from the 2010 Maule, 2011 Tohoku and the 2012
Haida-Gwaii earthquakes and tsunamis are used in model training, and the
later-occurring 2015 Illapel earthquake and tsunami in Chile for out-of-sample
model validation. Using the experimental framework described in the paper, we
achieved a 91.7% F1 score. Source code is available at:
https://github.com/vc1492a/tidd. Our work represents a new frontier in
detecting tsunami-driven IGWs in open-ocean, dramatically improving the
potential for natural hazards detection for coastal communities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04615">Sparse Array Design for Direction Finding using Deep Learning. (arXiv:2308.04615v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mishra_K/0/1/0/all/0/1">Kumar Vijay Mishra</a>, <a href="http://arxiv.org/find/eess/1/au:+Elbir_A/0/1/0/all/0/1">Ahmet M. Elbir</a>, <a href="http://arxiv.org/find/eess/1/au:+Ichige_K/0/1/0/all/0/1">Koichi Ichige</a></p>
<p>In the past few years, deep learning (DL) techniques have been introduced for
designing sparse arrays. These methods offer the advantages of feature
engineering and low prediction-stage complexity, which is helpful in tackling
the combinatorial search inherent to finding a sparse array. In this chapter,
we provide a synopsis of several direction finding applications of DL-based
sparse arrays. We begin by examining supervised and transfer learning
techniques that have applications in selecting sparse arrays for a cognitive
radar application. Here, we also discuss the use of meta-heuristic learning
algorithms such as simulated annealing for the case of designing
two-dimensional sparse arrays. Next, we consider DL-based antenna selection for
wireless communications, wherein sparse array problem may also be combined with
channel estimation, beamforming, or localization. Finally, we provide an
example of deep sparse array technique for integrated sensing and
communications (ISAC) application, wherein a trade-off of radar and
communications performance makes ISAC sparse array problem very challenging.
For each setting, we illustrate the performance of model-based optimization and
DL techniques through several numerical experiments. We discuss additional
considerations required to ensure robustness of DL-based algorithms against
various imperfections in array data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04616">Machine Learning, Deep Learning and Data Preprocessing Techniques for Detection, Prediction, and Monitoring of Stress and Stress-related Mental Disorders: A Scoping Review. (arXiv:2308.04616v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Razavi_M/0/1/0/all/0/1">Moein Razavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziyadidegan_S/0/1/0/all/0/1">Samira Ziyadidegan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jahromi_R/0/1/0/all/0/1">Reza Jahromi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazeminasab_S/0/1/0/all/0/1">Saber Kazeminasab</a>, <a href="http://arxiv.org/find/cs/1/au:+Janfaza_V/0/1/0/all/0/1">Vahid Janfaza</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmoudzadeh_A/0/1/0/all/0/1">Ahmadreza Mahmoudzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Baharlouei_E/0/1/0/all/0/1">Elaheh Baharlouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasangohar_F/0/1/0/all/0/1">Farzan Sasangohar</a></p>
<p>This comprehensive review systematically evaluates Machine Learning (ML)
methodologies employed in the detection, prediction, and analysis of mental
stress and its consequent mental disorders (MDs). Utilizing a rigorous scoping
review process, the investigation delves into the latest ML algorithms,
preprocessing techniques, and data types employed in the context of stress and
stress-related MDs. The findings highlight that Support Vector Machine (SVM),
Neural Network (NN), and Random Forest (RF) models consistently exhibit
superior accuracy and robustness among all machine learning algorithms
examined. Furthermore, the review underscores that physiological parameters,
such as heart rate measurements and skin response, are prevalently used as
stress predictors in ML algorithms. This is attributed to their rich
explanatory information concerning stress and stress-related MDs, as well as
the relative ease of data acquisition. Additionally, the application of
dimensionality reduction techniques, including mappings, feature selection,
filtering, and noise reduction, is frequently observed as a crucial step
preceding the training of ML algorithms. The synthesis of this review
identifies significant research gaps and outlines future directions for the
field. These encompass areas such as model interpretability, model
personalization, the incorporation of naturalistic settings, and real-time
processing capabilities for detection and prediction of stress and
stress-related MDs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04617">Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection. (arXiv:2308.04617v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Z/0/1/0/all/0/1">Zhen Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_D/0/1/0/all/0/1">David J. Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Kesidis_G/0/1/0/all/0/1">George Kesidis</a></p>
<p>Deep neural networks are vulnerable to backdoor attacks (Trojans), where an
attacker poisons the training set with backdoor triggers so that the neural
network learns to classify test-time triggers to the attacker's designated
target class. Recent work shows that backdoor poisoning induces over-fitting
(abnormally large activations) in the attacked model, which motivates a
general, post-training clipping method for backdoor mitigation, i.e., with
bounds on internal-layer activations learned using a small set of clean
samples. We devise a new such approach, choosing the activation bounds to
explicitly limit classification margins. This method gives superior performance
against peer methods for CIFAR-10 image classification. We also show that this
method has strong robustness against adaptive attacks, X2X attacks, and on
different datasets. Finally, we demonstrate a method extension for test-time
detection and correction based on the output differences between the original
and activation-bounded networks. The code of our method is online available.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04620">Multiclass Online Learnability under Bandit Feedback. (arXiv:2308.04620v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Raman_A/0/1/0/all/0/1">Ananth Raman</a>, <a href="http://arxiv.org/find/cs/1/au:+Raman_V/0/1/0/all/0/1">Vinod Raman</a>, <a href="http://arxiv.org/find/cs/1/au:+Subedi_U/0/1/0/all/0/1">Unique Subedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1">Ambuj Tewari</a></p>
<p>We study online multiclass classification under bandit feedback. We extend
the results of (daniely2013price) by showing that the finiteness of the Bandit
Littlestone dimension is necessary and sufficient for bandit online multiclass
learnability even when the label space is unbounded. Our result complements the
recent work by (hanneke2023multiclass) who show that the Littlestone dimension
characterizes online multiclass learnability in the full-information setting
when the label space is unbounded.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04637">Sparse Binary Transformers for Multivariate Time Series Modeling. (arXiv:2308.04637v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gorbett_M/0/1/0/all/0/1">Matt Gorbett</a>, <a href="http://arxiv.org/find/cs/1/au:+Shirazi_H/0/1/0/all/0/1">Hossein Shirazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_I/0/1/0/all/0/1">Indrakshi Ray</a></p>
<p>Compressed Neural Networks have the potential to enable deep learning across
new applications and smaller computational environments. However, understanding
the range of learning tasks in which such models can succeed is not well
studied. In this work, we apply sparse and binary-weighted Transformers to
multivariate time series problems, showing that the lightweight models achieve
accuracy comparable to that of dense floating-point Transformers of the same
structure. Our model achieves favorable results across three time series
learning tasks: classification, anomaly detection, and single-step forecasting.
Additionally, to reduce the computational complexity of the attention
mechanism, we apply two modifications, which show little to no decline in model
performance: 1) in the classification task, we apply a fixed mask to the query,
key, and value activations, and 2) for forecasting and anomaly detection, which
rely on predicting outputs at a single point in time, we propose an attention
mask to allow computation only at the current time step. Together, each
compression technique and attention modification substantially reduces the
number of non-zero operations necessary in the Transformer. We measure the
computational savings of our approach over a range of metrics including
parameter count, bit size, and floating point operation (FLOPs) count, showing
up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04649">Enhancing Optimization Performance: A Novel Hybridization of Gaussian Crunching Search and Powell&#x27;s Method for Derivative-Free Optimization. (arXiv:2308.04649v1 [math.OC])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Wong_B/0/1/0/all/0/1">Benny Wong</a></p>
<p>This research paper presents a novel approach to enhance optimization
performance through the hybridization of Gaussian Crunching Search (GCS) and
Powell's Method for derivative-free optimization. While GCS has shown promise
in overcoming challenges faced by traditional derivative-free optimization
methods [1], it may not always excel in finding the local minimum. On the other
hand, some traditional methods may have better performance in this regard.
However, GCS demonstrates its strength in escaping the trap of local minima and
approaching the global minima. Through experimentation, we discovered that by
combining GCS with certain traditional derivative-free optimization methods, we
can significantly boost performance while retaining the respective advantages
of each method. This hybrid approach opens up new possibilities for optimizing
complex systems and finding optimal solutions in a range of applications.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04650">Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals. (arXiv:2308.04650v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1">Hyewon Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Stultz_C/0/1/0/all/0/1">Collin M. Stultz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1">Marzyeh Ghassemi</a></p>
<p>Heart failure is a debilitating condition that affects millions of people
worldwide and has a significant impact on their quality of life and mortality
rates. An objective assessment of cardiac pressures remains an important method
for the diagnosis and treatment prognostication for patients with heart
failure. Although cardiac catheterization is the gold standard for estimating
central hemodynamic pressures, it is an invasive procedure that carries
inherent risks, making it a potentially dangerous procedure for some patients.
Approaches that leverage non-invasive signals - such as electrocardiogram (ECG)
- have the promise to make the routine estimation of cardiac pressures feasible
in both inpatient and outpatient settings. Prior models trained to estimate
intracardiac pressures (e.g., mean pulmonary capillary wedge pressure (mPCWP))
in a supervised fashion have shown good discriminatory ability but have been
limited to the labeled dataset from the heart failure cohort. To address this
issue and build a robust representation, we apply deep metric learning (DML)
and propose a novel self-supervised DML with distance-based mining that
improves the performance of a model with limited labels. We use a dataset that
contains over 5.4 million ECGs without concomitant central pressure labels to
pre-train a self-supervised DML model which showed improved classification of
elevated mPCWP compared to self-supervised contrastive baselines. Additionally,
the supervised DML model that is using ECGs with access to 8,172 mPCWP labels
demonstrated significantly better performance on the mPCWP regression task
compared to the supervised baseline. Moreover, our data suggest that DML yields
models that are performant across patient subgroups, even when some patient
subgroups are under-represented in the dataset. Our code is available at
https://github.com/mandiehyewon/ssldml
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04653">Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores. (arXiv:2308.04653v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Quihui_Rubio_P/0/1/0/all/0/1">Pablo Cesar Quihui-Rubio</a>, <a href="http://arxiv.org/find/eess/1/au:+Flores_Araiza_D/0/1/0/all/0/1">Daniel Flores-Araiza</a>, <a href="http://arxiv.org/find/eess/1/au:+Ochoa_Ruiz_G/0/1/0/all/0/1">Gilberto Ochoa-Ruiz</a>, <a href="http://arxiv.org/find/eess/1/au:+Gonzalez_Mendoza_M/0/1/0/all/0/1">Miguel Gonzalez-Mendoza</a>, <a href="http://arxiv.org/find/eess/1/au:+Mata_C/0/1/0/all/0/1">Christian Mata</a></p>
<p>This study focuses on comparing deep learning methods for the segmentation
and quantification of uncertainty in prostate segmentation from MRI images. The
aim is to improve the workflow of prostate cancer detection and diagnosis.
Seven different U-Net-based architectures, augmented with Monte-Carlo dropout,
are evaluated for automatic segmentation of the central zone, peripheral zone,
transition zone, and tumor, with uncertainty estimation. The top-performing
model in this study is the Attention R2U-Net, achieving a mean Intersection
over Union (IoU) of 76.3% and Dice Similarity Coefficient (DSC) of 85% for
segmenting all zones. Additionally, Attention R2U-Net exhibits the lowest
uncertainty values, particularly in the boundaries of the transition zone and
tumor, when compared to the other models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04660">Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Multiple Heterogeneous Datasets. (arXiv:2308.04660v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lyu_W/0/1/0/all/0/1">Wenlong Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shoubo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuai_J/0/1/0/all/0/1">Jie Chuai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhitang Chen</a></p>
<p>Bayesian optimization (BO) is widely adopted in black-box optimization
problems and it relies on a surrogate model to approximate the black-box
response function. With the increasing number of black-box optimization tasks
solved and even more to solve, the ability to learn from multiple prior tasks
to jointly pre-train a surrogate model is long-awaited to further boost
optimization efficiency. In this paper, we propose a simple approach to
pre-train a surrogate, which is a Gaussian process (GP) with a kernel defined
on deep features learned from a Transformer-based encoder, using datasets from
prior tasks with possibly heterogeneous input spaces. In addition, we provide a
simple yet effective mix-up initialization strategy for input tokens
corresponding to unseen input variables and therefore accelerate new tasks'
convergence. Experiments on both synthetic and real benchmark problems
demonstrate the effectiveness of our proposed pre-training and transfer BO
strategy over existing methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04663">Classification of lung cancer subtypes on CT images with synthetic pathological priors. (arXiv:2308.04663v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Zhu_W/0/1/0/all/0/1">Wentao Zhu</a>, <a href="http://arxiv.org/find/eess/1/au:+Jin_Y/0/1/0/all/0/1">Yuan Jin</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_G/0/1/0/all/0/1">Gege Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_G/0/1/0/all/0/1">Geng Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Egger_J/0/1/0/all/0/1">Jan Egger</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1">Shaoting Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Metaxas_D/0/1/0/all/0/1">Dimitris N. Metaxas</a></p>
<p>The accurate diagnosis on pathological subtypes for lung cancer is of
significant importance for the follow-up treatments and prognosis managements.
In this paper, we propose self-generating hybrid feature network (SGHF-Net) for
accurately classifying lung cancer subtypes on computed tomography (CT) images.
Inspired by studies stating that cross-scale associations exist in the image
patterns between the same case's CT images and its pathological images, we
innovatively developed a pathological feature synthetic module (PFSM), which
quantitatively maps cross-modality associations through deep neural networks,
to derive the "gold standard" information contained in the corresponding
pathological images from CT images. Additionally, we designed a radiological
feature extraction module (RFEM) to directly acquire CT image information and
integrated it with the pathological priors under an effective feature fusion
framework, enabling the entire classification model to generate more indicative
and specific pathologically related features and eventually output more
accurate predictions. The superiority of the proposed model lies in its ability
to self-generate hybrid features that contain multi-modality image information
based on a single-modality input. To evaluate the effectiveness, adaptability,
and generalization ability of our model, we performed extensive experiments on
a large-scale multi-center dataset (i.e., 829 cases from three hospitals) to
compare our model and a series of state-of-the-art (SOTA) classification
models. The experimental results demonstrated the superiority of our model for
lung cancer subtypes classification with significant accuracy improvements in
terms of accuracy (ACC), area under the curve (AUC), and F1 score.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04669">A General Implicit Framework for Fast NeRF Composition and Rendering. (arXiv:2308.04669v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xinyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yunlu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxiang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xiaogang Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_C/0/1/0/all/0/1">Changqing Zou</a></p>
<p>Recently, a variety of Neural radiance fields methods have garnered
remarkable success in high render speed. However, current accelerating methods
is specialized and not compatible for various implicit method, which prevent a
real-time composition over different kinds of NeRF works. Since NeRF relies on
sampling along rays, it's possible to provide a guidance generally. We propose
a general implicit pipeline to rapidly compose NeRF objects. This new method
enables the casting of dynamic shadows within or between objects using
analytical light sources while allowing multiple NeRF objects to be seamlessly
placed and rendered together with any arbitrary rigid transformations. Mainly,
our work introduces a new surface representation known as Neural Depth Fields
(NeDF) that quickly determines the spatial relationship between objects by
allowing direct intersection computation between rays and implicit surfaces. It
leverages an intersection neural network to query NeRF for acceleration instead
of depending on an explicit spatial structure.Our proposed method is the first
to enable both the progressive and interactive composition of NeRF objects.
Additionally, it also serves as a previewing plugin for a range of existing
NeRF works.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04690">Finite Element Operator Network for Solving Parametric PDEs. (arXiv:2308.04690v1 [math.NA])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/math/1/au:+Lee_J/0/1/0/all/0/1">Jae Yong Lee</a>, <a href="http://arxiv.org/find/math/1/au:+Ko_S/0/1/0/all/0/1">Seungchan Ko</a>, <a href="http://arxiv.org/find/math/1/au:+Hong_Y/0/1/0/all/0/1">Youngjoon Hong</a></p>
<p>Partial differential equations (PDEs) underlie our understanding and
prediction of natural phenomena across numerous fields, including physics,
engineering, and finance. However, solving parametric PDEs is a complex task
that necessitates efficient numerical methods. In this paper, we propose a
novel approach for solving parametric PDEs using a Finite Element Operator
Network (FEONet). Our proposed method leverages the power of deep learning in
conjunction with traditional numerical methods, specifically the finite element
method, to solve parametric PDEs in the absence of any paired input-output
training data. We demonstrate the effectiveness of our approach on several
benchmark problems and show that it outperforms existing state-of-the-art
methods in terms of accuracy, generalization, and computational flexibility.
Our FEONet framework shows potential for application in various fields where
PDEs play a crucial role in modeling complex domains with diverse boundary
conditions and singular behavior. Furthermore, we provide theoretical
convergence analysis to support our approach, utilizing finite element
approximation in numerical analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04696">Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects. (arXiv:2308.04696v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Amirian_S/0/1/0/all/0/1">Soheyla Amirian</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlson_L/0/1/0/all/0/1">Luke A. Carlson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Matthew F. Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lohse_I/0/1/0/all/0/1">Ines Lohse</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiss_K/0/1/0/all/0/1">Kurt R. Weiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Plate_J/0/1/0/all/0/1">Johannes F. Plate</a>, <a href="http://arxiv.org/find/cs/1/au:+Tafti_A/0/1/0/all/0/1">Ahmad P. Tafti</a></p>
<p>While artificial intelligence (AI) has made many successful applications in
various domains, its adoption in healthcare lags a little bit behind other
high-stakes settings. Several factors contribute to this slower uptake,
including regulatory frameworks, patient privacy concerns, and data
heterogeneity. However, one significant challenge that impedes the
implementation of AI in healthcare, particularly in orthopedics, is the lack of
explainability and interpretability around AI models. Addressing the challenge
of explainable AI (XAI) in orthopedics requires developing AI models and
algorithms that prioritize transparency and interpretability, allowing
clinicians, surgeons, and patients to understand the contributing factors
behind any AI-powered predictive or descriptive models. The current
contribution outlines several key challenges and opportunities that manifest in
XAI in orthopedic practice. This work emphasizes the need for interdisciplinary
collaborations between AI practitioners, orthopedic specialists, and regulatory
entities to establish standards and guidelines for the adoption of XAI in
orthopedics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04697">An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms. (arXiv:2308.04697v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Das_M/0/1/0/all/0/1">Mamata Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Alphonse_P/0/1/0/all/0/1">P.J.A. Alphonse</a>, <a href="http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1">Selvakumar K</a></p>
<p>Corona VIrus Disease abbreviated as COVID-19 is a novel virus which is
initially identified in Wuhan of China in December of 2019 and now this deadly
disease has spread all over the world. According to World Health Organization
(WHO), a total of 3,124,905 people died from 2019 to 2021, April. In this case,
many methods, AI base techniques, and machine learning algorithms have been
researched and are being used to save people from this pandemic. The SARS-CoV
and the 2019-nCoV, SARS-CoV-2 virus invade our bodies, causing some differences
in the structure of cell proteins. Protein-protein interaction (PPI) is an
essential process in our cells and plays a very important role in the
development of medicines and gives ideas about the disease. In this study, we
performed clustering on PPI networks generated from 92 genes of the Covi-19
dataset. We have used three graph-based clustering algorithms to give intuition
to the analysis of clusters.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04704">A Feature Set of Small Size for the PDF Malware Detection. (arXiv:2308.04704v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ran Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1">Charles Nicholas</a></p>
<p>Machine learning (ML)-based malware detection systems are becoming
increasingly important as malware threats increase and get more sophisticated.
PDF files are often used as vectors for phishing attacks because they are
widely regarded as trustworthy data resources, and are accessible across
different platforms. Therefore, researchers have developed many different PDF
malware detection methods. Performance in detecting PDF malware is greatly
influenced by feature selection. In this research, we propose a small features
set that don't require too much domain knowledge of the PDF file. We evaluate
proposed features with six different machine learning models. We report the
best accuracy of 99.75% when using Random Forest model. Our proposed feature
set, which consists of just 12 features, is one of the most conciseness in the
field of PDF malware detection. Despite its modest size, we obtain comparable
results to state-of-the-art that employ a much larger set of features.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04706">Pareto Invariant Representation Learning for Multimedia Recommendation. (arXiv:2308.04706v1 [cs.IR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shanshan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoxuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingsong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Chunyuan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Li Liu</a></p>
<p>Multimedia recommendation involves personalized ranking tasks, where
multimedia content is usually represented using a generic encoder. However,
these generic representations introduce spurious correlations that fail to
reveal users' true preferences. Existing works attempt to alleviate this
problem by learning invariant representations, but overlook the balance between
independent and identically distributed (IID) and out-of-distribution (OOD)
generalization. In this paper, we propose a framework called Pareto Invariant
Representation Learning (PaInvRL) to mitigate the impact of spurious
correlations from an IID-OOD multi-objective optimization perspective, by
learning invariant representations (intrinsic factors that attract user
attention) and variant representations (other factors) simultaneously.
Specifically, PaInvRL includes three iteratively executed modules: (i)
heterogeneous identification module, which identifies the heterogeneous
environments to reflect distributional shifts for user-item interactions; (ii)
invariant mask generation module, which learns invariant masks based on the
Pareto-optimal solutions that minimize the adaptive weighted Invariant Risk
Minimization (IRM) and Empirical Risk (ERM) losses; (iii) convert module, which
generates both variant representations and item-invariant representations for
training a multi-modal recommendation model that mitigates spurious
correlations and balances the generalization performance within and cross the
environmental distributions. We compare the proposed PaInvRL with
state-of-the-art recommendation models on three public multimedia
recommendation datasets (Movielens, Tiktok, and Kwai), and the experimental
results validate the effectiveness of PaInvRL for both within- and
cross-environmental learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04708">Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution. (arXiv:2308.04708v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ide_T/0/1/0/all/0/1">Tsuyoshi Id&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Abe_N/0/1/0/all/0/1">Naoki Abe</a></p>
<p>We address the task of probabilistic anomaly attribution in the black-box
regression setting, where the goal is to compute the probability distribution
of the attribution score of each input variable, given an observed anomaly. The
training dataset is assumed to be unavailable. This task differs from the
standard XAI (explainable AI) scenario, since we wish to explain the anomalous
deviation from a black-box prediction rather than the black-box model itself.
</p>
<p>We begin by showing that mainstream model-agnostic explanation methods, such
as the Shapley values, are not suitable for this task because of their
``deviation-agnostic property.'' We then propose a novel framework for
probabilistic anomaly attribution that allows us to not only compute
attribution scores as the predictive mean but also quantify the uncertainty of
those scores. This is done by considering a generative process for
perturbations that counter-factually bring the observed anomalous observation
back to normalcy. We introduce a variational Bayes algorithm for deriving the
distributions of per variable attribution scores. To the best of our knowledge,
this is the first probabilistic anomaly attribution framework that is free from
being deviation-agnostic.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04712">Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning. (arXiv:2308.04712v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Hoang H. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chenwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Ye Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a></p>
<p>Recent advanced methods in Natural Language Understanding for Task-oriented
Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a
large amount of annotated data to achieve competitive performance. In reality,
token-level annotations (slot labels) are time-consuming and difficult to
acquire. In this work, we study the Slot Induction (SI) task whose objective is
to induce slot boundaries without explicit knowledge of token-level slot
annotations. We propose leveraging Unsupervised Pre-trained Language Model
(PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised
semantic knowledge extracted from PLM, and (2) additional sentence-level intent
label signals available from TOD. Our approach is shown to be effective in SI
task and capable of bridging the gaps with token-level supervised models on two
NLU benchmark datasets. When generalized to emerging intents, our SI objectives
also provide enhanced slot label representations, leading to improved
performance on the Slot Filling tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04729">JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models. (arXiv:2308.04729v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peike Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yao Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yikai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Allen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Alex Wang</a></p>
<p>Music generation has attracted growing interest with the advancement of deep
generative models. However, generating music conditioned on textual
descriptions, known as text-to-music, remains challenging due to the complexity
of musical structures and high sampling rate requirements. Despite the task's
significance, prevailing generative models exhibit limitations in music
quality, computational efficiency, and generalization. This paper introduces
JEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a
diffusion model incorporating both autoregressive and non-autoregressive
training. Through in-context learning, JEN-1 performs various generation tasks
including text-guided music generation, music inpainting, and continuation.
Evaluations demonstrate JEN-1's superior performance over state-of-the-art
methods in text-music alignment and music quality while maintaining
computational efficiency. Our demos are available at
<a href="http://futureverse.com/research/jen/demos/jen1">this http URL</a>
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04735">Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations. (arXiv:2308.04735v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yongho Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yongho Choi</a></p>
<p>Physics-informed neural networks have been widely applied to partial
differential equations with great success because the physics-informed loss
essentially requires no observations or discretization. However, it is
difficult to optimize model parameters, and these parameters must be trained
for each distinct initial condition. To overcome these challenges in
second-order reaction-diffusion type equations, a possible way is to use
five-point stencil convolutional neural networks (FCNNs). FCNNs are trained
using two consecutive snapshots, where the time step corresponds to the step
size of the given snapshots. Thus, the time evolution of FCNNs depends on the
time step, and the time step must satisfy its CFL condition to avoid blow-up
solutions. In this work, we propose deep FCNNs that have large receptive fields
to predict time evolutions with a time step larger than the threshold of the
CFL condition. To evaluate our models, we consider the heat, Fisher's, and
Allen-Cahn equations with diverse initial conditions. We demonstrate that deep
FCNNs retain certain accuracies, in contrast to FDMs that blow up.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04739">Optimizing a Transformer-based network for a deep learning seismic processing workflow. (arXiv:2308.04739v1 [physics.geo-ph])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Harsuko_R/0/1/0/all/0/1">Randy Harsuko</a>, <a href="http://arxiv.org/find/physics/1/au:+Alkhalifah_T/0/1/0/all/0/1">Tariq Alkhalifah</a></p>
<p>StorSeismic is a recently introduced model based on the Transformer to adapt
to various seismic processing tasks through its pretraining and fine-tuning
training strategy. In the original implementation, StorSeismic utilized a
sinusoidal positional encoding and a conventional self-attention mechanism,
both borrowed from the natural language processing (NLP) applications. For
seismic processing they admitted good results, but also hinted to limitations
in efficiency and expressiveness. We propose modifications to these two key
components, by utilizing relative positional encoding and low-rank attention
matrices as replacements to the vanilla ones. The proposed changes are tested
on processing tasks applied to a realistic Marmousi and offshore field data as
a sequential strategy, starting from denoising, direct arrival removal,
multiple attenuation, and finally root-mean-squared velocity ($V_{RMS}$)
prediction for normal moveout (NMO) correction. We observe faster pretraining
and competitive results on the fine-tuning tasks and, additionally, fewer
parameters to train compared to the vanilla model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04748">Universal Fuzzing via Large Language Models. (arXiv:2308.04748v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1">Chunqiu Steven Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Paltenghi_M/0/1/0/all/0/1">Matteo Paltenghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1">Jia Le Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Pradel_M/0/1/0/all/0/1">Michael Pradel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lingming Zhang</a></p>
<p>Fuzzing has achieved tremendous success in discovering bugs and
vulnerabilities in various software systems. Systems under test (SUTs) that
take in programming or formal language as inputs, e.g., compilers, runtime
engines, constraint solvers, and software libraries with accessible APIs, are
especially important as they are fundamental building blocks of software
development. However, existing fuzzers for such systems often target a specific
language, and thus cannot be easily applied to other languages or even other
versions of the same language. Moreover, the inputs generated by existing
fuzzers are often limited to specific features of the input language, and thus
can hardly reveal bugs related to other or new features. This paper presents
Fuzz4All, the first fuzzer that is universal in the sense that it can target
many different input languages and many different features of these languages.
The key idea behind Fuzz4All is to leverage large language models (LLMs) as an
input generation and mutation engine, which enables the approach to produce
diverse and realistic inputs for any practically relevant language. To realize
this potential, we present a novel autoprompting technique, which creates LLM
prompts that are wellsuited for fuzzing, and a novel LLM-powered fuzzing loop,
which iteratively updates the prompt to create new fuzzing inputs. We evaluate
Fuzz4All on nine systems under test that take in six different languages (C,
C++, Go, SMT2, Java and Python) as inputs. The evaluation shows, across all six
languages, that universal fuzzing achieves higher coverage than existing,
language-specific fuzzers. Furthermore, Fuzz4All has identified 76 bugs in
widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit
quantum computing platform, with 47 bugs already confirmed by developers as
previously unknown.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04755">Collaborative Learning From Distributed Data With Differentially Private Synthetic Twin Data. (arXiv:2308.04755v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Prediger_L/0/1/0/all/0/1">Lukas Prediger</a>, <a href="http://arxiv.org/find/cs/1/au:+Jalko_J/0/1/0/all/0/1">Joonas J&#xe4;lk&#xf6;</a>, <a href="http://arxiv.org/find/cs/1/au:+Honkela_A/0/1/0/all/0/1">Antti Honkela</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1">Samuel Kaski</a></p>
<p>Consider a setting where multiple parties holding sensitive data aim to
collaboratively learn population level statistics, but pooling the sensitive
data sets is not possible. We propose a framework in which each party shares a
differentially private synthetic twin of their data. We study the feasibility
of combining such synthetic twin data sets for collaborative learning on
real-world health data from the UK Biobank. We discover that parties engaging
in the collaborative learning via shared synthetic data obtain more accurate
estimates of target statistics compared to using only their local data. This
finding extends to the difficult case of small heterogeneous data sets.
Furthermore, the more parties participate, the larger and more consistent the
improvements become. Finally, we find that data sharing can especially help
parties whose data contain underrepresented groups to perform better-adjusted
analysis for said groups. Based on our results we conclude that sharing of
synthetic twins is a viable method for enabling learning from sensitive data
without violating privacy constraints even if individual data sets are small or
do not represent the overall population well. The setting of distributed
sensitive data is often a bottleneck in biomedical research, which our study
shows can be alleviated with privacy-preserving collaborative learning methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04761">Feature Matching Data Synthesis for Non-IID Federated Learning. (arXiv:2308.04761v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zijian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuchang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1">Jiawei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuyi Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jessie Hui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a></p>
<p>Federated learning (FL) has emerged as a privacy-preserving paradigm that
trains neural networks on edge devices without collecting data at a central
server. However, FL encounters an inherent challenge in dealing with
non-independent and identically distributed (non-IID) data among devices. To
address this challenge, this paper proposes a hard feature matching data
synthesis (HFMDS) method to share auxiliary data besides local models.
Specifically, synthetic data are generated by learning the essential
class-relevant features of real samples and discarding the redundant features,
which helps to effectively tackle the non-IID issue. For better privacy
preservation, we propose a hard feature augmentation method to transfer real
features towards the decision boundary, with which the synthetic data not only
improve the model generalization but also erase the information of real
features. By integrating the proposed HFMDS method with FL, we present a novel
FL framework with data augmentation to relieve data heterogeneity. The
theoretical analysis highlights the effectiveness of our proposed data
synthesis method in solving the non-IID challenge. Simulation results further
demonstrate that our proposed HFMDS-FL algorithm outperforms the baselines in
terms of accuracy, privacy preservation, and computational cost on various
benchmark datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04762">Tram-FL: Routing-based Model Training for Decentralized Federated Learning. (arXiv:2308.04762v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Maejima_K/0/1/0/all/0/1">Kota Maejima</a>, <a href="http://arxiv.org/find/cs/1/au:+Nishio_T/0/1/0/all/0/1">Takayuki Nishio</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamazaki_A/0/1/0/all/0/1">Asato Yamazaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Hara_Azumi_Y/0/1/0/all/0/1">Yuko Hara-Azumi</a></p>
<p>In decentralized federated learning (DFL), substantial traffic from frequent
inter-node communication and non-independent and identically distributed
(non-IID) data challenges high-accuracy model acquisition. We propose Tram-FL,
a novel DFL method, which progressively refines a global model by transferring
it sequentially amongst nodes, rather than by exchanging and aggregating local
models. We also introduce a dynamic model routing algorithm for optimal route
selection, aimed at enhancing model precision with minimal forwarding. Our
experiments using MNIST, CIFAR-10, and IMDb datasets demonstrate that Tram-FL
with the proposed routing delivers high model accuracy under non-IID
conditions, outperforming baselines while reducing communication costs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04771">SUnAA: Sparse Unmixing using Archetypal Analysis. (arXiv:2308.04771v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rasti_B/0/1/0/all/0/1">Behnood Rasti</a> (HZDR), <a href="http://arxiv.org/find/cs/1/au:+Zouaoui_A/0/1/0/all/0/1">Alexandre Zouaoui</a> (Thoth), <a href="http://arxiv.org/find/cs/1/au:+Mairal_J/0/1/0/all/0/1">Julien Mairal</a> (Thoth), <a href="http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1">Jocelyn Chanussot</a> (Thoth)</p>
<p>This paper introduces a new sparse unmixing technique using archetypal
analysis (SUnAA). First, we design a new model based on archetypal analysis. We
assume that the endmembers of interest are a convex combination of endmembers
provided by a spectral library and that the number of endmembers of interest is
known. Then, we propose a minimization problem. Unlike most conventional sparse
unmixing methods, here the minimization problem is non-convex. We minimize the
optimization objective iteratively using an active set algorithm. Our method is
robust to the initialization and only requires the number of endmembers of
interest. SUnAA is evaluated using two simulated datasets for which results
confirm its better performance over other conventional and advanced techniques
in terms of signal-to-reconstruction error. SUnAA is also applied to Cuprite
dataset and the results are compared visually with the available geological map
provided for this dataset. The qualitative assessment demonstrates the
successful estimation of the minerals abundances and significantly improves the
detection of dominant minerals compared to the conventional regression-based
sparse unmixing methods. The Python implementation of SUnAA can be found at:
https://github.com/BehnoodRasti/SUnAA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04791">PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer. (arXiv:2308.04791v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shengsheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Weiwei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wentai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Songbo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongxiang Wang</a>, </p>
<p>Recently, Transformer-based models have shown remarkable performance in
long-term time series forecasting (LTSF) tasks due to their ability to model
long-term dependencies. However, the validity of Transformers for LTSF tasks
remains debatable, particularly since recent work has shown that simple linear
models can outperform numerous Transformer-based approaches. This suggests that
there are limitations to the application of Transformer in LTSF. Therefore,
this paper investigates three key issues when applying Transformer to LTSF:
temporal continuity, information density, and multi-channel relationships.
Accordingly, we propose three innovative solutions, including Placeholder
Enhancement Technique (PET), Long Sub-sequence Division (LSD), and
Multi-channel Separation and Interaction (MSI), which together form a novel
model called PETformer. These three key designs introduce prior biases suitable
for LTSF tasks. Extensive experiments have demonstrated that PETformer achieves
state-of-the-art (SOTA) performance on eight commonly used public datasets for
LTSF, outperforming all other models currently available. This demonstrates
that Transformer still possesses powerful capabilities in LTSF.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04796">Bayes Risk Consistency of Nonparametric Classification Rules for Spike Trains Data. (arXiv:2308.04796v1 [cs.IT])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Pawlak_M/0/1/0/all/0/1">Miros&#x142;aw Pawlak</a>, <a href="http://arxiv.org/find/cs/1/au:+Pabian_M/0/1/0/all/0/1">Mateusz Pabian</a>, <a href="http://arxiv.org/find/cs/1/au:+Rzepka_D/0/1/0/all/0/1">Dominik Rzepka</a></p>
<p>Spike trains data find a growing list of applications in computational
neuroscience, imaging, streaming data and finance. Machine learning strategies
for spike trains are based on various neural network and probabilistic models.
The probabilistic approach is relying on parametric or nonparametric
specifications of the underlying spike generation model. In this paper we
consider the two-class statistical classification problem for a class of spike
train data characterized by nonparametrically specified intensity functions. We
derive the optimal Bayes rule and next form the plug-in nonparametric kernel
classifier. Asymptotical properties of the rules are established including the
limit with respect to the increasing recording time interval and the size of a
training set. In particular the convergence of the kernel classifier to the
Bayes rule is proved. The obtained results are supported by a finite sample
simulation studies.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04832">TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks. (arXiv:2308.04832v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yuanhao Gong</a></p>
<p>Activation functions are essential components of neural networks. In this
paper, we introduce a new activation function called the Truncated and Signed
Square Root (TSSR) function. This function is distinctive because it is odd,
nonlinear, monotone and differentiable. Its gradient is continuous and always
positive. Thanks to these properties, it has the potential to improve the
numerical stability of neural networks. Several experiments confirm that the
proposed TSSR has better performance than other stat-of-the-art activation
functions. The proposed function has significant implications for the
development of neural network models and can be applied to a wide range of
applications in fields such as computer vision, natural language processing,
and speech recognition.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04836">Intrinsic Motivation via Surprise Memory. (arXiv:2308.04836v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hung Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_K/0/1/0/all/0/1">Kien Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dung Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1">Svetha Venkatesh</a></p>
<p>We present a new computing model for intrinsic rewards in reinforcement
learning that addresses the limitations of existing surprise-driven
explorations. The reward is the novelty of the surprise rather than the
surprise norm. We estimate the surprise novelty as retrieval errors of a memory
network wherein the memory stores and reconstructs surprises. Our surprise
memory (SM) augments the capability of surprise-based intrinsic motivators,
maintaining the agent's interest in exciting exploration while reducing
unwanted attraction to unpredictable or noisy observations. Our experiments
demonstrate that the SM combined with various surprise predictors exhibits
efficient exploring behaviors and significantly boosts the final performance in
sparse reward environments, including Noisy-TV, navigation and challenging
Atari games.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04844">Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning. (arXiv:2308.04844v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vanneste_A/0/1/0/all/0/1">Astrid Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Somers_T/0/1/0/all/0/1">Thomas Somers</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanneste_S/0/1/0/all/0/1">Simon Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Mets_K/0/1/0/all/0/1">Kevin Mets</a>, <a href="http://arxiv.org/find/cs/1/au:+Schepper_T/0/1/0/all/0/1">Tom De Schepper</a>, <a href="http://arxiv.org/find/cs/1/au:+Mercelis_S/0/1/0/all/0/1">Siegfried Mercelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hellinckx_P/0/1/0/all/0/1">Peter Hellinckx</a></p>
<p>Many multi-agent systems require inter-agent communication to properly
achieve their goal. By learning the communication protocol alongside the action
protocol using multi-agent reinforcement learning techniques, the agents gain
the flexibility to determine which information should be shared. However, when
the number of agents increases we need to create an encoding of the information
contained in these messages. In this paper, we investigate the effect of
increasing the amount of information that should be contained in a message and
increasing the number of agents. We evaluate these effects on two different
message encoding methods, the mean message encoder and the attention message
encoder. We perform our experiments on a matrix environment. Surprisingly, our
results show that the mean message encoder consistently outperforms the
attention message encoder. Therefore, we analyse the communication protocol
used by the agents that use the mean message encoder and can conclude that the
agents use a combination of an exponential and a logarithmic function in their
communication policy to avoid the loss of important information after applying
the mean message encoder.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04870">Decorrelating neurons using persistence. (arXiv:2308.04870v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ballester_R/0/1/0/all/0/1">Rub&#xe9;n Ballester</a>, <a href="http://arxiv.org/find/cs/1/au:+Casacuberta_C/0/1/0/all/0/1">Carles Casacuberta</a>, <a href="http://arxiv.org/find/cs/1/au:+Escalera_S/0/1/0/all/0/1">Sergio Escalera</a></p>
<p>We propose a novel way to improve the generalisation capacity of deep
learning models by reducing high correlations between neurons. For this, we
present two regularisation terms computed from the weights of a minimum
spanning tree of the clique whose vertices are the neurons of a given network
(or a sample of those), where weights on edges are correlation dissimilarities.
We provide an extensive set of experiments to validate the effectiveness of our
terms, showing that they outperform popular ones. Also, we demonstrate that
naive minimisation of all correlations between neurons obtains lower accuracies
than our regularisation terms, suggesting that redundancies play a significant
role in artificial neural networks, as evidenced by some studies in
neuroscience for real networks. We include a proof of differentiability of our
regularisers, thus developing the first effective topological persistence-based
regularisation terms that consider the whole set of neurons and that can be
applied to a feedforward architecture in any deep learning task such as
classification, data generation, or regression.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04887">Targeted and Troublesome: Tracking and Advertising on Children&#x27;s Websites. (arXiv:2308.04887v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Moti_Z/0/1/0/all/0/1">Zahra Moti</a>, <a href="http://arxiv.org/find/cs/1/au:+Senol_A/0/1/0/all/0/1">Asuman Senol</a>, <a href="http://arxiv.org/find/cs/1/au:+Bostani_H/0/1/0/all/0/1">Hamid Bostani</a>, <a href="http://arxiv.org/find/cs/1/au:+Borgesius_F/0/1/0/all/0/1">Frederik Zuiderveen Borgesius</a>, <a href="http://arxiv.org/find/cs/1/au:+Moonsamy_V/0/1/0/all/0/1">Veelasha Moonsamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathur_A/0/1/0/all/0/1">Arunesh Mathur</a>, <a href="http://arxiv.org/find/cs/1/au:+Acar_G/0/1/0/all/0/1">Gunes Acar</a></p>
<p>On the modern web, trackers and advertisers frequently construct and monetize
users' detailed behavioral profiles without consent. Despite various studies on
web tracking mechanisms and advertisements, there has been no rigorous study
focusing on websites targeted at children. To address this gap, we present a
measurement of tracking and (targeted) advertising on websites directed at
children. Motivated by lacking a comprehensive list of child-directed (i.e.,
targeted at children) websites, we first build a multilingual classifier based
on web page titles and descriptions. Applying this classifier to over two
million pages, we compile a list of two thousand child-directed websites.
Crawling these sites from five vantage points, we measure the prevalence of
trackers, fingerprinting scripts, and advertisements. Our crawler detects ads
displayed on child-directed websites and determines if ad targeting is enabled
by scraping ad disclosure pages whenever available. Our results show that
around 90% of child-directed websites embed one or more trackers, and about 27%
contain targeted advertisements--a practice that should require verifiable
parental consent. Next, we identify improper ads on child-directed websites by
developing an ML pipeline that processes both images and text extracted from
ads. The pipeline allows us to run semantic similarity queries for arbitrary
search terms, revealing ads that promote services related to dating, weight
loss, and mental health; as well as ads for sex toys and flirting chat
services. Some of these ads feature repulsive and sexually explicit imagery. In
summary, our findings indicate a trend of non-compliance with privacy
regulations and troubling ad safety practices among many advertisers and
child-directed websites. To protect children and create a safer online
environment, regulators and stakeholders must adopt and enforce more stringent
measures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04889">NLLG Quarterly arXiv Report 06/23: What are the most influential current AI Papers?. (arXiv:2308.04889v1 [cs.CY])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1">Steffen Eger</a>, <a href="http://arxiv.org/find/cs/1/au:+Leiter_C/0/1/0/all/0/1">Christoph Leiter</a>, <a href="http://arxiv.org/find/cs/1/au:+Belouadi_J/0/1/0/all/0/1">Jonas Belouadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ran Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kostikova_A/0/1/0/all/0/1">Aida Kostikova</a>, <a href="http://arxiv.org/find/cs/1/au:+Larionov_D/0/1/0/all/0/1">Daniil Larionov</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanran Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fresen_V/0/1/0/all/0/1">Vivian Fresen</a></p>
<p>The rapid growth of information in the field of Generative Artificial
Intelligence (AI), particularly in the subfields of Natural Language Processing
(NLP) and Machine Learning (ML), presents a significant challenge for
researchers and practitioners to keep pace with the latest developments. To
address the problem of information overload, this report by the Natural
Language Learning Group at Bielefeld University focuses on identifying the most
popular papers on arXiv, with a specific emphasis on NLP and ML. The objective
is to offer a quick guide to the most relevant and widely discussed research,
aiding both newcomers and established researchers in staying abreast of current
trends. In particular, we compile a list of the 40 most popular papers based on
normalized citation counts from the first half of 2023. We observe the
dominance of papers related to Large Language Models (LLMs) and specifically
ChatGPT during the first half of 2023, with the latter showing signs of
declining popularity more recently, however. Further, NLP related papers are
the most influential (around 60\% of top papers) even though there are twice as
many ML related papers in our data. Core issues investigated in the most
heavily cited papers are: LLM efficiency, evaluation techniques, ethical
considerations, embodied agents, and problem-solving with LLMs. Additionally,
we examine the characteristics of top papers in comparison to others outside
the top-40 list (noticing the top paper's focus on LLM related issues and
higher number of co-authors) and analyze the citation distributions in our
dataset, among others.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04896">Why Data Science Projects Fail. (arXiv:2308.04896v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Panda_B/0/1/0/all/0/1">Balaram Panda</a> (The University of Auckland)</p>
<p>Data Science is a modern Data Intelligence practice, which is the core of
many businesses and helps businesses build smart strategies around to deal with
businesses challenges more efficiently. Data Science practice also helps in
automating business processes using the algorithm, and it has several other
benefits, which also deliver in a non-profitable framework. In regards to data
science, three key components primarily influence the effective outcome of a
data science project. Those are 1.Availability of Data 2.Algorithm 3.Processing
power or infrastructure
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04898">An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures. (arXiv:2308.04898v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Singla_T/0/1/0/all/0/1">Tanmay Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandayuvaraj_D/0/1/0/all/0/1">Dharun Anandayuvaraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalu_K/0/1/0/all/0/1">Kelechi G. Kalu</a>, <a href="http://arxiv.org/find/cs/1/au:+Schorlemmer_T/0/1/0/all/0/1">Taylor R. Schorlemmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">James C. Davis</a></p>
<p>As we increasingly depend on software systems, the consequences of breaches
in the software supply chain become more severe. High-profile cyber attacks
like those on SolarWinds and ShadowHammer have resulted in significant
financial and data losses, underlining the need for stronger cybersecurity. One
way to prevent future breaches is by studying past failures. However,
traditional methods of analyzing these failures require manually reading and
summarizing reports about them. Automated support could reduce costs and allow
analysis of more failures. Natural Language Processing (NLP) techniques such as
Large Language Models (LLMs) could be leveraged to assist the analysis of
failures. In this study, we assessed the ability of Large Language Models
(LLMs) to analyze historical software supply chain breaches. We used LLMs to
replicate the manual analysis of 69 software supply chain security failures
performed by members of the Cloud Native Computing Foundation (CNCF). We
developed prompts for LLMs to categorize these by four dimensions: type of
compromise, intent, nature, and impact. GPT 3.5s categorizations had an average
accuracy of 68% and Bard had an accuracy of 58% over these dimensions. We
report that LLMs effectively characterize software supply chain failures when
the source articles are detailed enough for consensus among manual analysts,
but cannot yet replace human analysts. Future work can improve LLM performance
in this context, and study a broader range of articles and failures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04901">Towards true discovery of the differential equations. (arXiv:2308.04901v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hvatov_A/0/1/0/all/0/1">Alexander Hvatov</a>, <a href="http://arxiv.org/find/cs/1/au:+Titov_R/0/1/0/all/0/1">Roman Titov</a></p>
<p>Differential equation discovery, a machine learning subfield, is used to
develop interpretable models, particularly in nature-related applications. By
expertly incorporating the general parametric form of the equation of motion
and appropriate differential terms, algorithms can autonomously uncover
equations from data. This paper explores the prerequisites and tools for
independent equation discovery without expert input, eliminating the need for
equation form assumptions. We focus on addressing the challenge of assessing
the adequacy of discovered equations when the correct equation is unknown, with
the aim of providing insights for reliable equation discovery without prior
knowledge of the equation form.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04905">GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters. (arXiv:2308.04905v1 [cs.NI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bernardez_G/0/1/0/all/0/1">Guillermo Bern&#xe1;rdez</a>, <a href="http://arxiv.org/find/cs/1/au:+Suarez_Varela_J/0/1/0/all/0/1">Jos&#xe9; Su&#xe1;rez-Varela</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1">Shihan Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiangle Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Barlet_Ros_P/0/1/0/all/0/1">Pere Barlet-Ros</a>, <a href="http://arxiv.org/find/cs/1/au:+Cabellos_Aparicio_A/0/1/0/all/0/1">Albert Cabellos-Aparicio</a></p>
<p>Congestion Control (CC) plays a fundamental role in optimizing traffic in
Data Center Networks (DCN). Currently, DCNs mainly implement two main CC
protocols: DCTCP and DCQCN. Both protocols -- and their main variants -- are
based on Explicit Congestion Notification (ECN), where intermediate switches
mark packets when they detect congestion. The ECN configuration is thus a
crucial aspect on the performance of CC protocols. Nowadays, network experts
set static ECN parameters carefully selected to optimize the average network
performance. However, today's high-speed DCNs experience quick and abrupt
changes that severely change the network state (e.g., dynamic traffic
workloads, incast events, failures). This leads to under-utilization and
sub-optimal performance. This paper presents GraphCC, a novel Machine
Learning-based framework for in-network CC optimization. Our distributed
solution relies on a novel combination of Multi-agent Reinforcement Learning
(MARL) and Graph Neural Networks (GNN), and it is compatible with widely
deployed ECN-based CC protocols. GraphCC deploys distributed agents on switches
that communicate with their neighbors to cooperate and optimize the global ECN
configuration. In our evaluation, we test the performance of GraphCC under a
wide variety of scenarios, focusing on the capability of this solution to adapt
to new scenarios unseen during training (e.g., new traffic workloads, failures,
upgrades). We compare GraphCC with a state-of-the-art MARL-based solution for
ECN tuning -- ACC -- and observe that our proposed solution outperforms the
state-of-the-art baseline in all of the evaluation scenarios, showing
improvements up to $20\%$ in Flow Completion Time as well as significant
reductions in buffer occupancy ($38.0-85.7\%$).
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04923">Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery. (arXiv:2308.04923v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Hampe_N/0/1/0/all/0/1">Nils Hampe</a>, <a href="http://arxiv.org/find/eess/1/au:+Velzen_S/0/1/0/all/0/1">Sanne G. M. van Velzen</a>, <a href="http://arxiv.org/find/eess/1/au:+Aben_J/0/1/0/all/0/1">Jean-Paul Aben</a>, <a href="http://arxiv.org/find/eess/1/au:+Collet_C/0/1/0/all/0/1">Carlos Collet</a>, <a href="http://arxiv.org/find/eess/1/au:+Isgum_I/0/1/0/all/0/1">Ivana I&#x161;gum</a></p>
<p>Functionally significant coronary artery disease (CAD) is caused by plaque
buildup in the coronary arteries, potentially leading to narrowing of the
arterial lumen, i.e. coronary stenosis, that significantly obstructs blood flow
to the myocardium. The current reference for establishing the presence of a
functionally significant stenosis is invasive fractional flow reserve (FFR)
measurement. To avoid invasive measurements, non-invasive prediction of FFR
from coronary CT angiography (CCTA) has emerged. For this, machine learning
approaches, characterized by fast inference, are increasingly developed.
However, these methods predict a single FFR value per artery i.e. they don't
provide information about the stenosis location or treatment strategy. We
propose a deep learning-based method to predict the FFR along the artery from
CCTA scans. This study includes CCTA images of 110 patients who underwent
invasive FFR pullback measurement in 112 arteries. First, a multi planar
reconstruction (MPR) of the artery is fed to a variational autoencoder to
characterize the artery, i.e. through the lumen area and unsupervised artery
encodings. Thereafter, a convolutional neural network (CNN) predicts the FFR
along the artery. The CNN is supervised by multiple loss functions, notably a
loss function inspired by the Earth Mover's Distance (EMD) to predict the
correct location of FFR drops and a histogram-based loss to explicitly
supervise the slope of the FFR curve. To train and evaluate our model,
eight-fold cross-validation was performed. The resulting FFR curves show good
agreement with the reference allowing the distinction between diffuse and focal
CAD distributions in most cases. Quantitative evaluation yielded a mean
absolute difference in the area under the FFR pullback curve (AUPC) of 1.7. The
method may pave the way towards fast, accurate, automatic prediction of FFR
along the artery from CCTA.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04934">JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition. (arXiv:2308.04934v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bicsi_L/0/1/0/all/0/1">Lucian Bicsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alexe_B/0/1/0/all/0/1">Bogdan Alexe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1">Radu Tudor Ionescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Leordeanu_M/0/1/0/all/0/1">Marius Leordeanu</a></p>
<p>We propose JEDI, a multi-dataset semi-supervised learning method, which
efficiently combines knowledge from multiple experts, learned on different
datasets, to train and improve the performance of individual, per dataset,
student models. Our approach achieves this by addressing two important problems
in current machine learning research: generalization across datasets and
limitations of supervised training due to scarcity of labeled data. We start
with an arbitrary number of experts, pretrained on their own specific dataset,
which form the initial set of student models. The teachers are immediately
derived by concatenating the feature representations from the penultimate
layers of the students. We then train all models in a student-teacher
semi-supervised learning scenario until convergence. In our efficient approach,
student-teacher training is carried out jointly and end-to-end, showing that
both students and teachers improve their generalization capacity during
training. We validate our approach on four video action recognition datasets.
By simultaneously considering all datasets within a unified semi-supervised
setting, we demonstrate significant improvements over the initial experts.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04938">An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning. (arXiv:2308.04938v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Vanneste_A/0/1/0/all/0/1">Astrid Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanneste_S/0/1/0/all/0/1">Simon Vanneste</a>, <a href="http://arxiv.org/find/cs/1/au:+Mets_K/0/1/0/all/0/1">Kevin Mets</a>, <a href="http://arxiv.org/find/cs/1/au:+Schepper_T/0/1/0/all/0/1">Tom De Schepper</a>, <a href="http://arxiv.org/find/cs/1/au:+Mercelis_S/0/1/0/all/0/1">Siegfried Mercelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hellinckx_P/0/1/0/all/0/1">Peter Hellinckx</a></p>
<p>Communication is crucial in multi-agent reinforcement learning when agents
are not able to observe the full state of the environment. The most common
approach to allow learned communication between agents is the use of a
differentiable communication channel that allows gradients to flow between
agents as a form of feedback. However, this is challenging when we want to use
discrete messages to reduce the message size, since gradients cannot flow
through a discrete communication channel. Previous work proposed methods to
deal with this problem. However, these methods are tested in different
communication learning architectures and environments, making it hard to
compare them. In this paper, we compare several state-of-the-art discretization
methods as well as a novel approach. We do this comparison in the context of
communication learning using gradients from other agents and perform tests on
several environments. In addition, we present COMA-DIAL, a communication
learning approach based on DIAL and COMA extended with learning rate scaling
and adapted exploration. Using COMA-DIAL allows us to perform experiments on
more complex environments. Our results show that the novel ST-DRU method,
proposed in this paper, achieves the best results out of all discretization
methods across the different environments. It achieves the best or close to the
best performance in each of the experiments and is the only method that does
not fail on any of the tested environments.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04943">Differentially Private Graph Neural Network with Importance-Grained Noise Adaption. (arXiv:2308.04943v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yuxin Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jun Wu</a></p>
<p>Graph Neural Networks (GNNs) with differential privacy have been proposed to
preserve graph privacy when nodes represent personal and sensitive information.
However, the existing methods ignore that nodes with different importance may
yield diverse privacy demands, which may lead to over-protect some nodes and
decrease model utility. In this paper, we study the problem of
importance-grained privacy, where nodes contain personal data that need to be
kept private but are critical for training a GNN. We propose NAP-GNN, a
node-importance-grained privacy-preserving GNN algorithm with privacy
guarantees based on adaptive differential privacy to safeguard node
information. First, we propose a Topology-based Node Importance Estimation
(TNIE) method to infer unknown node importance with neighborhood and centrality
awareness. Second, an adaptive private aggregation method is proposed to
perturb neighborhood aggregation from node-importance-grain. Third, we propose
to privately train a graph learning algorithm on perturbed aggregations in
adaptive residual connection mode over multi-layers convolution for node-wise
tasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees.
Empirical experiments over real-world graph datasets show that NAP-GNN achieves
a better trade-off between privacy and accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04947">Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey. (arXiv:2308.04947v1 [q-fin.ST])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-fin/1/au:+Wang_L/0/1/0/all/0/1">Liping Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Li_J/0/1/0/all/0/1">Jiawei Li</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zhao_L/0/1/0/all/0/1">Lifan Zhao</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Kou_Z/0/1/0/all/0/1">Zhizhuo Kou</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wang_X/0/1/0/all/0/1">Xiaohan Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zhu_X/0/1/0/all/0/1">Xinyi Zhu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Shen_Y/0/1/0/all/0/1">Yanyan Shen</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Chen_L/0/1/0/all/0/1">Lei Chen</a></p>
<p>Predicting stock prices presents a challenging research problem due to the
inherent volatility and non-linear nature of the stock market. In recent years,
knowledge-enhanced stock price prediction methods have shown groundbreaking
results by utilizing external knowledge to understand the stock market. Despite
the importance of these methods, there is a scarcity of scholarly works that
systematically synthesize previous studies from the perspective of external
knowledge types. Specifically, the external knowledge can be modeled in
different data structures, which we group into non-graph-based formats and
graph-based formats: 1) non-graph-based knowledge captures contextual
information and multimedia descriptions specifically associated with an
individual stock; 2) graph-based knowledge captures interconnected and
interdependent information in the stock market. This survey paper aims to
provide a systematic and comprehensive description of methods for acquiring
external knowledge from various unstructured data sources and then
incorporating it into stock price prediction models. We also explore fusion
methods for combining external knowledge with historical price features.
Moreover, this paper includes a compilation of relevant datasets and delves
into potential future research directions in this domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04950">Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection. (arXiv:2308.04950v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Azizah_S/0/1/0/all/0/1">Shafna Fitria Nur Azizah</a>, <a href="http://arxiv.org/find/cs/1/au:+Cahyono_H/0/1/0/all/0/1">Hasan Dwi Cahyono</a>, <a href="http://arxiv.org/find/cs/1/au:+Sihwi_S/0/1/0/all/0/1">Sari Widya Sihwi</a>, <a href="http://arxiv.org/find/cs/1/au:+Widiarto_W/0/1/0/all/0/1">Wisnu Widiarto</a></p>
<p>Fake news is fake material in a news media format but is not processed
properly by news agencies. The fake material can provoke or defame significant
entities or individuals or potentially even for the personal interests of the
creators, causing problems for society. Distinguishing fake news and real news
is challenging due to limited of domain knowledge and time constraints.
According to the survey, the top three areas most exposed to hoaxes and
misinformation by residents are in Banten, DKI Jakarta and West Java. The model
of transformers is referring to an approach in the field of artificial
intelligence (AI) in natural language processing utilizing the deep learning
architectures. Transformers exercise a powerful attention mechanism to process
text in parallel and produce rich and contextual word representations. A
previous study indicates a superior performance of a transformer model known as
BERT over and above non transformer approach. However, some studies suggest the
performance can be improved with the use of improved BERT models known as
ALBERT and RoBERTa. However, the modified BERT models are not well explored for
detecting fake news in Bahasa Indonesia. In this research, we explore those
transformer models and found that ALBERT outperformed other models with 87.6%
accuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)
respectively. Source code available at:
https://github.com/Shafna81/fakenewsdetection.git
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04958">Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks. (arXiv:2308.04958v1 [cs.AI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Brittain_M/0/1/0/all/0/1">Marc W. Brittain</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_L/0/1/0/all/0/1">Luis E. Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Breeden_K/0/1/0/all/0/1">Kara Breeden</a></p>
<p>Advanced Air Mobility (AAM) introduces a new, efficient mode of
transportation with the use of vehicle autonomy and electrified aircraft to
provide increasingly autonomous transportation between previously underserved
markets. Safe and efficient navigation of low altitude aircraft through highly
dense environments requires the integration of a multitude of complex
observations, such as surveillance, knowledge of vehicle dynamics, and weather.
The processing and reasoning on these observations pose challenges due to the
various sources of uncertainty in the information while ensuring cooperation
with a variable number of aircraft in the airspace. These challenges coupled
with the requirement to make safety-critical decisions in real-time rule out
the use of conventional separation assurance techniques. We present a
decentralized reinforcement learning framework to provide autonomous
self-separation capabilities within AAM corridors with the use of speed and
vertical maneuvers. The problem is formulated as a Markov Decision Process and
solved by developing a novel extension to the sample-efficient, off-policy soft
actor-critic (SAC) algorithm. We introduce the use of attention networks for
variable-length observation processing and a distributed computing architecture
to achieve high training sample throughput as compared to existing approaches.
A comprehensive numerical study shows that the proposed framework can ensure
safe and efficient separation of aircraft in high density, dynamic environments
with various sources of uncertainty.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04960">Representation Learning for Audio Privacy Preservation using Source Separation and Robust Adversarial Learning. (arXiv:2308.04960v1 [cs.SD])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luong_D/0/1/0/all/0/1">Diep Luong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1">Minh Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Gharib_S/0/1/0/all/0/1">Shayan Gharib</a>, <a href="http://arxiv.org/find/cs/1/au:+Drossos_K/0/1/0/all/0/1">Konstantinos Drossos</a>, <a href="http://arxiv.org/find/cs/1/au:+Virtanen_T/0/1/0/all/0/1">Tuomas Virtanen</a></p>
<p>Privacy preservation has long been a concern in smart acoustic monitoring
systems, where speech can be passively recorded along with a target signal in
the system's operating environment. In this study, we propose the integration
of two commonly used approaches in privacy preservation: source separation and
adversarial representation learning. The proposed system learns the latent
representation of audio recordings such that it prevents differentiating
between speech and non-speech recordings. Initially, the source separation
network filters out some of the privacy-sensitive data, and during the
adversarial learning process, the system will learn privacy-preserving
representation on the filtered signal. We demonstrate the effectiveness of our
proposed method by comparing our method against systems without source
separation, without adversarial learning, and without both. Overall, our
results suggest that the proposed system can significantly improve speech
privacy preservation compared to that of using source separation or adversarial
learning solely while maintaining good performance in the acoustic monitoring
task.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04961">CasCIFF: A Cross-Domain Information Fusion Framework Tailored for Cascade Prediction in Social Networks. (arXiv:2308.04961v1 [cs.SI])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hongjun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1">Shun Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1">Chaolong Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Ying Qian</a></p>
<p>Existing approaches for information cascade prediction fall into three main
categories: feature-driven methods, point process-based methods, and deep
learning-based methods. Among them, deep learning-based methods, characterized
by its superior learning and representation capabilities, mitigates the
shortcomings inherent of the other methods. However, current deep learning
methods still face several persistent challenges. In particular, accurate
representation of user attributes remains problematic due to factors such as
fake followers and complex network configurations. Previous algorithms that
focus on the sequential order of user activations often neglect the rich
insights offered by activation timing. Furthermore, these techniques often fail
to holistically integrate temporal and structural aspects, thus missing the
nuanced propagation trends inherent in information cascades.To address these
issues, we propose the Cross-Domain Information Fusion Framework (CasCIFF),
which is tailored for information cascade prediction. This framework exploits
multi-hop neighborhood information to make user embeddings robust. When
embedding cascades, the framework intentionally incorporates timestamps,
endowing it with the ability to capture evolving patterns of information
diffusion. In particular, the CasCIFF seamlessly integrates the tasks of user
classification and cascade prediction into a consolidated framework, thereby
allowing the extraction of common features that prove useful for all tasks, a
strategy anchored in the principles of multi-task learning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04964">Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning. (arXiv:2308.04964v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Montaruli_B/0/1/0/all/0/1">Biagio Montaruli</a>, <a href="http://arxiv.org/find/cs/1/au:+Demetrio_L/0/1/0/all/0/1">Luca Demetrio</a>, <a href="http://arxiv.org/find/cs/1/au:+Valenza_A/0/1/0/all/0/1">Andrea Valenza</a>, <a href="http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1">Battista Biggio</a>, <a href="http://arxiv.org/find/cs/1/au:+Compagna_L/0/1/0/all/0/1">Luca Compagna</a>, <a href="http://arxiv.org/find/cs/1/au:+Balzarotti_D/0/1/0/all/0/1">Davide Balzarotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Ariu_D/0/1/0/all/0/1">Davide Ariu</a>, <a href="http://arxiv.org/find/cs/1/au:+Piras_L/0/1/0/all/0/1">Luca Piras</a></p>
<p>ModSecurity is widely recognized as the standard open-source Web Application
Firewall (WAF), maintained by the OWASP Foundation. It detects malicious
requests by matching them against the Core Rule Set, identifying well-known
attack patterns. Each rule in the CRS is manually assigned a weight, based on
the severity of the corresponding attack, and a request is detected as
malicious if the sum of the weights of the firing rules exceeds a given
threshold. In this work, we show that this simple strategy is largely
ineffective for detecting SQL injection (SQLi) attacks, as it tends to block
many legitimate requests, while also being vulnerable to adversarial SQLi
attacks, i.e., attacks intentionally manipulated to evade detection. To
overcome these issues, we design a robust machine learning model, named
AdvModSec, which uses the CRS rules as input features, and it is trained to
detect adversarial SQLi attacks. Our experiments show that AdvModSec, being
trained on the traffic directed towards the protected web services, achieves a
better trade-off between detection and false positive rates, improving the
detection rate of the vanilla version of ModSecurity with CRS by 21%. Moreover,
our approach is able to improve its adversarial robustness against adversarial
SQLi attacks by 42%, thereby taking a step forward towards building more robust
and trustworthy WAFs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04978">Transferable Models for Bioacoustics with Human Language Supervision. (arXiv:2308.04978v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Robinson_D/0/1/0/all/0/1">David Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Robinson_A/0/1/0/all/0/1">Adelaide Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Akrapongpisak_L/0/1/0/all/0/1">Lily Akrapongpisak</a></p>
<p>Passive acoustic monitoring offers a scalable, non-invasive method for
tracking global biodiversity and anthropogenic impacts on species. Although
deep learning has become a vital tool for processing this data, current models
are inflexible, typically cover only a handful of species, and are limited by
data scarcity. In this work, we propose BioLingual, a new model for
bioacoustics based on contrastive language-audio pretraining. We first
aggregate bioacoustic archives into a language-audio dataset, called
AnimalSpeak, with over a million audio-caption pairs holding information on
species, vocalization context, and animal behavior. After training on this
dataset to connect language and audio representations, our model can identify
over a thousand species' calls across taxa, complete bioacoustic tasks
zero-shot, and retrieve animal vocalization recordings from natural text
queries. When fine-tuned, BioLingual sets a new state-of-the-art on nine tasks
in the Benchmark of Animal Sounds. Given its broad taxa coverage and ability to
be flexibly queried in human language, we believe this model opens new
paradigms in ecological monitoring and research, including free-text search on
the world's acoustic monitoring archives. We open-source our models, dataset,
and code.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05011">Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories. (arXiv:2308.05011v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Manuel_P/0/1/0/all/0/1">P&#xe9;rez-Carrasco Manuel</a>, <a href="http://arxiv.org/find/cs/1/au:+Guillermo_C/0/1/0/all/0/1">Cabrera-Vives Guillermo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lorena_H/0/1/0/all/0/1">Hern&#xe1;ndez-Garc&#xed;a Lorena</a>, <a href="http://arxiv.org/find/cs/1/au:+Francisco_F/0/1/0/all/0/1">Forster Francisco</a>, <a href="http://arxiv.org/find/cs/1/au:+Paula_S/0/1/0/all/0/1">S&#xe1;nchez-S&#xe1;ez Paula</a>, <a href="http://arxiv.org/find/cs/1/au:+Alejandra_M/0/1/0/all/0/1">Mu&#xf1;oz Arancibia Alejandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicolas_A/0/1/0/all/0/1">Astorga Nicol&#xe1;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Franz_B/0/1/0/all/0/1">Bauer Franz</a>, <a href="http://arxiv.org/find/cs/1/au:+Amelia_B/0/1/0/all/0/1">Bayo Amelia</a>, <a href="http://arxiv.org/find/cs/1/au:+Martina_C/0/1/0/all/0/1">C&#xe1;diz-Leyton Martina</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcio_C/0/1/0/all/0/1">Catelan Marcio</a></p>
<p>With the increasing volume of astronomical data generated by modern survey
telescopes, automated pipelines and machine learning techniques have become
crucial for analyzing and extracting knowledge from these datasets. Anomaly
detection, i.e. the task of identifying irregular or unexpected patterns in the
data, is a complex challenge in astronomy. In this paper, we propose
Multi-Class Deep Support Vector Data Description (MCDSVDD), an extension of the
state-of-the-art anomaly detection algorithm One-Class Deep SVDD, specifically
designed to handle different inlier categories with distinct data
distributions. MCDSVDD uses a neural network to map the data into hyperspheres,
where each hypersphere represents a specific inlier category. The distance of
each sample from the centers of these hyperspheres determines the anomaly
score. We evaluate the effectiveness of MCDSVDD by comparing its performance
with several anomaly detection algorithms on a large dataset of astronomical
light-curves obtained from the Zwicky Transient Facility. Our results
demonstrate the efficacy of MCDSVDD in detecting anomalous sources while
leveraging the presence of different inlier categories. The code and the data
needed to reproduce our results are publicly available at
https://github.com/mperezcarrasco/AnomalyALeRCE.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05014">An Empirical Study of Bugs in Open-Source Federated Learning Framework. (arXiv:2308.05014v1 [cs.SE])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1">Weijie Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yuyang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_F/0/1/0/all/0/1">Fu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Lingling Fan</a></p>
<p>Federated learning (FL), as a decentralized machine learning solution to the
protection of users' private data, has become an important learning paradigm in
recent years, especially since the enforcement of stricter laws and regulations
in most countries. Therefore, a variety of FL frameworks are released to
facilitate the development and application of federated learning. Despite the
considerable amount of research on the security and privacy of FL models and
systems, the security issues in FL frameworks have not been systematically
studied yet. In this paper, we conduct the first empirical study on 1,112 FL
framework bugs to investigate their characteristics. These bugs are manually
collected, classified, and labeled from 12 open-source FL frameworks on GitHub.
In detail, we construct taxonomies of 15 symptoms, 12 root causes, and 20 fix
patterns of these bugs and investigate their correlations and distributions on
23 logical components and two main application scenarios. From the results of
our study, we present nine findings, discuss their implications, and propound
several suggestions to FL framework developers and security researchers on the
FL frameworks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05017">When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis. (arXiv:2308.05017v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yiyou Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhenmei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yingyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yixuan Li</a></p>
<p>Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeled
set by leveraging prior knowledge from a labeled set with known classes.
Despite its importance, there is a lack of theoretical foundations for NCD.
This paper bridges the gap by providing an analytical framework to formalize
and investigate when and how known classes can help discover novel classes.
Tailored to the NCD problem, we introduce a graph-theoretic representation that
can be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing this
objective is equivalent to factorizing the graph's adjacency matrix, which
allows us to derive a provable error bound and provide the sufficient and
necessary condition for NCD. Empirically, NSCL can match or outperform several
strong baselines on common benchmark datasets, which is appealing for practical
usage while enjoying theoretical guarantees.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05021">Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization. (arXiv:2308.05021v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yangming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Z/0/1/0/all/0/1">Zhaozhi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a></p>
<p>While diffusion models have achieved promising performances in data
synthesis, they might suffer error propagation because of their cascade
structure, where the distributional mismatch spreads and magnifies through the
chain of denoising modules. However, a strict analysis is expected since many
sequential models such as Conditional Random Field (CRF) are free from error
propagation. In this paper, we empirically and theoretically verify that
diffusion models are indeed affected by error propagation and we then propose a
regularization to address this problem. Our theoretical analysis reveals that
the question can be reduced to whether every denoising module of the diffusion
model is fault-tolerant. We derive insightful transition equations, indicating
that the module can't recover from input errors and even propagates additional
errors to the next module. Our analysis directly leads to a consistency
regularization scheme for diffusion models, which explicitly reduces the
distribution gap between forward and backward processes. We further introduce a
bootstrapping algorithm to reduce the computation cost of the regularizer. Our
experimental results on multiple image datasets show that our regularization
effectively handles error propagation and significantly improves the
performance of vanilla diffusion models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05027">AbDiffuser: Full-Atom Generation of In-Vitro Functioning Antibodies. (arXiv:2308.05027v1 [q-bio.BM])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/q-bio/1/au:+Martinkus_K/0/1/0/all/0/1">Karolis Martinkus</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ludwiczak_J/0/1/0/all/0/1">Jan Ludwiczak</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lian_W/0/1/0/all/0/1">Wei-Ching Lian</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lafrance_Vanasse_J/0/1/0/all/0/1">Julien Lafrance-Vanasse</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hotzel_I/0/1/0/all/0/1">Isidro Hotzel</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Rajpal_A/0/1/0/all/0/1">Arvind Rajpal</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wu_Y/0/1/0/all/0/1">Yan Wu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bonneau_R/0/1/0/all/0/1">Richard Bonneau</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gligorijevic_V/0/1/0/all/0/1">Vladimir Gligorijevic</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Loukas_A/0/1/0/all/0/1">Andreas Loukas</a></p>
<p>We introduce AbDiffuser, an equivariant and physics-informed diffusion model
for the joint generation of antibody 3D structures and sequences. AbDiffuser is
built on top of a new representation of protein structure, relies on a novel
architecture for aligned proteins, and utilizes strong diffusion priors to
improve the denoising process. Our approach improves protein diffusion by
taking advantage of domain knowledge and physics-based constraints; handles
sequence-length changes; and reduces memory complexity by an order of magnitude
enabling backbone and side chain generation. We validate AbDiffuser in silico
and in vitro. Numerical experiments showcase the ability of AbDiffuser to
generate antibodies that closely track the sequence and structural properties
of a reference set. Laboratory experiments confirm that all 16 HER2 antibodies
discovered were expressed at high levels and that 57.1% of selected designs
were tight binders.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05032">Density Crop-guided Semi-supervised Object Detection in Aerial Images. (arXiv:2308.05032v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Meethal_A/0/1/0/all/0/1">Akhil Meethal</a>, <a href="http://arxiv.org/find/cs/1/au:+Granger_E/0/1/0/all/0/1">Eric Granger</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersoli_M/0/1/0/all/0/1">Marco Pedersoli</a></p>
<p>One of the important bottlenecks in training modern object detectors is the
need for labeled images where bounding box annotations have to be produced for
each object present in the image. This bottleneck is further exacerbated in
aerial images where the annotators have to label small objects often
distributed in clusters on high-resolution images. In recent days, the
mean-teacher approach trained with pseudo-labels and weak-strong augmentation
consistency is gaining popularity for semi-supervised object detection.
However, a direct adaptation of such semi-supervised detectors for aerial
images where small clustered objects are often present, might not lead to
optimal results. In this paper, we propose a density crop-guided
semi-supervised detector that identifies the cluster of small objects during
training and also exploits them to improve performance at inference. During
training, image crops of clusters identified from labeled and unlabeled images
are used to augment the training set, which in turn increases the chance of
detecting small objects and creating good pseudo-labels for small objects on
the unlabeled images. During inference, the detector is not only able to detect
the objects of interest but also regions with a high density of small objects
(density crops) so that detections from the input image and detections from
image crops are combined, resulting in an overall more accurate object
prediction, especially for small objects. Empirical studies on the popular
benchmarks of VisDrone and DOTA datasets show the effectiveness of our density
crop-guided semi-supervised detector with an average improvement of more than
2\% over the basic mean-teacher method in COCO style AP. Our code is available
at: https://github.com/akhilpm/DroneSSOD.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05034">Kairos: : Practical Intrusion Detection and Investigation using Whole-system Provenance. (arXiv:2308.05034v1 [cs.CR])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zijun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_Q/0/1/0/all/0/1">Qiujian Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jinyuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1">Degang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasquier_T/0/1/0/all/0/1">Thomas Pasquier</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xueyuan Han</a></p>
<p>Provenance graphs are structured audit logs that describe the history of a
system's execution. Recent studies have explored a variety of techniques to
analyze provenance graphs for automated host intrusion detection, focusing
particularly on advanced persistent threats. Sifting through their design
documents, we identify four common dimensions that drive the development of
provenance-based intrusion detection systems (PIDSes): scope (can PIDSes detect
modern attacks that infiltrate across application boundaries?), attack
agnosticity (can PIDSes detect novel attacks without a priori knowledge of
attack characteristics?), timeliness (can PIDSes efficiently monitor host
systems as they run?), and attack reconstruction (can PIDSes distill attack
activity from large provenance graphs so that sysadmins can easily understand
and quickly respond to system intrusion?). We present KAIROS, the first PIDS
that simultaneously satisfies the desiderata in all four dimensions, whereas
existing approaches sacrifice at least one and struggle to achieve comparable
detection performance.
</p>
<p>Kairos leverages a novel graph neural network-based encoder-decoder
architecture that learns the temporal evolution of a provenance graph's
structural changes to quantify the degree of anomalousness for each system
event. Then, based on this fine-grained information, Kairos reconstructs attack
footprints, generating compact summary graphs that accurately describe
malicious activity over a stream of system audit logs. Using state-of-the-art
benchmark datasets, we demonstrate that Kairos outperforms previous approaches.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05036">Collaborative Wideband Spectrum Sensing and Scheduling for Networked UAVs in UTM Systems. (arXiv:2308.05036v1 [eess.SP])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Chintareddy_S/0/1/0/all/0/1">Sravan Reddy Chintareddy</a>, <a href="http://arxiv.org/find/eess/1/au:+Roach_K/0/1/0/all/0/1">Keenan Roach</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheung_K/0/1/0/all/0/1">Kenny Cheung</a>, <a href="http://arxiv.org/find/eess/1/au:+Hashemi_M/0/1/0/all/0/1">Morteza Hashemi</a></p>
<p>In this paper, we propose a data-driven framework for collaborative wideband
spectrum sensing and scheduling for networked unmanned aerial vehicles (UAVs),
which act as the secondary users to opportunistically utilize detected spectrum
holes. To this end, we propose a multi-class classification problem for
wideband spectrum sensing to detect vacant spectrum spots based on collected
I/Q samples. To enhance the accuracy of the spectrum sensing module, the
outputs from the multi-class classification by each individual UAV are fused at
a server in the unmanned aircraft system traffic management (UTM) ecosystem. In
the spectrum scheduling phase, we leverage reinforcement learning (RL)
solutions to dynamically allocate the detected spectrum holes to the secondary
users (i.e., UAVs). To evaluate the proposed methods, we establish a
comprehensive simulation framework that generates a near-realistic synthetic
dataset using MATLAB LTE toolbox by incorporating base-station~(BS) locations
in a chosen area of interest, performing ray-tracing, and emulating the primary
users channel usage in terms of I/Q samples. This evaluation methodology
provides a flexible framework to generate large spectrum datasets that could be
used for developing ML/AI-based spectrum management solutions for aerial
devices.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05046">RadGraph2: Modeling Disease Progression in Radiology Reports via Hierarchical Information Extraction. (arXiv:2308.05046v1 [cs.CL])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Khanna_S/0/1/0/all/0/1">Sameer Khanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Dejl_A/0/1/0/all/0/1">Adam Dejl</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1">Kibo Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_Q/0/1/0/all/0/1">Quoc Hung Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_H/0/1/0/all/0/1">Hanh Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenz_A/0/1/0/all/0/1">Agustina Saenz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1">Pranav Rajpurkar</a></p>
<p>We present RadGraph2, a novel dataset for extracting information from
radiology reports that focuses on capturing changes in disease state and device
placement over time. We introduce a hierarchical schema that organizes entities
based on their relationships and show that using this hierarchy during training
improves the performance of an information extraction model. Specifically, we
propose a modification to the DyGIE++ framework, resulting in our model HGIE,
which outperforms previous models in entity and relation extraction tasks. We
demonstrate that RadGraph2 enables models to capture a wider variety of
findings and perform better at relation extraction compared to those trained on
the original RadGraph dataset. Our work provides the foundation for developing
automated systems that can track disease progression over time and develop
information extraction models that leverage the natural hierarchy of labels in
the medical domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05059">A Novel Method for improving accuracy in neural network by reinstating traditional back propagation technique. (arXiv:2308.05059v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+R_G/0/1/0/all/0/1">Gokulprasath R</a></p>
<p>Deep learning has revolutionized industries like computer vision, natural
language processing, and speech recognition. However, back propagation, the
main method for training deep neural networks, faces challenges like
computational overhead and vanishing gradients. In this paper, we propose a
novel instant parameter update methodology that eliminates the need for
computing gradients at each layer. Our approach accelerates learning, avoids
the vanishing gradient problem, and outperforms state-of-the-art methods on
benchmark data sets. This research presents a promising direction for efficient
and effective deep neural network training.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05061">Prompting In-Context Operator Learning with Sensor Data, Equations, and Natural Language. (arXiv:2308.05061v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Liu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_T/0/1/0/all/0/1">Tingwei Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siting Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1">Stanley J. Osher</a></p>
<p>In the growing domain of scientific machine learning, in-context operator
learning has demonstrated notable potential in learning operators from prompted
data during inference stage without weight updates. However, the current
model's overdependence on sensor data, may inadvertently overlook the
invaluable human insight into the operator. To address this, we present a
transformation of in-context operator learning into a multi-modal paradigm. We
propose the use of "captions" to integrate human knowledge about the operator,
expressed through natural language descriptions and equations. We illustrate
how this method not only broadens the flexibility and generality of
physics-informed learning, but also significantly boosts learning performance
and reduces data needs. Furthermore, we introduce a more efficient neural
network architecture for multi-modal in-context operator learning, referred to
as "ICON-LM", based on a language-model-like architecture. We demonstrate the
viability of "ICON-LM" for scientific machine learning tasks, which creates a
new path for the application of language models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05075">Bayesian Inverse Transition Learning for Offline Settings. (arXiv:2308.05075v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Benac_L/0/1/0/all/0/1">Leo Benac</a>, <a href="http://arxiv.org/find/cs/1/au:+Parbhoo_S/0/1/0/all/0/1">Sonali Parbhoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1">Finale Doshi-Velez</a></p>
<p>Offline Reinforcement learning is commonly used for sequential
decision-making in domains such as healthcare and education, where the rewards
are known and the transition dynamics $T$ must be estimated on the basis of
batch data. A key challenge for all tasks is how to learn a reliable estimate
of the transition dynamics $T$ that produce near-optimal policies that are safe
enough so that they never take actions that are far away from the best action
with respect to their value functions and informative enough so that they
communicate the uncertainties they have. Using data from an expert, we propose
a new constraint-based approach that captures our desiderata for reliably
learning a posterior distribution of the transition dynamics $T$ that is free
from gradients. Our results demonstrate that by using our constraints, we learn
a high-performing policy, while considerably reducing the policy's variance
over different datasets. We also explain how combining uncertainty estimation
with these constraints can help us infer a partial ranking of actions that
produce higher returns, and helps us infer safer and more informative policies
for planning.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05092">A degree of image identification at sub-human scales could be possible with more advanced clusters. (arXiv:2308.05092v1 [cs.CV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+J_P/0/1/0/all/0/1">Prateek Y J</a></p>
<p>The purpose of the research is to determine if currently available
self-supervised learning techniques can accomplish human level comprehension of
visual images using the same degree and amount of sensory input that people
acquire from. Initial research on this topic solely considered data volume
scaling. Here, we scale both the volume of data and the quality of the image.
This scaling experiment is a self-supervised learning method that may be done
without any outside financing. We find that scaling up data volume and picture
resolution at the same time enables human-level item detection performance at
sub-human sizes.We run a scaling experiment with vision transformers trained on
up to 200000 images up to 256 ppi.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05101">DOST -- Domain Obedient Self-supervised Training for Multi Label Classification with Noisy Labels. (arXiv:2308.05101v1 [cs.LG])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Soumadeep Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Garain_U/0/1/0/all/0/1">Utpal Garain</a>, <a href="http://arxiv.org/find/cs/1/au:+Ukil_A/0/1/0/all/0/1">Arijit Ukil</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_A/0/1/0/all/0/1">Arpan Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Khandelwal_S/0/1/0/all/0/1">Sundeep Khandelwal</a></p>
<p>The enormous demand for annotated data brought forth by deep learning
techniques has been accompanied by the problem of annotation noise. Although
this issue has been widely discussed in machine learning literature, it has
been relatively unexplored in the context of "multi-label classification" (MLC)
tasks which feature more complicated kinds of noise. Additionally, when the
domain in question has certain logical constraints, noisy annotations often
exacerbate their violations, making such a system unacceptable to an expert.
This paper studies the effect of label noise on domain rule violation incidents
in the MLC task, and incorporates domain rules into our learning algorithm to
mitigate the effect of noise. We propose the Domain Obedient Self-supervised
Training (DOST) paradigm which not only makes deep learning models more aligned
to domain rules, but also improves learning performance in key metrics and
minimizes the effect of annotation noise. This novel approach uses domain
guidance to detect offending annotations and deter rule-violating predictions
in a self-supervised manner, thus making it more "data efficient" and domain
compliant. Empirical studies, performed over two large scale multi-label
classification datasets, demonstrate that our method results in improvement
across the board, and often entirely counteracts the effect of noise.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.05103">Improved Multi-Shot Diffusion-Weighted MRI with Zero-Shot Self-Supervised Learning Reconstruction. (arXiv:2308.05103v1 [eess.IV])</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Cho_J/0/1/0/all/0/1">Jaejin Cho</a>, <a href="http://arxiv.org/find/eess/1/au:+Jun_Y/0/1/0/all/0/1">Yohan Jun</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1">Xiaoqing Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Kobayashi_C/0/1/0/all/0/1">Caique Kobayashi</a>, <a href="http://arxiv.org/find/eess/1/au:+Bilgic_B/0/1/0/all/0/1">Berkin Bilgic</a></p>
<p>Diffusion MRI is commonly performed using echo-planar imaging (EPI) due to
its rapid acquisition time. However, the resolution of diffusion-weighted
images is often limited by magnetic field inhomogeneity-related artifacts and
blurring induced by T2- and T2*-relaxation effects. To address these
limitations, multi-shot EPI (msEPI) combined with parallel imaging techniques
is frequently employed. Nevertheless, reconstructing msEPI can be challenging
due to phase variation between multiple shots. In this study, we introduce a
novel msEPI reconstruction approach called zero-MIRID (zero-shot
self-supervised learning of Multi-shot Image Reconstruction for Improved
Diffusion MRI). This method jointly reconstructs msEPI data by incorporating
deep learning-based image regularization techniques. The network incorporates
CNN denoisers in both k- and image-spaces, while leveraging virtual coils to
enhance image reconstruction conditioning. By employing a self-supervised
learning technique and dividing sampled data into three groups, the proposed
approach achieves superior results compared to the state-of-the-art parallel
imaging method, as demonstrated in an in-vivo experiment.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/1911.12965">Sparse and Low-Rank High-Order Tensor Regression via Parallel Proximal Method. (arXiv:1911.12965v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yinghao Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Beilun Wang</a></p>
<p>Recently, tensor data (or multidimensional array) have been generated in many
modern applications, such as functional magnetic resonance imaging (fMRI) in
neuroscience and videos in video analysis. Many efforts are made in recent
years to predict the relationship between tensor features and univariate
responses. However, previously proposed methods either lose structural
information within tensor data or have prohibitively expensive time costs,
especially for large-scale data with high-order structures. To address such
problems, we propose the Sparse and Low-rank Tensor Regression (SLTR) model.
Our model enforces sparsity and low-rankness of the tensor coefficient by
directly applying $\ell_1$ norm and tensor nuclear norm, such that it preserves
structural information of the tensor. To make the solving procedure scalable
and efficient, SLTR makes use of the proximal gradient method, which can be
easily implemented parallelly. We evaluate SLTR on several simulated datasets
and one video action recognition dataset. Experiment results show that,
compared with previous models, SLTR can obtain a better solution with much
fewer time costs. Moreover, our model's predictions exhibit meaningful
interpretations on the video dataset.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2007.07461">Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity. (arXiv:2007.07461v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaiqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham M. Kakade</a>, <a href="http://arxiv.org/find/cs/1/au:+Basar_T/0/1/0/all/0/1">Tamer Ba&#x15f;ar</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin F. Yang</a></p>
<p>Model-based reinforcement learning (RL), which finds an optimal policy using
an empirical model, has long been recognized as one of the corner stones of RL.
It is especially suitable for multi-agent RL (MARL), as it naturally decouples
the learning and the planning phases, and avoids the non-stationarity problem
when all agents are improving their policies simultaneously using samples.
Though intuitive and widely-used, the sample complexity of model-based MARL
algorithms has not been fully investigated. In this paper, our goal is to
address the fundamental question about its sample complexity. We study arguably
the most basic MARL setting: two-player discounted zero-sum Markov games, given
only access to a generative model. We show that model-based MARL achieves a
sample complexity of $\tilde O(|S||A||B|(1-\gamma)^{-3}\epsilon^{-2})$ for
finding the Nash equilibrium (NE) value up to some $\epsilon$ error, and the
$\epsilon$-NE policies with a smooth planning oracle, where $\gamma$ is the
discount factor, and $S,A,B$ denote the state space, and the action spaces for
the two agents. We further show that such a sample bound is minimax-optimal (up
to logarithmic factors) if the algorithm is reward-agnostic, where the
algorithm queries state transition samples without reward knowledge, by
establishing a matching lower bound. This is in contrast to the usual
reward-aware setting, with a
$\tilde\Omega(|S|(|A|+|B|)(1-\gamma)^{-3}\epsilon^{-2})$ lower bound, where
this model-based approach is near-optimal with only a gap on the $|A|,|B|$
dependence. Our results not only demonstrate the sample-efficiency of this
basic model-based approach in MARL, but also elaborate on the fundamental
tradeoff between its power (easily handling the more challenging
reward-agnostic case) and limitation (less adaptive and suboptimal in
$|A|,|B|$), particularly arises in the multi-agent context.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2108.13672">SANSformers: Self-Supervised Forecasting in Electronic Health Records with Attention-Free Models. (arXiv:2108.13672v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kumar_Y/0/1/0/all/0/1">Yogesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilin_A/0/1/0/all/0/1">Alexander Ilin</a>, <a href="http://arxiv.org/find/cs/1/au:+Salo_H/0/1/0/all/0/1">Henri Salo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulathinal_S/0/1/0/all/0/1">Sangita Kulathinal</a>, <a href="http://arxiv.org/find/cs/1/au:+Leinonen_M/0/1/0/all/0/1">Maarit K. Leinonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Marttinen_P/0/1/0/all/0/1">Pekka Marttinen</a></p>
<p>The application of Transformer neural networks to Electronic Health Records
(EHR) is challenging due to the distinct, multidimensional sequential structure
of EHR data, often leading to underperformance when compared to simpler linear
models. Thus, the advantages of Transformers, such as efficient transfer
learning and improved scalability are not fully exploited in EHR applications.
To overcome these challenges, we introduce SANSformer, a novel attention-free
sequential model designed specifically with inductive biases to cater for the
unique characteristics of EHR data.
</p>
<p>Our main application area is predicting future healthcare utilization, a
crucial task for effectively allocating healthcare resources. This task becomes
particularly difficult when dealing with divergent patient subgroups. These
subgroups, characterized by unique health trajectories and often small in size,
such as patients with rare diseases, require specialized modeling approaches.
To address this, we adopt a self-supervised pretraining strategy, which we term
Generative Summary Pretraining (GSP). GSP predicts summary statistics of a
future window in the patient's history based on their past health records, thus
demonstrating potential to deal with the noisy and complex nature of EHR data.
We pretrain our models on a comprehensive health registry encompassing close to
one million patients, before fine-tuning them for specific subgroup prediction
tasks.
</p>
<p>In our evaluations, SANSformer consistently outshines strong EHR baselines.
Importantly, our GSP pretraining method greatly enhances model performance,
especially for smaller patient subgroups. Our findings underscore the
substantial potential of bespoke attention-free models and self-supervised
pretraining for enhancing healthcare utilization predictions across a broad
range of patient groups.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2110.02414">Imaginary Hindsight Experience Replay: Curious Model-based Learning for Sparse Reward Tasks. (arXiv:2110.02414v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+McCarthy_R/0/1/0/all/0/1">Robert McCarthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Redmond_S/0/1/0/all/0/1">Stephen J. Redmond</a></p>
<p>Model-based reinforcement learning is a promising learning strategy for
practical robotic applications due to its improved data-efficiency versus
model-free counterparts. However, current state-of-the-art model-based methods
rely on shaped reward signals, which can be difficult to design and implement.
To remedy this, we propose a simple model-based method tailored for
sparse-reward multi-goal tasks that foregoes the need for complicated reward
engineering. This approach, termed Imaginary Hindsight Experience Replay,
minimises real-world interactions by incorporating imaginary data into policy
updates. To improve exploration in the sparse-reward setting, the policy is
trained with standard Hindsight Experience Replay and endowed with
curiosity-based intrinsic rewards. Upon evaluation, this approach provides an
order of magnitude increase in data-efficiency on average versus the
state-of-the-art model-free method in the benchmark OpenAI Gym Fetch Robotics
tasks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.00407">Inverse problem for parameters identification in a modified SIRD epidemic model using ensemble neural networks. (arXiv:2203.00407v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Petrica_M/0/1/0/all/0/1">Marian Petrica</a>, <a href="http://arxiv.org/find/cs/1/au:+Popescu_I/0/1/0/all/0/1">Ionel Popescu</a></p>
<p>In this paper, we propose a parameter identification methodology of the SIRD
model, an extension of the classical SIR model, that considers the deceased as
a separate category. In addition, our model includes one parameter which is the
ratio between the real total number of infected and the number of infected that
were documented in the official statistics.
</p>
<p>Due to many factors, like governmental decisions, several variants
circulating, opening and closing of schools, the typical assumption that the
parameters of the model stay constant for long periods of time is not
realistic. Thus our objective is to create a method which works for short
periods of time. In this scope, we approach the estimation relying on the
previous 7 days of data and then use the identified parameters to make
predictions.
</p>
<p>To perform the estimation of the parameters we propose the average of an
ensemble of neural networks. Each neural network is constructed based on a
database built by solving the SIRD for 7 days, with random parameters. In this
way, the networks learn the parameters from the solution of the SIRD model.
</p>
<p>Lastly we use the ensemble to get estimates of the parameters from the real
data of Covid19 in Romania and then we illustrate the predictions for different
periods of time, from 10 up to 45 days, for the number of deaths. The main goal
was to apply this approach on the analysis of COVID-19 evolution in Romania,
but this was also exemplified on other countries like Hungary, Czech Republic
and Poland with similar results.
</p>
<p>The results are backed by a theorem which guarantees that we can recover the
parameters of the model from the reported data. We believe this methodology can
be used as a general tool for dealing with short term predictions of infectious
diseases or in other compartmental models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2203.01937">BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification. (arXiv:2203.01937v5 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Yuanhong Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1">Fengbei Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1">Hu Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Chong Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Tian_Y/0/1/0/all/0/1">Yu Tian</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yuyuan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Carneiro_G/0/1/0/all/0/1">Gustavo Carneiro</a></p>
<p>Deep learning methods have shown outstanding classification accuracy in
medical imaging problems, which is largely attributed to the availability of
large-scale datasets manually annotated with clean labels. However, given the
high cost of such manual annotation, new medical imaging classification
problems may need to rely on machine-generated noisy labels extracted from
radiology reports. Indeed, many Chest X-ray (CXR) classifiers have already been
modelled from datasets with noisy labels, but their training procedure is in
general not robust to noisy-label samples, leading to sub-optimal models.
Furthermore, CXR datasets are mostly multi-label, so current noisy-label
learning methods designed for multi-class problems cannot be easily adapted. In
this paper, we propose a new method designed for the noisy multi-label CXR
learning, which detects and smoothly re-labels samples from the dataset, which
is then used to train common multi-label classifiers. The proposed method
optimises a bag of multi-label descriptors (BoMD) to promote their similarity
with the semantic descriptors produced by BERT models from the multi-label
image annotation. Our experiments on diverse noisy multi-label training sets
and clean testing sets show that our model has state-of-the-art accuracy and
robustness in many CXR multi-label classification benchmarks.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2204.05885">A Hierarchical Block Distance Model for Ultra Low-Dimensional Graph Representations. (arXiv:2204.05885v2 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Nakis_N/0/1/0/all/0/1">Nikolaos Nakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Celikkanat_A/0/1/0/all/0/1">Abdulkadir &#xc7;elikkanat</a>, <a href="http://arxiv.org/find/cs/1/au:+Jorgensen_S/0/1/0/all/0/1">Sune Lehmann J&#xf8;rgensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Morup_M/0/1/0/all/0/1">Morten M&#xf8;rup</a></p>
<p>Graph Representation Learning (GRL) has become central for characterizing
structures of complex networks and performing tasks such as link prediction,
node classification, network reconstruction, and community detection. Whereas
numerous generative GRL models have been proposed, many approaches have
prohibitive computational requirements hampering large-scale network analysis,
fewer are able to explicitly account for structure emerging at multiple scales,
and only a few explicitly respect important network properties such as
homophily and transitivity. This paper proposes a novel scalable graph
representation learning method named the Hierarchical Block Distance Model
(HBDM). The HBDM imposes a multiscale block structure akin to stochastic block
modeling (SBM) and accounts for homophily and transitivity by accurately
approximating the latent distance model (LDM) throughout the inferred
hierarchy. The HBDM naturally accommodates unipartite, directed, and bipartite
networks whereas the hierarchy is designed to ensure linearithmic time and
space complexity enabling the analysis of very large-scale networks. We
evaluate the performance of the HBDM on massive networks consisting of millions
of nodes. Importantly, we find that the proposed HBDM framework significantly
outperforms recent scalable approaches in all considered downstream tasks.
Surprisingly, we observe superior performance even imposing ultra-low
two-dimensional embeddings facilitating accurate direct and hierarchical-aware
network visualization and interpretation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2206.14797">3D-Aware Video Generation. (arXiv:2206.14797v4 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bahmani_S/0/1/0/all/0/1">Sherwin Bahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jeong Joon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Paschalidou_D/0/1/0/all/0/1">Despoina Paschalidou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wetzstein_G/0/1/0/all/0/1">Gordon Wetzstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas Guibas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a></p>
<p>Generative models have emerged as an essential building block for many image
synthesis and editing tasks. Recent advances in this field have also enabled
high-quality 3D or video content to be generated that exhibits either
multi-view or temporal consistency. With our work, we explore 4D generative
adversarial networks (GANs) that learn unconditional generation of 3D-aware
videos. By combining neural implicit representations with time-aware
discriminator, we develop a GAN framework that synthesizes 3D video supervised
only with monocular videos. We show that our method learns a rich embedding of
decomposable 3D structures and motions that enables new visual effects of
spatio-temporal renderings while producing imagery with quality comparable to
that of existing 3D or video GANs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2209.07970">Causal Fourier Analysis on Directed Acyclic Graphs and Posets. (arXiv:2209.07970v3 [eess.SP] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Seifert_B/0/1/0/all/0/1">Bastian Seifert</a>, <a href="http://arxiv.org/find/eess/1/au:+Wendler_C/0/1/0/all/0/1">Chris Wendler</a>, <a href="http://arxiv.org/find/eess/1/au:+Puschel_M/0/1/0/all/0/1">Markus P&#xfc;schel</a></p>
<p>We present a novel form of Fourier analysis, and associated signal processing
concepts, for signals (or data) indexed by edge-weighted directed acyclic
graphs (DAGs). This means that our Fourier basis yields an eigendecomposition
of a suitable notion of shift and convolution operators that we define. DAGs
are the common model to capture causal relationships between data values and in
this case our proposed Fourier analysis relates data with its causes under a
linearity assumption that we define. The definition of the Fourier transform
requires the transitive closure of the weighted DAG for which several forms are
possible depending on the interpretation of the edge weights. Examples include
level of influence, distance, or pollution distribution. Our framework is
different from prior GSP: it is specific to DAGs and leverages, and extends,
the classical theory of Moebius inversion from combinatorics. For a
prototypical application we consider DAGs modeling dynamic networks in which
edges change over time. Specifically, we model the spread of an infection on
such a DAG obtained from real-world contact tracing data and learn the
infection signal from samples assuming sparsity in the Fourier domain.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.10780">An out-of-distribution discriminator based on Bayesian neural network epistemic uncertainty. (arXiv:2210.10780v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ancell_E/0/1/0/all/0/1">Ethan Ancell</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennett_C/0/1/0/all/0/1">Christopher Bennett</a>, <a href="http://arxiv.org/find/cs/1/au:+Debusschere_B/0/1/0/all/0/1">Bert Debusschere</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sapan Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hays_P/0/1/0/all/0/1">Park Hays</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">T. Patrick Xiao</a></p>
<p>Neural networks have revolutionized the field of machine learning with
increased predictive capability. In addition to improving the predictions of
neural networks, there is a simultaneous demand for reliable uncertainty
quantification on estimates made by machine learning methods such as neural
networks. Bayesian neural networks (BNNs) are an important type of neural
network with built-in capability for quantifying uncertainty. This paper
discusses aleatoric and epistemic uncertainty in BNNs and how they can be
calculated. With an example dataset of images where the goal is to identify the
amplitude of an event in the image, it is shown that epistemic uncertainty
tends to be lower in images which are well-represented in the training dataset
and tends to be high in images which are not well-represented. An algorithm for
out-of-distribution (OoD) detection with BNN epistemic uncertainty is
introduced along with various experiments demonstrating factors influencing the
OoD detection capability in a BNN. The OoD detection capability with epistemic
uncertainty is shown to be comparable to the OoD detection in the discriminator
network of a generative adversarial network (GAN) with comparable network
architecture.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2210.12126">One-Shot Neural Fields for 3D Object Understanding. (arXiv:2210.12126v3 [cs.RO] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Blukis_V/0/1/0/all/0/1">Valts Blukis</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1">Taeyeop Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Tremblay_J/0/1/0/all/0/1">Jonathan Tremblay</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_B/0/1/0/all/0/1">Bowen Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1">Kuk-Jin Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>, <a href="http://arxiv.org/find/cs/1/au:+Birchfield_S/0/1/0/all/0/1">Stan Birchfield</a></p>
<p>We present a unified and compact scene representation for robotics, where
each object in the scene is depicted by a latent code capturing geometry and
appearance. This representation can be decoded for various tasks such as novel
view rendering, 3D reconstruction (e.g. recovering depth, point clouds, or
voxel maps), collision checking, and stable grasp prediction. We build our
representation from a single RGB input image at test time by leveraging recent
advances in Neural Radiance Fields (NeRF) that learn category-level priors on
large multiview datasets, then fine-tune on novel objects from one or few
views. We expand the NeRF model for additional grasp outputs and explore ways
to leverage this representation for robotics. At test-time, we build the
representation from a single RGB input image observing the scene from only one
viewpoint. We find that the recovered representation allows rendering from
novel views, including of occluded object parts, and also for predicting
successful stable grasps. Grasp poses can be directly decoded from our latent
representation with an implicit grasp decoder. We experimented in both
simulation and real world and demonstrated the capability for robust robotic
grasping using such compact representation. Website:
https://nerfgrasp.github.io
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.02408">Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis. (arXiv:2211.02408v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1">Lukas Struppek</a>, <a href="http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1">Dominik Hintersdorf</a>, <a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1">Kristian Kersting</a></p>
<p>While text-to-image synthesis currently enjoys great popularity among
researchers and the general public, the security of these models has been
neglected so far. Many text-guided image generation models rely on pre-trained
text encoders from external sources, and their users trust that the retrieved
models will behave as promised. Unfortunately, this might not be the case. We
introduce backdoor attacks against text-guided generative models and
demonstrate that their text encoders pose a major tampering risk. Our attacks
only slightly alter an encoder so that no suspicious model behavior is apparent
for image generations with clean prompts. By then inserting a single character
trigger into the prompt, e.g., a non-Latin character or emoji, the adversary
can trigger the model to either generate images with pre-defined attributes or
images following a hidden, potentially malicious description. We empirically
demonstrate the high effectiveness of our attacks on Stable Diffusion and
highlight that the injection process of a single backdoor takes less than two
minutes. Besides phrasing our approach solely as an attack, it can also force
an encoder to forget phrases related to certain concepts, such as nudity or
violence, and help to make image generation safer.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.06108">RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection System. (arXiv:2211.06108v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yanlong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jianan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Q/0/1/0/all/0/1">Qing-Long Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1">Gang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Bing Zhu</a></p>
<p>In autonomous driving systems, LiDAR and radar play important roles in the
perception of the surrounding environment. LiDAR provides accurate 3D spatial
sensing information but cannot work in adverse weather like fog. On the other
hand, the radar signal can be diffracted when encountering raindrops or mist
particles thanks to its wavelength, but it suffers from large noise. Recent
state-of-the-art works reveal that fusion of radar and LiDAR can lead to robust
detection in adverse weather. The existing works adopt convolutional neural
network architecture to extract features from each sensor data stream, then
align and aggregate the two branch features to predict object detection
results. However, these methods have low accuracy of bounding box estimations
due to a simple design of label assignment and fusion strategies. In this
paper, we propose a bird's-eye view fusion learning-based anchor box-free
object detection system, which fuses the feature derived from the radar
range-azimuth heatmap and the LiDAR point cloud to estimate the possible
objects. Different label assignment strategies have been designed to facilitate
the consistency between the classification of foreground or background anchor
points and the corresponding bounding box regressions. In addition, the
performance of the proposed object detector is further enhanced by employing a
novel interactive transformer module. The superior performance of the methods
proposed in this paper has been demonstrated using the recently published
Oxford Radar RobotCar dataset. Our system's average precision significantly
outperforms the best state-of-the-art method by 13.1% and 19.0% at IoU of 0.8
under 'Clear+Foggy' training conditions for 'Clear' and 'Foggy' testing,
respectively.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2211.14946">Self-Destructing Models: Increasing the Costs of Harmful Dual Uses of Foundation Models. (arXiv:2211.14946v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1">Peter Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_E/0/1/0/all/0/1">Eric Mitchell</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1">Christopher D. Manning</a>, <a href="http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1">Dan Jurafsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a></p>
<p>A growing ecosystem of large, open-source foundation models has reduced the
labeled data and technical expertise necessary to apply machine learning to
many new problems. Yet foundation models pose a clear dual-use risk,
indiscriminately reducing the costs of building both harmful and beneficial
machine learning systems. Policy tools such as restricted model access and
export controls are the primary methods currently used to mitigate such
dual-use risks. In this work, we review potential safe-release strategies and
argue that both policymakers and AI researchers would benefit from
fundamentally new technologies enabling more precise control over the
downstream usage of open-source foundation models. We propose one such
approach: the task blocking paradigm, in which foundation models are trained
with an additional mechanism to impede adaptation to harmful tasks without
sacrificing performance on desirable tasks. We call the resulting models
self-destructing models, inspired by mechanisms that prevent adversaries from
using tools for harmful purposes. We present an algorithm for training
self-destructing models leveraging techniques from meta-learning and
adversarial learning, which we call meta-learned adversarial censoring (MLAC).
In a small-scale experiment, we show MLAC can largely prevent a BERT-style
model from being re-purposed to perform gender identification without harming
the model's ability to perform profession classification.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2212.10445">Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization. (arXiv:2212.10445v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Rame_A/0/1/0/all/0/1">Alexandre Ram&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1">Kartik Ahuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1">Matthieu Cord</a>, <a href="http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1">L&#xe9;on Bottou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_Paz_D/0/1/0/all/0/1">David Lopez-Paz</a></p>
<p>Foundation models are redefining how AI systems are built. Practitioners now
follow a standard procedure to build their machine learning solutions: from a
pre-trained foundation model, they fine-tune the weights on the target task of
interest. So, the Internet is swarmed by a handful of foundation models
fine-tuned on many diverse tasks: these individual fine-tunings exist in
isolation without benefiting from each other. In our opinion, this is a missed
opportunity, as these specialized models contain rich and diverse features. In
this paper, we thus propose model ratatouille, a new strategy to recycle the
multiple fine-tunings of the same foundation model on diverse auxiliary tasks.
Specifically, we repurpose these auxiliary weights as initializations for
multiple parallel fine-tunings on the target task; then, we average all
fine-tuned weights to obtain the final model. This recycling strategy aims at
maximizing the diversity in weights by leveraging the diversity in auxiliary
tasks. Empirically, it improves the state of the art on the reference DomainBed
benchmark for out-of-distribution generalization. Looking forward, this work
contributes to the emerging paradigm of updatable machine learning where, akin
to open-source software development, the community collaborates to reliably
update machine learning models. Our code is released:
https://github.com/facebookresearch/ModelRatatouille.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2301.07820">Emergence of the SVD as an interpretable factorization in deep learning for inverse problems. (arXiv:2301.07820v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sule_S/0/1/0/all/0/1">Shashank Sule</a>, <a href="http://arxiv.org/find/cs/1/au:+Spencer_R/0/1/0/all/0/1">Richard G. Spencer</a>, <a href="http://arxiv.org/find/cs/1/au:+Czaja_W/0/1/0/all/0/1">Wojciech Czaja</a></p>
<p>Within the framework of deep learning we demonstrate the emergence of the
singular value decomposition (SVD) of the weight matrix as a tool for
interpretation of neural networks (NN) when combined with the descrambling
transformation--a recently-developed technique for addressing interpretability
in noisy parameter estimation neural networks \cite{amey2021neural}. By
considering the averaging effect of the data passed to the descrambling
minimization problem, we show that descrambling transformations--in the large
data limit--can be expressed in terms of the SVD of the NN weights and the
input autocorrelation matrix. Using this fact, we show that within the class of
noisy parameter estimation problems the SVD may be the structure through which
trained networks encode a signal model. We substantiate our theoretical
findings with empirical evidence from both linear and non-linear signal models.
Our results also illuminate the connections between a mathematical theory of
semantic development \cite{saxe2019mathematical} and neural network
interpretability.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.00722">A Survey of Deep Learning: From Activations to Transformers. (arXiv:2302.00722v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Johannes Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachos_M/0/1/0/all/0/1">Michalis Vlachos</a></p>
<p>The past decade has witnessed remarkable advancements in deep learning, owing
to the emergence of various architectures, layers, objectives, and optimization
techniques. These consist of a multitude of variations of attention,
normalization, skip connections, transformer, and self-supervised learning
methods, among others. Our goal is to furnish a comprehensive survey of
significant recent contributions in these domains to individuals with a
fundamental grasp of deep learning. Our aspiration is that an integrated and
comprehensive approach of influential recent works will facilitate the
formation of new connections between different areas of deep learning. In our
discussion, we discuss multiple patterns that summarize the key strategies for
many of the successful innovations over the last decade. We also include a
discussion on recent commercially built, closed-source models such as OpenAI's
GPT-4 and Google's PaLM 2.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2302.14102">Connectivity Optimized Nested Graph Networks for Crystal Structures. (arXiv:2302.14102v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ruff_R/0/1/0/all/0/1">Robin Ruff</a>, <a href="http://arxiv.org/find/cs/1/au:+Reiser_P/0/1/0/all/0/1">Patrick Reiser</a>, <a href="http://arxiv.org/find/cs/1/au:+Stuhmer_J/0/1/0/all/0/1">Jan St&#xfc;hmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Friederich_P/0/1/0/all/0/1">Pascal Friederich</a></p>
<p>Graph neural networks (GNNs) have been applied to a large variety of
applications in materials science and chemistry. Here, we recapitulate the
graph construction for crystalline (periodic) materials and investigate its
impact on the GNNs model performance. We suggest the asymmetric unit cell as a
representation to reduce the number of atoms by using all symmetries of the
system. This substantially reduced the computational cost and thus time needed
to train large graph neural networks without any loss in accuracy. Furthermore,
with a simple but systematically built GNN architecture based on message
passing and line graph templates, we introduce a general architecture (Nested
Graph Network, NGN) that is applicable to a wide range of tasks. We show that
our suggested models systematically improve state-of-the-art results across all
tasks within the MatBench benchmark. Further analysis shows that optimized
connectivity and deeper message functions are responsible for the improvement.
Asymmetric unit cells and connectivity optimization can be generally applied to
(crystal) graph networks, while our suggested nested graph framework will open
new ways of systematic comparison of GNN architectures.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.02898">Stabilizing the Maximal Entropy Moment Method for Rarefied Gas Dynamics at Single-Precision. (arXiv:2303.02898v2 [physics.flu-dyn] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/physics/1/au:+Zheng_C/0/1/0/all/0/1">Candi Zheng</a>, <a href="http://arxiv.org/find/physics/1/au:+Yang_W/0/1/0/all/0/1">Wang Yang</a>, <a href="http://arxiv.org/find/physics/1/au:+Chen_S/0/1/0/all/0/1">Shiyi Chen</a></p>
<p>Developing extended hydrodynamics equations valid for both dense and rarefied
gases remains a great challenge. A systematical solution for this challenge is
the moment method describing both dense and rarefied gas behaviors with moments
of gas molecule velocity distributions. Among moment methods, the maximal
entropy moment method (MEM) stands out for its well-posedness and stability,
which utilizes velocity distributions with maximized entropy. However, finding
such distributions requires solving an ill-conditioned and
computation-demanding optimization problem. This problem causes numerical
overflow and breakdown when the numerical precision is insufficient, especially
for flows like high-speed shock waves. It also prevents modern GPUs from
accelerating optimization with their enormous single floating-point precision
computation power. This paper aims to stabilize MEM, making it practical for
simulating very strong normal shock waves on modern GPUs at single precision.
We propose the gauge transformations for MEM, making the optimization less
ill-conditioned. We also tackle numerical overflow and breakdown by adopting
the canonical form of distribution and Newton's modified optimization method.
With these techniques, we achieved a single-precision GPU simulation of a Mach
10 shock wave with 35 moments MEM, surpassing the previous double-precision
results of Mach 4. Moreover, we argued that over-refined spatial mesh degrades
both the accuracy and stability of MEM. Overall, this paper makes the maximal
entropy moment method practical for simulating very strong normal shock waves
on modern GPUs at single-precision, with significant stability improvement
compared to previous methods.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.04673">Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference. (arXiv:2303.04673v2 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Susan Xueqing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1">Ahmed H. Awadallah</a></p>
<p>Large Language Models (LLMs) have sparked significant interest in their
generative capabilities, leading to the development of various commercial
applications. The high cost of using the models drives application builders to
maximize the value of generation under a limited inference budget. This paper
presents a study of optimizing inference hyperparameters such as the number of
responses, temperature and max tokens, which significantly affects the
utility/cost of text generation. We design a framework named EcoOptiGen which
leverages economical hyperparameter optimization and cost-based pruning.
Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its
effectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML
library: \url{https://aka.ms/autogen}.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.07122">Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference. (arXiv:2303.07122v3 [cs.AI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Sahara Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Faruque_O/0/1/0/all/0/1">Omar Faruque</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yiyi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gani_M/0/1/0/all/0/1">Md. Osman Gani</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_A/0/1/0/all/0/1">Aneesh Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shchlegel_N/0/1/0/all/0/1">Nicole-Jienne Shchlegel</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianwu Wang</a></p>
<p>The warming of the Arctic, also known as Arctic amplification, is led by
several atmospheric and oceanic drivers. However, the details of its underlying
thermodynamic causes are still unknown. Inferring the causal effects of
atmospheric processes on sea ice melt using fixed treatment effect strategies
leads to unrealistic counterfactual estimations. Such models are also prone to
bias due to time-varying confoundedness. Further, the complex non-linearity in
Earth science data makes it infeasible to perform causal inference using
existing marginal structural techniques. In order to tackle these challenges,
we propose TCINet - time-series causal inference model to infer causation under
continuous treatment using recurrent neural networks and a novel probabilistic
balancing technique. Through experiments on synthetic and observational data,
we show how our research can substantially improve the ability to quantify
leading causes of Arctic sea ice melt, further paving paths for causal
inference in observational Earth science.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.16839">MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks. (arXiv:2303.16839v3 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kuo_W/0/1/0/all/0/1">Weicheng Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Piergiovanni_A/0/1/0/all/0/1">AJ Piergiovanni</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dahun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiyang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Caine_B/0/1/0/all/0/1">Ben Caine</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogale_A/0/1/0/all/0/1">Abhijit Ogale</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Luowei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1">Andrew Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhifeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1">Claire Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Angelova_A/0/1/0/all/0/1">Anelia Angelova</a></p>
<p>The development of language models have moved from encoder-decoder to
decoder-only designs. In addition, we observe that the two most popular
multimodal tasks, the generative and contrastive tasks, are nontrivial to
accommodate in one architecture, and further need adaptations for downstream
tasks. We propose a novel paradigm of training with a decoder-only model for
multimodal tasks, which is surprisingly effective in jointly learning of these
disparate vision-language tasks. This is done with a simple model, called
MaMMUT. It consists of a single vision encoder and a text decoder, and is able
to accommodate contrastive and generative learning by a novel two-pass approach
on the text decoder. We demonstrate that joint learning of these diverse
objectives is simple, effective, and maximizes the weight-sharing of the model
across these tasks. Furthermore, the same architecture enables straightforward
extensions to open-vocabulary object detection and video-language tasks. The
model tackles a diverse range of tasks, while being modest in capacity. Our
model achieves the state of the art on image-text and text-image retrieval,
video question answering and open-vocabulary detection tasks, outperforming
much larger and more extensively trained foundational models. It shows very
competitive results on VQA and Video Captioning, especially considering its
capacity. Ablations confirm the flexibility and advantages of our approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.17566">Non-Invasive Fairness in Learning through the Lens of Data Drift. (arXiv:2303.17566v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Ke Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meliou_A/0/1/0/all/0/1">Alexandra Meliou</a></p>
<p>Machine Learning (ML) models are widely employed to drive many modern data
systems. While they are undeniably powerful tools, ML models often demonstrate
imbalanced performance and unfair behaviors. The root of this problem often
lies in the fact that different subpopulations commonly display divergent
trends: as a learning algorithm tries to identify trends in the data, it
naturally favors the trends of the majority groups, leading to a model that
performs poorly and unfairly for minority populations. Our goal is to improve
the fairness and trustworthiness of ML models by applying only non-invasive
interventions, i.e., without altering the data or the learning algorithm. We
use a simple but key insight: the divergence of trends between different
populations, and, consecutively, between a learned model and minority
populations, is analogous to data drift, which indicates the poor conformance
between parts of the data and the trained model. We explore two strategies
(model-splitting and reweighing) to resolve this drift, aiming to improve the
overall conformance of models to the underlying data. Both our methods
introduce novel ways to employ the recently-proposed data profiling primitive
of Conformance Constraints. Our experimental evaluation over 7 real-world
datasets shows that both DifFair and ConFair improve the fairness of ML models.
We demonstrate scenarios where DifFair has an edge, though ConFair has the
greatest practical impact and outperforms other baselines. Moreover, as a
model-agnostic technique, ConFair stays robust when used against different
models than the ones on which the weights have been learned, which is not the
case for other state of the art.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2303.17805">On the Effect of Initialization: The Scaling Path of 2-Layer Neural Networks. (arXiv:2303.17805v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Neumayer_S/0/1/0/all/0/1">Sebastian Neumayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Chizat_L/0/1/0/all/0/1">L&#xe9;na&#xef;c Chizat</a>, <a href="http://arxiv.org/find/cs/1/au:+Unser_M/0/1/0/all/0/1">Michael Unser</a></p>
<p>In supervised learning, the regularization path is sometimes used as a
convenient theoretical proxy for the optimization path of gradient descent
initialized from zero. In this paper, we study a modification of the
regularization path for infinite-width 2-layer ReLU neural networks with
nonzero initial distribution of the weights at different scales. By exploiting
a link with unbalanced optimal-transport theory, we show that, despite the
non-convexity of the 2-layer network training, this problem admits an
infinite-dimensional convex counterpart. We formulate the corresponding
functional-optimization problem and investigate its main properties. In
particular, we show that, as the scale of the initialization ranges between $0$
and $+\infty$, the associated path interpolates continuously between the
so-called kernel and rich regimes. Numerical experiments confirm that, in our
setting, the scaling path and the final states of the optimization path behave
similarly, even beyond these extreme points.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.00409">DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection. (arXiv:2304.00409v2 [cs.CR] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yizheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zhoujie Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Alowain_L/0/1/0/all/0/1">Lamya Alowain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_D/0/1/0/all/0/1">David Wagner</a></p>
<p>We propose and release a new vulnerable source code dataset. We curate the
dataset by crawling security issue websites, extracting vulnerability-fixing
commits and source codes from the corresponding projects. Our new dataset
contains 18,945 vulnerable functions spanning 150 CWEs and 330,492
non-vulnerable functions extracted from 7,514 commits. Our dataset covers 295
more projects than all previous datasets combined.
</p>
<p>Combining our new dataset with previous datasets, we present an analysis of
the challenges and promising research directions of using deep learning for
detecting software vulnerabilities. We study 11 model architectures belonging
to 4 families. Our results show that deep learning is still not ready for
vulnerability detection, due to high false positive rate, low F1 score, and
difficulty of detecting hard CWEs. In particular, we demonstrate an important
generalization challenge for the deployment of deep learning-based models. We
show that increasing the volume of training data may not further improve the
performance of deep learning models for vulnerability detection, but might be
useful to improve the generalization ability to unseen projects.
</p>
<p>We also identify hopeful future research directions. We demonstrate that
large language models (LLMs) are a promising research direction for ML-based
vulnerability detection, outperforming Graph Neural Networks (GNNs) with
code-structure features in our experiments. Moreover, developing source code
specific pre-training objectives is a promising research direction to improve
the vulnerability detection performance.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.08424">Long-term Forecasting with TiDE: Time-series Dense Encoder. (arXiv:2304.08424v3 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Das_A/0/1/0/all/0/1">Abhimanyu Das</a>, <a href="http://arxiv.org/find/stat/1/au:+Kong_W/0/1/0/all/0/1">Weihao Kong</a>, <a href="http://arxiv.org/find/stat/1/au:+Leach_A/0/1/0/all/0/1">Andrew Leach</a>, <a href="http://arxiv.org/find/stat/1/au:+Mathur_S/0/1/0/all/0/1">Shaan Mathur</a>, <a href="http://arxiv.org/find/stat/1/au:+Sen_R/0/1/0/all/0/1">Rajat Sen</a>, <a href="http://arxiv.org/find/stat/1/au:+Yu_R/0/1/0/all/0/1">Rose Yu</a></p>
<p>Recent work has shown that simple linear models can outperform several
Transformer based approaches in long term time-series forecasting. Motivated by
this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model,
Time-series Dense Encoder (TiDE), for long-term time-series forecasting that
enjoys the simplicity and speed of linear models while also being able to
handle covariates and non-linear dependencies. Theoretically, we prove that the
simplest linear analogue of our model can achieve near optimal error rate for
linear dynamical systems (LDS) under some assumptions. Empirically, we show
that our method can match or outperform prior approaches on popular long-term
time-series forecasting benchmarks while being 5-10x faster than the best
Transformer based model.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2304.13571">Quantum Natural Policy Gradients: Towards Sample-Efficient Reinforcement Learning. (arXiv:2304.13571v2 [quant-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Meyer_N/0/1/0/all/0/1">Nico Meyer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Scherer_D/0/1/0/all/0/1">Daniel D. Scherer</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Plinge_A/0/1/0/all/0/1">Axel Plinge</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Mutschler_C/0/1/0/all/0/1">Christopher Mutschler</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hartmann_M/0/1/0/all/0/1">Michael J. Hartmann</a></p>
<p>Reinforcement learning is a growing field in AI with a lot of potential.
Intelligent behavior is learned automatically through trial and error in
interaction with the environment. However, this learning process is often
costly. Using variational quantum circuits as function approximators
potentially can reduce this cost. In order to implement this, we propose the
quantum natural policy gradient (QNPG) algorithm -- a second-order
gradient-based routine that takes advantage of an efficient approximation of
the quantum Fisher information matrix. We experimentally demonstrate that QNPG
outperforms first-order based training on Contextual Bandits environments
regarding convergence speed and stability and moreover reduces the sample
complexity. Furthermore, we provide evidence for the practical feasibility of
our approach by training on a 12-qubit hardware device.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02041">Low-complexity subspace-descent over symmetric positive definite manifold. (arXiv:2305.02041v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Darmwal_Y/0/1/0/all/0/1">Yogesh Darmwal</a>, <a href="http://arxiv.org/find/stat/1/au:+Rajawat_K/0/1/0/all/0/1">Ketan Rajawat</a></p>
<p>This work puts forth low-complexity Riemannian subspace descent algorithms
for the minimization of functions over the symmetric positive definite (SPD)
manifold. Different from the existing Riemannian gradient descent variants, the
proposed approach utilizes carefully chosen subspaces that allow the update to
be written as a product of the Cholesky factor of the iterate and a sparse
matrix. The resulting updates avoid the costly matrix operations like matrix
exponentiation and dense matrix multiplication, which are generally required in
almost all other Riemannian optimization algorithms on SPD manifold. We further
identify a broad class of functions, arising in diverse applications, such as
kernel matrix learning, covariance estimation of Gaussian distributions,
maximum likelihood parameter estimation of elliptically contoured
distributions, and parameter estimation in Gaussian mixture model problems,
over which the Riemannian gradients can be calculated efficiently. The proposed
uni-directional and multi-directional Riemannian subspace descent variants
incur per-iteration complexities of $\mathcal{O}(n)$ and $\mathcal{O}(n^2)$
respectively, as compared to the $\mathcal{O}(n^3)$ or higher complexity
incurred by all existing Riemannian gradient descent variants. The superior
runtime and low per-iteration complexity of the proposed algorithms is also
demonstrated via numerical tests on large-scale covariance estimation problems.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.02396">Can Feature Engineering Help Quantum Machine Learning for Malware Detection?. (arXiv:2305.02396v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ran Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Eren_M/0/1/0/all/0/1">Maksim Eren</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1">Charles Nicholas</a></p>
<p>With the increasing number and sophistication of malware attacks, malware
detection systems based on machine learning (ML) grow in importance. At the
same time, many popular ML models used in malware classification are supervised
solutions. These supervised classifiers often do not generalize well to novel
malware. Therefore, they need to be re-trained frequently to detect new malware
specimens, which can be time-consuming. Our work addresses this problem in a
hybrid framework of theoretical Quantum ML, combined with feature selection
strategies to reduce the data size and malware classifier training time. The
preliminary results show that VQC with XGBoost selected features can get a
78.91% test accuracy on the simulator. The average accuracy for the model
trained using the features selected with XGBoost was 74% (+- 11.35%) on the IBM
5 qubits machines.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.03210">AttentionViz: A Global View of Transformer Attention. (arXiv:2305.03210v2 [cs.HC] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1">Catherine Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yida Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1">Aoyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Cynthia Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Viegas_F/0/1/0/all/0/1">Fernanda Vi&#xe9;gas</a>, <a href="http://arxiv.org/find/cs/1/au:+Wattenberg_M/0/1/0/all/0/1">Martin Wattenberg</a></p>
<p>Transformer models are revolutionizing machine learning, but their inner
workings remain mysterious. In this work, we present a new visualization
technique designed to help researchers understand the self-attention mechanism
in transformers that allows these models to learn rich, contextual
relationships between elements of a sequence. The main idea behind our method
is to visualize a joint embedding of the query and key vectors used by
transformer models to compute attention. Unlike previous attention
visualization techniques, our approach enables the analysis of global patterns
across multiple input sequences. We create an interactive visualization tool,
AttentionViz (demo: <a href="http://attentionviz.com">this http URL</a>), based on these joint query-key
embeddings, and use it to study attention mechanisms in both language and
vision transformers. We demonstrate the utility of our approach in improving
model understanding and offering new insights about query-key interactions
through several application scenarios and expert feedback.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.05738">DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on Wearable Medical Sensors. (arXiv:2305.05738v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chia-Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1">Niraj K. Jha</a></p>
<p>Modern advances in machine learning (ML) and wearable medical sensors (WMSs)
in edge devices have enabled ML-driven disease detection for smart healthcare.
Conventional ML-driven disease detection methods rely on customizing individual
models for each disease and its corresponding WMS data. However, such methods
lack adaptability to distribution shifts and new task classification classes.
Moreover, they need to be rearchitected and retrained from scratch for each new
disease. To address these challenges, we propose DOCTOR, a multi-disease
detection continual learning (CL) framework based on WMSs. It employs a
multi-headed deep neural network (DNN) and an exemplar-replay-style CL
algorithm. The CL algorithm enables the framework to continually learn new
missions where different data distributions, classification classes, and
disease detection tasks are introduced sequentially. It counteracts
catastrophic forgetting with a data preservation method and a synthetic data
generation (SDG) module. The data preservation method efficiently preserves the
most informative subset of training data from previous missions for replay. The
SDG module models the probability distribution of the real training data and
generates synthetic data for replays while retaining data privacy. The
multi-headed DNN enables DOCTOR to detect multiple diseases simultaneously
based on user WMS data. In various CL experiments, we demonstrate DOCTOR's
efficacy in maintaining high disease classification accuracy with a single DNN
model. DOCTOR achieves 1.43 times better average test accuracy, 1.25 times
better F1-score, and 0.41 higher backward transfer than the naive fine-tuning
framework, with a small model size and in complex CL scenarios.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2305.08992">The Brain Tumor Segmentation (BraTS) Challenge 2023: Local Synthesis of Healthy Brain Tissue via Inpainting. (arXiv:2305.08992v2 [eess.IV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Kofler_F/0/1/0/all/0/1">Florian Kofler</a>, <a href="http://arxiv.org/find/eess/1/au:+Meissen_F/0/1/0/all/0/1">Felix Meissen</a>, <a href="http://arxiv.org/find/eess/1/au:+Steinbauer_F/0/1/0/all/0/1">Felix Steinbauer</a>, <a href="http://arxiv.org/find/eess/1/au:+Graf_R/0/1/0/all/0/1">Robert Graf</a>, <a href="http://arxiv.org/find/eess/1/au:+Oswald_E/0/1/0/all/0/1">Eva Oswald</a>, <a href="http://arxiv.org/find/eess/1/au:+Rosa_E/0/1/0/all/0/1">Ezequiel de da Rosa</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Hongwei Bran Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Baid_U/0/1/0/all/0/1">Ujjwal Baid</a>, <a href="http://arxiv.org/find/eess/1/au:+Hoelzl_F/0/1/0/all/0/1">Florian Hoelzl</a>, <a href="http://arxiv.org/find/eess/1/au:+Turgut_O/0/1/0/all/0/1">Oezguen Turgut</a>, <a href="http://arxiv.org/find/eess/1/au:+Horvath_I/0/1/0/all/0/1">Izabela Horvath</a>, <a href="http://arxiv.org/find/eess/1/au:+Waldmannstetter_D/0/1/0/all/0/1">Diana Waldmannstetter</a>, <a href="http://arxiv.org/find/eess/1/au:+Bukas_C/0/1/0/all/0/1">Christina Bukas</a>, <a href="http://arxiv.org/find/eess/1/au:+Adewole_M/0/1/0/all/0/1">Maruf Adewole</a>, <a href="http://arxiv.org/find/eess/1/au:+Anwar_S/0/1/0/all/0/1">Syed Muhammad Anwar</a>, <a href="http://arxiv.org/find/eess/1/au:+Janas_A/0/1/0/all/0/1">Anastasia Janas</a>, <a href="http://arxiv.org/find/eess/1/au:+Kazerooni_A/0/1/0/all/0/1">Anahita Fathi Kazerooni</a>, <a href="http://arxiv.org/find/eess/1/au:+LaBella_D/0/1/0/all/0/1">Dominic LaBella</a>, <a href="http://arxiv.org/find/eess/1/au:+Moawad_A/0/1/0/all/0/1">Ahmed W Moawad</a>, <a href="http://arxiv.org/find/eess/1/au:+Farahani_K/0/1/0/all/0/1">Keyvan Farahani</a>, <a href="http://arxiv.org/find/eess/1/au:+Eddy_J/0/1/0/all/0/1">James Eddy</a>, <a href="http://arxiv.org/find/eess/1/au:+Bergquist_T/0/1/0/all/0/1">Timothy Bergquist</a>, <a href="http://arxiv.org/find/eess/1/au:+Chung_V/0/1/0/all/0/1">Verena Chung</a>, <a href="http://arxiv.org/find/eess/1/au:+Shinohara_R/0/1/0/all/0/1">Russell Takeshi Shinohara</a>, <a href="http://arxiv.org/find/eess/1/au:+Dako_F/0/1/0/all/0/1">Farouk Dako</a>, <a href="http://arxiv.org/find/eess/1/au:+Wiggins_W/0/1/0/all/0/1">Walter Wiggins</a>, <a href="http://arxiv.org/find/eess/1/au:+Reitman_Z/0/1/0/all/0/1">Zachary Reitman</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Chunhao Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xinyang Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Jiang_Z/0/1/0/all/0/1">Zhifan Jiang</a>, <a href="http://arxiv.org/find/eess/1/au:+Familiar_A/0/1/0/all/0/1">Ariana Familiar</a>, <a href="http://arxiv.org/find/eess/1/au:+Conte_G/0/1/0/all/0/1">Gian-Marco Conte</a>, <a href="http://arxiv.org/find/eess/1/au:+Johanson_E/0/1/0/all/0/1">Elaine Johanson</a>, <a href="http://arxiv.org/find/eess/1/au:+Meier_Z/0/1/0/all/0/1">Zeke Meier</a>, <a href="http://arxiv.org/find/eess/1/au:+Davatzikos_C/0/1/0/all/0/1">Christos Davatzikos</a>, <a href="http://arxiv.org/find/eess/1/au:+Freymann_J/0/1/0/all/0/1">John Freymann</a>, <a href="http://arxiv.org/find/eess/1/au:+Kirby_J/0/1/0/all/0/1">Justin Kirby</a>, <a href="http://arxiv.org/find/eess/1/au:+Bilello_M/0/1/0/all/0/1">Michel Bilello</a>, <a href="http://arxiv.org/find/eess/1/au:+Fathallah_Shaykh_H/0/1/0/all/0/1">Hassan M Fathallah-Shaykh</a>, <a href="http://arxiv.org/find/eess/1/au:+Wiest_R/0/1/0/all/0/1">Roland Wiest</a>, <a href="http://arxiv.org/find/eess/1/au:+Kirschke_J/0/1/0/all/0/1">Jan Kirschke</a>, <a href="http://arxiv.org/find/eess/1/au:+Colen_R/0/1/0/all/0/1">Rivka R Colen</a>, <a href="http://arxiv.org/find/eess/1/au:+Kotrotsou_A/0/1/0/all/0/1">Aikaterini Kotrotsou</a>, <a href="http://arxiv.org/find/eess/1/au:+Lamontagne_P/0/1/0/all/0/1">Pamela Lamontagne</a>, <a href="http://arxiv.org/find/eess/1/au:+Marcus_D/0/1/0/all/0/1">Daniel Marcus</a>, <a href="http://arxiv.org/find/eess/1/au:+Milchenko_M/0/1/0/all/0/1">Mikhail Milchenko</a>, <a href="http://arxiv.org/find/eess/1/au:+Nazeri_A/0/1/0/all/0/1">Arash Nazeri</a>, <a href="http://arxiv.org/find/eess/1/au:+Weber_M/0/1/0/all/0/1">Marc-Andr&#xe9; Weber</a>, et al. (20 additional authors not shown)</p>
<p>A myriad of algorithms for the automatic analysis of brain MR images is
available to support clinicians in their decision-making. For brain tumor
patients, the image acquisition time series typically starts with a scan that
is already pathological. This poses problems, as many algorithms are designed
to analyze healthy brains and provide no guarantees for images featuring
lesions. Examples include but are not limited to algorithms for brain anatomy
parcellation, tissue segmentation, and brain extraction. To solve this dilemma,
we introduce the BraTS 2023 inpainting challenge. Here, the participants' task
is to explore inpainting techniques to synthesize healthy brain scans from
lesioned ones. The following manuscript contains the task formulation, dataset,
and submission procedure. Later it will be updated to summarize the findings of
the challenge. The challenge is organized as part of the BraTS 2023 challenge
hosted at the MICCAI 2023 conference in Vancouver, Canada.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.01951">GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction. (arXiv:2306.01951v4 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Amit Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_J/0/1/0/all/0/1">Juan Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Elshocht_O/0/1/0/all/0/1">Olivier Elshocht</a>, <a href="http://arxiv.org/find/cs/1/au:+Smeets_J/0/1/0/all/0/1">Jeroen Smeets</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a></p>
<p>Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes
within graphs, finding applications in network security, fraud detection,
social media spam detection, and various other domains. A common method for GAD
is Graph Auto-Encoders (GAEs), which encode graph data into node
representations and identify anomalies by assessing the reconstruction quality
of the graphs based on these representations. However, existing GAE models are
primarily optimized for direct link reconstruction, resulting in nodes
connected in the graph being clustered in the latent space. As a result, they
excel at detecting cluster-type structural anomalies but struggle with more
complex structural anomalies that do not conform to clusters. To address this
limitation, we propose a novel solution called GAD-NR, a new variant of GAE
that incorporates neighborhood reconstruction for graph anomaly detection.
GAD-NR aims to reconstruct the entire neighborhood of a node, encompassing the
local structure, self-attributes, and neighbor attributes, based on the
corresponding node representation. By comparing the neighborhood reconstruction
loss between anomalous nodes and normal nodes, GAD-NR can effectively detect
any anomalies. Extensive experimentation conducted on six real-world datasets
validates the effectiveness of GAD-NR, showcasing significant improvements (by
up to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NR
is openly available. Importantly, the comparative analysis reveals that the
existing methods perform well only in detecting one or two types of anomalies
out of the three types studied. In contrast, GAD-NR excels at detecting all
three types of anomalies across the datasets, demonstrating its comprehensive
anomaly detection capabilities.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09417">Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis. (arXiv:2306.09417v3 [eess.AS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/eess/1/au:+Mehta_S/0/1/0/all/0/1">Shivam Mehta</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Siyang Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Alexanderson_S/0/1/0/all/0/1">Simon Alexanderson</a>, <a href="http://arxiv.org/find/eess/1/au:+Beskow_J/0/1/0/all/0/1">Jonas Beskow</a>, <a href="http://arxiv.org/find/eess/1/au:+Szekely_E/0/1/0/all/0/1">&#xc9;va Sz&#xe9;kely</a>, <a href="http://arxiv.org/find/eess/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a></p>
<p>With read-aloud speech synthesis achieving high naturalness scores, there is
a growing research interest in synthesising spontaneous speech. However, human
spontaneous face-to-face conversation has both spoken and non-verbal aspects
(here, co-speech gestures). Only recently has research begun to explore the
benefits of jointly synthesising these two modalities in a single system. The
previous state of the art used non-probabilistic methods, which fail to capture
the variability of human speech and motion, and risk producing oversmoothing
artefacts and sub-optimal synthesis quality. We present the first
diffusion-based probabilistic model, called Diff-TTSG, that jointly learns to
synthesise speech and gestures together. Our method can be trained on small
datasets from scratch. Furthermore, we describe a set of careful uni- and
multi-modal subjective tests for evaluating integrated speech and gesture
synthesis systems, and use them to validate our proposed approach. Please see
https://shivammehta25.github.io/Diff-TTSG/ for video examples, data, and code.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2306.09633">The False Dawn: Reevaluating Google&#x27;s Reinforcement Learning for Chip Macro Placement. (arXiv:2306.09633v5 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1">Igor L. Markov</a></p>
<p>Reinforcement learning (RL) for physical design of silicon chips in a Google
2021 Nature paper stirred controversy due to poorly documented claims that
raised eyebrows and attracted critical media coverage. The Nature paper
withheld most inputs needed to produce reported results and some critical steps
in the methodology. But two separate evaluations filled in the gaps and
demonstrated that Google RL lags behind human designers, behind a well-known
algorithm (Simulated Annealing), and also behind generally-available commercial
software, while taking longer to run. Crosschecked data show that the integrity
of the Nature paper is substantially undermined owing to errors in conduct,
analysis and reporting. Before publishing, Google rebuffed internal allegations
of fraud.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.00365">Understanding recent deep-learning techniques for identifying collective variables of molecular dynamics. (arXiv:2307.00365v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutte_C/0/1/0/all/0/1">Christof Sch&#xfc;tte</a></p>
<p>High-dimensional metastable molecular system can often be characterised by a
few features of the system, i.e. collective variables (CVs). Thanks to the
rapid advance in the area of machine learning and deep learning, various deep
learning-based CV identification techniques have been developed in recent
years, allowing accurate modelling and efficient simulation of complex
molecular systems. In this paper, we look at two different categories of deep
learning-based approaches for finding CVs, either by computing leading
eigenfunctions of infinitesimal generator or transfer operator associated to
the underlying dynamics, or by learning an autoencoder via minimisation of
reconstruction error. We present a concise overview of the mathematics behind
these two approaches and conduct a comparative numerical study of these two
approaches on illustrative examples.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03364">Distilled Pruning: Using Synthetic Data to Win the Lottery. (arXiv:2307.03364v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+McDermott_L/0/1/0/all/0/1">Luke McDermott</a>, <a href="http://arxiv.org/find/cs/1/au:+Cummings_D/0/1/0/all/0/1">Daniel Cummings</a></p>
<p>This work introduces a novel approach to pruning deep learning models by
using distilled data. Unlike conventional strategies which primarily focus on
architectural or algorithmic optimization, our method reconsiders the role of
data in these scenarios. Distilled datasets capture essential patterns from
larger datasets, and we demonstrate how to leverage this capability to enable a
computationally efficient pruning process. Our approach can find sparse,
trainable subnetworks (a.k.a. Lottery Tickets) up to 5x faster than Iterative
Magnitude Pruning at comparable sparsity on CIFAR-10. The experimental results
highlight the potential of using distilled data for resource-efficient neural
network pruning, model compression, and neural architecture search.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.03759">A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection. (arXiv:2307.03759v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1">Ming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Koh_H/0/1/0/all/0/1">Huan Yee Koh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1">Qingsong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zambon_D/0/1/0/all/0/1">Daniele Zambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Alippi_C/0/1/0/all/0/1">Cesare Alippi</a>, <a href="http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1">Geoffrey I. Webb</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shirui Pan</a></p>
<p>Time series are the primary data type used to record dynamic system
measurements and generated in great volume by both physical sensors and online
processes (virtual sensors). Time series analytics is therefore crucial to
unlocking the wealth of information implicit in available data. With the recent
advancements in graph neural networks (GNNs), there has been a surge in
GNN-based approaches for time series analysis. These approaches can explicitly
model inter-temporal and inter-variable relationships, which traditional and
other deep neural network-based methods struggle to do. In this survey, we
provide a comprehensive review of graph neural networks for time series
analysis (GNN4TS), encompassing four fundamental dimensions: forecasting,
classification, anomaly detection, and imputation. Our aim is to guide
designers and practitioners to understand, build applications, and advance
research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy
of GNN4TS. Then, we present and discuss representative research works and
introduce mainstream applications of GNN4TS. A comprehensive discussion of
potential future research directions completes the survey. This survey, for the
first time, brings together a vast array of knowledge on GNN-based time series
research, highlighting foundations, practical applications, and opportunities
of graph neural networks for time series analysis.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06713">Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models. (arXiv:2307.06713v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Estienne_L/0/1/0/all/0/1">Lautaro Estienne</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_L/0/1/0/all/0/1">Luciana Ferrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Vera_M/0/1/0/all/0/1">Mat&#xed;as Vera</a>, <a href="http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1">Pablo Piantanida</a></p>
<p>A wide variety of natural language tasks are currently being addressed with
large-scale language models (LLMs). These models are usually trained with a
very large amount of unsupervised text data and adapted to perform a downstream
natural language task using methods like fine-tuning, calibration or in-context
learning. In this work, we propose an approach to adapt the prior class
distribution to perform text classification tasks without the need for labelled
samples and only few in-domain sample queries. The proposed approach treats the
LLM as a black box, adding a stage where the model posteriors are calibrated to
the task. Results show that these methods outperform the un-adapted model for
different number of training shots in the prompt and a previous approach were
calibration is performed without using any adaptation data.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.06775">A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Feldman_J/0/1/0/all/0/1">Jonathan Feldman</a></p>
<p>Over the last decade, there has been a vast increase in eating disorder
diagnoses and eating disorder-attributed deaths, reaching their zenith during
the Covid-19 pandemic. This immense growth derived in part from the stressors
of the pandemic but also from increased exposure to social media, which is rife
with content that promotes eating disorders. This study aimed to create a
multimodal deep learning model that can determine if a given social media post
promotes eating disorders based on a combination of visual and textual data. A
labeled dataset of Tweets was collected from Twitter, upon which twelve deep
learning models were trained and tested. Based on model performance, the most
effective deep learning model was the multimodal fusion of the RoBERTa natural
language processing model and the MaxViT image classification model, attaining
accuracy and F1 scores of 95.9% and 0.959, respectively. The RoBERTa and MaxViT
fusion model, deployed to classify an unlabeled dataset of posts from the
social media sites Tumblr and Reddit, generated results akin to those of
previous research studies that did not employ artificial intelligence-based
techniques, indicating that deep learning models can develop insights congruent
to those of researchers. Additionally, the model was used to conduct a
timeseries analysis of yet unseen Tweets from eight Twitter hashtags,
uncovering that, since 2014, the relative abundance of content that promotes
eating disorders has decreased drastically within those communities. Despite
this reduction, by 2018, content that promotes eating disorders had either
stopped declining or increased in ampleness anew on these hashtags.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08131">INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks. (arXiv:2307.08131v2 [cs.SI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Tiukhova_E/0/1/0/all/0/1">Elena Tiukhova</a>, <a href="http://arxiv.org/find/cs/1/au:+Penaloza_E/0/1/0/all/0/1">Emiliano Penaloza</a>, <a href="http://arxiv.org/find/cs/1/au:+Oskarsdottir_M/0/1/0/all/0/1">Mar&#xed;a &#xd3;skarsd&#xf3;ttir</a>, <a href="http://arxiv.org/find/cs/1/au:+Baesens_B/0/1/0/all/0/1">Bart Baesens</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoeck_M/0/1/0/all/0/1">Monique Snoeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Bravo_C/0/1/0/all/0/1">Cristi&#xe1;n Bravo</a></p>
<p>Leveraging network information for predictive modeling has become widespread
in many domains. Within the realm of referral and targeted marketing,
influencer detection stands out as an area that could greatly benefit from the
incorporation of dynamic network representation due to the ongoing development
of customer-brand relationships. To elaborate this idea, we introduce
INFLECT-DGNN, a new framework for INFLuencer prEdiCTion with Dynamic Graph
Neural Networks that combines Graph Neural Networks (GNN) and Recurrent Neural
Networks (RNN) with weighted loss functions, the Synthetic Minority
Oversampling TEchnique (SMOTE) adapted for graph data, and a carefully crafted
rolling-window strategy. To evaluate predictive performance, we utilize a
unique corporate data set with networks of three cities and derive a
profit-driven evaluation methodology for influencer prediction. Our results
show how using RNN to encode temporal attributes alongside GNNs significantly
improves predictive performance. We compare the results of various models to
demonstrate the importance of capturing graph representation, temporal
dependencies, and using a profit-driven methodology for evaluation.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08621">Retentive Network: A Successor to Transformer for Large Language Models. (arXiv:2307.08621v4 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yutao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1">Li Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shaohan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shuming Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yuqing Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jilong Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianyong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a></p>
<p>In this work, we propose Retentive Network (RetNet) as a foundation
architecture for large language models, simultaneously achieving training
parallelism, low-cost inference, and good performance. We theoretically derive
the connection between recurrence and attention. Then we propose the retention
mechanism for sequence modeling, which supports three computation paradigms,
i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel
representation allows for training parallelism. The recurrent representation
enables low-cost $O(1)$ inference, which improves decoding throughput, latency,
and GPU memory without sacrificing performance. The chunkwise recurrent
representation facilitates efficient long-sequence modeling with linear
complexity, where each chunk is encoded parallelly while recurrently
summarizing the chunks. Experimental results on language modeling show that
RetNet achieves favorable scaling results, parallel training, low-cost
deployment, and efficient inference. The intriguing properties make RetNet a
strong successor to Transformer for large language models. Code will be
available at https://aka.ms/retnet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.08873">An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient. (arXiv:2307.08873v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yudong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guiliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1">Pascal Poupart</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yangchen Pan</a></p>
<p>Restricting the variance of a policy's return is a popular choice in
risk-averse Reinforcement Learning (RL) due to its clear mathematical
definition and easy interpretability. Traditional methods directly restrict the
total return variance. Recent methods restrict the per-step reward variance as
a proxy. We thoroughly examine the limitations of these variance-based methods,
such as sensitivity to numerical scale and hindering of policy learning, and
propose to use an alternative risk measure, Gini deviation, as a substitute. We
study various properties of this new risk measure and derive a policy gradient
algorithm to minimize it. Empirical evaluation in domains where risk-aversion
can be clearly defined, shows that our algorithm can mitigate the limitations
of variance-based risk measures and achieves high return with low risk in terms
of variance and Gini deviation when others fail to learn a reasonable policy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.10763">Actor-agnostic Multi-label Action Recognition with Multi-modal Query. (arXiv:2307.10763v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Mondal_A/0/1/0/all/0/1">Anindya Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1">Sauradip Nag</a>, <a href="http://arxiv.org/find/cs/1/au:+Prada_J/0/1/0/all/0/1">Joaquin M Prada</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiatian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_A/0/1/0/all/0/1">Anjan Dutta</a></p>
<p>Existing action recognition methods are typically actor-specific due to the
intrinsic topological and apparent differences among the actors. This requires
actor-specific pose estimation (e.g., humans vs. animals), leading to
cumbersome model design complexity and high maintenance costs. Moreover, they
often focus on learning the visual modality alone and single-label
classification whilst neglecting other available information sources (e.g.,
class name text) and the concurrent occurrence of multiple actions. To overcome
these limitations, we propose a new approach called 'actor-agnostic multi-modal
multi-label action recognition,' which offers a unified solution for various
types of actors, including humans and animals. We further formulate a novel
Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object
detection framework (e.g., DETR), characterized by leveraging visual and
textual modalities to represent the action classes better. The elimination of
actor-specific model designs is a key advantage, as it removes the need for
actor pose estimation altogether. Extensive experiments on five publicly
available benchmarks show that our MSQNet consistently outperforms the prior
arts of actor-specific alternatives on human and animal single- and multi-label
action recognition tasks by up to 50%. Code will be released at
https://github.com/mondalanindya/MSQNet.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12306">Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zheyuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shukla_K/0/1/0/all/0/1">Khemraj Shukla</a>, <a href="http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1">George Em Karniadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1">Kenji Kawaguchi</a></p>
<p>The curse-of-dimensionality (CoD) taxes computational resources heavily with
exponentially increasing computational cost as the dimension increases. This
poses great challenges in solving high-dimensional PDEs as Richard Bellman
first pointed out over 60 years ago. While there has been some recent success
in solving numerically partial differential equations (PDEs) in high
dimensions, such computations are prohibitively expensive, and true scaling of
general nonlinear PDEs to high dimensions has never been achieved. In this
paper, we develop a new method of scaling up physics-informed neural networks
(PINNs) to solve arbitrary high-dimensional PDEs. The new method, called
Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs
into pieces corresponding to different dimensions and samples randomly a subset
of these dimensional pieces in each iteration of training PINNs. We
theoretically prove the convergence guarantee and other desired properties of
the proposed method. We experimentally demonstrate that the proposed method
allows us to solve many notoriously hard high-dimensional PDEs, including the
Hamilton-Jacobi-Bellman (HJB) and the Schr\"{o}dinger equations in thousands of
dimensions very fast on a single GPU using the PINNs mesh-free approach. For
instance, we solve nontrivial nonlinear PDEs (one HJB equation and one
Black-Scholes equation) in 100,000 dimensions in 6 hours on a single GPU using
SDGD with PINNs. Since SDGD is a general training methodology of PINNs, SDGD
can be applied to any current and future variants of PINNs to scale them up for
arbitrary high-dimensional PDEs.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12449">WEPRO: Weight Prediction for Efficient Optimization of Hybrid Quantum-Classical Algorithms. (arXiv:2307.12449v2 [quant-ph] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/quant-ph/1/au:+Kundu_S/0/1/0/all/0/1">Satwik Kundu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kundu_D/0/1/0/all/0/1">Debarshi Kundu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ghosh_S/0/1/0/all/0/1">Swaroop Ghosh</a></p>
<p>The exponential run time of quantum simulators on classical machines and long
queue depths and high costs of real quantum devices present significant
challenges in the effective training of Variational Quantum Algorithms (VQAs)
like Quantum Neural Networks (QNNs), Variational Quantum Eigensolver (VQE) and
Quantum Approximate Optimization Algorithm (QAOA). To address these
limitations, we propose a new approach, WEPRO (Weight Prediction), which
accelerates the convergence of VQAs by exploiting regular trends in the
parameter weights. We introduce two techniques for optimal prediction
performance namely, Naive Prediction (NaP) and Adaptive Prediction (AdaP).
Through extensive experimentation and training of multiple QNN models on
various datasets, we demonstrate that WEPRO offers a speedup of approximately
$2.25\times$ compared to standard training methods, while also providing
improved accuracy (up to $2.3\%$ higher) and loss (up to $6.1\%$ lower) with
low storage and computational overheads. We also evaluate WEPRO's effectiveness
in VQE for molecular ground-state energy estimation and in QAOA for graph
MaxCut. Our results show that WEPRO leads to speed improvements of up to
$3.1\times$ for VQE and $2.91\times$ for QAOA, compared to traditional
optimization techniques, while using up to $3.3\times$ less number of shots
(i.e., repeated circuit executions) per training iteration.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.12943">Efficiently Sampling the PSD Cone with the Metric Dikin Walk. (arXiv:2307.12943v2 [cs.DS] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kook_Y/0/1/0/all/0/1">Yunbum Kook</a>, <a href="http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1">Santosh S. Vempala</a></p>
<p>Semi-definite programs represent a frontier of efficient computation. While
there has been much progress on semi-definite optimization, with moderate-sized
instances currently solvable in practice by the interior-point method, the
basic problem of sampling semi-definite solutions remains a formidable
challenge. The direct application of known polynomial-time algorithms for
sampling general convex bodies to semi-definite sampling leads to a
prohibitively high running time. In addition, known general methods require an
expensive rounding phase as pre-processing. Here we analyze the Dikin walk, by
first adapting it to general metrics, then devising suitable metrics for the
PSD cone with affine constraints. The resulting mixing time and per-step
complexity are considerably smaller, and by an appropriate choice of the
metric, the dependence on the number of constraints can be made
polylogarithmic. We introduce a refined notion of self-concordant matrix
functions and give rules for combining different metrics. Along the way, we
further develop the theory of interior-point methods for sampling.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.14565">Auto-Tables: Synthesizing Multi-Step Transformations to Relationalize Tables without Using Examples. (arXiv:2307.14565v2 [cs.DB] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yeye He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Cong Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1">Surajit Chaudhuri</a></p>
<p>Relational tables, where each row corresponds to an entity and each column
corresponds to an attribute, have been the standard for tables in relational
databases. However, such a standard cannot be taken for granted when dealing
with tables "in the wild". Our survey of real spreadsheet-tables and web-tables
shows that over 30% of such tables do not conform to the relational standard,
for which complex table-restructuring transformations are needed before these
tables can be queried easily using SQL-based analytics tools. Unfortunately,
the required transformations are non-trivial to program, which has become a
substantial pain point for technical and non-technical users alike, as
evidenced by large numbers of forum questions in places like StackOverflow and
Excel/Power-BI/Tableau forums.
</p>
<p>We develop an Auto-Tables system that can automatically synthesize pipelines
with multi-step transformations (in Python or other languages), to transform
non-relational tables into standard relational forms for downstream analytics,
obviating the need for users to manually program transformations. We compile an
extensive benchmark for this new task, by collecting 244 real test cases from
user spreadsheets and online forums. Our evaluation suggests that Auto-Tables
can successfully synthesize transformations for over 70% of test cases at
interactive speeds, without requiring any input from users, making this an
effective tool for both technical and non-technical users to prepare data for
analytics.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2307.16186">ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning. (arXiv:2307.16186v2 [cs.MA] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1">Rongye Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_P/0/1/0/all/0/1">Pu Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yongkai Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenjun Wu</a></p>
<p>Multi-agent reinforcement learning (MARL) has achieved promising results in
recent years. However, most existing reinforcement learning methods require a
large amount of data for model training. In addition, data-efficient
reinforcement learning requires the construction of strong inductive biases,
which are ignored in the current MARL approaches. Inspired by the symmetry
phenomenon in multi-agent systems, this paper proposes a framework for
exploiting prior knowledge by integrating data augmentation and a well-designed
consistency loss into the existing MARL methods. In addition, the proposed
framework is model-agnostic and can be applied to most of the current MARL
algorithms. Experimental tests on multiple challenging tasks demonstrate the
effectiveness of the proposed framework. Moreover, the proposed framework is
applied to a physical multi-robot testbed to show its superiority.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.00824">An Exact Kernel Equivalence for Finite Classification Models. (arXiv:2308.00824v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Bell_B/0/1/0/all/0/1">Brian Bell</a>, <a href="http://arxiv.org/find/cs/1/au:+Geyer_M/0/1/0/all/0/1">Michael Geyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Glickenstein_D/0/1/0/all/0/1">David Glickenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_A/0/1/0/all/0/1">Amanda Fernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Moore_J/0/1/0/all/0/1">Juston Moore</a></p>
<p>We explore the equivalence between neural networks and kernel methods by
deriving the first exact representation of any finite-size parametric
classification model trained with gradient descent as a kernel machine. We
compare our exact representation to the well-known Neural Tangent Kernel (NTK)
and discuss approximation error relative to the NTK and other non-exact path
kernel formulations. We experimentally demonstrate that the kernel can be
computed for realistic networks up to machine precision. We use this exact
kernel to show that our theoretical contribution can provide useful insights
into the predictions made by neural networks, particularly the way in which
they generalize.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01011">Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach. (arXiv:2308.01011v3 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chunwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoxu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lijun Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuankai Wu</a></p>
<p>Time series analysis is a fundamental task in various application domains,
and deep learning approaches have demonstrated remarkable performance in this
area. However, many real-world time series data exhibit significant periodic or
quasi-periodic dynamics that are often not adequately captured by existing deep
learning-based solutions. This results in an incomplete representation of the
underlying dynamic behaviors of interest. To address this gap, we propose an
unsupervised method called Floss that automatically regularizes learned
representations in the frequency domain. The Floss method first automatically
detects major periodicities from the time series. It then employs periodic
shift and spectral density similarity measures to learn meaningful
representations with periodic consistency. In addition, Floss can be easily
incorporated into both supervised, semi-supervised, and unsupervised learning
frameworks. We conduct extensive experiments on common time series
classification, forecasting, and anomaly detection tasks to demonstrate the
effectiveness of Floss. We incorporate Floss into several representative deep
learning solutions to justify our design choices and demonstrate that it is
capable of automatically discovering periodic dynamics and improving
state-of-the-art deep learning models.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01097">Spatio-Temporal Branching for Motion Prediction using Motion Increments. (arXiv:2308.01097v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiexin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yujie Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiang_W/0/1/0/all/0/1">Wenwen Qiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ba_Y/0/1/0/all/0/1">Ying Ba</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_B/0/1/0/all/0/1">Bing Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a></p>
<p>Human motion prediction (HMP) has emerged as a popular research topic due to
its diverse applications, but it remains a challenging task due to the
stochastic and aperiodic nature of future poses. Traditional methods rely on
hand-crafted features and machine learning techniques, which often struggle to
model the complex dynamics of human motion. Recent deep learning-based methods
have achieved success by learning spatio-temporal representations of motion,
but these models often overlook the reliability of motion data. Additionally,
the temporal and spatial dependencies of skeleton nodes are distinct. The
temporal relationship captures motion information over time, while the spatial
relationship describes body structure and the relationships between different
nodes. In this paper, we propose a novel spatio-temporal branching network
using incremental information for HMP, which decouples the learning of
temporal-domain and spatial-domain features, extracts more motion information,
and achieves complementary cross-domain knowledge learning through knowledge
distillation. Our approach effectively reduces noise interference and provides
more expressive information for characterizing motion by separately extracting
temporal and spatial features. We evaluate our approach on standard HMP
benchmarks and outperform state-of-the-art methods in terms of prediction
accuracy.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.01621">A Novel Convolutional Neural Network Architecture with a Continuous Symmetry. (arXiv:2308.01621v2 [cs.CV] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1">Hang Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_B/0/1/0/all/0/1">Bing Bai</a></p>
<p>This paper introduces a new Convolutional Neural Network (ConvNet)
architecture inspired by a class of partial differential equations (PDEs)
called quasi-linear hyperbolic systems. With comparable performance on the
image classification task, it allows for the modification of the weights via a
continuous group of symmetry. This is a significant shift from traditional
models where the architecture and weights are essentially fixed. We wish to
promote the (internal) symmetry as a new desirable property for a neural
network, and to draw attention to the PDE perspective in analyzing and
interpreting ConvNets in the broader Deep Learning community.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02182">AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification. (arXiv:2308.02182v2 [cs.NI] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Malekghaini_N/0/1/0/all/0/1">Navid Malekghaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Akbari_E/0/1/0/all/0/1">Elham Akbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Salahuddin_M/0/1/0/all/0/1">Mohammad A. Salahuddin</a>, <a href="http://arxiv.org/find/cs/1/au:+Limam_N/0/1/0/all/0/1">Noura Limam</a>, <a href="http://arxiv.org/find/cs/1/au:+Boutaba_R/0/1/0/all/0/1">Raouf Boutaba</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_B/0/1/0/all/0/1">Bertrand Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moteau_S/0/1/0/all/0/1">Stephanie Moteau</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuffin_S/0/1/0/all/0/1">Stephane Tuffin</a></p>
<p>Deep learning (DL) has been successfully applied to encrypted network traffic
classification in experimental settings. However, in production use, it has
been shown that a DL classifier's performance inevitably decays over time.
Re-training the model on newer datasets has been shown to only partially
improve its performance. Manually re-tuning the model architecture to meet the
performance expectations on newer datasets is time-consuming and requires
domain expertise. We propose AutoML4ETC, a novel tool to automatically design
efficient and high-performing neural architectures for encrypted traffic
classification. We define a novel, powerful search space tailored specifically
for the near real-time classification of encrypted traffic using packet header
bytes. We show that with different search strategies over our search space,
AutoML4ETC generates neural architectures that outperform the state-of-the-art
encrypted traffic classifiers on several datasets, including public benchmark
datasets and real-world TLS and QUIC traffic collected from the Orange mobile
network. In addition to being more accurate, AutoML4ETC's architectures are
significantly more efficient and lighter in terms of the number of parameters.
Finally, we make AutoML4ETC publicly available for future research.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.02582">Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting. (arXiv:2308.02582v3 [cs.CL] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1">Aseem Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhaisaheb_S/0/1/0/all/0/1">Shabbirhussain Bhaisaheb</a>, <a href="http://arxiv.org/find/cs/1/au:+Nigam_H/0/1/0/all/0/1">Harshit Nigam</a>, <a href="http://arxiv.org/find/cs/1/au:+Patwardhan_M/0/1/0/all/0/1">Manasi Patwardhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vig_L/0/1/0/all/0/1">Lovekesh Vig</a>, <a href="http://arxiv.org/find/cs/1/au:+Shroff_G/0/1/0/all/0/1">Gautam Shroff</a></p>
<p>Cross-domain and cross-compositional generalization of Text-to-SQL semantic
parsing is a challenging task. Existing Large Language Model (LLM) based
solutions rely on inference-time retrieval of few-shot exemplars from the
training set to synthesize a run-time prompt for each Natural Language (NL)
test query. In contrast, we devise an algorithm which performs offline sampling
of a minimal set-of few-shots from the training data, with complete coverage of
SQL clauses, operators and functions, and maximal domain coverage within the
allowed token length. This allows for synthesis of a fixed Generic Prompt (GP),
with a diverse set-of exemplars common across NL test queries, avoiding
expensive test time exemplar retrieval. We further auto-adapt the GP to the
target database domain (DA-GP), to better handle cross-domain generalization;
followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle
cross-compositional generalization. The synthesis of LTMP-DA-GP is an offline
task, to be performed one-time per new database with minimal human
intervention. Our approach demonstrates superior performance on the KaggleDBQA
dataset, designed to evaluate generalizability for the Text-to-SQL task. We
further showcase consistent performance improvement of LTMP-DA-GP over GP,
across LLMs and databases of KaggleDBQA, highlighting the efficacy and model
agnostic benefits of our prompt based adapt and decompose approach.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03210">Time-Parameterized Convolutional Neural Networks for Irregularly Sampled Time Series. (arXiv:2308.03210v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Kosma_C/0/1/0/all/0/1">Chrysoula Kosma</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolentzos_G/0/1/0/all/0/1">Giannis Nikolentzos</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1">Michalis Vazirgiannis</a></p>
<p>Irregularly sampled multivariate time series are ubiquitous in several
application domains, leading to sparse, not fully-observed and non-aligned
observations across different variables. Standard sequential neural network
architectures, such as recurrent neural networks (RNNs) and convolutional
neural networks (CNNs), consider regular spacing between observation times,
posing significant challenges to irregular time series modeling. While most of
the proposed architectures incorporate RNN variants to handle irregular time
intervals, convolutional neural networks have not been adequately studied in
the irregular sampling setting. In this paper, we parameterize convolutional
layers by employing time-explicitly initialized kernels. Such general functions
of time enhance the learning process of continuous-time hidden dynamics and can
be efficiently incorporated into convolutional kernel weights. We, thus,
propose the time-parameterized convolutional neural network (TPCNN), which
shares similar properties with vanilla convolutions but is carefully designed
for irregularly sampled time series. We evaluate TPCNN on both interpolation
and classification tasks involving real-world irregularly sampled multivariate
time series datasets. Our experimental results indicate the competitive
performance of the proposed TPCNN model which is also significantly more
efficient than other state-of-the-art methods. At the same time, the proposed
architecture allows the interpretability of the input series by leveraging the
combination of learnable time functions that improve the network performance in
subsequent tasks and expedite the inaugural application of convolutions in this
field.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03443">Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces. (arXiv:2308.03443v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Shimizu_T/0/1/0/all/0/1">Tatsuhiro Shimizu</a>, <a href="http://arxiv.org/find/stat/1/au:+Forastiere_L/0/1/0/all/0/1">Laura Forastiere</a></p>
<p>We study Off-Policy Evaluation (OPE) in contextual bandit settings with large
action spaces. The benchmark estimators suffer from severe bias and variance
tradeoffs. Parametric approaches suffer from bias due to difficulty specifying
the correct model, whereas ones with importance weight suffer from variance. To
overcome these limitations, Marginalized Inverse Propensity Scoring (MIPS) was
proposed to mitigate the estimator's variance via embeddings of an action. To
make the estimator more accurate, we propose the doubly robust estimator of
MIPS called the Marginalized Doubly Robust (MDR) estimator. Theoretical
analysis shows that the proposed estimator is unbiased under weaker assumptions
than MIPS while maintaining variance reduction against IPS, which was the main
advantage of MIPS. The empirical experiment verifies the supremacy of MDR
against existing estimators.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03999">Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning. (arXiv:2308.03999v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Dalal_A/0/1/0/all/0/1">Abhilekha Dalal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_M/0/1/0/all/0/1">Md Kamruzzaman Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Barua_A/0/1/0/all/0/1">Adrita Barua</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasserman_E/0/1/0/all/0/1">Eugene Vasserman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hitzler_P/0/1/0/all/0/1">Pascal Hitzler</a></p>
<p>A major challenge in Explainable AI is in correctly interpreting activations
of hidden neurons: accurate interpretations would provide insights into the
question of what a deep learning system has internally detected as relevant on
the input, demystifying the otherwise black-box character of deep learning
systems. The state of the art indicates that hidden node activations can, in
some cases, be interpretable in a way that makes sense to humans, but
systematic automated methods that would be able to hypothesize and verify
interpretations of hidden neuron activations are underexplored. In this paper,
we provide such a method and demonstrate that it provides meaningful
interpretations. Our approach is based on using large-scale background
knowledge approximately 2 million classes curated from the Wikipedia concept
hierarchy together with a symbolic reasoning approach called Concept Induction
based on description logics, originally developed for applications in the
Semantic Web field. Our results show that we can automatically attach
meaningful labels from the background knowledge to individual neurons in the
dense layer of a Convolutional Neural Network through a hypothesis and
verification process.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04365">SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v2 [stat.ML] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/stat/1/au:+Vowels_M/0/1/0/all/0/1">Matthew J. Vowels</a></p>
<p>Causal inference is a crucial goal of science, enabling researchers to arrive
at meaningful conclusions regarding the predictions of hypothetical
interventions using observational data. Path models, Structural Equation Models
(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to
unambiguously specify assumptions regarding the causal structure underlying a
phenomenon. Unlike DAGs, which make very few assumptions about the functional
and parametric form, SEM assumes linearity. This can result in functional
misspecification which prevents researchers from undertaking reliable effect
size estimation. In contrast, we propose Super Learner Equation Modeling, a
path modeling technique integrating machine learning Super Learner ensembles.
We empirically demonstrate its ability to provide consistent and unbiased
estimates of causal effects, its competitive performance for linear models when
compared with SEM, and highlight its superiority over SEM when dealing with
non-linear relationships. We provide open-source code, and a tutorial notebook
with example usage, accentuating the easy-to-use nature of the method.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04396">Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining. (arXiv:2308.04396v2 [cs.LG] UPDATED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Blatt_J/0/1/0/all/0/1">Jonas Blatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Delfmann_P/0/1/0/all/0/1">Patrick Delfmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schubert_P/0/1/0/all/0/1">Petra Schubert</a></p>
<p>One aim of Process Mining (PM) is the discovery of process models from event
logs of information systems. PM has been successfully applied to
process-oriented enterprise systems but is less suited for communication- and
document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are
very fine-granular and PM applied to their logs results in spaghetti models. A
common solution for this is event abstraction, i.e., converting low-level logs
into more abstract high-level logs before running discovery algorithms. ECS
logs come with special characteristics that have so far not been fully
addressed by existing event abstraction approaches. We aim to close this gap
with a tailored ECS event abstraction (ECSEA) approach that trains a model by
comparing recorded actual user activities (high-level traces) with the
system-generated low-level traces (extracted from the ECS). The model allows us
to automatically convert future low-level traces into an abstracted high-level
log that can be used for PM. Our evaluation shows that the algorithm produces
accurate results. ECSEA is a preprocessing method that is essential for the
interpretation of collaborative work activity in ECS, which we call Social
Process Mining.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.03217">Local Consensus Enhanced Siamese Network with Reciprocal Loss for Two-view Correspondence Learning. (arXiv:2308.03217v1 [cs.CV] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Linbo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xianyong Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1">Chenjie Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a></p>
<p>Recent studies of two-view correspondence learning usually establish an
end-to-end network to jointly predict correspondence reliability and relative
pose. We improve such a framework from two aspects. First, we propose a Local
Feature Consensus (LFC) plugin block to augment the features of existing
models. Given a correspondence feature, the block augments its neighboring
features with mutual neighborhood consensus and aggregates them to produce an
enhanced feature. As inliers obey a uniform cross-view transformation and share
more consistent learned features than outliers, feature consensus strengthens
inlier correlation and suppresses outlier distraction, which makes output
features more discriminative for classifying inliers/outliers. Second, existing
approaches supervise network training with the ground truth correspondences and
essential matrix projecting one image to the other for an input image pair,
without considering the information from the reverse mapping. We extend
existing models to a Siamese network with a reciprocal loss that exploits the
supervision of mutual projection, which considerably promotes the matching
performance without introducing additional model parameters. Building upon
MSA-Net, we implement the two proposals and experimentally achieve
state-of-the-art performance on benchmark datasets.
</p>
</p>
</div>
<div class="article">
<h1><a href="http://arxiv.org/abs/2308.04226">OpinionConv: Conversational Product Search with Grounded Opinions. (arXiv:2308.04226v1 [cs.HC] CROSS LISTED)</a></h1>
<p><b>Authors:</b>  <a href="http://arxiv.org/find/cs/1/au:+Javadi_V/0/1/0/all/0/1">Vahid Sadiri Javadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Potthast_M/0/1/0/all/0/1">Martin Potthast</a>, <a href="http://arxiv.org/find/cs/1/au:+Flek_L/0/1/0/all/0/1">Lucie Flek</a></p>
<p>When searching for products, the opinions of others play an important role in
making informed decisions. Subjective experiences about a product can be a
valuable source of information. This is also true in sales conversations, where
a customer and a sales assistant exchange facts and opinions about products.
However, training an AI for such conversations is complicated by the fact that
language models do not possess authentic opinions for their lack of real-world
experience. We address this problem by leveraging product reviews as a rich
source of product opinions to ground conversational AI in true subjective
narratives. With OpinionConv, we develop the first conversational AI for
simulating sales conversations. To validate the generated conversations, we
conduct several user studies showing that the generated opinions are perceived
as realistic. Our assessors also confirm the importance of opinions as an
informative basis for decision-making.
</p>
</p>
</div>

    </div>
    </body>
    